{"textgrid.poem.48565": {"metadata": {"author": {"name": "Fleming, Paul", "birth": "N.A.", "death": "N.A."}, "title": "14. Auf Herren Timothei Poli neugebornen T\u00f6chterleins Christinen ihr Absterben", "genre": "verse", "period": "N.A.", "pub_year": 1624, "urn": "N.A.", "language": ["de:0.57", "nl:0.42"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ists denn wieder schon verloren?", "tokens": ["Ists", "denn", "wie\u00b7der", "schon", "ver\u00b7lo\u00b7ren", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "ADV", "ADV", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "War es doch kaum recht geboren,", "tokens": ["War", "es", "doch", "kaum", "recht", "ge\u00b7bo\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ADV", "ADJD", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "das geliebte sch\u00f6ne Kind!", "tokens": ["das", "ge\u00b7lieb\u00b7te", "sch\u00f6\u00b7ne", "Kind", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Ja! So bald es vor ist kommen,", "tokens": ["Ja", "!", "So", "bald", "es", "vor", "ist", "kom\u00b7men", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$.", "ADV", "ADV", "PPER", "APPR", "VAFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "so bald ist es auch genommen.", "tokens": ["so", "bald", "ist", "es", "auch", "ge\u00b7nom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VAFIN", "PPER", "ADV", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Schaut doch, was wir Menschen sind!", "tokens": ["Schaut", "doch", ",", "was", "wir", "Men\u00b7schen", "sind", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "$,", "PRELS", "PPER", "NN", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Etwan wie ein Tausentsch\u00f6nlein,", "tokens": ["Et\u00b7wan", "wie", "ein", "Tau\u00b7sent\u00b7sch\u00f6n\u00b7lein", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "ART", "NN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.2": {"text": "das gemalte Lenzens\u00f6hnlein,", "tokens": ["das", "ge\u00b7mal\u00b7te", "Len\u00b7zen\u00b7s\u00f6hn\u00b7lein", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "mit dem fr\u00fchen Tag' entsteht,", "tokens": ["mit", "dem", "fr\u00fc\u00b7hen", "Tag'", "ent\u00b7steht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "welches, wie es mit ihm wachet,", "tokens": ["wel\u00b7ches", ",", "wie", "es", "mit", "ihm", "wa\u00b7chet", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "$,", "PWAV", "PPER", "APPR", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "mit ihm scheinet, mit ihm lachet,", "tokens": ["mit", "ihm", "schei\u00b7net", ",", "mit", "ihm", "la\u00b7chet", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVFIN", "$,", "APPR", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "so auch mit ihm untergeht:", "tokens": ["so", "auch", "mit", "ihm", "un\u00b7ter\u00b7geht", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "PPER", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "also hastu dich verborgen,", "tokens": ["al\u00b7so", "has\u00b7tu", "dich", "ver\u00b7bor\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Bl\u00fcmlein, um den sechsten Morgen,", "tokens": ["Bl\u00fcm\u00b7lein", ",", "um", "den", "sechs\u00b7ten", "Mor\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KOUI", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "liegest tot nun hingestreckt,", "tokens": ["lie\u00b7gest", "tot", "nun", "hin\u00b7ge\u00b7streckt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "ADV", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "und hast durch das schnelle Scheiden", "tokens": ["und", "hast", "durch", "das", "schnel\u00b7le", "Schei\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "APPR", "ART", "ADJA", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "deinen frommen Eltern beiden", "tokens": ["dei\u00b7nen", "from\u00b7men", "El\u00b7tern", "bei\u00b7den"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN", "PIAT"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "ein sehr langes Leid erweckt.", "tokens": ["ein", "sehr", "lan\u00b7ges", "Leid", "er\u00b7weckt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJA", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Klagt, Betr\u00fcbte, wie ihr sollet!", "tokens": ["Klagt", ",", "Be\u00b7tr\u00fcb\u00b7te", ",", "wie", "ihr", "sol\u00b7let", "!"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "NN", "$,", "PWAV", "PPER", "VMFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sie ist doch, wo ihr hin wollet.", "tokens": ["Sie", "ist", "doch", ",", "wo", "ihr", "hin", "wol\u00b7let", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "$,", "PWAV", "PPER", "ADV", "VMFIN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Uns ist \u00fcbel, ihr ist wol.", "tokens": ["Uns", "ist", "\u00fc\u00b7bel", ",", "ihr", "ist", "wol", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "$,", "PPER", "VAFIN", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Ihr Geist, der ist voller Prangen;", "tokens": ["Ihr", "Geist", ",", "der", "ist", "vol\u00b7ler", "Pran\u00b7gen", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PRELS", "VAFIN", "ADJA", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "nur ihr Leib ist hingegangen,", "tokens": ["nur", "ihr", "Leib", "ist", "hin\u00b7ge\u00b7gan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "wohin Alles ist und soll.", "tokens": ["wo\u00b7hin", "Al\u00b7les", "ist", "und", "soll", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "VAFIN", "KON", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Wo selbst die Natur hin stehet,", "tokens": ["Wo", "selbst", "die", "Na\u00b7tur", "hin", "ste\u00b7het", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "ART", "NN", "ADV", "VVFIN", "$,"], "meter": "+---+-+-", "measure": "dactylic.init"}, "line.2": {"text": "wo die gro\u00dfe Welt hin gehet,", "tokens": ["wo", "die", "gro\u00b7\u00dfe", "Welt", "hin", "ge\u00b7het", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADJA", "NN", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "dem eilt auch die kleine zu.", "tokens": ["dem", "eilt", "auch", "die", "klei\u00b7ne", "zu", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "ART", "ADJA", "PTKVZ", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Sterben und geboren werden", "tokens": ["Ster\u00b7ben", "und", "ge\u00b7bo\u00b7ren", "wer\u00b7den"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "KON", "VVPP", "VAINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "ist das stete Tun der Erden;", "tokens": ["ist", "das", "ste\u00b7te", "Tun", "der", "Er\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "ADJA", "NN", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "nur ihr Tod ist ihre Ruh'.", "tokens": ["nur", "ihr", "Tod", "ist", "ih\u00b7re", "Ruh'", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "VAFIN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Babels Mauren sind versunken,", "tokens": ["Ba\u00b7bels", "Mau\u00b7ren", "sind", "ver\u00b7sun\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Rhodus sein Kolo\u00df ertrunken,", "tokens": ["Rho\u00b7dus", "sein", "Ko\u00b7lo\u00df", "er\u00b7trun\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "PPOSAT", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Nilus Werke giengen ein.", "tokens": ["Ni\u00b7lus", "Wer\u00b7ke", "gien\u00b7gen", "ein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "VVFIN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Sterblich waren alle Wunder", "tokens": ["Sterb\u00b7lich", "wa\u00b7ren", "al\u00b7le", "Wun\u00b7der"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJD", "VAFIN", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "wie die Meister, wie itzunder", "tokens": ["wie", "die", "Meis\u00b7ter", ",", "wie", "it\u00b7zun\u00b7der"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["PWAV", "ART", "NN", "$,", "PWAV", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "wir und k\u00fcnftig Alle sein.", "tokens": ["wir", "und", "k\u00fcnf\u00b7tig", "Al\u00b7le", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "KON", "ADJD", "PIS", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Assur wurde teil den Persen,", "tokens": ["As\u00b7sur", "wur\u00b7de", "teil", "den", "Per\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "di\u00df dem Griechen. Dessen Fersen", "tokens": ["di\u00df", "dem", "Grie\u00b7chen", ".", "Des\u00b7sen", "Fer\u00b7sen"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["PDS", "ART", "NN", "$.", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "folgte nach die ewge Stadt.", "tokens": ["folg\u00b7te", "nach", "die", "ew\u00b7ge", "Stadt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Doch, wie ewig sie gewesen,", "tokens": ["Doch", ",", "wie", "e\u00b7wig", "sie", "ge\u00b7we\u00b7sen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "PWAV", "ADJD", "PPER", "VAPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "kan man h\u00f6ren, sehn und lesen:", "tokens": ["kan", "man", "h\u00f6\u00b7ren", ",", "sehn", "und", "le\u00b7sen", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIS", "VVINF", "$,", "VVINF", "KON", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Schein ists, was sie Ewigs hat.", "tokens": ["Schein", "ists", ",", "was", "sie", "E\u00b7wigs", "hat", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "$,", "PRELS", "PPER", "ADV", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Alles wird darum geboren,", "tokens": ["Al\u00b7les", "wird", "da\u00b7rum", "ge\u00b7bo\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "PAV", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "da\u00df es wieder sei verloren.", "tokens": ["da\u00df", "es", "wie\u00b7der", "sei", "ver\u00b7lo\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VAFIN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Nichts bleibt allzeit, was so ist.", "tokens": ["Nichts", "bleibt", "all\u00b7zeit", ",", "was", "so", "ist", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ADV", "$,", "PRELS", "ADV", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Alles, was sich angefangen,", "tokens": ["Al\u00b7les", ",", "was", "sich", "an\u00b7ge\u00b7fan\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["PIS", "$,", "PRELS", "PRF", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "gehet stets in dem Verlangen,", "tokens": ["ge\u00b7het", "stets", "in", "dem", "Ver\u00b7lan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "da\u00df es seinen Tod erkiest.", "tokens": ["da\u00df", "es", "sei\u00b7nen", "Tod", "er\u00b7kiest", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Sterben ist der Weg zum Leben;", "tokens": ["Ster\u00b7ben", "ist", "der", "Weg", "zum", "Le\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ART", "NN", "APPRART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ph\u00f6nix wird es Zeugn\u00fc\u00df geben,", "tokens": ["Ph\u00f6\u00b7nix", "wird", "es", "Zeug\u00b7n\u00fc\u00df", "ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PPER", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "selbst sein Vater, selbst sein Kind.", "tokens": ["selbst", "sein", "Va\u00b7ter", ",", "selbst", "sein", "Kind", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "$,", "ADV", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Soll es morgen wieder tagen,", "tokens": ["Soll", "es", "mor\u00b7gen", "wie\u00b7der", "ta\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "ADV", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "so wird Heute hin getragen,", "tokens": ["so", "wird", "Heu\u00b7te", "hin", "ge\u00b7tra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "wo viel' tausent' Gestern sind.", "tokens": ["wo", "viel'", "tau\u00b7sent'", "Ge\u00b7stern", "sind", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "VVFIN", "NN", "VAFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "Es ist Alles Gottes Gabe.", "tokens": ["Es", "ist", "Al\u00b7les", "Got\u00b7tes", "Ga\u00b7be", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIAT", "NN", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Alles, was ich itzund habe,", "tokens": ["Al\u00b7les", ",", "was", "ich", "it\u00b7zund", "ha\u00b7be", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "$,", "PWS", "PPER", "ADV", "VAFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "hab' ich vormals nicht gehabt;", "tokens": ["hab'", "ich", "vor\u00b7mals", "nicht", "ge\u00b7habt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "PTKNEG", "VAPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "der irrt, der es ewig gl\u00e4ubet.", "tokens": ["der", "irrt", ",", "der", "es", "e\u00b7wig", "gl\u00e4u\u00b7bet", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "VVFIN", "$,", "PRELS", "PPER", "ADJD", "VVFIN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Wucher ists, so lang' es bleibet,", "tokens": ["Wu\u00b7cher", "ists", ",", "so", "lang'", "es", "blei\u00b7bet", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "$,", "ADV", "ADV", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "was uns unsern Sin erlabt.", "tokens": ["was", "uns", "un\u00b7sern", "Sin", "er\u00b7labt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "PPOSAT", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Als Gott sie euch \u00fcberreichet,", "tokens": ["Als", "Gott", "sie", "euch", "\u00fc\u00b7berr\u00b7ei\u00b7chet", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "PPER", "PPER", "VVFIN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "habt ihr euch mit ihm vergleichet,", "tokens": ["habt", "ihr", "euch", "mit", "ihm", "ver\u00b7glei\u00b7chet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PRF", "APPR", "PPER", "VVFIN", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.3": {"text": "da\u00df sie dennoch seine sei.", "tokens": ["da\u00df", "sie", "den\u00b7noch", "sei\u00b7ne", "sei", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PPOSAT", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Da\u00df er, wenn er auch nur wolte,", "tokens": ["Da\u00df", "er", ",", "wenn", "er", "auch", "nur", "wol\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "KOUS", "PPER", "ADV", "ADV", "VMFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "sie hinwieder nehmen solte,", "tokens": ["sie", "hin\u00b7wie\u00b7der", "neh\u00b7men", "sol\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVINF", "VMFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "mu\u00dftet ihr ihm stellen frei.", "tokens": ["mu\u00df\u00b7tet", "ihr", "ihm", "stel\u00b7len", "frei", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PPER", "VVFIN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Und die Warheit rau\u00df zu sagen:", "tokens": ["Und", "die", "War\u00b7heit", "rau\u00df", "zu", "sa\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "PTKVZ", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Neid ists, da\u00df wir sie beklagen.", "tokens": ["Neid", "ists", ",", "da\u00df", "wir", "sie", "be\u00b7kla\u00b7gen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "$,", "KOUS", "PPER", "PPER", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wol dir, o du kurzer Gast!", "tokens": ["Wol", "dir", ",", "o", "du", "kur\u00b7zer", "Gast", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "$,", "FM", "PPER", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wol dir, die du in sechs Tagen", "tokens": ["Wol", "dir", ",", "die", "du", "in", "sechs", "Ta\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "PPER", "$,", "PRELS", "PPER", "APPR", "CARD", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "eines ieden Alters Plagen", "tokens": ["ei\u00b7nes", "ie\u00b7den", "Al\u00b7ters", "Pla\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "PIAT", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "g\u00e4nzlich \u00fcberstanden hast!", "tokens": ["g\u00e4nz\u00b7lich", "\u00fc\u00b7bers\u00b7tan\u00b7den", "hast", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "VVPP", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Kleine Tochter, sei nun seelig", "tokens": ["Klei\u00b7ne", "Toch\u00b7ter", ",", "sei", "nun", "see\u00b7lig"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ADJA", "NN", "$,", "VAFIN", "ADV", "ADJD"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "und zeuch uns auch stets allm\u00e4lig", "tokens": ["und", "zeuch", "uns", "auch", "stets", "all\u00b7m\u00e4\u00b7lig"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVIMP", "PPER", "ADV", "ADV", "ADJD"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "nach dir auf und Himmel an,", "tokens": ["nach", "dir", "auf", "und", "Him\u00b7mel", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "PTKVZ", "KON", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "da\u00df auch wir der Zahl der Frommen", "tokens": ["da\u00df", "auch", "wir", "der", "Zahl", "der", "From\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "PPER", "ART", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "in die du bist aufgenommen,", "tokens": ["in", "die", "du", "bist", "auf\u00b7ge\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "balde werden zugetan!", "tokens": ["bal\u00b7de", "wer\u00b7den", "zu\u00b7ge\u00b7tan", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "Diesen Korb voll Anemonen,", "tokens": ["Die\u00b7sen", "Korb", "voll", "A\u00b7ne\u00b7mo\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "ADJD", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "der der Frost stets soll verschonen,", "tokens": ["der", "der", "Frost", "stets", "soll", "ver\u00b7scho\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "ADV", "VMFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "streuen wir auf deine Gruft.", "tokens": ["streu\u00b7en", "wir", "auf", "dei\u00b7ne", "Gruft", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Schlafe ruhsam in dem K\u00fchlen!", "tokens": ["Schla\u00b7fe", "ruh\u00b7sam", "in", "dem", "K\u00fch\u00b7len", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Um dich her soll ewig spielen", "tokens": ["Um", "dich", "her", "soll", "e\u00b7wig", "spie\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUI", "PRF", "APZR", "VMFIN", "ADJD", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "die gesunde Maienluft.", "tokens": ["die", "ge\u00b7sun\u00b7de", "Mai\u00b7en\u00b7luft", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.15": {"line.1": {"text": "Ists denn wieder schon verloren?", "tokens": ["Ists", "denn", "wie\u00b7der", "schon", "ver\u00b7lo\u00b7ren", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "ADV", "ADV", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "War es doch kaum recht geboren,", "tokens": ["War", "es", "doch", "kaum", "recht", "ge\u00b7bo\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ADV", "ADJD", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "das geliebte sch\u00f6ne Kind!", "tokens": ["das", "ge\u00b7lieb\u00b7te", "sch\u00f6\u00b7ne", "Kind", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Ja! So bald es vor ist kommen,", "tokens": ["Ja", "!", "So", "bald", "es", "vor", "ist", "kom\u00b7men", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$.", "ADV", "ADV", "PPER", "APPR", "VAFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "so bald ist es auch genommen.", "tokens": ["so", "bald", "ist", "es", "auch", "ge\u00b7nom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VAFIN", "PPER", "ADV", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Schaut doch, was wir Menschen sind!", "tokens": ["Schaut", "doch", ",", "was", "wir", "Men\u00b7schen", "sind", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "$,", "PRELS", "PPER", "NN", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.16": {"line.1": {"text": "Etwan wie ein Tausentsch\u00f6nlein,", "tokens": ["Et\u00b7wan", "wie", "ein", "Tau\u00b7sent\u00b7sch\u00f6n\u00b7lein", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "ART", "NN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.2": {"text": "das gemalte Lenzens\u00f6hnlein,", "tokens": ["das", "ge\u00b7mal\u00b7te", "Len\u00b7zen\u00b7s\u00f6hn\u00b7lein", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "mit dem fr\u00fchen Tag' entsteht,", "tokens": ["mit", "dem", "fr\u00fc\u00b7hen", "Tag'", "ent\u00b7steht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "welches, wie es mit ihm wachet,", "tokens": ["wel\u00b7ches", ",", "wie", "es", "mit", "ihm", "wa\u00b7chet", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "$,", "PWAV", "PPER", "APPR", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "mit ihm scheinet, mit ihm lachet,", "tokens": ["mit", "ihm", "schei\u00b7net", ",", "mit", "ihm", "la\u00b7chet", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVFIN", "$,", "APPR", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "so auch mit ihm untergeht:", "tokens": ["so", "auch", "mit", "ihm", "un\u00b7ter\u00b7geht", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "PPER", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.17": {"line.1": {"text": "also hastu dich verborgen,", "tokens": ["al\u00b7so", "has\u00b7tu", "dich", "ver\u00b7bor\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Bl\u00fcmlein, um den sechsten Morgen,", "tokens": ["Bl\u00fcm\u00b7lein", ",", "um", "den", "sechs\u00b7ten", "Mor\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KOUI", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "liegest tot nun hingestreckt,", "tokens": ["lie\u00b7gest", "tot", "nun", "hin\u00b7ge\u00b7streckt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "ADV", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "und hast durch das schnelle Scheiden", "tokens": ["und", "hast", "durch", "das", "schnel\u00b7le", "Schei\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "APPR", "ART", "ADJA", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "deinen frommen Eltern beiden", "tokens": ["dei\u00b7nen", "from\u00b7men", "El\u00b7tern", "bei\u00b7den"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN", "PIAT"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "ein sehr langes Leid erweckt.", "tokens": ["ein", "sehr", "lan\u00b7ges", "Leid", "er\u00b7weckt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJA", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.18": {"line.1": {"text": "Klagt, Betr\u00fcbte, wie ihr sollet!", "tokens": ["Klagt", ",", "Be\u00b7tr\u00fcb\u00b7te", ",", "wie", "ihr", "sol\u00b7let", "!"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "NN", "$,", "PWAV", "PPER", "VMFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sie ist doch, wo ihr hin wollet.", "tokens": ["Sie", "ist", "doch", ",", "wo", "ihr", "hin", "wol\u00b7let", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "$,", "PWAV", "PPER", "ADV", "VMFIN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Uns ist \u00fcbel, ihr ist wol.", "tokens": ["Uns", "ist", "\u00fc\u00b7bel", ",", "ihr", "ist", "wol", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "$,", "PPER", "VAFIN", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Ihr Geist, der ist voller Prangen;", "tokens": ["Ihr", "Geist", ",", "der", "ist", "vol\u00b7ler", "Pran\u00b7gen", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PRELS", "VAFIN", "ADJA", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "nur ihr Leib ist hingegangen,", "tokens": ["nur", "ihr", "Leib", "ist", "hin\u00b7ge\u00b7gan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "wohin Alles ist und soll.", "tokens": ["wo\u00b7hin", "Al\u00b7les", "ist", "und", "soll", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "VAFIN", "KON", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.19": {"line.1": {"text": "Wo selbst die Natur hin stehet,", "tokens": ["Wo", "selbst", "die", "Na\u00b7tur", "hin", "ste\u00b7het", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "ART", "NN", "ADV", "VVFIN", "$,"], "meter": "+---+-+-", "measure": "dactylic.init"}, "line.2": {"text": "wo die gro\u00dfe Welt hin gehet,", "tokens": ["wo", "die", "gro\u00b7\u00dfe", "Welt", "hin", "ge\u00b7het", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADJA", "NN", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "dem eilt auch die kleine zu.", "tokens": ["dem", "eilt", "auch", "die", "klei\u00b7ne", "zu", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "ART", "ADJA", "PTKVZ", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Sterben und geboren werden", "tokens": ["Ster\u00b7ben", "und", "ge\u00b7bo\u00b7ren", "wer\u00b7den"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "KON", "VVPP", "VAINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "ist das stete Tun der Erden;", "tokens": ["ist", "das", "ste\u00b7te", "Tun", "der", "Er\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "ADJA", "NN", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "nur ihr Tod ist ihre Ruh'.", "tokens": ["nur", "ihr", "Tod", "ist", "ih\u00b7re", "Ruh'", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "VAFIN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.20": {"line.1": {"text": "Babels Mauren sind versunken,", "tokens": ["Ba\u00b7bels", "Mau\u00b7ren", "sind", "ver\u00b7sun\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Rhodus sein Kolo\u00df ertrunken,", "tokens": ["Rho\u00b7dus", "sein", "Ko\u00b7lo\u00df", "er\u00b7trun\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "PPOSAT", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Nilus Werke giengen ein.", "tokens": ["Ni\u00b7lus", "Wer\u00b7ke", "gien\u00b7gen", "ein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "VVFIN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Sterblich waren alle Wunder", "tokens": ["Sterb\u00b7lich", "wa\u00b7ren", "al\u00b7le", "Wun\u00b7der"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJD", "VAFIN", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "wie die Meister, wie itzunder", "tokens": ["wie", "die", "Meis\u00b7ter", ",", "wie", "it\u00b7zun\u00b7der"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["PWAV", "ART", "NN", "$,", "PWAV", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "wir und k\u00fcnftig Alle sein.", "tokens": ["wir", "und", "k\u00fcnf\u00b7tig", "Al\u00b7le", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "KON", "ADJD", "PIS", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.21": {"line.1": {"text": "Assur wurde teil den Persen,", "tokens": ["As\u00b7sur", "wur\u00b7de", "teil", "den", "Per\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "di\u00df dem Griechen. Dessen Fersen", "tokens": ["di\u00df", "dem", "Grie\u00b7chen", ".", "Des\u00b7sen", "Fer\u00b7sen"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["PDS", "ART", "NN", "$.", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "folgte nach die ewge Stadt.", "tokens": ["folg\u00b7te", "nach", "die", "ew\u00b7ge", "Stadt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Doch, wie ewig sie gewesen,", "tokens": ["Doch", ",", "wie", "e\u00b7wig", "sie", "ge\u00b7we\u00b7sen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "PWAV", "ADJD", "PPER", "VAPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "kan man h\u00f6ren, sehn und lesen:", "tokens": ["kan", "man", "h\u00f6\u00b7ren", ",", "sehn", "und", "le\u00b7sen", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIS", "VVINF", "$,", "VVINF", "KON", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Schein ists, was sie Ewigs hat.", "tokens": ["Schein", "ists", ",", "was", "sie", "E\u00b7wigs", "hat", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "$,", "PRELS", "PPER", "ADV", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.22": {"line.1": {"text": "Alles wird darum geboren,", "tokens": ["Al\u00b7les", "wird", "da\u00b7rum", "ge\u00b7bo\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "PAV", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "da\u00df es wieder sei verloren.", "tokens": ["da\u00df", "es", "wie\u00b7der", "sei", "ver\u00b7lo\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VAFIN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Nichts bleibt allzeit, was so ist.", "tokens": ["Nichts", "bleibt", "all\u00b7zeit", ",", "was", "so", "ist", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ADV", "$,", "PRELS", "ADV", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Alles, was sich angefangen,", "tokens": ["Al\u00b7les", ",", "was", "sich", "an\u00b7ge\u00b7fan\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["PIS", "$,", "PRELS", "PRF", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "gehet stets in dem Verlangen,", "tokens": ["ge\u00b7het", "stets", "in", "dem", "Ver\u00b7lan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "da\u00df es seinen Tod erkiest.", "tokens": ["da\u00df", "es", "sei\u00b7nen", "Tod", "er\u00b7kiest", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.23": {"line.1": {"text": "Sterben ist der Weg zum Leben;", "tokens": ["Ster\u00b7ben", "ist", "der", "Weg", "zum", "Le\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ART", "NN", "APPRART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ph\u00f6nix wird es Zeugn\u00fc\u00df geben,", "tokens": ["Ph\u00f6\u00b7nix", "wird", "es", "Zeug\u00b7n\u00fc\u00df", "ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PPER", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "selbst sein Vater, selbst sein Kind.", "tokens": ["selbst", "sein", "Va\u00b7ter", ",", "selbst", "sein", "Kind", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "$,", "ADV", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Soll es morgen wieder tagen,", "tokens": ["Soll", "es", "mor\u00b7gen", "wie\u00b7der", "ta\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "ADV", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "so wird Heute hin getragen,", "tokens": ["so", "wird", "Heu\u00b7te", "hin", "ge\u00b7tra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "wo viel' tausent' Gestern sind.", "tokens": ["wo", "viel'", "tau\u00b7sent'", "Ge\u00b7stern", "sind", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "VVFIN", "NN", "VAFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.24": {"line.1": {"text": "Es ist Alles Gottes Gabe.", "tokens": ["Es", "ist", "Al\u00b7les", "Got\u00b7tes", "Ga\u00b7be", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIAT", "NN", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Alles, was ich itzund habe,", "tokens": ["Al\u00b7les", ",", "was", "ich", "it\u00b7zund", "ha\u00b7be", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "$,", "PWS", "PPER", "ADV", "VAFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "hab' ich vormals nicht gehabt;", "tokens": ["hab'", "ich", "vor\u00b7mals", "nicht", "ge\u00b7habt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "PTKNEG", "VAPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "der irrt, der es ewig gl\u00e4ubet.", "tokens": ["der", "irrt", ",", "der", "es", "e\u00b7wig", "gl\u00e4u\u00b7bet", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "VVFIN", "$,", "PRELS", "PPER", "ADJD", "VVFIN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Wucher ists, so lang' es bleibet,", "tokens": ["Wu\u00b7cher", "ists", ",", "so", "lang'", "es", "blei\u00b7bet", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "$,", "ADV", "ADV", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "was uns unsern Sin erlabt.", "tokens": ["was", "uns", "un\u00b7sern", "Sin", "er\u00b7labt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "PPOSAT", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.25": {"line.1": {"text": "Als Gott sie euch \u00fcberreichet,", "tokens": ["Als", "Gott", "sie", "euch", "\u00fc\u00b7berr\u00b7ei\u00b7chet", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "PPER", "PPER", "VVFIN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "habt ihr euch mit ihm vergleichet,", "tokens": ["habt", "ihr", "euch", "mit", "ihm", "ver\u00b7glei\u00b7chet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PRF", "APPR", "PPER", "VVFIN", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.3": {"text": "da\u00df sie dennoch seine sei.", "tokens": ["da\u00df", "sie", "den\u00b7noch", "sei\u00b7ne", "sei", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PPOSAT", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Da\u00df er, wenn er auch nur wolte,", "tokens": ["Da\u00df", "er", ",", "wenn", "er", "auch", "nur", "wol\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "KOUS", "PPER", "ADV", "ADV", "VMFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "sie hinwieder nehmen solte,", "tokens": ["sie", "hin\u00b7wie\u00b7der", "neh\u00b7men", "sol\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVINF", "VMFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "mu\u00dftet ihr ihm stellen frei.", "tokens": ["mu\u00df\u00b7tet", "ihr", "ihm", "stel\u00b7len", "frei", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PPER", "VVFIN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.26": {"line.1": {"text": "Und die Warheit rau\u00df zu sagen:", "tokens": ["Und", "die", "War\u00b7heit", "rau\u00df", "zu", "sa\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "PTKVZ", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Neid ists, da\u00df wir sie beklagen.", "tokens": ["Neid", "ists", ",", "da\u00df", "wir", "sie", "be\u00b7kla\u00b7gen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "$,", "KOUS", "PPER", "PPER", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wol dir, o du kurzer Gast!", "tokens": ["Wol", "dir", ",", "o", "du", "kur\u00b7zer", "Gast", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "$,", "FM", "PPER", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wol dir, die du in sechs Tagen", "tokens": ["Wol", "dir", ",", "die", "du", "in", "sechs", "Ta\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "PPER", "$,", "PRELS", "PPER", "APPR", "CARD", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "eines ieden Alters Plagen", "tokens": ["ei\u00b7nes", "ie\u00b7den", "Al\u00b7ters", "Pla\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "PIAT", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "g\u00e4nzlich \u00fcberstanden hast!", "tokens": ["g\u00e4nz\u00b7lich", "\u00fc\u00b7bers\u00b7tan\u00b7den", "hast", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "VVPP", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.27": {"line.1": {"text": "Kleine Tochter, sei nun seelig", "tokens": ["Klei\u00b7ne", "Toch\u00b7ter", ",", "sei", "nun", "see\u00b7lig"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ADJA", "NN", "$,", "VAFIN", "ADV", "ADJD"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "und zeuch uns auch stets allm\u00e4lig", "tokens": ["und", "zeuch", "uns", "auch", "stets", "all\u00b7m\u00e4\u00b7lig"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVIMP", "PPER", "ADV", "ADV", "ADJD"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "nach dir auf und Himmel an,", "tokens": ["nach", "dir", "auf", "und", "Him\u00b7mel", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "PTKVZ", "KON", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "da\u00df auch wir der Zahl der Frommen", "tokens": ["da\u00df", "auch", "wir", "der", "Zahl", "der", "From\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "PPER", "ART", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "in die du bist aufgenommen,", "tokens": ["in", "die", "du", "bist", "auf\u00b7ge\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "balde werden zugetan!", "tokens": ["bal\u00b7de", "wer\u00b7den", "zu\u00b7ge\u00b7tan", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.28": {"line.1": {"text": "Diesen Korb voll Anemonen,", "tokens": ["Die\u00b7sen", "Korb", "voll", "A\u00b7ne\u00b7mo\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "ADJD", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "der der Frost stets soll verschonen,", "tokens": ["der", "der", "Frost", "stets", "soll", "ver\u00b7scho\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "ADV", "VMFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "streuen wir auf deine Gruft.", "tokens": ["streu\u00b7en", "wir", "auf", "dei\u00b7ne", "Gruft", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Schlafe ruhsam in dem K\u00fchlen!", "tokens": ["Schla\u00b7fe", "ruh\u00b7sam", "in", "dem", "K\u00fch\u00b7len", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Um dich her soll ewig spielen", "tokens": ["Um", "dich", "her", "soll", "e\u00b7wig", "spie\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUI", "PRF", "APZR", "VMFIN", "ADJD", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "die gesunde Maienluft.", "tokens": ["die", "ge\u00b7sun\u00b7de", "Mai\u00b7en\u00b7luft", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}