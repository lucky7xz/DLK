{"textgrid.poem.54932": {"metadata": {"author": {"name": "Scheerbart, Paul", "birth": "N.A.", "death": "N.A."}, "title": "1L: Ja \u2013 meine Sonnenk\u00e4lber", "genre": "verse", "period": "N.A.", "pub_year": 1889, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ja \u2013 meine Sonnenk\u00e4lber", "tokens": ["Ja", "\u2013", "mei\u00b7ne", "Son\u00b7nen\u00b7k\u00e4l\u00b7ber"], "token_info": ["word", "punct", "word", "word"], "pos": ["PTKANT", "$(", "PPOSAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Sind mit \u00d6l begossen,", "tokens": ["Sind", "mit", "\u00d6l", "be\u00b7gos\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "NN", "VVPP", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Sind na\u00df wie Badelaken", "tokens": ["Sind", "na\u00df", "wie", "Ba\u00b7de\u00b7la\u00b7ken"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "ADJD", "KOKOM", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und erweichte Schrippen.", "tokens": ["Und", "er\u00b7weich\u00b7te", "Schrip\u00b7pen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.5": {"text": "Ich wei\u00df mit diesen feuchten", "tokens": ["Ich", "wei\u00df", "mit", "die\u00b7sen", "feuch\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "PDAT", "ADJA"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "M\u00e4rchenweltschleimtieren", "tokens": ["M\u00e4r\u00b7chen\u00b7welt\u00b7schleim\u00b7tie\u00b7ren"], "token_info": ["word"], "pos": ["NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.7": {"text": "Nichts anzufangen \u2013 nichts.", "tokens": ["Nichts", "an\u00b7zu\u00b7fan\u00b7gen", "\u2013", "nichts", "."], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["PIS", "VVIZU", "$(", "PIS", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "Solche alten Sp\u00e4\u00dfe", "tokens": ["Sol\u00b7che", "al\u00b7ten", "Sp\u00e4\u00b7\u00dfe"], "token_info": ["word", "word", "word"], "pos": ["PIAT", "ADJA", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.9": {"text": "Sind doch eigentlich abscheulich.", "tokens": ["Sind", "doch", "ei\u00b7gent\u00b7lich", "ab\u00b7scheu\u00b7lich", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "ADJD", "$."], "meter": "+-+--+--", "measure": "trochaic.tri.relaxed"}}, "stanza.2": {"line.1": {"text": "Ja \u2013 meine Sonnenk\u00e4lber", "tokens": ["Ja", "\u2013", "mei\u00b7ne", "Son\u00b7nen\u00b7k\u00e4l\u00b7ber"], "token_info": ["word", "punct", "word", "word"], "pos": ["PTKANT", "$(", "PPOSAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Sind mit \u00d6l begossen,", "tokens": ["Sind", "mit", "\u00d6l", "be\u00b7gos\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "NN", "VVPP", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Sind na\u00df wie Badelaken", "tokens": ["Sind", "na\u00df", "wie", "Ba\u00b7de\u00b7la\u00b7ken"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "ADJD", "KOKOM", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und erweichte Schrippen.", "tokens": ["Und", "er\u00b7weich\u00b7te", "Schrip\u00b7pen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.5": {"text": "Ich wei\u00df mit diesen feuchten", "tokens": ["Ich", "wei\u00df", "mit", "die\u00b7sen", "feuch\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "PDAT", "ADJA"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "M\u00e4rchenweltschleimtieren", "tokens": ["M\u00e4r\u00b7chen\u00b7welt\u00b7schleim\u00b7tie\u00b7ren"], "token_info": ["word"], "pos": ["NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.7": {"text": "Nichts anzufangen \u2013 nichts.", "tokens": ["Nichts", "an\u00b7zu\u00b7fan\u00b7gen", "\u2013", "nichts", "."], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["PIS", "VVIZU", "$(", "PIS", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "Solche alten Sp\u00e4\u00dfe", "tokens": ["Sol\u00b7che", "al\u00b7ten", "Sp\u00e4\u00b7\u00dfe"], "token_info": ["word", "word", "word"], "pos": ["PIAT", "ADJA", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.9": {"text": "Sind doch eigentlich abscheulich.", "tokens": ["Sind", "doch", "ei\u00b7gent\u00b7lich", "ab\u00b7scheu\u00b7lich", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "ADJD", "$."], "meter": "+-+--+--", "measure": "trochaic.tri.relaxed"}}}}}