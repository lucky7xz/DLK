{"dta.poem.9208": {"metadata": {"author": {"name": "Weise, Christian", "birth": "N.A.", "death": "N.A."}, "title": "ViII.  \n Ein Abri\u00df der Sch\u00f6nheit selber.", "genre": "Lyrik; Drama; Prosa", "period": "N.A.", "pub_year": "1701", "urn": "urn:nbn:de:kobv:b4-25043-0", "language": ["de:0.99"], "booktitle": "Weise, Christian: \u00dcberfl\u00fc\u00dfige Gedancken Der gr\u00fcnenden jugend. Leipzig, 1701."}, "poem": {"stanza.1": {"line.1": {"text": "Ich wei\u00df ein liebes sch\u00e4tzgen/", "tokens": ["Ich", "wei\u00df", "ein", "lie\u00b7bes", "sch\u00e4tz\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Ein artig kammer k\u00e4tzgen/", "tokens": ["Ein", "ar\u00b7tig", "kam\u00b7mer", "k\u00e4tz\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "ADJD", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Dar\u00fcber mu\u00df ich mich bem\u00fchn/", "tokens": ["Da\u00b7r\u00fc\u00b7ber", "mu\u00df", "ich", "mich", "be\u00b7m\u00fchn", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VMFIN", "PPER", "PRF", "VVINF", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und sie auf meinen schauplatz ziehn.", "tokens": ["Und", "sie", "auf", "mei\u00b7nen", "schau\u00b7platz", "ziehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "2. Das m\u00e4dgen mu\u00df in allen", "tokens": ["Das", "m\u00e4d\u00b7gen", "mu\u00df", "in", "al\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "VVINF", "VMFIN", "APPR", "PIAT"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Den leuthen wohlgefallen/", "tokens": ["Den", "leu\u00b7then", "wohl\u00b7ge\u00b7fal\u00b7len", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und hat auch nicht ein eintzig glied/", "tokens": ["Und", "hat", "auch", "nicht", "ein", "eint\u00b7zig", "glied", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "PTKNEG", "ART", "ADJD", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Da\u00df nicht der sch\u00f6nheit \u00e4hnlich sieht.", "tokens": ["Da\u00df", "nicht", "der", "sch\u00f6n\u00b7heit", "\u00e4hn\u00b7lich", "sieht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PTKNEG", "ART", "NN", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "3. Die haare stehn ihr nette/", "tokens": ["Die", "haa\u00b7re", "stehn", "ihr", "net\u00b7te", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "VVFIN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Gleich wie mein stroh im bette/", "tokens": ["Gleich", "wie", "mein", "stroh", "im", "bet\u00b7te", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "PPOSAT", "ADJD", "APPRART", "VVFIN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und sind so naturell und krau\u00df/", "tokens": ["Und", "sind", "so", "na\u00b7tu\u00b7rell", "und", "krau\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "ADJD", "KON", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wie einer krancken wasser-mau\u00df.", "tokens": ["Wie", "ei\u00b7ner", "kran\u00b7cken", "was\u00b7ser\u00b7mau\u00df", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "4. Sie stutzet mit dem zopffe", "tokens": ["Sie", "stut\u00b7zet", "mit", "dem", "zopf\u00b7fe"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Auf ihrem kleinen kopffe:", "tokens": ["Auf", "ih\u00b7rem", "klei\u00b7nen", "kopf\u00b7fe", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Du lieber kopff/ bist du nicht rund/", "tokens": ["Du", "lie\u00b7ber", "kopff", "/", "bist", "du", "nicht", "rund", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "NE", "$(", "VAFIN", "PPER", "PTKNEG", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wie meiner grossemutter hund.", "tokens": ["Wie", "mei\u00b7ner", "gros\u00b7se\u00b7mut\u00b7ter", "hund", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "5. Die auserlesne stirne", "tokens": ["Die", "au\u00b7ser\u00b7les\u00b7ne", "stir\u00b7ne"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Sieht fast wie eine birne/", "tokens": ["Sieht", "fast", "wie", "ei\u00b7ne", "bir\u00b7ne", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "KOKOM", "ART", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Die draussen auf den miste liegt/", "tokens": ["Die", "draus\u00b7sen", "auf", "den", "mis\u00b7te", "liegt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "ART", "ADJA", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und hier und da ein fleckgen kriegt.", "tokens": ["Und", "hier", "und", "da", "ein", "fleck\u00b7gen", "kriegt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "KON", "ADV", "ART", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "6. Die sch\u00f6nen ohres-l\u00f6cher", "tokens": ["Die", "sch\u00f6\u00b7nen", "oh\u00b7res\u00b7l\u00f6\u00b7cher"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Die sind/ wie zwey gem\u00e4cher/", "tokens": ["Die", "sind", "/", "wie", "zwey", "ge\u00b7m\u00e4\u00b7cher", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "$(", "KOKOM", "CARD", "ADJA", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Da fl\u00f6h und l\u00e4use bleiben stehn/", "tokens": ["Da", "fl\u00f6h", "und", "l\u00e4u\u00b7se", "blei\u00b7ben", "stehn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "KON", "NN", "VVINF", "VVINF", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wann sie aufs h\u00e4u\u00dfgen wollen gehn.", "tokens": ["Wann", "sie", "aufs", "h\u00e4u\u00df\u00b7gen", "wol\u00b7len", "gehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "APPRART", "ADJA", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "7. ", "tokens": [], "token_info": [], "pos": []}, "line.2": {"text": "Als wie die k\u00e4se-n\u00e4ppgen/", "tokens": ["Als", "wie", "die", "k\u00e4\u00b7se\u00b7n\u00e4pp\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOKOM", "ART", "ADJA", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Die sind voll ru\u00df bi\u00df oben an/", "tokens": ["Die", "sind", "voll", "ru\u00df", "bi\u00df", "o\u00b7ben", "an", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADJD", "NN", "APPR", "ADV", "PTKVZ", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Da\u00df man sie bald wegschauffeln kan.", "tokens": ["Da\u00df", "man", "sie", "bald", "weg\u00b7schauf\u00b7feln", "kan", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPER", "ADV", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "8. Die augen macht sie helle", "tokens": ["Die", "au\u00b7gen", "macht", "sie", "hel\u00b7le"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADJA"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Wie eine pferde-schelle", "tokens": ["Wie", "ei\u00b7ne", "pfer\u00b7de\u00b7schel\u00b7le"], "token_info": ["word", "word", "word"], "pos": ["PWAV", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Wann sie ein blickgen scharff-verliebt/", "tokens": ["Wann", "sie", "ein", "blick\u00b7gen", "scha\u00b7rff\u00b7ver\u00b7liebt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "ADJA", "VVFIN", "$("], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.4": {"text": "Als eine todte ratte giebt.", "tokens": ["Als", "ei\u00b7ne", "tod\u00b7te", "rat\u00b7te", "giebt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "9. Die nase steckt im quarge/", "tokens": ["Die", "na\u00b7se", "steckt", "im", "quar\u00b7ge", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPRART", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Gleich wie in einem sarge/", "tokens": ["Gleich", "wie", "in", "ei\u00b7nem", "sar\u00b7ge", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Sonst ist das leder zart und keusch/", "tokens": ["Sonst", "ist", "das", "le\u00b7der", "zart", "und", "keusch", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "ADJA", "ADJD", "KON", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wie angebrantes sch\u00f6psen-fleisch.", "tokens": ["Wie", "an\u00b7ge\u00b7bran\u00b7tes", "sch\u00f6p\u00b7sen\u00b7fleisch", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PWAV", "ADJA", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "10. ", "tokens": [], "token_info": [], "pos": []}, "line.2": {"text": "Gleich wie der hund/ im borne/", "tokens": ["Gleich", "wie", "der", "hund", "/", "im", "bor\u00b7ne", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "ART", "NN", "$(", "APPRART", "ADJA", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und wie ein bauer in der stadt/", "tokens": ["Und", "wie", "ein", "bau\u00b7er", "in", "der", "stadt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ART", "NN", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wann er ein eisen funden hat.", "tokens": ["Wann", "er", "ein", "ei\u00b7sen", "fun\u00b7den", "hat", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "ADJA", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "11. Die wohlgestalten backen/", "tokens": ["Die", "wohl\u00b7ge\u00b7stal\u00b7ten", "ba\u00b7cken", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Wie auch der sch\u00f6ne nacken/", "tokens": ["Wie", "auch", "der", "sch\u00f6\u00b7ne", "na\u00b7cken", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Die sind/ wo ichs vergleichen mag/", "tokens": ["Die", "sind", "/", "wo", "ichs", "ver\u00b7glei\u00b7chen", "mag", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "$(", "PWAV", "PIS", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mie eines m\u00fcllers kohlen-sack.", "tokens": ["Mie", "ei\u00b7nes", "m\u00fcl\u00b7lers", "koh\u00b7len\u00b7sack", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "12. In ihrem zarten kinne", "tokens": ["In", "ih\u00b7rem", "zar\u00b7ten", "kin\u00b7ne"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Hat neulich eine spinne/", "tokens": ["Hat", "neu\u00b7lich", "ei\u00b7ne", "spin\u00b7ne", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "VVFIN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Vier wochen lang ein nest gebaut/", "tokens": ["Vier", "wo\u00b7chen", "lang", "ein", "nest", "ge\u00b7baut", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "ADJD", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und gleichwohl hat ihr nicht gegraut.", "tokens": ["Und", "gleich\u00b7wohl", "hat", "ihr", "nicht", "ge\u00b7graut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "PPER", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "13. Die grossen leder-flaschen", "tokens": ["Die", "gros\u00b7sen", "le\u00b7der\u00b7fla\u00b7schen"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Sind wie die bettel-taschen/", "tokens": ["Sind", "wie", "die", "bet\u00b7tel\u00b7ta\u00b7schen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "KOKOM", "ART", "ADJA", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und hencken albern vor sich weg", "tokens": ["Und", "hen\u00b7cken", "al\u00b7bern", "vor", "sich", "weg"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADJD", "APPR", "PRF", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Als ein gebeitzter kirschner-fleck.", "tokens": ["Als", "ein", "ge\u00b7beitz\u00b7ter", "kir\u00b7schner\u00b7fleck", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "14. Die wohl geschickten h\u00e4nde", "tokens": ["Die", "wohl", "ge\u00b7schick\u00b7ten", "h\u00e4n\u00b7de"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADV", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Sind weich/ wie alte w\u00e4nde/", "tokens": ["Sind", "weich", "/", "wie", "al\u00b7te", "w\u00e4n\u00b7de", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "$(", "KOKOM", "ADJA", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Die finger sind so zart und frisch", "tokens": ["Die", "fin\u00b7ger", "sind", "so", "zart", "und", "frisch"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "VAFIN", "ADV", "ADJD", "KON", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wie ein verdorbner flederwisch.", "tokens": ["Wie", "ein", "ver\u00b7dorb\u00b7ner", "fle\u00b7der\u00b7wisch", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "15. Die armen sind wie priegel/", "tokens": ["Die", "ar\u00b7men", "sind", "wie", "prie\u00b7gel", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VAFIN", "KOKOM", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Und wie die h\u00f6llen-riegel/", "tokens": ["Und", "wie", "die", "h\u00f6l\u00b7len\u00b7rie\u00b7gel", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ART", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Die gucken zu den ermeln raus/", "tokens": ["Die", "gu\u00b7cken", "zu", "den", "er\u00b7meln", "raus", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "VVFIN", "PTKVZ", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und sehn wie eine blut-wurst aus.", "tokens": ["Und", "sehn", "wie", "ei\u00b7ne", "blut\u00b7wurst", "aus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVINF", "KOKOM", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "16. Mehr hab ich nicht gesehen/", "tokens": ["Mehr", "hab", "ich", "nicht", "ge\u00b7se\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PTKNEG", "VVPP", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Es soll auch nicht geschehen/", "tokens": ["Es", "soll", "auch", "nicht", "ge\u00b7sche\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "PTKNEG", "VVPP", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Dann wo sie sich nackt sehen l\u00e4st/", "tokens": ["Dann", "wo", "sie", "sich", "nackt", "se\u00b7hen", "l\u00e4st", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PWAV", "PPER", "PRF", "ADJD", "VVINF", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So sterb ich warlich an der pest.", "tokens": ["So", "sterb", "ich", "war\u00b7lich", "an", "der", "pest", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.17": {"line.1": {"text": "17. Drum wil ich nur beschliessen/", "tokens": ["Drum", "wil", "ich", "nur", "be\u00b7schlies\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VMFIN", "PPER", "ADV", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Weil ich nicht mehr kan wissen/", "tokens": ["Weil", "ich", "nicht", "mehr", "kan", "wis\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "ADV", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Doch dieses sey zu guter letzt", "tokens": ["Doch", "die\u00b7ses", "sey", "zu", "gu\u00b7ter", "letzt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PDS", "VAFIN", "APPR", "ADJA", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Jhr als ein wunsch hinzu gesetzt.", "tokens": ["Ihr", "als", "ein", "wunsch", "hin\u00b7zu", "ge\u00b7setzt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "KOUS", "ART", "ADJD", "PTKVZ", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.18": {"line.1": {"text": "18. Bestecket sie mit raute/", "tokens": ["Be\u00b7ste\u00b7cket", "sie", "mit", "rau\u00b7te", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "VVFIN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Spickt sie mit sauer kraute/", "tokens": ["Spickt", "sie", "mit", "sau\u00b7er", "krau\u00b7te", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ADJA", "NN", "$("], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.3": {"text": "Und schicket sie mit haut und haar", "tokens": ["Und", "schi\u00b7cket", "sie", "mit", "haut", "und", "haar"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "APPR", "ADJD", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Dem hencker zu dem neuen-jahr.", "tokens": ["Dem", "hen\u00b7cker", "zu", "dem", "neu\u00b7en\u00b7jahr", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}