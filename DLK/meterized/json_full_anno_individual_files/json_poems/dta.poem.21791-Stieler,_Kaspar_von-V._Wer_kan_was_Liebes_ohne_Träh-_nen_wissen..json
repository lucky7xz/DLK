{"dta.poem.21791": {"metadata": {"author": {"name": "Stieler, Kaspar von", "birth": "N.A.", "death": "N.A."}, "title": "V.  \n  Wer kan was Liebes ohne Tr\u00e4h-  \n nen wissen.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1660", "urn": "urn:nbn:de:kobv:b4-20586-2", "language": ["de:0.99"], "booktitle": "Filidor der Dorfferer [i. e. Stieler, Kaspar von]: Die Geharnschte Venus. Hamburg, 1660."}, "poem": {"stanza.1": {"line.1": {"text": "Charille wird mir abgerissen/", "tokens": ["Cha\u00b7ril\u00b7le", "wird", "mir", "ab\u00b7ge\u00b7ris\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PPER", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "und du verbeutst/ ich solte nicht", "tokens": ["und", "du", "ver\u00b7beutst", "/", "ich", "sol\u00b7te", "nicht"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "$(", "PPER", "VMFIN", "PTKNEG"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "mit Tr\u00e4hnen waschen mein Gesicht.", "tokens": ["mit", "Tr\u00e4h\u00b7nen", "wa\u00b7schen", "mein", "Ge\u00b7sicht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "ach! solt\u2019 ich sie mit Freuden missen/", "tokens": ["ach", "!", "solt'", "ich", "sie", "mit", "Freu\u00b7den", "mis\u00b7sen", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$.", "VMFIN", "PPER", "PPER", "APPR", "NN", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Filander/ die mir in Gefahr", "tokens": ["Fi\u00b7lan\u00b7der", "/", "die", "mir", "in", "Ge\u00b7fahr"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NE", "$(", "PRELS", "PPER", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Trost/ Lust in allen Sorgen war.", "tokens": ["Trost", "/", "Lust", "in", "al\u00b7len", "Sor\u00b7gen", "war", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "NN", "APPR", "PIAT", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Kein gr\u00f6sser Kreuz ist auff der Erden/", "tokens": ["Kein", "gr\u00f6s\u00b7ser", "Kreuz", "ist", "auff", "der", "Er\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "VAFIN", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "als wenn sich Lieb\u2019 und Liebe trennt", "tokens": ["als", "wenn", "sich", "Lieb'", "und", "Lie\u00b7be", "trennt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOKOM", "KOUS", "PRF", "NN", "KON", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "wenn/ die in Gegen-g\u00fcnsten brennt", "tokens": ["wenn", "/", "die", "in", "Ge\u00b7gen\u00b7g\u00fcns\u00b7ten", "brennt"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "$(", "ART", "APPR", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "vom Liebstem mu\u00df geschieden werden.", "tokens": ["vom", "Liebs\u00b7tem", "mu\u00df", "ge\u00b7schie\u00b7den", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VMFIN", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Ich glaube nicht/ da\u00df eine Pein", "tokens": ["Ich", "glau\u00b7be", "nicht", "/", "da\u00df", "ei\u00b7ne", "Pein"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PTKNEG", "$(", "KOUS", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "mit dieser kan zugleichen sein.", "tokens": ["mit", "die\u00b7ser", "kan", "zu\u00b7glei\u00b7chen", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDS", "VMFIN", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Sie liegt in eines fremden Armen/", "tokens": ["Sie", "liegt", "in", "ei\u00b7nes", "frem\u00b7den", "Ar\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "ein T\u00f6lpel feuchtet ihren Mund/", "tokens": ["ein", "T\u00f6l\u00b7pel", "feuch\u00b7tet", "ih\u00b7ren", "Mund", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sie seuffzet nach mir iede Stund\u2019", "tokens": ["Sie", "seuff\u00b7zet", "nach", "mir", "ie\u00b7de", "Stund'"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "PPER", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "und fleht mich an um mein Erbarmen.", "tokens": ["und", "fleht", "mich", "an", "um", "mein", "Er\u00b7bar\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "APPR", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Der Eltern Geiz und Sauer-Zahn", "tokens": ["Der", "El\u00b7tern", "Geiz", "und", "Sau\u00b7e\u00b7rZahn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "macht/ da\u00df ich sie nicht retten kan.", "tokens": ["macht", "/", "da\u00df", "ich", "sie", "nicht", "ret\u00b7ten", "kan", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$(", "KOUS", "PPER", "PPER", "PTKNEG", "VVINF", "VMFIN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.4": {"line.1": {"text": "Jezt wird sie zu der Eh gezwungen/", "tokens": ["Jezt", "wird", "sie", "zu", "der", "Eh", "ge\u00b7zwun\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "APPR", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "iezt mu\u00df sie schlagen Hand in Hand/", "tokens": ["iezt", "mu\u00df", "sie", "schla\u00b7gen", "Hand", "in", "Hand", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADJA", "NN", "APPR", "NN", "$("], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.3": {"text": "ich werd\u2019 erf\u00fcllt mit Spott und Schand\u2019", "tokens": ["ich", "werd'", "er\u00b7f\u00fcllt", "mit", "Spott", "und", "Schand'"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "VVPP", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "und ab von ihrer Gunst verdrungen.", "tokens": ["und", "ab", "von", "ih\u00b7rer", "Gunst", "ver\u00b7drun\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKVZ", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Sie weint und klagt/ und ich soll sie", "tokens": ["Sie", "weint", "und", "klagt", "/", "und", "ich", "soll", "sie"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "$(", "KON", "PPER", "VMFIN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "verlassen sonder Leid und M\u00fch.", "tokens": ["ver\u00b7las\u00b7sen", "son\u00b7der", "Leid", "und", "M\u00fch", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "KON", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Filander/ ich wil Sie beweinen/", "tokens": ["Fi\u00b7lan\u00b7der", "/", "ich", "wil", "Sie", "be\u00b7wei\u00b7nen", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$(", "PPER", "VMFIN", "PPER", "VVINF", "$("], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "ich werd ein neuer Flu\u00df f\u00fcr ihr", "tokens": ["ich", "werd", "ein", "neu\u00b7er", "Flu\u00df", "f\u00fcr", "ihr"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "APPR", "PPOSAT"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "ich werd\u2019 als Niobe zu Steinen/", "tokens": ["ich", "werd'", "als", "Ni\u00b7o\u00b7be", "zu", "Stei\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "KOKOM", "NE", "APPR", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "ein Baum/ ein Schall/ ich werde nichts", "tokens": ["ein", "Baum", "/", "ein", "Schall", "/", "ich", "wer\u00b7de", "nichts"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "$(", "ART", "NN", "$(", "PPER", "VAFIN", "PIS"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "um ihrentwegen angesichts.", "tokens": ["um", "ih\u00b7rent\u00b7we\u00b7gen", "an\u00b7ge\u00b7sichts", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KOUI", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}