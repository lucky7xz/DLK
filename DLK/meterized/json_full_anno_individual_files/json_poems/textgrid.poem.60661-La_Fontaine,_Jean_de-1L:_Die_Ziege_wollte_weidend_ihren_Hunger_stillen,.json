{"textgrid.poem.60661": {"metadata": {"author": {"name": "La Fontaine, Jean de", "birth": "N.A.", "death": "N.A."}, "title": "1L: Die Ziege wollte weidend ihren Hunger stillen,", "genre": "verse", "period": "N.A.", "pub_year": 1658, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Die Ziege wollte weidend ihren Hunger stillen,", "tokens": ["Die", "Zie\u00b7ge", "woll\u00b7te", "wei\u00b7dend", "ih\u00b7ren", "Hun\u00b7ger", "stil\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "ADJD", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Um sich die leeren Euter wieder anzuf\u00fcllen.", "tokens": ["Um", "sich", "die", "lee\u00b7ren", "Eu\u00b7ter", "wie\u00b7der", "an\u00b7zu\u00b7f\u00fcl\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PRF", "ART", "ADJA", "NN", "ADV", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Als sie beim Fortgehn fest die T\u00fcr verschlo\u00df,", "tokens": ["Als", "sie", "beim", "Fort\u00b7gehn", "fest", "die", "T\u00fcr", "ver\u00b7schlo\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPRART", "NN", "VVFIN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Verwarnte sie das Zicklein, ihren Spro\u00df:", "tokens": ["Ver\u00b7warn\u00b7te", "sie", "das", "Zic\u00b7klein", ",", "ih\u00b7ren", "Spro\u00df", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "$,", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "\u00bbum deines Lebens willen h\u00fcte dich", "tokens": ["\u00bb", "um", "dei\u00b7nes", "Le\u00b7bens", "wil\u00b7len", "h\u00fc\u00b7te", "dich"], "token_info": ["punct", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "APPR", "PPOSAT", "NN", "NN", "VVFIN", "PPER"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Und \u00f6ffne nicht, es sei, du h\u00f6rtest mich.", "tokens": ["Und", "\u00f6ff\u00b7ne", "nicht", ",", "es", "sei", ",", "du", "h\u00f6r\u00b7test", "mich", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKNEG", "$,", "PPER", "VAFIN", "$,", "PPER", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Mein Losungswort ist \u2013 merk dir's recht \u2013:", "tokens": ["Mein", "Lo\u00b7sungs\u00b7wort", "ist", "\u2013", "merk", "dir's", "recht", "\u2013", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "$(", "VVFIN", "PIS", "ADJD", "$(", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Zum Henker mit dem Wolfsgeschlecht!\u00ab", "tokens": ["Zum", "Hen\u00b7ker", "mit", "dem", "Wolfs\u00b7ge\u00b7schlecht", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPRART", "NN", "APPR", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Als sie so sprach zu ihrem kleinen Jungen,", "tokens": ["Als", "sie", "so", "sprach", "zu", "ih\u00b7rem", "klei\u00b7nen", "Jun\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VVFIN", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Kam zuf\u00e4llig der Wolf vorbeigesprungen;", "tokens": ["Kam", "zu\u00b7f\u00e4l\u00b7lig", "der", "Wolf", "vor\u00b7bei\u00b7ge\u00b7sprun\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADJD", "ART", "NE", "VVPP", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.11": {"text": "Sie sah ihn nicht, er aber h\u00f6rte fein", "tokens": ["Sie", "sah", "ihn", "nicht", ",", "er", "a\u00b7ber", "h\u00f6r\u00b7te", "fein"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "PTKNEG", "$,", "PPER", "ADV", "VVFIN", "ADJD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "Und pr\u00e4gte gut das Losungswort sich ein,", "tokens": ["Und", "pr\u00e4g\u00b7te", "gut", "das", "Lo\u00b7sungs\u00b7wort", "sich", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "ART", "NN", "PRF", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "Versteckte sich, und als die Alte fort,", "tokens": ["Ver\u00b7steck\u00b7te", "sich", ",", "und", "als", "die", "Al\u00b7te", "fort", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "$,", "KON", "KOUS", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "Lief er zur T\u00fcre hin, verstellte dort", "tokens": ["Lief", "er", "zur", "T\u00fc\u00b7re", "hin", ",", "ver\u00b7stell\u00b7te", "dort"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["VVFIN", "PPER", "APPRART", "NN", "PTKVZ", "$,", "VVFIN", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.15": {"text": "Der Stimme Klang und sprach das Losungswort:", "tokens": ["Der", "Stim\u00b7me", "Klang", "und", "sprach", "das", "Lo\u00b7sungs\u00b7wort", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "KON", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.16": {"text": "\u00bbzum Henker mit dem Wolfsgeschlecht\u00ab \u2013", "tokens": ["\u00bb", "zum", "Hen\u00b7ker", "mit", "dem", "Wolfs\u00b7ge\u00b7schlecht", "\u00ab", "\u2013"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "APPRART", "NN", "APPR", "ART", "NN", "$(", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "Erwartend, da\u00df darauf die T\u00fcr sich \u00f6ffnen m\u00f6cht.", "tokens": ["Er\u00b7war\u00b7tend", ",", "da\u00df", "da\u00b7rauf", "die", "T\u00fcr", "sich", "\u00f6ff\u00b7nen", "m\u00f6cht", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "KOUS", "PAV", "ART", "NN", "PRF", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Argw\u00f6hnisch aber rief das Gei\u00dfenkind", "tokens": ["Arg\u00b7w\u00f6h\u00b7nisch", "a\u00b7ber", "rief", "das", "Gei\u00b7\u00df\u00b7en\u00b7kind"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "ADV", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.19": {"text": "Heraus durch eine Spalte: \u00bbZeige mir", "tokens": ["He\u00b7raus", "durch", "ei\u00b7ne", "Spal\u00b7te", ":", "\u00bb", "Zei\u00b7ge", "mir"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word"], "pos": ["ADV", "APPR", "ART", "NN", "$.", "$(", "VVIMP", "PPER"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.20": {"text": "Die wei\u00dfe Pfote, und ich \u00f6ffne dir.\u00ab", "tokens": ["Die", "wei\u00b7\u00dfe", "Pfo\u00b7te", ",", "und", "ich", "\u00f6ff\u00b7ne", "dir", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "KON", "PPER", "VVFIN", "PPER", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.21": {"text": "Da wei\u00dfe Pfoten bei den W\u00f6lfen nun", "tokens": ["Da", "wei\u00b7\u00dfe", "Pfo\u00b7ten", "bei", "den", "W\u00f6l\u00b7fen", "nun"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJA", "NN", "APPR", "ART", "NN", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.22": {"text": "Bekanntlich Seltenheiten sind,", "tokens": ["Be\u00b7kannt\u00b7lich", "Sel\u00b7ten\u00b7hei\u00b7ten", "sind", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.23": {"text": "So wu\u00dfte unser R\u00e4uber nichts zu tun;", "tokens": ["So", "wu\u00df\u00b7te", "un\u00b7ser", "R\u00e4u\u00b7ber", "nichts", "zu", "tun", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "PIS", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.24": {"text": "Er sah um seine Hoffnung sich betrogen", "tokens": ["Er", "sah", "um", "sei\u00b7ne", "Hoff\u00b7nung", "sich", "be\u00b7tro\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN", "PRF", "VVPP"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.25": {"text": "Und ist ganz sachte wieder heimgezogen.", "tokens": ["Und", "ist", "ganz", "sach\u00b7te", "wie\u00b7der", "heim\u00b7ge\u00b7zo\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "VVFIN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.26": {"text": "Was h\u00e4tte mit dem Zicklein sich begeben,", "tokens": ["Was", "h\u00e4t\u00b7te", "mit", "dem", "Zic\u00b7klein", "sich", "be\u00b7ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "APPR", "ART", "NN", "PRF", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.27": {"text": "Wenn es allein dem Losungswort vertraut?", "tokens": ["Wenn", "es", "al\u00b7lein", "dem", "Lo\u00b7sungs\u00b7wort", "ver\u00b7traut", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Besser auf mehr denn eine Sicherheit gebaut!", "tokens": ["Bes\u00b7ser", "auf", "mehr", "denn", "ei\u00b7ne", "Si\u00b7cher\u00b7heit", "ge\u00b7baut", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "ADV", "ADV", "ART", "NN", "VVPP", "$."], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.2": {"text": "In manchen F\u00e4llen kann es ein Zuviel nicht geben.", "tokens": ["In", "man\u00b7chen", "F\u00e4l\u00b7len", "kann", "es", "ein", "Zu\u00b7viel", "nicht", "ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VMFIN", "PPER", "ART", "NN", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Die Ziege wollte weidend ihren Hunger stillen,", "tokens": ["Die", "Zie\u00b7ge", "woll\u00b7te", "wei\u00b7dend", "ih\u00b7ren", "Hun\u00b7ger", "stil\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "ADJD", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Um sich die leeren Euter wieder anzuf\u00fcllen.", "tokens": ["Um", "sich", "die", "lee\u00b7ren", "Eu\u00b7ter", "wie\u00b7der", "an\u00b7zu\u00b7f\u00fcl\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PRF", "ART", "ADJA", "NN", "ADV", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Als sie beim Fortgehn fest die T\u00fcr verschlo\u00df,", "tokens": ["Als", "sie", "beim", "Fort\u00b7gehn", "fest", "die", "T\u00fcr", "ver\u00b7schlo\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPRART", "NN", "VVFIN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Verwarnte sie das Zicklein, ihren Spro\u00df:", "tokens": ["Ver\u00b7warn\u00b7te", "sie", "das", "Zic\u00b7klein", ",", "ih\u00b7ren", "Spro\u00df", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "$,", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "\u00bbum deines Lebens willen h\u00fcte dich", "tokens": ["\u00bb", "um", "dei\u00b7nes", "Le\u00b7bens", "wil\u00b7len", "h\u00fc\u00b7te", "dich"], "token_info": ["punct", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "APPR", "PPOSAT", "NN", "NN", "VVFIN", "PPER"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Und \u00f6ffne nicht, es sei, du h\u00f6rtest mich.", "tokens": ["Und", "\u00f6ff\u00b7ne", "nicht", ",", "es", "sei", ",", "du", "h\u00f6r\u00b7test", "mich", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKNEG", "$,", "PPER", "VAFIN", "$,", "PPER", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Mein Losungswort ist \u2013 merk dir's recht \u2013:", "tokens": ["Mein", "Lo\u00b7sungs\u00b7wort", "ist", "\u2013", "merk", "dir's", "recht", "\u2013", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "$(", "VVFIN", "PIS", "ADJD", "$(", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Zum Henker mit dem Wolfsgeschlecht!\u00ab", "tokens": ["Zum", "Hen\u00b7ker", "mit", "dem", "Wolfs\u00b7ge\u00b7schlecht", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPRART", "NN", "APPR", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Als sie so sprach zu ihrem kleinen Jungen,", "tokens": ["Als", "sie", "so", "sprach", "zu", "ih\u00b7rem", "klei\u00b7nen", "Jun\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VVFIN", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Kam zuf\u00e4llig der Wolf vorbeigesprungen;", "tokens": ["Kam", "zu\u00b7f\u00e4l\u00b7lig", "der", "Wolf", "vor\u00b7bei\u00b7ge\u00b7sprun\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADJD", "ART", "NE", "VVPP", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.11": {"text": "Sie sah ihn nicht, er aber h\u00f6rte fein", "tokens": ["Sie", "sah", "ihn", "nicht", ",", "er", "a\u00b7ber", "h\u00f6r\u00b7te", "fein"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "PTKNEG", "$,", "PPER", "ADV", "VVFIN", "ADJD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "Und pr\u00e4gte gut das Losungswort sich ein,", "tokens": ["Und", "pr\u00e4g\u00b7te", "gut", "das", "Lo\u00b7sungs\u00b7wort", "sich", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "ART", "NN", "PRF", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "Versteckte sich, und als die Alte fort,", "tokens": ["Ver\u00b7steck\u00b7te", "sich", ",", "und", "als", "die", "Al\u00b7te", "fort", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "$,", "KON", "KOUS", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "Lief er zur T\u00fcre hin, verstellte dort", "tokens": ["Lief", "er", "zur", "T\u00fc\u00b7re", "hin", ",", "ver\u00b7stell\u00b7te", "dort"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["VVFIN", "PPER", "APPRART", "NN", "PTKVZ", "$,", "VVFIN", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.15": {"text": "Der Stimme Klang und sprach das Losungswort:", "tokens": ["Der", "Stim\u00b7me", "Klang", "und", "sprach", "das", "Lo\u00b7sungs\u00b7wort", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "KON", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.16": {"text": "\u00bbzum Henker mit dem Wolfsgeschlecht\u00ab \u2013", "tokens": ["\u00bb", "zum", "Hen\u00b7ker", "mit", "dem", "Wolfs\u00b7ge\u00b7schlecht", "\u00ab", "\u2013"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "APPRART", "NN", "APPR", "ART", "NN", "$(", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "Erwartend, da\u00df darauf die T\u00fcr sich \u00f6ffnen m\u00f6cht.", "tokens": ["Er\u00b7war\u00b7tend", ",", "da\u00df", "da\u00b7rauf", "die", "T\u00fcr", "sich", "\u00f6ff\u00b7nen", "m\u00f6cht", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "KOUS", "PAV", "ART", "NN", "PRF", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Argw\u00f6hnisch aber rief das Gei\u00dfenkind", "tokens": ["Arg\u00b7w\u00f6h\u00b7nisch", "a\u00b7ber", "rief", "das", "Gei\u00b7\u00df\u00b7en\u00b7kind"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "ADV", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.19": {"text": "Heraus durch eine Spalte: \u00bbZeige mir", "tokens": ["He\u00b7raus", "durch", "ei\u00b7ne", "Spal\u00b7te", ":", "\u00bb", "Zei\u00b7ge", "mir"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word"], "pos": ["ADV", "APPR", "ART", "NN", "$.", "$(", "VVIMP", "PPER"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.20": {"text": "Die wei\u00dfe Pfote, und ich \u00f6ffne dir.\u00ab", "tokens": ["Die", "wei\u00b7\u00dfe", "Pfo\u00b7te", ",", "und", "ich", "\u00f6ff\u00b7ne", "dir", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "KON", "PPER", "VVFIN", "PPER", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.21": {"text": "Da wei\u00dfe Pfoten bei den W\u00f6lfen nun", "tokens": ["Da", "wei\u00b7\u00dfe", "Pfo\u00b7ten", "bei", "den", "W\u00f6l\u00b7fen", "nun"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJA", "NN", "APPR", "ART", "NN", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.22": {"text": "Bekanntlich Seltenheiten sind,", "tokens": ["Be\u00b7kannt\u00b7lich", "Sel\u00b7ten\u00b7hei\u00b7ten", "sind", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.23": {"text": "So wu\u00dfte unser R\u00e4uber nichts zu tun;", "tokens": ["So", "wu\u00df\u00b7te", "un\u00b7ser", "R\u00e4u\u00b7ber", "nichts", "zu", "tun", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "PIS", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.24": {"text": "Er sah um seine Hoffnung sich betrogen", "tokens": ["Er", "sah", "um", "sei\u00b7ne", "Hoff\u00b7nung", "sich", "be\u00b7tro\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN", "PRF", "VVPP"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.25": {"text": "Und ist ganz sachte wieder heimgezogen.", "tokens": ["Und", "ist", "ganz", "sach\u00b7te", "wie\u00b7der", "heim\u00b7ge\u00b7zo\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "VVFIN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.26": {"text": "Was h\u00e4tte mit dem Zicklein sich begeben,", "tokens": ["Was", "h\u00e4t\u00b7te", "mit", "dem", "Zic\u00b7klein", "sich", "be\u00b7ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "APPR", "ART", "NN", "PRF", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.27": {"text": "Wenn es allein dem Losungswort vertraut?", "tokens": ["Wenn", "es", "al\u00b7lein", "dem", "Lo\u00b7sungs\u00b7wort", "ver\u00b7traut", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Besser auf mehr denn eine Sicherheit gebaut!", "tokens": ["Bes\u00b7ser", "auf", "mehr", "denn", "ei\u00b7ne", "Si\u00b7cher\u00b7heit", "ge\u00b7baut", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "ADV", "ADV", "ART", "NN", "VVPP", "$."], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.2": {"text": "In manchen F\u00e4llen kann es ein Zuviel nicht geben.", "tokens": ["In", "man\u00b7chen", "F\u00e4l\u00b7len", "kann", "es", "ein", "Zu\u00b7viel", "nicht", "ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VMFIN", "PPER", "ART", "NN", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}