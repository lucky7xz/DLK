{"textgrid.poem.31243": {"metadata": {"author": {"name": "Holz, Arno", "birth": "N.A.", "death": "N.A."}, "title": "1L: Dorilis r\u00e4ucht aller Orten", "genre": "verse", "period": "N.A.", "pub_year": 1896, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Dorilis r\u00e4ucht aller Orten", "tokens": ["Do\u00b7ri\u00b7lis", "r\u00e4ucht", "al\u00b7ler", "Or\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "VVFIN", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "nach Conf\u00e4kkt und Mandel-Dorten.", "tokens": ["nach", "Con\u00b7f\u00e4kkt", "und", "Man\u00b7del\u00b7Dor\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "KON", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Doch manch h\u00fcbsches Stellgen", "tokens": ["Doch", "manch", "h\u00fcb\u00b7sches", "Stell\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PIAT", "ADJA", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "hat auch Florabellgen.", "tokens": ["hat", "auch", "Flo\u00b7ra\u00b7bell\u00b7gen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.2": {"line.1": {"text": "Gantz mit Rohsen \u00fcbergossen", "tokens": ["Gantz", "mit", "Roh\u00b7sen", "\u00fc\u00b7ber\u00b7gos\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "APPR", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "glentzt auch Candie mir zum Bossen.", "tokens": ["glentzt", "auch", "Can\u00b7die", "mir", "zum", "Bos\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "NN", "PPER", "APPRART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Sylviens Ku\u00df-Korallen", "tokens": ["Syl\u00b7viens", "Ku\u00df\u00b7Ko\u00b7ral\u00b7len"], "token_info": ["word", "word"], "pos": ["NE", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "gleich-falls mir gefallen.", "tokens": ["gleich\u00b7falls", "mir", "ge\u00b7fal\u00b7len", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.3": {"line.1": {"text": "Auch Marindgen ist mein Schm\u00e4kkgen.", "tokens": ["Auch", "Ma\u00b7rind\u00b7gen", "ist", "mein", "Schm\u00e4kk\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "VAFIN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Duppel-r\u00fcndlig qwillt ihr J\u00e4kkgen.", "tokens": ["Dup\u00b7pel\u00b7r\u00fcnd\u00b7lig", "qwillt", "ihr", "J\u00e4kk\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und wa\u00df for ein Fellgen", "tokens": ["Und", "wa\u00df", "for", "ein", "Fell\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "hat erst Katrinellgen!", "tokens": ["hat", "erst", "Kat\u00b7ri\u00b7nell\u00b7gen", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.4": {"line.1": {"text": "Cleliens halb verstekkte Dinger", "tokens": ["Cle\u00b7li\u00b7ens", "halb", "vers\u00b7tekk\u00b7te", "Din\u00b7ger"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "ADJD", "ADJA", "NN"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.2": {"text": "lokken gleich-falls mir die Finger.", "tokens": ["lok\u00b7ken", "gleich\u00b7falls", "mir", "die", "Fin\u00b7ger", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PPER", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Au\u00df Rubin die Spizzen", "tokens": ["Au\u00df", "Ru\u00b7bin", "die", "Spiz\u00b7zen"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NE", "ART", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "g\u00e4ntzlig mich erhizzen!", "tokens": ["g\u00e4ntz\u00b7lig", "mich", "er\u00b7hiz\u00b7zen", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "PPER", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.5": {"line.1": {"text": "Doch ich gl\u00e4ube/ doch ich d\u00e4ncke/", "tokens": ["Doch", "ich", "gl\u00e4u\u00b7be", "/", "doch", "ich", "d\u00e4n\u00b7cke", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "$(", "KON", "PPER", "VVFIN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "wenn ich gantz mich dreyn vers\u00e4ncke/", "tokens": ["wenn", "ich", "gantz", "mich", "dreyn", "ver\u00b7s\u00e4n\u00b7cke", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PPER", "ADV", "VVFIN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "s\u00e4lbst bei Klariminden", "tokens": ["s\u00e4lbst", "bei", "Kla\u00b7ri\u00b7min\u00b7den"], "token_info": ["word", "word", "word"], "pos": ["ADV", "APPR", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "w\u00fcrde man wa\u00df finden.", "tokens": ["w\u00fcr\u00b7de", "man", "wa\u00df", "fin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "VVFIN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.6": {"line.1": {"text": "Blandula und Rosadore/", "tokens": ["Blan\u00b7du\u00b7la", "und", "Ro\u00b7sa\u00b7do\u00b7re", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "KON", "NE", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Purpuris und Zeliflore/", "tokens": ["Pur\u00b7pu\u00b7ris", "und", "Ze\u00b7lif\u00b7lo\u00b7re", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "KON", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Su\u00dfgen und Moralle/", "tokens": ["Su\u00df\u00b7gen", "und", "Mo\u00b7ral\u00b7le", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "g\u00f6lden sind sie alle!", "tokens": ["g\u00f6l\u00b7den", "sind", "sie", "al\u00b7le", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "VAFIN", "PPER", "PIS", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.7": {"line.1": {"text": "Soll ich dr\u00fcmb mich nun erh\u00e4ncken", "tokens": ["Soll", "ich", "dr\u00fcmb", "mich", "nun", "er\u00b7h\u00e4n\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "PPER", "VVFIN", "PPER", "ADV", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "und mich an den Galgen sch\u00e4ncken?", "tokens": ["und", "mich", "an", "den", "Gal\u00b7gen", "sch\u00e4n\u00b7cken", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "APPR", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Oder mich beweiben?", "tokens": ["O\u00b7der", "mich", "be\u00b7wei\u00b7ben", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Nein. Dih\u00df la\u00df ich bleiben.", "tokens": ["Nein", ".", "Dih\u00df", "la\u00df", "ich", "blei\u00b7ben", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$.", "PDS", "VVFIN", "PPER", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.8": {"line.1": {"text": "Mit so angenehmen Dirnen", "tokens": ["Mit", "so", "an\u00b7ge\u00b7neh\u00b7men", "Dir\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ADV", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "darff kein Sch\u00e4ffer sich verzwirnen.", "tokens": ["darff", "kein", "Sch\u00e4f\u00b7fer", "sich", "ver\u00b7zwir\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIAT", "NN", "PRF", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Eine nach der andern!", "tokens": ["Ei\u00b7ne", "nach", "der", "an\u00b7dern", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "ADJA", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Dafnis stammt au\u00df Flandern.", "tokens": ["Daf\u00b7nis", "stammt", "au\u00df", "Flan\u00b7dern", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPR", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.9": {"line.1": {"text": "Dorilis r\u00e4ucht aller Orten", "tokens": ["Do\u00b7ri\u00b7lis", "r\u00e4ucht", "al\u00b7ler", "Or\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "VVFIN", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "nach Conf\u00e4kkt und Mandel-Dorten.", "tokens": ["nach", "Con\u00b7f\u00e4kkt", "und", "Man\u00b7del\u00b7Dor\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "KON", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Doch manch h\u00fcbsches Stellgen", "tokens": ["Doch", "manch", "h\u00fcb\u00b7sches", "Stell\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PIAT", "ADJA", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "hat auch Florabellgen.", "tokens": ["hat", "auch", "Flo\u00b7ra\u00b7bell\u00b7gen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.10": {"line.1": {"text": "Gantz mit Rohsen \u00fcbergossen", "tokens": ["Gantz", "mit", "Roh\u00b7sen", "\u00fc\u00b7ber\u00b7gos\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "APPR", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "glentzt auch Candie mir zum Bossen.", "tokens": ["glentzt", "auch", "Can\u00b7die", "mir", "zum", "Bos\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "NN", "PPER", "APPRART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Sylviens Ku\u00df-Korallen", "tokens": ["Syl\u00b7viens", "Ku\u00df\u00b7Ko\u00b7ral\u00b7len"], "token_info": ["word", "word"], "pos": ["NE", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "gleich-falls mir gefallen.", "tokens": ["gleich\u00b7falls", "mir", "ge\u00b7fal\u00b7len", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.11": {"line.1": {"text": "Auch Marindgen ist mein Schm\u00e4kkgen.", "tokens": ["Auch", "Ma\u00b7rind\u00b7gen", "ist", "mein", "Schm\u00e4kk\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "VAFIN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Duppel-r\u00fcndlig qwillt ihr J\u00e4kkgen.", "tokens": ["Dup\u00b7pel\u00b7r\u00fcnd\u00b7lig", "qwillt", "ihr", "J\u00e4kk\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und wa\u00df for ein Fellgen", "tokens": ["Und", "wa\u00df", "for", "ein", "Fell\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "hat erst Katrinellgen!", "tokens": ["hat", "erst", "Kat\u00b7ri\u00b7nell\u00b7gen", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.12": {"line.1": {"text": "Cleliens halb verstekkte Dinger", "tokens": ["Cle\u00b7li\u00b7ens", "halb", "vers\u00b7tekk\u00b7te", "Din\u00b7ger"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "ADJD", "ADJA", "NN"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.2": {"text": "lokken gleich-falls mir die Finger.", "tokens": ["lok\u00b7ken", "gleich\u00b7falls", "mir", "die", "Fin\u00b7ger", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PPER", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Au\u00df Rubin die Spizzen", "tokens": ["Au\u00df", "Ru\u00b7bin", "die", "Spiz\u00b7zen"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NE", "ART", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "g\u00e4ntzlig mich erhizzen!", "tokens": ["g\u00e4ntz\u00b7lig", "mich", "er\u00b7hiz\u00b7zen", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "PPER", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.13": {"line.1": {"text": "Doch ich gl\u00e4ube/ doch ich d\u00e4ncke/", "tokens": ["Doch", "ich", "gl\u00e4u\u00b7be", "/", "doch", "ich", "d\u00e4n\u00b7cke", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "$(", "KON", "PPER", "VVFIN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "wenn ich gantz mich dreyn vers\u00e4ncke/", "tokens": ["wenn", "ich", "gantz", "mich", "dreyn", "ver\u00b7s\u00e4n\u00b7cke", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PPER", "ADV", "VVFIN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "s\u00e4lbst bei Klariminden", "tokens": ["s\u00e4lbst", "bei", "Kla\u00b7ri\u00b7min\u00b7den"], "token_info": ["word", "word", "word"], "pos": ["ADV", "APPR", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "w\u00fcrde man wa\u00df finden.", "tokens": ["w\u00fcr\u00b7de", "man", "wa\u00df", "fin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "VVFIN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.14": {"line.1": {"text": "Blandula und Rosadore/", "tokens": ["Blan\u00b7du\u00b7la", "und", "Ro\u00b7sa\u00b7do\u00b7re", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "KON", "NE", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Purpuris und Zeliflore/", "tokens": ["Pur\u00b7pu\u00b7ris", "und", "Ze\u00b7lif\u00b7lo\u00b7re", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "KON", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Su\u00dfgen und Moralle/", "tokens": ["Su\u00df\u00b7gen", "und", "Mo\u00b7ral\u00b7le", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "g\u00f6lden sind sie alle!", "tokens": ["g\u00f6l\u00b7den", "sind", "sie", "al\u00b7le", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "VAFIN", "PPER", "PIS", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.15": {"line.1": {"text": "Soll ich dr\u00fcmb mich nun erh\u00e4ncken", "tokens": ["Soll", "ich", "dr\u00fcmb", "mich", "nun", "er\u00b7h\u00e4n\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "PPER", "VVFIN", "PPER", "ADV", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "und mich an den Galgen sch\u00e4ncken?", "tokens": ["und", "mich", "an", "den", "Gal\u00b7gen", "sch\u00e4n\u00b7cken", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "APPR", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Oder mich beweiben?", "tokens": ["O\u00b7der", "mich", "be\u00b7wei\u00b7ben", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Nein. Dih\u00df la\u00df ich bleiben.", "tokens": ["Nein", ".", "Dih\u00df", "la\u00df", "ich", "blei\u00b7ben", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$.", "PDS", "VVFIN", "PPER", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.16": {"line.1": {"text": "Mit so angenehmen Dirnen", "tokens": ["Mit", "so", "an\u00b7ge\u00b7neh\u00b7men", "Dir\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ADV", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "darff kein Sch\u00e4ffer sich verzwirnen.", "tokens": ["darff", "kein", "Sch\u00e4f\u00b7fer", "sich", "ver\u00b7zwir\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIAT", "NN", "PRF", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Eine nach der andern!", "tokens": ["Ei\u00b7ne", "nach", "der", "an\u00b7dern", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "ADJA", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Dafnis stammt au\u00df Flandern.", "tokens": ["Daf\u00b7nis", "stammt", "au\u00df", "Flan\u00b7dern", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPR", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}}}}