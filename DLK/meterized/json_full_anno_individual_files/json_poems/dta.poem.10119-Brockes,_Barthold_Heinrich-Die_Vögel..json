{"dta.poem.10119": {"metadata": {"author": {"name": "Brockes, Barthold Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "Die V\u00f6gel.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1735", "urn": "urn:nbn:de:kobv:b4-20086-0", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Es ist in unterschiednen Thieren", "tokens": ["Es", "ist", "in", "un\u00b7ter\u00b7schied\u00b7nen", "Thie\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ein Etwas, welches fast vern\u00fcnftig scheint.", "tokens": ["Ein", "Et\u00b7was", ",", "wel\u00b7ches", "fast", "ver\u00b7n\u00fcnf\u00b7tig", "scheint", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "$,", "PRELS", "ADV", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Allein dergleichen ist fast nirgend so zu schauen,", "tokens": ["Al\u00b7lein", "derg\u00b7lei\u00b7chen", "ist", "fast", "nir\u00b7gend", "so", "zu", "schau\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "VAFIN", "ADV", "ADV", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Als in der V\u00f6gel Kunst, womit sie Rester bauen.", "tokens": ["Als", "in", "der", "V\u00f6\u00b7gel", "Kunst", ",", "wo\u00b7mit", "sie", "Res\u00b7ter", "bau\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "ART", "NN", "NN", "$,", "PWAV", "PPER", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Zum ersten: welcher Meister hat", "tokens": ["Zum", "ers\u00b7ten", ":", "wel\u00b7cher", "Meis\u00b7ter", "hat"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["APPRART", "ADJA", "$.", "PWAT", "NN", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Denselbigen gezeigt, da\u00df sie sie n\u00f6thig h\u00e4tten?", "tokens": ["Den\u00b7sel\u00b7bi\u00b7gen", "ge\u00b7zeigt", ",", "da\u00df", "sie", "sie", "n\u00f6\u00b7thig", "h\u00e4t\u00b7ten", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVPP", "$,", "KOUS", "PPER", "PPER", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wer lehrte sie, da\u00df sie, \u00fcm sich zu retten,", "tokens": ["Wer", "lehr\u00b7te", "sie", ",", "da\u00df", "sie", ",", "\u00fcm", "sich", "zu", "ret\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "$,", "KOUS", "PPER", "$,", "KOUI", "PRF", "PTKZU", "VVINF", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Dieselben nicht zu spat", "tokens": ["Die\u00b7sel\u00b7ben", "nicht", "zu", "spat"], "token_info": ["word", "word", "word", "word"], "pos": ["PDS", "PTKNEG", "PTKZU", "VVFIN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Verfertigten? und wer bracht\u2019 ihnen bey,", "tokens": ["Ver\u00b7fer\u00b7tig\u00b7ten", "?", "und", "wer", "bracht'", "ih\u00b7nen", "bey", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "KON", "PWS", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Auf welche Weis\u2019 ein Nest zu machen sey?", "tokens": ["Auf", "wel\u00b7che", "Weis'", "ein", "Nest", "zu", "ma\u00b7chen", "sey", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PWAT", "NN", "ART", "NN", "PTKZU", "VVINF", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Was f\u00fcr ein Mathematicus", "tokens": ["Was", "f\u00fcr", "ein", "Ma\u00b7the\u00b7ma\u00b7ti\u00b7cus"], "token_info": ["word", "word", "word", "word"], "pos": ["PWS", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Gab ihnen die Figur, so, wie man bauen mu\u00df?", "tokens": ["Gab", "ih\u00b7nen", "die", "Fi\u00b7gur", ",", "so", ",", "wie", "man", "bau\u00b7en", "mu\u00df", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "$,", "ADV", "$,", "PWAV", "PIS", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Welch K\u00fcnstler hat dieselbigen gelehrt,", "tokens": ["Welch", "K\u00fcnst\u00b7ler", "hat", "die\u00b7sel\u00b7bi\u00b7gen", "ge\u00b7lehrt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "PDS", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Da\u00df ein gewisser Grund zum Bau geh\u00f6rt?", "tokens": ["Da\u00df", "ein", "ge\u00b7wis\u00b7ser", "Grund", "zum", "Bau", "ge\u00b7h\u00f6rt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Da sie ja, sonder ie zu fehlen,", "tokens": ["Da", "sie", "ja", ",", "son\u00b7der", "ie", "zu", "feh\u00b7len", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "$,", "KON", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Dergleichen Oerter immer wehlen.", "tokens": ["Derg\u00b7lei\u00b7chen", "O\u00b7er\u00b7ter", "im\u00b7mer", "weh\u00b7len", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "NN", "ADV", "VVINF", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.13": {"text": "Welch eine Mutter zeigt, aus Vorsorg\u2019, ihnen,", "tokens": ["Welch", "ei\u00b7ne", "Mut\u00b7ter", "zeigt", ",", "aus", "Vor\u00b7sor\u00b7g'", ",", "ih\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["PIAT", "ART", "NN", "VVFIN", "$,", "APPR", "NN", "$,", "PPER", "$,"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.14": {"text": "Um ihr klein Nestchen weich zu machen,", "tokens": ["Um", "ihr", "klein", "Nest\u00b7chen", "weich", "zu", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PPER", "ADJD", "NN", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "Sanft, niedlich und bequem, stat andrer Sachen,", "tokens": ["Sanft", ",", "nied\u00b7lich", "und", "be\u00b7quem", ",", "stat", "an\u00b7drer", "Sa\u00b7chen", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "ADJD", "KON", "ADJD", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.16": {"text": "Sich zarter Woll\u2019 und Federn zu bedienen?", "tokens": ["Sich", "zar\u00b7ter", "Woll'", "und", "Fe\u00b7dern", "zu", "be\u00b7die\u00b7nen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADJA", "NN", "KON", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.17": {"text": "Ja, wenn dergleichen nicht zu finden seyn,", "tokens": ["Ja", ",", "wenn", "derg\u00b7lei\u00b7chen", "nicht", "zu", "fin\u00b7den", "seyn", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "KOUS", "PIS", "PTKNEG", "PTKZU", "VVINF", "VAINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.18": {"text": "Wer gab so denn denselbigen die Triebe,", "tokens": ["Wer", "gab", "so", "denn", "den\u00b7sel\u00b7bi\u00b7gen", "die", "Trie\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ADV", "ADV", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.19": {"text": "Von einer Kunst- erf\u00fcllten Liebe,", "tokens": ["Von", "ei\u00b7ner", "Kunst", "er\u00b7f\u00fcll\u00b7ten", "Lie\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "TRUNC", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.20": {"text": "Und z\u00e4rtlichen Erfindung, ein?", "tokens": ["Und", "z\u00e4rt\u00b7li\u00b7chen", "Er\u00b7fin\u00b7dung", ",", "ein", "?"], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "ADJA", "NN", "$,", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.21": {"text": "Da\u00df sie aus eigner Brust die Federchen zu nehmen,", "tokens": ["Da\u00df", "sie", "aus", "eig\u00b7ner", "Brust", "die", "Fe\u00b7der\u00b7chen", "zu", "neh\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ADJA", "NN", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Mit ihrem Schnabel sich bequemen;", "tokens": ["Mit", "ih\u00b7rem", "Schna\u00b7bel", "sich", "be\u00b7que\u00b7men", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PRF", "ADJA", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.23": {"text": "Damit die zarte Zucht in einer weichen Wiegen", "tokens": ["Da\u00b7mit", "die", "zar\u00b7te", "Zucht", "in", "ei\u00b7ner", "wei\u00b7chen", "Wie\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PAV", "ART", "ADJA", "NN", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Mag sanft, bequem und ruhig liegen?", "tokens": ["Mag", "sanft", ",", "be\u00b7quem", "und", "ru\u00b7hig", "lie\u00b7gen", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADJD", "$,", "ADJD", "KON", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Durch welche Weisheit sind die V\u00f6gel angef\u00fchrt,", "tokens": ["Durch", "wel\u00b7che", "Weis\u00b7heit", "sind", "die", "V\u00f6\u00b7gel", "an\u00b7ge\u00b7f\u00fchrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PWAT", "NN", "VAFIN", "ART", "NN", "VVPP", "$,"], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.2": {"text": "Da\u00df iede Art ihr Nest, auf eigne Art, formirt?", "tokens": ["Da\u00df", "ie\u00b7de", "Art", "ihr", "Nest", ",", "auf", "eig\u00b7ne", "Art", ",", "for\u00b7mirt", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "PIAT", "NN", "PPOSAT", "NN", "$,", "APPR", "ADJA", "NN", "$,", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Begreifft es wol ein Mensch, wie solch ein Nest", "tokens": ["Be\u00b7greifft", "es", "wol", "ein", "Mensch", ",", "wie", "solch", "ein", "Nest"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "ART", "NN", "$,", "PWAV", "PIAT", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Auf tausend Arten sich zusammen setzen l\u00e4sst?", "tokens": ["Auf", "tau\u00b7send", "Ar\u00b7ten", "sich", "zu\u00b7sam\u00b7men", "set\u00b7zen", "l\u00e4sst", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "CARD", "NN", "PRF", "ADV", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Wer fl\u00f6sset solchen Muth und solch Vertrauen", "tokens": ["Wer", "fl\u00f6s\u00b7set", "sol\u00b7chen", "Muth", "und", "solch", "Ver\u00b7trau\u00b7en"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "PIAT", "NN", "KON", "PIAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Der schnellen Schwalben ein, ihr Nest bey uns zu bauen?", "tokens": ["Der", "schnel\u00b7len", "Schwal\u00b7ben", "ein", ",", "ihr", "Nest", "bey", "uns", "zu", "bau\u00b7en", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKVZ", "$,", "PPOSAT", "NN", "APPR", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Indem sie uns ihr Werck zu weisen sich nicht schent,", "tokens": ["In\u00b7dem", "sie", "uns", "ihr", "Werck", "zu", "wei\u00b7sen", "sich", "nicht", "schent", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "PPOSAT", "NN", "PTKZU", "VVFIN", "PRF", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Uns recht zu Zeugen nimmt, sich gleichsam selbst erbeut,", "tokens": ["Uns", "recht", "zu", "Zeu\u00b7gen", "nimmt", ",", "sich", "gleich\u00b7sam", "selbst", "er\u00b7beut", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "APPR", "NN", "VVFIN", "$,", "PRF", "ADJD", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Aufrichtig alles uns zu zeigen.", "tokens": ["Auf\u00b7rich\u00b7tig", "al\u00b7les", "uns", "zu", "zei\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "PIS", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Sie bauet nicht aus Heu, auch nicht aus kleinen Zweigen,", "tokens": ["Sie", "bau\u00b7et", "nicht", "aus", "Heu", ",", "auch", "nicht", "aus", "klei\u00b7nen", "Zwei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "APPR", "NN", "$,", "ADV", "PTKNEG", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Sie bauet recht aus Kalck und Thon ihr Nest;", "tokens": ["Sie", "bau\u00b7et", "recht", "aus", "Kalck", "und", "Thon", "ihr", "Nest", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "NN", "KON", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Und zwar so starck und fest,", "tokens": ["Und", "zwar", "so", "starck", "und", "fest", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "ADJD", "KON", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "Da\u00df, braucht man sich dazu nicht Krafft und St\u00e4rcke,", "tokens": ["Da\u00df", ",", "braucht", "man", "sich", "da\u00b7zu", "nicht", "Krafft", "und", "St\u00e4r\u00b7cke", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$,", "VVFIN", "PIS", "PRF", "PAV", "PTKNEG", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Es sich nicht leicht zerst\u00f6ren l\u00e4sst.", "tokens": ["Es", "sich", "nicht", "leicht", "zer\u00b7st\u00f6\u00b7ren", "l\u00e4sst", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PRF", "PTKNEG", "ADJD", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Und doch bedient sie sich zu diesem Wercke", "tokens": ["Und", "doch", "be\u00b7dient", "sie", "sich", "zu", "die\u00b7sem", "Wer\u00b7cke"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "PPER", "PRF", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Des Schnabels blo\u00df allein.", "tokens": ["Des", "Schna\u00b7bels", "blo\u00df", "al\u00b7lein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.13": {"text": "Man mache (k\u00f6nnt\u2019 es m\u00f6glich seyn)", "tokens": ["Man", "ma\u00b7che", "(", "k\u00f6nnt'", "es", "m\u00f6g\u00b7lich", "seyn", ")"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "$(", "VMFIN", "PPER", "ADJD", "VAINF", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Den gr\u00f6sten Meister einst so klein", "tokens": ["Den", "gr\u00f6s\u00b7ten", "Meis\u00b7ter", "einst", "so", "klein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "ADV", "ADV", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Als eine Schwalb: man la\u00df ihm den Verstand,", "tokens": ["Als", "ei\u00b7ne", "Schwalb", ":", "man", "la\u00df", "ihm", "den", "Ver\u00b7stand", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "$.", "PIS", "VVIMP", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.16": {"text": "Doch, stat der Werck-Zeug, und der Hand,", "tokens": ["Doch", ",", "stat", "der", "Wer\u00b7ck\u00b7Zeug", ",", "und", "der", "Hand", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "$,", "APPR", "ART", "NN", "$,", "KON", "ART", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.17": {"text": "Nichts als den Schnabel nur, dann schaue man,", "tokens": ["Nichts", "als", "den", "Schna\u00b7bel", "nur", ",", "dann", "schau\u00b7e", "man", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIS", "KOKOM", "ART", "NN", "ADV", "$,", "ADV", "VVFIN", "PIS", "$,"], "meter": "++-+-+-+-+", "measure": "iambic.penta.spondeus"}, "line.18": {"text": "Ob er dergleichen machen kann.", "tokens": ["Ob", "er", "derg\u00b7lei\u00b7chen", "ma\u00b7chen", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIS", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Betrachtete man doch, dem weisen GOTT zu Ehren,", "tokens": ["Be\u00b7trach\u00b7te\u00b7te", "man", "doch", ",", "dem", "wei\u00b7sen", "GoTT", "zu", "Eh\u00b7ren", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ADV", "$,", "ART", "ADJA", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die Wunder, welche man sonst leider nicht betrachtet,", "tokens": ["Die", "Wun\u00b7der", ",", "wel\u00b7che", "man", "sonst", "lei\u00b7der", "nicht", "be\u00b7trach\u00b7tet", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PIS", "ADV", "ADV", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und, durch Gewohnheit, kaum des denckens w\u00fcrdig achtet;", "tokens": ["Und", ",", "durch", "Ge\u00b7wohn\u00b7heit", ",", "kaum", "des", "den\u00b7ckens", "w\u00fcr\u00b7dig", "ach\u00b7tet", ";"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "APPR", "NN", "$,", "ADV", "ART", "ADV", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Man w\u00fcrd\u2019, o grosser GOTT! Dich weis\u2019 und gro\u00df zu", "tokens": ["Man", "w\u00fcrd'", ",", "o", "gros\u00b7ser", "GoTT", "!", "Dich", "weis'", "und", "gro\u00df", "zu"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PIS", "VAFIN", "$,", "FM", "ADJA", "NN", "$.", "PPER", "PTKVZ", "KON", "ADJD", "PTKZU"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Sich nicht ers\u00e4ttigen, sich nicht erm\u00fcden k\u00f6nnen.", "tokens": ["Sich", "nicht", "er\u00b7s\u00e4t\u00b7ti\u00b7gen", ",", "sich", "nicht", "er\u00b7m\u00fc\u00b7den", "k\u00f6n\u00b7nen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PRF", "PTKNEG", "VVINF", "$,", "PRF", "PTKNEG", "VVINF", "VMINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}