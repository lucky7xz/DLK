{"textgrid.poem.24605": {"metadata": {"author": {"name": "Hunold, Christian Friedrich", "birth": "N.A.", "death": "N.A."}, "title": "Uber die scharfsinnigen Reden in Gesellschaft", "genre": "verse", "period": "N.A.", "pub_year": 1701, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Da\u00df stets ein sch\u00f6nes Wort erfreut/", "tokens": ["Da\u00df", "stets", "ein", "sch\u00f6\u00b7nes", "Wort", "er\u00b7freut", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Er fordert viel Geschicklichkeit:", "tokens": ["Er", "for\u00b7dert", "viel", "Ge\u00b7schick\u00b7lich\u00b7keit", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und weil so wenige in dieser Kunst vollkommen/", "tokens": ["Und", "weil", "so", "we\u00b7ni\u00b7ge", "in", "die\u00b7ser", "Kunst", "voll\u00b7kom\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ADV", "PIS", "APPR", "PDAT", "NN", "ADJD", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So hat der beste stets die Mittel-Bahn genommen.", "tokens": ["So", "hat", "der", "bes\u00b7te", "stets", "die", "Mit\u00b7tel\u00b7Bahn", "ge\u00b7nom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "ADJA", "ADV", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Der sch\u00f6ne Reden streut/", "tokens": ["Der", "sch\u00f6\u00b7ne", "Re\u00b7den", "streut", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Und will dadurch die Leute lachend machen/", "tokens": ["Und", "will", "da\u00b7durch", "die", "Leu\u00b7te", "la\u00b7chend", "ma\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PAV", "ART", "NN", "ADJD", "VVINF", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Betr\u00fcget sich fast allezeit.", "tokens": ["Be\u00b7tr\u00fc\u00b7get", "sich", "fast", "al\u00b7le\u00b7zeit", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ADV", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Doch welcher nicht viel krumme Springe macht/", "tokens": ["Doch", "wel\u00b7cher", "nicht", "viel", "krum\u00b7me", "Sprin\u00b7ge", "macht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRELS", "PTKNEG", "ADV", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Und selber nicht zum ersten lacht/", "tokens": ["Und", "sel\u00b7ber", "nicht", "zum", "ers\u00b7ten", "lacht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PTKNEG", "APPRART", "ADJA", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Der kan zum letzten lachen.", "tokens": ["Der", "kan", "zum", "letz\u00b7ten", "la\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "APPRART", "ADJA", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Da\u00df stets ein sch\u00f6nes Wort erfreut/", "tokens": ["Da\u00df", "stets", "ein", "sch\u00f6\u00b7nes", "Wort", "er\u00b7freut", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Er fordert viel Geschicklichkeit:", "tokens": ["Er", "for\u00b7dert", "viel", "Ge\u00b7schick\u00b7lich\u00b7keit", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und weil so wenige in dieser Kunst vollkommen/", "tokens": ["Und", "weil", "so", "we\u00b7ni\u00b7ge", "in", "die\u00b7ser", "Kunst", "voll\u00b7kom\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ADV", "PIS", "APPR", "PDAT", "NN", "ADJD", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So hat der beste stets die Mittel-Bahn genommen.", "tokens": ["So", "hat", "der", "bes\u00b7te", "stets", "die", "Mit\u00b7tel\u00b7Bahn", "ge\u00b7nom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "ADJA", "ADV", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Der sch\u00f6ne Reden streut/", "tokens": ["Der", "sch\u00f6\u00b7ne", "Re\u00b7den", "streut", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Und will dadurch die Leute lachend machen/", "tokens": ["Und", "will", "da\u00b7durch", "die", "Leu\u00b7te", "la\u00b7chend", "ma\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PAV", "ART", "NN", "ADJD", "VVINF", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Betr\u00fcget sich fast allezeit.", "tokens": ["Be\u00b7tr\u00fc\u00b7get", "sich", "fast", "al\u00b7le\u00b7zeit", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ADV", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Doch welcher nicht viel krumme Springe macht/", "tokens": ["Doch", "wel\u00b7cher", "nicht", "viel", "krum\u00b7me", "Sprin\u00b7ge", "macht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRELS", "PTKNEG", "ADV", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Und selber nicht zum ersten lacht/", "tokens": ["Und", "sel\u00b7ber", "nicht", "zum", "ers\u00b7ten", "lacht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PTKNEG", "APPRART", "ADJA", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Der kan zum letzten lachen.", "tokens": ["Der", "kan", "zum", "letz\u00b7ten", "la\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "APPRART", "ADJA", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}}}}