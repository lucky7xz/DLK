{"textgrid.poem.65134": {"metadata": {"author": {"name": "Paoli, Betty", "birth": "N.A.", "death": "N.A."}, "title": "1L: Kein M\u00e4hrlein blo\u00df, kein m\u00fc\u00dfiges Erfinden,", "genre": "verse", "period": "N.A.", "pub_year": 1854, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Kein M\u00e4hrlein blo\u00df, kein m\u00fc\u00dfiges Erfinden,", "tokens": ["Kein", "M\u00e4hr\u00b7lein", "blo\u00df", ",", "kein", "m\u00fc\u00b7\u00dfi\u00b7ges", "Er\u00b7fin\u00b7den", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "ADV", "$,", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Thatsache ist es, wie man eine nennt:", "tokens": ["Thats\u00b7a\u00b7che", "ist", "es", ",", "wie", "man", "ei\u00b7ne", "nennt", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "$,", "PWAV", "PIS", "ART", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Ein Glied, das l\u00e4ngst schon ward vom Leib getrennet,", "tokens": ["Ein", "Glied", ",", "das", "l\u00e4ngst", "schon", "ward", "vom", "Leib", "ge\u00b7tren\u00b7net", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ADV", "ADV", "VAFIN", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Noch gegenw\u00e4rtig bleibt es dem Empfinden.", "tokens": ["Noch", "ge\u00b7gen\u00b7w\u00e4r\u00b7tig", "bleibt", "es", "dem", "Emp\u00b7fin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Mag es als Staub hinwirbeln in den Winden,", "tokens": ["Mag", "es", "als", "Staub", "hin\u00b7wir\u00b7beln", "in", "den", "Win\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "KOUS", "NN", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Da\u00df kein Atom das and're mehr erkennt,", "tokens": ["Da\u00df", "kein", "A\u00b7tom", "das", "an\u00b7d'\u00b7re", "mehr", "er\u00b7kennt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "NN", "ART", "PIS", "ADV", "VVFIN", "$,"], "meter": "---+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Und der nicht weichen will und nicht entschwinden. \u2013", "tokens": ["Und", "der", "nicht", "wei\u00b7chen", "will", "und", "nicht", "ent\u00b7schwin\u00b7den", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ART", "PTKNEG", "VVINF", "VMFIN", "KON", "PTKNEG", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Wirst du dies Bild dir wohl zu deuten wissen?", "tokens": ["Wirst", "du", "dies", "Bild", "dir", "wohl", "zu", "deu\u00b7ten", "wis\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PDS", "NN", "PPER", "ADV", "PTKZU", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ein Theil von meiner Seele war mein Lieben,", "tokens": ["Ein", "Theil", "von", "mei\u00b7ner", "See\u00b7le", "war", "mein", "Lie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPOSAT", "NN", "VAFIN", "PPOSAT", "ADJA", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Du hast es blutend davon losgerissen!", "tokens": ["Du", "hast", "es", "blu\u00b7tend", "da\u00b7von", "los\u00b7ge\u00b7ris\u00b7sen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADJD", "PAV", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "In alle L\u00fcfte sah ich es zerstieben!", "tokens": ["In", "al\u00b7le", "L\u00fcf\u00b7te", "sah", "ich", "es", "zer\u00b7stie\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVFIN", "PPER", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Doch w\u00e4hrend ich es selber mu\u00df vermissen,", "tokens": ["Doch", "w\u00e4h\u00b7rend", "ich", "es", "sel\u00b7ber", "mu\u00df", "ver\u00b7mis\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PPER", "ADV", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Ist mir sein ganzer, voller Schmerz geblieben!", "tokens": ["Ist", "mir", "sein", "gan\u00b7zer", ",", "vol\u00b7ler", "Schmerz", "ge\u00b7blie\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PPOSAT", "ADJA", "$,", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "Kein M\u00e4hrlein blo\u00df, kein m\u00fc\u00dfiges Erfinden,", "tokens": ["Kein", "M\u00e4hr\u00b7lein", "blo\u00df", ",", "kein", "m\u00fc\u00b7\u00dfi\u00b7ges", "Er\u00b7fin\u00b7den", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "ADV", "$,", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Thatsache ist es, wie man eine nennt:", "tokens": ["Thats\u00b7a\u00b7che", "ist", "es", ",", "wie", "man", "ei\u00b7ne", "nennt", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "$,", "PWAV", "PIS", "ART", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Ein Glied, das l\u00e4ngst schon ward vom Leib getrennet,", "tokens": ["Ein", "Glied", ",", "das", "l\u00e4ngst", "schon", "ward", "vom", "Leib", "ge\u00b7tren\u00b7net", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ADV", "ADV", "VAFIN", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Noch gegenw\u00e4rtig bleibt es dem Empfinden.", "tokens": ["Noch", "ge\u00b7gen\u00b7w\u00e4r\u00b7tig", "bleibt", "es", "dem", "Emp\u00b7fin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "Mag es als Staub hinwirbeln in den Winden,", "tokens": ["Mag", "es", "als", "Staub", "hin\u00b7wir\u00b7beln", "in", "den", "Win\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "KOUS", "NN", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Da\u00df kein Atom das and're mehr erkennt,", "tokens": ["Da\u00df", "kein", "A\u00b7tom", "das", "an\u00b7d'\u00b7re", "mehr", "er\u00b7kennt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "NN", "ART", "PIS", "ADV", "VVFIN", "$,"], "meter": "---+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Und der nicht weichen will und nicht entschwinden. \u2013", "tokens": ["Und", "der", "nicht", "wei\u00b7chen", "will", "und", "nicht", "ent\u00b7schwin\u00b7den", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ART", "PTKNEG", "VVINF", "VMFIN", "KON", "PTKNEG", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.7": {"line.1": {"text": "Wirst du dies Bild dir wohl zu deuten wissen?", "tokens": ["Wirst", "du", "dies", "Bild", "dir", "wohl", "zu", "deu\u00b7ten", "wis\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PDS", "NN", "PPER", "ADV", "PTKZU", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ein Theil von meiner Seele war mein Lieben,", "tokens": ["Ein", "Theil", "von", "mei\u00b7ner", "See\u00b7le", "war", "mein", "Lie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPOSAT", "NN", "VAFIN", "PPOSAT", "ADJA", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Du hast es blutend davon losgerissen!", "tokens": ["Du", "hast", "es", "blu\u00b7tend", "da\u00b7von", "los\u00b7ge\u00b7ris\u00b7sen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADJD", "PAV", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.8": {"line.1": {"text": "In alle L\u00fcfte sah ich es zerstieben!", "tokens": ["In", "al\u00b7le", "L\u00fcf\u00b7te", "sah", "ich", "es", "zer\u00b7stie\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVFIN", "PPER", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Doch w\u00e4hrend ich es selber mu\u00df vermissen,", "tokens": ["Doch", "w\u00e4h\u00b7rend", "ich", "es", "sel\u00b7ber", "mu\u00df", "ver\u00b7mis\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PPER", "ADV", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Ist mir sein ganzer, voller Schmerz geblieben!", "tokens": ["Ist", "mir", "sein", "gan\u00b7zer", ",", "vol\u00b7ler", "Schmerz", "ge\u00b7blie\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PPOSAT", "ADJA", "$,", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}}}}