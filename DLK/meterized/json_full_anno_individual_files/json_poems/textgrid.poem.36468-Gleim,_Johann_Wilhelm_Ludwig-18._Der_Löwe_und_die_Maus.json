{"textgrid.poem.36468": {"metadata": {"author": {"name": "Gleim, Johann Wilhelm Ludwig", "birth": "N.A.", "death": "N.A."}, "title": "18. Der L\u00f6we und die Maus", "genre": "verse", "period": "N.A.", "pub_year": 1761, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ein L\u00f6we br\u00fcllte; pl\u00f6tzlich kroch,", "tokens": ["Ein", "L\u00f6\u00b7we", "br\u00fcll\u00b7te", ";", "pl\u00f6tz\u00b7lich", "kroch", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NE", "VVFIN", "$.", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Aus seinem dunkeln Mauseloch", "tokens": ["Aus", "sei\u00b7nem", "dun\u00b7keln", "Mau\u00b7se\u00b7loch"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ein M\u00e4uschen an das Tageslicht,", "tokens": ["Ein", "M\u00e4u\u00b7schen", "an", "das", "Ta\u00b7ges\u00b7licht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und horchte; schrecklich war's zu h\u00f6ren!", "tokens": ["Und", "horch\u00b7te", ";", "schreck\u00b7lich", "wa\u00b7r's", "zu", "h\u00f6\u00b7ren", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "ADJD", "VAFIN", "PTKZU", "VVINF", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Und doch erschrak das M\u00e4uschen nicht.", "tokens": ["Und", "doch", "er\u00b7schrak", "das", "M\u00e4u\u00b7schen", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "ART", "NN", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ei, sprachs, er will uns br\u00fcllen lehren;", "tokens": ["Ei", ",", "sprachs", ",", "er", "will", "uns", "br\u00fcl\u00b7len", "leh\u00b7ren", ";"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "$,", "PPER", "VMFIN", "PPER", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Und fing zu pfeifen an,", "tokens": ["Und", "fing", "zu", "pfei\u00b7fen", "an", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKZU", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "Und stand, und \u00fcbte sich, dem L\u00f6wen nachzubr\u00fcllen.", "tokens": ["Und", "stand", ",", "und", "\u00fcb\u00b7te", "sich", ",", "dem", "L\u00f6\u00b7wen", "nach\u00b7zu\u00b7br\u00fcl\u00b7len", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "KON", "VVFIN", "PRF", "$,", "ART", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Wenn ich die That nicht loben kann,", "tokens": ["Wenn", "ich", "die", "That", "nicht", "lo\u00b7ben", "kann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "PTKNEG", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So lob ich doch den guten Willen.", "tokens": ["So", "lob", "ich", "doch", "den", "gu\u00b7ten", "Wil\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "PPER", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Ein L\u00f6we br\u00fcllte; pl\u00f6tzlich kroch,", "tokens": ["Ein", "L\u00f6\u00b7we", "br\u00fcll\u00b7te", ";", "pl\u00f6tz\u00b7lich", "kroch", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NE", "VVFIN", "$.", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Aus seinem dunkeln Mauseloch", "tokens": ["Aus", "sei\u00b7nem", "dun\u00b7keln", "Mau\u00b7se\u00b7loch"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ein M\u00e4uschen an das Tageslicht,", "tokens": ["Ein", "M\u00e4u\u00b7schen", "an", "das", "Ta\u00b7ges\u00b7licht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und horchte; schrecklich war's zu h\u00f6ren!", "tokens": ["Und", "horch\u00b7te", ";", "schreck\u00b7lich", "wa\u00b7r's", "zu", "h\u00f6\u00b7ren", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "ADJD", "VAFIN", "PTKZU", "VVINF", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Und doch erschrak das M\u00e4uschen nicht.", "tokens": ["Und", "doch", "er\u00b7schrak", "das", "M\u00e4u\u00b7schen", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "ART", "NN", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ei, sprachs, er will uns br\u00fcllen lehren;", "tokens": ["Ei", ",", "sprachs", ",", "er", "will", "uns", "br\u00fcl\u00b7len", "leh\u00b7ren", ";"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "$,", "PPER", "VMFIN", "PPER", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Und fing zu pfeifen an,", "tokens": ["Und", "fing", "zu", "pfei\u00b7fen", "an", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKZU", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "Und stand, und \u00fcbte sich, dem L\u00f6wen nachzubr\u00fcllen.", "tokens": ["Und", "stand", ",", "und", "\u00fcb\u00b7te", "sich", ",", "dem", "L\u00f6\u00b7wen", "nach\u00b7zu\u00b7br\u00fcl\u00b7len", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "KON", "VVFIN", "PRF", "$,", "ART", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Wenn ich die That nicht loben kann,", "tokens": ["Wenn", "ich", "die", "That", "nicht", "lo\u00b7ben", "kann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "PTKNEG", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So lob ich doch den guten Willen.", "tokens": ["So", "lob", "ich", "doch", "den", "gu\u00b7ten", "Wil\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "PPER", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}