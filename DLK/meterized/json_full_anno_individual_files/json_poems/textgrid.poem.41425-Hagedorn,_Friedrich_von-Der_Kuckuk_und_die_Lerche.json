{"textgrid.poem.41425": {"metadata": {"author": {"name": "Hagedorn, Friedrich von", "birth": "N.A.", "death": "N.A."}, "title": "Der Kuckuk und die Lerche", "genre": "verse", "period": "N.A.", "pub_year": 1731, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Den Kuckuk fragt die Lerche:", "tokens": ["Den", "Kuc\u00b7kuk", "fragt", "die", "Ler\u00b7che", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Wie k\u00f6mmt es, sage mir,", "tokens": ["Wie", "k\u00f6mmt", "es", ",", "sa\u00b7ge", "mir", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "$,", "VVFIN", "PPER", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Da\u00df die gereisten St\u00f6rche", "tokens": ["Da\u00df", "die", "ge\u00b7reis\u00b7ten", "St\u00f6r\u00b7che"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Nicht schlauer sind, als wir?", "tokens": ["Nicht", "schlau\u00b7er", "sind", ",", "als", "wir", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PTKNEG", "ADJD", "VAFIN", "$,", "KOUS", "PPER", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Sie sollen uns beweisen,", "tokens": ["Sie", "sol\u00b7len", "uns", "be\u00b7wei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Erwidert er, und lacht,", "tokens": ["Er\u00b7wi\u00b7dert", "er", ",", "und", "lacht", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "KON", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Da\u00df nicht das viele Reisen", "tokens": ["Da\u00df", "nicht", "das", "vie\u00b7le", "Rei\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PTKNEG", "ART", "PIAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Die Dummen kl\u00fcger macht.", "tokens": ["Die", "Dum\u00b7men", "kl\u00fc\u00b7ger", "macht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Den Kuckuk fragt die Lerche:", "tokens": ["Den", "Kuc\u00b7kuk", "fragt", "die", "Ler\u00b7che", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Wie k\u00f6mmt es, sage mir,", "tokens": ["Wie", "k\u00f6mmt", "es", ",", "sa\u00b7ge", "mir", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "$,", "VVFIN", "PPER", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Da\u00df die gereisten St\u00f6rche", "tokens": ["Da\u00df", "die", "ge\u00b7reis\u00b7ten", "St\u00f6r\u00b7che"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Nicht schlauer sind, als wir?", "tokens": ["Nicht", "schlau\u00b7er", "sind", ",", "als", "wir", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PTKNEG", "ADJD", "VAFIN", "$,", "KOUS", "PPER", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Sie sollen uns beweisen,", "tokens": ["Sie", "sol\u00b7len", "uns", "be\u00b7wei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Erwidert er, und lacht,", "tokens": ["Er\u00b7wi\u00b7dert", "er", ",", "und", "lacht", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "KON", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Da\u00df nicht das viele Reisen", "tokens": ["Da\u00df", "nicht", "das", "vie\u00b7le", "Rei\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PTKNEG", "ART", "PIAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Die Dummen kl\u00fcger macht.", "tokens": ["Die", "Dum\u00b7men", "kl\u00fc\u00b7ger", "macht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}}}}