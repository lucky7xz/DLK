{"dta.poem.10766": {"metadata": {"author": {"name": "Opitz, Martin", "birth": "N.A.", "death": "N.A."}, "title": "Epigramma Ejusdem.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1624", "urn": "urn:nbn:de:kobv:b4-200905197859", "language": ["de:0.99"], "booktitle": "Opitz, Martin: Teutsche P\u00f6emata und: Aristarchvs Wieder die verachtung Teutscher Sprach. Stra\u00dfburg, 1624."}, "poem": {"stanza.1": {"line.1": {"text": "Ph&#339;bus pflegt jetzt zu rennen/", "tokens": ["Ph", "&#339;", "bus", "pflegt", "jetzt", "zu", "ren\u00b7nen", "/"], "token_info": ["word", "XML_entity", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$(", "NE", "VVFIN", "ADV", "PTKZU", "VVINF", "$("], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.2": {"text": "Durch de\u00df runden Himmels Saal/", "tokens": ["Durch", "de\u00df", "run\u00b7den", "Him\u00b7mels", "Saal", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Da er pfleget vberal", "tokens": ["Da", "er", "pfle\u00b7get", "vbe\u00b7ral"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PPER", "VVFIN", "NE"], "meter": "--+--+", "measure": "anapaest.di.plus"}, "line.4": {"text": "Den Erdboden zuverbrennen.", "tokens": ["Den", "Erd\u00b7bo\u00b7den", "zu\u00b7ver\u00b7bren\u00b7nen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Doch brennt Ph&#339;bus nicht so sehr/", "tokens": ["Doch", "brennt", "Ph", "&#339;", "bus", "nicht", "so", "sehr", "/"], "token_info": ["word", "word", "word", "XML_entity", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "NE", "$(", "NE", "PTKNEG", "ADV", "ADV", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Weil mein Hertze brennt viel mehr.", "tokens": ["Weil", "mein", "Hert\u00b7ze", "brennt", "viel", "mehr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "VVFIN", "VVFIN", "ADV", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Hat doch ", "tokens": ["Hat", "doch"], "token_info": ["word", "word"], "pos": ["VAFIN", "ADV"], "meter": "-+", "measure": "iambic.single"}, "line.8": {"text": "Nicht durchs gantze Griechenland/", "tokens": ["Nicht", "durchs", "gant\u00b7ze", "Grie\u00b7chen\u00b7land", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPRART", "ADJA", "NE", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.9": {"text": "Sondern durch ", "tokens": ["Son\u00b7dern", "durch"], "token_info": ["word", "word"], "pos": ["KON", "APPR"], "meter": "+-+", "measure": "trochaic.di"}, "line.10": {"text": "Seinen vntergang erfahren.", "tokens": ["Sei\u00b7nen", "vn\u00b7ter\u00b7gang", "er\u00b7fah\u00b7ren", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.11": {"text": "Doch brennt Troja nicht so sehr/", "tokens": ["Doch", "brennt", "Tro\u00b7ja", "nicht", "so", "sehr", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "NE", "PTKNEG", "ADV", "ADV", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.12": {"text": "Weil mein Hertze bren\u0303t viel mehr.", "tokens": ["Weil", "mein", "Hert\u00b7ze", "bre\u00f1t", "viel", "mehr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "VVFIN", "VVFIN", "ADV", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.13": {"text": "Die hochtrabenden Poeten/", "tokens": ["Die", "hoch\u00b7tra\u00b7ben\u00b7den", "Po\u00b7et\u00b7en", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$("], "meter": "-+--+---", "measure": "iambic.di.relaxed"}, "line.14": {"text": "Setzen einen Berg genand", "tokens": ["Set\u00b7zen", "ei\u00b7nen", "Berg", "ge\u00b7nand"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "ART", "NN", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.15": {"text": "&#198;tna der durch seinen brand/", "tokens": ["&#198;", "tna", "der", "durch", "sei\u00b7nen", "brand", "/"], "token_info": ["XML_entity", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "NE", "ART", "APPR", "PPOSAT", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.16": {"text": "Die Beywohner solte T\u00f6dten.", "tokens": ["Die", "Bey\u00b7woh\u00b7ner", "sol\u00b7te", "T\u00f6d\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.17": {"text": "Doch brennt &#198;tna nicht so sehr/", "tokens": ["Doch", "brennt", "&#198;", "tna", "nicht", "so", "sehr", "/"], "token_info": ["word", "word", "XML_entity", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$(", "NE", "PTKNEG", "ADV", "ADV", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.18": {"text": "Weil mein Hertze brennt viel mehr.", "tokens": ["Weil", "mein", "Hert\u00b7ze", "brennt", "viel", "mehr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "VVFIN", "VVFIN", "ADV", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.19": {"text": "Bleibet ", "tokens": ["Blei\u00b7bet"], "token_info": ["word"], "pos": ["NN"], "meter": "+-", "measure": "trochaic.single"}, "line.20": {"text": "Troja geht auff im brand/", "tokens": ["Tro\u00b7ja", "geht", "auff", "im", "brand", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPR", "APPRART", "NN", "$("], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.21": {"text": "&#198;tna brennt durchs gantze Land:", "tokens": ["&#198;", "tna", "brennt", "durchs", "gant\u00b7ze", "Land", ":"], "token_info": ["XML_entity", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "NE", "VVFIN", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.22": {"text": "Ph&#339;bus, Troja, &#198;tna, brennen", "tokens": ["Ph", "&#339;", "bus", ",", "Tro\u00b7ja", ",", "&#198;", "tna", ",", "bren\u00b7nen"], "token_info": ["word", "XML_entity", "word", "punct", "word", "punct", "XML_entity", "word", "punct", "word"], "pos": ["NE", "$(", "NE", "$,", "NE", "$,", "$(", "NE", "$,", "VVINF"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.23": {"text": "Alle drey doch nicht so sehr/", "tokens": ["Al\u00b7le", "drey", "doch", "nicht", "so", "sehr", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "CARD", "ADV", "PTKNEG", "ADV", "ADV", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.24": {"text": "Weil mein Hertze brennt viel mehr.", "tokens": ["Weil", "mein", "Hert\u00b7ze", "brennt", "viel", "mehr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "VVFIN", "VVFIN", "ADV", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}