{"textgrid.poem.39982": {"metadata": {"author": {"name": "Laurentius von Schn\u00fcffis", "birth": "N.A.", "death": "N.A."}, "title": "Anflehung Himmlischer H\u00fclffe", "genre": "verse", "period": "N.A.", "pub_year": 1667, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Soll ich nun von der Bu\u00df zu schreiben mich befrechen/", "tokens": ["Soll", "ich", "nun", "von", "der", "Bu\u00df", "zu", "schrei\u00b7ben", "mich", "be\u00b7fre\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "APPR", "ART", "NN", "PTKZU", "VVINF", "PPER", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der ich doch solcher Kunst selbst unerfahren bin/", "tokens": ["Der", "ich", "doch", "sol\u00b7cher", "Kunst", "selbst", "un\u00b7er\u00b7fah\u00b7ren", "bin", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "PIAT", "NN", "ADV", "ADJD", "VAFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "So mu\u00df das mir dein Geist/ O weiser GOTT/ einsprechen/", "tokens": ["So", "mu\u00df", "das", "mir", "dein", "Geist", "/", "O", "wei\u00b7ser", "GoTT", "/", "ein\u00b7spre\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "PPER", "PPOSAT", "NN", "$(", "NE", "ADJA", "NN", "$(", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und die Unwissenheit von mir gantz nemmen hin;", "tokens": ["Und", "die", "Un\u00b7wis\u00b7sen\u00b7heit", "von", "mir", "gantz", "nem\u00b7men", "hin", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "APPR", "PPER", "ADV", "VVFIN", "PTKVZ", "$."], "meter": "--++-+--+--+", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Sey mein ", "tokens": ["Sey", "mein"], "token_info": ["word", "word"], "pos": ["VAFIN", "PPOSAT"], "meter": "-+", "measure": "iambic.single"}, "line.6": {"text": "Dein Blut/ O Jesu/ sey mein s\u00fcsser ", "tokens": ["Dein", "Blut", "/", "O", "Je\u00b7su", "/", "sey", "mein", "s\u00fcs\u00b7ser"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["PPOSAT", "NN", "$(", "NE", "NE", "$(", "VAFIN", "PPOSAT", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Da will ich meine Sinn/ und halb-erstorbne Geister/", "tokens": ["Da", "will", "ich", "mei\u00b7ne", "Sinn", "/", "und", "halb\u00b7er\u00b7storb\u00b7ne", "Geis\u00b7ter", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PPOSAT", "NN", "$(", "KON", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Wie auch mein d\u00fcrre Zung frisch anzuseuchten gehn.", "tokens": ["Wie", "auch", "mein", "d\u00fcr\u00b7re", "Zung", "frisch", "an\u00b7zu\u00b7seuch\u00b7ten", "gehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "PPOSAT", "ADJA", "NN", "ADJD", "VVIZU", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Maria sey von mir zur ", "tokens": ["Ma\u00b7ria", "sey", "von", "mir", "zur"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "VAFIN", "APPR", "PPER", "APPRART"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.10": {"text": "Die Mutter klugster Sinn/ und h\u00f6chster Wissenschafft/", "tokens": ["Die", "Mut\u00b7ter", "klugs\u00b7ter", "Sinn", "/", "und", "h\u00f6chs\u00b7ter", "Wis\u00b7sen\u00b7schafft", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$(", "KON", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Die vor den Englen wird/ erleucht zu seyn gepriesen/", "tokens": ["Die", "vor", "den", "Eng\u00b7len", "wird", "/", "er\u00b7leucht", "zu", "seyn", "ge\u00b7prie\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "VAFIN", "$(", "VVPP", "PTKZU", "VAINF", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Die wird von ", "tokens": ["Die", "wird", "von"], "token_info": ["word", "word", "word"], "pos": ["PDS", "VAFIN", "APPR"], "meter": "++-", "measure": "unknown.measure.di"}, "line.13": {"text": "Sey meine Lorbeer-H\u00fctt/ und Christlicher ", "tokens": ["Sey", "mei\u00b7ne", "Lor\u00b7beer\u00b7H\u00fctt", "/", "und", "Christ\u00b7li\u00b7cher"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["VAFIN", "PPOSAT", "NN", "$(", "KON", "NN"], "meter": "-+-+-+-+--", "measure": "unknown.measure.tetra"}, "line.14": {"text": "Von dort hoff ich zu seyn/ wie ", "tokens": ["Von", "dort", "hoff", "ich", "zu", "seyn", "/", "wie"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["APPR", "ADV", "VVFIN", "PPER", "PTKZU", "VAINF", "$(", "KOKOM"], "meter": "+-+-++-", "measure": "unknown.measure.tetra"}, "line.15": {"text": "Von dorten ich den Thau dern g\u00f6ldnen Gnaden fa\u00df'.", "tokens": ["Von", "dor\u00b7ten", "ich", "den", "Thau", "dern", "g\u00f6ld\u00b7nen", "Gna\u00b7den", "fa\u00df'", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "PPER", "ART", "NN", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Zu Gottes Lob/ und Ehr fang' ich dann an zu dichten/", "tokens": ["Zu", "Got\u00b7tes", "Lob", "/", "und", "Ehr", "fang'", "ich", "dann", "an", "zu", "dich\u00b7ten", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "NN", "$(", "KON", "NN", "VVFIN", "PPER", "ADV", "APPR", "APPR", "ADJA", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "(ach/ da\u00df es auch zum Heyl dern grossen S\u00fcndern sey!)", "tokens": ["(", "ach", "/", "da\u00df", "es", "auch", "zum", "Heyl", "dern", "gros\u00b7sen", "S\u00fcn\u00b7dern", "sey", "!", ")"], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "XY", "$(", "KOUS", "PPER", "ADV", "APPRART", "NN", "ART", "ADJA", "NN", "VAFIN", "$.", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Will nach des Himmels Port hertzhafft die S\u00e4gel richten/", "tokens": ["Will", "nach", "des", "Him\u00b7mels", "Port", "hertz\u00b7hafft", "die", "S\u00e4\u00b7gel", "rich\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "APPR", "ART", "NN", "NE", "VVFIN", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "So sto\u00df ich dann von Land/ Gl\u00fccks-Winde steht mir bey.", "tokens": ["So", "sto\u00df", "ich", "dann", "von", "Land", "/", "Gl\u00fccks\u00b7Win\u00b7de", "steht", "mir", "bey", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPR", "NN", "$(", "NN", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Soll ich nun von der Bu\u00df zu schreiben mich befrechen/", "tokens": ["Soll", "ich", "nun", "von", "der", "Bu\u00df", "zu", "schrei\u00b7ben", "mich", "be\u00b7fre\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "APPR", "ART", "NN", "PTKZU", "VVINF", "PPER", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der ich doch solcher Kunst selbst unerfahren bin/", "tokens": ["Der", "ich", "doch", "sol\u00b7cher", "Kunst", "selbst", "un\u00b7er\u00b7fah\u00b7ren", "bin", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "PIAT", "NN", "ADV", "ADJD", "VAFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "So mu\u00df das mir dein Geist/ O weiser GOTT/ einsprechen/", "tokens": ["So", "mu\u00df", "das", "mir", "dein", "Geist", "/", "O", "wei\u00b7ser", "GoTT", "/", "ein\u00b7spre\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "PPER", "PPOSAT", "NN", "$(", "NE", "ADJA", "NN", "$(", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und die Unwissenheit von mir gantz nemmen hin;", "tokens": ["Und", "die", "Un\u00b7wis\u00b7sen\u00b7heit", "von", "mir", "gantz", "nem\u00b7men", "hin", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "APPR", "PPER", "ADV", "VVFIN", "PTKVZ", "$."], "meter": "--++-+--+--+", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Sey mein ", "tokens": ["Sey", "mein"], "token_info": ["word", "word"], "pos": ["VAFIN", "PPOSAT"], "meter": "-+", "measure": "iambic.single"}, "line.6": {"text": "Dein Blut/ O Jesu/ sey mein s\u00fcsser ", "tokens": ["Dein", "Blut", "/", "O", "Je\u00b7su", "/", "sey", "mein", "s\u00fcs\u00b7ser"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["PPOSAT", "NN", "$(", "NE", "NE", "$(", "VAFIN", "PPOSAT", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Da will ich meine Sinn/ und halb-erstorbne Geister/", "tokens": ["Da", "will", "ich", "mei\u00b7ne", "Sinn", "/", "und", "halb\u00b7er\u00b7storb\u00b7ne", "Geis\u00b7ter", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PPOSAT", "NN", "$(", "KON", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Wie auch mein d\u00fcrre Zung frisch anzuseuchten gehn.", "tokens": ["Wie", "auch", "mein", "d\u00fcr\u00b7re", "Zung", "frisch", "an\u00b7zu\u00b7seuch\u00b7ten", "gehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "PPOSAT", "ADJA", "NN", "ADJD", "VVIZU", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Maria sey von mir zur ", "tokens": ["Ma\u00b7ria", "sey", "von", "mir", "zur"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "VAFIN", "APPR", "PPER", "APPRART"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.10": {"text": "Die Mutter klugster Sinn/ und h\u00f6chster Wissenschafft/", "tokens": ["Die", "Mut\u00b7ter", "klugs\u00b7ter", "Sinn", "/", "und", "h\u00f6chs\u00b7ter", "Wis\u00b7sen\u00b7schafft", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$(", "KON", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Die vor den Englen wird/ erleucht zu seyn gepriesen/", "tokens": ["Die", "vor", "den", "Eng\u00b7len", "wird", "/", "er\u00b7leucht", "zu", "seyn", "ge\u00b7prie\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "VAFIN", "$(", "VVPP", "PTKZU", "VAINF", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Die wird von ", "tokens": ["Die", "wird", "von"], "token_info": ["word", "word", "word"], "pos": ["PDS", "VAFIN", "APPR"], "meter": "++-", "measure": "unknown.measure.di"}, "line.13": {"text": "Sey meine Lorbeer-H\u00fctt/ und Christlicher ", "tokens": ["Sey", "mei\u00b7ne", "Lor\u00b7beer\u00b7H\u00fctt", "/", "und", "Christ\u00b7li\u00b7cher"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["VAFIN", "PPOSAT", "NN", "$(", "KON", "NN"], "meter": "-+-+-+-+--", "measure": "unknown.measure.tetra"}, "line.14": {"text": "Von dort hoff ich zu seyn/ wie ", "tokens": ["Von", "dort", "hoff", "ich", "zu", "seyn", "/", "wie"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["APPR", "ADV", "VVFIN", "PPER", "PTKZU", "VAINF", "$(", "KOKOM"], "meter": "+-+-++-", "measure": "unknown.measure.tetra"}, "line.15": {"text": "Von dorten ich den Thau dern g\u00f6ldnen Gnaden fa\u00df'.", "tokens": ["Von", "dor\u00b7ten", "ich", "den", "Thau", "dern", "g\u00f6ld\u00b7nen", "Gna\u00b7den", "fa\u00df'", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "PPER", "ART", "NN", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Zu Gottes Lob/ und Ehr fang' ich dann an zu dichten/", "tokens": ["Zu", "Got\u00b7tes", "Lob", "/", "und", "Ehr", "fang'", "ich", "dann", "an", "zu", "dich\u00b7ten", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "NN", "$(", "KON", "NN", "VVFIN", "PPER", "ADV", "APPR", "APPR", "ADJA", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "(ach/ da\u00df es auch zum Heyl dern grossen S\u00fcndern sey!)", "tokens": ["(", "ach", "/", "da\u00df", "es", "auch", "zum", "Heyl", "dern", "gros\u00b7sen", "S\u00fcn\u00b7dern", "sey", "!", ")"], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "XY", "$(", "KOUS", "PPER", "ADV", "APPRART", "NN", "ART", "ADJA", "NN", "VAFIN", "$.", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Will nach des Himmels Port hertzhafft die S\u00e4gel richten/", "tokens": ["Will", "nach", "des", "Him\u00b7mels", "Port", "hertz\u00b7hafft", "die", "S\u00e4\u00b7gel", "rich\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "APPR", "ART", "NN", "NE", "VVFIN", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "So sto\u00df ich dann von Land/ Gl\u00fccks-Winde steht mir bey.", "tokens": ["So", "sto\u00df", "ich", "dann", "von", "Land", "/", "Gl\u00fccks\u00b7Win\u00b7de", "steht", "mir", "bey", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPR", "NN", "$(", "NN", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}