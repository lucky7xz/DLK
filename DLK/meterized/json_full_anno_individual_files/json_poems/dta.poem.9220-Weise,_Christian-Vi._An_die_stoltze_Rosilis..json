{"dta.poem.9220": {"metadata": {"author": {"name": "Weise, Christian", "birth": "N.A.", "death": "N.A."}, "title": "Vi.  \n An die stoltze Rosilis.", "genre": "Lyrik; Drama; Prosa", "period": "N.A.", "pub_year": "1701", "urn": "urn:nbn:de:kobv:b4-25043-0", "language": ["de:0.99"], "booktitle": "Weise, Christian: \u00dcberfl\u00fc\u00dfige Gedancken Der gr\u00fcnenden jugend. Leipzig, 1701."}, "poem": {"stanza.1": {"line.1": {"text": "Ich kan nicht l\u00e4nger bitten/", "tokens": ["Ich", "kan", "nicht", "l\u00e4n\u00b7ger", "bit\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PTKNEG", "ADJD", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Es ist vor mich zu viel/", "tokens": ["Es", "ist", "vor", "mich", "zu", "viel", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "PPER", "PTKA", "PIS", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Wo sie an ihren sitten", "tokens": ["Wo", "sie", "an", "ih\u00b7ren", "sit\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Nicht anders werden wil/", "tokens": ["Nicht", "an\u00b7ders", "wer\u00b7den", "wil", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "VAINF", "VMFIN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "So hab ichs schon bedacht/", "tokens": ["So", "hab", "ichs", "schon", "be\u00b7dacht", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIS", "ADV", "VVPP", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Und gebe gute nacht.", "tokens": ["Und", "ge\u00b7be", "gu\u00b7te", "nacht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "2. Man trifft dergleichen leute", "tokens": ["Man", "trifft", "derg\u00b7lei\u00b7chen", "leu\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "PIS", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Noch allenthalben an/", "tokens": ["Noch", "al\u00b7len\u00b7thal\u00b7ben", "an", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PTKVZ", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Wer wei\u00df/ ob ich nicht heute", "tokens": ["Wer", "wei\u00df", "/", "ob", "ich", "nicht", "heu\u00b7te"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "$(", "KOUS", "PPER", "PTKNEG", "ADV"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Was frisches haben kan?", "tokens": ["Was", "fri\u00b7sches", "ha\u00b7ben", "kan", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "ADJA", "VAINF", "VMFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Die welt ist gro\u00df genung/", "tokens": ["Die", "welt", "ist", "gro\u00df", "ge\u00b7nung", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Und ich bin starck und jung.", "tokens": ["Und", "ich", "bin", "starck", "und", "jung", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "3. So wolte sie es haben/", "tokens": ["So", "wol\u00b7te", "sie", "es", "ha\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PPER", "VAFIN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Ich solte mich allein", "tokens": ["Ich", "sol\u00b7te", "mich", "al\u00b7lein"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PPER", "ADV"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Mit leerer hoffnung laben/", "tokens": ["Mit", "lee\u00b7rer", "hoff\u00b7nung", "la\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und doch ihr diener seyn/", "tokens": ["Und", "doch", "ihr", "die\u00b7ner", "seyn", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PPOSAT", "NN", "VAINF", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Drum sch\u00fctzte sie bey mir", "tokens": ["Drum", "sch\u00fctz\u00b7te", "sie", "bey", "mir"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "PPER", "APPR", "PPER"], "meter": "-+-++-", "measure": "unknown.measure.tri"}, "line.6": {"text": "So lahme possen f\u00fcr.", "tokens": ["So", "lah\u00b7me", "pos\u00b7sen", "f\u00fcr", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "APPR", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "4. Ach nein/ es sind der sauren/", "tokens": ["Ach", "nein", "/", "es", "sind", "der", "sau\u00b7ren", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKANT", "$(", "PPER", "VAFIN", "ART", "ADJA", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Ich wei\u00df wohl/ was ich thu/", "tokens": ["Ich", "wei\u00df", "wohl", "/", "was", "ich", "thu", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$(", "PWS", "PPER", "VVFIN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "So hetzet man die bauren/", "tokens": ["So", "het\u00b7zet", "man", "die", "bau\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "ART", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Ich bin zu schlim darzu/", "tokens": ["Ich", "bin", "zu", "schlim", "dar\u00b7zu", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKA", "ADJD", "PAV", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Es treffe mir so ein:", "tokens": ["Es", "tref\u00b7fe", "mir", "so", "ein", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Quarck m\u00fcste butter seyn.", "tokens": ["Quarck", "m\u00fcs\u00b7te", "but\u00b7ter", "seyn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "ADJD", "VAINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "5. Ey/ sol ich mich verlieben?", "tokens": ["Ey", "/", "sol", "ich", "mich", "ver\u00b7lie\u00b7ben", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "VMFIN", "PPER", "PRF", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Soll ich mich auf den todt", "tokens": ["Soll", "ich", "mich", "auf", "den", "todt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "PPER", "PRF", "APPR", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Um ihre gunst betr\u00fcben?", "tokens": ["Um", "ih\u00b7re", "gunst", "be\u00b7tr\u00fc\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUI", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Ach nein/ es hat nicht noth/", "tokens": ["Ach", "nein", "/", "es", "hat", "nicht", "noth", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKANT", "$(", "PPER", "VAFIN", "PTKNEG", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Sie ist gar falsch bericht/", "tokens": ["Sie", "ist", "gar", "falsch", "be\u00b7richt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "VVPP", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Vor liebe sterb ich nicht.", "tokens": ["Vor", "lie\u00b7be", "sterb", "ich", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "6. ", "tokens": [], "token_info": [], "pos": []}, "line.2": {"text": "Verbleibe wer du bist/", "tokens": ["Ver\u00b7blei\u00b7be", "wer", "du", "bist", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PWS", "PPER", "VAFIN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und wo ein viertel st\u00fcndgen", "tokens": ["Und", "wo", "ein", "vier\u00b7tel", "st\u00fcnd\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "ART", "NN", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Dir nicht beschwerlich ist/", "tokens": ["Dir", "nicht", "be\u00b7schwer\u00b7lich", "ist", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKNEG", "ADJD", "VAFIN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "So sieh zum fenster nau\u00df/", "tokens": ["So", "sieh", "zum", "fens\u00b7ter", "nau\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPRART", "NN", "PTKVZ", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Ich such einander hau\u00df.", "tokens": ["Ich", "such", "ein\u00b7an\u00b7der", "hau\u00df", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "7. Ich wil dich \u00fcbertrotzen/", "tokens": ["Ich", "wil", "dich", "\u00fc\u00b7bert\u00b7rot\u00b7zen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PRF", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Sey noch einmahl so stoltz/", "tokens": ["Sey", "noch", "ein\u00b7mahl", "so", "stoltz", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "ADV", "ADJD", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "La\u00df dein gesichte strotzen/", "tokens": ["La\u00df", "dein", "ge\u00b7sich\u00b7te", "strot\u00b7zen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPOSAT", "ADJA", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Als wie ein eichen-holtz/", "tokens": ["Als", "wie", "ein", "ei\u00b7chen\u00b7holtz", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOKOM", "ART", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Ich geh nunmehr gemach", "tokens": ["Ich", "geh", "nun\u00b7mehr", "ge\u00b7mach"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "ADV"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Und frage nichts darnach.", "tokens": ["Und", "fra\u00b7ge", "nichts", "dar\u00b7nach", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIS", "PAV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}}}}