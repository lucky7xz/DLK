{"dta.poem.19877": {"metadata": {"author": {"name": "B\u00fcrger, Gottfried August", "birth": "N.A.", "death": "N.A."}, "title": "Neue  \n weltliche hochteutsche Reime,  \n   enthaltend  \n die ebentheyerliche doch wahrhaftige  \n  Historiam  \n von der  \n  wundersch\u00f6nen Durchlauchtigen  \n Kaiserlichen  \n  Prinzessin Europa,  \n und  \n  einem uralten heidnischen  \n G\u00f6zen,  \n  Jupiter   item   Zeus  \n genant ,  \n als welcher sich nicht entbl\u00f6det, unter der Larve  \n eines unvern\u00fcnftigen Stieres, an h\u00f6chstgedachter Prin-  \n zessin ein  crimen raptus,  zu teutsch: Jung-  \n fernraub auszuiiben.  \n   Also gesezet und an das Licht gestellet  \n durch  \n  M.  Jocosum Hilarium,  \n Po\u00ebt, caes. laur.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1778", "urn": "urn:nbn:de:kobv:b4-20090519672", "language": ["de:0.99"], "booktitle": "B\u00fcrger, Gottfried August: Gedichte. G\u00f6ttingen, 1778."}, "poem": {"stanza.1": {"line.1": {"text": "Vor Alters war ein Gott,               ", "tokens": ["Vor", "Al\u00b7ters", "war", "ein", "Gott", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Von nicht geringem Ruhme,", "tokens": ["Von", "nicht", "ge\u00b7rin\u00b7gem", "Ruh\u00b7me", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PTKNEG", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Im blinden Heidenthume.", "tokens": ["Im", "blin\u00b7den", "Hei\u00b7den\u00b7thu\u00b7me", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Nun aber ist er todt.", "tokens": ["Nun", "a\u00b7ber", "ist", "er", "todt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VAFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Er starb \u201e \u201e ", "tokens": ["Er", "starb", "\u201e", "\u201e"], "token_info": ["word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "$(", "$("], "meter": "-+", "measure": "iambic.single"}, "line.6": {"text": "Ich weis nicht mehr das ", "tokens": ["Ich", "weis", "nicht", "mehr", "das"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "PTKVZ", "PTKNEG", "ADV", "ART"], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.2": {"line.1": {"text": "Der war an Schelmerei,", "tokens": ["Der", "war", "an", "Schel\u00b7me\u00b7rei", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "APPR", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Das Weibsen zu betr\u00fcgen,", "tokens": ["Das", "Weib\u00b7sen", "zu", "be\u00b7tr\u00fc\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Von dem Papa der L\u00fcgen", "tokens": ["Von", "dem", "Pa\u00b7pa", "der", "L\u00fc\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Das \u00e4chte Konterfei;", "tokens": ["Das", "\u00e4ch\u00b7te", "Kon\u00b7ter\u00b7fei", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Und kurz, auf alle F\u00e4lle,", "tokens": ["Und", "kurz", ",", "auf", "al\u00b7le", "F\u00e4l\u00b7le", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "$,", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Ein lockerer Geselle.", "tokens": ["Ein", "lo\u00b7cke\u00b7rer", "Ge\u00b7sel\u00b7le", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Ich hab\u2019 ein altes Buch,", "tokens": ["Ich", "hab'", "ein", "al\u00b7tes", "Buch", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Das thut von ihm berichten", "tokens": ["Das", "thut", "von", "ihm", "be\u00b7rich\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "APPR", "PPER", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Viel schnurrige Geschichten,", "tokens": ["Viel", "schnur\u00b7ri\u00b7ge", "Ge\u00b7schich\u00b7ten", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Worin manch Stuzer gnug", "tokens": ["Wo\u00b7rin", "manch", "Stu\u00b7zer", "gnug"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "PIAT", "NN", "ADV"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "F\u00fcr seinen Schnabel f\u00e4nde,", "tokens": ["F\u00fcr", "sei\u00b7nen", "Schna\u00b7bel", "f\u00e4n\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Wenn er Latein verst\u00e4nde.", "tokens": ["Wenn", "er", "La\u00b7tein", "ver\u00b7st\u00e4n\u00b7de", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NN", "VVFIN", "$."], "meter": "--+--+-", "measure": "anapaest.di.plus"}}, "stanza.4": {"line.1": {"text": "Mein unverdrosner Mund", "tokens": ["Mein", "un\u00b7ver\u00b7dros\u00b7ner", "Mund"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Sol, ohne viel zu w\u00e4len,", "tokens": ["Sol", ",", "oh\u00b7ne", "viel", "zu", "w\u00e4\u00b7len", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "$,", "KOUI", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Nur Einen Knif erz\u00e4len.", "tokens": ["Nur", "Ei\u00b7nen", "Knif", "er\u00b7z\u00e4\u00b7len", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Denn th\u00e4t\u2019 ich alle kund,", "tokens": ["Denn", "th\u00e4t'", "ich", "al\u00b7le", "kund", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PIS", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "So w\u00e4re zu besorgen,", "tokens": ["So", "w\u00e4\u00b7re", "zu", "be\u00b7sor\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Ich s\u00e4ng\u2019 bis \u00fcbermorgen.", "tokens": ["Ich", "s\u00e4ng'", "bis", "\u00fc\u00b7ber\u00b7mor\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Eur Bazen sol euch nicht,", "tokens": ["Eur", "Ba\u00b7zen", "sol", "euch", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VMFIN", "PPER", "PTKNEG", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Geehrte Herrn, gereuen.", "tokens": ["Ge\u00b7ehr\u00b7te", "Herrn", ",", "ge\u00b7reu\u00b7en", "."], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["ADJA", "NN", "$,", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Mein Liedel sol euch freuen! \u2014", "tokens": ["Mein", "Lie\u00b7del", "sol", "euch", "freu\u00b7en", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPOSAT", "NN", "VMFIN", "PPER", "VVINF", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Doch ihr dort! Schelmgez\u00fccht!", "tokens": ["Doch", "ihr", "dort", "!", "Schelm\u00b7ge\u00b7z\u00fccht", "!"], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "PPER", "ADV", "$.", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Kroaten, hinter\u2019n B\u00e4nken!", "tokens": ["Kroa\u00b7ten", ",", "hin\u00b7ter'n", "B\u00e4n\u00b7ken", "!"], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "ADJA", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.6": {"text": "Last nach mit L\u00e4rm und Schw\u00e4nken!", "tokens": ["Last", "nach", "mit", "L\u00e4rm", "und", "Schw\u00e4n\u00b7ken", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Heda! Hier nichts gegekt,", "tokens": ["He\u00b7da", "!", "Hier", "nichts", "ge\u00b7gekt", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$.", "ADV", "PIS", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Ihr ungewaschnen Buben!", "tokens": ["Ihr", "un\u00b7ge\u00b7waschnen", "Bu\u00b7ben", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Narrirt in andern Stuben,", "tokens": ["Nar\u00b7rirt", "in", "an\u00b7dern", "Stu\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Nur mich last ungenekt!", "tokens": ["Nur", "mich", "last", "un\u00b7ge\u00b7nekt", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VVFIN", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Sonst h\u00e4ngt euch, schnaps! am Munde", "tokens": ["Sonst", "h\u00e4ngt", "euch", ",", "schnaps", "!", "am", "Mun\u00b7de"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "$,", "VVFIN", "$.", "APPRART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Ein Schlos; wiegt tausend Pfunde.", "tokens": ["Ein", "Schlos", ";", "wiegt", "tau\u00b7send", "Pfun\u00b7de", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$.", "VVFIN", "CARD", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Ha! das Donatgeschmeis!", "tokens": ["Ha", "!", "das", "Do\u00b7nat\u00b7ge\u00b7schmeis", "!"], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["ITJ", "$.", "ART", "NN", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.2": {"text": "Kaum h\u00f6rt und sieht\u2019s was Neues,", "tokens": ["Kaum", "h\u00f6rt", "und", "sieht's", "was", "Neu\u00b7es", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "KON", "FM", "FM", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "So hat es gleich Geschreies,", "tokens": ["So", "hat", "es", "gleich", "Ge\u00b7schrei\u00b7es", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "So puppert Herz und Steis.", "tokens": ["So", "pup\u00b7pert", "Herz", "und", "Steis", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NN", "KON", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Gedult! Man wird\u2019s euch zalen,", "tokens": ["Ge\u00b7dult", "!", "Man", "wird's", "euch", "za\u00b7len", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "PIS", "VAFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Euch d\u00fcnnen Schulpennalen!", "tokens": ["Euch", "d\u00fcn\u00b7nen", "Schul\u00b7pen\u00b7na\u00b7len", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Traut nicht! Es regt sich hie,", "tokens": ["Traut", "nicht", "!", "Es", "regt", "sich", "hie", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "$.", "PPER", "VVFIN", "PRF", "ADV", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "In meinem Wolfstornister,", "tokens": ["In", "mei\u00b7nem", "Wolfs\u00b7tor\u00b7nis\u00b7ter", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Der Kukuk und sein K\u00fcster \u2014", "tokens": ["Der", "Ku\u00b7kuk", "und", "sein", "K\u00fcs\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "PPOSAT", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Ein Kobolt \u2014 heist Genie.", "tokens": ["Ein", "Ko\u00b7bolt", "heist", "Ge\u00b7nie", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "VAFIN", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.5": {"text": "Dem schaft\u2019s gar guten Frieden,", "tokens": ["Dem", "schaft's", "gar", "gu\u00b7ten", "Frie\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Wem Gott solch Ding beschieden.", "tokens": ["Wem", "Gott", "solch", "Ding", "be\u00b7schie\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "PIAT", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Last ja den Griesgram gehn!", "tokens": ["Last", "ja", "den", "Gries\u00b7gram", "gehn", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "VVINF", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.2": {"text": "Er weis euch zu kuranzen;", "tokens": ["Er", "weis", "euch", "zu", "ku\u00b7ran\u00b7zen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKVZ", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "L\u00e4st euch wie Affen tanzen,", "tokens": ["L\u00e4st", "euch", "wie", "Af\u00b7fen", "tan\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "KOKOM", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und auf den K\u00f6pfen stehn;", "tokens": ["Und", "auf", "den", "K\u00f6p\u00b7fen", "stehn", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Wird euch mal begenieen,", "tokens": ["Wird", "euch", "mal", "be\u00b7ge\u00b7ni\u00b7e\u00b7en", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "VVPP", "$,"], "meter": "+-+--+--", "measure": "trochaic.tri.relaxed"}, "line.6": {"text": "Da\u00df euch die Steisse gl\u00fchen. \u2014", "tokens": ["Da\u00df", "euch", "die", "Steis\u00b7se", "gl\u00fc\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "Doch ihr, Kunstj\u00fcngerlein!", "tokens": ["Doch", "ihr", ",", "Kunst\u00b7j\u00fcn\u00b7ger\u00b7lein", "!"], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["KON", "PPER", "$,", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "M\u00f6gt meine Melodeien", "tokens": ["M\u00f6gt", "mei\u00b7ne", "Me\u00b7lo\u00b7dei\u00b7en"], "token_info": ["word", "word", "word"], "pos": ["VMFIN", "PPOSAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Nur nicht flugs nachlalleien.", "tokens": ["Nur", "nicht", "flugs", "nach\u00b7lal\u00b7lei\u00b7en", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKNEG", "ADV", "VVIZU", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "So leicht lalt sich\u2019s nicht \u2019nein.", "tokens": ["So", "leicht", "lalt", "sich's", "nicht", "'n\u00b7ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "PIS", "PTKNEG", "NN", "$."], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.5": {"text": "Beherzigt doch das ", "tokens": ["Be\u00b7her\u00b7zigt", "doch", "das"], "token_info": ["word", "word", "word"], "pos": ["VVFIN", "ADV", "ART"], "meter": "-+-+-", "measure": "iambic.di"}, "line.6": {"text": "Cacatum non est pictum. &#8212; &#8212; &#8212;             ", "tokens": ["Ca\u00b7ca\u00b7tum", "non", "est", "pic\u00b7tum", ".", "&#8212;", "&#8212;", "&#8212;"], "token_info": ["word", "word", "word", "word", "punct", "XML_entity", "XML_entity", "XML_entity"], "pos": ["FM", "FM", "FM", "FM", "$.", "$(", "$(", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.11": {"line.1": {"text": "Eur Bazen sol euch nicht,", "tokens": ["Eur", "Ba\u00b7zen", "sol", "euch", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VMFIN", "PPER", "PTKNEG", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Geehrte Herrn, gereuen.", "tokens": ["Ge\u00b7ehr\u00b7te", "Herrn", ",", "ge\u00b7reu\u00b7en", "."], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["ADJA", "NN", "$,", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Mein Liedel sol euch freuen!", "tokens": ["Mein", "Lie\u00b7del", "sol", "euch", "freu\u00b7en", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Nun schaut mir ins Gesicht!", "tokens": ["Nun", "schaut", "mir", "ins", "Ge\u00b7sicht", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPRART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Merkt auf mit Herz und Sinnen!", "tokens": ["Merkt", "auf", "mit", "Herz", "und", "Sin\u00b7nen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "APPR", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Wil endlich mal beginnen. \u2014", "tokens": ["Wil", "end\u00b7lich", "mal", "be\u00b7gin\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["VMFIN", "ADV", "ADV", "VVINF", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "Zeus w\u00e4lzt\u2019 im Bette sich,", "tokens": ["Zeus", "w\u00e4lzt'", "im", "Bet\u00b7te", "sich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPRART", "NN", "PRF", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Nachdem er lang gelegen,", "tokens": ["Nach\u00b7dem", "er", "lang", "ge\u00b7le\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Wie Potentaten pflegen,", "tokens": ["Wie", "Po\u00b7ten\u00b7ta\u00b7ten", "pfle\u00b7gen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PWAV", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und fluchte m\u00f6rderlich:", "tokens": ["Und", "fluch\u00b7te", "m\u00f6r\u00b7der\u00b7lich", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "\u201eschon trommelt\u2019s zur Parade!", "tokens": ["\u201e", "schon", "trom\u00b7melt's", "zur", "Pa\u00b7ra\u00b7de", "!"], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VVFIN", "APPRART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Wo bleibt die Schokolade?", "tokens": ["Wo", "bleibt", "die", "Scho\u00b7ko\u00b7la\u00b7de", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.13": {"line.1": {"text": "Gleich bringt sie sein Lakei;", "tokens": ["Gleich", "bringt", "sie", "sein", "La\u00b7kei", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Bringt Schlafrok, Toffeln, Hose,", "tokens": ["Bringt", "Schlaf\u00b7rok", ",", "Tof\u00b7feln", ",", "Ho\u00b7se", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["VVFIN", "NN", "$,", "NN", "$,", "NE", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Schlept Pfeiffe, Knasterdose", "tokens": ["Schlept", "Pfeif\u00b7fe", ",", "Knas\u00b7ter\u00b7do\u00b7se"], "token_info": ["word", "word", "punct", "word"], "pos": ["NN", "NN", "$,", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Nebst Fidibus herbei.", "tokens": ["Nebst", "Fi\u00b7di\u00b7bus", "her\u00b7bei", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NE", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Denn Morgens ging kein M\u00e4dchen", "tokens": ["Denn", "Mor\u00b7gens", "ging", "kein", "M\u00e4d\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "PIAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Gern in sein Kabinetchen.", "tokens": ["Gern", "in", "sein", "Ka\u00b7bi\u00b7net\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.14": {"line.1": {"text": "Er schl\u00fcrft\u2019 acht Tassen aus;", "tokens": ["Er", "schl\u00fcrft'", "acht", "Tas\u00b7sen", "aus", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "CARD", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Hing dann, zum Zeitvertreibe,", "tokens": ["Hing", "dann", ",", "zum", "Zeit\u00b7ver\u00b7trei\u00b7be", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "$,", "APPRART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Sich mit dem halben Leibe", "tokens": ["Sich", "mit", "dem", "hal\u00b7ben", "Lei\u00b7be"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PRF", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Zum Himmelsfenster \u2019naus,", "tokens": ["Zum", "Him\u00b7mels\u00b7fens\u00b7ter", "'naus", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "NN", "NE", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Und schmauchte, frisch und munter,", "tokens": ["Und", "schmauch\u00b7te", ",", "frisch", "und", "mun\u00b7ter", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Sein Pfeifchen Knaster \u2019runter.", "tokens": ["Sein", "Pfei\u00b7fchen", "Knas\u00b7ter", "'r\u00b7un\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "NE", "NE", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.15": {"line.1": {"text": "Und durch sein Perspectiv", "tokens": ["Und", "durch", "sein", "Per\u00b7spec\u00b7tiv"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Visirt\u2019 er von dem Himmel,", "tokens": ["Vi\u00b7sirt'", "er", "von", "dem", "Him\u00b7mel", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Nach unserm Weltget\u00fcmmel.", "tokens": ["Nach", "un\u00b7serm", "Welt\u00b7ge\u00b7t\u00fcm\u00b7mel", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Sonst mochten wol so tief", "tokens": ["Sonst", "moch\u00b7ten", "wol", "so", "tief"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "ADV", "ADV", "ADJD"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Die abgeschw\u00e4chten Augen", "tokens": ["Die", "ab\u00b7ge\u00b7schw\u00e4ch\u00b7ten", "Au\u00b7gen"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Nicht mehr zu sehen taugen.", "tokens": ["Nicht", "mehr", "zu", "se\u00b7hen", "tau\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.16": {"line.1": {"text": "Da nahm er schmunzelnd wahr,", "tokens": ["Da", "nahm", "er", "schmun\u00b7zelnd", "wahr", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Auf sch\u00f6nbebl\u00fcmten Auen,", "tokens": ["Auf", "sch\u00f6n\u00b7be\u00b7bl\u00fcm\u00b7ten", "Au\u00b7en", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Gar lieblich anzuschauen,", "tokens": ["Gar", "lieb\u00b7lich", "an\u00b7zu\u00b7schau\u00b7en", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVIZU", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Vergn\u00fcgter M\u00e4gdlein Schaar,", "tokens": ["Ver\u00b7gn\u00fcg\u00b7ter", "M\u00e4gd\u00b7lein", "Schaar", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Die auf dem gr\u00fcnen Rasen", "tokens": ["Die", "auf", "dem", "gr\u00fc\u00b7nen", "Ra\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Sich G\u00e4nsebl\u00fcmchen lasen.", "tokens": ["Sich", "G\u00e4n\u00b7se\u00b7bl\u00fcm\u00b7chen", "la\u00b7sen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PRF", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.17": {"line.1": {"text": "Die Sch\u00f6nste war geschm\u00fckt", "tokens": ["Die", "Sch\u00f6ns\u00b7te", "war", "ge\u00b7schm\u00fckt"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "VVPP"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Mit einem leichten Kleide,", "tokens": ["Mit", "ei\u00b7nem", "leich\u00b7ten", "Klei\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Von rosinfarbner Seide,", "tokens": ["Von", "ro\u00b7sin\u00b7farb\u00b7ner", "Sei\u00b7de", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Mit Fadengold durchstikt.", "tokens": ["Mit", "Fa\u00b7den\u00b7gold", "durchs\u00b7tikt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Die Andern aber schienen", "tokens": ["Die", "An\u00b7dern", "a\u00b7ber", "schie\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "ADV", "VVFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "In Demut ihr zu dienen.", "tokens": ["In", "De\u00b7mut", "ihr", "zu", "die\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.18": {"line.1": {"text": "Die niedliche Gestalt,", "tokens": ["Die", "nied\u00b7li\u00b7che", "Ge\u00b7stalt", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Die schlanken zarten Glieder,", "tokens": ["Die", "schlan\u00b7ken", "zar\u00b7ten", "Glie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Besah er auf und nieder.", "tokens": ["Be\u00b7sah", "er", "auf", "und", "nie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKVZ", "KON", "PTKVZ", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Ihr Alter er gar bald", "tokens": ["Ihr", "Al\u00b7ter", "er", "gar", "bald"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "PPER", "ADV", "ADV"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Recht kunstverst\u00e4ndig sch\u00e4zte,", "tokens": ["Recht", "kunst\u00b7ver\u00b7st\u00e4n\u00b7dig", "sch\u00e4z\u00b7te", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Und es auf Sechzehn sezte.", "tokens": ["Und", "es", "auf", "Sech\u00b7zehn", "sez\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "APPR", "CARD", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.19": {"line.1": {"text": "Zum Blumenlesen war", "tokens": ["Zum", "Blu\u00b7men\u00b7le\u00b7sen", "war"], "token_info": ["word", "word", "word"], "pos": ["APPRART", "NN", "VAFIN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Ihr R\u00f6kchen aufgehoben.", "tokens": ["Ihr", "R\u00f6k\u00b7chen", "auf\u00b7ge\u00b7ho\u00b7ben", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Das Perspectiv von oben", "tokens": ["Das", "Per\u00b7spec\u00b7tiv", "von", "o\u00b7ben"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "ADV"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Sah alles auf ein Haar.", "tokens": ["Sah", "al\u00b7les", "auf", "ein", "Haar", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "APPR", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Die F\u00fcschen, Knie, und Waden", "tokens": ["Die", "F\u00fc\u00b7schen", ",", "Knie", ",", "und", "Wa\u00b7den"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word"], "pos": ["ART", "NN", "$,", "NN", "$,", "KON", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Behagten Seiner Gnaden.", "tokens": ["Be\u00b7hag\u00b7ten", "Sei\u00b7ner", "Gna\u00b7den", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.20": {"line.1": {"text": "Sein Herzenshammer schlug.", "tokens": ["Sein", "Her\u00b7zens\u00b7ham\u00b7mer", "schlug", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Bald wolt\u2019 er mehr gewinnen.", "tokens": ["Bald", "wolt'", "er", "mehr", "ge\u00b7win\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Da hub er an zu sinnen,", "tokens": ["Da", "hub", "er", "an", "zu", "sin\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PTKVZ", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Auf arge List und Trug.", "tokens": ["Auf", "ar\u00b7ge", "List", "und", "Trug", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "KON", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Ihn d\u00fcnkt, sie zu erschnappen,", "tokens": ["Ihn", "d\u00fcnkt", ",", "sie", "zu", "er\u00b7schnap\u00b7pen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Sey\u2019s Noth, sich zu verkappen.", "tokens": ["Sey's", "Noth", ",", "sich", "zu", "ver\u00b7kap\u00b7pen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "PRF", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.21": {"line.1": {"text": "Er kl\u00fcgelt\u2019 und erfand,", "tokens": ["Er", "kl\u00fc\u00b7gelt'", "und", "er\u00b7fand", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Nach schlauem Spintisiren,", "tokens": ["Nach", "schlau\u00b7em", "Spin\u00b7ti\u00b7si\u00b7ren", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Als Stier sich zu maskiren:", "tokens": ["Als", "Stier", "sich", "zu", "mas\u00b7ki\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "PRF", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Doch ist mir unbekant,", "tokens": ["Doch", "ist", "mir", "un\u00b7be\u00b7kant", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Wie dieses zugegangen?", "tokens": ["Wie", "die\u00b7ses", "zu\u00b7ge\u00b7gan\u00b7gen", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["PWAV", "PDS", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Und wie er\u2019s angefangen?", "tokens": ["Und", "wie", "er's", "an\u00b7ge\u00b7fan\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PIS", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.22": {"line.1": {"text": "Ich mag um Schlaf und Ruh", "tokens": ["Ich", "mag", "um", "Schlaf", "und", "Ruh"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Durch Gr\u00fcbeln mich nicht bringen.", "tokens": ["Durch", "Gr\u00fc\u00b7beln", "mich", "nicht", "brin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PPER", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Allein von rechten Dingen", "tokens": ["Al\u00b7lein", "von", "rech\u00b7ten", "Din\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "APPR", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Ging solches Spiel nicht zu.", "tokens": ["Ging", "sol\u00b7ches", "Spiel", "nicht", "zu", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "NN", "PTKNEG", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Es half ihm, sonder Zweifel,", "tokens": ["Es", "half", "ihm", ",", "son\u00b7der", "Zwei\u00b7fel", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$,", "KON", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Gott sey bei uns! \u2020 \u2020 \u2020 der Teufel.", "tokens": ["Gott", "sey", "bei", "uns", "!", "\u2020", "\u2020", "\u2020", "der", "Teu\u00b7fel", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "APPR", "PPER", "$.", "XY", "XY", "XY", "ART", "NN", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.23": {"line.1": {"text": "Kurz um, er k\u00f6mt als Stier,", "tokens": ["Kurz", "um", ",", "er", "k\u00f6mt", "als", "Stier", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "PTKVZ", "$,", "PPER", "VVFIN", "KOUS", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Und grast auf dem Gefilde,", "tokens": ["Und", "grast", "auf", "dem", "Ge\u00b7fil\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Als f\u00fchrt\u2019 er nichts im Schilde,", "tokens": ["Als", "f\u00fchrt'", "er", "nichts", "im", "Schil\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VVFIN", "PPER", "PIS", "APPRART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Erst ziemlich weit von ihr,", "tokens": ["Erst", "ziem\u00b7lich", "weit", "von", "ihr", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADJD", "APPR", "PPER", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Und scheint den Frauenzimmern", "tokens": ["Und", "scheint", "den", "Frau\u00b7en\u00b7zim\u00b7mern"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Sich schlecht um sie zu k\u00fcmmern.", "tokens": ["Sich", "schlecht", "um", "sie", "zu", "k\u00fcm\u00b7mern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADJD", "APPR", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.24": {"line.1": {"text": "Alm\u00e4hlich hub er an,", "tokens": ["Al\u00b7m\u00e4h\u00b7lich", "hub", "er", "an", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Sich n\u00e4her an zu drehen.", "tokens": ["Sich", "n\u00e4\u00b7her", "an", "zu", "dre\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADJD", "PTKVZ", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Doch noch blieb sie nicht stehen.", "tokens": ["Doch", "noch", "blieb", "sie", "nicht", "ste\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "PTKNEG", "VVINF", "$."], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Der Krep wuchs ihr bergan.", "tokens": ["Der", "Krep", "wuchs", "ihr", "ber\u00b7gan", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Auch ward ihr in die L\u00e4nge", "tokens": ["Auch", "ward", "ihr", "in", "die", "L\u00e4n\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Die Schn\u00fcrbrust m\u00e4chtig enge.", "tokens": ["Die", "Schn\u00fcr\u00b7brust", "m\u00e4ch\u00b7tig", "en\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "ADJA", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.25": {"line.1": {"text": "Doch h\u00f6rt nur! Mein Monsieur", "tokens": ["Doch", "h\u00f6rt", "nur", "!", "Mein", "Mon\u00b7si\u00b7eur"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "$.", "PPOSAT", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Verstand die fintenvolle", "tokens": ["Ver\u00b7stand", "die", "fin\u00b7ten\u00b7vol\u00b7le"], "token_info": ["word", "word", "word"], "pos": ["NN", "ART", "ADJA"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Vorherstudirte Rolle,", "tokens": ["Vor\u00b7her\u00b7stu\u00b7dir\u00b7te", "Rol\u00b7le", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Wie ich mein A b c.", "tokens": ["Wie", "ich", "mein", "A", "b", "c."], "token_info": ["word", "word", "word", "word", "word", "abbreviation"], "pos": ["PWAV", "PPER", "PPOSAT", "XY", "XY", "XY"], "meter": "-+-+-", "measure": "iambic.di"}, "line.5": {"text": "War er Akt\u00f6r, ich wette,", "tokens": ["War", "er", "Ak\u00b7t\u00f6r", ",", "ich", "wet\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "NN", "$,", "PPER", "VVFIN", "$,"], "meter": "+-++-+-", "measure": "unknown.measure.tetra"}, "line.6": {"text": "Da\u00df man geklatschet h\u00e4tte.", "tokens": ["Da\u00df", "man", "ge\u00b7klat\u00b7schet", "h\u00e4t\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.26": {"line.1": {"text": "Er hatte Theorie", "tokens": ["Er", "hat\u00b7te", "The\u00b7o\u00b7rie"], "token_info": ["word", "word", "word"], "pos": ["PPER", "VAFIN", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Mit Praxis wol verbunden.", "tokens": ["Mit", "Pra\u00b7xis", "wol", "ver\u00b7bun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "In seinen Nebenstunden", "tokens": ["In", "sei\u00b7nen", "Ne\u00b7bens\u00b7tun\u00b7den"], "token_info": ["word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Verabs\u00e4umt\u2019 er fast nie,", "tokens": ["Ver\u00b7ab\u00b7s\u00e4umt'", "er", "fast", "nie", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Nasonis Buch zu treiben,", "tokens": ["Na\u00b7so\u00b7nis", "Buch", "zu", "trei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Und Noten beizuschreiben.", "tokens": ["Und", "No\u00b7ten", "bei\u00b7zu\u00b7schrei\u00b7ben", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.27": {"line.1": {"text": "Drum that der arge Stier", "tokens": ["Drum", "that", "der", "ar\u00b7ge", "Stier"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Sehr zahm und sehr geduldig,", "tokens": ["Sehr", "zahm", "und", "sehr", "ge\u00b7dul\u00b7dig", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KON", "ADV", "ADJD", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Schien keiner T\u00fccke schuldig,", "tokens": ["Schien", "kei\u00b7ner", "T\u00fc\u00b7cke", "schul\u00b7dig", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "NN", "ADJD", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und suchte mit Manier,", "tokens": ["Und", "such\u00b7te", "mit", "Ma\u00b7nier", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Durch Kopfhang sich und Schweigen", "tokens": ["Durch", "Kopf\u00b7hang", "sich", "und", "Schwei\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "PRF", "KON", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Empfindsam gar zu zeigen.", "tokens": ["Emp\u00b7find\u00b7sam", "gar", "zu", "zei\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.28": {"line.1": {"text": "Das M\u00e4gdlein, durch den Schein", "tokens": ["Das", "M\u00e4gd\u00b7lein", ",", "durch", "den", "Schein"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "$,", "APPR", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Von Sitsamkeit betrogen,", "tokens": ["Von", "Sit\u00b7sam\u00b7keit", "be\u00b7tro\u00b7gen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Ward endlich ihm gewogen.", "tokens": ["Ward", "end\u00b7lich", "ihm", "ge\u00b7wo\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PPER", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "\u201esolt\u2019 er wol kurrig seyn?", "tokens": ["\u201e", "solt'", "er", "wol", "kur\u00b7rig", "seyn", "?"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VMFIN", "PPER", "ADV", "ADJD", "VAINF", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.5": {"text": "Sprach sie zu ihrer Amme,", "tokens": ["Sprach", "sie", "zu", "ih\u00b7rer", "Am\u00b7me", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "\u201eer gleicht ja einem Lamme!\u201e", "tokens": ["\u201e", "er", "gleicht", "ja", "ei\u00b7nem", "Lam\u00b7me", "!", "\u201e"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPER", "VVFIN", "ADV", "ART", "NN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.29": {"line.1": {"text": "Die alte Strunsel rief:", "tokens": ["Die", "al\u00b7te", "Strun\u00b7sel", "rief", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "\u201eei! welche sch\u00f6ne Frage!", "tokens": ["\u201e", "ei", "!", "wel\u00b7che", "sch\u00f6\u00b7ne", "Fra\u00b7ge", "!"], "token_info": ["punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ITJ", "$.", "PWAT", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Nach alter teutscher Sage,", "tokens": ["Nach", "al\u00b7ter", "teut\u00b7scher", "Sa\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Sind stille Wasser tief.", "tokens": ["Sind", "stil\u00b7le", "Was\u00b7ser", "tief", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJA", "NN", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Drum, ", "tokens": ["Drum", ","], "token_info": ["word", "punct"], "pos": ["PAV", "$,"], "meter": "-", "measure": "single.down"}, "line.6": {"text": "Dem b\u00f6sen Stier vom Leibe!\u201e \u2014", "tokens": ["Dem", "b\u00f6\u00b7sen", "Stier", "vom", "Lei\u00b7be", "!", "\u201e"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "APPRART", "NN", "$.", "$(", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.30": {"line.1": {"text": "\u201eich m\u00f6chte, fiel sie ein,", "tokens": ["\u201e", "ich", "m\u00f6ch\u00b7te", ",", "fiel", "sie", "ein", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VMFIN", "$,", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Ihm wol ein Kr\u00e4nzel binden,", "tokens": ["Ihm", "wol", "ein", "Kr\u00e4n\u00b7zel", "bin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und um die H\u00f6rner winden.", "tokens": ["Und", "um", "die", "H\u00f6r\u00b7ner", "win\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Er wird schon artig seyn,", "tokens": ["Er", "wird", "schon", "ar\u00b7tig", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "VAINF", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Wenn ich h\u00fcbsch traulich rabb\u2019le", "tokens": ["Wenn", "ich", "h\u00fcbsch", "trau\u00b7lich", "rab\u00b7b'\u00b7le"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADJD", "ADJD", "VVFIN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Und hinter\u2019m Ohr ihm krabb\u2019le.\u201e \u2014", "tokens": ["Und", "hin\u00b7ter'm", "Ohr", "ihm", "krab\u00b7b'\u00b7le", ".", "\u201e"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["KON", "APPRART", "NN", "PPER", "VVFIN", "$.", "$(", "$("], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.31": {"line.1": {"text": "Fort, Kind! da k\u00f6mt er! Ah!\u201e \u201e \u201e", "tokens": ["Fort", ",", "Kind", "!", "da", "k\u00f6mt", "er", "!", "Ah", "!", "\u201e", "\u201e", "\u201e"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "punct", "punct", "punct", "punct"], "pos": ["NE", "$,", "NN", "$.", "ADV", "VVFIN", "PPER", "$.", "NN", "$.", "$(", "$(", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Doch er lies sacht die Glieder", "tokens": ["Doch", "er", "lies", "sacht", "die", "Glie\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "ADJD", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Ins weiche Gr\u00e4schen nieder,", "tokens": ["Ins", "wei\u00b7che", "Gr\u00e4sc\u00b7hen", "nie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Lag wiederk\u00e4uend da.", "tokens": ["Lag", "wie\u00b7der\u00b7k\u00e4u\u00b7end", "da", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "VVPP", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Sein Auge, dum und ehrlich,", "tokens": ["Sein", "Au\u00b7ge", ",", "dum", "und", "ehr\u00b7lich", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "NE", "KON", "ADJD", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Schien g\u00e4nzlich nicht gef\u00e4rlich.", "tokens": ["Schien", "g\u00e4nz\u00b7lich", "nicht", "ge\u00b7f\u00e4r\u00b7lich", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "PTKNEG", "ADJD", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.32": {"line.1": {"text": "Da ward das M\u00e4gdlein k\u00fchn,", "tokens": ["Da", "ward", "das", "M\u00e4gd\u00b7lein", "k\u00fchn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Und trieb mit ihm viel Possen,", "tokens": ["Und", "trieb", "mit", "ihm", "viel", "Pos\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PPER", "PIAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "(das lit er unverdrossen)", "tokens": ["(", "das", "lit", "er", "un\u00b7ver\u00b7dros\u00b7sen", ")"], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PDS", "VVFIN", "PPER", "ADJD", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und ach! und stieg auf ihn.", "tokens": ["Und", "ach", "!", "und", "stieg", "auf", "ihn", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "XY", "$.", "KON", "VVFIN", "APPR", "PPER", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "\u201ehi! Hi! Ich wil\u2019s doch wagen,", "tokens": ["\u201e", "hi", "!", "Hi", "!", "Ich", "wil's", "doch", "wa\u00b7gen", ","], "token_info": ["punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ITJ", "$.", "NE", "$.", "PPER", "VMFIN", "ADV", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Ob mich das Thier wil tragen?\u201e", "tokens": ["Ob", "mich", "das", "Thier", "wil", "tra\u00b7gen", "?", "\u201e"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VMFIN", "VVINF", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.33": {"line.1": {"text": "Doch der verkapte Gast", "tokens": ["Doch", "der", "ver\u00b7kap\u00b7te", "Gast"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Empfand auf seinem R\u00fccken,", "tokens": ["Emp\u00b7fand", "auf", "sei\u00b7nem", "R\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Mit krabbelndem Entz\u00fccken,", "tokens": ["Mit", "krab\u00b7beln\u00b7dem", "Ent\u00b7z\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Kaum seine sch\u00f6ne Last,", "tokens": ["Kaum", "sei\u00b7ne", "sch\u00f6\u00b7ne", "Last", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "So sprang er auf und rente,", "tokens": ["So", "sprang", "er", "auf", "und", "ren\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PTKVZ", "KON", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Als ob der Kopf ihm brente.", "tokens": ["Als", "ob", "der", "Kopf", "ihm", "bren\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "ART", "NN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.34": {"line.1": {"text": "Und lief, in vollem Trab,", "tokens": ["Und", "lief", ",", "in", "vol\u00b7lem", "Trab", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Queerfeldein, schnurgerade,", "tokens": ["Que\u00b7er\u00b7fel\u00b7dein", ",", "schnur\u00b7ge\u00b7ra\u00b7de", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Zum n\u00e4chsten Meergestade,", "tokens": ["Zum", "n\u00e4chs\u00b7ten", "Meer\u00b7ge\u00b7sta\u00b7de", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und hui! that er hinab,", "tokens": ["Und", "hui", "!", "that", "er", "hin\u00b7ab", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "NE", "$.", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Kein Weilchen zu verlieren,", "tokens": ["Kein", "Weil\u00b7chen", "zu", "ver\u00b7lie\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Den Sprung mit allen Vieren.", "tokens": ["Den", "Sprung", "mit", "al\u00b7len", "Vie\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.35": {"line.1": {"text": "\u201each! schrien die Zofen, ach!", "tokens": ["\u201e", "ach", "!", "schri\u00b7en", "die", "Zo\u00b7fen", ",", "ach", "!"], "token_info": ["punct", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["$(", "ITJ", "$.", "VVFIN", "ART", "NN", "$,", "ITJ", "$."], "meter": "+---+-+", "measure": "dactylic.init"}, "line.2": {"text": "(die an das Ufer sprangen", "tokens": ["(", "die", "an", "das", "U\u00b7fer", "spran\u00b7gen"], "token_info": ["punct", "word", "word", "word", "word", "word"], "pos": ["$(", "ART", "APPR", "ART", "NN", "VVFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und ihre H\u00e4nde rangen)", "tokens": ["Und", "ih\u00b7re", "H\u00e4n\u00b7de", "ran\u00b7gen", ")"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Ach! Ach! Prinzessin, ach!", "tokens": ["Ach", "!", "Ach", "!", "Prin\u00b7zes\u00b7sin", ",", "ach", "!"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ITJ", "$.", "ITJ", "$.", "NN", "$,", "ITJ", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.5": {"text": "Was f\u00fcr ein Streich, Ihr Gnaden!", "tokens": ["Was", "f\u00fcr", "ein", "Streich", ",", "Ihr", "Gna\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "APPR", "ART", "NN", "$,", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Nun han wir\u2019s auszubaden.", "tokens": ["Nun", "han", "wir's", "aus\u00b7zu\u00b7ba\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIS", "VVIZU", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.36": {"line.1": {"text": "Allein das arme Kind", "tokens": ["Al\u00b7lein", "das", "ar\u00b7me", "Kind"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Hub, zappelnd mit den Beinen,", "tokens": ["Hub", ",", "zap\u00b7pelnd", "mit", "den", "Bei\u00b7nen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ADJD", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Erb\u00e4rmlich an zu weinen:", "tokens": ["Er\u00b7b\u00e4rm\u00b7lich", "an", "zu", "wei\u00b7nen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "PTKVZ", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "\u201each! helft mir! helft geschwind!", "tokens": ["\u201e", "ach", "!", "helft", "mir", "!", "helft", "ge\u00b7schwind", "!"], "token_info": ["punct", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "ITJ", "$.", "VVFIN", "PPER", "$.", "VVFIN", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Doch unser Schalk vor Freude", "tokens": ["Doch", "un\u00b7ser", "Schalk", "vor", "Freu\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "APPR", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "War taub zu ihrem Leide.", "tokens": ["War", "taub", "zu", "ih\u00b7rem", "Lei\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.37": {"line.1": {"text": "Nichts half ihr Ach und Weh.", "tokens": ["Nichts", "half", "ihr", "Ach", "und", "Weh", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPOSAT", "NN", "KON", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Sie muste f\u00fcrbas reiten.", "tokens": ["Sie", "mus\u00b7te", "f\u00fcr\u00b7bas", "rei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Da gaft\u2019 auf beiden Seiten,", "tokens": ["Da", "gaft'", "auf", "bei\u00b7den", "Sei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Janhagel aus der See,", "tokens": ["Jan\u00b7ha\u00b7gel", "aus", "der", "See", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Und hub, ganz ausgelassen,", "tokens": ["Und", "hub", ",", "ganz", "aus\u00b7ge\u00b7las\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "ADV", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Hier\u00fcber an zu spassen.", "tokens": ["Hier\u00b7\u00fc\u00b7ber", "an", "zu", "spas\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PAV", "APZR", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.38": {"line.1": {"text": "Der Stier sprach nicht ein Wort,", "tokens": ["Der", "Stier", "sprach", "nicht", "ein", "Wort", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKNEG", "ART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Und trug sie sonder Gnade", "tokens": ["Und", "trug", "sie", "son\u00b7der", "Gna\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "PIAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Hin\u00fcber ans Gestade,", "tokens": ["Hin\u00b7\u00fc\u00b7ber", "ans", "Ge\u00b7sta\u00b7de", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und kam in sichern Port.", "tokens": ["Und", "kam", "in", "si\u00b7chern", "Port", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ADJA", "NE", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Darob empfand der Heide", "tokens": ["Da\u00b7rob", "emp\u00b7fand", "der", "Hei\u00b7de"], "token_info": ["word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Herzinnigliche Freude.", "tokens": ["Her\u00b7zin\u00b7nig\u00b7li\u00b7che", "Freu\u00b7de", "."], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}}, "stanza.39": {"line.1": {"text": "Hier sank sie auf den Sand,", "tokens": ["Hier", "sank", "sie", "auf", "den", "Sand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Ganz mat durch langes Reiten", "tokens": ["Ganz", "mat", "durch", "lan\u00b7ges", "Rei\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "APPR", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und Herzensbangigkeiten,", "tokens": ["Und", "Her\u00b7zens\u00b7ban\u00b7gig\u00b7kei\u00b7ten", ","], "token_info": ["word", "word", "punct"], "pos": ["KON", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Von Sinnen und Verstand.", "tokens": ["Von", "Sin\u00b7nen", "und", "Ver\u00b7stand", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Vielleicht hat\u2019s auch darneben", "tokens": ["Viel\u00b7leicht", "hat's", "auch", "dar\u00b7ne\u00b7ben"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ADV", "PAV"], "meter": "-+--+--", "measure": "iambic.di.relaxed"}, "line.6": {"text": "Ein W\u00f6lfchen abgegeben.", "tokens": ["Ein", "W\u00f6lf\u00b7chen", "ab\u00b7ge\u00b7ge\u00b7ben", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.40": {"line.1": {"text": "Mein Stier nahm frisch und froh", "tokens": ["Mein", "Stier", "nahm", "frisch", "und", "froh"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VVFIN", "ADJD", "KON", "ADJD"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Dies Tempo wahr, und spielte,", "tokens": ["Dies", "Tem\u00b7po", "wahr", ",", "und", "spiel\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PDS", "NN", "PTKVZ", "$,", "KON", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Als sie nicht sah und f\u00fchlte,", "tokens": ["Als", "sie", "nicht", "sah", "und", "f\u00fchl\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Ein neues ", "tokens": ["Ein", "neu\u00b7es"], "token_info": ["word", "word"], "pos": ["ART", "ADJA"], "meter": "-+-", "measure": "amphibrach.single"}, "line.5": {"text": "Denn er verstand den ", "tokens": ["Denn", "er", "ver\u00b7stand", "den"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "ART"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.6": {"text": "Mit ", "tokens": ["Mit"], "token_info": ["word"], "pos": ["APPR"], "meter": "-", "measure": "single.down"}}, "stanza.41": {"line.1": {"text": "Und trat als Kavalier,", "tokens": ["Und", "trat", "als", "Ka\u00b7va\u00b7lier", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "KOUS", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "In hochfrisirten Haaren,", "tokens": ["In", "hoch\u00b7fri\u00b7sir\u00b7ten", "Haa\u00b7ren", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Wie damals Mode waren,", "tokens": ["Wie", "da\u00b7mals", "Mo\u00b7de", "wa\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "NN", "VAFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Mit dem Flakon zu ihr,", "tokens": ["Mit", "dem", "Fla\u00b7kon", "zu", "ihr", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "PPER", "$,"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.5": {"text": "Und hub, um Brust und H\u00fcften,", "tokens": ["Und", "hub", ",", "um", "Brust", "und", "H\u00fcf\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "KOUI", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Die Schn\u00fcrbrust an zu l\u00fcften.", "tokens": ["Die", "Schn\u00fcr\u00b7brust", "an", "zu", "l\u00fcf\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.42": {"line.1": {"text": "Kaum war sie aufgeschn\u00fcrt,", "tokens": ["Kaum", "war", "sie", "auf\u00b7ge\u00b7schn\u00fcrt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Kaum kizelt\u2019 ihre Nase", "tokens": ["Kaum", "ki\u00b7zelt'", "ih\u00b7re", "Na\u00b7se"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Der Duft aus seinem Glase,", "tokens": ["Der", "Duft", "aus", "sei\u00b7nem", "Gla\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "So war sie auch kurirt;", "tokens": ["So", "war", "sie", "auch", "ku\u00b7rirt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Drauf er, wie sich\u2019s geb\u00fcrte,", "tokens": ["Drauf", "er", ",", "wie", "sich's", "ge\u00b7b\u00fcr\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PAV", "PPER", "$,", "PWAV", "PIS", "VVFIN", "$,"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.6": {"text": "Comme &#231;a mit ihr charmirte:             ", "tokens": ["Com\u00b7me", "&#231;", "a", "mit", "ihr", "charm\u00b7ir\u00b7te", ":"], "token_info": ["word", "XML_entity", "word", "word", "word", "word", "punct"], "pos": ["FM", "FM", "FM", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+---+-", "measure": "unknown.measure.tri"}}, "stanza.43": {"line.1": {"text": "\u201ewilkommen hier ins Gr\u00fcn!", "tokens": ["\u201e", "wil\u00b7kom\u00b7men", "hier", "ins", "Gr\u00fcn", "!"], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Per dio! das bejah' ich,               ", "tokens": ["Per", "dio", "!", "das", "be\u00b7jah'", "ich", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$.", "PDS", "VVFIN", "PPER", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Mein blaues Wunder sah ich!", "tokens": ["Mein", "blau\u00b7es", "Wun\u00b7der", "sah", "ich", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVFIN", "PPER", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Woher, mein Kind, wohin?", "tokens": ["Wo\u00b7her", ",", "mein", "Kind", ",", "wo\u00b7hin", "?"], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["PWAV", "$,", "PPOSAT", "NN", "$,", "PWAV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "So weit durch\u2019s Meer zu reiten!", "tokens": ["So", "weit", "durch's", "Meer", "zu", "rei\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "APPRART", "NN", "PTKZU", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Und doch nicht abzugleiten? \u2014", "tokens": ["Und", "doch", "nicht", "ab\u00b7zu\u00b7glei\u00b7ten", "?"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ADV", "PTKNEG", "VVIZU", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.44": {"line.1": {"text": "Indessen freut mich\u2019s, hier", "tokens": ["In\u00b7des\u00b7sen", "freut", "mich's", ",", "hier"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["ADV", "VVFIN", "PIS", "$,", "ADV"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "In meinem schlechten Garten,", "tokens": ["In", "mei\u00b7nem", "schlech\u00b7ten", "Gar\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Gehorsamst aufzuwarten.", "tokens": ["Ge\u00b7hor\u00b7samst", "auf\u00b7zu\u00b7war\u00b7ten", "."], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVIZU", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Ma foi! das ahnte mir,               ", "tokens": ["Ma", "foi", "!", "das", "ahn\u00b7te", "mir", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$.", "PDS", "VVFIN", "PPER", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Heut hatt\u2019 ich so ein Tr\u00e4umchen \u201e \u201e \u201e", "tokens": ["Heut", "hatt'", "ich", "so", "ein", "Tr\u00e4um\u00b7chen", "\u201e", "\u201e", "\u201e"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ART", "NN", "$(", "$(", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Auch jukte mir das D\u00e4umchen.", "tokens": ["Auch", "juk\u00b7te", "mir", "das", "D\u00e4um\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.45": {"line.1": {"text": "Man zog ihr wakres Thier,", "tokens": ["Man", "zog", "ihr", "wak\u00b7res", "Thier", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Worauf sie hergeritten,", "tokens": ["Wo\u00b7rauf", "sie", "her\u00b7ge\u00b7rit\u00b7ten", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PAV", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Nachdem sie abgeschritten,", "tokens": ["Nach\u00b7dem", "sie", "ab\u00b7ge\u00b7schrit\u00b7ten", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Gleich in den Stal von hier.", "tokens": ["Gleich", "in", "den", "Stal", "von", "hier", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "APPR", "ADV", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.5": {"text": "Da sol es, nach Verlangen,", "tokens": ["Da", "sol", "es", ",", "nach", "Ver\u00b7lan\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "$,", "APPR", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Sein Futter schon empfangen.", "tokens": ["Sein", "Fut\u00b7ter", "schon", "emp\u00b7fan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.46": {"line.1": {"text": "Sie werden, Herzchen, gelt?", "tokens": ["Sie", "wer\u00b7den", ",", "Herz\u00b7chen", ",", "gelt", "?"], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "NN", "$,", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Wol noch ein wenig frieren?", "tokens": ["Wol", "noch", "ein", "we\u00b7nig", "frie\u00b7ren", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "PIS", "VVINF", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.3": {"text": "Geruhn sie zu spazieren", "tokens": ["Ge\u00b7ruhn", "sie", "zu", "spa\u00b7zie\u00b7ren"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "PPER", "PTKZU", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "In dieses Lustgezelt,", "tokens": ["In", "die\u00b7ses", "Lust\u00b7ge\u00b7zelt", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Und thun in meiner Klause,", "tokens": ["Und", "thun", "in", "mei\u00b7ner", "Klau\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Als w\u00e4ren sie zu Hause.", "tokens": ["Als", "w\u00e4\u00b7ren", "sie", "zu", "Hau\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VAFIN", "PPER", "APPR", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.47": {"line.1": {"text": "Hier pflegen sie der Ruh,", "tokens": ["Hier", "pfle\u00b7gen", "sie", "der", "Ruh", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Und troknen sich, mein Schnekchen,", "tokens": ["Und", "trok\u00b7nen", "sich", ",", "mein", "Schnek\u00b7chen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "$,", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Ihr Hemde, samt dem R\u00f6kchen,", "tokens": ["Ihr", "Hem\u00b7de", ",", "samt", "dem", "R\u00f6k\u00b7chen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Die Str\u00fcmpfchen und die Schuh.", "tokens": ["Die", "Str\u00fcmpf\u00b7chen", "und", "die", "Schuh", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Ich, mit Permi\u00df, wil ihnen", "tokens": ["Ich", ",", "mit", "Per\u00b7mi\u00df", ",", "wil", "ih\u00b7nen"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word"], "pos": ["PPER", "$,", "APPR", "NN", "$,", "VMFIN", "PPER"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.6": {"text": "Stat Kammerm\u00e4dchens dienen. \u2014", "tokens": ["Stat", "Kam\u00b7mer\u00b7m\u00e4d\u00b7chens", "die\u00b7nen", "."], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["NN", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.48": {"line.1": {"text": "Sie str\u00e4ubte j\u00fcngferlich", "tokens": ["Sie", "str\u00e4ub\u00b7te", "j\u00fcng\u00b7fer\u00b7lich"], "token_info": ["word", "word", "word"], "pos": ["PPER", "VVFIN", "ADJD"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Sich anfangs zwar ein wenig:", "tokens": ["Sich", "an\u00b7fangs", "zwar", "ein", "we\u00b7nig", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADV", "ADV", "ART", "PIS", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Doch er bat unterth\u00e4nig,", "tokens": ["Doch", "er", "bat", "un\u00b7ter\u00b7th\u00e4\u00b7nig", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ADJD", "$,"], "meter": "--++-+-", "measure": "anapaest.init"}, "line.4": {"text": "Und da ergab sie sich.", "tokens": ["Und", "da", "er\u00b7gab", "sie", "sich", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "PRF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Nun, hochgeehrte G\u00e4ste,", "tokens": ["Nun", ",", "hoch\u00b7geehr\u00b7te", "G\u00e4s\u00b7te", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["ADV", "$,", "ADJA", "NN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.6": {"text": "Merkt auf! Nun k\u00f6mt das Beste.", "tokens": ["Merkt", "auf", "!", "Nun", "k\u00f6mt", "das", "Bes\u00b7te", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PTKVZ", "$.", "ADV", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.49": {"line.1": {"text": "Hem! \u201e \u201e \u201e Ha! Ich merke wol", "tokens": ["Hem", "!", "\u201e", "\u201e", "\u201e", "Ha", "!", "Ich", "mer\u00b7ke", "wol"], "token_info": ["word", "punct", "punct", "punct", "punct", "word", "punct", "word", "word", "word"], "pos": ["NE", "$.", "$(", "$(", "$(", "ITJ", "$.", "PPER", "VVFIN", "ADV"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "An euren wehrten Nasen,", "tokens": ["An", "eu\u00b7ren", "wehr\u00b7ten", "Na\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Da\u00df ich mit h\u00fcbschen Phrasen", "tokens": ["Da\u00df", "ich", "mit", "h\u00fcb\u00b7schen", "Phra\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Eur Ohr nun kizeln sol.", "tokens": ["Eur", "Ohr", "nun", "ki\u00b7zeln", "sol", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADV", "VVINF", "VMFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Ihr m\u00f6chtet, um den Bazen,", "tokens": ["Ihr", "m\u00f6ch\u00b7tet", ",", "um", "den", "Ba\u00b7zen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "$,", "KOUI", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "F\u00fcr Lachen gern zerplazen.", "tokens": ["F\u00fcr", "La\u00b7chen", "gern", "zer\u00b7pla\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.50": {"line.1": {"text": "Doch, theure G\u00f6nner, seht,", "tokens": ["Doch", ",", "theu\u00b7re", "G\u00f6n\u00b7ner", ",", "seht", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["KON", "$,", "ADJA", "NN", "$,", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Was ich dabei riskire!", "tokens": ["Was", "ich", "da\u00b7bei", "ris\u00b7ki\u00b7re", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "PAV", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Wenn\u2019s der Pastor erf\u00fchre,", "tokens": ["Wenn's", "der", "Pas\u00b7tor", "er\u00b7f\u00fch\u00b7re", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Der keinen Spas versteht,", "tokens": ["Der", "kei\u00b7nen", "Spas", "ver\u00b7steht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Dann wehe meiner Ehre! \u2014", "tokens": ["Dann", "we\u00b7he", "mei\u00b7ner", "Eh\u00b7re", "!"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "ADJD", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Ich kenne die Past\u00f6re! \u2014", "tokens": ["Ich", "ken\u00b7ne", "die", "Pas\u00b7t\u00f6\u00b7re", "!"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.51": {"line.1": {"text": "Drum weg mit Sch\u00e4kerei\u2019n!", "tokens": ["Drum", "weg", "mit", "Sch\u00e4\u00b7ke\u00b7rei'n", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PAV", "ADV", "APPR", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Von s\u00fcskandirten Zoten", "tokens": ["Von", "s\u00fcs\u00b7kan\u00b7dir\u00b7ten", "Zo\u00b7ten"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Wird vollends nichts geboten.", "tokens": ["Wird", "vol\u00b7lends", "nichts", "ge\u00b7bo\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PIS", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Hilarius h\u00e4lt fein", "tokens": ["Hi\u00b7la\u00b7rius", "h\u00e4lt", "fein"], "token_info": ["word", "word", "word"], "pos": ["NE", "VVFIN", "ADJD"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.5": {"text": "Auf Ehrbarkeit und ", "tokens": ["Auf", "Ehr\u00b7bar\u00b7keit", "und"], "token_info": ["word", "word", "word"], "pos": ["APPR", "NN", "KON"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.6": {"text": "Ihr Herren ", "tokens": ["Ihr", "Her\u00b7ren"], "token_info": ["word", "word"], "pos": ["PPOSAT", "NN"], "meter": "-+-", "measure": "amphibrach.single"}}, "stanza.52": {"line.1": {"text": "In Z\u00fcchten, wie sich\u2019s ziemt,", "tokens": ["In", "Z\u00fcch\u00b7ten", ",", "wie", "sich's", "ziemt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "PWAV", "PIS", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Weil mich vor langem Breie", "tokens": ["Weil", "mich", "vor", "lan\u00b7gem", "Brei\u00b7e"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "In solchen Schosen scheue,", "tokens": ["In", "sol\u00b7chen", "Scho\u00b7sen", "scheu\u00b7e", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Meld\u2019 ich nur kurz verbl\u00fcmt:", "tokens": ["Meld'", "ich", "nur", "kurz", "ver\u00b7bl\u00fcmt", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Hier that mit seiner Sch\u00f6ne", "tokens": ["Hier", "that", "mit", "sei\u00b7ner", "Sch\u00f6\u00b7ne"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Der Herr sich treflich ", "tokens": ["Der", "Herr", "sich", "tref\u00b7lich"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "PRF", "ADJD"], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.53": {"line.1": {"text": "Nun schwammen mit Geschrei,", "tokens": ["Nun", "schwam\u00b7men", "mit", "Ge\u00b7schrei", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "In langen gr\u00fcnen Haaren,", "tokens": ["In", "lan\u00b7gen", "gr\u00fc\u00b7nen", "Haa\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Der Wassernixen Schaaren", "tokens": ["Der", "Was\u00b7ser\u00b7ni\u00b7xen", "Schaa\u00b7ren"], "token_info": ["word", "word", "word"], "pos": ["ART", "NN", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Hart an den Strand herbei:", "tokens": ["Hart", "an", "den", "Strand", "her\u00b7bei", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Zu sehen das Spektakel,", "tokens": ["Zu", "se\u00b7hen", "das", "Spek\u00b7ta\u00b7kel", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "ART", "NN", "$,"], "meter": "-+--+--", "measure": "iambic.di.relaxed"}, "line.6": {"text": "In diesem Tabernakel.", "tokens": ["In", "die\u00b7sem", "Ta\u00b7ber\u00b7na\u00b7kel", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.54": {"line.1": {"text": "Manch Nixchen wurde rot;", "tokens": ["Manch", "Nix\u00b7chen", "wur\u00b7de", "rot", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Manch Nixchen wurde l\u00fcstern;", "tokens": ["Manch", "Nix\u00b7chen", "wur\u00b7de", "l\u00fcs\u00b7tern", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "ADJD", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Jen\u2019s neigte sich zum Fl\u00fcstern;", "tokens": ["Jen's", "neig\u00b7te", "sich", "zum", "Fl\u00fcs\u00b7tern", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PRF", "APPRART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Dies lachte sich halb todt;", "tokens": ["Dies", "lach\u00b7te", "sich", "halb", "todt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PRF", "ADJD", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Neptun, gelehnt ans Ruder,", "tokens": ["Nep\u00b7tun", ",", "ge\u00b7lehnt", "ans", "Ru\u00b7der", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVPP", "APPRART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Rief: Prosit, lieber Bruder!", "tokens": ["Rief", ":", "Pro\u00b7sit", ",", "lie\u00b7ber", "Bru\u00b7der", "!"], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$.", "NN", "$,", "ADV", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.55": {"line.1": {"text": "Nun dank, o frommer Christ,", "tokens": ["Nun", "dank", ",", "o", "from\u00b7mer", "Christ", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "FM", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Im Namen aller Weiber,", "tokens": ["Im", "Na\u00b7men", "al\u00b7ler", "Wei\u00b7ber", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PIAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Da\u00df dieser Heid\u2019 und R\u00e4uber", "tokens": ["Da\u00df", "die\u00b7ser", "Heid'", "und", "R\u00e4u\u00b7ber"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PDAT", "NN", "KON", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Bereits gestorben ist.", "tokens": ["Be\u00b7reits", "ge\u00b7stor\u00b7ben", "ist", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "VVPP", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Zwar \u201e \u201e \u201e fehlt\u2019s auch zum Verf\u00fchren", "tokens": ["Zwar", "\u201e", "\u201e", "\u201e", "fehlt's", "auch", "zum", "Ver\u00b7f\u00fch\u00b7ren"], "token_info": ["word", "punct", "punct", "punct", "word", "word", "word", "word"], "pos": ["ADV", "$(", "$(", "$(", "VVFIN", "ADV", "APPRART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Nicht an getauften Stieren.", "tokens": ["Nicht", "an", "ge\u00b7tauf\u00b7ten", "Stie\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}}}}