{"textgrid.poem.53484": {"metadata": {"author": {"name": "Tucholsky, Kurt", "birth": "N.A.", "death": "N.A."}, "title": "Memento", "genre": "verse", "period": "N.A.", "pub_year": 1912, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Uns Junge hat es umgerissen \u2013", "tokens": ["Uns", "Jun\u00b7ge", "hat", "es", "um\u00b7ge\u00b7ris\u00b7sen", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "VAFIN", "PPER", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "wir stehen drau\u00dfen so im Feld,", "tokens": ["wir", "ste\u00b7hen", "drau\u00b7\u00dfen", "so", "im", "Feld", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "wir glaubten schon, zu halten und zu wissen \u2013", "tokens": ["wir", "glaub\u00b7ten", "schon", ",", "zu", "hal\u00b7ten", "und", "zu", "wis\u00b7sen", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "PTKZU", "VVINF", "KON", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "und da versank die ganze Welt.", "tokens": ["und", "da", "ver\u00b7sank", "die", "gan\u00b7ze", "Welt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "\u00bbdie Welt ist falsch!\u00ab Sie ist doch kein Exempel,", "tokens": ["\u00bb", "die", "Welt", "ist", "falsch", "!", "\u00ab", "Sie", "ist", "doch", "kein", "Ex\u00b7em\u00b7pel", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "VAFIN", "ADJD", "$.", "$(", "PPER", "VAFIN", "ADV", "PIAT", "NN", "$,"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "wozu der Lehrer seine L\u00f6sung hat \u2013", "tokens": ["wo\u00b7zu", "der", "Leh\u00b7rer", "sei\u00b7ne", "L\u00f6\u00b7sung", "hat", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "PPOSAT", "NN", "VAFIN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "sie ist real und warf uns alle Tempel", "tokens": ["sie", "ist", "re\u00b7al", "und", "warf", "uns", "al\u00b7le", "Tem\u00b7pel"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADJD", "KON", "VVFIN", "PPER", "PIAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "und, was wir lieb gehabt, um \u2013 wie ein Kartenblatt.", "tokens": ["und", ",", "was", "wir", "lieb", "ge\u00b7habt", ",", "um", "\u2013", "wie", "ein", "Kar\u00b7ten\u00b7blatt", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "$,", "PRELS", "PPER", "ADJD", "VAPP", "$,", "KOUI", "$(", "KOKOM", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Ihr mahnt den J\u00fcngling, tapfer durchzuhalten.", "tokens": ["Ihr", "mahnt", "den", "J\u00fcng\u00b7ling", ",", "tap\u00b7fer", "durch\u00b7zu\u00b7hal\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Gewi\u00df, das scheint ja seine Pflicht \u2013", "tokens": ["Ge\u00b7wi\u00df", ",", "das", "scheint", "ja", "sei\u00b7ne", "Pflicht", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PDS", "VVFIN", "ADV", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "doch was da in ihm war vom guten, alten,", "tokens": ["doch", "was", "da", "in", "ihm", "war", "vom", "gu\u00b7ten", ",", "al\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "PWS", "ADV", "APPR", "PPER", "VAFIN", "APPRART", "ADJA", "$,", "ADJA", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "das gibts in Zukunft alles nicht?", "tokens": ["das", "gibts", "in", "Zu\u00b7kunft", "al\u00b7les", "nicht", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPR", "NN", "PIS", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Der neue Wert, die neue Stufenleiter,", "tokens": ["Der", "neu\u00b7e", "Wert", ",", "die", "neu\u00b7e", "Stu\u00b7fen\u00b7lei\u00b7ter", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "der oben und der unten \u2013 seltsam Spiel:", "tokens": ["der", "o\u00b7ben", "und", "der", "un\u00b7ten", "\u2013", "selt\u00b7sam", "Spiel", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADV", "KON", "ART", "ADV", "$(", "ADJD", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Hier gilt die Faust, der S\u00e4bel und der Reiter \u2013", "tokens": ["Hier", "gilt", "die", "Faust", ",", "der", "S\u00e4\u00b7bel", "und", "der", "Rei\u00b7ter", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$,", "ART", "NN", "KON", "ART", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "das was wir ehren, gilt nicht viel.", "tokens": ["das", "was", "wir", "eh\u00b7ren", ",", "gilt", "nicht", "viel", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "PRELS", "PPER", "VVINF", "$,", "VVFIN", "PTKNEG", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Mu\u00df das so sein? So darfs nicht bis zur Neige,", "tokens": ["Mu\u00df", "das", "so", "sein", "?", "So", "darfs", "nicht", "bis", "zur", "Nei\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PDS", "ADV", "VAINF", "$.", "ADV", "VMFIN", "PTKNEG", "ADV", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "nicht bis zum Ende gehn. Wir bleiben rein.", "tokens": ["nicht", "bis", "zum", "En\u00b7de", "gehn", ".", "Wir", "blei\u00b7ben", "rein", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "APPRART", "NN", "VVINF", "$.", "PPER", "VVFIN", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Wir halten durch \u2013 es scheint mir gar nicht feige:", "tokens": ["Wir", "hal\u00b7ten", "durch", "\u2013", "es", "scheint", "mir", "gar", "nicht", "fei\u00b7ge", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "$(", "PPER", "VVFIN", "PPER", "ADV", "PTKNEG", "ADJD", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Soldat und doch ein B\u00fcrger sein!", "tokens": ["Sol\u00b7dat", "und", "doch", "ein", "B\u00fcr\u00b7ger", "sein", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "ADV", "ART", "NN", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Sprecht euerm Jungen von der Kriegertugend,", "tokens": ["Sprecht", "eu\u00b7erm", "Jun\u00b7gen", "von", "der", "Krie\u00b7ger\u00b7tu\u00b7gend", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "doch davon auch, wenn hart der Panzer klirrt:", "tokens": ["doch", "da\u00b7von", "auch", ",", "wenn", "hart", "der", "Pan\u00b7zer", "klirrt", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PAV", "ADV", "$,", "KOUS", "ADJD", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Da\u00df er den Tr\u00e4umen seiner Jugend", "tokens": ["Da\u00df", "er", "den", "Tr\u00e4u\u00b7men", "sei\u00b7ner", "Ju\u00b7gend"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "NN", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "soll Achtung tragen, wenn er Mann sein wird!", "tokens": ["soll", "Ach\u00b7tung", "tra\u00b7gen", ",", "wenn", "er", "Mann", "sein", "wird", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "NN", "VVINF", "$,", "KOUS", "PPER", "NN", "VAINF", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.7": {"line.1": {"text": "Uns Junge hat es umgerissen \u2013", "tokens": ["Uns", "Jun\u00b7ge", "hat", "es", "um\u00b7ge\u00b7ris\u00b7sen", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "VAFIN", "PPER", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "wir stehen drau\u00dfen so im Feld,", "tokens": ["wir", "ste\u00b7hen", "drau\u00b7\u00dfen", "so", "im", "Feld", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "wir glaubten schon, zu halten und zu wissen \u2013", "tokens": ["wir", "glaub\u00b7ten", "schon", ",", "zu", "hal\u00b7ten", "und", "zu", "wis\u00b7sen", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "PTKZU", "VVINF", "KON", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "und da versank die ganze Welt.", "tokens": ["und", "da", "ver\u00b7sank", "die", "gan\u00b7ze", "Welt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "\u00bbdie Welt ist falsch!\u00ab Sie ist doch kein Exempel,", "tokens": ["\u00bb", "die", "Welt", "ist", "falsch", "!", "\u00ab", "Sie", "ist", "doch", "kein", "Ex\u00b7em\u00b7pel", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "VAFIN", "ADJD", "$.", "$(", "PPER", "VAFIN", "ADV", "PIAT", "NN", "$,"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "wozu der Lehrer seine L\u00f6sung hat \u2013", "tokens": ["wo\u00b7zu", "der", "Leh\u00b7rer", "sei\u00b7ne", "L\u00f6\u00b7sung", "hat", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "PPOSAT", "NN", "VAFIN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "sie ist real und warf uns alle Tempel", "tokens": ["sie", "ist", "re\u00b7al", "und", "warf", "uns", "al\u00b7le", "Tem\u00b7pel"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADJD", "KON", "VVFIN", "PPER", "PIAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "und, was wir lieb gehabt, um \u2013 wie ein Kartenblatt.", "tokens": ["und", ",", "was", "wir", "lieb", "ge\u00b7habt", ",", "um", "\u2013", "wie", "ein", "Kar\u00b7ten\u00b7blatt", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "$,", "PRELS", "PPER", "ADJD", "VAPP", "$,", "KOUI", "$(", "KOKOM", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Ihr mahnt den J\u00fcngling, tapfer durchzuhalten.", "tokens": ["Ihr", "mahnt", "den", "J\u00fcng\u00b7ling", ",", "tap\u00b7fer", "durch\u00b7zu\u00b7hal\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Gewi\u00df, das scheint ja seine Pflicht \u2013", "tokens": ["Ge\u00b7wi\u00df", ",", "das", "scheint", "ja", "sei\u00b7ne", "Pflicht", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PDS", "VVFIN", "ADV", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "doch was da in ihm war vom guten, alten,", "tokens": ["doch", "was", "da", "in", "ihm", "war", "vom", "gu\u00b7ten", ",", "al\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "PWS", "ADV", "APPR", "PPER", "VAFIN", "APPRART", "ADJA", "$,", "ADJA", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "das gibts in Zukunft alles nicht?", "tokens": ["das", "gibts", "in", "Zu\u00b7kunft", "al\u00b7les", "nicht", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPR", "NN", "PIS", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Der neue Wert, die neue Stufenleiter,", "tokens": ["Der", "neu\u00b7e", "Wert", ",", "die", "neu\u00b7e", "Stu\u00b7fen\u00b7lei\u00b7ter", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "der oben und der unten \u2013 seltsam Spiel:", "tokens": ["der", "o\u00b7ben", "und", "der", "un\u00b7ten", "\u2013", "selt\u00b7sam", "Spiel", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADV", "KON", "ART", "ADV", "$(", "ADJD", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Hier gilt die Faust, der S\u00e4bel und der Reiter \u2013", "tokens": ["Hier", "gilt", "die", "Faust", ",", "der", "S\u00e4\u00b7bel", "und", "der", "Rei\u00b7ter", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$,", "ART", "NN", "KON", "ART", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "das was wir ehren, gilt nicht viel.", "tokens": ["das", "was", "wir", "eh\u00b7ren", ",", "gilt", "nicht", "viel", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "PRELS", "PPER", "VVINF", "$,", "VVFIN", "PTKNEG", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Mu\u00df das so sein? So darfs nicht bis zur Neige,", "tokens": ["Mu\u00df", "das", "so", "sein", "?", "So", "darfs", "nicht", "bis", "zur", "Nei\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PDS", "ADV", "VAINF", "$.", "ADV", "VMFIN", "PTKNEG", "ADV", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "nicht bis zum Ende gehn. Wir bleiben rein.", "tokens": ["nicht", "bis", "zum", "En\u00b7de", "gehn", ".", "Wir", "blei\u00b7ben", "rein", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "APPRART", "NN", "VVINF", "$.", "PPER", "VVFIN", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Wir halten durch \u2013 es scheint mir gar nicht feige:", "tokens": ["Wir", "hal\u00b7ten", "durch", "\u2013", "es", "scheint", "mir", "gar", "nicht", "fei\u00b7ge", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "$(", "PPER", "VVFIN", "PPER", "ADV", "PTKNEG", "ADJD", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Soldat und doch ein B\u00fcrger sein!", "tokens": ["Sol\u00b7dat", "und", "doch", "ein", "B\u00fcr\u00b7ger", "sein", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "ADV", "ART", "NN", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Sprecht euerm Jungen von der Kriegertugend,", "tokens": ["Sprecht", "eu\u00b7erm", "Jun\u00b7gen", "von", "der", "Krie\u00b7ger\u00b7tu\u00b7gend", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "doch davon auch, wenn hart der Panzer klirrt:", "tokens": ["doch", "da\u00b7von", "auch", ",", "wenn", "hart", "der", "Pan\u00b7zer", "klirrt", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PAV", "ADV", "$,", "KOUS", "ADJD", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Da\u00df er den Tr\u00e4umen seiner Jugend", "tokens": ["Da\u00df", "er", "den", "Tr\u00e4u\u00b7men", "sei\u00b7ner", "Ju\u00b7gend"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "NN", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "soll Achtung tragen, wenn er Mann sein wird!", "tokens": ["soll", "Ach\u00b7tung", "tra\u00b7gen", ",", "wenn", "er", "Mann", "sein", "wird", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "NN", "VVINF", "$,", "KOUS", "PPER", "NN", "VAINF", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}}}}