{"textgrid.poem.26403": {"metadata": {"author": {"name": "Dauthendey, Max", "birth": "N.A.", "death": "N.A."}, "title": "1L: Sch\u00f6n und nicht nur obenhin", "genre": "verse", "period": "N.A.", "pub_year": 1892, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Sch\u00f6n und nicht nur obenhin", "tokens": ["Sch\u00f6n", "und", "nicht", "nur", "o\u00b7ben\u00b7hin"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "KON", "PTKNEG", "ADV", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Schien dem Paul die Metzgerin.", "tokens": ["Schien", "dem", "Paul", "die", "Metz\u00b7ge\u00b7rin", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NE", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "War er auch der Lehrling nur,", "tokens": ["War", "er", "auch", "der", "Lehr\u00b7ling", "nur", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ART", "NN", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Trug er doch schon Schnurrbartspur.", "tokens": ["Trug", "er", "doch", "schon", "Schnurr\u00b7bart\u00b7spur", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "An der blut'gen Schl\u00e4chterbank", "tokens": ["An", "der", "blut'\u00b7gen", "Schl\u00e4ch\u00b7ter\u00b7bank"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Machten ihn zwei Augen krank.", "tokens": ["Mach\u00b7ten", "ihn", "zwei", "Au\u00b7gen", "krank", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "CARD", "NN", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Schlug er K\u00e4lber ins Genick,", "tokens": ["Schlug", "er", "K\u00e4l\u00b7ber", "ins", "Ge\u00b7nick", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "APPRART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Leicht trug er den Todesblick.", "tokens": ["Leicht", "trug", "er", "den", "To\u00b7des\u00b7blick", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.3": {"line.1": {"text": "Doch das Aug' der Metzgerfrau", "tokens": ["Doch", "das", "Aug'", "der", "Metz\u00b7ger\u00b7frau"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Machte ihm den Blick voll Tau.", "tokens": ["Mach\u00b7te", "ihm", "den", "Blick", "voll", "Tau", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "ADJD", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und der Schleifstein fiel ihm hin,", "tokens": ["Und", "der", "Schleifs\u00b7tein", "fiel", "ihm", "hin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.4": {"text": "Dran ers Messer sollt' abziehn.", "tokens": ["Dran", "ers", "Mes\u00b7ser", "sollt'", "ab\u00b7ziehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ADJA", "NN", "VMFIN", "VVIZU", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}}, "stanza.4": {"line.1": {"text": "Eingeweid' kroch um ihn her,", "tokens": ["Ein\u00b7ge\u00b7weid'", "kroch", "um", "ihn", "her", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPER", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Kalb und Schwein verwechselt er.", "tokens": ["Kalb", "und", "Schwein", "ver\u00b7wech\u00b7selt", "er", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "NN", "VVFIN", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Sieht die Metzgerin ihn an,", "tokens": ["Sieht", "die", "Metz\u00b7ge\u00b7rin", "ihn", "an", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "PPER", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Unser Paul gleich sterben kann.", "tokens": ["Un\u00b7ser", "Paul", "gleich", "ster\u00b7ben", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADV", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Und mal, mittags war's, im Laden", "tokens": ["Und", "mal", ",", "mit\u00b7tags", "wa\u00b7r's", ",", "im", "La\u00b7den"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["KON", "ADV", "$,", "ADV", "VAFIN", "$,", "APPRART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Seine Lehrlingskameraden", "tokens": ["Sei\u00b7ne", "Lehr\u00b7lings\u00b7ka\u00b7me\u00b7ra\u00b7den"], "token_info": ["word", "word"], "pos": ["PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Neckten ihn: er w\u00e4r' wie Teig,", "tokens": ["Neck\u00b7ten", "ihn", ":", "er", "w\u00e4r'", "wie", "Teig", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$.", "PPER", "VAFIN", "KOKOM", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und vielleicht im Grunde feig.", "tokens": ["Und", "viel\u00b7leicht", "im", "Grun\u00b7de", "feig", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPRART", "NN", "ADJD", "$."], "meter": "--+-+-+", "measure": "anapaest.init"}}, "stanza.6": {"line.1": {"text": "Und der Paul, er mu\u00dft' erblassen:", "tokens": ["Und", "der", "Paul", ",", "er", "mu\u00dft'", "er\u00b7blas\u00b7sen", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NE", "$,", "PPER", "VMFIN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "\u00bbwollt Ihr einen Spa\u00df schnell sehn?\u00ab", "tokens": ["\u00bb", "wollt", "Ihr", "ei\u00b7nen", "Spa\u00df", "schnell", "sehn", "?", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VMFIN", "PPER", "ART", "NN", "ADJD", "VVINF", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Rief er, tat das Messer drehn.", "tokens": ["Rief", "er", ",", "tat", "das", "Mes\u00b7ser", "drehn", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "VVFIN", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Stie\u00df sich's bis ans Heft ins Herze", "tokens": ["Stie\u00df", "sich's", "bis", "ans", "Heft", "ins", "Her\u00b7ze"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PIS", "ADV", "APPRART", "NN", "APPRART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und fiel um, bleich wie 'ne Kerze.", "tokens": ["Und", "fiel", "um", ",", "bleich", "wie", "'ne", "Ker\u00b7ze", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKVZ", "$,", "ADJD", "KOKOM", "ART", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Denn er wu\u00dfte schrecklich gut,", "tokens": ["Denn", "er", "wu\u00df\u00b7te", "schreck\u00b7lich", "gut", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ADJD", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Nur der Tod beweist den Mut.", "tokens": ["Nur", "der", "Tod", "be\u00b7weist", "den", "Mut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Was half's, da\u00df die Metzgerin", "tokens": ["Was", "ha\u00b7lf's", ",", "da\u00df", "die", "Metz\u00b7ge\u00b7rin"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PWS", "VVFIN", "$,", "KOUS", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Tausend Schreie schreit um ihn!", "tokens": ["Tau\u00b7send", "Schrei\u00b7e", "schreit", "um", "ihn", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "VVFIN", "APPR", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Nichts mehr seine Leiche r\u00fchrte,", "tokens": ["Nichts", "mehr", "sei\u00b7ne", "Lei\u00b7che", "r\u00fchr\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "ADV", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wenn er's noch so gern auch sp\u00fcrte.", "tokens": ["Wenn", "er's", "noch", "so", "gern", "auch", "sp\u00fcr\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ADV", "ADV", "ADV", "ADV", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Sch\u00f6n und nicht nur obenhin", "tokens": ["Sch\u00f6n", "und", "nicht", "nur", "o\u00b7ben\u00b7hin"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "KON", "PTKNEG", "ADV", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Schien dem Paul die Metzgerin.", "tokens": ["Schien", "dem", "Paul", "die", "Metz\u00b7ge\u00b7rin", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NE", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "War er auch der Lehrling nur,", "tokens": ["War", "er", "auch", "der", "Lehr\u00b7ling", "nur", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ART", "NN", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Trug er doch schon Schnurrbartspur.", "tokens": ["Trug", "er", "doch", "schon", "Schnurr\u00b7bart\u00b7spur", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "An der blut'gen Schl\u00e4chterbank", "tokens": ["An", "der", "blut'\u00b7gen", "Schl\u00e4ch\u00b7ter\u00b7bank"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Machten ihn zwei Augen krank.", "tokens": ["Mach\u00b7ten", "ihn", "zwei", "Au\u00b7gen", "krank", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "CARD", "NN", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Schlug er K\u00e4lber ins Genick,", "tokens": ["Schlug", "er", "K\u00e4l\u00b7ber", "ins", "Ge\u00b7nick", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "APPRART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Leicht trug er den Todesblick.", "tokens": ["Leicht", "trug", "er", "den", "To\u00b7des\u00b7blick", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.11": {"line.1": {"text": "Doch das Aug' der Metzgerfrau", "tokens": ["Doch", "das", "Aug'", "der", "Metz\u00b7ger\u00b7frau"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Machte ihm den Blick voll Tau.", "tokens": ["Mach\u00b7te", "ihm", "den", "Blick", "voll", "Tau", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "ADJD", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und der Schleifstein fiel ihm hin,", "tokens": ["Und", "der", "Schleifs\u00b7tein", "fiel", "ihm", "hin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.4": {"text": "Dran ers Messer sollt' abziehn.", "tokens": ["Dran", "ers", "Mes\u00b7ser", "sollt'", "ab\u00b7ziehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ADJA", "NN", "VMFIN", "VVIZU", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}}, "stanza.12": {"line.1": {"text": "Eingeweid' kroch um ihn her,", "tokens": ["Ein\u00b7ge\u00b7weid'", "kroch", "um", "ihn", "her", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPER", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Kalb und Schwein verwechselt er.", "tokens": ["Kalb", "und", "Schwein", "ver\u00b7wech\u00b7selt", "er", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "NN", "VVFIN", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Sieht die Metzgerin ihn an,", "tokens": ["Sieht", "die", "Metz\u00b7ge\u00b7rin", "ihn", "an", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "PPER", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Unser Paul gleich sterben kann.", "tokens": ["Un\u00b7ser", "Paul", "gleich", "ster\u00b7ben", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADV", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Und mal, mittags war's, im Laden", "tokens": ["Und", "mal", ",", "mit\u00b7tags", "wa\u00b7r's", ",", "im", "La\u00b7den"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["KON", "ADV", "$,", "ADV", "VAFIN", "$,", "APPRART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Seine Lehrlingskameraden", "tokens": ["Sei\u00b7ne", "Lehr\u00b7lings\u00b7ka\u00b7me\u00b7ra\u00b7den"], "token_info": ["word", "word"], "pos": ["PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Neckten ihn: er w\u00e4r' wie Teig,", "tokens": ["Neck\u00b7ten", "ihn", ":", "er", "w\u00e4r'", "wie", "Teig", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$.", "PPER", "VAFIN", "KOKOM", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und vielleicht im Grunde feig.", "tokens": ["Und", "viel\u00b7leicht", "im", "Grun\u00b7de", "feig", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPRART", "NN", "ADJD", "$."], "meter": "--+-+-+", "measure": "anapaest.init"}}, "stanza.14": {"line.1": {"text": "Und der Paul, er mu\u00dft' erblassen:", "tokens": ["Und", "der", "Paul", ",", "er", "mu\u00dft'", "er\u00b7blas\u00b7sen", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NE", "$,", "PPER", "VMFIN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "\u00bbwollt Ihr einen Spa\u00df schnell sehn?\u00ab", "tokens": ["\u00bb", "wollt", "Ihr", "ei\u00b7nen", "Spa\u00df", "schnell", "sehn", "?", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VMFIN", "PPER", "ART", "NN", "ADJD", "VVINF", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Rief er, tat das Messer drehn.", "tokens": ["Rief", "er", ",", "tat", "das", "Mes\u00b7ser", "drehn", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "VVFIN", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.15": {"line.1": {"text": "Stie\u00df sich's bis ans Heft ins Herze", "tokens": ["Stie\u00df", "sich's", "bis", "ans", "Heft", "ins", "Her\u00b7ze"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PIS", "ADV", "APPRART", "NN", "APPRART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und fiel um, bleich wie 'ne Kerze.", "tokens": ["Und", "fiel", "um", ",", "bleich", "wie", "'ne", "Ker\u00b7ze", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKVZ", "$,", "ADJD", "KOKOM", "ART", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Denn er wu\u00dfte schrecklich gut,", "tokens": ["Denn", "er", "wu\u00df\u00b7te", "schreck\u00b7lich", "gut", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ADJD", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Nur der Tod beweist den Mut.", "tokens": ["Nur", "der", "Tod", "be\u00b7weist", "den", "Mut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.16": {"line.1": {"text": "Was half's, da\u00df die Metzgerin", "tokens": ["Was", "ha\u00b7lf's", ",", "da\u00df", "die", "Metz\u00b7ge\u00b7rin"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PWS", "VVFIN", "$,", "KOUS", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Tausend Schreie schreit um ihn!", "tokens": ["Tau\u00b7send", "Schrei\u00b7e", "schreit", "um", "ihn", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "VVFIN", "APPR", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Nichts mehr seine Leiche r\u00fchrte,", "tokens": ["Nichts", "mehr", "sei\u00b7ne", "Lei\u00b7che", "r\u00fchr\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "ADV", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wenn er's noch so gern auch sp\u00fcrte.", "tokens": ["Wenn", "er's", "noch", "so", "gern", "auch", "sp\u00fcr\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ADV", "ADV", "ADV", "ADV", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}}}}