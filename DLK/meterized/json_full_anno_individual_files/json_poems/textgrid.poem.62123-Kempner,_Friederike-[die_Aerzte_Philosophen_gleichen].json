{"textgrid.poem.62123": {"metadata": {"author": {"name": "Kempner, Friederike", "birth": "N.A.", "death": "N.A."}, "title": "[die Aerzte Philosophen gleichen]", "genre": "verse", "period": "N.A.", "pub_year": 1868, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Die Aerzte Philosophen gleichen \u2013", "tokens": ["Die", "A\u00b7erz\u00b7te", "Phi\u00b7lo\u00b7so\u00b7phen", "glei\u00b7chen", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "$("], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Der gro\u00dfe staunt und betet an,", "tokens": ["Der", "gro\u00b7\u00dfe", "staunt", "und", "be\u00b7tet", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "KON", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der kleine sieht in Gottes Reichen", "tokens": ["Der", "klei\u00b7ne", "sieht", "in", "Got\u00b7tes", "Rei\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "VVFIN", "APPR", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Sich selbst als gr\u00f6\u00dftes Wunder an. \u2013", "tokens": ["Sich", "selbst", "als", "gr\u00f6\u00df\u00b7tes", "Wun\u00b7der", "an", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PRF", "ADV", "KOUS", "ADJA", "NN", "PTKVZ", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Beschr\u00e4nktheit absolut diktieret!", "tokens": ["Be\u00b7schr\u00e4nk\u00b7theit", "ab\u00b7so\u00b7lut", "dik\u00b7tie\u00b7ret", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die Weisheit bleibt ihr fremd und fern \u2013", "tokens": ["Die", "Weis\u00b7heit", "bleibt", "ihr", "fremd", "und", "fern", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADJD", "KON", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wen nie der Genius ber\u00fchret,", "tokens": ["Wen", "nie", "der", "Ge\u00b7nius", "be\u00b7r\u00fch\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Ein solches M\u00e4nnchen t\u00e4uscht sich gern.", "tokens": ["Ein", "sol\u00b7ches", "M\u00e4nn\u00b7chen", "t\u00e4uscht", "sich", "gern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VVFIN", "PRF", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Wer niemand \u00fcber sich zum Richter,", "tokens": ["Wer", "nie\u00b7mand", "\u00fc\u00b7ber", "sich", "zum", "Rich\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PIS", "APPR", "PRF", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wer niemals sagt: ich wei\u00df es nicht, \u2013", "tokens": ["Wer", "nie\u00b7mals", "sagt", ":", "ich", "wei\u00df", "es", "nicht", ",", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWS", "ADV", "VVFIN", "$.", "PPER", "VVFIN", "PPER", "PTKNEG", "$,", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der taugt zu keinem h\u00f6h'ren Richter", "tokens": ["Der", "taugt", "zu", "kei\u00b7nem", "h\u00f6h'\u00b7ren", "Rich\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "APPR", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Mit seinem unfehlbaren Licht.", "tokens": ["Mit", "sei\u00b7nem", "un\u00b7fehl\u00b7ba\u00b7ren", "Licht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Die Aerzte Philosophen gleichen \u2013", "tokens": ["Die", "A\u00b7erz\u00b7te", "Phi\u00b7lo\u00b7so\u00b7phen", "glei\u00b7chen", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "$("], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Der gro\u00dfe staunt und betet an,", "tokens": ["Der", "gro\u00b7\u00dfe", "staunt", "und", "be\u00b7tet", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "KON", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der kleine sieht in Gottes Reichen", "tokens": ["Der", "klei\u00b7ne", "sieht", "in", "Got\u00b7tes", "Rei\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "VVFIN", "APPR", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Sich selbst als gr\u00f6\u00dftes Wunder an. \u2013", "tokens": ["Sich", "selbst", "als", "gr\u00f6\u00df\u00b7tes", "Wun\u00b7der", "an", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PRF", "ADV", "KOUS", "ADJA", "NN", "PTKVZ", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Beschr\u00e4nktheit absolut diktieret!", "tokens": ["Be\u00b7schr\u00e4nk\u00b7theit", "ab\u00b7so\u00b7lut", "dik\u00b7tie\u00b7ret", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die Weisheit bleibt ihr fremd und fern \u2013", "tokens": ["Die", "Weis\u00b7heit", "bleibt", "ihr", "fremd", "und", "fern", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADJD", "KON", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wen nie der Genius ber\u00fchret,", "tokens": ["Wen", "nie", "der", "Ge\u00b7nius", "be\u00b7r\u00fch\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Ein solches M\u00e4nnchen t\u00e4uscht sich gern.", "tokens": ["Ein", "sol\u00b7ches", "M\u00e4nn\u00b7chen", "t\u00e4uscht", "sich", "gern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VVFIN", "PRF", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Wer niemand \u00fcber sich zum Richter,", "tokens": ["Wer", "nie\u00b7mand", "\u00fc\u00b7ber", "sich", "zum", "Rich\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PIS", "APPR", "PRF", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wer niemals sagt: ich wei\u00df es nicht, \u2013", "tokens": ["Wer", "nie\u00b7mals", "sagt", ":", "ich", "wei\u00df", "es", "nicht", ",", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWS", "ADV", "VVFIN", "$.", "PPER", "VVFIN", "PPER", "PTKNEG", "$,", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der taugt zu keinem h\u00f6h'ren Richter", "tokens": ["Der", "taugt", "zu", "kei\u00b7nem", "h\u00f6h'\u00b7ren", "Rich\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "APPR", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Mit seinem unfehlbaren Licht.", "tokens": ["Mit", "sei\u00b7nem", "un\u00b7fehl\u00b7ba\u00b7ren", "Licht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}