{"textgrid.poem.53692": {"metadata": {"author": {"name": "Tucholsky, Kurt", "birth": "N.A.", "death": "N.A."}, "title": "Die deutsche Laute", "genre": "verse", "period": "N.A.", "pub_year": 1912, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Als wenn ich fr\u00fch und sp\u00e4t, nachdem es etwa kam,", "tokens": ["Als", "wenn", "ich", "fr\u00fch", "und", "sp\u00e4t", ",", "nach\u00b7dem", "es", "et\u00b7wa", "kam", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "PPER", "ADJD", "KON", "ADJD", "$,", "KOUS", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "in deiner Gegenwart die deutsche Laute nahm . . .", "tokens": ["in", "dei\u00b7ner", "Ge\u00b7gen\u00b7wart", "die", "deut\u00b7sche", "Lau\u00b7te", "nahm", ".", ".", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ART", "ADJA", "NN", "VVFIN", "$.", "$.", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Man lauert, sitzt und sinnt, ver\u00e4ndert, schreibt, durchstreicht,", "tokens": ["Man", "lau\u00b7ert", ",", "sitzt", "und", "sinnt", ",", "ver\u00b7\u00e4n\u00b7dert", ",", "schreibt", ",", "durch\u00b7streicht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PIS", "VVFIN", "$,", "VVFIN", "KON", "VVFIN", "$,", "VVPP", "$,", "VVFIN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "schmei\u00dft Silb und Reim herum, versetzt, verwirft, vergleicht,", "tokens": ["schmei\u00dft", "Silb", "und", "Reim", "he\u00b7rum", ",", "ver\u00b7setzt", ",", "ver\u00b7wirft", ",", "ver\u00b7gleicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["VVFIN", "NE", "KON", "NN", "PTKVZ", "$,", "VVPP", "$,", "VVFIN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "eh W\u00f6rter und Begriff so wahr als zierlich passen", "tokens": ["eh", "W\u00f6r\u00b7ter", "und", "Be\u00b7griff", "so", "wahr", "als", "zier\u00b7lich", "pas\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "NN", "KON", "NN", "ADV", "ADJD", "KOKOM", "ADJD", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "und in des Lesers Ohr ein gr\u00fcndlich Etwas lassen.", "tokens": ["und", "in", "des", "Le\u00b7sers", "Ohr", "ein", "gr\u00fcnd\u00b7lich", "Et\u00b7was", "las\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "NN", "ART", "ADJD", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Doch wenn es unser Flei\u00df auch noch so sch\u00f6n gemeint", "tokens": ["Doch", "wenn", "es", "un\u00b7ser", "Flei\u00df", "auch", "noch", "so", "sch\u00f6n", "ge\u00b7meint"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "PPOSAT", "NN", "ADV", "ADV", "ADV", "ADJD", "VVPP"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "und nachmals vor der Welt mit Sorg und Furcht erscheint,", "tokens": ["und", "nach\u00b7mals", "vor", "der", "Welt", "mit", "Sorg", "und", "Furcht", "er\u00b7scheint", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "ART", "NN", "APPR", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "so wird es oft so kahl und obenhin gelesen,", "tokens": ["so", "wird", "es", "oft", "so", "kahl", "und", "o\u00b7ben\u00b7hin", "ge\u00b7le\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ADV", "ADJD", "KON", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "als w\u00e4r es ein Gebet von Habermann gewesen.", "tokens": ["als", "w\u00e4r", "es", "ein", "Ge\u00b7bet", "von", "Ha\u00b7ber\u00b7mann", "ge\u00b7we\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOKOM", "VAFIN", "PPER", "ART", "NN", "APPR", "NN", "VAPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Schweig du doch nur, du H\u00e4lfte meiner Brust!", "tokens": ["Schweig", "du", "doch", "nur", ",", "du", "H\u00e4lf\u00b7te", "mei\u00b7ner", "Brust", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "$,", "PPER", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Denn was du weinst, ist Blut aus meinem Herzen.", "tokens": ["Denn", "was", "du", "weinst", ",", "ist", "Blut", "aus", "mei\u00b7nem", "Her\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "VVFIN", "$,", "VAFIN", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Ich taumle so und hab an nichts mehr Lust", "tokens": ["Ich", "taum\u00b7le", "so", "und", "hab", "an", "nichts", "mehr", "Lust"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "KON", "VAFIN", "APPR", "PIS", "PIAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "als an der Angst und den getreuen Schmerzen,", "tokens": ["als", "an", "der", "Angst", "und", "den", "ge\u00b7treu\u00b7en", "Schmer\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "ART", "NN", "KON", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "womit der Stern, der unsre Liebe trennt, die Augen brennt.", "tokens": ["wo\u00b7mit", "der", "Stern", ",", "der", "uns\u00b7re", "Lie\u00b7be", "trennt", ",", "die", "Au\u00b7gen", "brennt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "$,", "PRELS", "PPOSAT", "NN", "VVFIN", "$,", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}}, "stanza.4": {"line.1": {"text": "Als wenn ich fr\u00fch und sp\u00e4t, nachdem es etwa kam,", "tokens": ["Als", "wenn", "ich", "fr\u00fch", "und", "sp\u00e4t", ",", "nach\u00b7dem", "es", "et\u00b7wa", "kam", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "PPER", "ADJD", "KON", "ADJD", "$,", "KOUS", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "in deiner Gegenwart die deutsche Laute nahm . . .", "tokens": ["in", "dei\u00b7ner", "Ge\u00b7gen\u00b7wart", "die", "deut\u00b7sche", "Lau\u00b7te", "nahm", ".", ".", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ART", "ADJA", "NN", "VVFIN", "$.", "$.", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Man lauert, sitzt und sinnt, ver\u00e4ndert, schreibt, durchstreicht,", "tokens": ["Man", "lau\u00b7ert", ",", "sitzt", "und", "sinnt", ",", "ver\u00b7\u00e4n\u00b7dert", ",", "schreibt", ",", "durch\u00b7streicht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PIS", "VVFIN", "$,", "VVFIN", "KON", "VVFIN", "$,", "VVPP", "$,", "VVFIN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "schmei\u00dft Silb und Reim herum, versetzt, verwirft, vergleicht,", "tokens": ["schmei\u00dft", "Silb", "und", "Reim", "he\u00b7rum", ",", "ver\u00b7setzt", ",", "ver\u00b7wirft", ",", "ver\u00b7gleicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["VVFIN", "NE", "KON", "NN", "PTKVZ", "$,", "VVPP", "$,", "VVFIN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "eh W\u00f6rter und Begriff so wahr als zierlich passen", "tokens": ["eh", "W\u00f6r\u00b7ter", "und", "Be\u00b7griff", "so", "wahr", "als", "zier\u00b7lich", "pas\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "NN", "KON", "NN", "ADV", "ADJD", "KOKOM", "ADJD", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "und in des Lesers Ohr ein gr\u00fcndlich Etwas lassen.", "tokens": ["und", "in", "des", "Le\u00b7sers", "Ohr", "ein", "gr\u00fcnd\u00b7lich", "Et\u00b7was", "las\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "NN", "ART", "ADJD", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Doch wenn es unser Flei\u00df auch noch so sch\u00f6n gemeint", "tokens": ["Doch", "wenn", "es", "un\u00b7ser", "Flei\u00df", "auch", "noch", "so", "sch\u00f6n", "ge\u00b7meint"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "PPOSAT", "NN", "ADV", "ADV", "ADV", "ADJD", "VVPP"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "und nachmals vor der Welt mit Sorg und Furcht erscheint,", "tokens": ["und", "nach\u00b7mals", "vor", "der", "Welt", "mit", "Sorg", "und", "Furcht", "er\u00b7scheint", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "ART", "NN", "APPR", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "so wird es oft so kahl und obenhin gelesen,", "tokens": ["so", "wird", "es", "oft", "so", "kahl", "und", "o\u00b7ben\u00b7hin", "ge\u00b7le\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ADV", "ADJD", "KON", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "als w\u00e4r es ein Gebet von Habermann gewesen.", "tokens": ["als", "w\u00e4r", "es", "ein", "Ge\u00b7bet", "von", "Ha\u00b7ber\u00b7mann", "ge\u00b7we\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOKOM", "VAFIN", "PPER", "ART", "NN", "APPR", "NN", "VAPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Schweig du doch nur, du H\u00e4lfte meiner Brust!", "tokens": ["Schweig", "du", "doch", "nur", ",", "du", "H\u00e4lf\u00b7te", "mei\u00b7ner", "Brust", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "$,", "PPER", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Denn was du weinst, ist Blut aus meinem Herzen.", "tokens": ["Denn", "was", "du", "weinst", ",", "ist", "Blut", "aus", "mei\u00b7nem", "Her\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "VVFIN", "$,", "VAFIN", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Ich taumle so und hab an nichts mehr Lust", "tokens": ["Ich", "taum\u00b7le", "so", "und", "hab", "an", "nichts", "mehr", "Lust"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "KON", "VAFIN", "APPR", "PIS", "PIAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "als an der Angst und den getreuen Schmerzen,", "tokens": ["als", "an", "der", "Angst", "und", "den", "ge\u00b7treu\u00b7en", "Schmer\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "ART", "NN", "KON", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "womit der Stern, der unsre Liebe trennt, die Augen brennt.", "tokens": ["wo\u00b7mit", "der", "Stern", ",", "der", "uns\u00b7re", "Lie\u00b7be", "trennt", ",", "die", "Au\u00b7gen", "brennt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "$,", "PRELS", "PPOSAT", "NN", "VVFIN", "$,", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}}}}}