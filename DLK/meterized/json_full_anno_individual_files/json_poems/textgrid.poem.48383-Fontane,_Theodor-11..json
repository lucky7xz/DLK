{"textgrid.poem.48383": {"metadata": {"author": {"name": "Fontane, Theodor", "birth": "N.A.", "death": "N.A."}, "title": "11.", "genre": "verse", "period": "N.A.", "pub_year": 1860, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Die ihr euch \u00bb", "tokens": ["Die", "ihr", "euch", "\u00bb"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "PPER", "PPER", "$("], "meter": "+-+", "measure": "trochaic.di"}, "line.2": {"text": "Zu eigner und des K\u00f6nigs Ehr',", "tokens": ["Zu", "eig\u00b7ner", "und", "des", "K\u00f6\u00b7nigs", "Ehr'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "KON", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die ihr euch Jakobiten nanntet,", "tokens": ["Die", "ihr", "euch", "Ja\u00b7ko\u00b7bi\u00b7ten", "nann\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PPER", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Zu Thron und Stuart euch bekanntet", "tokens": ["Zu", "Thron", "und", "Stu\u00b7art", "euch", "be\u00b7kann\u00b7tet"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN", "PPER", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Und endlich doch den R\u00fccken wandtet,", "tokens": ["Und", "end\u00b7lich", "doch", "den", "R\u00fc\u00b7cken", "wand\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "O tretet her.", "tokens": ["O", "tre\u00b7tet", "her", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PTKVZ", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.2": {"line.1": {"text": "Was k\u00e4mpft ihr noch voll halben Zwanges", "tokens": ["Was", "k\u00e4mpft", "ihr", "noch", "voll", "hal\u00b7ben", "Zwan\u00b7ges"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "ADJD", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ein leeres Wortgefecht \u00bbums Recht\u00ab?", "tokens": ["Ein", "lee\u00b7res", "Wort\u00b7ge\u00b7fecht", "\u00bb", "ums", "Recht", "\u00ab", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "$(", "APPRART", "NN", "$(", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Entschlagt euch des gelehrten Dranges,", "tokens": ["Ent\u00b7schlagt", "euch", "des", "ge\u00b7lehr\u00b7ten", "Dran\u00b7ges", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ich sag': ein kurz Schwert und ein langes,", "tokens": ["Ich", "sag'", ":", "ein", "kurz", "Schwert", "und", "ein", "lan\u00b7ges", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "ART", "ADJD", "NN", "KON", "ART", "ADJA", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.5": {"text": "Ich sag': ein stark' Herz und ein banges,", "tokens": ["Ich", "sag'", ":", "ein", "stark'", "Herz", "und", "ein", "ban\u00b7ges", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "ART", "ADJA", "NN", "KON", "ART", "ADJA", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.3": {"line.1": {"text": "Was schwankt ihr l\u00e4nger bang und sch\u00fcchtern?", "tokens": ["Was", "schwankt", "ihr", "l\u00e4n\u00b7ger", "bang", "und", "sch\u00fcch\u00b7tern", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ADJD", "ADJD", "KON", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Der ", "tokens": ["Der"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}, "line.3": {"text": "Was schwankt ihr l\u00e4nger bang und sch\u00fcchtern?", "tokens": ["Was", "schwankt", "ihr", "l\u00e4n\u00b7ger", "bang", "und", "sch\u00fcch\u00b7tern", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ADJD", "ADJD", "KON", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "F\u00fcgt euch den neuen Himmelslichtern", "tokens": ["F\u00fcgt", "euch", "den", "neu\u00b7en", "Him\u00b7mels\u00b7lich\u00b7tern"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "NN"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.5": {"text": "Und \u2013 \u00fcberlasset seinen Richtern", "tokens": ["Und", "\u2013", "\u00fc\u00b7ber\u00b7las\u00b7set", "sei\u00b7nen", "Rich\u00b7tern"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["KON", "$(", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Die ihr euch \u00bb", "tokens": ["Die", "ihr", "euch", "\u00bb"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "PPER", "PPER", "$("], "meter": "+-+", "measure": "trochaic.di"}, "line.2": {"text": "Zu eigner und des K\u00f6nigs Ehr',", "tokens": ["Zu", "eig\u00b7ner", "und", "des", "K\u00f6\u00b7nigs", "Ehr'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "KON", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die ihr euch Jakobiten nanntet,", "tokens": ["Die", "ihr", "euch", "Ja\u00b7ko\u00b7bi\u00b7ten", "nann\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PPER", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Zu Thron und Stuart euch bekanntet", "tokens": ["Zu", "Thron", "und", "Stu\u00b7art", "euch", "be\u00b7kann\u00b7tet"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN", "PPER", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Und endlich doch den R\u00fccken wandtet,", "tokens": ["Und", "end\u00b7lich", "doch", "den", "R\u00fc\u00b7cken", "wand\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "O tretet her.", "tokens": ["O", "tre\u00b7tet", "her", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PTKVZ", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.5": {"line.1": {"text": "Was k\u00e4mpft ihr noch voll halben Zwanges", "tokens": ["Was", "k\u00e4mpft", "ihr", "noch", "voll", "hal\u00b7ben", "Zwan\u00b7ges"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "ADJD", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ein leeres Wortgefecht \u00bbums Recht\u00ab?", "tokens": ["Ein", "lee\u00b7res", "Wort\u00b7ge\u00b7fecht", "\u00bb", "ums", "Recht", "\u00ab", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "$(", "APPRART", "NN", "$(", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Entschlagt euch des gelehrten Dranges,", "tokens": ["Ent\u00b7schlagt", "euch", "des", "ge\u00b7lehr\u00b7ten", "Dran\u00b7ges", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ich sag': ein kurz Schwert und ein langes,", "tokens": ["Ich", "sag'", ":", "ein", "kurz", "Schwert", "und", "ein", "lan\u00b7ges", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "ART", "ADJD", "NN", "KON", "ART", "ADJA", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.5": {"text": "Ich sag': ein stark' Herz und ein banges,", "tokens": ["Ich", "sag'", ":", "ein", "stark'", "Herz", "und", "ein", "ban\u00b7ges", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "ART", "ADJA", "NN", "KON", "ART", "ADJA", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.6": {"line.1": {"text": "Was schwankt ihr l\u00e4nger bang und sch\u00fcchtern?", "tokens": ["Was", "schwankt", "ihr", "l\u00e4n\u00b7ger", "bang", "und", "sch\u00fcch\u00b7tern", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ADJD", "ADJD", "KON", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Der ", "tokens": ["Der"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}, "line.3": {"text": "Was schwankt ihr l\u00e4nger bang und sch\u00fcchtern?", "tokens": ["Was", "schwankt", "ihr", "l\u00e4n\u00b7ger", "bang", "und", "sch\u00fcch\u00b7tern", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ADJD", "ADJD", "KON", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "F\u00fcgt euch den neuen Himmelslichtern", "tokens": ["F\u00fcgt", "euch", "den", "neu\u00b7en", "Him\u00b7mels\u00b7lich\u00b7tern"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "NN"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.5": {"text": "Und \u2013 \u00fcberlasset seinen Richtern", "tokens": ["Und", "\u2013", "\u00fc\u00b7ber\u00b7las\u00b7set", "sei\u00b7nen", "Rich\u00b7tern"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["KON", "$(", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}