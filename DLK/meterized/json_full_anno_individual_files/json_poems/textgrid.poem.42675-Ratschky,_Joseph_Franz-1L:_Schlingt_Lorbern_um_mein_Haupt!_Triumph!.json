{"textgrid.poem.42675": {"metadata": {"author": {"name": "Ratschky, Joseph Franz", "birth": "N.A.", "death": "N.A."}, "title": "1L: Schlingt Lorbern um mein Haupt! Triumph!", "genre": "verse", "period": "N.A.", "pub_year": 1783, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Schlingt Lorbern um mein Haupt! Triumph!", "tokens": ["Schlingt", "Lor\u00b7bern", "um", "mein", "Haupt", "!", "Tri\u00b7umph", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["VVFIN", "NN", "APPR", "PPOSAT", "NN", "$.", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Triumph! o Freunde!", "tokens": ["Tri\u00b7umph", "!", "o", "Freun\u00b7de", "!"], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NN", "$.", "FM", "NN", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.3": {"text": "Korinn' ergiebt des Siegers Armen sich:", "tokens": ["Ko\u00b7rinn'", "er\u00b7giebt", "des", "Sie\u00b7gers", "Ar\u00b7men", "sich", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ART", "NN", "NN", "PRF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Umsonst vereinigten sich alle meine Feinde,", "tokens": ["Um\u00b7sonst", "ver\u00b7ei\u00b7nig\u00b7ten", "sich", "al\u00b7le", "mei\u00b7ne", "Fein\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "PIAT", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Sich Gatte, Schloss und W\u00e4chter wider mich.", "tokens": ["Sich", "Gat\u00b7te", ",", "Schloss", "und", "W\u00e4ch\u00b7ter", "wi\u00b7der", "mich", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "NN", "$,", "NN", "KON", "NE", "APPR", "PPER", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Es t\u00f6ne doppelt laut des Ruhmes Siegstrompete!", "tokens": ["Es", "t\u00f6\u00b7ne", "dop\u00b7pelt", "laut", "des", "Ruh\u00b7mes", "Siegs\u00b7trom\u00b7pe\u00b7te", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Denn meine Beut' ist unbefleckt von Blut:", "tokens": ["Denn", "mei\u00b7ne", "Beut'", "ist", "un\u00b7be\u00b7fleckt", "von", "Blut", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VAFIN", "ADJD", "APPR", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Nicht einen schwachen Wall, nicht unhaltbare St\u00e4dte,", "tokens": ["Nicht", "ei\u00b7nen", "schwa\u00b7chen", "Wall", ",", "nicht", "un\u00b7halt\u00b7ba\u00b7re", "St\u00e4d\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ART", "ADJA", "NN", "$,", "PTKNEG", "ADJA", "NN", "$,"], "meter": "-+-+-+-++--+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Ein stattlich Weib bezwang mein Heldenmuth!", "tokens": ["Ein", "statt\u00b7lich", "Weib", "be\u00b7zwang", "mein", "Hel\u00b7den\u00b7muth", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Als einst im zehnten Jahr die Stadt der Dardaniden", "tokens": ["Als", "einst", "im", "zehn\u00b7ten", "Jahr", "die", "Stadt", "der", "Dar\u00b7da\u00b7ni\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "APPRART", "ADJA", "NN", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ein banger Raub der Griechen wurde, schrieb", "tokens": ["Ein", "ban\u00b7ger", "Raub", "der", "Grie\u00b7chen", "wur\u00b7de", ",", "schrieb"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "VAFIN", "$,", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Der Ruf so Vielen Lob und Preis zu, dass Atriden", "tokens": ["Der", "Ruf", "so", "Vie\u00b7len", "Lob", "und", "Preis", "zu", ",", "dass", "At\u00b7ri\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "ADV", "PIAT", "NN", "KON", "NN", "PTKVZ", "$,", "KOUS", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "F\u00fcr seinen Theil nur wenig Ehre blieb.", "tokens": ["F\u00fcr", "sei\u00b7nen", "Theil", "nur", "we\u00b7nig", "Eh\u00b7re", "blieb", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADV", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Mir bleiben meines Siegs Verdienste ganz; nicht Einer", "tokens": ["Mir", "blei\u00b7ben", "mei\u00b7nes", "Siegs", "Ver\u00b7diens\u00b7te", "ganz", ";", "nicht", "Ei\u00b7ner"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "NN", "ADV", "$.", "PTKNEG", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Nahm hilfreich Theil an meinem Heldenstreich:", "tokens": ["Nahm", "hilf\u00b7reich", "Theil", "an", "mei\u00b7nem", "Hel\u00b7den\u00b7streich", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Ich k\u00e4mpft' und siegt' allein, war Feldherr und Gemeiner,", "tokens": ["Ich", "k\u00e4mpft'", "und", "siegt'", "al\u00b7lein", ",", "war", "Feld\u00b7herr", "und", "Ge\u00b7mei\u00b7ner", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "ADV", "$,", "VAFIN", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-++--+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "War F\u00fcsilier und K\u00fcrassier zugleich.", "tokens": ["War", "F\u00fc\u00b7si\u00b7lier", "und", "K\u00fc\u00b7ras\u00b7sier", "zu\u00b7gleich", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "KON", "NN", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "Mein Sieg ist nicht das Werk des Zufalls einer Stunde,", "tokens": ["Mein", "Sieg", "ist", "nicht", "das", "Werk", "des", "Zu\u00b7falls", "ei\u00b7ner", "Stun\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "PTKNEG", "ART", "NN", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ich \u00fcberwand durch Geistesgegenwart:", "tokens": ["Ich", "\u00fc\u00b7ber\u00b7wand", "durch", "Geis\u00b7tes\u00b7ge\u00b7gen\u00b7wart", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Mein Unternehmen ist nicht Neuerung; die Kunde", "tokens": ["Mein", "Un\u00b7ter\u00b7neh\u00b7men", "ist", "nicht", "Neu\u00b7e\u00b7rung", ";", "die", "Kun\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PPOSAT", "NN", "VAFIN", "PTKNEG", "NN", "$.", "ART", "NN"], "meter": "-+-+-+-+---+-", "measure": "unknown.measure.penta"}, "line.4": {"text": "Der Vorzeit strotzt von Fehden dieser Art.", "tokens": ["Der", "Vor\u00b7zeit", "strotzt", "von", "Feh\u00b7den", "die\u00b7ser", "Art", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "NN", "PDAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "Als Tyndars Tochter einst mit Paris floh, geriethen", "tokens": ["Als", "Tyn\u00b7dars", "Toch\u00b7ter", "einst", "mit", "Pa\u00b7ris", "floh", ",", "ge\u00b7rie\u00b7then"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["KOUS", "NE", "NN", "ADV", "APPR", "NE", "VVFIN", "$,", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Europa nicht und Asien in Streit?", "tokens": ["Eu\u00b7ro\u00b7pa", "nicht", "und", "A\u00b7sien", "in", "Streit", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PTKNEG", "KON", "NN", "APPR", "NN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Ward nicht ein rauher Schwarm Centauren und Lapithen", "tokens": ["Ward", "nicht", "ein", "rau\u00b7her", "Schwarm", "Cen\u00b7tau\u00b7ren", "und", "La\u00b7pi\u00b7then"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PTKNEG", "ART", "ADJA", "NN", "NN", "KON", "NN"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Einst durch ein Weib beym Trinkgelag entzweyt?", "tokens": ["Einst", "durch", "ein", "Weib", "beym", "Trink\u00b7ge\u00b7lag", "ent\u00b7zweyt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.7": {"line.1": {"text": "Ein Weib riss das Gefolg \u00c4neens in des milden", "tokens": ["Ein", "Weib", "riss", "das", "Ge\u00b7folg", "\u00c4\u00b7neens", "in", "des", "mil\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "NN", "APPR", "ART", "ADJA"], "meter": "-++--+-+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Latins Gebiet zu neuen K\u00e4mpfen hin:", "tokens": ["La\u00b7tins", "Ge\u00b7biet", "zu", "neu\u00b7en", "K\u00e4mp\u00b7fen", "hin", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "APPR", "ADJA", "NN", "PTKVZ", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.3": {"text": "Des Weibes Reitz bewog Roms Stifter, sich den wilden", "tokens": ["Des", "Wei\u00b7bes", "Reitz", "be\u00b7wog", "Roms", "Stif\u00b7ter", ",", "sich", "den", "wil\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "NN", "VVFIN", "NE", "NN", "$,", "PRF", "ART", "ADJA"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Verw\u00e4gnen Grimm der Schw\u00e4ger zuzuziehn.", "tokens": ["Ver\u00b7w\u00e4g\u00b7nen", "Grimm", "der", "Schw\u00e4\u00b7ger", "zu\u00b7zu\u00b7ziehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "ART", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.8": {"line.1": {"text": "Oft reitzt die blendende milchfarbne Kuh, zur s\u00fcssen", "tokens": ["Oft", "reitzt", "die", "blen\u00b7den\u00b7de", "milch\u00b7farb\u00b7ne", "Kuh", ",", "zur", "s\u00fcs\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "ADJA", "NN", "$,", "APPRART", "ADJA"], "meter": "-+-+--++-+-+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Begattung reif, die Bullen zum Turnier:", "tokens": ["Be\u00b7gat\u00b7tung", "reif", ",", "die", "Bul\u00b7len", "zum", "Tur\u00b7nier", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "$,", "ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Seht! so erhob auch ich, doch ohne Blutvergiessen,", "tokens": ["Seht", "!", "so", "er\u00b7hob", "auch", "ich", ",", "doch", "oh\u00b7ne", "Blut\u00b7ver\u00b7gies\u00b7sen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$.", "ADV", "VVFIN", "ADV", "PPER", "$,", "ADV", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Auf Amors Wink der Liebe Kriegspanier.", "tokens": ["Auf", "A\u00b7mors", "Wink", "der", "Lie\u00b7be", "Kriegs\u00b7pa\u00b7nier", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "NN", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.9": {"line.1": {"text": "Schlingt Lorbern um mein Haupt! Triumph!", "tokens": ["Schlingt", "Lor\u00b7bern", "um", "mein", "Haupt", "!", "Tri\u00b7umph", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["VVFIN", "NN", "APPR", "PPOSAT", "NN", "$.", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Triumph! o Freunde!", "tokens": ["Tri\u00b7umph", "!", "o", "Freun\u00b7de", "!"], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NN", "$.", "FM", "NN", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.3": {"text": "Korinn' ergiebt des Siegers Armen sich:", "tokens": ["Ko\u00b7rinn'", "er\u00b7giebt", "des", "Sie\u00b7gers", "Ar\u00b7men", "sich", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ART", "NN", "NN", "PRF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Umsonst vereinigten sich alle meine Feinde,", "tokens": ["Um\u00b7sonst", "ver\u00b7ei\u00b7nig\u00b7ten", "sich", "al\u00b7le", "mei\u00b7ne", "Fein\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "PIAT", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Sich Gatte, Schloss und W\u00e4chter wider mich.", "tokens": ["Sich", "Gat\u00b7te", ",", "Schloss", "und", "W\u00e4ch\u00b7ter", "wi\u00b7der", "mich", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "NN", "$,", "NN", "KON", "NE", "APPR", "PPER", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.10": {"line.1": {"text": "Es t\u00f6ne doppelt laut des Ruhmes Siegstrompete!", "tokens": ["Es", "t\u00f6\u00b7ne", "dop\u00b7pelt", "laut", "des", "Ruh\u00b7mes", "Siegs\u00b7trom\u00b7pe\u00b7te", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Denn meine Beut' ist unbefleckt von Blut:", "tokens": ["Denn", "mei\u00b7ne", "Beut'", "ist", "un\u00b7be\u00b7fleckt", "von", "Blut", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VAFIN", "ADJD", "APPR", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Nicht einen schwachen Wall, nicht unhaltbare St\u00e4dte,", "tokens": ["Nicht", "ei\u00b7nen", "schwa\u00b7chen", "Wall", ",", "nicht", "un\u00b7halt\u00b7ba\u00b7re", "St\u00e4d\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ART", "ADJA", "NN", "$,", "PTKNEG", "ADJA", "NN", "$,"], "meter": "-+-+-+-++--+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Ein stattlich Weib bezwang mein Heldenmuth!", "tokens": ["Ein", "statt\u00b7lich", "Weib", "be\u00b7zwang", "mein", "Hel\u00b7den\u00b7muth", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.11": {"line.1": {"text": "Als einst im zehnten Jahr die Stadt der Dardaniden", "tokens": ["Als", "einst", "im", "zehn\u00b7ten", "Jahr", "die", "Stadt", "der", "Dar\u00b7da\u00b7ni\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "APPRART", "ADJA", "NN", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ein banger Raub der Griechen wurde, schrieb", "tokens": ["Ein", "ban\u00b7ger", "Raub", "der", "Grie\u00b7chen", "wur\u00b7de", ",", "schrieb"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "VAFIN", "$,", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Der Ruf so Vielen Lob und Preis zu, dass Atriden", "tokens": ["Der", "Ruf", "so", "Vie\u00b7len", "Lob", "und", "Preis", "zu", ",", "dass", "At\u00b7ri\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "ADV", "PIAT", "NN", "KON", "NN", "PTKVZ", "$,", "KOUS", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "F\u00fcr seinen Theil nur wenig Ehre blieb.", "tokens": ["F\u00fcr", "sei\u00b7nen", "Theil", "nur", "we\u00b7nig", "Eh\u00b7re", "blieb", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADV", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.12": {"line.1": {"text": "Mir bleiben meines Siegs Verdienste ganz; nicht Einer", "tokens": ["Mir", "blei\u00b7ben", "mei\u00b7nes", "Siegs", "Ver\u00b7diens\u00b7te", "ganz", ";", "nicht", "Ei\u00b7ner"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "NN", "ADV", "$.", "PTKNEG", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Nahm hilfreich Theil an meinem Heldenstreich:", "tokens": ["Nahm", "hilf\u00b7reich", "Theil", "an", "mei\u00b7nem", "Hel\u00b7den\u00b7streich", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Ich k\u00e4mpft' und siegt' allein, war Feldherr und Gemeiner,", "tokens": ["Ich", "k\u00e4mpft'", "und", "siegt'", "al\u00b7lein", ",", "war", "Feld\u00b7herr", "und", "Ge\u00b7mei\u00b7ner", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "ADV", "$,", "VAFIN", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-++--+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "War F\u00fcsilier und K\u00fcrassier zugleich.", "tokens": ["War", "F\u00fc\u00b7si\u00b7lier", "und", "K\u00fc\u00b7ras\u00b7sier", "zu\u00b7gleich", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "KON", "NN", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.13": {"line.1": {"text": "Mein Sieg ist nicht das Werk des Zufalls einer Stunde,", "tokens": ["Mein", "Sieg", "ist", "nicht", "das", "Werk", "des", "Zu\u00b7falls", "ei\u00b7ner", "Stun\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "PTKNEG", "ART", "NN", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ich \u00fcberwand durch Geistesgegenwart:", "tokens": ["Ich", "\u00fc\u00b7ber\u00b7wand", "durch", "Geis\u00b7tes\u00b7ge\u00b7gen\u00b7wart", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Mein Unternehmen ist nicht Neuerung; die Kunde", "tokens": ["Mein", "Un\u00b7ter\u00b7neh\u00b7men", "ist", "nicht", "Neu\u00b7e\u00b7rung", ";", "die", "Kun\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PPOSAT", "NN", "VAFIN", "PTKNEG", "NN", "$.", "ART", "NN"], "meter": "-+-+-+-+---+-", "measure": "unknown.measure.penta"}, "line.4": {"text": "Der Vorzeit strotzt von Fehden dieser Art.", "tokens": ["Der", "Vor\u00b7zeit", "strotzt", "von", "Feh\u00b7den", "die\u00b7ser", "Art", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "NN", "PDAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.14": {"line.1": {"text": "Als Tyndars Tochter einst mit Paris floh, geriethen", "tokens": ["Als", "Tyn\u00b7dars", "Toch\u00b7ter", "einst", "mit", "Pa\u00b7ris", "floh", ",", "ge\u00b7rie\u00b7then"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["KOUS", "NE", "NN", "ADV", "APPR", "NE", "VVFIN", "$,", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Europa nicht und Asien in Streit?", "tokens": ["Eu\u00b7ro\u00b7pa", "nicht", "und", "A\u00b7sien", "in", "Streit", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PTKNEG", "KON", "NN", "APPR", "NN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Ward nicht ein rauher Schwarm Centauren und Lapithen", "tokens": ["Ward", "nicht", "ein", "rau\u00b7her", "Schwarm", "Cen\u00b7tau\u00b7ren", "und", "La\u00b7pi\u00b7then"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PTKNEG", "ART", "ADJA", "NN", "NN", "KON", "NN"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Einst durch ein Weib beym Trinkgelag entzweyt?", "tokens": ["Einst", "durch", "ein", "Weib", "beym", "Trink\u00b7ge\u00b7lag", "ent\u00b7zweyt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.15": {"line.1": {"text": "Ein Weib riss das Gefolg \u00c4neens in des milden", "tokens": ["Ein", "Weib", "riss", "das", "Ge\u00b7folg", "\u00c4\u00b7neens", "in", "des", "mil\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "NN", "APPR", "ART", "ADJA"], "meter": "-++--+-+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Latins Gebiet zu neuen K\u00e4mpfen hin:", "tokens": ["La\u00b7tins", "Ge\u00b7biet", "zu", "neu\u00b7en", "K\u00e4mp\u00b7fen", "hin", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "APPR", "ADJA", "NN", "PTKVZ", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.3": {"text": "Des Weibes Reitz bewog Roms Stifter, sich den wilden", "tokens": ["Des", "Wei\u00b7bes", "Reitz", "be\u00b7wog", "Roms", "Stif\u00b7ter", ",", "sich", "den", "wil\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "NN", "VVFIN", "NE", "NN", "$,", "PRF", "ART", "ADJA"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Verw\u00e4gnen Grimm der Schw\u00e4ger zuzuziehn.", "tokens": ["Ver\u00b7w\u00e4g\u00b7nen", "Grimm", "der", "Schw\u00e4\u00b7ger", "zu\u00b7zu\u00b7ziehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "ART", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.16": {"line.1": {"text": "Oft reitzt die blendende milchfarbne Kuh, zur s\u00fcssen", "tokens": ["Oft", "reitzt", "die", "blen\u00b7den\u00b7de", "milch\u00b7farb\u00b7ne", "Kuh", ",", "zur", "s\u00fcs\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "ADJA", "NN", "$,", "APPRART", "ADJA"], "meter": "-+-+--++-+-+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Begattung reif, die Bullen zum Turnier:", "tokens": ["Be\u00b7gat\u00b7tung", "reif", ",", "die", "Bul\u00b7len", "zum", "Tur\u00b7nier", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "$,", "ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Seht! so erhob auch ich, doch ohne Blutvergiessen,", "tokens": ["Seht", "!", "so", "er\u00b7hob", "auch", "ich", ",", "doch", "oh\u00b7ne", "Blut\u00b7ver\u00b7gies\u00b7sen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$.", "ADV", "VVFIN", "ADV", "PPER", "$,", "ADV", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Auf Amors Wink der Liebe Kriegspanier.", "tokens": ["Auf", "A\u00b7mors", "Wink", "der", "Lie\u00b7be", "Kriegs\u00b7pa\u00b7nier", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "NN", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}}}}