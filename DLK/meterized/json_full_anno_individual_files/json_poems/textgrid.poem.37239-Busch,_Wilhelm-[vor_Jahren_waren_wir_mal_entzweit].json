{"textgrid.poem.37239": {"metadata": {"author": {"name": "Busch, Wilhelm", "birth": "N.A.", "death": "N.A."}, "title": "[vor Jahren waren wir mal entzweit]", "genre": "verse", "period": "N.A.", "pub_year": 1870, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Vor Jahren waren wir mal entzweit", "tokens": ["Vor", "Jah\u00b7ren", "wa\u00b7ren", "wir", "mal", "ent\u00b7zweit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "VAFIN", "PPER", "ADV", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Und taten uns manches zum Torte;", "tokens": ["Und", "ta\u00b7ten", "uns", "man\u00b7ches", "zum", "Tor\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PIS", "APPRART", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "Wir sagten uns beide zu jener Zeit", "tokens": ["Wir", "sag\u00b7ten", "uns", "bei\u00b7de", "zu", "je\u00b7ner", "Zeit"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "PIS", "APPR", "PDAT", "NN"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Viel bitterb\u00f6se Worte.", "tokens": ["Viel", "bit\u00b7ter\u00b7b\u00f6\u00b7se", "Wor\u00b7te", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Drauf haben wir uns ineinander geschickt;", "tokens": ["Drauf", "ha\u00b7ben", "wir", "uns", "in\u00b7ein\u00b7an\u00b7der", "ge\u00b7schickt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "PPER", "PRF", "ADV", "VVPP", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "Wir schlossen Frieden und haben", "tokens": ["Wir", "schlos\u00b7sen", "Frie\u00b7den", "und", "ha\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "NN", "KON", "VAFIN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Die bitterb\u00f6sen Worte erstickt", "tokens": ["Die", "bit\u00b7ter\u00b7b\u00f6\u00b7sen", "Wor\u00b7te", "er\u00b7stickt"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVPP"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Und fest und tief begraben.", "tokens": ["Und", "fest", "und", "tief", "be\u00b7gra\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "KON", "ADJD", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Jetzt ist es wirklich recht fatal,", "tokens": ["Jetzt", "ist", "es", "wirk\u00b7lich", "recht", "fa\u00b7tal", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "ADJD", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df wieder ein Zwist notwendig.", "tokens": ["Da\u00df", "wie\u00b7der", "ein", "Zwist", "not\u00b7wen\u00b7dig", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "ADJD", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "O weh! die Worte von dazumal,", "tokens": ["O", "weh", "!", "die", "Wor\u00b7te", "von", "da\u00b7zu\u00b7mal", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "PTKVZ", "$.", "ART", "NN", "APPR", "ADV", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Die werden nun wieder lebendig.", "tokens": ["Die", "wer\u00b7den", "nun", "wie\u00b7der", "le\u00b7ben\u00b7dig", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "ADV", "ADJD", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.4": {"line.1": {"text": "Die kommen nun erst in offnen Streit", "tokens": ["Die", "kom\u00b7men", "nun", "erst", "in", "off\u00b7nen", "Streit"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "ADV", "ADV", "APPR", "ADJA", "NN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Und fliegen auf alle D\u00e4cher;", "tokens": ["Und", "flie\u00b7gen", "auf", "al\u00b7le", "D\u00e4\u00b7cher", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PIAT", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Nun bringen wir sie in Ewigkeit", "tokens": ["Nun", "brin\u00b7gen", "wir", "sie", "in", "E\u00b7wig\u00b7keit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "APPR", "NN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Nicht wieder in ihre L\u00f6cher.", "tokens": ["Nicht", "wie\u00b7der", "in", "ih\u00b7re", "L\u00f6\u00b7cher", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.5": {"line.1": {"text": "Vor Jahren waren wir mal entzweit", "tokens": ["Vor", "Jah\u00b7ren", "wa\u00b7ren", "wir", "mal", "ent\u00b7zweit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "VAFIN", "PPER", "ADV", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Und taten uns manches zum Torte;", "tokens": ["Und", "ta\u00b7ten", "uns", "man\u00b7ches", "zum", "Tor\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PIS", "APPRART", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "Wir sagten uns beide zu jener Zeit", "tokens": ["Wir", "sag\u00b7ten", "uns", "bei\u00b7de", "zu", "je\u00b7ner", "Zeit"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "PIS", "APPR", "PDAT", "NN"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Viel bitterb\u00f6se Worte.", "tokens": ["Viel", "bit\u00b7ter\u00b7b\u00f6\u00b7se", "Wor\u00b7te", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Drauf haben wir uns ineinander geschickt;", "tokens": ["Drauf", "ha\u00b7ben", "wir", "uns", "in\u00b7ein\u00b7an\u00b7der", "ge\u00b7schickt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "PPER", "PRF", "ADV", "VVPP", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "Wir schlossen Frieden und haben", "tokens": ["Wir", "schlos\u00b7sen", "Frie\u00b7den", "und", "ha\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "NN", "KON", "VAFIN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Die bitterb\u00f6sen Worte erstickt", "tokens": ["Die", "bit\u00b7ter\u00b7b\u00f6\u00b7sen", "Wor\u00b7te", "er\u00b7stickt"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVPP"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Und fest und tief begraben.", "tokens": ["Und", "fest", "und", "tief", "be\u00b7gra\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "KON", "ADJD", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Jetzt ist es wirklich recht fatal,", "tokens": ["Jetzt", "ist", "es", "wirk\u00b7lich", "recht", "fa\u00b7tal", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "ADJD", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df wieder ein Zwist notwendig.", "tokens": ["Da\u00df", "wie\u00b7der", "ein", "Zwist", "not\u00b7wen\u00b7dig", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "ADJD", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "O weh! die Worte von dazumal,", "tokens": ["O", "weh", "!", "die", "Wor\u00b7te", "von", "da\u00b7zu\u00b7mal", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "PTKVZ", "$.", "ART", "NN", "APPR", "ADV", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Die werden nun wieder lebendig.", "tokens": ["Die", "wer\u00b7den", "nun", "wie\u00b7der", "le\u00b7ben\u00b7dig", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "ADV", "ADJD", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.8": {"line.1": {"text": "Die kommen nun erst in offnen Streit", "tokens": ["Die", "kom\u00b7men", "nun", "erst", "in", "off\u00b7nen", "Streit"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "ADV", "ADV", "APPR", "ADJA", "NN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Und fliegen auf alle D\u00e4cher;", "tokens": ["Und", "flie\u00b7gen", "auf", "al\u00b7le", "D\u00e4\u00b7cher", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PIAT", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Nun bringen wir sie in Ewigkeit", "tokens": ["Nun", "brin\u00b7gen", "wir", "sie", "in", "E\u00b7wig\u00b7keit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "APPR", "NN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Nicht wieder in ihre L\u00f6cher.", "tokens": ["Nicht", "wie\u00b7der", "in", "ih\u00b7re", "L\u00f6\u00b7cher", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}}}}