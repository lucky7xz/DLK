{"textgrid.poem.48858": {"metadata": {"author": {"name": "Fleming, Paul", "birth": "N.A.", "death": "N.A."}, "title": "83. An Amandulen", "genre": "verse", "period": "N.A.", "pub_year": 1624, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Du schreibst, Amandule, du k\u00f6nnest nicht vorbei,", "tokens": ["Du", "schreibst", ",", "A\u00b7man\u00b7du\u00b7le", ",", "du", "k\u00f6n\u00b7nest", "nicht", "vor\u00b7bei", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "NE", "$,", "PPER", "VMFIN", "PTKNEG", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "du m\u00fcssest mich von Grund' und ganzer Seelen lieben,", "tokens": ["du", "m\u00fcs\u00b7sest", "mich", "von", "Grund'", "und", "gan\u00b7zer", "See\u00b7len", "lie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PRF", "APPR", "NN", "KON", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "di\u00df aber mache dir so gar ein scharf Betr\u00fcben,", "tokens": ["di\u00df", "a\u00b7ber", "ma\u00b7che", "dir", "so", "gar", "ein", "scharf", "Be\u00b7tr\u00fc\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "VVFIN", "PPER", "ADV", "ADV", "ART", "ADJD", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "da\u00df auf der Erden ihm Nichts zu vergleichen sei.", "tokens": ["da\u00df", "auf", "der", "Er\u00b7den", "ihm", "Nichts", "zu", "ver\u00b7glei\u00b7chen", "sei", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "ART", "NN", "PPER", "PIS", "PTKZU", "VVINF", "VAFIN", "$."], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}}, "stanza.2": {"line.1": {"text": "Nun glaub ich dir es leicht' und zeugs auch ohne Scheu,", "tokens": ["Nun", "glaub", "ich", "dir", "es", "leicht'", "und", "zeugs", "auch", "oh\u00b7ne", "Scheu", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "PPER", "VVFIN", "KON", "ADV", "ADV", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "auch mir ist hier von dir ein gro\u00dfer Stachel blieben,", "tokens": ["auch", "mir", "ist", "hier", "von", "dir", "ein", "gro\u00b7\u00dfer", "Sta\u00b7chel", "blie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VAFIN", "ADV", "APPR", "PPER", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "und wie ich dieses dir so ofte zu geschrieben,", "tokens": ["und", "wie", "ich", "die\u00b7ses", "dir", "so", "of\u00b7te", "zu", "ge\u00b7schrie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPER", "PDAT", "PPER", "ADV", "ADJA", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "so schreib' ich dir es itzt noch einmal klar und frei.", "tokens": ["so", "schreib'", "ich", "dir", "es", "itzt", "noch", "ein\u00b7mal", "klar", "und", "frei", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "PPER", "ADV", "ADV", "ADV", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "So bleibst da krank nach mir, ich ungesund nach dir,", "tokens": ["So", "bleibst", "da", "krank", "nach", "mir", ",", "ich", "un\u00b7ge\u00b7sund", "nach", "dir", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "ADJD", "APPR", "PPER", "$,", "PPER", "ADJD", "APPR", "PPER", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "du meiner \u00c4ngsten Qual, ich deiner Schmerzen Brunnen.", "tokens": ["du", "mei\u00b7ner", "\u00c4ngs\u00b7ten", "Qual", ",", "ich", "dei\u00b7ner", "Schmer\u00b7zen", "Brun\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PPOSAT", "NN", "NN", "$,", "PPER", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Doch glaub ich stark daher, da\u00df weder dir, noch mir", "tokens": ["Doch", "glaub", "ich", "stark", "da\u00b7her", ",", "da\u00df", "we\u00b7der", "dir", ",", "noch", "mir"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "ADJD", "PAV", "$,", "KOUS", "KON", "PPER", "$,", "ADV", "PPER"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "das Leben wird gef\u00e4hrdt: sei ja nicht, Lieb, gesonnen,", "tokens": ["das", "Le\u00b7ben", "wird", "ge\u00b7f\u00e4hrdt", ":", "sei", "ja", "nicht", ",", "Lieb", ",", "ge\u00b7son\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVPP", "$.", "VAFIN", "ADV", "PTKNEG", "$,", "NN", "$,", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "zu \u00e4ndern diesen Stand. Freu dich mit mir der Pein,", "tokens": ["zu", "\u00e4n\u00b7dern", "die\u00b7sen", "Stand", ".", "Freu", "dich", "mit", "mir", "der", "Pein", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "PDAT", "NN", "$.", "NN", "PRF", "APPR", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "f\u00fcr welcher Krankheit ich nicht w\u00fcndsche frisch zu sein.", "tokens": ["f\u00fcr", "wel\u00b7cher", "Krank\u00b7heit", "ich", "nicht", "w\u00fcnd\u00b7sche", "frisch", "zu", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PWAT", "NN", "PPER", "PTKNEG", "VVFIN", "ADJD", "PTKZU", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Du schreibst, Amandule, du k\u00f6nnest nicht vorbei,", "tokens": ["Du", "schreibst", ",", "A\u00b7man\u00b7du\u00b7le", ",", "du", "k\u00f6n\u00b7nest", "nicht", "vor\u00b7bei", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "NE", "$,", "PPER", "VMFIN", "PTKNEG", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "du m\u00fcssest mich von Grund' und ganzer Seelen lieben,", "tokens": ["du", "m\u00fcs\u00b7sest", "mich", "von", "Grund'", "und", "gan\u00b7zer", "See\u00b7len", "lie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PRF", "APPR", "NN", "KON", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "di\u00df aber mache dir so gar ein scharf Betr\u00fcben,", "tokens": ["di\u00df", "a\u00b7ber", "ma\u00b7che", "dir", "so", "gar", "ein", "scharf", "Be\u00b7tr\u00fc\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "VVFIN", "PPER", "ADV", "ADV", "ART", "ADJD", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "da\u00df auf der Erden ihm Nichts zu vergleichen sei.", "tokens": ["da\u00df", "auf", "der", "Er\u00b7den", "ihm", "Nichts", "zu", "ver\u00b7glei\u00b7chen", "sei", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "ART", "NN", "PPER", "PIS", "PTKZU", "VVINF", "VAFIN", "$."], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}}, "stanza.6": {"line.1": {"text": "Nun glaub ich dir es leicht' und zeugs auch ohne Scheu,", "tokens": ["Nun", "glaub", "ich", "dir", "es", "leicht'", "und", "zeugs", "auch", "oh\u00b7ne", "Scheu", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "PPER", "VVFIN", "KON", "ADV", "ADV", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "auch mir ist hier von dir ein gro\u00dfer Stachel blieben,", "tokens": ["auch", "mir", "ist", "hier", "von", "dir", "ein", "gro\u00b7\u00dfer", "Sta\u00b7chel", "blie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VAFIN", "ADV", "APPR", "PPER", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "und wie ich dieses dir so ofte zu geschrieben,", "tokens": ["und", "wie", "ich", "die\u00b7ses", "dir", "so", "of\u00b7te", "zu", "ge\u00b7schrie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPER", "PDAT", "PPER", "ADV", "ADJA", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "so schreib' ich dir es itzt noch einmal klar und frei.", "tokens": ["so", "schreib'", "ich", "dir", "es", "itzt", "noch", "ein\u00b7mal", "klar", "und", "frei", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "PPER", "ADV", "ADV", "ADV", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "So bleibst da krank nach mir, ich ungesund nach dir,", "tokens": ["So", "bleibst", "da", "krank", "nach", "mir", ",", "ich", "un\u00b7ge\u00b7sund", "nach", "dir", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "ADJD", "APPR", "PPER", "$,", "PPER", "ADJD", "APPR", "PPER", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "du meiner \u00c4ngsten Qual, ich deiner Schmerzen Brunnen.", "tokens": ["du", "mei\u00b7ner", "\u00c4ngs\u00b7ten", "Qual", ",", "ich", "dei\u00b7ner", "Schmer\u00b7zen", "Brun\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PPOSAT", "NN", "NN", "$,", "PPER", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Doch glaub ich stark daher, da\u00df weder dir, noch mir", "tokens": ["Doch", "glaub", "ich", "stark", "da\u00b7her", ",", "da\u00df", "we\u00b7der", "dir", ",", "noch", "mir"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "ADJD", "PAV", "$,", "KOUS", "KON", "PPER", "$,", "ADV", "PPER"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "das Leben wird gef\u00e4hrdt: sei ja nicht, Lieb, gesonnen,", "tokens": ["das", "Le\u00b7ben", "wird", "ge\u00b7f\u00e4hrdt", ":", "sei", "ja", "nicht", ",", "Lieb", ",", "ge\u00b7son\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVPP", "$.", "VAFIN", "ADV", "PTKNEG", "$,", "NN", "$,", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "zu \u00e4ndern diesen Stand. Freu dich mit mir der Pein,", "tokens": ["zu", "\u00e4n\u00b7dern", "die\u00b7sen", "Stand", ".", "Freu", "dich", "mit", "mir", "der", "Pein", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "PDAT", "NN", "$.", "NN", "PRF", "APPR", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "f\u00fcr welcher Krankheit ich nicht w\u00fcndsche frisch zu sein.", "tokens": ["f\u00fcr", "wel\u00b7cher", "Krank\u00b7heit", "ich", "nicht", "w\u00fcnd\u00b7sche", "frisch", "zu", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PWAT", "NN", "PPER", "PTKNEG", "VVFIN", "ADJD", "PTKZU", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}