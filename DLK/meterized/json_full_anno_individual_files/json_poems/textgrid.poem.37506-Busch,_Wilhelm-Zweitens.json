{"textgrid.poem.37506": {"metadata": {"author": {"name": "Busch, Wilhelm", "birth": "N.A.", "death": "N.A."}, "title": "Zweitens", "genre": "verse", "period": "N.A.", "pub_year": 1870, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ein Irrtum, welcher sehr verbreitet", "tokens": ["Ein", "Irr\u00b7tum", ",", "wel\u00b7cher", "sehr", "ver\u00b7brei\u00b7tet"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "ADV", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und manchen J\u00fcngling irreleitet,", "tokens": ["Und", "man\u00b7chen", "J\u00fcng\u00b7ling", "ir\u00b7re\u00b7lei\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Ist der: da\u00df Liebe eine Sache,", "tokens": ["Ist", "der", ":", "da\u00df", "Lie\u00b7be", "ei\u00b7ne", "Sa\u00b7che", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "$.", "KOUS", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die immer viel Vergn\u00fcgen mache.", "tokens": ["Die", "im\u00b7mer", "viel", "Ver\u00b7gn\u00fc\u00b7gen", "ma\u00b7che", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Antonio meinte dieses, als", "tokens": ["An\u00b7to\u00b7nio", "mein\u00b7te", "die\u00b7ses", ",", "als"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["NE", "VVFIN", "PDS", "$,", "KOUS"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Er gr\u00f6\u00dfer wurde, ebenfalls. \u2013", "tokens": ["Er", "gr\u00f6\u00b7\u00dfer", "wur\u00b7de", ",", "e\u00b7ben\u00b7falls", ".", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "punct", "punct"], "pos": ["PPER", "ADJD", "VAFIN", "$,", "ADV", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Denn ach! noch immer liebt' er ja", "tokens": ["Denn", "ach", "!", "noch", "im\u00b7mer", "liebt'", "er", "ja"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "XY", "$.", "ADV", "ADV", "VVFIN", "PPER", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die schon erw\u00e4hnte Julia,", "tokens": ["Die", "schon", "er\u00b7w\u00e4hn\u00b7te", "Ju\u00b7lia", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "VVFIN", "NE", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.4": {"line.1": {"text": "Selbst dann noch, als die Auserw\u00e4hlte", "tokens": ["Selbst", "dann", "noch", ",", "als", "die", "Au\u00b7ser\u00b7w\u00e4hl\u00b7te"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "ADV", "ADV", "$,", "KOUS", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sich einem Manne anverm\u00e4hlte. \u2013", "tokens": ["Sich", "ei\u00b7nem", "Man\u00b7ne", "an\u00b7ver\u00b7m\u00e4hl\u00b7te", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["PRF", "ART", "NN", "VVFIN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "An einem Abend, kalt und bitter,", "tokens": ["An", "ei\u00b7nem", "A\u00b7bend", ",", "kalt", "und", "bit\u00b7ter", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Als er, wie \u00f6fters schon, die Zither", "tokens": ["Als", "er", ",", "wie", "\u00f6f\u00b7ters", "schon", ",", "die", "Zi\u00b7ther"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["KOUS", "PPER", "$,", "PWAV", "ADV", "ADV", "$,", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Vor ihrem Fenster klagend schl\u00e4gt,", "tokens": ["Vor", "ih\u00b7rem", "Fens\u00b7ter", "kla\u00b7gend", "schl\u00e4gt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVPP", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ob er vielleicht ihr Herz bewegt \u2013", "tokens": ["Ob", "er", "viel\u00b7leicht", "ihr", "Herz", "be\u00b7wegt", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Pst! pst! \u2013 ert\u00f6nt es da hernieder \u2013", "tokens": ["Pst", "!", "pst", "!", "\u2013", "er\u00b7t\u00f6nt", "es", "da", "her\u00b7nie\u00b7der", "\u2013"], "token_info": ["word", "punct", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "VVFIN", "$.", "$(", "VVFIN", "PPER", "ADV", "PTKVZ", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df durch die halberstarrten Glieder", "tokens": ["Da\u00df", "durch", "die", "hal\u00b7ber\u00b7starr\u00b7ten", "Glie\u00b7der"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Ein wonnevoller Schrecken dringt \u2013", "tokens": ["Ein", "won\u00b7ne\u00b7vol\u00b7ler", "Schre\u00b7cken", "dringt", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Pst! pst! Sieh da! Sie winkt, sie winkt! \u2013", "tokens": ["Pst", "!", "pst", "!", "Sieh", "da", "!", "Sie", "winkt", ",", "sie", "winkt", "!", "\u2013"], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["NN", "$.", "VVFIN", "$.", "NE", "PTKVZ", "$.", "PPER", "VVFIN", "$,", "PPER", "VVFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Von Hoffnungsfl\u00fcgeln sanft gehoben", "tokens": ["Von", "Hoff\u00b7nungs\u00b7fl\u00fc\u00b7geln", "sanft", "ge\u00b7ho\u00b7ben"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NN", "ADJD", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Schwebt er treppauf und fliegt nach oben.", "tokens": ["Schwebt", "er", "trep\u00b7pauf", "und", "fliegt", "nach", "o\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKVZ", "KON", "VVFIN", "APPR", "ADV", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Wer m\u00f6chte nicht, wenn er durchfroren,", "tokens": ["Wer", "m\u00f6ch\u00b7te", "nicht", ",", "wenn", "er", "durch\u00b7fro\u00b7ren", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PTKNEG", "$,", "KOUS", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die halbverglasten steifen Ohren", "tokens": ["Die", "halb\u00b7ver\u00b7glas\u00b7ten", "stei\u00b7fen", "Oh\u00b7ren"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "An einen warmen Busen dr\u00fccken", "tokens": ["An", "ei\u00b7nen", "war\u00b7men", "Bu\u00b7sen", "dr\u00fc\u00b7cken"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und so allm\u00e4hlich sich erquicken???", "tokens": ["Und", "so", "all\u00b7m\u00e4h\u00b7lich", "sich", "er\u00b7qui\u00b7cken", "???"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJD", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Antonio hoffte dieses, als", "tokens": ["An\u00b7to\u00b7nio", "hoff\u00b7te", "die\u00b7ses", ",", "als"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["NE", "VVFIN", "PDS", "$,", "KOUS"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Er hergekommen, ebenfalls.", "tokens": ["Er", "her\u00b7ge\u00b7kom\u00b7men", ",", "e\u00b7ben\u00b7falls", "."], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["PPER", "VVPP", "$,", "ADV", "$."], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}}, "stanza.10": {"line.1": {"text": "Doch ach! kaum hat er Platz genommen,", "tokens": ["Doch", "ach", "!", "kaum", "hat", "er", "Platz", "ge\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "XY", "$.", "ADV", "VAFIN", "PPER", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Da h\u00f6rt man drau\u00dfen schon was kommen.", "tokens": ["Da", "h\u00f6rt", "man", "drau\u00b7\u00dfen", "schon", "was", "kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "ADV", "ADV", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Mit Husten und mit Sporenklang", "tokens": ["Mit", "Hus\u00b7ten", "und", "mit", "Spo\u00b7ren\u00b7klang"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Klirrt der Gemahl den Flur entlang.", "tokens": ["Klirrt", "der", "Ge\u00b7mahl", "den", "Flur", "ent\u00b7lang", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ART", "NN", "PTKVZ", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.11": {"line.1": {"text": "Schnell unters Fa\u00df! \u2013 so ruft das Weib", "tokens": ["Schnell", "un\u00b7ters", "Fa\u00df", "!", "\u2013", "so", "ruft", "das", "Weib"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word"], "pos": ["ADJD", "APPRART", "NN", "$.", "$(", "ADV", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und st\u00fclpt's Antonio auf den Leib;", "tokens": ["Und", "st\u00fclpt's", "An\u00b7to\u00b7nio", "auf", "den", "Leib", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "NE", "APPR", "ART", "NN", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Und auch die Katze, sehr erschreckt,", "tokens": ["Und", "auch", "die", "Kat\u00b7ze", ",", "sehr", "er\u00b7schreckt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "$,", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wird in der Hast mit zugedeckt.", "tokens": ["Wird", "in", "der", "Hast", "mit", "zu\u00b7ge\u00b7deckt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "ART", "NN", "APPR", "VVPP", "$."], "meter": "-+-+---+", "measure": "unknown.measure.tri"}}, "stanza.12": {"line.1": {"text": "Der Hausherr f\u00e4ngt als Biedermann", "tokens": ["Der", "Haus\u00b7herr", "f\u00e4ngt", "als", "Bie\u00b7der\u00b7mann"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "KOUS", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mit seiner Frau zu kosen an.", "tokens": ["Mit", "sei\u00b7ner", "Frau", "zu", "ko\u00b7sen", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PTKZU", "VVINF", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Antonio aber, sehr beengt,", "tokens": ["An\u00b7to\u00b7nio", "a\u00b7ber", ",", "sehr", "be\u00b7engt", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "ADV", "$,", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Hat seine Finger eingezw\u00e4ngt.", "tokens": ["Hat", "sei\u00b7ne", "Fin\u00b7ger", "ein\u00b7ge\u00b7zw\u00e4ngt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Derweil versp\u00fcret hinterw\u00e4rts", "tokens": ["Der\u00b7weil", "ver\u00b7sp\u00fc\u00b7ret", "hin\u00b7ter\u00b7w\u00e4rts"], "token_info": ["word", "word", "word"], "pos": ["ADV", "VVFIN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Am Schwanz die Katze gro\u00dfen Schmerz.", "tokens": ["Am", "Schwanz", "die", "Kat\u00b7ze", "gro\u00b7\u00dfen", "Schmerz", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "Sie meint: Antonio hat's getan!", "tokens": ["Sie", "meint", ":", "An\u00b7to\u00b7nio", "hat's", "ge\u00b7tan", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "NE", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Kralle kratzt, es bei\u00dft der Zahn.", "tokens": ["Die", "Kral\u00b7le", "kratzt", ",", "es", "bei\u00dft", "der", "Zahn", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "PPER", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "Das Fa\u00df f\u00e4llt um, der L\u00e4rm wird gro\u00df,", "tokens": ["Das", "Fa\u00df", "f\u00e4llt", "um", ",", "der", "L\u00e4rm", "wird", "gro\u00df", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "$,", "ART", "NN", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Katze l\u00e4\u00dft so leicht nicht los.", "tokens": ["Die", "Kat\u00b7ze", "l\u00e4\u00dft", "so", "leicht", "nicht", "los", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "ADJD", "PTKNEG", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.17": {"line.1": {"text": "Mit seinem Degen st\u00f6\u00dft der Mann.", "tokens": ["Mit", "sei\u00b7nem", "De\u00b7gen", "st\u00f6\u00dft", "der", "Mann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Antonio dr\u00fcckt sich, wie er kann.", "tokens": ["An\u00b7to\u00b7nio", "dr\u00fcckt", "sich", ",", "wie", "er", "kann", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PRF", "$,", "PWAV", "PPER", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.18": {"line.1": {"text": "Und kommt gekrochen und verfroren", "tokens": ["Und", "kommt", "ge\u00b7kro\u00b7chen", "und", "ver\u00b7fro\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "VVPP", "KON", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Zu eines Klosters ernsten Toren.", "tokens": ["Zu", "ei\u00b7nes", "Klos\u00b7ters", "erns\u00b7ten", "To\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "O Welt, mit uns ist's nun vorbei!", "tokens": ["O", "Welt", ",", "mit", "uns", "ist's", "nun", "vor\u00b7bei", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "APPR", "PPER", "VAFIN", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ihr Weiber, fahrt mir aus dem Sinn!", "tokens": ["Ihr", "Wei\u00b7ber", ",", "fahrt", "mir", "aus", "dem", "Sinn", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.5": {"text": "Du K\u00f6nigin des Himmels sei", "tokens": ["Du", "K\u00f6\u00b7ni\u00b7gin", "des", "Him\u00b7mels", "sei"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "NN", "ART", "NN", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Auch meines Herzens K\u00f6nigin.", "tokens": ["Auch", "mei\u00b7nes", "Her\u00b7zens", "K\u00f6\u00b7ni\u00b7gin", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Salve Regina!", "tokens": ["Sal\u00b7ve", "Re\u00b7gi\u00b7na", "!"], "token_info": ["word", "word", "punct"], "pos": ["NE", "NE", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.19": {"line.1": {"text": "Ein Irrtum, welcher sehr verbreitet", "tokens": ["Ein", "Irr\u00b7tum", ",", "wel\u00b7cher", "sehr", "ver\u00b7brei\u00b7tet"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "ADV", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und manchen J\u00fcngling irreleitet,", "tokens": ["Und", "man\u00b7chen", "J\u00fcng\u00b7ling", "ir\u00b7re\u00b7lei\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Ist der: da\u00df Liebe eine Sache,", "tokens": ["Ist", "der", ":", "da\u00df", "Lie\u00b7be", "ei\u00b7ne", "Sa\u00b7che", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "$.", "KOUS", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die immer viel Vergn\u00fcgen mache.", "tokens": ["Die", "im\u00b7mer", "viel", "Ver\u00b7gn\u00fc\u00b7gen", "ma\u00b7che", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.20": {"line.1": {"text": "Antonio meinte dieses, als", "tokens": ["An\u00b7to\u00b7nio", "mein\u00b7te", "die\u00b7ses", ",", "als"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["NE", "VVFIN", "PDS", "$,", "KOUS"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Er gr\u00f6\u00dfer wurde, ebenfalls. \u2013", "tokens": ["Er", "gr\u00f6\u00b7\u00dfer", "wur\u00b7de", ",", "e\u00b7ben\u00b7falls", ".", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "punct", "punct"], "pos": ["PPER", "ADJD", "VAFIN", "$,", "ADV", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.21": {"line.1": {"text": "Denn ach! noch immer liebt' er ja", "tokens": ["Denn", "ach", "!", "noch", "im\u00b7mer", "liebt'", "er", "ja"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "XY", "$.", "ADV", "ADV", "VVFIN", "PPER", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die schon erw\u00e4hnte Julia,", "tokens": ["Die", "schon", "er\u00b7w\u00e4hn\u00b7te", "Ju\u00b7lia", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "VVFIN", "NE", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.22": {"line.1": {"text": "Selbst dann noch, als die Auserw\u00e4hlte", "tokens": ["Selbst", "dann", "noch", ",", "als", "die", "Au\u00b7ser\u00b7w\u00e4hl\u00b7te"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "ADV", "ADV", "$,", "KOUS", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sich einem Manne anverm\u00e4hlte. \u2013", "tokens": ["Sich", "ei\u00b7nem", "Man\u00b7ne", "an\u00b7ver\u00b7m\u00e4hl\u00b7te", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["PRF", "ART", "NN", "VVFIN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.23": {"line.1": {"text": "An einem Abend, kalt und bitter,", "tokens": ["An", "ei\u00b7nem", "A\u00b7bend", ",", "kalt", "und", "bit\u00b7ter", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Als er, wie \u00f6fters schon, die Zither", "tokens": ["Als", "er", ",", "wie", "\u00f6f\u00b7ters", "schon", ",", "die", "Zi\u00b7ther"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["KOUS", "PPER", "$,", "PWAV", "ADV", "ADV", "$,", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.24": {"line.1": {"text": "Vor ihrem Fenster klagend schl\u00e4gt,", "tokens": ["Vor", "ih\u00b7rem", "Fens\u00b7ter", "kla\u00b7gend", "schl\u00e4gt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVPP", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ob er vielleicht ihr Herz bewegt \u2013", "tokens": ["Ob", "er", "viel\u00b7leicht", "ihr", "Herz", "be\u00b7wegt", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.25": {"line.1": {"text": "Pst! pst! \u2013 ert\u00f6nt es da hernieder \u2013", "tokens": ["Pst", "!", "pst", "!", "\u2013", "er\u00b7t\u00f6nt", "es", "da", "her\u00b7nie\u00b7der", "\u2013"], "token_info": ["word", "punct", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "VVFIN", "$.", "$(", "VVFIN", "PPER", "ADV", "PTKVZ", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df durch die halberstarrten Glieder", "tokens": ["Da\u00df", "durch", "die", "hal\u00b7ber\u00b7starr\u00b7ten", "Glie\u00b7der"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Ein wonnevoller Schrecken dringt \u2013", "tokens": ["Ein", "won\u00b7ne\u00b7vol\u00b7ler", "Schre\u00b7cken", "dringt", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Pst! pst! Sieh da! Sie winkt, sie winkt! \u2013", "tokens": ["Pst", "!", "pst", "!", "Sieh", "da", "!", "Sie", "winkt", ",", "sie", "winkt", "!", "\u2013"], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["NN", "$.", "VVFIN", "$.", "NE", "PTKVZ", "$.", "PPER", "VVFIN", "$,", "PPER", "VVFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Von Hoffnungsfl\u00fcgeln sanft gehoben", "tokens": ["Von", "Hoff\u00b7nungs\u00b7fl\u00fc\u00b7geln", "sanft", "ge\u00b7ho\u00b7ben"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NN", "ADJD", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Schwebt er treppauf und fliegt nach oben.", "tokens": ["Schwebt", "er", "trep\u00b7pauf", "und", "fliegt", "nach", "o\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKVZ", "KON", "VVFIN", "APPR", "ADV", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.26": {"line.1": {"text": "Wer m\u00f6chte nicht, wenn er durchfroren,", "tokens": ["Wer", "m\u00f6ch\u00b7te", "nicht", ",", "wenn", "er", "durch\u00b7fro\u00b7ren", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PTKNEG", "$,", "KOUS", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die halbverglasten steifen Ohren", "tokens": ["Die", "halb\u00b7ver\u00b7glas\u00b7ten", "stei\u00b7fen", "Oh\u00b7ren"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "An einen warmen Busen dr\u00fccken", "tokens": ["An", "ei\u00b7nen", "war\u00b7men", "Bu\u00b7sen", "dr\u00fc\u00b7cken"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und so allm\u00e4hlich sich erquicken???", "tokens": ["Und", "so", "all\u00b7m\u00e4h\u00b7lich", "sich", "er\u00b7qui\u00b7cken", "???"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJD", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.27": {"line.1": {"text": "Antonio hoffte dieses, als", "tokens": ["An\u00b7to\u00b7nio", "hoff\u00b7te", "die\u00b7ses", ",", "als"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["NE", "VVFIN", "PDS", "$,", "KOUS"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Er hergekommen, ebenfalls.", "tokens": ["Er", "her\u00b7ge\u00b7kom\u00b7men", ",", "e\u00b7ben\u00b7falls", "."], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["PPER", "VVPP", "$,", "ADV", "$."], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}}, "stanza.28": {"line.1": {"text": "Doch ach! kaum hat er Platz genommen,", "tokens": ["Doch", "ach", "!", "kaum", "hat", "er", "Platz", "ge\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "XY", "$.", "ADV", "VAFIN", "PPER", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Da h\u00f6rt man drau\u00dfen schon was kommen.", "tokens": ["Da", "h\u00f6rt", "man", "drau\u00b7\u00dfen", "schon", "was", "kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "ADV", "ADV", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Mit Husten und mit Sporenklang", "tokens": ["Mit", "Hus\u00b7ten", "und", "mit", "Spo\u00b7ren\u00b7klang"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Klirrt der Gemahl den Flur entlang.", "tokens": ["Klirrt", "der", "Ge\u00b7mahl", "den", "Flur", "ent\u00b7lang", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ART", "NN", "PTKVZ", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.29": {"line.1": {"text": "Schnell unters Fa\u00df! \u2013 so ruft das Weib", "tokens": ["Schnell", "un\u00b7ters", "Fa\u00df", "!", "\u2013", "so", "ruft", "das", "Weib"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word"], "pos": ["ADJD", "APPRART", "NN", "$.", "$(", "ADV", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und st\u00fclpt's Antonio auf den Leib;", "tokens": ["Und", "st\u00fclpt's", "An\u00b7to\u00b7nio", "auf", "den", "Leib", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "NE", "APPR", "ART", "NN", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Und auch die Katze, sehr erschreckt,", "tokens": ["Und", "auch", "die", "Kat\u00b7ze", ",", "sehr", "er\u00b7schreckt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "$,", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wird in der Hast mit zugedeckt.", "tokens": ["Wird", "in", "der", "Hast", "mit", "zu\u00b7ge\u00b7deckt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "ART", "NN", "APPR", "VVPP", "$."], "meter": "-+-+---+", "measure": "unknown.measure.tri"}}, "stanza.30": {"line.1": {"text": "Der Hausherr f\u00e4ngt als Biedermann", "tokens": ["Der", "Haus\u00b7herr", "f\u00e4ngt", "als", "Bie\u00b7der\u00b7mann"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "KOUS", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mit seiner Frau zu kosen an.", "tokens": ["Mit", "sei\u00b7ner", "Frau", "zu", "ko\u00b7sen", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PTKZU", "VVINF", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.31": {"line.1": {"text": "Antonio aber, sehr beengt,", "tokens": ["An\u00b7to\u00b7nio", "a\u00b7ber", ",", "sehr", "be\u00b7engt", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "ADV", "$,", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Hat seine Finger eingezw\u00e4ngt.", "tokens": ["Hat", "sei\u00b7ne", "Fin\u00b7ger", "ein\u00b7ge\u00b7zw\u00e4ngt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.32": {"line.1": {"text": "Derweil versp\u00fcret hinterw\u00e4rts", "tokens": ["Der\u00b7weil", "ver\u00b7sp\u00fc\u00b7ret", "hin\u00b7ter\u00b7w\u00e4rts"], "token_info": ["word", "word", "word"], "pos": ["ADV", "VVFIN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Am Schwanz die Katze gro\u00dfen Schmerz.", "tokens": ["Am", "Schwanz", "die", "Kat\u00b7ze", "gro\u00b7\u00dfen", "Schmerz", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.33": {"line.1": {"text": "Sie meint: Antonio hat's getan!", "tokens": ["Sie", "meint", ":", "An\u00b7to\u00b7nio", "hat's", "ge\u00b7tan", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "NE", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Kralle kratzt, es bei\u00dft der Zahn.", "tokens": ["Die", "Kral\u00b7le", "kratzt", ",", "es", "bei\u00dft", "der", "Zahn", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "PPER", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.34": {"line.1": {"text": "Das Fa\u00df f\u00e4llt um, der L\u00e4rm wird gro\u00df,", "tokens": ["Das", "Fa\u00df", "f\u00e4llt", "um", ",", "der", "L\u00e4rm", "wird", "gro\u00df", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "$,", "ART", "NN", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Katze l\u00e4\u00dft so leicht nicht los.", "tokens": ["Die", "Kat\u00b7ze", "l\u00e4\u00dft", "so", "leicht", "nicht", "los", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "ADJD", "PTKNEG", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.35": {"line.1": {"text": "Mit seinem Degen st\u00f6\u00dft der Mann.", "tokens": ["Mit", "sei\u00b7nem", "De\u00b7gen", "st\u00f6\u00dft", "der", "Mann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Antonio dr\u00fcckt sich, wie er kann.", "tokens": ["An\u00b7to\u00b7nio", "dr\u00fcckt", "sich", ",", "wie", "er", "kann", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PRF", "$,", "PWAV", "PPER", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.36": {"line.1": {"text": "Und kommt gekrochen und verfroren", "tokens": ["Und", "kommt", "ge\u00b7kro\u00b7chen", "und", "ver\u00b7fro\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "VVPP", "KON", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Zu eines Klosters ernsten Toren.", "tokens": ["Zu", "ei\u00b7nes", "Klos\u00b7ters", "erns\u00b7ten", "To\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "O Welt, mit uns ist's nun vorbei!", "tokens": ["O", "Welt", ",", "mit", "uns", "ist's", "nun", "vor\u00b7bei", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "APPR", "PPER", "VAFIN", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ihr Weiber, fahrt mir aus dem Sinn!", "tokens": ["Ihr", "Wei\u00b7ber", ",", "fahrt", "mir", "aus", "dem", "Sinn", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.5": {"text": "Du K\u00f6nigin des Himmels sei", "tokens": ["Du", "K\u00f6\u00b7ni\u00b7gin", "des", "Him\u00b7mels", "sei"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "NN", "ART", "NN", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Auch meines Herzens K\u00f6nigin.", "tokens": ["Auch", "mei\u00b7nes", "Her\u00b7zens", "K\u00f6\u00b7ni\u00b7gin", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Salve Regina!", "tokens": ["Sal\u00b7ve", "Re\u00b7gi\u00b7na", "!"], "token_info": ["word", "word", "punct"], "pos": ["NE", "NE", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}}}}