{"textgrid.poem.63390": {"metadata": {"author": {"name": "Klabund", "birth": "N.A.", "death": "N.A."}, "title": "Im Spiegel", "genre": "verse", "period": "N.A.", "pub_year": 1909, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ich sehe in den Spiegel.", "tokens": ["Ich", "se\u00b7he", "in", "den", "Spie\u00b7gel", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Was f\u00fcr ein unversch\u00e4mter Blick mustert mich?", "tokens": ["Was", "f\u00fcr", "ein", "un\u00b7ver\u00b7sch\u00e4m\u00b7ter", "Blick", "mus\u00b7tert", "mich", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "ART", "ADJA", "NN", "VVFIN", "PPER", "$."], "meter": "-+-+-+-++-+", "measure": "unknown.measure.hexa"}, "line.3": {"text": "Jetzt zieht er sich schon in sich selbst zur\u00fcck \u2013", "tokens": ["Jetzt", "zieht", "er", "sich", "schon", "in", "sich", "selbst", "zu\u00b7r\u00fcck", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "ADV", "APPR", "PRF", "ADV", "PTKVZ", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Pardon: ich habe mich fixiert.", "tokens": ["Par\u00b7don", ":", "ich", "ha\u00b7be", "mich", "fi\u00b7xiert", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "PPER", "VAFIN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ich will mir nicht zu nahe treten.", "tokens": ["Ich", "will", "mir", "nicht", "zu", "na\u00b7he", "tre\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "PTKNEG", "PTKA", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Meine Freunde kann ich mir an den Fingern einer Hand abz\u00e4hlen.", "tokens": ["Mei\u00b7ne", "Freun\u00b7de", "kann", "ich", "mir", "an", "den", "Fin\u00b7gern", "ei\u00b7ner", "Hand", "ab\u00b7z\u00e4h\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VMFIN", "PPER", "PRF", "APPR", "ART", "NN", "ART", "NN", "VVIZU", "$."], "meter": "+-+--+-+-+-+-+-+-", "measure": "trochaic.octa.plus.relaxed"}, "line.2": {"text": "F\u00fcr meine Feinde brauch ich schon eine Rechenmaschine.", "tokens": ["F\u00fcr", "mei\u00b7ne", "Fein\u00b7de", "brauch", "ich", "schon", "ei\u00b7ne", "Re\u00b7chen\u00b7ma\u00b7schi\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "PPER", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+--+--+-", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Was bedeuten diese tiefen Furchen auf meiner Stirn?", "tokens": ["Was", "be\u00b7deu\u00b7ten", "die\u00b7se", "tie\u00b7fen", "Fur\u00b7chen", "auf", "mei\u00b7ner", "Stirn", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PDAT", "ADJA", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-+--+-+", "measure": "trochaic.septa.relaxed"}, "line.4": {"text": "Ich werde Kresse und Vergi\u00dfmeinnicht drein s\u00e4en.", "tokens": ["Ich", "wer\u00b7de", "Kres\u00b7se", "und", "Ver\u00b7gi\u00df\u00b7mein\u00b7nicht", "drein", "s\u00e4\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NN", "KON", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Im Berliner botanischen Garten, sah ich einen Negersch\u00e4del,", "tokens": ["Im", "Ber\u00b7li\u00b7ner", "bo\u00b7ta\u00b7ni\u00b7schen", "Gar\u00b7ten", ",", "sah", "ich", "ei\u00b7nen", "Ne\u00b7ger\u00b7sch\u00e4\u00b7del", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "ADJA", "NN", "$,", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+--+-+-+-+-+-+-+-", "measure": "iambic.octa.plus.relaxed"}, "line.2": {"text": "Aus dem eine Orchidee spro\u00df.", "tokens": ["Aus", "dem", "ei\u00b7ne", "Or\u00b7chi\u00b7dee", "spro\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ART", "NN", "VVFIN", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.3": {"text": "So vornehm wollen wir's gar nicht machen.", "tokens": ["So", "vor\u00b7nehm", "wol\u00b7len", "wir's", "gar", "nicht", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VMFIN", "PIS", "ADV", "PTKNEG", "VVINF", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Bei uns gen\u00fcgt auch ein schlichtes deutsches Feldgew\u00e4chs.", "tokens": ["Bei", "uns", "ge\u00b7n\u00fcgt", "auch", "ein", "schlich\u00b7tes", "deut\u00b7sches", "Feld\u00b7ge\u00b7w\u00e4chs", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVFIN", "ADV", "ART", "ADJA", "ADJA", "NN", "$."], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.4": {"line.1": {"text": "Wir wollen durch die Blume zu den \u00dcberlebenden sprechen,", "tokens": ["Wir", "wol\u00b7len", "durch", "die", "Blu\u00b7me", "zu", "den", "\u00dc\u00b7berl\u00b7e\u00b7ben\u00b7den", "spre\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPR", "ART", "NN", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+--+-", "measure": "iambic.septa.relaxed"}, "line.2": {"text": "Wie wir so oft zu den nunmehr verwesten sprachen.", "tokens": ["Wie", "wir", "so", "oft", "zu", "den", "nun\u00b7mehr", "ver\u00b7wes\u00b7ten", "spra\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "ADV", "APPR", "ART", "ADV", "VVFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Also, meine liebe Leibf\u00fcchsin:", "tokens": ["Al\u00b7so", ",", "mei\u00b7ne", "lie\u00b7be", "Leib\u00b7f\u00fcc\u00b7hsin", ":"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PPOSAT", "ADJA", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Du kommst mir deine Blume \u2013 Prost! Blume!", "tokens": ["Du", "kommst", "mir", "dei\u00b7ne", "Blu\u00b7me", "\u2013", "Prost", "!", "Blu\u00b7me", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PPOSAT", "NN", "$(", "NN", "$.", "NN", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.5": {"line.1": {"text": "Der Spiegel zittert.", "tokens": ["Der", "Spie\u00b7gel", "zit\u00b7tert", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.2": {"text": "Seine Oberfl\u00e4che kr\u00e4uselt sich, weil ich lache.", "tokens": ["Sei\u00b7ne", "O\u00b7berf\u00b7l\u00e4\u00b7che", "kr\u00e4u\u00b7selt", "sich", ",", "weil", "ich", "la\u00b7che", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PRF", "$,", "KOUS", "PPER", "VVFIN", "$."], "meter": "+-+-+-+--+-+-", "measure": "trochaic.hexa.relaxed"}, "line.3": {"text": "Da ist der Mond \u2013 er tritt aus dem Spiegel in feuriger R\u00fcstung", "tokens": ["Da", "ist", "der", "Mond", "\u2013", "er", "tritt", "aus", "dem", "Spie\u00b7gel", "in", "feu\u00b7ri\u00b7ger", "R\u00fcs\u00b7tung"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ART", "NN", "$(", "PPER", "VVFIN", "APPR", "ART", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+--+--+--+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Und legt seine wei\u00dfe k\u00fchle Hand auf meine fieberhei\u00dfe Stirn.", "tokens": ["Und", "legt", "sei\u00b7ne", "wei\u00b7\u00dfe", "k\u00fch\u00b7le", "Hand", "auf", "mei\u00b7ne", "fie\u00b7ber\u00b7hei\u00b7\u00dfe", "Stirn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "ADJA", "ADJA", "NN", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+--+-+-+-+-+-+-+", "measure": "iambic.octa.plus.relaxed"}}, "stanza.6": {"line.1": {"text": "Ich sehe in den Spiegel.", "tokens": ["Ich", "se\u00b7he", "in", "den", "Spie\u00b7gel", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Was f\u00fcr ein unversch\u00e4mter Blick mustert mich?", "tokens": ["Was", "f\u00fcr", "ein", "un\u00b7ver\u00b7sch\u00e4m\u00b7ter", "Blick", "mus\u00b7tert", "mich", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "ART", "ADJA", "NN", "VVFIN", "PPER", "$."], "meter": "-+-+-+-++-+", "measure": "unknown.measure.hexa"}, "line.3": {"text": "Jetzt zieht er sich schon in sich selbst zur\u00fcck \u2013", "tokens": ["Jetzt", "zieht", "er", "sich", "schon", "in", "sich", "selbst", "zu\u00b7r\u00fcck", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "ADV", "APPR", "PRF", "ADV", "PTKVZ", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Pardon: ich habe mich fixiert.", "tokens": ["Par\u00b7don", ":", "ich", "ha\u00b7be", "mich", "fi\u00b7xiert", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "PPER", "VAFIN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ich will mir nicht zu nahe treten.", "tokens": ["Ich", "will", "mir", "nicht", "zu", "na\u00b7he", "tre\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "PTKNEG", "PTKA", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Meine Freunde kann ich mir an den Fingern einer Hand abz\u00e4hlen.", "tokens": ["Mei\u00b7ne", "Freun\u00b7de", "kann", "ich", "mir", "an", "den", "Fin\u00b7gern", "ei\u00b7ner", "Hand", "ab\u00b7z\u00e4h\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VMFIN", "PPER", "PRF", "APPR", "ART", "NN", "ART", "NN", "VVIZU", "$."], "meter": "+-+--+-+-+-+-+-+-", "measure": "trochaic.octa.plus.relaxed"}, "line.2": {"text": "F\u00fcr meine Feinde brauch ich schon eine Rechenmaschine.", "tokens": ["F\u00fcr", "mei\u00b7ne", "Fein\u00b7de", "brauch", "ich", "schon", "ei\u00b7ne", "Re\u00b7chen\u00b7ma\u00b7schi\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "PPER", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+--+--+-", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Was bedeuten diese tiefen Furchen auf meiner Stirn?", "tokens": ["Was", "be\u00b7deu\u00b7ten", "die\u00b7se", "tie\u00b7fen", "Fur\u00b7chen", "auf", "mei\u00b7ner", "Stirn", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PDAT", "ADJA", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-+--+-+", "measure": "trochaic.septa.relaxed"}, "line.4": {"text": "Ich werde Kresse und Vergi\u00dfmeinnicht drein s\u00e4en.", "tokens": ["Ich", "wer\u00b7de", "Kres\u00b7se", "und", "Ver\u00b7gi\u00df\u00b7mein\u00b7nicht", "drein", "s\u00e4\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NN", "KON", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "Im Berliner botanischen Garten, sah ich einen Negersch\u00e4del,", "tokens": ["Im", "Ber\u00b7li\u00b7ner", "bo\u00b7ta\u00b7ni\u00b7schen", "Gar\u00b7ten", ",", "sah", "ich", "ei\u00b7nen", "Ne\u00b7ger\u00b7sch\u00e4\u00b7del", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "ADJA", "NN", "$,", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+--+-+-+-+-+-+-+-", "measure": "iambic.octa.plus.relaxed"}, "line.2": {"text": "Aus dem eine Orchidee spro\u00df.", "tokens": ["Aus", "dem", "ei\u00b7ne", "Or\u00b7chi\u00b7dee", "spro\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ART", "NN", "VVFIN", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.3": {"text": "So vornehm wollen wir's gar nicht machen.", "tokens": ["So", "vor\u00b7nehm", "wol\u00b7len", "wir's", "gar", "nicht", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VMFIN", "PIS", "ADV", "PTKNEG", "VVINF", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Bei uns gen\u00fcgt auch ein schlichtes deutsches Feldgew\u00e4chs.", "tokens": ["Bei", "uns", "ge\u00b7n\u00fcgt", "auch", "ein", "schlich\u00b7tes", "deut\u00b7sches", "Feld\u00b7ge\u00b7w\u00e4chs", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVFIN", "ADV", "ART", "ADJA", "ADJA", "NN", "$."], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.9": {"line.1": {"text": "Wir wollen durch die Blume zu den \u00dcberlebenden sprechen,", "tokens": ["Wir", "wol\u00b7len", "durch", "die", "Blu\u00b7me", "zu", "den", "\u00dc\u00b7berl\u00b7e\u00b7ben\u00b7den", "spre\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPR", "ART", "NN", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+--+-", "measure": "iambic.septa.relaxed"}, "line.2": {"text": "Wie wir so oft zu den nunmehr verwesten sprachen.", "tokens": ["Wie", "wir", "so", "oft", "zu", "den", "nun\u00b7mehr", "ver\u00b7wes\u00b7ten", "spra\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "ADV", "APPR", "ART", "ADV", "VVFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Also, meine liebe Leibf\u00fcchsin:", "tokens": ["Al\u00b7so", ",", "mei\u00b7ne", "lie\u00b7be", "Leib\u00b7f\u00fcc\u00b7hsin", ":"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PPOSAT", "ADJA", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Du kommst mir deine Blume \u2013 Prost! Blume!", "tokens": ["Du", "kommst", "mir", "dei\u00b7ne", "Blu\u00b7me", "\u2013", "Prost", "!", "Blu\u00b7me", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PPOSAT", "NN", "$(", "NN", "$.", "NN", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.10": {"line.1": {"text": "Der Spiegel zittert.", "tokens": ["Der", "Spie\u00b7gel", "zit\u00b7tert", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.2": {"text": "Seine Oberfl\u00e4che kr\u00e4uselt sich, weil ich lache.", "tokens": ["Sei\u00b7ne", "O\u00b7berf\u00b7l\u00e4\u00b7che", "kr\u00e4u\u00b7selt", "sich", ",", "weil", "ich", "la\u00b7che", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PRF", "$,", "KOUS", "PPER", "VVFIN", "$."], "meter": "+-+-+-+--+-+-", "measure": "trochaic.hexa.relaxed"}, "line.3": {"text": "Da ist der Mond \u2013 er tritt aus dem Spiegel in feuriger R\u00fcstung", "tokens": ["Da", "ist", "der", "Mond", "\u2013", "er", "tritt", "aus", "dem", "Spie\u00b7gel", "in", "feu\u00b7ri\u00b7ger", "R\u00fcs\u00b7tung"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ART", "NN", "$(", "PPER", "VVFIN", "APPR", "ART", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+--+--+--+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Und legt seine wei\u00dfe k\u00fchle Hand auf meine fieberhei\u00dfe Stirn.", "tokens": ["Und", "legt", "sei\u00b7ne", "wei\u00b7\u00dfe", "k\u00fch\u00b7le", "Hand", "auf", "mei\u00b7ne", "fie\u00b7ber\u00b7hei\u00b7\u00dfe", "Stirn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "ADJA", "ADJA", "NN", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+--+-+-+-+-+-+-+", "measure": "iambic.octa.plus.relaxed"}}}}}