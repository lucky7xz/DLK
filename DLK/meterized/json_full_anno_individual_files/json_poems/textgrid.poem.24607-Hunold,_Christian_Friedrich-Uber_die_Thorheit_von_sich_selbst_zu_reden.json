{"textgrid.poem.24607": {"metadata": {"author": {"name": "Hunold, Christian Friedrich", "birth": "N.A.", "death": "N.A."}, "title": "Uber die Thorheit von sich selbst zu reden", "genre": "verse", "period": "N.A.", "pub_year": 1701, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Den ersten Tag/ an dem ", "tokens": ["Den", "ers\u00b7ten", "Tag", "/", "an", "dem"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["ART", "ADJA", "NN", "$(", "APPR", "ART"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Erzehlt' er mir den Lauf von seinem gantzen Leben/", "tokens": ["Er\u00b7zehlt'", "er", "mir", "den", "Lauf", "von", "sei\u00b7nem", "gant\u00b7zen", "Le\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "ART", "NN", "APPR", "PPOSAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Was sich vor langer Zeit und neulich noch begeben/", "tokens": ["Was", "sich", "vor", "lan\u00b7ger", "Zeit", "und", "neu\u00b7lich", "noch", "be\u00b7ge\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PRF", "APPR", "ADJA", "NN", "KON", "ADV", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und was ins k\u00fcnftige von ihm noch wird geschehn;", "tokens": ["Und", "was", "ins", "k\u00fcnf\u00b7ti\u00b7ge", "von", "ihm", "noch", "wird", "ge\u00b7schehn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "APPRART", "ADJA", "APPR", "PPER", "ADV", "VAFIN", "VVPP", "$."], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Was er zu vor und itzt/ ja was er hofft zu werden/", "tokens": ["Was", "er", "zu", "vor", "und", "itzt", "/", "ja", "was", "er", "hofft", "zu", "wer\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "PTKZU", "PTKVZ", "KON", "ADV", "$(", "ADV", "PWS", "PPER", "VVFIN", "PTKZU", "VAINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Sein Hau\u00df/ Gesch\u00e4fft und Geld/ und seine Freund auf Erden/", "tokens": ["Sein", "Hau\u00df", "/", "Ge\u00b7sch\u00e4fft", "und", "Geld", "/", "und", "sei\u00b7ne", "Freund", "auf", "Er\u00b7den", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$(", "NN", "KON", "NN", "$(", "KON", "PPOSAT", "NN", "APPR", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und l\u00e4\u00dfet mir die Zeit zu einer Antwort nicht.", "tokens": ["Und", "l\u00e4\u00b7\u00dfet", "mir", "die", "Zeit", "zu", "ei\u00b7ner", "Ant\u00b7wort", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ART", "NN", "APPR", "ART", "NN", "PTKNEG", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Doch wie er mehr gesagt/ als er geneigt zu h\u00f6ren/", "tokens": ["Doch", "wie", "er", "mehr", "ge\u00b7sagt", "/", "als", "er", "ge\u00b7neigt", "zu", "h\u00f6\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPER", "ADV", "VVPP", "$(", "KOUS", "PPER", "VVPP", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "So lehrt er mich auch mehr/ als er gedenckt zu lehren:", "tokens": ["So", "lehrt", "er", "mich", "auch", "mehr", "/", "als", "er", "ge\u00b7denckt", "zu", "leh\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "ADV", "ADV", "$(", "KOUS", "PPER", "VVPP", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Wie da\u00df ein Narr mit mir dem ersten Tage spricht.", "tokens": ["Wie", "da\u00df", "ein", "Narr", "mit", "mir", "dem", "ers\u00b7ten", "Ta\u00b7ge", "spricht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOKOM", "KOUS", "ART", "NN", "APPR", "PPER", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Den ersten Tag/ an dem ", "tokens": ["Den", "ers\u00b7ten", "Tag", "/", "an", "dem"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["ART", "ADJA", "NN", "$(", "APPR", "ART"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Erzehlt' er mir den Lauf von seinem gantzen Leben/", "tokens": ["Er\u00b7zehlt'", "er", "mir", "den", "Lauf", "von", "sei\u00b7nem", "gant\u00b7zen", "Le\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "ART", "NN", "APPR", "PPOSAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Was sich vor langer Zeit und neulich noch begeben/", "tokens": ["Was", "sich", "vor", "lan\u00b7ger", "Zeit", "und", "neu\u00b7lich", "noch", "be\u00b7ge\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PRF", "APPR", "ADJA", "NN", "KON", "ADV", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und was ins k\u00fcnftige von ihm noch wird geschehn;", "tokens": ["Und", "was", "ins", "k\u00fcnf\u00b7ti\u00b7ge", "von", "ihm", "noch", "wird", "ge\u00b7schehn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "APPRART", "ADJA", "APPR", "PPER", "ADV", "VAFIN", "VVPP", "$."], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Was er zu vor und itzt/ ja was er hofft zu werden/", "tokens": ["Was", "er", "zu", "vor", "und", "itzt", "/", "ja", "was", "er", "hofft", "zu", "wer\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "PTKZU", "PTKVZ", "KON", "ADV", "$(", "ADV", "PWS", "PPER", "VVFIN", "PTKZU", "VAINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Sein Hau\u00df/ Gesch\u00e4fft und Geld/ und seine Freund auf Erden/", "tokens": ["Sein", "Hau\u00df", "/", "Ge\u00b7sch\u00e4fft", "und", "Geld", "/", "und", "sei\u00b7ne", "Freund", "auf", "Er\u00b7den", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$(", "NN", "KON", "NN", "$(", "KON", "PPOSAT", "NN", "APPR", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und l\u00e4\u00dfet mir die Zeit zu einer Antwort nicht.", "tokens": ["Und", "l\u00e4\u00b7\u00dfet", "mir", "die", "Zeit", "zu", "ei\u00b7ner", "Ant\u00b7wort", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ART", "NN", "APPR", "ART", "NN", "PTKNEG", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Doch wie er mehr gesagt/ als er geneigt zu h\u00f6ren/", "tokens": ["Doch", "wie", "er", "mehr", "ge\u00b7sagt", "/", "als", "er", "ge\u00b7neigt", "zu", "h\u00f6\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPER", "ADV", "VVPP", "$(", "KOUS", "PPER", "VVPP", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "So lehrt er mich auch mehr/ als er gedenckt zu lehren:", "tokens": ["So", "lehrt", "er", "mich", "auch", "mehr", "/", "als", "er", "ge\u00b7denckt", "zu", "leh\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "ADV", "ADV", "$(", "KOUS", "PPER", "VVPP", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Wie da\u00df ein Narr mit mir dem ersten Tage spricht.", "tokens": ["Wie", "da\u00df", "ein", "Narr", "mit", "mir", "dem", "ers\u00b7ten", "Ta\u00b7ge", "spricht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOKOM", "KOUS", "ART", "NN", "APPR", "PPER", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}