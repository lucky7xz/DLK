{"textgrid.poem.55209": {"metadata": {"author": {"name": "Goethe, Johann Wolfgang", "birth": "N.A.", "death": "N.A."}, "title": "K\u00fcnstlers Fug und Recht", "genre": "verse", "period": "N.A.", "pub_year": 1792, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ein frommer Maler mit vielem Flei\u00df", "tokens": ["Ein", "from\u00b7mer", "Ma\u00b7ler", "mit", "vie\u00b7lem", "Flei\u00df"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "APPR", "PIS", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Hatte manchmal gewonnen den Preis,", "tokens": ["Hat\u00b7te", "manch\u00b7mal", "ge\u00b7won\u00b7nen", "den", "Preis", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "VVPP", "ART", "NN", "$,"], "meter": "--+--+--+", "measure": "anapaest.tri.plus"}, "line.3": {"text": "Und manchmal lie\u00df er's auch geschehn,", "tokens": ["Und", "manch\u00b7mal", "lie\u00df", "er's", "auch", "ge\u00b7schehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PIS", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Da\u00df er einem bessern nach mu\u00dft stehn;", "tokens": ["Da\u00df", "er", "ei\u00b7nem", "bes\u00b7sern", "nach", "mu\u00dft", "stehn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "APPR", "VMFIN", "VVINF", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.5": {"text": "Hatte seine Tafeln fortgemalt,", "tokens": ["Hat\u00b7te", "sei\u00b7ne", "Ta\u00b7feln", "fort\u00b7ge\u00b7malt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.6": {"text": "Wie man sie lobt, wie man sie bezahlt.", "tokens": ["Wie", "man", "sie", "lobt", ",", "wie", "man", "sie", "be\u00b7zahlt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "PPER", "VVFIN", "$,", "PWAV", "PIS", "PPER", "VVPP", "$."], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.7": {"text": "Da kamen einige gut hinaus;", "tokens": ["Da", "ka\u00b7men", "ei\u00b7ni\u00b7ge", "gut", "hin\u00b7aus", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "ADJD", "PTKVZ", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Man baut' ihn' sogar ein Heiligenhaus.", "tokens": ["Man", "baut'", "ihn'", "so\u00b7gar", "ein", "Hei\u00b7li\u00b7gen\u00b7haus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "ADV", "ART", "NN", "$."], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}}, "stanza.2": {"line.1": {"text": "Nun fand er Gelegenheit einmal,", "tokens": ["Nun", "fand", "er", "Ge\u00b7le\u00b7gen\u00b7heit", "ein\u00b7mal", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "NN", "ADV", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Zu malen eine Wand im Saal;", "tokens": ["Zu", "ma\u00b7len", "ei\u00b7ne", "Wand", "im", "Saal", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mit emsigen Z\u00fcgen er staffiert',", "tokens": ["Mit", "em\u00b7si\u00b7gen", "Z\u00fc\u00b7gen", "er", "staf\u00b7fiert'", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "PPER", "VVFIN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Was \u00f6fters in der Welt passiert;", "tokens": ["Was", "\u00f6f\u00b7ters", "in", "der", "Welt", "pas\u00b7siert", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Zog seinen Umri\u00df leicht und klar,", "tokens": ["Zog", "sei\u00b7nen", "Um\u00b7ri\u00df", "leicht", "und", "klar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-----+", "measure": "dactylic.init"}, "line.6": {"text": "Man konnte sehn, was gemeint da war.", "tokens": ["Man", "konn\u00b7te", "sehn", ",", "was", "ge\u00b7meint", "da", "war", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "VVINF", "$,", "PRELS", "VVPP", "ADV", "VAFIN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.3": {"line.1": {"text": "Mit wenig Farben er koloriert',", "tokens": ["Mit", "we\u00b7nig", "Far\u00b7ben", "er", "ko\u00b7lo\u00b7riert'", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "PPER", "VVFIN", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.2": {"text": "Doch so, da\u00df er das Aug frappiert'.", "tokens": ["Doch", "so", ",", "da\u00df", "er", "das", "Aug", "frap\u00b7piert'", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$,", "KOUS", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Er glaubt' es f\u00fcr den Platz gerecht", "tokens": ["Er", "glaubt'", "es", "f\u00fcr", "den", "Platz", "ge\u00b7recht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "ART", "NN", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und nicht zu gut und nicht zu schlecht,", "tokens": ["Und", "nicht", "zu", "gut", "und", "nicht", "zu", "schlecht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "PTKA", "ADJD", "KON", "PTKNEG", "PTKA", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Da\u00df es versammelte Herrn und Fraun", "tokens": ["Da\u00df", "es", "ver\u00b7sam\u00b7mel\u00b7te", "Herrn", "und", "Fraun"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "VVFIN", "NN", "KON", "NN"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.6": {"text": "M\u00f6chten einmal mit Lust beschaun;", "tokens": ["M\u00f6ch\u00b7ten", "ein\u00b7mal", "mit", "Lust", "be\u00b7schaun", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "APPR", "NN", "VVINF", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.7": {"text": "Zugleich er auch noch w\u00fcnscht' und wollt,", "tokens": ["Zu\u00b7gleich", "er", "auch", "noch", "w\u00fcnscht'", "und", "wollt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "ADV", "ADV", "VVFIN", "KON", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Da\u00df man dabei was denken sollt.", "tokens": ["Da\u00df", "man", "da\u00b7bei", "was", "den\u00b7ken", "sollt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PAV", "PIS", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Als nun die Arbeit fertig war,", "tokens": ["Als", "nun", "die", "Ar\u00b7beit", "fer\u00b7tig", "war", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da trat herein manch Freundespaar,", "tokens": ["Da", "trat", "her\u00b7ein", "manch", "Freun\u00b7de\u00b7spaar", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PTKVZ", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Das unsers K\u00fcnstlers Werke liebt", "tokens": ["Das", "un\u00b7sers", "K\u00fcnst\u00b7lers", "Wer\u00b7ke", "liebt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und darum desto mehr betr\u00fcbt,", "tokens": ["Und", "da\u00b7rum", "des\u00b7to", "mehr", "be\u00b7tr\u00fcbt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PAV", "ADV", "ADV", "VVPP", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.5": {"text": "Da\u00df an der losen, leidigen Wand", "tokens": ["Da\u00df", "an", "der", "lo\u00b7sen", ",", "lei\u00b7di\u00b7gen", "Wand"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["KOUS", "APPR", "ART", "VVINF", "$,", "ADJA", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.6": {"text": "Nicht auch ein G\u00f6tterbildnis stand.", "tokens": ["Nicht", "auch", "ein", "G\u00f6t\u00b7ter\u00b7bild\u00b7nis", "stand", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Die setzten ihn sogleich zur Red,", "tokens": ["Die", "setz\u00b7ten", "ihn", "sog\u00b7leich", "zur", "Red", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADV", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Warum er so was malen t\u00e4t,", "tokens": ["Wa\u00b7rum", "er", "so", "was", "ma\u00b7len", "t\u00e4t", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "PIS", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Da doch der Saal und seine W\u00e4nd", "tokens": ["Da", "doch", "der", "Saal", "und", "sei\u00b7ne", "W\u00e4nd"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "ART", "NN", "KON", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Geh\u00f6rten nur f\u00fcr Narrenh\u00e4nd;", "tokens": ["Ge\u00b7h\u00f6r\u00b7ten", "nur", "f\u00fcr", "Nar\u00b7ren\u00b7h\u00e4nd", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "APPR", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Er sollte sich nicht lassen verf\u00fchren", "tokens": ["Er", "soll\u00b7te", "sich", "nicht", "las\u00b7sen", "ver\u00b7f\u00fch\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PRF", "PTKNEG", "VVINF", "VVINF"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.12": {"text": "Und nun auch B\u00e4nk und Tische beschmieren;", "tokens": ["Und", "nun", "auch", "B\u00e4nk", "und", "Ti\u00b7sche", "be\u00b7schmie\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.13": {"text": "Er sollte bei seinen Tafeln bleiben", "tokens": ["Er", "soll\u00b7te", "bei", "sei\u00b7nen", "Ta\u00b7feln", "blei\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "APPR", "PPOSAT", "NN", "VVINF"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.14": {"text": "Und h\u00fcbsch mit seinem Pinsel schreiben;", "tokens": ["Und", "h\u00fcbsch", "mit", "sei\u00b7nem", "Pin\u00b7sel", "schrei\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "Und sagten ihm von dieser Art", "tokens": ["Und", "sag\u00b7ten", "ihm", "von", "die\u00b7ser", "Art"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Noch viel Verbindlichs in den Bart.", "tokens": ["Noch", "viel", "Ver\u00b7bind\u00b7lichs", "in", "den", "Bart", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Er sprach darauf bescheidentlich:", "tokens": ["Er", "sprach", "da\u00b7rauf", "be\u00b7schei\u00b7dent\u00b7lich", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PAV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u00bbeure gute Meinung besch\u00e4met mich.", "tokens": ["\u00bb", "eu\u00b7re", "gu\u00b7te", "Mei\u00b7nung", "be\u00b7sch\u00e4\u00b7met", "mich", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPOSAT", "ADJA", "NN", "VVFIN", "PPER", "$."], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Es freut mich mehr nichts auf der Welt,", "tokens": ["Es", "freut", "mich", "mehr", "nichts", "auf", "der", "Welt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "PIS", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Als wenn euch je mein Werk gef\u00e4llt.", "tokens": ["Als", "wenn", "euch", "je", "mein", "Werk", "ge\u00b7f\u00e4llt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "PPER", "ADV", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Da aber aus eigenem Beruf", "tokens": ["Da", "a\u00b7ber", "aus", "ei\u00b7ge\u00b7nem", "Be\u00b7ruf"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "APPR", "ADJA", "NN"], "meter": "-+--+---+", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Gott der Herr allerlei Tier' erschuf,", "tokens": ["Gott", "der", "Herr", "al\u00b7ler\u00b7lei", "Tier'", "er\u00b7schuf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "PIAT", "NN", "VVFIN", "$,"], "meter": "+-+--+--+", "measure": "trochaic.tetra.relaxed"}, "line.7": {"text": "Da\u00df auch sogar das w\u00fcste Schwein,", "tokens": ["Da\u00df", "auch", "so\u00b7gar", "das", "w\u00fcs\u00b7te", "Schwein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Kr\u00f6ten und Schlangen vom Herren sein,", "tokens": ["Kr\u00f6\u00b7ten", "und", "Schlan\u00b7gen", "vom", "Her\u00b7ren", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "APPRART", "NN", "VAINF", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.9": {"text": "Und er auch manches nur ebauchiert", "tokens": ["Und", "er", "auch", "man\u00b7ches", "nur", "e\u00b7bauc\u00b7hiert"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "ADV", "PIS", "ADV", "VVPP"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.10": {"text": "Und gerade nicht alles ausgef\u00fchrt", "tokens": ["Und", "ge\u00b7ra\u00b7de", "nicht", "al\u00b7les", "aus\u00b7ge\u00b7f\u00fchrt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "PTKNEG", "PIS", "VVPP"], "meter": "--+--+-+-+", "measure": "anapaest.di.plus"}, "line.11": {"text": "(wie man den Menschen denn selbst nicht scharf", "tokens": ["(", "wie", "man", "den", "Men\u00b7schen", "denn", "selbst", "nicht", "scharf"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "PWAV", "PIS", "ART", "NN", "KON", "ADV", "PTKNEG", "VVFIN"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.12": {"text": "Und nur en gros betrachten darf):", "tokens": ["Und", "nur", "en", "gros", "be\u00b7trach\u00b7ten", "darf", ")", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ADV", "FM", "ADJD", "VVINF", "VMFIN", "$(", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "So hab ich als ein armer Knecht", "tokens": ["So", "hab", "ich", "als", "ein", "ar\u00b7mer", "Knecht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "KOUS", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Vom s\u00fcndlich menschlichen Geschlecht", "tokens": ["Vom", "s\u00fcnd\u00b7lich", "menschli\u00b7chen", "Ge\u00b7schlecht"], "token_info": ["word", "word", "word", "word"], "pos": ["APPRART", "ADJD", "ADJA", "NN"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.15": {"text": "Von Jugend auf allerlei Lust gesp\u00fcrt", "tokens": ["Von", "Ju\u00b7gend", "auf", "al\u00b7ler\u00b7lei", "Lust", "ge\u00b7sp\u00fcrt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "APPR", "PIAT", "NN", "VVPP"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.16": {"text": "Und mich in allerlei exerziert,", "tokens": ["Und", "mich", "in", "al\u00b7ler\u00b7lei", "ex\u00b7er\u00b7ziert", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.17": {"text": "Und so durch \u00dcbung und durch Gl\u00fcck", "tokens": ["Und", "so", "durch", "\u00dc\u00b7bung", "und", "durch", "Gl\u00fcck"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "APPR", "NN", "KON", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.18": {"text": "Gelang mir, sagt ihr, manches St\u00fcck.", "tokens": ["Ge\u00b7lang", "mir", ",", "sagt", "ihr", ",", "man\u00b7ches", "St\u00fcck", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "PPER", "$,", "VVFIN", "PPER", "$,", "PIAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "Nun d\u00e4cht ich, nach vielem Rennen und Laufen", "tokens": ["Nun", "d\u00e4cht", "ich", ",", "nach", "vie\u00b7lem", "Ren\u00b7nen", "und", "Lau\u00b7fen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "$,", "APPR", "PIS", "NN", "KON", "NN"], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.20": {"text": "D\u00fcrft einer auch einmal verschnaufen,", "tokens": ["D\u00fcrft", "ei\u00b7ner", "auch", "ein\u00b7mal", "ver\u00b7schnau\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIS", "ADV", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.21": {"text": "Ohne da\u00df jeder gleich, der wohl ihm wollt,", "tokens": ["Oh\u00b7ne", "da\u00df", "je\u00b7der", "gleich", ",", "der", "wohl", "ihm", "wollt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "KOUS", "PIS", "ADV", "$,", "PRELS", "ADV", "PPER", "VMFIN", "$,"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.22": {"text": "Ihn 'nen faulen Bengel hei\u00dfen sollt.", "tokens": ["Ihn", "'nen", "fau\u00b7len", "Ben\u00b7gel", "hei\u00b7\u00dfen", "sollt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "ADJA", "NN", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.6": {"line.1": {"text": "Drum ist mein Wort zu dieser Frist,", "tokens": ["Drum", "ist", "mein", "Wort", "zu", "die\u00b7ser", "Frist", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "PPOSAT", "NN", "APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wie's allezeit gewesen ist:", "tokens": ["Wie's", "al\u00b7le\u00b7zeit", "ge\u00b7we\u00b7sen", "ist", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "VAPP", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mit keiner Arbeit hab ich geprahlt,", "tokens": ["Mit", "kei\u00b7ner", "Ar\u00b7beit", "hab", "ich", "ge\u00b7prahlt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VAFIN", "PPER", "VVPP", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Und was ich gemalt hab, hab ich gemalt.\u00ab", "tokens": ["Und", "was", "ich", "ge\u00b7malt", "hab", ",", "hab", "ich", "ge\u00b7malt", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["KON", "PWS", "PPER", "VVPP", "VAFIN", "$,", "VAFIN", "PPER", "VVPP", "$.", "$("], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}}, "stanza.7": {"line.1": {"text": "Ein frommer Maler mit vielem Flei\u00df", "tokens": ["Ein", "from\u00b7mer", "Ma\u00b7ler", "mit", "vie\u00b7lem", "Flei\u00df"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "APPR", "PIS", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Hatte manchmal gewonnen den Preis,", "tokens": ["Hat\u00b7te", "manch\u00b7mal", "ge\u00b7won\u00b7nen", "den", "Preis", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "VVPP", "ART", "NN", "$,"], "meter": "--+--+--+", "measure": "anapaest.tri.plus"}, "line.3": {"text": "Und manchmal lie\u00df er's auch geschehn,", "tokens": ["Und", "manch\u00b7mal", "lie\u00df", "er's", "auch", "ge\u00b7schehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PIS", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Da\u00df er einem bessern nach mu\u00dft stehn;", "tokens": ["Da\u00df", "er", "ei\u00b7nem", "bes\u00b7sern", "nach", "mu\u00dft", "stehn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "APPR", "VMFIN", "VVINF", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.5": {"text": "Hatte seine Tafeln fortgemalt,", "tokens": ["Hat\u00b7te", "sei\u00b7ne", "Ta\u00b7feln", "fort\u00b7ge\u00b7malt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.6": {"text": "Wie man sie lobt, wie man sie bezahlt.", "tokens": ["Wie", "man", "sie", "lobt", ",", "wie", "man", "sie", "be\u00b7zahlt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "PPER", "VVFIN", "$,", "PWAV", "PIS", "PPER", "VVPP", "$."], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.7": {"text": "Da kamen einige gut hinaus;", "tokens": ["Da", "ka\u00b7men", "ei\u00b7ni\u00b7ge", "gut", "hin\u00b7aus", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "ADJD", "PTKVZ", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Man baut' ihn' sogar ein Heiligenhaus.", "tokens": ["Man", "baut'", "ihn'", "so\u00b7gar", "ein", "Hei\u00b7li\u00b7gen\u00b7haus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "ADV", "ART", "NN", "$."], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}}, "stanza.8": {"line.1": {"text": "Nun fand er Gelegenheit einmal,", "tokens": ["Nun", "fand", "er", "Ge\u00b7le\u00b7gen\u00b7heit", "ein\u00b7mal", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "NN", "ADV", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Zu malen eine Wand im Saal;", "tokens": ["Zu", "ma\u00b7len", "ei\u00b7ne", "Wand", "im", "Saal", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mit emsigen Z\u00fcgen er staffiert',", "tokens": ["Mit", "em\u00b7si\u00b7gen", "Z\u00fc\u00b7gen", "er", "staf\u00b7fiert'", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "PPER", "VVFIN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Was \u00f6fters in der Welt passiert;", "tokens": ["Was", "\u00f6f\u00b7ters", "in", "der", "Welt", "pas\u00b7siert", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Zog seinen Umri\u00df leicht und klar,", "tokens": ["Zog", "sei\u00b7nen", "Um\u00b7ri\u00df", "leicht", "und", "klar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-----+", "measure": "dactylic.init"}, "line.6": {"text": "Man konnte sehn, was gemeint da war.", "tokens": ["Man", "konn\u00b7te", "sehn", ",", "was", "ge\u00b7meint", "da", "war", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "VVINF", "$,", "PRELS", "VVPP", "ADV", "VAFIN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.9": {"line.1": {"text": "Mit wenig Farben er koloriert',", "tokens": ["Mit", "we\u00b7nig", "Far\u00b7ben", "er", "ko\u00b7lo\u00b7riert'", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "PPER", "VVFIN", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.2": {"text": "Doch so, da\u00df er das Aug frappiert'.", "tokens": ["Doch", "so", ",", "da\u00df", "er", "das", "Aug", "frap\u00b7piert'", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$,", "KOUS", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Er glaubt' es f\u00fcr den Platz gerecht", "tokens": ["Er", "glaubt'", "es", "f\u00fcr", "den", "Platz", "ge\u00b7recht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "ART", "NN", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und nicht zu gut und nicht zu schlecht,", "tokens": ["Und", "nicht", "zu", "gut", "und", "nicht", "zu", "schlecht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "PTKA", "ADJD", "KON", "PTKNEG", "PTKA", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Da\u00df es versammelte Herrn und Fraun", "tokens": ["Da\u00df", "es", "ver\u00b7sam\u00b7mel\u00b7te", "Herrn", "und", "Fraun"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "VVFIN", "NN", "KON", "NN"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.6": {"text": "M\u00f6chten einmal mit Lust beschaun;", "tokens": ["M\u00f6ch\u00b7ten", "ein\u00b7mal", "mit", "Lust", "be\u00b7schaun", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "APPR", "NN", "VVINF", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.7": {"text": "Zugleich er auch noch w\u00fcnscht' und wollt,", "tokens": ["Zu\u00b7gleich", "er", "auch", "noch", "w\u00fcnscht'", "und", "wollt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "ADV", "ADV", "VVFIN", "KON", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Da\u00df man dabei was denken sollt.", "tokens": ["Da\u00df", "man", "da\u00b7bei", "was", "den\u00b7ken", "sollt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PAV", "PIS", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Als nun die Arbeit fertig war,", "tokens": ["Als", "nun", "die", "Ar\u00b7beit", "fer\u00b7tig", "war", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da trat herein manch Freundespaar,", "tokens": ["Da", "trat", "her\u00b7ein", "manch", "Freun\u00b7de\u00b7spaar", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PTKVZ", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Das unsers K\u00fcnstlers Werke liebt", "tokens": ["Das", "un\u00b7sers", "K\u00fcnst\u00b7lers", "Wer\u00b7ke", "liebt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und darum desto mehr betr\u00fcbt,", "tokens": ["Und", "da\u00b7rum", "des\u00b7to", "mehr", "be\u00b7tr\u00fcbt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PAV", "ADV", "ADV", "VVPP", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.5": {"text": "Da\u00df an der losen, leidigen Wand", "tokens": ["Da\u00df", "an", "der", "lo\u00b7sen", ",", "lei\u00b7di\u00b7gen", "Wand"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["KOUS", "APPR", "ART", "VVINF", "$,", "ADJA", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.6": {"text": "Nicht auch ein G\u00f6tterbildnis stand.", "tokens": ["Nicht", "auch", "ein", "G\u00f6t\u00b7ter\u00b7bild\u00b7nis", "stand", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Die setzten ihn sogleich zur Red,", "tokens": ["Die", "setz\u00b7ten", "ihn", "sog\u00b7leich", "zur", "Red", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADV", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Warum er so was malen t\u00e4t,", "tokens": ["Wa\u00b7rum", "er", "so", "was", "ma\u00b7len", "t\u00e4t", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "PIS", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Da doch der Saal und seine W\u00e4nd", "tokens": ["Da", "doch", "der", "Saal", "und", "sei\u00b7ne", "W\u00e4nd"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "ART", "NN", "KON", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Geh\u00f6rten nur f\u00fcr Narrenh\u00e4nd;", "tokens": ["Ge\u00b7h\u00f6r\u00b7ten", "nur", "f\u00fcr", "Nar\u00b7ren\u00b7h\u00e4nd", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "APPR", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Er sollte sich nicht lassen verf\u00fchren", "tokens": ["Er", "soll\u00b7te", "sich", "nicht", "las\u00b7sen", "ver\u00b7f\u00fch\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PRF", "PTKNEG", "VVINF", "VVINF"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.12": {"text": "Und nun auch B\u00e4nk und Tische beschmieren;", "tokens": ["Und", "nun", "auch", "B\u00e4nk", "und", "Ti\u00b7sche", "be\u00b7schmie\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.13": {"text": "Er sollte bei seinen Tafeln bleiben", "tokens": ["Er", "soll\u00b7te", "bei", "sei\u00b7nen", "Ta\u00b7feln", "blei\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "APPR", "PPOSAT", "NN", "VVINF"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.14": {"text": "Und h\u00fcbsch mit seinem Pinsel schreiben;", "tokens": ["Und", "h\u00fcbsch", "mit", "sei\u00b7nem", "Pin\u00b7sel", "schrei\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "Und sagten ihm von dieser Art", "tokens": ["Und", "sag\u00b7ten", "ihm", "von", "die\u00b7ser", "Art"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Noch viel Verbindlichs in den Bart.", "tokens": ["Noch", "viel", "Ver\u00b7bind\u00b7lichs", "in", "den", "Bart", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Er sprach darauf bescheidentlich:", "tokens": ["Er", "sprach", "da\u00b7rauf", "be\u00b7schei\u00b7dent\u00b7lich", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PAV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u00bbeure gute Meinung besch\u00e4met mich.", "tokens": ["\u00bb", "eu\u00b7re", "gu\u00b7te", "Mei\u00b7nung", "be\u00b7sch\u00e4\u00b7met", "mich", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPOSAT", "ADJA", "NN", "VVFIN", "PPER", "$."], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Es freut mich mehr nichts auf der Welt,", "tokens": ["Es", "freut", "mich", "mehr", "nichts", "auf", "der", "Welt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "PIS", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Als wenn euch je mein Werk gef\u00e4llt.", "tokens": ["Als", "wenn", "euch", "je", "mein", "Werk", "ge\u00b7f\u00e4llt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "PPER", "ADV", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Da aber aus eigenem Beruf", "tokens": ["Da", "a\u00b7ber", "aus", "ei\u00b7ge\u00b7nem", "Be\u00b7ruf"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "APPR", "ADJA", "NN"], "meter": "-+--+---+", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Gott der Herr allerlei Tier' erschuf,", "tokens": ["Gott", "der", "Herr", "al\u00b7ler\u00b7lei", "Tier'", "er\u00b7schuf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "PIAT", "NN", "VVFIN", "$,"], "meter": "+-+--+--+", "measure": "trochaic.tetra.relaxed"}, "line.7": {"text": "Da\u00df auch sogar das w\u00fcste Schwein,", "tokens": ["Da\u00df", "auch", "so\u00b7gar", "das", "w\u00fcs\u00b7te", "Schwein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Kr\u00f6ten und Schlangen vom Herren sein,", "tokens": ["Kr\u00f6\u00b7ten", "und", "Schlan\u00b7gen", "vom", "Her\u00b7ren", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "APPRART", "NN", "VAINF", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.9": {"text": "Und er auch manches nur ebauchiert", "tokens": ["Und", "er", "auch", "man\u00b7ches", "nur", "e\u00b7bauc\u00b7hiert"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "ADV", "PIS", "ADV", "VVPP"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.10": {"text": "Und gerade nicht alles ausgef\u00fchrt", "tokens": ["Und", "ge\u00b7ra\u00b7de", "nicht", "al\u00b7les", "aus\u00b7ge\u00b7f\u00fchrt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "PTKNEG", "PIS", "VVPP"], "meter": "--+--+-+-+", "measure": "anapaest.di.plus"}, "line.11": {"text": "(wie man den Menschen denn selbst nicht scharf", "tokens": ["(", "wie", "man", "den", "Men\u00b7schen", "denn", "selbst", "nicht", "scharf"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "PWAV", "PIS", "ART", "NN", "KON", "ADV", "PTKNEG", "VVFIN"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.12": {"text": "Und nur en gros betrachten darf):", "tokens": ["Und", "nur", "en", "gros", "be\u00b7trach\u00b7ten", "darf", ")", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ADV", "FM", "ADJD", "VVINF", "VMFIN", "$(", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "So hab ich als ein armer Knecht", "tokens": ["So", "hab", "ich", "als", "ein", "ar\u00b7mer", "Knecht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "KOUS", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Vom s\u00fcndlich menschlichen Geschlecht", "tokens": ["Vom", "s\u00fcnd\u00b7lich", "menschli\u00b7chen", "Ge\u00b7schlecht"], "token_info": ["word", "word", "word", "word"], "pos": ["APPRART", "ADJD", "ADJA", "NN"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.15": {"text": "Von Jugend auf allerlei Lust gesp\u00fcrt", "tokens": ["Von", "Ju\u00b7gend", "auf", "al\u00b7ler\u00b7lei", "Lust", "ge\u00b7sp\u00fcrt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "APPR", "PIAT", "NN", "VVPP"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.16": {"text": "Und mich in allerlei exerziert,", "tokens": ["Und", "mich", "in", "al\u00b7ler\u00b7lei", "ex\u00b7er\u00b7ziert", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.17": {"text": "Und so durch \u00dcbung und durch Gl\u00fcck", "tokens": ["Und", "so", "durch", "\u00dc\u00b7bung", "und", "durch", "Gl\u00fcck"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "APPR", "NN", "KON", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.18": {"text": "Gelang mir, sagt ihr, manches St\u00fcck.", "tokens": ["Ge\u00b7lang", "mir", ",", "sagt", "ihr", ",", "man\u00b7ches", "St\u00fcck", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "PPER", "$,", "VVFIN", "PPER", "$,", "PIAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "Nun d\u00e4cht ich, nach vielem Rennen und Laufen", "tokens": ["Nun", "d\u00e4cht", "ich", ",", "nach", "vie\u00b7lem", "Ren\u00b7nen", "und", "Lau\u00b7fen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "$,", "APPR", "PIS", "NN", "KON", "NN"], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.20": {"text": "D\u00fcrft einer auch einmal verschnaufen,", "tokens": ["D\u00fcrft", "ei\u00b7ner", "auch", "ein\u00b7mal", "ver\u00b7schnau\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIS", "ADV", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.21": {"text": "Ohne da\u00df jeder gleich, der wohl ihm wollt,", "tokens": ["Oh\u00b7ne", "da\u00df", "je\u00b7der", "gleich", ",", "der", "wohl", "ihm", "wollt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "KOUS", "PIS", "ADV", "$,", "PRELS", "ADV", "PPER", "VMFIN", "$,"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.22": {"text": "Ihn 'nen faulen Bengel hei\u00dfen sollt.", "tokens": ["Ihn", "'nen", "fau\u00b7len", "Ben\u00b7gel", "hei\u00b7\u00dfen", "sollt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "ADJA", "NN", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.12": {"line.1": {"text": "Drum ist mein Wort zu dieser Frist,", "tokens": ["Drum", "ist", "mein", "Wort", "zu", "die\u00b7ser", "Frist", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "PPOSAT", "NN", "APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wie's allezeit gewesen ist:", "tokens": ["Wie's", "al\u00b7le\u00b7zeit", "ge\u00b7we\u00b7sen", "ist", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "VAPP", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mit keiner Arbeit hab ich geprahlt,", "tokens": ["Mit", "kei\u00b7ner", "Ar\u00b7beit", "hab", "ich", "ge\u00b7prahlt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VAFIN", "PPER", "VVPP", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Und was ich gemalt hab, hab ich gemalt.\u00ab", "tokens": ["Und", "was", "ich", "ge\u00b7malt", "hab", ",", "hab", "ich", "ge\u00b7malt", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["KON", "PWS", "PPER", "VVPP", "VAFIN", "$,", "VAFIN", "PPER", "VVPP", "$.", "$("], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}}}}}