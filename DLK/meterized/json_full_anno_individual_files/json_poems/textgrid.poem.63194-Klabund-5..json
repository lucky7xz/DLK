{"textgrid.poem.63194": {"metadata": {"author": {"name": "Klabund", "birth": "N.A.", "death": "N.A."}, "title": "5.", "genre": "verse", "period": "N.A.", "pub_year": 1909, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ich stopfe dir mein Taschentuch in die Wunde", "tokens": ["Ich", "stop\u00b7fe", "dir", "mein", "Ta\u00b7schen\u00b7tuch", "in", "die", "Wun\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "PPOSAT", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Oder was einmal Taschentuch gewesen.", "tokens": ["O\u00b7der", "was", "ein\u00b7mal", "Ta\u00b7schen\u00b7tuch", "ge\u00b7we\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ADV", "NN", "VAPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Gott schl\u00e4gt die elfte Stunde.", "tokens": ["Gott", "schl\u00e4gt", "die", "elf\u00b7te", "Stun\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Soll ich dir aus der Bergpredigt vorlesen?", "tokens": ["Soll", "ich", "dir", "aus", "der", "Berg\u00b7pre\u00b7digt", "vor\u00b7le\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PPER", "APPR", "ART", "NN", "VVINF", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}}, "stanza.2": {"line.1": {"text": "Liebet euch untereinander. Ich hab nie gewagt", "tokens": ["Lie\u00b7bet", "euch", "un\u00b7ter\u00b7ein\u00b7an\u00b7der", ".", "Ich", "hab", "nie", "ge\u00b7wagt"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "$.", "PPER", "VAFIN", "ADV", "VVPP"], "meter": "+--+--+-+-+-+", "measure": "dactylic.di.plus"}, "line.2": {"text": "Jemand zu lieben: wie ich liebe jetzt dich, halbtoter Freund.", "tokens": ["Je\u00b7mand", "zu", "lie\u00b7ben", ":", "wie", "ich", "lie\u00b7be", "jetzt", "dich", ",", "halb\u00b7to\u00b7ter", "Freund", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PIS", "PTKZU", "VVINF", "$.", "PWAV", "PPER", "VVFIN", "ADV", "PPER", "$,", "ADJA", "NN", "$."], "meter": "+--+-+-+--+-+-+", "measure": "iambic.septa.invert"}, "line.3": {"text": "Und du bist doch nur ein Hund, der auf fremden Feldern streunt", "tokens": ["Und", "du", "bist", "doch", "nur", "ein", "Hund", ",", "der", "auf", "frem\u00b7den", "Fel\u00b7dern", "streunt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VAFIN", "ADV", "ADV", "ART", "NN", "$,", "PRELS", "APPR", "ADJA", "NN", "VVFIN"], "meter": "+-+-+-+--+-+-+", "measure": "trochaic.septa.relaxed"}, "line.4": {"text": "Und (wie nach Kaninchen) nach letzter Liebe jagt.", "tokens": ["Und", "(", "wie", "nach", "Ka\u00b7nin\u00b7chen", ")", "nach", "letz\u00b7ter", "Lie\u00b7be", "jagt", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$(", "KOKOM", "APPR", "NN", "$(", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}}, "stanza.3": {"line.1": {"text": "R\u00e4udiger Hund. Wir sind alle von Ungeziefer zerzaust.", "tokens": ["R\u00e4u\u00b7di\u00b7ger", "Hund", ".", "Wir", "sind", "al\u00b7le", "von", "Un\u00b7ge\u00b7zie\u00b7fer", "zer\u00b7zaust", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$.", "PPER", "VAFIN", "PIS", "APPR", "NN", "VVFIN", "$."], "meter": "+--+--+--+-+--+", "measure": "dactylic.tri.plus"}, "line.2": {"text": "Ehe wir uns in den Himmel bequemen,", "tokens": ["E\u00b7he", "wir", "uns", "in", "den", "Him\u00b7mel", "be\u00b7que\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "APPR", "ART", "NN", "ADJA", "$,"], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.3": {"text": "M\u00fcssen wir ein (russisches) Dampfbad nehmen,", "tokens": ["M\u00fcs\u00b7sen", "wir", "ein", "(", "rus\u00b7si\u00b7sches", ")", "Dampf\u00b7bad", "neh\u00b7men", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NN", "PPER", "ART", "$(", "ADJA", "$(", "NN", "VVINF", "$,"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.4": {"text": "Und Gottvater selber ists, der uns laust.", "tokens": ["Und", "Gott\u00b7va\u00b7ter", "sel\u00b7ber", "ists", ",", "der", "uns", "laust", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ADV", "VAFIN", "$,", "PRELS", "PPER", "VVFIN", "$."], "meter": "-++-+-+--+", "measure": "iambic.penta.chol"}}, "stanza.4": {"line.1": {"text": "Ich stopfe dir mein Taschentuch in die Wunde", "tokens": ["Ich", "stop\u00b7fe", "dir", "mein", "Ta\u00b7schen\u00b7tuch", "in", "die", "Wun\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "PPOSAT", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Oder was einmal Taschentuch gewesen.", "tokens": ["O\u00b7der", "was", "ein\u00b7mal", "Ta\u00b7schen\u00b7tuch", "ge\u00b7we\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ADV", "NN", "VAPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Gott schl\u00e4gt die elfte Stunde.", "tokens": ["Gott", "schl\u00e4gt", "die", "elf\u00b7te", "Stun\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Soll ich dir aus der Bergpredigt vorlesen?", "tokens": ["Soll", "ich", "dir", "aus", "der", "Berg\u00b7pre\u00b7digt", "vor\u00b7le\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PPER", "APPR", "ART", "NN", "VVINF", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}}, "stanza.5": {"line.1": {"text": "Liebet euch untereinander. Ich hab nie gewagt", "tokens": ["Lie\u00b7bet", "euch", "un\u00b7ter\u00b7ein\u00b7an\u00b7der", ".", "Ich", "hab", "nie", "ge\u00b7wagt"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "$.", "PPER", "VAFIN", "ADV", "VVPP"], "meter": "+--+--+-+-+-+", "measure": "dactylic.di.plus"}, "line.2": {"text": "Jemand zu lieben: wie ich liebe jetzt dich, halbtoter Freund.", "tokens": ["Je\u00b7mand", "zu", "lie\u00b7ben", ":", "wie", "ich", "lie\u00b7be", "jetzt", "dich", ",", "halb\u00b7to\u00b7ter", "Freund", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PIS", "PTKZU", "VVINF", "$.", "PWAV", "PPER", "VVFIN", "ADV", "PPER", "$,", "ADJA", "NN", "$."], "meter": "+--+-+-+--+-+-+", "measure": "iambic.septa.invert"}, "line.3": {"text": "Und du bist doch nur ein Hund, der auf fremden Feldern streunt", "tokens": ["Und", "du", "bist", "doch", "nur", "ein", "Hund", ",", "der", "auf", "frem\u00b7den", "Fel\u00b7dern", "streunt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VAFIN", "ADV", "ADV", "ART", "NN", "$,", "PRELS", "APPR", "ADJA", "NN", "VVFIN"], "meter": "+-+-+-+--+-+-+", "measure": "trochaic.septa.relaxed"}, "line.4": {"text": "Und (wie nach Kaninchen) nach letzter Liebe jagt.", "tokens": ["Und", "(", "wie", "nach", "Ka\u00b7nin\u00b7chen", ")", "nach", "letz\u00b7ter", "Lie\u00b7be", "jagt", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$(", "KOKOM", "APPR", "NN", "$(", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}}, "stanza.6": {"line.1": {"text": "R\u00e4udiger Hund. Wir sind alle von Ungeziefer zerzaust.", "tokens": ["R\u00e4u\u00b7di\u00b7ger", "Hund", ".", "Wir", "sind", "al\u00b7le", "von", "Un\u00b7ge\u00b7zie\u00b7fer", "zer\u00b7zaust", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$.", "PPER", "VAFIN", "PIS", "APPR", "NN", "VVFIN", "$."], "meter": "+--+--+--+-+--+", "measure": "dactylic.tri.plus"}, "line.2": {"text": "Ehe wir uns in den Himmel bequemen,", "tokens": ["E\u00b7he", "wir", "uns", "in", "den", "Him\u00b7mel", "be\u00b7que\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "APPR", "ART", "NN", "ADJA", "$,"], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.3": {"text": "M\u00fcssen wir ein (russisches) Dampfbad nehmen,", "tokens": ["M\u00fcs\u00b7sen", "wir", "ein", "(", "rus\u00b7si\u00b7sches", ")", "Dampf\u00b7bad", "neh\u00b7men", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NN", "PPER", "ART", "$(", "ADJA", "$(", "NN", "VVINF", "$,"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.4": {"text": "Und Gottvater selber ists, der uns laust.", "tokens": ["Und", "Gott\u00b7va\u00b7ter", "sel\u00b7ber", "ists", ",", "der", "uns", "laust", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ADV", "VAFIN", "$,", "PRELS", "PPER", "VVFIN", "$."], "meter": "-++-+-+--+", "measure": "iambic.penta.chol"}}}}}