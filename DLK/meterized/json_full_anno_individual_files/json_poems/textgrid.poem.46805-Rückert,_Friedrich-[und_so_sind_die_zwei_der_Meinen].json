{"textgrid.poem.46805": {"metadata": {"author": {"name": "R\u00fcckert, Friedrich", "birth": "N.A.", "death": "N.A."}, "title": "[und so sind die zwei der Meinen]", "genre": "verse", "period": "N.A.", "pub_year": 1827, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Und so sind die zwei der Meinen,", "tokens": ["Und", "so", "sind", "die", "zwei", "der", "Mei\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "ART", "CARD", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Die sonst zu den Gr\u00f6\u00dfern z\u00e4hlten,", "tokens": ["Die", "sonst", "zu", "den", "Gr\u00f6\u00b7\u00dfern", "z\u00e4hl\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Als noch nicht die Kleinern fehlten,", "tokens": ["Als", "noch", "nicht", "die", "Klei\u00b7nern", "fehl\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PTKNEG", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Nun geworden zu den Kleinen.", "tokens": ["Nun", "ge\u00b7wor\u00b7den", "zu", "den", "Klei\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAPP", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Deren Stelle zu ersetzen,", "tokens": ["De\u00b7ren", "Stel\u00b7le", "zu", "er\u00b7set\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Uns des Schadens zu ergetzen,", "tokens": ["Uns", "des", "Scha\u00b7dens", "zu", "er\u00b7get\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "M\u00f6chten sie noch kleiner scheinen,", "tokens": ["M\u00f6ch\u00b7ten", "sie", "noch", "klei\u00b7ner", "schei\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "ADJD", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Und noch kindischer gebahren,", "tokens": ["Und", "noch", "kin\u00b7di\u00b7scher", "ge\u00b7bah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJD", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "Als es zusteht ihren Jahren.", "tokens": ["Als", "es", "zu\u00b7steht", "ih\u00b7ren", "Jah\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "PPOSAT", "NN", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.10": {"text": "Ja, sie m\u00f6chten mit Behagen", "tokens": ["Ja", ",", "sie", "m\u00f6ch\u00b7ten", "mit", "Be\u00b7ha\u00b7gen"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["PTKANT", "$,", "PPER", "VMFIN", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.11": {"text": "Sich auf Schultern lassen tragen,", "tokens": ["Sich", "auf", "Schul\u00b7tern", "las\u00b7sen", "tra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "NN", "VVINF", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.12": {"text": "Und mir zausen an den Haaren.", "tokens": ["Und", "mir", "zau\u00b7sen", "an", "den", "Haa\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.13": {"text": "Doch am ungelindern Zucke", "tokens": ["Doch", "am", "un\u00b7ge\u00b7lin\u00b7dern", "Zu\u00b7cke"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPRART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.14": {"text": "Merk' ich und am schwerern Drucke,", "tokens": ["Merk'", "ich", "und", "am", "schwe\u00b7rern", "Dru\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "KON", "APPRART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.15": {"text": "Da\u00df es doch nicht sind die Kleinen,", "tokens": ["Da\u00df", "es", "doch", "nicht", "sind", "die", "Klei\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PTKNEG", "VAFIN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.16": {"text": "Die sie vorzustellen meinen.", "tokens": ["Die", "sie", "vor\u00b7zu\u00b7stel\u00b7len", "mei\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVIZU", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Und so sind die zwei der Meinen,", "tokens": ["Und", "so", "sind", "die", "zwei", "der", "Mei\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "ART", "CARD", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Die sonst zu den Gr\u00f6\u00dfern z\u00e4hlten,", "tokens": ["Die", "sonst", "zu", "den", "Gr\u00f6\u00b7\u00dfern", "z\u00e4hl\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Als noch nicht die Kleinern fehlten,", "tokens": ["Als", "noch", "nicht", "die", "Klei\u00b7nern", "fehl\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PTKNEG", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Nun geworden zu den Kleinen.", "tokens": ["Nun", "ge\u00b7wor\u00b7den", "zu", "den", "Klei\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAPP", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Deren Stelle zu ersetzen,", "tokens": ["De\u00b7ren", "Stel\u00b7le", "zu", "er\u00b7set\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Uns des Schadens zu ergetzen,", "tokens": ["Uns", "des", "Scha\u00b7dens", "zu", "er\u00b7get\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "M\u00f6chten sie noch kleiner scheinen,", "tokens": ["M\u00f6ch\u00b7ten", "sie", "noch", "klei\u00b7ner", "schei\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "ADJD", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Und noch kindischer gebahren,", "tokens": ["Und", "noch", "kin\u00b7di\u00b7scher", "ge\u00b7bah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJD", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "Als es zusteht ihren Jahren.", "tokens": ["Als", "es", "zu\u00b7steht", "ih\u00b7ren", "Jah\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "PPOSAT", "NN", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.10": {"text": "Ja, sie m\u00f6chten mit Behagen", "tokens": ["Ja", ",", "sie", "m\u00f6ch\u00b7ten", "mit", "Be\u00b7ha\u00b7gen"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["PTKANT", "$,", "PPER", "VMFIN", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.11": {"text": "Sich auf Schultern lassen tragen,", "tokens": ["Sich", "auf", "Schul\u00b7tern", "las\u00b7sen", "tra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "NN", "VVINF", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.12": {"text": "Und mir zausen an den Haaren.", "tokens": ["Und", "mir", "zau\u00b7sen", "an", "den", "Haa\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.13": {"text": "Doch am ungelindern Zucke", "tokens": ["Doch", "am", "un\u00b7ge\u00b7lin\u00b7dern", "Zu\u00b7cke"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPRART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.14": {"text": "Merk' ich und am schwerern Drucke,", "tokens": ["Merk'", "ich", "und", "am", "schwe\u00b7rern", "Dru\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "KON", "APPRART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.15": {"text": "Da\u00df es doch nicht sind die Kleinen,", "tokens": ["Da\u00df", "es", "doch", "nicht", "sind", "die", "Klei\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PTKNEG", "VAFIN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.16": {"text": "Die sie vorzustellen meinen.", "tokens": ["Die", "sie", "vor\u00b7zu\u00b7stel\u00b7len", "mei\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVIZU", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}}}}