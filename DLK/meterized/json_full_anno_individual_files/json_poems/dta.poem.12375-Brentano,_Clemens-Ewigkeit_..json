{"dta.poem.12375": {"metadata": {"author": {"name": "Brentano, Clemens", "birth": "N.A.", "death": "N.A."}, "title": "Ewigkeit .", "genre": "Lyrik", "period": "N.A.", "pub_year": "1806", "urn": "urn:nbn:de:kobv:b4-20090519157", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "O Ewigkeit, o Ewigkeit!               ", "tokens": ["O", "E\u00b7wig\u00b7keit", ",", "o", "E\u00b7wig\u00b7keit", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "FM", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wie lang bist du, o Ewigkeit,", "tokens": ["Wie", "lang", "bist", "du", ",", "o", "E\u00b7wig\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VAFIN", "PPER", "$,", "FM", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Doch eilt zu dir schnell unsre Zeit,", "tokens": ["Doch", "eilt", "zu", "dir", "schnell", "uns\u00b7re", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PPER", "ADJD", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Gleich wie das Heerpferd zu dem Streit,", "tokens": ["Gleich", "wie", "das", "Heer\u00b7pferd", "zu", "dem", "Streit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Nach Haus der Bot, das Schiff zum Gestad,", "tokens": ["Nach", "Haus", "der", "Bot", ",", "das", "Schiff", "zum", "Ge\u00b7stad", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ART", "NN", "$,", "ART", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.6": {"text": "Der schnelle Pfeil vom Bogen ab.", "tokens": ["Der", "schnel\u00b7le", "Pfeil", "vom", "Bo\u00b7gen", "ab", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPRART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "O Ewigkeit, u. s. w.", "tokens": ["O", "E\u00b7wig\u00b7keit", ",", "u.", "s.", "w."], "token_info": ["word", "word", "punct", "abbreviation", "abbreviation", "abbreviation"], "pos": ["NE", "NN", "$,", "KON", "VVIMP", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.2": {"text": "Gleich wie an einer Kugel rund,", "tokens": ["Gleich", "wie", "an", "ei\u00b7ner", "Ku\u00b7gel", "rund", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "APPR", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Kein Anfang und kein End ist kund;", "tokens": ["Kein", "An\u00b7fang", "und", "kein", "End", "ist", "kund", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "KON", "PIAT", "NN", "VAFIN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Also, o Ewigkeit an dir,", "tokens": ["Al\u00b7so", ",", "o", "E\u00b7wig\u00b7keit", "an", "dir", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "FM", "NN", "APPR", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Noch Ein- noch Ausgang finden wir.", "tokens": ["Noch", "Ein", "noch", "Aus\u00b7gang", "fin\u00b7den", "wir", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "TRUNC", "KON", "NN", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "O Ewigkeit, u. s. w.", "tokens": ["O", "E\u00b7wig\u00b7keit", ",", "u.", "s.", "w."], "token_info": ["word", "word", "punct", "abbreviation", "abbreviation", "abbreviation"], "pos": ["NE", "NN", "$,", "KON", "VVIMP", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.2": {"text": "Du bist ein Ring unendlich weit,", "tokens": ["Du", "bist", "ein", "Ring", "un\u00b7end\u00b7lich", "weit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "ADJD", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Dein Mittelpunkt hei\u00dft Allezeit,", "tokens": ["Dein", "Mit\u00b7tel\u00b7punkt", "hei\u00dft", "Al\u00b7le\u00b7zeit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Niemahl der weite Umkrei\u00df dein,", "tokens": ["Nie\u00b7mahl", "der", "wei\u00b7te", "Um\u00b7krei\u00df", "dein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "PPOSAT", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.5": {"text": "Weil deiner nie kein End wird seyn.", "tokens": ["Weil", "dei\u00b7ner", "nie", "kein", "End", "wird", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "ADV", "PIAT", "NN", "VAFIN", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "O Ewigkeit, u. s. w.", "tokens": ["O", "E\u00b7wig\u00b7keit", ",", "u.", "s.", "w."], "token_info": ["word", "word", "punct", "abbreviation", "abbreviation", "abbreviation"], "pos": ["NE", "NN", "$,", "KON", "VVIMP", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.2": {"text": "Hinnehmen k\u00f6nnt ein V\u00f6glein klein,", "tokens": ["Hin\u00b7neh\u00b7men", "k\u00f6nnt", "ein", "V\u00f6\u00b7glein", "klein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "All ganzer Welt Sandk\u00f6rnlein ein:", "tokens": ["All", "gan\u00b7zer", "Welt", "Sand\u00b7k\u00f6rn\u00b7lein", "ein", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "NN", "PTKVZ", "$."], "meter": "-+-++--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Wenns nur eins n\u00e4hm all tausend Jahr,", "tokens": ["Wenns", "nur", "eins", "n\u00e4hm", "all", "tau\u00b7send", "Jahr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PIS", "VVFIN", "PIAT", "CARD", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Nach dem w\u00e4r nichts von ihr f\u00fcrwahr.", "tokens": ["Nach", "dem", "w\u00e4r", "nichts", "von", "ihr", "f\u00fcr\u00b7wahr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "VAFIN", "PIS", "APPR", "PPER", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "O Ewigkeit, u. s. w.", "tokens": ["O", "E\u00b7wig\u00b7keit", ",", "u.", "s.", "w."], "token_info": ["word", "word", "punct", "abbreviation", "abbreviation", "abbreviation"], "pos": ["NE", "NN", "$,", "KON", "VVIMP", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.2": {"text": "In dir, wenn nur all tausend Jahr", "tokens": ["In", "dir", ",", "wenn", "nur", "all", "tau\u00b7send", "Jahr"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPER", "$,", "KOUS", "ADV", "PIAT", "CARD", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ein Aug verg\u00f6\u00df ein kleine Thr\u00e4n,", "tokens": ["Ein", "Aug", "ver\u00b7g\u00f6\u00df", "ein", "klei\u00b7ne", "Thr\u00e4n", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "W\u00fcrd wachsen Wasser solche Meng,", "tokens": ["W\u00fcrd", "wach\u00b7sen", "Was\u00b7ser", "sol\u00b7che", "Meng", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJA", "NN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Da\u00df Erd und Himmel w\u00e4r zu eng.", "tokens": ["Da\u00df", "Erd", "und", "Him\u00b7mel", "w\u00e4r", "zu", "eng", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "NN", "VAFIN", "PTKA", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "O Ewigkeit, u. s. w.", "tokens": ["O", "E\u00b7wig\u00b7keit", ",", "u.", "s.", "w."], "token_info": ["word", "word", "punct", "abbreviation", "abbreviation", "abbreviation"], "pos": ["NE", "NN", "$,", "KON", "VVIMP", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.2": {"text": "Den Sand im Meer und Tropfen all,", "tokens": ["Den", "Sand", "im", "Meer", "und", "Trop\u00b7fen", "all", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "KON", "NN", "PIAT", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sind nur ein Bruch der einen Zahl;", "tokens": ["Sind", "nur", "ein", "Bruch", "der", "ei\u00b7nen", "Zahl", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "ART", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Allein schwitzt \u00fcber dir umsonst,", "tokens": ["Al\u00b7lein", "schwitzt", "\u00fc\u00b7ber", "dir", "um\u00b7sonst", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "PPER", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die tiefste Me\u00df- und Rechenkunst.", "tokens": ["Die", "tiefs\u00b7te", "Me\u00df", "und", "Re\u00b7chen\u00b7kunst", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "TRUNC", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "O Ewigkeit, u. s. w.", "tokens": ["O", "E\u00b7wig\u00b7keit", ",", "u.", "s.", "w."], "token_info": ["word", "word", "punct", "abbreviation", "abbreviation", "abbreviation"], "pos": ["NE", "NN", "$,", "KON", "VVIMP", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.2": {"text": "H\u00f6r Mensch: So lange Gott wird seyn,", "tokens": ["H\u00f6r", "Mensch", ":", "So", "lan\u00b7ge", "Gott", "wird", "seyn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$.", "ADV", "ADV", "NN", "VAFIN", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So lang wird seyn der H\u00f6llen Pein,", "tokens": ["So", "lang", "wird", "seyn", "der", "H\u00f6l\u00b7len", "Pein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VAFIN", "PPOSAT", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So lang wird seyn des Himmels Freud,", "tokens": ["So", "lang", "wird", "seyn", "des", "Him\u00b7mels", "Freud", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VAFIN", "PPOSAT", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "O lange Freud, o langes Leid!", "tokens": ["O", "lan\u00b7ge", "Freud", ",", "o", "lan\u00b7ges", "Leid", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$,", "FM", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}