{"textgrid.poem.42448": {"metadata": {"author": {"name": "Liliencron, Detlev von", "birth": "N.A.", "death": "N.A."}, "title": "1L: Als ich heut' im Hufnershaus", "genre": "verse", "period": "N.A.", "pub_year": 1876, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Als ich heut' im Hufnershaus", "tokens": ["Als", "ich", "heut'", "im", "Huf\u00b7ners\u00b7haus"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "APPRART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Lebewohl genommen", "tokens": ["Le\u00b7be\u00b7wohl", "ge\u00b7nom\u00b7men"], "token_info": ["word", "word"], "pos": ["NN", "VVPP"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Und ins Freie trat hinaus,", "tokens": ["Und", "ins", "Frei\u00b7e", "trat", "hin\u00b7aus", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "NN", "VVFIN", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "War die Nacht gekommen.", "tokens": ["War", "die", "Nacht", "ge\u00b7kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.2": {"line.1": {"text": "Sehen konnt' ich keinen Schritt,", "tokens": ["Se\u00b7hen", "konnt'", "ich", "kei\u00b7nen", "Schritt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "VMFIN", "PPER", "PIAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Nirgends Mond und Sterne.", "tokens": ["Nir\u00b7gends", "Mond", "und", "Ster\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "KON", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Spricht mein Gastfreund: Hans soll mit", "tokens": ["Spricht", "mein", "Gast\u00b7freund", ":", "Hans", "soll", "mit"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "PPOSAT", "NN", "$.", "NE", "VMFIN", "APPR"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und die Stalllaterne.", "tokens": ["Und", "die", "Stall\u00b7la\u00b7ter\u00b7ne", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.3": {"line.1": {"text": "Hans, der greise, taube Knecht,", "tokens": ["Hans", ",", "der", "grei\u00b7se", ",", "tau\u00b7be", "Knecht", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "PRELS", "ADJD", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Krippen, Spinneweben,", "tokens": ["Krip\u00b7pen", ",", "Spin\u00b7ne\u00b7we\u00b7ben", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Tenne, Licht und Drahtgeflecht \u2013", "tokens": ["Ten\u00b7ne", ",", "Licht", "und", "Draht\u00b7ge\u00b7flecht", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "NN", "KON", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "K\u00f6nnt' ein Bildchen geben.", "tokens": ["K\u00f6nnt'", "ein", "Bild\u00b7chen", "ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.4": {"line.1": {"text": "Trudchen steht dabei und lacht,", "tokens": ["Trud\u00b7chen", "steht", "da\u00b7bei", "und", "lacht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PAV", "KON", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "An der Mutter Seite.", "tokens": ["An", "der", "Mut\u00b7ter", "Sei\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Trudchen, bitt' ich, abgemacht,", "tokens": ["Trud\u00b7chen", ",", "bitt'", "ich", ",", "ab\u00b7ge\u00b7macht", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "PPER", "$,", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Gieb mir das Geleite.", "tokens": ["Gieb", "mir", "das", "Ge\u00b7lei\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.5": {"line.1": {"text": "Und des Bauern frisches Kind", "tokens": ["Und", "des", "Bau\u00b7ern", "fri\u00b7sches", "Kind"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Ist zur\u00fcckgesprungen,", "tokens": ["Ist", "zu\u00b7r\u00fcck\u00b7ge\u00b7sprun\u00b7gen", ","], "token_info": ["word", "word", "punct"], "pos": ["VAFIN", "VVPP", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Hat sich leicht ein Tuch geschwind", "tokens": ["Hat", "sich", "leicht", "ein", "Tuch", "ge\u00b7schwind"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PRF", "ADJD", "ART", "NN", "VVPP"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Um den Kopf geschlungen.", "tokens": ["Um", "den", "Kopf", "ge\u00b7schlun\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUI", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.6": {"line.1": {"text": "Reizend sah das M\u00e4del aus", "tokens": ["Rei\u00b7zend", "sah", "das", "M\u00e4\u00b7del", "aus"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVPP", "VVFIN", "ART", "NN", "APPR"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Im Geblink der Leuchte.", "tokens": ["Im", "Ge\u00b7blink", "der", "Leuch\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "$."], "meter": "--+-+-", "measure": "anapaest.init"}, "line.3": {"text": "Kaum noch hellt das Elternhaus", "tokens": ["Kaum", "noch", "hellt", "das", "El\u00b7tern\u00b7haus"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "VVFIN", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Aus der Nebelfeuchte.", "tokens": ["Aus", "der", "Ne\u00b7bel\u00b7feuch\u00b7te", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$."], "meter": "--+-+-", "measure": "anapaest.init"}}, "stanza.7": {"line.1": {"text": "Trabt der Alte uns voran,", "tokens": ["Trabt", "der", "Al\u00b7te", "uns", "vo\u00b7ran", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "PPER", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Treu, wie zwei Verirrten,", "tokens": ["Treu", ",", "wie", "zwei", "Ver\u00b7irr\u00b7ten", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KOKOM", "CARD", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Folgen wir wie L\u00e4mmer dann,", "tokens": ["Fol\u00b7gen", "wir", "wie", "L\u00e4m\u00b7mer", "dann", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "KOKOM", "NN", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "L\u00e4mmer ihrem Hirten.", "tokens": ["L\u00e4m\u00b7mer", "ih\u00b7rem", "Hir\u00b7ten", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.8": {"line.1": {"text": "Wo sich durch den Buchenstand", "tokens": ["Wo", "sich", "durch", "den", "Bu\u00b7chen\u00b7stand"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "PRF", "APPR", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Eng der Weg gewunden,", "tokens": ["Eng", "der", "Weg", "ge\u00b7wun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "ART", "NN", "VAPP", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Hat sich schleunig Hand in Hand,", "tokens": ["Hat", "sich", "schleu\u00b7nig", "Hand", "in", "Hand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PRF", "ADJD", "NN", "APPR", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Mund zu Mund gefunden.", "tokens": ["Mund", "zu", "Mund", "ge\u00b7fun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.9": {"line.1": {"text": "Finsternis und Waldesruh,", "tokens": ["Fins\u00b7ter\u00b7nis", "und", "Wal\u00b7des\u00b7ruh", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "KON", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Himmel ohne Sterne.", "tokens": ["Him\u00b7mel", "oh\u00b7ne", "Ster\u00b7ne", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Unverdrossen, immerzu", "tokens": ["Un\u00b7ver\u00b7dros\u00b7sen", ",", "im\u00b7mer\u00b7zu"], "token_info": ["word", "punct", "word"], "pos": ["NN", "$,", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wandert die Laterne.", "tokens": ["Wan\u00b7dert", "die", "La\u00b7ter\u00b7ne", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.10": {"line.1": {"text": "Trifft ihr Schimmer Ast und Baum:", "tokens": ["Trifft", "ihr", "Schim\u00b7mer", "Ast", "und", "Baum", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "NN", "KON", "NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Blinzeln tausend Augen?", "tokens": ["Blin\u00b7zeln", "tau\u00b7send", "Au\u00b7gen", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "CARD", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Wie sich, unerh\u00f6rt, ist's Traum,", "tokens": ["Wie", "sich", ",", "un\u00b7er\u00b7h\u00f6rt", ",", "ist's", "Traum", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "PRF", "$,", "ADJD", "$,", "VAFIN", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Lipp' an Lippe saugen.", "tokens": ["Lipp'", "an", "Lip\u00b7pe", "sau\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "NN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.11": {"line.1": {"text": "Z\u00f6gern wir auf unserm Gang?", "tokens": ["Z\u00f6\u00b7gern", "wir", "auf", "un\u00b7serm", "Gang", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "La\u00df den Alten eilen.", "tokens": ["La\u00df", "den", "Al\u00b7ten", "ei\u00b7len", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Ach, mein Herz im \u00dcberdrang", "tokens": ["Ach", ",", "mein", "Herz", "im", "\u00dc\u00b7ber\u00b7drang"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["ITJ", "$,", "PPOSAT", "NN", "APPRART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "M\u00f6chte weilen, weilen.", "tokens": ["M\u00f6ch\u00b7te", "wei\u00b7len", ",", "wei\u00b7len", "."], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["VMFIN", "VVINF", "$,", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.12": {"line.1": {"text": "Bis zuletzt erschrocken h\u00e4lt", "tokens": ["Bis", "zu\u00b7letzt", "er\u00b7schro\u00b7cken", "h\u00e4lt"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ADV", "VVINF", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Hans am Holzesrande.", "tokens": ["Hans", "am", "Hol\u00b7zes\u00b7ran\u00b7de", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "APPRART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Lichtscheu unter'm Laubgezelt", "tokens": ["Licht\u00b7scheu", "un\u00b7ter'm", "Laub\u00b7ge\u00b7zelt"], "token_info": ["word", "word", "word"], "pos": ["NN", "APPRART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Schleicht die Kontrebande.", "tokens": ["Schleicht", "die", "Kont\u00b7re\u00b7ban\u00b7de", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.13": {"line.1": {"text": "Doch nun endlich sind wir da,", "tokens": ["Doch", "nun", "end\u00b7lich", "sind", "wir", "da", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "VAFIN", "PPER", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Schrei'n ihm in die Ohren:", "tokens": ["Schrei'n", "ihm", "in", "die", "Oh\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "APPR", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Alterchen, Hallelujah,", "tokens": ["Al\u00b7ter\u00b7chen", ",", "Hal\u00b7le\u00b7lu\u00b7jah", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$,", "ITJ", "$,"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.4": {"text": "Hast uns nicht verloren.", "tokens": ["Hast", "uns", "nicht", "ver\u00b7lo\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PTKNEG", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.14": {"line.1": {"text": "Scheidegru\u00df am Meilenstein,", "tokens": ["Schei\u00b7de\u00b7gru\u00df", "am", "Mei\u00b7len\u00b7stein", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPRART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Dichtverh\u00fcllte Ferne,", "tokens": ["Dicht\u00b7ver\u00b7h\u00fcll\u00b7te", "Fer\u00b7ne", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Letzter Blitz und letzter Schein,", "tokens": ["Letz\u00b7ter", "Blitz", "und", "letz\u00b7ter", "Schein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "KON", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Fort ist die Laterne.", "tokens": ["Fort", "ist", "die", "La\u00b7ter\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "ART", "NN", "$."], "meter": "+---+-", "measure": "dactylic.init"}}, "stanza.15": {"line.1": {"text": "Als ich heut' im Hufnershaus", "tokens": ["Als", "ich", "heut'", "im", "Huf\u00b7ners\u00b7haus"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "APPRART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Lebewohl genommen", "tokens": ["Le\u00b7be\u00b7wohl", "ge\u00b7nom\u00b7men"], "token_info": ["word", "word"], "pos": ["NN", "VVPP"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Und ins Freie trat hinaus,", "tokens": ["Und", "ins", "Frei\u00b7e", "trat", "hin\u00b7aus", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "NN", "VVFIN", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "War die Nacht gekommen.", "tokens": ["War", "die", "Nacht", "ge\u00b7kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.16": {"line.1": {"text": "Sehen konnt' ich keinen Schritt,", "tokens": ["Se\u00b7hen", "konnt'", "ich", "kei\u00b7nen", "Schritt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "VMFIN", "PPER", "PIAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Nirgends Mond und Sterne.", "tokens": ["Nir\u00b7gends", "Mond", "und", "Ster\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "KON", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Spricht mein Gastfreund: Hans soll mit", "tokens": ["Spricht", "mein", "Gast\u00b7freund", ":", "Hans", "soll", "mit"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "PPOSAT", "NN", "$.", "NE", "VMFIN", "APPR"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und die Stalllaterne.", "tokens": ["Und", "die", "Stall\u00b7la\u00b7ter\u00b7ne", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.17": {"line.1": {"text": "Hans, der greise, taube Knecht,", "tokens": ["Hans", ",", "der", "grei\u00b7se", ",", "tau\u00b7be", "Knecht", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "PRELS", "ADJD", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Krippen, Spinneweben,", "tokens": ["Krip\u00b7pen", ",", "Spin\u00b7ne\u00b7we\u00b7ben", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Tenne, Licht und Drahtgeflecht \u2013", "tokens": ["Ten\u00b7ne", ",", "Licht", "und", "Draht\u00b7ge\u00b7flecht", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "NN", "KON", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "K\u00f6nnt' ein Bildchen geben.", "tokens": ["K\u00f6nnt'", "ein", "Bild\u00b7chen", "ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.18": {"line.1": {"text": "Trudchen steht dabei und lacht,", "tokens": ["Trud\u00b7chen", "steht", "da\u00b7bei", "und", "lacht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PAV", "KON", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "An der Mutter Seite.", "tokens": ["An", "der", "Mut\u00b7ter", "Sei\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Trudchen, bitt' ich, abgemacht,", "tokens": ["Trud\u00b7chen", ",", "bitt'", "ich", ",", "ab\u00b7ge\u00b7macht", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "PPER", "$,", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Gieb mir das Geleite.", "tokens": ["Gieb", "mir", "das", "Ge\u00b7lei\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.19": {"line.1": {"text": "Und des Bauern frisches Kind", "tokens": ["Und", "des", "Bau\u00b7ern", "fri\u00b7sches", "Kind"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Ist zur\u00fcckgesprungen,", "tokens": ["Ist", "zu\u00b7r\u00fcck\u00b7ge\u00b7sprun\u00b7gen", ","], "token_info": ["word", "word", "punct"], "pos": ["VAFIN", "VVPP", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Hat sich leicht ein Tuch geschwind", "tokens": ["Hat", "sich", "leicht", "ein", "Tuch", "ge\u00b7schwind"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PRF", "ADJD", "ART", "NN", "VVPP"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Um den Kopf geschlungen.", "tokens": ["Um", "den", "Kopf", "ge\u00b7schlun\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUI", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.20": {"line.1": {"text": "Reizend sah das M\u00e4del aus", "tokens": ["Rei\u00b7zend", "sah", "das", "M\u00e4\u00b7del", "aus"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVPP", "VVFIN", "ART", "NN", "APPR"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Im Geblink der Leuchte.", "tokens": ["Im", "Ge\u00b7blink", "der", "Leuch\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "$."], "meter": "--+-+-", "measure": "anapaest.init"}, "line.3": {"text": "Kaum noch hellt das Elternhaus", "tokens": ["Kaum", "noch", "hellt", "das", "El\u00b7tern\u00b7haus"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "VVFIN", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Aus der Nebelfeuchte.", "tokens": ["Aus", "der", "Ne\u00b7bel\u00b7feuch\u00b7te", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$."], "meter": "--+-+-", "measure": "anapaest.init"}}, "stanza.21": {"line.1": {"text": "Trabt der Alte uns voran,", "tokens": ["Trabt", "der", "Al\u00b7te", "uns", "vo\u00b7ran", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "PPER", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Treu, wie zwei Verirrten,", "tokens": ["Treu", ",", "wie", "zwei", "Ver\u00b7irr\u00b7ten", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KOKOM", "CARD", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Folgen wir wie L\u00e4mmer dann,", "tokens": ["Fol\u00b7gen", "wir", "wie", "L\u00e4m\u00b7mer", "dann", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "KOKOM", "NN", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "L\u00e4mmer ihrem Hirten.", "tokens": ["L\u00e4m\u00b7mer", "ih\u00b7rem", "Hir\u00b7ten", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.22": {"line.1": {"text": "Wo sich durch den Buchenstand", "tokens": ["Wo", "sich", "durch", "den", "Bu\u00b7chen\u00b7stand"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "PRF", "APPR", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Eng der Weg gewunden,", "tokens": ["Eng", "der", "Weg", "ge\u00b7wun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "ART", "NN", "VAPP", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Hat sich schleunig Hand in Hand,", "tokens": ["Hat", "sich", "schleu\u00b7nig", "Hand", "in", "Hand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PRF", "ADJD", "NN", "APPR", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Mund zu Mund gefunden.", "tokens": ["Mund", "zu", "Mund", "ge\u00b7fun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.23": {"line.1": {"text": "Finsternis und Waldesruh,", "tokens": ["Fins\u00b7ter\u00b7nis", "und", "Wal\u00b7des\u00b7ruh", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "KON", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Himmel ohne Sterne.", "tokens": ["Him\u00b7mel", "oh\u00b7ne", "Ster\u00b7ne", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Unverdrossen, immerzu", "tokens": ["Un\u00b7ver\u00b7dros\u00b7sen", ",", "im\u00b7mer\u00b7zu"], "token_info": ["word", "punct", "word"], "pos": ["NN", "$,", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wandert die Laterne.", "tokens": ["Wan\u00b7dert", "die", "La\u00b7ter\u00b7ne", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.24": {"line.1": {"text": "Trifft ihr Schimmer Ast und Baum:", "tokens": ["Trifft", "ihr", "Schim\u00b7mer", "Ast", "und", "Baum", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "NN", "KON", "NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Blinzeln tausend Augen?", "tokens": ["Blin\u00b7zeln", "tau\u00b7send", "Au\u00b7gen", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "CARD", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Wie sich, unerh\u00f6rt, ist's Traum,", "tokens": ["Wie", "sich", ",", "un\u00b7er\u00b7h\u00f6rt", ",", "ist's", "Traum", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "PRF", "$,", "ADJD", "$,", "VAFIN", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Lipp' an Lippe saugen.", "tokens": ["Lipp'", "an", "Lip\u00b7pe", "sau\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "NN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.25": {"line.1": {"text": "Z\u00f6gern wir auf unserm Gang?", "tokens": ["Z\u00f6\u00b7gern", "wir", "auf", "un\u00b7serm", "Gang", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "La\u00df den Alten eilen.", "tokens": ["La\u00df", "den", "Al\u00b7ten", "ei\u00b7len", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Ach, mein Herz im \u00dcberdrang", "tokens": ["Ach", ",", "mein", "Herz", "im", "\u00dc\u00b7ber\u00b7drang"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["ITJ", "$,", "PPOSAT", "NN", "APPRART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "M\u00f6chte weilen, weilen.", "tokens": ["M\u00f6ch\u00b7te", "wei\u00b7len", ",", "wei\u00b7len", "."], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["VMFIN", "VVINF", "$,", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.26": {"line.1": {"text": "Bis zuletzt erschrocken h\u00e4lt", "tokens": ["Bis", "zu\u00b7letzt", "er\u00b7schro\u00b7cken", "h\u00e4lt"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ADV", "VVINF", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Hans am Holzesrande.", "tokens": ["Hans", "am", "Hol\u00b7zes\u00b7ran\u00b7de", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "APPRART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Lichtscheu unter'm Laubgezelt", "tokens": ["Licht\u00b7scheu", "un\u00b7ter'm", "Laub\u00b7ge\u00b7zelt"], "token_info": ["word", "word", "word"], "pos": ["NN", "APPRART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Schleicht die Kontrebande.", "tokens": ["Schleicht", "die", "Kont\u00b7re\u00b7ban\u00b7de", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.27": {"line.1": {"text": "Doch nun endlich sind wir da,", "tokens": ["Doch", "nun", "end\u00b7lich", "sind", "wir", "da", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "VAFIN", "PPER", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Schrei'n ihm in die Ohren:", "tokens": ["Schrei'n", "ihm", "in", "die", "Oh\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "APPR", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Alterchen, Hallelujah,", "tokens": ["Al\u00b7ter\u00b7chen", ",", "Hal\u00b7le\u00b7lu\u00b7jah", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$,", "ITJ", "$,"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.4": {"text": "Hast uns nicht verloren.", "tokens": ["Hast", "uns", "nicht", "ver\u00b7lo\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PTKNEG", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.28": {"line.1": {"text": "Scheidegru\u00df am Meilenstein,", "tokens": ["Schei\u00b7de\u00b7gru\u00df", "am", "Mei\u00b7len\u00b7stein", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPRART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Dichtverh\u00fcllte Ferne,", "tokens": ["Dicht\u00b7ver\u00b7h\u00fcll\u00b7te", "Fer\u00b7ne", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Letzter Blitz und letzter Schein,", "tokens": ["Letz\u00b7ter", "Blitz", "und", "letz\u00b7ter", "Schein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "KON", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Fort ist die Laterne.", "tokens": ["Fort", "ist", "die", "La\u00b7ter\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "ART", "NN", "$."], "meter": "+---+-", "measure": "dactylic.init"}}}}}