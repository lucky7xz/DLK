{"textgrid.poem.43992": {"metadata": {"author": {"name": "G\u00fcnther, Johann Christian", "birth": "N.A.", "death": "N.A."}, "title": "1L: Br\u00fcder, last uns lustig seyn,", "genre": "verse", "period": "N.A.", "pub_year": 1709, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Br\u00fcder, last uns lustig seyn,", "tokens": ["Br\u00fc\u00b7der", ",", "last", "uns", "lus\u00b7tig", "seyn", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "PPER", "ADJD", "VAINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Weil der Fr\u00fchling w\u00e4hret", "tokens": ["Weil", "der", "Fr\u00fch\u00b7ling", "w\u00e4h\u00b7ret"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "VVFIN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Und der Jugend Sonnenschein", "tokens": ["Und", "der", "Ju\u00b7gend", "Son\u00b7nen\u00b7schein"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Unser Laub verkl\u00e4ret.", "tokens": ["Un\u00b7ser", "Laub", "ver\u00b7kl\u00e4\u00b7ret", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.5": {"text": "Grab und Baare warthen nicht;", "tokens": ["Grab", "und", "Baa\u00b7re", "wart\u00b7hen", "nicht", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NE", "VVFIN", "PTKNEG", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Wer die Rosen jezo bricht,", "tokens": ["Wer", "die", "Ro\u00b7sen", "je\u00b7zo", "bricht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "NN", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Dem ist der Kranz bescheeret.", "tokens": ["Dem", "ist", "der", "Kranz", "be\u00b7schee\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Unsers Lebens schnelle Flucht", "tokens": ["Un\u00b7sers", "Le\u00b7bens", "schnel\u00b7le", "Flucht"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Leidet keinen Z\u00fcgel,", "tokens": ["Lei\u00b7det", "kei\u00b7nen", "Z\u00fc\u00b7gel", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Und des Schicksals Eifersucht", "tokens": ["Und", "des", "Schick\u00b7sals", "Ei\u00b7fer\u00b7sucht"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Macht ihr stetig Fl\u00fcgel.", "tokens": ["Macht", "ihr", "ste\u00b7tig", "Fl\u00fc\u00b7gel", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADJD", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.5": {"text": "Zeit und Jahre fliehn davon,", "tokens": ["Zeit", "und", "Jah\u00b7re", "fliehn", "da\u00b7von", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VVFIN", "PAV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Und vielleichte schnizt man schon", "tokens": ["Und", "viel\u00b7leich\u00b7te", "schnizt", "man", "schon"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PIS", "VVFIN", "PIS", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "An unsers Grabes Riegel.", "tokens": ["An", "un\u00b7sers", "Gra\u00b7bes", "Rie\u00b7gel", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Wo sind diese, sagt es mir,", "tokens": ["Wo", "sind", "die\u00b7se", ",", "sagt", "es", "mir", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PDS", "$,", "VVFIN", "PPER", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Die vor wenig Jahren", "tokens": ["Die", "vor", "we\u00b7nig", "Jah\u00b7ren"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "APPR", "PIAT", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Eben also, gleich wie wir,", "tokens": ["E\u00b7ben", "al\u00b7so", ",", "gleich", "wie", "wir", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$,", "ADV", "KOKOM", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Jung und fr\u00f6hlich waren?", "tokens": ["Jung", "und", "fr\u00f6h\u00b7lich", "wa\u00b7ren", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "ADJD", "VAFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.5": {"text": "Ihre Leiber deckt der Sand,", "tokens": ["Ih\u00b7re", "Lei\u00b7ber", "deckt", "der", "Sand", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Sie sind in ein ander Land", "tokens": ["Sie", "sind", "in", "ein", "an\u00b7der", "Land"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "APPR", "ART", "ADJA", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.7": {"text": "Aus dieser Welt gefahren.", "tokens": ["Aus", "die\u00b7ser", "Welt", "ge\u00b7fah\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Wer nach unsern V\u00e4tern forscht,", "tokens": ["Wer", "nach", "un\u00b7sern", "V\u00e4\u00b7tern", "forscht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Mag den Kirchhof fragen;", "tokens": ["Mag", "den", "Kirch\u00b7hof", "fra\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Ihr Gebein, so l\u00e4ngst vermorscht,", "tokens": ["Ihr", "Ge\u00b7bein", ",", "so", "l\u00e4ngst", "ver\u00b7morscht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "ADV", "ADV", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wird ihm Antwort sagen.", "tokens": ["Wird", "ihm", "Ant\u00b7wort", "sa\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "NN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.5": {"text": "Kan uns doch der Himmel bald,", "tokens": ["Kan", "uns", "doch", "der", "Him\u00b7mel", "bald", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "ART", "NN", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Eh die Morgenglocke schallt,", "tokens": ["Eh", "die", "Mor\u00b7gen\u00b7glo\u00b7cke", "schallt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "In unsre Gr\u00e4ber tragen.", "tokens": ["In", "uns\u00b7re", "Gr\u00e4\u00b7ber", "tra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Unterde\u00dfen seyd vergn\u00fcgt,", "tokens": ["Un\u00b7ter\u00b7de\u00b7\u00dfen", "seyd", "ver\u00b7gn\u00fcgt", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Last den Himmel walten,", "tokens": ["Last", "den", "Him\u00b7mel", "wal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Trinckt, bis euch das Bier besiegt,", "tokens": ["Trinckt", ",", "bis", "euch", "das", "Bier", "be\u00b7siegt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "KOUS", "PPER", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Nach Manier der Alten!", "tokens": ["Nach", "Ma\u00b7nier", "der", "Al\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.5": {"text": "Fort! Mir w\u00e4\u00dfert schon das Maul,", "tokens": ["Fort", "!", "Mir", "w\u00e4\u00b7\u00dfert", "schon", "das", "Maul", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "PPER", "VVFIN", "ADV", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Und, ihr andern, seyd nicht faul,", "tokens": ["Und", ",", "ihr", "an\u00b7dern", ",", "seyd", "nicht", "faul", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "$,", "PPOSAT", "ADJA", "$,", "VAFIN", "PTKNEG", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Die Mode zu erhalten.", "tokens": ["Die", "Mo\u00b7de", "zu", "er\u00b7hal\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Dieses Gl\u00e4schen bring ich dir,", "tokens": ["Die\u00b7ses", "Gl\u00e4s\u00b7chen", "bring", "ich", "dir", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "VVFIN", "PPER", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Da\u00df die Liebste lebe", "tokens": ["Da\u00df", "die", "Liebs\u00b7te", "le\u00b7be"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "VVFIN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Und der Nachwelt bald von dir", "tokens": ["Und", "der", "Nach\u00b7welt", "bald", "von", "dir"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "ADV", "APPR", "PPER"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Einen Abri\u00df gebe.", "tokens": ["Ei\u00b7nen", "Ab\u00b7ri\u00df", "ge\u00b7be", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.5": {"text": "Sezt ihr andern gleichfalls an,", "tokens": ["Sezt", "ihr", "an\u00b7dern", "gleich\u00b7falls", "an", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PIS", "ADV", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Und wenn dieses ist gethan,", "tokens": ["Und", "wenn", "die\u00b7ses", "ist", "ge\u00b7than", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PDS", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "So lebt der edle Rebe.", "tokens": ["So", "lebt", "der", "ed\u00b7le", "Re\u00b7be", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Br\u00fcder, last uns lustig seyn,", "tokens": ["Br\u00fc\u00b7der", ",", "last", "uns", "lus\u00b7tig", "seyn", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "PPER", "ADJD", "VAINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Weil der Fr\u00fchling w\u00e4hret", "tokens": ["Weil", "der", "Fr\u00fch\u00b7ling", "w\u00e4h\u00b7ret"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "VVFIN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Und der Jugend Sonnenschein", "tokens": ["Und", "der", "Ju\u00b7gend", "Son\u00b7nen\u00b7schein"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Unser Laub verkl\u00e4ret.", "tokens": ["Un\u00b7ser", "Laub", "ver\u00b7kl\u00e4\u00b7ret", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.5": {"text": "Grab und Baare warthen nicht;", "tokens": ["Grab", "und", "Baa\u00b7re", "wart\u00b7hen", "nicht", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NE", "VVFIN", "PTKNEG", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Wer die Rosen jezo bricht,", "tokens": ["Wer", "die", "Ro\u00b7sen", "je\u00b7zo", "bricht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "NN", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Dem ist der Kranz bescheeret.", "tokens": ["Dem", "ist", "der", "Kranz", "be\u00b7schee\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Unsers Lebens schnelle Flucht", "tokens": ["Un\u00b7sers", "Le\u00b7bens", "schnel\u00b7le", "Flucht"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Leidet keinen Z\u00fcgel,", "tokens": ["Lei\u00b7det", "kei\u00b7nen", "Z\u00fc\u00b7gel", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Und des Schicksals Eifersucht", "tokens": ["Und", "des", "Schick\u00b7sals", "Ei\u00b7fer\u00b7sucht"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Macht ihr stetig Fl\u00fcgel.", "tokens": ["Macht", "ihr", "ste\u00b7tig", "Fl\u00fc\u00b7gel", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADJD", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.5": {"text": "Zeit und Jahre fliehn davon,", "tokens": ["Zeit", "und", "Jah\u00b7re", "fliehn", "da\u00b7von", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VVFIN", "PAV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Und vielleichte schnizt man schon", "tokens": ["Und", "viel\u00b7leich\u00b7te", "schnizt", "man", "schon"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PIS", "VVFIN", "PIS", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "An unsers Grabes Riegel.", "tokens": ["An", "un\u00b7sers", "Gra\u00b7bes", "Rie\u00b7gel", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Wo sind diese, sagt es mir,", "tokens": ["Wo", "sind", "die\u00b7se", ",", "sagt", "es", "mir", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PDS", "$,", "VVFIN", "PPER", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Die vor wenig Jahren", "tokens": ["Die", "vor", "we\u00b7nig", "Jah\u00b7ren"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "APPR", "PIAT", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Eben also, gleich wie wir,", "tokens": ["E\u00b7ben", "al\u00b7so", ",", "gleich", "wie", "wir", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$,", "ADV", "KOKOM", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Jung und fr\u00f6hlich waren?", "tokens": ["Jung", "und", "fr\u00f6h\u00b7lich", "wa\u00b7ren", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "ADJD", "VAFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.5": {"text": "Ihre Leiber deckt der Sand,", "tokens": ["Ih\u00b7re", "Lei\u00b7ber", "deckt", "der", "Sand", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Sie sind in ein ander Land", "tokens": ["Sie", "sind", "in", "ein", "an\u00b7der", "Land"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "APPR", "ART", "ADJA", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.7": {"text": "Aus dieser Welt gefahren.", "tokens": ["Aus", "die\u00b7ser", "Welt", "ge\u00b7fah\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "Wer nach unsern V\u00e4tern forscht,", "tokens": ["Wer", "nach", "un\u00b7sern", "V\u00e4\u00b7tern", "forscht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Mag den Kirchhof fragen;", "tokens": ["Mag", "den", "Kirch\u00b7hof", "fra\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Ihr Gebein, so l\u00e4ngst vermorscht,", "tokens": ["Ihr", "Ge\u00b7bein", ",", "so", "l\u00e4ngst", "ver\u00b7morscht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "ADV", "ADV", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wird ihm Antwort sagen.", "tokens": ["Wird", "ihm", "Ant\u00b7wort", "sa\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "NN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.5": {"text": "Kan uns doch der Himmel bald,", "tokens": ["Kan", "uns", "doch", "der", "Him\u00b7mel", "bald", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "ART", "NN", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Eh die Morgenglocke schallt,", "tokens": ["Eh", "die", "Mor\u00b7gen\u00b7glo\u00b7cke", "schallt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "In unsre Gr\u00e4ber tragen.", "tokens": ["In", "uns\u00b7re", "Gr\u00e4\u00b7ber", "tra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "Unterde\u00dfen seyd vergn\u00fcgt,", "tokens": ["Un\u00b7ter\u00b7de\u00b7\u00dfen", "seyd", "ver\u00b7gn\u00fcgt", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Last den Himmel walten,", "tokens": ["Last", "den", "Him\u00b7mel", "wal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Trinckt, bis euch das Bier besiegt,", "tokens": ["Trinckt", ",", "bis", "euch", "das", "Bier", "be\u00b7siegt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "KOUS", "PPER", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Nach Manier der Alten!", "tokens": ["Nach", "Ma\u00b7nier", "der", "Al\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.5": {"text": "Fort! Mir w\u00e4\u00dfert schon das Maul,", "tokens": ["Fort", "!", "Mir", "w\u00e4\u00b7\u00dfert", "schon", "das", "Maul", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "PPER", "VVFIN", "ADV", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Und, ihr andern, seyd nicht faul,", "tokens": ["Und", ",", "ihr", "an\u00b7dern", ",", "seyd", "nicht", "faul", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "$,", "PPOSAT", "ADJA", "$,", "VAFIN", "PTKNEG", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Die Mode zu erhalten.", "tokens": ["Die", "Mo\u00b7de", "zu", "er\u00b7hal\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "Dieses Gl\u00e4schen bring ich dir,", "tokens": ["Die\u00b7ses", "Gl\u00e4s\u00b7chen", "bring", "ich", "dir", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "VVFIN", "PPER", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Da\u00df die Liebste lebe", "tokens": ["Da\u00df", "die", "Liebs\u00b7te", "le\u00b7be"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "VVFIN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Und der Nachwelt bald von dir", "tokens": ["Und", "der", "Nach\u00b7welt", "bald", "von", "dir"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "ADV", "APPR", "PPER"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Einen Abri\u00df gebe.", "tokens": ["Ei\u00b7nen", "Ab\u00b7ri\u00df", "ge\u00b7be", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.5": {"text": "Sezt ihr andern gleichfalls an,", "tokens": ["Sezt", "ihr", "an\u00b7dern", "gleich\u00b7falls", "an", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PIS", "ADV", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Und wenn dieses ist gethan,", "tokens": ["Und", "wenn", "die\u00b7ses", "ist", "ge\u00b7than", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PDS", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "So lebt der edle Rebe.", "tokens": ["So", "lebt", "der", "ed\u00b7le", "Re\u00b7be", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}}}}