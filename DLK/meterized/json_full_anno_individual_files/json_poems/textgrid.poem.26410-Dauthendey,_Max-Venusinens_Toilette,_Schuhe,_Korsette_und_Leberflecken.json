{"textgrid.poem.26410": {"metadata": {"author": {"name": "Dauthendey, Max", "birth": "N.A.", "death": "N.A."}, "title": "Venusinens Toilette, Schuhe, Korsette und Leberflecken", "genre": "verse", "period": "N.A.", "pub_year": 1892, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Pr\u00e4chtig sind die Tiere,", "tokens": ["Pr\u00e4ch\u00b7tig", "sind", "die", "Tie\u00b7re", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Die nichts s\u00fcndig finden,", "tokens": ["Die", "nichts", "s\u00fcn\u00b7dig", "fin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "ADJD", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Leben ihrer Liebe,", "tokens": ["Le\u00b7ben", "ih\u00b7rer", "Lie\u00b7be", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Sterben und verschwinden.", "tokens": ["Ster\u00b7ben", "und", "ver\u00b7schwin\u00b7den", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.2": {"line.1": {"text": "Eitler doch als Pfauen", "tokens": ["Eit\u00b7ler", "doch", "als", "Pfau\u00b7en"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "ADV", "KOUS", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Sind die Menschenseelen", "tokens": ["Sind", "die", "Men\u00b7schen\u00b7see\u00b7len"], "token_info": ["word", "word", "word"], "pos": ["VAFIN", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Und verbreiten Grauen.", "tokens": ["Und", "ver\u00b7brei\u00b7ten", "Grau\u00b7en", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.3": {"line.1": {"text": "G\u00f6tterd\u00e4mm'rung herrschte", "tokens": ["G\u00f6t\u00b7ter\u00b7d\u00e4m\u00b7m'\u00b7rung", "herrschte"], "token_info": ["word", "word"], "pos": ["NN", "VVFIN"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Auf der Erde Trachten,", "tokens": ["Auf", "der", "Er\u00b7de", "Trach\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Denn die G\u00f6tter konnten", "tokens": ["Denn", "die", "G\u00f6t\u00b7ter", "konn\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "VMFIN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Keinen Mensch mehr achten,", "tokens": ["Kei\u00b7nen", "Mensch", "mehr", "ach\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "ADV", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.4": {"line.1": {"text": "Hielten sich verborgen,", "tokens": ["Hiel\u00b7ten", "sich", "ver\u00b7bor\u00b7gen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "VVPP", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Nahmen mit die Freuden, \u2013", "tokens": ["Nah\u00b7men", "mit", "die", "Freu\u00b7den", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "APPR", "ART", "NN", "$,", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Seufzen blieb und Sorgen.", "tokens": ["Seuf\u00b7zen", "blieb", "und", "Sor\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "KON", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.5": {"line.1": {"text": "In dem H\u00f6rselberge", "tokens": ["In", "dem", "H\u00f6r\u00b7sel\u00b7ber\u00b7ge"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ART", "NN"], "meter": "+-++-+", "measure": "unknown.measure.tetra"}, "line.2": {"text": "Sa\u00df Frau Venusine", "tokens": ["Sa\u00df", "Frau", "Ve\u00b7nu\u00b7si\u00b7ne"], "token_info": ["word", "word", "word"], "pos": ["VVFIN", "NN", "NE"], "meter": "-+-+--", "measure": "unknown.measure.di"}, "line.3": {"text": "Tausend Jahr in Tr\u00e4nen", "tokens": ["Tau\u00b7send", "Jahr", "in", "Tr\u00e4\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["CARD", "NN", "APPR", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Und mit m\u00fcder Miene.", "tokens": ["Und", "mit", "m\u00fc\u00b7der", "Mie\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ADJA", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.6": {"line.1": {"text": "Endlich aber f\u00fchlte", "tokens": ["End\u00b7lich", "a\u00b7ber", "f\u00fchl\u00b7te"], "token_info": ["word", "word", "word"], "pos": ["ADV", "ADV", "VVFIN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Sie die Zeit gekommen,", "tokens": ["Sie", "die", "Zeit", "ge\u00b7kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Die die Nacht fortsp\u00fclte.", "tokens": ["Die", "die", "Nacht", "fort\u00b7sp\u00fcl\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.7": {"line.1": {"text": "Alte Sitt' und Weisen", "tokens": ["Al\u00b7te", "Sitt'", "und", "Wei\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJA", "NN", "KON", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Gehen dann in Spr\u00fcngen,", "tokens": ["Ge\u00b7hen", "dann", "in", "Spr\u00fcn\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "APPR", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Wenn die G\u00f6tter kreisen", "tokens": ["Wenn", "die", "G\u00f6t\u00b7ter", "krei\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "VVINF"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Und sich selbst verj\u00fcngen.", "tokens": ["Und", "sich", "selbst", "ver\u00b7j\u00fcn\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "ADV", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.8": {"line.1": {"text": "Denn auch ihrer Dauer", "tokens": ["Denn", "auch", "ih\u00b7rer", "Dau\u00b7er"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ADV", "PPOSAT", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Liegt der Tod am Wege,", "tokens": ["Liegt", "der", "Tod", "am", "We\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "APPRART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Sitzt die Zeit als Mauer.", "tokens": ["Sitzt", "die", "Zeit", "als", "Mau\u00b7er", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "KOUS", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.9": {"line.1": {"text": "Bl\u00fchend unter Schmerzen", "tokens": ["Bl\u00fc\u00b7hend", "un\u00b7ter", "Schmer\u00b7zen"], "token_info": ["word", "word", "word"], "pos": ["ADJD", "APPR", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Schrie Frau Venusine:", "tokens": ["Schrie", "Frau", "Ve\u00b7nu\u00b7si\u00b7ne", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "NN", "NE", "$."], "meter": "-+-+--", "measure": "unknown.measure.di"}, "line.3": {"text": "\u00bbmenschen, tote Tiere", "tokens": ["\u00bb", "men\u00b7schen", ",", "to\u00b7te", "Tie\u00b7re"], "token_info": ["punct", "word", "punct", "word", "word"], "pos": ["$(", "VVINF", "$,", "ADJA", "NN"], "meter": "--+-+-", "measure": "anapaest.init"}, "line.4": {"text": "Seid ihr ohne Minne!", "tokens": ["Seid", "ihr", "oh\u00b7ne", "Min\u00b7ne", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAIMP", "PPER", "APPR", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.10": {"line.1": {"text": "Geist macht kaltes D\u00fcrsten.", "tokens": ["Geist", "macht", "kal\u00b7tes", "D\u00fcrs\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ADJA", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Euch gilt heut die Liebe", "tokens": ["Euch", "gilt", "heut", "die", "Lie\u00b7be"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Gleich den Pferdfleischw\u00fcrsten.", "tokens": ["Gleich", "den", "Pferd\u00b7fleischw\u00fcrs\u00b7ten", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.11": {"line.1": {"text": "Kindlich seid ihr Menschen,", "tokens": ["Kind\u00b7lich", "seid", "ihr", "Men\u00b7schen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Kindlich im Erfinden.", "tokens": ["Kind\u00b7lich", "im", "Er\u00b7fin\u00b7den", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "APPRART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Denn ihr wollt die Liebe", "tokens": ["Denn", "ihr", "wollt", "die", "Lie\u00b7be"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VMFIN", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Durch die Tinte binden.", "tokens": ["Durch", "die", "Tin\u00b7te", "bin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.12": {"line.1": {"text": "Leidenschaften werden", "tokens": ["Lei\u00b7den\u00b7schaf\u00b7ten", "wer\u00b7den"], "token_info": ["word", "word"], "pos": ["NN", "VAINF"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "T\u00e4glich unbequemer", "tokens": ["T\u00e4g\u00b7lich", "un\u00b7be\u00b7que\u00b7mer"], "token_info": ["word", "word"], "pos": ["ADJD", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Und geha\u00dft auf Erden.", "tokens": ["Und", "ge\u00b7ha\u00dft", "auf", "Er\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.13": {"line.1": {"text": "Leidenschaftlich lobten", "tokens": ["Lei\u00b7den\u00b7schaft\u00b7lich", "lob\u00b7ten"], "token_info": ["word", "word"], "pos": ["ADJD", "VVFIN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Mich einst frohe Heiden.", "tokens": ["Mich", "einst", "fro\u00b7he", "Hei\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADJA", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.14": {"line.1": {"text": "Selbst k\u00f6nnt ihr euch fluchen;", "tokens": ["Selbst", "k\u00f6nnt", "ihr", "euch", "flu\u00b7chen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Schon im Mutterleibe", "tokens": ["Schon", "im", "Mut\u00b7ter\u00b7lei\u00b7be"], "token_info": ["word", "word", "word"], "pos": ["ADV", "APPRART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Darf euch Fluch aufsuchen.", "tokens": ["Darf", "euch", "Fluch", "auf\u00b7su\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "NN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.15": {"line.1": {"text": "Habt gar viel erfunden.", "tokens": ["Habt", "gar", "viel", "er\u00b7fun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Machtet selbst euch schlechter.", "tokens": ["Mach\u00b7tet", "selbst", "euch", "schlech\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PPER", "ADJD", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Habt die S\u00fcnd' erdichtet.", "tokens": ["Habt", "die", "S\u00fcnd'", "er\u00b7dich\u00b7tet", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Ihr, des Lebens Aechter,", "tokens": ["Ihr", ",", "des", "Le\u00b7bens", "A\u00b7ech\u00b7ter", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "ART", "NN", "NN", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}}, "stanza.16": {"line.1": {"text": "Wollt auch Schuld einimpfen", "tokens": ["Wollt", "auch", "Schuld", "ein\u00b7imp\u00b7fen"], "token_info": ["word", "word", "word", "word"], "pos": ["VMFIN", "ADV", "NN", "VVINF"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Schon den Embryonen,", "tokens": ["Schon", "den", "Emb\u00b7ry\u00b7o\u00b7nen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Unschuld b\u00f6s beschimpfen.", "tokens": ["Un\u00b7schuld", "b\u00f6s", "be\u00b7schimp\u00b7fen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "ADJD", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.17": {"line.1": {"text": "Aber neue Zeiten", "tokens": ["A\u00b7ber", "neu\u00b7e", "Zei\u00b7ten"], "token_info": ["word", "word", "word"], "pos": ["KON", "ADJA", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Treten unter Waffen.", "tokens": ["Tre\u00b7ten", "un\u00b7ter", "Waf\u00b7fen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Frei will sich die Freude", "tokens": ["Frei", "will", "sich", "die", "Freu\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "VMFIN", "PRF", "ART", "NN"], "meter": "+---+-", "measure": "dactylic.init"}, "line.4": {"text": "Neu bei euch erschaffen.", "tokens": ["Neu", "bei", "euch", "er\u00b7schaf\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "PPER", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.18": {"line.1": {"text": "B\u00f6s nicht und nicht besser", "tokens": ["B\u00f6s", "nicht", "und", "nicht", "bes\u00b7ser"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "PTKNEG", "KON", "PTKNEG", "ADJD"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Gleich den anderen Tieren,", "tokens": ["Gleich", "den", "an\u00b7de\u00b7ren", "Tie\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.3": {"text": "Seid ihr, Bratenfresser. \u2013", "tokens": ["Seid", "ihr", ",", "Bra\u00b7ten\u00b7fres\u00b7ser", ".", "\u2013"], "token_info": ["word", "word", "punct", "word", "punct", "punct"], "pos": ["VAIMP", "PPER", "$,", "NN", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.19": {"line.1": {"text": "S\u00f6hnchen Amor, h\u00f6re:", "tokens": ["S\u00f6hn\u00b7chen", "A\u00b7mor", ",", "h\u00f6\u00b7re", ":"], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["NN", "NE", "$,", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Rot wie eine Hummer", "tokens": ["Rot", "wie", "ei\u00b7ne", "Hum\u00b7mer"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "KOKOM", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Schie\u00dft Du Dich nur m\u00fcde,", "tokens": ["Schie\u00dft", "Du", "Dich", "nur", "m\u00fc\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "ADV", "ADJD", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Machst die Pfeil' nur krummer.", "tokens": ["Machst", "die", "Pfeil'", "nur", "krum\u00b7mer", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ADV", "ADJD", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.20": {"line.1": {"text": "Wirf ihn fort den Bogen!", "tokens": ["Wirf", "ihn", "fort", "den", "Bo\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "PTKVZ", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Mit Maschingewehren", "tokens": ["Mit", "Ma\u00b7schin\u00b7ge\u00b7weh\u00b7ren"], "token_info": ["word", "word"], "pos": ["APPR", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Komm vor's Herz gezogen.", "tokens": ["Komm", "vor's", "Herz", "ge\u00b7zo\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPRART", "NN", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.21": {"line.1": {"text": "Menschen tragen Panzer-", "tokens": ["Men\u00b7schen", "tra\u00b7gen", "Pan\u00b7ze\u00b7r"], "token_info": ["word", "word", "word"], "pos": ["NN", "VVINF", "TRUNC"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Platten unter Hemden,", "tokens": ["Plat\u00b7ten", "un\u00b7ter", "Hem\u00b7den", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Drunter da verlachen", "tokens": ["Drun\u00b7ter", "da", "ver\u00b7la\u00b7chen"], "token_info": ["word", "word", "word"], "pos": ["PAV", "ADV", "VVINF"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Dich die Unversch\u00e4mten.", "tokens": ["Dich", "die", "Un\u00b7ver\u00b7sch\u00e4m\u00b7ten", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.22": {"line.1": {"text": "Siehe, wie Verbannte", "tokens": ["Sie\u00b7he", ",", "wie", "Ver\u00b7bann\u00b7te"], "token_info": ["word", "punct", "word", "word"], "pos": ["VVIMP", "$,", "PWAV", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Lebten wir im Berge", "tokens": ["Leb\u00b7ten", "wir", "im", "Ber\u00b7ge"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "APPRART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Von der Welt Verkannte!", "tokens": ["Von", "der", "Welt", "Ver\u00b7kann\u00b7te", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.23": {"line.1": {"text": "La\u00df uns unter Leute", "tokens": ["La\u00df", "uns", "un\u00b7ter", "Leu\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["VVIMP", "PPER", "APPR", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "In die St\u00e4dte gehen!", "tokens": ["In", "die", "St\u00e4d\u00b7te", "ge\u00b7hen", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Zu lang man sich scheute", "tokens": ["Zu", "lang", "man", "sich", "scheu\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PTKA", "ADJD", "PIS", "PRF", "VVFIN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "Uns ins Aug zu sehen.", "tokens": ["Uns", "ins", "Aug", "zu", "se\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPRART", "NN", "PTKZU", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.24": {"line.1": {"text": "Immer nur in Tr\u00e4umen", "tokens": ["Im\u00b7mer", "nur", "in", "Tr\u00e4u\u00b7men"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ADV", "APPR", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Sangen wir verborgen", "tokens": ["San\u00b7gen", "wir", "ver\u00b7bor\u00b7gen"], "token_info": ["word", "word", "word"], "pos": ["VVFIN", "PPER", "VVPP"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Und in Gartenb\u00e4umen.", "tokens": ["Und", "in", "Gar\u00b7ten\u00b7b\u00e4u\u00b7men", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "$."], "meter": "--+-+-", "measure": "anapaest.init"}}, "stanza.25": {"line.1": {"text": "Nur wie Duft der Blumen", "tokens": ["Nur", "wie", "Duft", "der", "Blu\u00b7men"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "KOKOM", "NN", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Die zum Fr\u00fchling kamen,", "tokens": ["Die", "zum", "Fr\u00fch\u00b7ling", "ka\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "APPRART", "NN", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Gar zu zart und s\u00fc\u00dflich", "tokens": ["Gar", "zu", "zart", "und", "s\u00fc\u00df\u00b7lich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "PTKA", "ADJD", "KON", "ADJD"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Wir uns stets benahmen.", "tokens": ["Wir", "uns", "stets", "be\u00b7nah\u00b7men", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "PPER", "ADV", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.26": {"line.1": {"text": "Offen will ich streiten,", "tokens": ["Of\u00b7fen", "will", "ich", "strei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "PPER", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Leibeslust will leben,", "tokens": ["Lei\u00b7bes\u00b7lust", "will", "le\u00b7ben", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Zeit verschiebt die Zeiten!", "tokens": ["Zeit", "ver\u00b7schiebt", "die", "Zei\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.27": {"line.1": {"text": "Eckehardt, Getreuer,", "tokens": ["E\u00b7cke\u00b7hardt", ",", "Ge\u00b7treu\u00b7er", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NE", "$,", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "W\u00e4chter vor dem B\u00f6sen,", "tokens": ["W\u00e4ch\u00b7ter", "vor", "dem", "B\u00f6\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "La\u00df nach Tausend Jahren", "tokens": ["La\u00df", "nach", "Tau\u00b7send", "Jah\u00b7ren"], "token_info": ["word", "word", "word", "word"], "pos": ["VVIMP", "APPR", "CARD", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Deine Wach abl\u00f6sen!", "tokens": ["Dei\u00b7ne", "Wach", "ab\u00b7l\u00f6\u00b7sen", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.28": {"line.1": {"text": "Hast den Berg beh\u00fctet", "tokens": ["Hast", "den", "Berg", "be\u00b7h\u00fc\u00b7tet"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "ART", "NN", "VVFIN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Tausend Jahr vor Argem,", "tokens": ["Tau\u00b7send", "Jahr", "vor", "Ar\u00b7gem", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "APPR", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Sei mit Huld verg\u00fctet!", "tokens": ["Sei", "mit", "Huld", "ver\u00b7g\u00fc\u00b7tet", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "NN", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.29": {"line.1": {"text": "Sei verj\u00fcngt, und folge", "tokens": ["Sei", "ver\u00b7j\u00fcngt", ",", "und", "fol\u00b7ge"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["VAFIN", "VVPP", "$,", "KON", "VVFIN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Ohne graue Falte", "tokens": ["Oh\u00b7ne", "grau\u00b7e", "Fal\u00b7te"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ADJA", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Uns hinaus zum Berge,", "tokens": ["Uns", "hin\u00b7aus", "zum", "Ber\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "APZR", "APPRART", "NN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "La\u00df im Berg das Alte!", "tokens": ["La\u00df", "im", "Berg", "das", "Al\u00b7te", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "APPRART", "NN", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.30": {"line.1": {"text": "Trage jungen Scheitel,", "tokens": ["Tra\u00b7ge", "jun\u00b7gen", "Schei\u00b7tel", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ADJA", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "La\u00df die wei\u00dfen Haare,", "tokens": ["La\u00df", "die", "wei\u00b7\u00dfen", "Haa\u00b7re", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Und werd' etwas eitel.\u00ab", "tokens": ["Und", "werd'", "et\u00b7was", "ei\u00b7tel", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VAFIN", "ADV", "ADJD", "$.", "$("], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.31": {"line.1": {"text": "\u00bbja, wir wollen reisen\u00ab,", "tokens": ["\u00bb", "ja", ",", "wir", "wol\u00b7len", "rei\u00b7sen", "\u00ab", ","], "token_info": ["punct", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PTKANT", "$,", "PPER", "VMFIN", "VVINF", "$(", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Sprach verj\u00fcngt der alte", "tokens": ["Sprach", "ver\u00b7j\u00fcngt", "der", "al\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "VVFIN", "ART", "ADJA"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Eckehardt, der Treue,", "tokens": ["E\u00b7cke\u00b7hardt", ",", "der", "Treu\u00b7e", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Mit der Denkerfalte.", "tokens": ["Mit", "der", "Den\u00b7ker\u00b7fal\u00b7te", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.32": {"line.1": {"text": "\u00bbherrin, der ich diene,", "tokens": ["\u00bb", "her\u00b7rin", ",", "der", "ich", "die\u00b7ne", ","], "token_info": ["punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PTKVZ", "$,", "PRELS", "PPER", "PDS", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Viele Dich verga\u00dfen,", "tokens": ["Vie\u00b7le", "Dich", "ver\u00b7ga\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PIS", "PPER", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Zeig Dich Venusine!", "tokens": ["Zeig", "Dich", "Ve\u00b7nu\u00b7si\u00b7ne", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "PPER", "NE", "$."], "meter": "-+----", "measure": "dactylic.init"}}, "stanza.33": {"line.1": {"text": "Auch der Barbarossa", "tokens": ["Auch", "der", "Bar\u00b7ba\u00b7ros\u00b7sa"], "token_info": ["word", "word", "word"], "pos": ["ADV", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Stieg schon vom Kyffh\u00e4user.", "tokens": ["Stieg", "schon", "vom", "Kyff\u00b7h\u00e4u\u00b7ser", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "APPRART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Heute hinter Bergen", "tokens": ["Heu\u00b7te", "hin\u00b7ter", "Ber\u00b7gen"], "token_info": ["word", "word", "word"], "pos": ["ADV", "APPR", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Wohnen nur Duckm\u00e4user.", "tokens": ["Woh\u00b7nen", "nur", "Duck\u00b7m\u00e4u\u00b7ser", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ADV", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.34": {"line.1": {"text": "Deine roten Schleier", "tokens": ["Dei\u00b7ne", "ro\u00b7ten", "Schlei\u00b7er"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "L\u00fcfte Venusine,", "tokens": ["L\u00fcf\u00b7te", "Ve\u00b7nu\u00b7si\u00b7ne", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "NE", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Trag die H\u00fcften freier!\u00ab", "tokens": ["Trag", "die", "H\u00fcf\u00b7ten", "frei\u00b7er", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "ART", "NN", "ADJD", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.35": {"line.1": {"text": "\u00bbja, getreuer W\u00e4chter,", "tokens": ["\u00bb", "ja", ",", "ge\u00b7treu\u00b7er", "W\u00e4ch\u00b7ter", ","], "token_info": ["punct", "word", "punct", "word", "word", "punct"], "pos": ["$(", "PTKANT", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Fest bin ich entschlossen,", "tokens": ["Fest", "bin", "ich", "ent\u00b7schlos\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "VVPP", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Will zu Menschen gehen,", "tokens": ["Will", "zu", "Men\u00b7schen", "ge\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "APPR", "NN", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Die mich schwer verdrossen,", "tokens": ["Die", "mich", "schwer", "ver\u00b7dros\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADJD", "VVPP", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.36": {"line.1": {"text": "Die mich froh einst lobten", "tokens": ["Die", "mich", "froh", "einst", "lob\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "ADJD", "ADV", "VVFIN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Und dann gegen alle", "tokens": ["Und", "dann", "ge\u00b7gen", "al\u00b7le"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ADV", "APPR", "PIAT"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Fleischesl\u00fcste tobten.", "tokens": ["Flei\u00b7sches\u00b7l\u00fcs\u00b7te", "tob\u00b7ten", "."], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.37": {"line.1": {"text": "Diese armen Menschen", "tokens": ["Die\u00b7se", "ar\u00b7men", "Men\u00b7schen"], "token_info": ["word", "word", "word"], "pos": ["PDAT", "ADJA", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Will ich jetzt begl\u00fccken.", "tokens": ["Will", "ich", "jetzt", "be\u00b7gl\u00fc\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Ohne Leibesliebe", "tokens": ["Oh\u00b7ne", "Lei\u00b7bes\u00b7lie\u00b7be"], "token_info": ["word", "word"], "pos": ["APPR", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Geht die Seel' in St\u00fccken.", "tokens": ["Geht", "die", "Seel'", "in", "St\u00fc\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "APPR", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.38": {"line.1": {"text": "Ich will nicht mehr bangen", "tokens": ["Ich", "will", "nicht", "mehr", "ban\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PTKNEG", "ADV", "VVINF"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Vorm Verstand der Zwerge", "tokens": ["Vorm", "Ver\u00b7stand", "der", "Zwer\u00b7ge"], "token_info": ["word", "word", "word", "word"], "pos": ["APPRART", "NN", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Und vor seinen Zangen.", "tokens": ["Und", "vor", "sei\u00b7nen", "Zan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.39": {"line.1": {"text": "Will mal Rom aufsuchen,", "tokens": ["Will", "mal", "Rom", "auf\u00b7su\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "NE", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Wo man mich versto\u00dfen;", "tokens": ["Wo", "man", "mich", "ver\u00b7sto\u00b7\u00dfen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "PRF", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Wo man einst aus Wollust", "tokens": ["Wo", "man", "einst", "aus", "Wol\u00b7lust"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "PIS", "ADV", "APPR", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "T\u00f6tete mit Rosen.", "tokens": ["T\u00f6\u00b7te\u00b7te", "mit", "Ro\u00b7sen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.40": {"line.1": {"text": "M\u00f6glich, da\u00df ich finde", "tokens": ["M\u00f6g\u00b7lich", ",", "da\u00df", "ich", "fin\u00b7de"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["ADJD", "$,", "KOUS", "PPER", "VVFIN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Dort noch eine Gr\u00f6\u00dfe,", "tokens": ["Dort", "noch", "ei\u00b7ne", "Gr\u00f6\u00b7\u00dfe", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Der ich mich verbinde.", "tokens": ["Der", "ich", "mich", "ver\u00b7bin\u00b7de", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PRF", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.41": {"line.1": {"text": "Erst will ich mich kleiden", "tokens": ["Erst", "will", "ich", "mich", "klei\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PPER", "PRF", "VVINF"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Gleich den Menschenfrauen,", "tokens": ["Gleich", "den", "Men\u00b7schen\u00b7frau\u00b7en", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Die heut in den St\u00e4dten", "tokens": ["Die", "heut", "in", "den", "St\u00e4d\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "APPR", "ART", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "In die Welt sich trauen.", "tokens": ["In", "die", "Welt", "sich", "trau\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PRF", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.42": {"line.1": {"text": "Auch sind stolze Kleider,", "tokens": ["Auch", "sind", "stol\u00b7ze", "Klei\u00b7der", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADJA", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Trotz der G\u00f6tterw\u00fcrde,", "tokens": ["Trotz", "der", "G\u00f6t\u00b7ter\u00b7w\u00fcr\u00b7de", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Keinem Weib zur B\u00fcrde.\u00ab", "tokens": ["Kei\u00b7nem", "Weib", "zur", "B\u00fcr\u00b7de", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["PIAT", "NN", "APPRART", "NN", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.43": {"line.1": {"text": "\u00bbherrin Venusine,", "tokens": ["\u00bb", "her\u00b7rin", "Ve\u00b7nu\u00b7si\u00b7ne", ","], "token_info": ["punct", "word", "word", "punct"], "pos": ["$(", "ADV", "NE", "$,"], "meter": "+--+--", "measure": "dactylic.di.plus"}, "line.2": {"text": "Kleider, die verbergen", "tokens": ["Klei\u00b7der", ",", "die", "ver\u00b7ber\u00b7gen"], "token_info": ["word", "punct", "word", "word"], "pos": ["NN", "$,", "PRELS", "VVINF"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "M\u00e4ngel nur und reizen", "tokens": ["M\u00e4n\u00b7gel", "nur", "und", "rei\u00b7zen"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "ADV", "KON", "VVINF"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Unter Menschenzwergen.\u00ab", "tokens": ["Un\u00b7ter", "Men\u00b7schenz\u00b7wer\u00b7gen", ".", "\u00ab"], "token_info": ["word", "word", "punct", "punct"], "pos": ["APPR", "NN", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.44": {"line.1": {"text": "So sprach wie die Alten", "tokens": ["So", "sprach", "wie", "die", "Al\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "KOKOM", "ART", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Eckehardt der Junge,", "tokens": ["E\u00b7cke\u00b7hardt", "der", "Jun\u00b7ge", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Konnt' den Mund nicht halten.", "tokens": ["Konnt'", "den", "Mund", "nicht", "hal\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ART", "NN", "PTKNEG", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.45": {"line.1": {"text": "\u00bbeckehardt, viel weiser", "tokens": ["\u00bb", "ec\u00b7ke\u00b7hardt", ",", "viel", "wei\u00b7ser"], "token_info": ["punct", "word", "punct", "word", "word"], "pos": ["$(", "ADJD", "$,", "PIAT", "ADJA"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Hast Du sonst geraten.", "tokens": ["Hast", "Du", "sonst", "ge\u00b7ra\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Kleider sind die Sauce", "tokens": ["Klei\u00b7der", "sind", "die", "Sau\u00b7ce"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "VAFIN", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Schmackhaft bei dem Braten.", "tokens": ["Schmack\u00b7haft", "bei", "dem", "Bra\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.46": {"line.1": {"text": "Jederzeit bei Damen", "tokens": ["Je\u00b7der\u00b7zeit", "bei", "Da\u00b7men"], "token_info": ["word", "word", "word"], "pos": ["ADV", "APPR", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Waren Kleider n\u00f6tig,", "tokens": ["Wa\u00b7ren", "Klei\u00b7der", "n\u00f6\u00b7tig", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "ADJD", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Das geh\u00f6rt zum Rahmen.", "tokens": ["Das", "ge\u00b7h\u00f6rt", "zum", "Rah\u00b7men", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPRART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.47": {"line.1": {"text": "In den Tausend Jahren,", "tokens": ["In", "den", "Tau\u00b7send", "Jah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "CARD", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Die ich hier versonnen", "tokens": ["Die", "ich", "hier", "ver\u00b7son\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "PPER", "ADV", "VVINF"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "In dem H\u00f6rselberge,", "tokens": ["In", "dem", "H\u00f6r\u00b7sel\u00b7ber\u00b7ge", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,"], "meter": "+-++-+", "measure": "unknown.measure.tetra"}, "line.4": {"text": "Hab ich's ausgesponnen.", "tokens": ["Hab", "ich's", "aus\u00b7ge\u00b7spon\u00b7nen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PIS", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.48": {"line.1": {"text": "Ja, sogar das Schn\u00fcren", "tokens": ["Ja", ",", "so\u00b7gar", "das", "Schn\u00fc\u00b7ren"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["PTKANT", "$,", "ADV", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Soll die Venus leiden,", "tokens": ["Soll", "die", "Ve\u00b7nus", "lei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Gilt es zu verf\u00fchren.", "tokens": ["Gilt", "es", "zu", "ver\u00b7f\u00fch\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKZU", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.49": {"line.1": {"text": "Enger sind nicht Kleider", "tokens": ["En\u00b7ger", "sind", "nicht", "Klei\u00b7der"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "VAFIN", "PTKNEG", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Als die Einsamkeiten", "tokens": ["Als", "die", "Ein\u00b7sam\u00b7kei\u00b7ten"], "token_info": ["word", "word", "word"], "pos": ["KOUS", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "In dem H\u00f6rselberge,", "tokens": ["In", "dem", "H\u00f6r\u00b7sel\u00b7ber\u00b7ge", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,"], "meter": "+-++-+", "measure": "unknown.measure.tetra"}, "line.4": {"text": "Die mir Qual bereiten.", "tokens": ["Die", "mir", "Qual", "be\u00b7rei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "NN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.50": {"line.1": {"text": "Soll mal was geschehen,", "tokens": ["Soll", "mal", "was", "ge\u00b7sche\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "PIS", "VVPP", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Mu\u00df man nicht nur kritisch", "tokens": ["Mu\u00df", "man", "nicht", "nur", "kri\u00b7tisch"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VMFIN", "PIS", "PTKNEG", "ADV", "ADJD"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Drauf herniedersehen.", "tokens": ["Drauf", "her\u00b7nie\u00b7der\u00b7se\u00b7hen", "."], "token_info": ["word", "word", "punct"], "pos": ["PAV", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.51": {"line.1": {"text": "Bringt mir alle Dinge,", "tokens": ["Bringt", "mir", "al\u00b7le", "Din\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PIAT", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Die ein Weib heut zieren!", "tokens": ["Die", "ein", "Weib", "heut", "zie\u00b7ren", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "ADV", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Alles will ich tragen,", "tokens": ["Al\u00b7les", "will", "ich", "tra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "PPER", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Nichts soll mich genieren.\u00ab", "tokens": ["Nichts", "soll", "mich", "ge\u00b7nie\u00b7ren", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["PIS", "VMFIN", "PPER", "VVINF", "$.", "$("], "meter": "+---+-", "measure": "dactylic.init"}}, "stanza.52": {"line.1": {"text": "Zofe Melusine", "tokens": ["Zo\u00b7fe", "Me\u00b7lu\u00b7si\u00b7ne"], "token_info": ["word", "word"], "pos": ["NN", "NE"], "meter": "+---+-", "measure": "dactylic.init"}, "line.2": {"text": "Naht beim Wink der Wimper,", "tokens": ["Naht", "beim", "Wink", "der", "Wim\u00b7per", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPRART", "NN", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Dient mit kluger Miene.", "tokens": ["Dient", "mit", "klu\u00b7ger", "Mie\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ADJA", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.53": {"line.1": {"text": "Bringt zuerst die Schuhe,", "tokens": ["Bringt", "zu\u00b7erst", "die", "Schu\u00b7he", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Doch die haben T\u00fccken.", "tokens": ["Doch", "die", "ha\u00b7ben", "T\u00fc\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VAFIN", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Ach, von hundert Paaren", "tokens": ["Ach", ",", "von", "hun\u00b7dert", "Paa\u00b7ren"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["ITJ", "$,", "APPR", "CARD", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Will nicht Eines gl\u00fccken.", "tokens": ["Will", "nicht", "Ei\u00b7nes", "gl\u00fc\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PTKNEG", "PIS", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.54": {"line.1": {"text": "Keines will recht sitzen.", "tokens": ["Kei\u00b7nes", "will", "recht", "sit\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "ADJD", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Zof' und G\u00f6ttin zerren,", "tokens": ["Zof'", "und", "G\u00f6t\u00b7tin", "zer\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "NN", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Zof' und G\u00f6ttin schwitzen.", "tokens": ["Zof'", "und", "G\u00f6t\u00b7tin", "schwit\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "NN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.55": {"line.1": {"text": "Venus F\u00fc\u00dfen waren", "tokens": ["Ve\u00b7nus", "F\u00fc\u00b7\u00dfen", "wa\u00b7ren"], "token_info": ["word", "word", "word"], "pos": ["NE", "NN", "VAFIN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Klein noch die Enormen,", "tokens": ["Klein", "noch", "die", "En\u00b7or\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Und man mu\u00dfte extra", "tokens": ["Und", "man", "mu\u00df\u00b7te", "ex\u00b7tra"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PIS", "VMFIN", "ADV"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Neue Schuhe formen.", "tokens": ["Neu\u00b7e", "Schu\u00b7he", "for\u00b7men", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.56": {"line.1": {"text": "F\u00fc\u00dfe leicht sich breiten,", "tokens": ["F\u00fc\u00b7\u00dfe", "leicht", "sich", "brei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "PRF", "ADJA", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Trug man nur Sandalen", "tokens": ["Trug", "man", "nur", "San\u00b7da\u00b7len"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PIS", "ADV", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Seit den Ewigkeiten.", "tokens": ["Seit", "den", "E\u00b7wig\u00b7kei\u00b7ten", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.57": {"line.1": {"text": "Eckhardt konnt' die Trauer", "tokens": ["Eck\u00b7hardt", "konnt'", "die", "Trau\u00b7er"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "VMFIN", "ART", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Nicht gleich \u00fcberwinden,", "tokens": ["Nicht", "gleich", "\u00fc\u00b7berw\u00b7in\u00b7den", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Als der Herrin F\u00fc\u00dfe", "tokens": ["Als", "der", "Her\u00b7rin", "F\u00fc\u00b7\u00dfe"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "In den Schuh'n verschwinden.", "tokens": ["In", "den", "Schuh'n", "ver\u00b7schwin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.58": {"line.1": {"text": "Nachdenklich im Gehen", "tokens": ["Nach\u00b7denk\u00b7lich", "im", "Ge\u00b7hen"], "token_info": ["word", "word", "word"], "pos": ["ADV", "APPRART", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Starrt' er sonst versunken", "tokens": ["Starrt'", "er", "sonst", "ver\u00b7sun\u00b7ken"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "VVINF"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Auf der G\u00f6ttin Zehen.", "tokens": ["Auf", "der", "G\u00f6t\u00b7tin", "Ze\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "CARD", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.59": {"line.1": {"text": "Konnt' sich dran durch Stunden", "tokens": ["Konnt'", "sich", "dran", "durch", "Stun\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VMFIN", "PRF", "PAV", "APPR", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Wie an R\u00f6slein weiden,", "tokens": ["Wie", "an", "R\u00f6s\u00b7lein", "wei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPR", "NN", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Doch jetzt litt sein Auge", "tokens": ["Doch", "jetzt", "litt", "sein", "Au\u00b7ge"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "PPOSAT", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "H\u00fchneraugenleiden.", "tokens": ["H\u00fch\u00b7ner\u00b7au\u00b7gen\u00b7lei\u00b7den", "."], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.60": {"line.1": {"text": "Stets doch blieb der Alte,", "tokens": ["Stets", "doch", "blieb", "der", "Al\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Eckehardt der Junge", "tokens": ["E\u00b7cke\u00b7hardt", "der", "Jun\u00b7ge"], "token_info": ["word", "word", "word"], "pos": ["NE", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Mit der Denkerfalte.", "tokens": ["Mit", "der", "Den\u00b7ker\u00b7fal\u00b7te", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.61": {"line.1": {"text": "Melusine brachte", "tokens": ["Me\u00b7lu\u00b7si\u00b7ne", "brach\u00b7te"], "token_info": ["word", "word"], "pos": ["NE", "VVFIN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Spitzen aus den St\u00e4dten,", "tokens": ["Spit\u00b7zen", "aus", "den", "St\u00e4d\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Die auch h\u00f6chste Damen", "tokens": ["Die", "auch", "h\u00f6chs\u00b7te", "Da\u00b7men"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADV", "ADJA", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Gern getragen h\u00e4tten.", "tokens": ["Gern", "ge\u00b7tra\u00b7gen", "h\u00e4t\u00b7ten", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "VVPP", "VAFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.62": {"line.1": {"text": "Doch die seidnen Faden", "tokens": ["Doch", "die", "seid\u00b7nen", "Fa\u00b7den"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "PPOSAT", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Kitzeln sehr die G\u00f6ttin,", "tokens": ["Kit\u00b7zeln", "sehr", "die", "G\u00f6t\u00b7tin", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Wie ein Nest von Maden.", "tokens": ["Wie", "ein", "Nest", "von", "Ma\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "APPR", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.63": {"line.1": {"text": "Niemals man je besser", "tokens": ["Nie\u00b7mals", "man", "je", "bes\u00b7ser"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "PIS", "ADV", "ADJD"], "meter": "+--+--", "measure": "dactylic.di.plus"}, "line.2": {"text": "Eine Frau frisierte,", "tokens": ["Ei\u00b7ne", "Frau", "fri\u00b7sier\u00b7te", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Als klein Amor selber", "tokens": ["Als", "klein", "A\u00b7mor", "sel\u00b7ber"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ADJD", "NE", "ADV"], "meter": "-++-+-", "measure": "unknown.measure.tri"}, "line.4": {"text": "Die Mama toupierte.", "tokens": ["Die", "Ma\u00b7ma", "tou\u00b7pier\u00b7te", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.64": {"line.1": {"text": "Still h\u00e4lt sie ohn Klagen,", "tokens": ["Still", "h\u00e4lt", "sie", "ohn", "Kla\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "PPER", "APPR", "NN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Trug bald Nadeln, K\u00e4mme", "tokens": ["Trug", "bald", "Na\u00b7deln", ",", "K\u00e4m\u00b7me"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["NN", "ADV", "NN", "$,", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Und auch Haareinlagen.", "tokens": ["Und", "auch", "Haa\u00b7rein\u00b7la\u00b7gen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADV", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.65": {"line.1": {"text": "Zofe Melusine", "tokens": ["Zo\u00b7fe", "Me\u00b7lu\u00b7si\u00b7ne"], "token_info": ["word", "word"], "pos": ["NN", "NE"], "meter": "+---+-", "measure": "dactylic.init"}, "line.2": {"text": "Schn\u00fcrt sie auch ins nette", "tokens": ["Schn\u00fcrt", "sie", "auch", "ins", "net\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "APPRART", "ADJA"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Fischgebeinte schlanke", "tokens": ["Fischge\u00b7bein\u00b7te", "schlan\u00b7ke"], "token_info": ["word", "word"], "pos": ["NN", "VVFIN"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "Seidene Korsette.", "tokens": ["Sei\u00b7de\u00b7ne", "Kor\u00b7set\u00b7te", "."], "token_info": ["word", "word", "punct"], "pos": ["PPOSAT", "NN", "$."], "meter": "+---+-", "measure": "dactylic.init"}}, "stanza.66": {"line.1": {"text": "Eckehardt erbittert", "tokens": ["E\u00b7cke\u00b7hardt", "er\u00b7bit\u00b7tert"], "token_info": ["word", "word"], "pos": ["NE", "VVPP"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Flucht auf seidne Kerker,", "tokens": ["Flucht", "auf", "seid\u00b7ne", "Ker\u00b7ker", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Drin man sich vergittert.", "tokens": ["Drin", "man", "sich", "ver\u00b7git\u00b7tert", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "PRF", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.67": {"line.1": {"text": "\u00bbherrin, Deine Br\u00fcste", "tokens": ["\u00bb", "her\u00b7rin", ",", "Dei\u00b7ne", "Br\u00fcs\u00b7te"], "token_info": ["punct", "word", "punct", "word", "word"], "pos": ["$(", "PTKVZ", "$,", "PPOSAT", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Werden noch zwei Wunden", "tokens": ["Wer\u00b7den", "noch", "zwei", "Wun\u00b7den"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "CARD", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Hinterm Fischbeingitter", "tokens": ["Hin\u00b7term", "Fischbein\u00b7git\u00b7ter"], "token_info": ["word", "word"], "pos": ["APPRART", "NN"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "Lebst Du keine Stunden.\u00ab", "tokens": ["Lebst", "Du", "kei\u00b7ne", "Stun\u00b7den", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PPER", "PIAT", "NN", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.68": {"line.1": {"text": "Kaum hat er's gesprochen", "tokens": ["Kaum", "hat", "er's", "ge\u00b7spro\u00b7chen"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PIS", "VVPP"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Kracht schon das Korsette,", "tokens": ["Kracht", "schon", "das", "Kor\u00b7set\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ART", "NN", "$,"], "meter": "++--+-", "measure": "trochaic.tri.relaxed"}, "line.3": {"text": "Hing geknickt zerbrochen.", "tokens": ["Hing", "ge\u00b7knickt", "zer\u00b7bro\u00b7chen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "VVPP", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.69": {"line.1": {"text": "Wie zwei F\u00fcllen sprangen", "tokens": ["Wie", "zwei", "F\u00fcl\u00b7len", "spran\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "CARD", "NN", "VVINF"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Venusinens Br\u00fcste", "tokens": ["Ve\u00b7nu\u00b7si\u00b7nens", "Br\u00fcs\u00b7te"], "token_info": ["word", "word"], "pos": ["NE", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Bei dem ersten Atem", "tokens": ["Bei", "dem", "ers\u00b7ten", "A\u00b7tem"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Durchs Gebeinger\u00fcste.", "tokens": ["Durchs", "Ge\u00b7bein\u00b7ge\u00b7r\u00fcs\u00b7te", "."], "token_info": ["word", "word", "punct"], "pos": ["APPRART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.70": {"line.1": {"text": "Auch ein neues Mieder", "tokens": ["Auch", "ein", "neu\u00b7es", "Mie\u00b7der"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ART", "ADJA", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Tat nicht lange halten,", "tokens": ["Tat", "nicht", "lan\u00b7ge", "hal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PTKNEG", "ADV", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Leicht knickt sie es nieder.", "tokens": ["Leicht", "knickt", "sie", "es", "nie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "PPER", "PPER", "PTKVZ", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.71": {"line.1": {"text": "Bis man ihr die B\u00fcste", "tokens": ["Bis", "man", "ihr", "die", "B\u00fcs\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PIS", "PPER", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Fa\u00dft in Draht und Banden,", "tokens": ["Fa\u00dft", "in", "Draht", "und", "Ban\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "NN", "KON", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Und die wilden Br\u00fcste", "tokens": ["Und", "die", "wil\u00b7den", "Br\u00fcs\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Sich gel\u00e4hmt dreinfanden.", "tokens": ["Sich", "ge\u00b7l\u00e4hmt", "drein\u00b7fan\u00b7den", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PRF", "ADJD", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.72": {"line.1": {"text": "Strumpfband und auch Kragen,", "tokens": ["Strumpf\u00b7band", "und", "auch", "Kra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "ADV", "NN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Hutnadeln und H\u00fcte", "tokens": ["Hut\u00b7na\u00b7deln", "und", "H\u00fc\u00b7te"], "token_info": ["word", "word", "word"], "pos": ["NN", "KON", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Lernte sie zu tragen.", "tokens": ["Lern\u00b7te", "sie", "zu", "tra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKZU", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.73": {"line.1": {"text": "Venusin studierte", "tokens": ["Ve\u00b7nu\u00b7sin", "stu\u00b7dier\u00b7te"], "token_info": ["word", "word"], "pos": ["NE", "VVFIN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Auch die Umgangsb\u00fccher,", "tokens": ["Auch", "die", "Um\u00b7gangs\u00b7b\u00fc\u00b7cher", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Lernt mit Gabeln essen", "tokens": ["Lernt", "mit", "Ga\u00b7beln", "es\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "NN", "VVINF"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Und braucht Taschent\u00fccher.", "tokens": ["Und", "braucht", "Ta\u00b7schen\u00b7t\u00fc\u00b7cher", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.74": {"line.1": {"text": "So ward sie zur ", "tokens": ["So", "ward", "sie", "zur"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "APPRART"], "meter": "-+-+", "measure": "iambic.di"}, "line.2": {"text": "Bei der Hemdabnahme.", "tokens": ["Bei", "der", "Hemd\u00b7ab\u00b7nah\u00b7me", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.75": {"line.1": {"text": "Eins nur macht ihr Sorge:", "tokens": ["Eins", "nur", "macht", "ihr", "Sor\u00b7ge", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "VVFIN", "PPOSAT", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Kaum ist sie entkleidet,", "tokens": ["Kaum", "ist", "sie", "ent\u00b7klei\u00b7det", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "VVPP", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Seufzt sie, da\u00df sie nirgends", "tokens": ["Seufzt", "sie", ",", "da\u00df", "sie", "nir\u00b7gends"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "PPER", "$,", "KOUS", "PPER", "ADV"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Ach, an Fehlern leidet.", "tokens": ["Ach", ",", "an", "Feh\u00b7lern", "lei\u00b7det", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "APPR", "NN", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.76": {"line.1": {"text": "Nirgends sitzt ein Flecken", "tokens": ["Nir\u00b7gends", "sitzt", "ein", "Fle\u00b7cken"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Irgendwo am Leibe,", "tokens": ["Ir\u00b7gend\u00b7wo", "am", "Lei\u00b7be", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Nichts kann sie entdecken.", "tokens": ["Nichts", "kann", "sie", "ent\u00b7de\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "PPER", "VVINF", "$."], "meter": "++--+-", "measure": "trochaic.tri.relaxed"}}, "stanza.77": {"line.1": {"text": "\u00bbund ich will nicht besser", "tokens": ["\u00bb", "und", "ich", "will", "nicht", "bes\u00b7ser"], "token_info": ["punct", "word", "word", "word", "word", "word"], "pos": ["$(", "KON", "PPER", "VMFIN", "PTKNEG", "ADJD"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Als die Erdenfrauen", "tokens": ["Als", "die", "Er\u00b7den\u00b7frau\u00b7en"], "token_info": ["word", "word", "word"], "pos": ["KOUS", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Mich in M\u00e4nnern\u00e4he", "tokens": ["Mich", "in", "M\u00e4n\u00b7ner\u00b7n\u00e4\u00b7he"], "token_info": ["word", "word", "word"], "pos": ["PPER", "APPR", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Fleckenlos getrauen.", "tokens": ["Fle\u00b7cken\u00b7los", "ge\u00b7trau\u00b7en", "."], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.78": {"line.1": {"text": "Dieses w\u00e4r wie Tadel", "tokens": ["Die\u00b7ses", "w\u00e4r", "wie", "Ta\u00b7del"], "token_info": ["word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "KOKOM", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Schwachen Menschenkindern,", "tokens": ["Schwa\u00b7chen", "Men\u00b7schen\u00b7kin\u00b7dern", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Und ich halt auf Adel.\u00ab", "tokens": ["Und", "ich", "halt", "auf", "A\u00b7del", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "PPER", "VVFIN", "APPR", "NN", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.79": {"line.1": {"text": "Doch die Zofe meinte:", "tokens": ["Doch", "die", "Zo\u00b7fe", "mein\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "\u00bbg\u00f6ttin seid Ihr eben!", "tokens": ["\u00bb", "g\u00f6t\u00b7tin", "seid", "Ihr", "e\u00b7ben", "!"], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "NE", "VAFIN", "PPER", "ADV", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "G\u00f6ttern ist nicht zugleich", "tokens": ["G\u00f6t\u00b7tern", "ist", "nicht", "zu\u00b7gleich"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "VAFIN", "PTKNEG", "ADV"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.4": {"text": "Menschliches gegeben.", "tokens": ["Menschli\u00b7ches", "ge\u00b7ge\u00b7ben", "."], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVPP", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.80": {"line.1": {"text": "Was sollten bezwecken,", "tokens": ["Was", "soll\u00b7ten", "be\u00b7zwe\u00b7cken", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "VVINF", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Herrin Venusine,", "tokens": ["Her\u00b7rin", "Ve\u00b7nu\u00b7si\u00b7ne", ","], "token_info": ["word", "word", "punct"], "pos": ["NE", "NE", "$,"], "meter": "+--+--", "measure": "dactylic.di.plus"}, "line.3": {"text": "Schwarze Leberflecken?\u00ab", "tokens": ["Schwar\u00b7ze", "Le\u00b7ber\u00b7fle\u00b7cken", "?", "\u00ab"], "token_info": ["word", "word", "punct", "punct"], "pos": ["ADJA", "NN", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.81": {"line.1": {"text": "\u00bbwisse,\u00ab spricht die G\u00f6ttin,", "tokens": ["\u00bb", "wis\u00b7se", ",", "\u00ab", "spricht", "die", "G\u00f6t\u00b7tin", ","], "token_info": ["punct", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "$,", "$(", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "\u00bbzu viel Reinheit blendet,", "tokens": ["\u00bb", "zu", "viel", "Rein\u00b7heit", "blen\u00b7det", ","], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "PIAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Da\u00df das Alltagsauge", "tokens": ["Da\u00df", "das", "All\u00b7tags\u00b7au\u00b7ge"], "token_info": ["word", "word", "word"], "pos": ["KOUS", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Sich dann abseits wendet.", "tokens": ["Sich", "dann", "ab\u00b7seits", "wen\u00b7det", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PRF", "ADV", "ADV", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.82": {"line.1": {"text": "Vor dem steifen Strau\u00dfe", "tokens": ["Vor", "dem", "stei\u00b7fen", "Strau\u00b7\u00dfe"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Tadelloser Lilien", "tokens": ["Ta\u00b7del\u00b7lo\u00b7ser", "Li\u00b7li\u00b7en"], "token_info": ["word", "word"], "pos": ["ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ist man nicht zu Hause.", "tokens": ["Ist", "man", "nicht", "zu", "Hau\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "PTKNEG", "APPR", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.83": {"line.1": {"text": "Frauen geben Heimat", "tokens": ["Frau\u00b7en", "ge\u00b7ben", "Hei\u00b7mat"], "token_info": ["word", "word", "word"], "pos": ["NN", "VVINF", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Abgehetzten M\u00e4nnern,", "tokens": ["Ab\u00b7ge\u00b7hetz\u00b7ten", "M\u00e4n\u00b7nern", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Die am Tage starten", "tokens": ["Die", "am", "Ta\u00b7ge", "star\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "APPRART", "NN", "VVFIN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Gleich den besten Rennern,", "tokens": ["Gleich", "den", "bes\u00b7ten", "Ren\u00b7nern", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.84": {"line.1": {"text": "Die gern Hindernisse", "tokens": ["Die", "gern", "Hin\u00b7der\u00b7nis\u00b7se"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Halszerbrechend nehmen", "tokens": ["Hals\u00b7zer\u00b7bre\u00b7chend", "neh\u00b7men"], "token_info": ["word", "word"], "pos": ["ADJD", "VVINF"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Und das Ungewisse.", "tokens": ["Und", "das", "Un\u00b7ge\u00b7wis\u00b7se", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.85": {"line.1": {"text": "Kommen solche m\u00fcde", "tokens": ["Kom\u00b7men", "sol\u00b7che", "m\u00fc\u00b7de"], "token_info": ["word", "word", "word"], "pos": ["NN", "PIAT", "ADJA"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Abends von dem Traben,", "tokens": ["A\u00b7bends", "von", "dem", "Tra\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "St\u00f6rt sie allzu Hohes,", "tokens": ["St\u00f6rt", "sie", "all\u00b7zu", "Ho\u00b7hes", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKA", "ADJA", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Weil sie's Aug voll haben", "tokens": ["Weil", "sie's", "Aug", "voll", "ha\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ADJA", "NN", "ADJD", "VAFIN"], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.86": {"line.1": {"text": "Voll von Staub und Kohlen,", "tokens": ["Voll", "von", "Staub", "und", "Koh\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "NN", "KON", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Sehen oft noch Ziffern,", "tokens": ["Se\u00b7hen", "oft", "noch", "Zif\u00b7fern", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADV", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Die sich \u00fcberholen.", "tokens": ["Die", "sich", "\u00fc\u00b7berh\u00b7o\u00b7len", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "PRF", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.87": {"line.1": {"text": "Eine kurze Spanne", "tokens": ["Ei\u00b7ne", "kur\u00b7ze", "Span\u00b7ne"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Reicht die Nacht zum Morgen.", "tokens": ["Reicht", "die", "Nacht", "zum", "Mor\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "APPRART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Dann pfeift die Maschine \u2013", "tokens": ["Dann", "pfeift", "die", "Ma\u00b7schi\u00b7ne", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$("], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "Feilschend kommen Sorgen.", "tokens": ["Feil\u00b7schend", "kom\u00b7men", "Sor\u00b7gen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.88": {"line.1": {"text": "In ", "tokens": ["In"], "token_info": ["word"], "pos": ["APPR"], "meter": "-", "measure": "single.down"}, "line.2": {"text": "Passen keine ", "tokens": ["Pas\u00b7sen", "kei\u00b7ne"], "token_info": ["word", "word"], "pos": ["NN", "PIAT"], "meter": "+-+-", "measure": "trochaic.di"}}, "stanza.89": {"line.1": {"text": "Mehr denn ", "tokens": ["Mehr", "denn"], "token_info": ["word", "word"], "pos": ["PIAT", "KON"], "meter": "-+", "measure": "iambic.single"}, "line.2": {"text": "Ist dem Herz erquickend,", "tokens": ["Ist", "dem", "Herz", "er\u00b7qui\u00b7ckend", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Stimmt den K\u00f6rper milder.", "tokens": ["Stimmt", "den", "K\u00f6r\u00b7per", "mil\u00b7der", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.90": {"line.1": {"text": "Traulichkeit zu wecken", "tokens": ["Trau\u00b7lich\u00b7keit", "zu", "we\u00b7cken"], "token_info": ["word", "word", "word"], "pos": ["NN", "PTKZU", "VVINF"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Will am G\u00f6tterleibe", "tokens": ["Will", "am", "G\u00f6t\u00b7ter\u00b7lei\u00b7be"], "token_info": ["word", "word", "word"], "pos": ["VMFIN", "APPRART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Ich die Leberflecken.", "tokens": ["Ich", "die", "Le\u00b7ber\u00b7fle\u00b7cken", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.91": {"line.1": {"text": "Eile Melusine,", "tokens": ["Ei\u00b7le", "Me\u00b7lu\u00b7si\u00b7ne", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "NE", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Hol den Mediziner!", "tokens": ["Hol", "den", "Me\u00b7di\u00b7zi\u00b7ner", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Er sei heut nicht Krankheits-", "tokens": ["Er", "sei", "heut", "nicht", "Krank\u00b7heits"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "PTKNEG", "TRUNC"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "Sondern Sch\u00f6nheitsdiener.", "tokens": ["Son\u00b7dern", "Sch\u00f6n\u00b7heits\u00b7die\u00b7ner", "."], "token_info": ["word", "word", "punct"], "pos": ["KON", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.92": {"line.1": {"text": "Soll mir mit Lanzetten", "tokens": ["Soll", "mir", "mit", "Lan\u00b7zet\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["VMFIN", "PPER", "APPR", "NN"], "meter": "+--+--", "measure": "dactylic.di.plus"}, "line.2": {"text": "Leberflecken impfen,", "tokens": ["Le\u00b7ber\u00b7fle\u00b7cken", "imp\u00b7fen", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Von den braunen netten.\u00ab", "tokens": ["Von", "den", "brau\u00b7nen", "net\u00b7ten", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.93": {"line.1": {"text": "\u00bbschwerlich,\u00ab sagt die Zofe,", "tokens": ["\u00bb", "schwer\u00b7lich", ",", "\u00ab", "sagt", "die", "Zo\u00b7fe", ","], "token_info": ["punct", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "$,", "$(", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "\u00bbwird ein Arzt sich finden,", "tokens": ["\u00bb", "wird", "ein", "Arzt", "sich", "fin\u00b7den", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VAFIN", "ART", "NN", "PRF", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Weil die Luft im Berge", "tokens": ["Weil", "die", "Luft", "im", "Ber\u00b7ge"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "APPRART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Menschen nicht verwinden.", "tokens": ["Men\u00b7schen", "nicht", "ver\u00b7win\u00b7den", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PTKNEG", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.94": {"line.1": {"text": "Wer von all den k\u00fchlen,", "tokens": ["Wer", "von", "all", "den", "k\u00fch\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "PIAT", "ART", "ADJA", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Welche Leichen schneiden,", "tokens": ["Wel\u00b7che", "Lei\u00b7chen", "schnei\u00b7den", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PWAT", "NN", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Wird nicht Venus f\u00fchlen?", "tokens": ["Wird", "nicht", "Ve\u00b7nus", "f\u00fch\u00b7len", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PTKNEG", "NN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.95": {"line.1": {"text": "Und dann mu\u00df er sterben,", "tokens": ["Und", "dann", "mu\u00df", "er", "ster\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VMFIN", "PPER", "VVINF", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Kann er nichts erreichen,", "tokens": ["Kann", "er", "nichts", "er\u00b7rei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PIS", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "W\u00fcrde er entlassen", "tokens": ["W\u00fcr\u00b7de", "er", "ent\u00b7las\u00b7sen"], "token_info": ["word", "word", "word"], "pos": ["VAFIN", "PPER", "VVINF"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Ohne Liebeszeichen,", "tokens": ["Oh\u00b7ne", "Lie\u00b7bes\u00b7zei\u00b7chen", ","], "token_info": ["word", "word", "punct"], "pos": ["APPR", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.96": {"line.1": {"text": "W\u00fcrde nie genesen,", "tokens": ["W\u00fcr\u00b7de", "nie", "ge\u00b7ne\u00b7sen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "VVPP", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Weil er hier im Berge", "tokens": ["Weil", "er", "hier", "im", "Ber\u00b7ge"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "APPRART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Ohne Luft gewesen.", "tokens": ["Oh\u00b7ne", "Luft", "ge\u00b7we\u00b7sen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "VAPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.97": {"line.1": {"text": "Darum Herrin sage", "tokens": ["Da\u00b7rum", "Her\u00b7rin", "sa\u00b7ge"], "token_info": ["word", "word", "word"], "pos": ["PAV", "NN", "VVFIN"], "meter": "-+-+--", "measure": "unknown.measure.di"}, "line.2": {"text": "Deine Wunschangaben!", "tokens": ["Dei\u00b7ne", "Wun\u00b7schan\u00b7ga\u00b7ben", "!"], "token_info": ["word", "word", "punct"], "pos": ["PPOSAT", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Wo willst du die Flecken,", "tokens": ["Wo", "willst", "du", "die", "Fle\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "PPER", "ART", "NN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "Die Versch\u00e4mten haben?", "tokens": ["Die", "Ver\u00b7sch\u00e4m\u00b7ten", "ha\u00b7ben", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.98": {"line.1": {"text": "Wie ich es dann mache,", "tokens": ["Wie", "ich", "es", "dann", "ma\u00b7che", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PPER", "ADV", "VVFIN", "$,"], "meter": "+---+-", "measure": "dactylic.init"}, "line.2": {"text": "Dir die Flecklein hole,", "tokens": ["Dir", "die", "Flec\u00b7klein", "ho\u00b7le", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Sei dann meine Sache.\u00ab", "tokens": ["Sei", "dann", "mei\u00b7ne", "Sa\u00b7che", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["VAFIN", "ADV", "PPOSAT", "NN", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.99": {"line.1": {"text": "\u00bbkluge Melusine,\u00ab", "tokens": ["\u00bb", "klu\u00b7ge", "Me\u00b7lu\u00b7si\u00b7ne", ",", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "punct"], "pos": ["$(", "ADJA", "NN", "$,", "$("], "meter": "+---+-", "measure": "dactylic.init"}, "line.2": {"text": "Venusin err\u00f6tet,", "tokens": ["Ve\u00b7nu\u00b7sin", "er\u00b7r\u00f6\u00b7tet", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVPP", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "\u00bbjegliche Sekunde", "tokens": ["\u00bb", "jeg\u00b7li\u00b7che", "Se\u00b7kun\u00b7de"], "token_info": ["punct", "word", "word"], "pos": ["$(", "PIAT", "NN"], "meter": "+---+-", "measure": "dactylic.init"}, "line.4": {"text": "Wird ein Mensch get\u00f6tet.", "tokens": ["Wird", "ein", "Mensch", "ge\u00b7t\u00f6\u00b7tet", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.100": {"line.1": {"text": "Stirbt er mal am Herzen,", "tokens": ["Stirbt", "er", "mal", "am", "Her\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "APPRART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Sind das auch bei G\u00f6ttern", "tokens": ["Sind", "das", "auch", "bei", "G\u00f6t\u00b7tern"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "PDS", "ADV", "APPR", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Einzig echte Schmerzen.", "tokens": ["Ein\u00b7zig", "ech\u00b7te", "Schmer\u00b7zen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "ADJA", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.101": {"line.1": {"text": "Wenn er mir gefiele,", "tokens": ["Wenn", "er", "mir", "ge\u00b7fie\u00b7le", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "W\u00fcrd' ich ihn nicht schonen.", "tokens": ["W\u00fcrd'", "ich", "ihn", "nicht", "scho\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PPER", "PTKNEG", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Aber sollt' er sterben,", "tokens": ["A\u00b7ber", "sollt'", "er", "ster\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Nur weil wir hier wohnen,", "tokens": ["Nur", "weil", "wir", "hier", "woh\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PPER", "ADV", "VVINF", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.102": {"line.1": {"text": "Weil die Luft im Berge", "tokens": ["Weil", "die", "Luft", "im", "Ber\u00b7ge"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "APPRART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Schon den Tod kann bringen", "tokens": ["Schon", "den", "Tod", "kann", "brin\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "VMFIN", "VVINF"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Einem Menschenzwerge?!", "tokens": ["Ei\u00b7nem", "Men\u00b7schenz\u00b7wer\u00b7ge", "?!"], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.103": {"line.1": {"text": "Flott weg mal zu t\u00f6ten", "tokens": ["Flott", "weg", "mal", "zu", "t\u00f6\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "ADV", "ADV", "PTKZU", "VVINF"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Lieb ich sonst ohn' Ma\u00dfen,", "tokens": ["Lieb", "ich", "sonst", "ohn'", "Ma\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "APPR", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Heut' doch will ich Deinem", "tokens": ["Heut'", "doch", "will", "ich", "Dei\u00b7nem"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "VMFIN", "PPER", "PPOSAT"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Rat mich \u00fcberlassen.", "tokens": ["Rat", "mich", "\u00fc\u00b7ber\u00b7las\u00b7sen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PPER", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.104": {"line.1": {"text": "Geh und bring die Flecken!", "tokens": ["Geh", "und", "bring", "die", "Fle\u00b7cken", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Kann ich nicht entdecken\u00ab.", "tokens": ["Kann", "ich", "nicht", "ent\u00b7de\u00b7cken", "\u00ab", "."], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["VMFIN", "PPER", "PTKNEG", "VVINF", "$(", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.105": {"line.1": {"text": "Melusine kichert", "tokens": ["Me\u00b7lu\u00b7si\u00b7ne", "ki\u00b7chert"], "token_info": ["word", "word"], "pos": ["NE", "VVFIN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Und ist schon verschwunden;", "tokens": ["Und", "ist", "schon", "ver\u00b7schwun\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "VVPP", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Hat verj\u00fcngt den Eckhardt", "tokens": ["Hat", "ver\u00b7j\u00fcngt", "den", "Eck\u00b7hardt"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "VVFIN", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Unterm Tor gefunden.", "tokens": ["Un\u00b7term", "Tor", "ge\u00b7fun\u00b7den", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.106": {"line.1": {"text": "Spricht: \u00bbKomm' auf ne Weile!", "tokens": ["Spricht", ":", "\u00bb", "Komm'", "auf", "ne", "Wei\u00b7le", "!"], "token_info": ["word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$.", "$(", "VVIMP", "APPR", "ADJA", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Kannst jetzt etwas lernen.", "tokens": ["Kannst", "jetzt", "et\u00b7was", "ler\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "PIS", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Schnell, ich habe Eile!", "tokens": ["Schnell", ",", "ich", "ha\u00b7be", "Ei\u00b7le", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "PPER", "VAFIN", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.107": {"line.1": {"text": "Sieh, ich will zum Arzte,", "tokens": ["Sieh", ",", "ich", "will", "zum", "Arz\u00b7te", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PPER", "VMFIN", "APPRART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Und er soll mich impfen,", "tokens": ["Und", "er", "soll", "mich", "imp\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VMFIN", "PPER", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Da\u00df uns nicht die Pocken", "tokens": ["Da\u00df", "uns", "nicht", "die", "Po\u00b7cken"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PTKNEG", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Einmal b\u00f6s verglimpfen.", "tokens": ["Ein\u00b7mal", "b\u00f6s", "ver\u00b7glimp\u00b7fen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.108": {"line.1": {"text": "Ist die Impf geschehen,", "tokens": ["Ist", "die", "Impf", "ge\u00b7sche\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Sollst Du's Venus tuen;", "tokens": ["Sollst", "Du's", "Ve\u00b7nus", "tu\u00b7en", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "NE", "NE", "VVINF", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Komm' jetzt, sollst es sehen\u00ab ...", "tokens": ["Komm'", "jetzt", ",", "sollst", "es", "se\u00b7hen", "\u00ab", "..."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["VVIMP", "ADV", "$,", "VMFIN", "PPER", "VVINF", "$(", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.109": {"line.1": {"text": "Venus fragt am Abend:", "tokens": ["Ve\u00b7nus", "fragt", "am", "A\u00b7bend", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPRART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "\u00bbhast Du sie die Flecken?\u00ab", "tokens": ["\u00bb", "hast", "Du", "sie", "die", "Fle\u00b7cken", "?", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VAFIN", "PPER", "PPER", "ART", "NN", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "\u00bbja,\u00ab lacht Melusine,", "tokens": ["\u00bb", "ja", ",", "\u00ab", "lacht", "Me\u00b7lu\u00b7si\u00b7ne", ","], "token_info": ["punct", "word", "punct", "punct", "word", "word", "punct"], "pos": ["$(", "PTKANT", "$,", "$(", "VVFIN", "NE", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "\u00bbkann sie nicht verstecken.", "tokens": ["\u00bb", "kann", "sie", "nicht", "ver\u00b7ste\u00b7cken", "."], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "VMFIN", "PPER", "PTKNEG", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.110": {"line.1": {"text": "Ach, der Arzt nicht ruhte,", "tokens": ["Ach", ",", "der", "Arzt", "nicht", "ruh\u00b7te", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "ART", "NN", "PTKNEG", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Nicht nur bei drei Orten,", "tokens": ["Nicht", "nur", "bei", "drei", "Or\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "APPR", "CARD", "NN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "W\u00fchlte er im Blute.\u00ab", "tokens": ["W\u00fchl\u00b7te", "er", "im", "Blu\u00b7te", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PPER", "APPRART", "NN", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.111": {"line.1": {"text": "Venus, bei der Lampe,", "tokens": ["Ve\u00b7nus", ",", "bei", "der", "Lam\u00b7pe", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "APPR", "ART", "NN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Sieht voll Sommersprossen", "tokens": ["Sieht", "voll", "Som\u00b7mer\u00b7spros\u00b7sen"], "token_info": ["word", "word", "word"], "pos": ["VVFIN", "ADJD", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Ihre h\u00fcbsche Zofe,", "tokens": ["Ih\u00b7re", "h\u00fcb\u00b7sche", "Zo\u00b7fe", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Punkt an Punkt durchschossen.", "tokens": ["Punkt", "an", "Punkt", "durch\u00b7schos\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "NN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.112": {"line.1": {"text": "Venus lacht mit Schallen:", "tokens": ["Ve\u00b7nus", "lacht", "mit", "Schal\u00b7len", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPR", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "\u00bbso gut hat dem Doktor", "tokens": ["\u00bb", "so", "gut", "hat", "dem", "Dok\u00b7tor"], "token_info": ["punct", "word", "word", "word", "word", "word"], "pos": ["$(", "ADV", "ADJD", "VAFIN", "ART", "NN"], "meter": "-++-+-", "measure": "unknown.measure.tri"}, "line.3": {"text": "Jeder Fleck gefallen?", "tokens": ["Je\u00b7der", "Fleck", "ge\u00b7fal\u00b7len", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.113": {"line.1": {"text": "Da\u00df er sich dann \u00fcbte", "tokens": ["Da\u00df", "er", "sich", "dann", "\u00fcb\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PRF", "ADV", "VVFIN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Und Dich ganz bes\u00e4te?", "tokens": ["Und", "Dich", "ganz", "be\u00b7s\u00e4\u00b7te", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ADV", "VVFIN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Ach, wenn ich von Deinen", "tokens": ["Ach", ",", "wenn", "ich", "von", "Dei\u00b7nen"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["ITJ", "$,", "KOUS", "PPER", "APPR", "PPOSAT"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Hundert einen h\u00e4tte!\u00ab", "tokens": ["Hun\u00b7dert", "ei\u00b7nen", "h\u00e4t\u00b7te", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PIS", "VAFIN", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.114": {"line.1": {"text": "Eckehardt, verst\u00e4ndig,", "tokens": ["E\u00b7cke\u00b7hardt", ",", "ver\u00b7st\u00e4n\u00b7dig", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NE", "$,", "ADJD", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Impft sie, \u2013 und im Berge", "tokens": ["Impft", "sie", ",", "\u2013", "und", "im", "Ber\u00b7ge"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word"], "pos": ["VVFIN", "PPER", "$,", "$(", "KON", "APPRART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Lachte man unb\u00e4ndig.", "tokens": ["Lach\u00b7te", "man", "un\u00b7b\u00e4n\u00b7dig", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ADJD", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.115": {"line.1": {"text": "Pr\u00e4chtig sind die Tiere,", "tokens": ["Pr\u00e4ch\u00b7tig", "sind", "die", "Tie\u00b7re", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Die nichts s\u00fcndig finden,", "tokens": ["Die", "nichts", "s\u00fcn\u00b7dig", "fin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "ADJD", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Leben ihrer Liebe,", "tokens": ["Le\u00b7ben", "ih\u00b7rer", "Lie\u00b7be", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Sterben und verschwinden.", "tokens": ["Ster\u00b7ben", "und", "ver\u00b7schwin\u00b7den", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.116": {"line.1": {"text": "Eitler doch als Pfauen", "tokens": ["Eit\u00b7ler", "doch", "als", "Pfau\u00b7en"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "ADV", "KOUS", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Sind die Menschenseelen", "tokens": ["Sind", "die", "Men\u00b7schen\u00b7see\u00b7len"], "token_info": ["word", "word", "word"], "pos": ["VAFIN", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Und verbreiten Grauen.", "tokens": ["Und", "ver\u00b7brei\u00b7ten", "Grau\u00b7en", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.117": {"line.1": {"text": "G\u00f6tterd\u00e4mm'rung herrschte", "tokens": ["G\u00f6t\u00b7ter\u00b7d\u00e4m\u00b7m'\u00b7rung", "herrschte"], "token_info": ["word", "word"], "pos": ["NN", "VVFIN"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Auf der Erde Trachten,", "tokens": ["Auf", "der", "Er\u00b7de", "Trach\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Denn die G\u00f6tter konnten", "tokens": ["Denn", "die", "G\u00f6t\u00b7ter", "konn\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "VMFIN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Keinen Mensch mehr achten,", "tokens": ["Kei\u00b7nen", "Mensch", "mehr", "ach\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "ADV", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.118": {"line.1": {"text": "Hielten sich verborgen,", "tokens": ["Hiel\u00b7ten", "sich", "ver\u00b7bor\u00b7gen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "VVPP", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Nahmen mit die Freuden, \u2013", "tokens": ["Nah\u00b7men", "mit", "die", "Freu\u00b7den", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "APPR", "ART", "NN", "$,", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Seufzen blieb und Sorgen.", "tokens": ["Seuf\u00b7zen", "blieb", "und", "Sor\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "KON", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.119": {"line.1": {"text": "In dem H\u00f6rselberge", "tokens": ["In", "dem", "H\u00f6r\u00b7sel\u00b7ber\u00b7ge"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ART", "NN"], "meter": "+-++-+", "measure": "unknown.measure.tetra"}, "line.2": {"text": "Sa\u00df Frau Venusine", "tokens": ["Sa\u00df", "Frau", "Ve\u00b7nu\u00b7si\u00b7ne"], "token_info": ["word", "word", "word"], "pos": ["VVFIN", "NN", "NE"], "meter": "-+-+--", "measure": "unknown.measure.di"}, "line.3": {"text": "Tausend Jahr in Tr\u00e4nen", "tokens": ["Tau\u00b7send", "Jahr", "in", "Tr\u00e4\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["CARD", "NN", "APPR", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Und mit m\u00fcder Miene.", "tokens": ["Und", "mit", "m\u00fc\u00b7der", "Mie\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ADJA", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.120": {"line.1": {"text": "Endlich aber f\u00fchlte", "tokens": ["End\u00b7lich", "a\u00b7ber", "f\u00fchl\u00b7te"], "token_info": ["word", "word", "word"], "pos": ["ADV", "ADV", "VVFIN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Sie die Zeit gekommen,", "tokens": ["Sie", "die", "Zeit", "ge\u00b7kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Die die Nacht fortsp\u00fclte.", "tokens": ["Die", "die", "Nacht", "fort\u00b7sp\u00fcl\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.121": {"line.1": {"text": "Alte Sitt' und Weisen", "tokens": ["Al\u00b7te", "Sitt'", "und", "Wei\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJA", "NN", "KON", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Gehen dann in Spr\u00fcngen,", "tokens": ["Ge\u00b7hen", "dann", "in", "Spr\u00fcn\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "APPR", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Wenn die G\u00f6tter kreisen", "tokens": ["Wenn", "die", "G\u00f6t\u00b7ter", "krei\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "VVINF"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Und sich selbst verj\u00fcngen.", "tokens": ["Und", "sich", "selbst", "ver\u00b7j\u00fcn\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "ADV", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.122": {"line.1": {"text": "Denn auch ihrer Dauer", "tokens": ["Denn", "auch", "ih\u00b7rer", "Dau\u00b7er"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ADV", "PPOSAT", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Liegt der Tod am Wege,", "tokens": ["Liegt", "der", "Tod", "am", "We\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "APPRART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Sitzt die Zeit als Mauer.", "tokens": ["Sitzt", "die", "Zeit", "als", "Mau\u00b7er", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "KOUS", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.123": {"line.1": {"text": "Bl\u00fchend unter Schmerzen", "tokens": ["Bl\u00fc\u00b7hend", "un\u00b7ter", "Schmer\u00b7zen"], "token_info": ["word", "word", "word"], "pos": ["ADJD", "APPR", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Schrie Frau Venusine:", "tokens": ["Schrie", "Frau", "Ve\u00b7nu\u00b7si\u00b7ne", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "NN", "NE", "$."], "meter": "-+-+--", "measure": "unknown.measure.di"}, "line.3": {"text": "\u00bbmenschen, tote Tiere", "tokens": ["\u00bb", "men\u00b7schen", ",", "to\u00b7te", "Tie\u00b7re"], "token_info": ["punct", "word", "punct", "word", "word"], "pos": ["$(", "VVINF", "$,", "ADJA", "NN"], "meter": "--+-+-", "measure": "anapaest.init"}, "line.4": {"text": "Seid ihr ohne Minne!", "tokens": ["Seid", "ihr", "oh\u00b7ne", "Min\u00b7ne", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAIMP", "PPER", "APPR", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.124": {"line.1": {"text": "Geist macht kaltes D\u00fcrsten.", "tokens": ["Geist", "macht", "kal\u00b7tes", "D\u00fcrs\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ADJA", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Euch gilt heut die Liebe", "tokens": ["Euch", "gilt", "heut", "die", "Lie\u00b7be"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Gleich den Pferdfleischw\u00fcrsten.", "tokens": ["Gleich", "den", "Pferd\u00b7fleischw\u00fcrs\u00b7ten", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.125": {"line.1": {"text": "Kindlich seid ihr Menschen,", "tokens": ["Kind\u00b7lich", "seid", "ihr", "Men\u00b7schen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Kindlich im Erfinden.", "tokens": ["Kind\u00b7lich", "im", "Er\u00b7fin\u00b7den", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "APPRART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Denn ihr wollt die Liebe", "tokens": ["Denn", "ihr", "wollt", "die", "Lie\u00b7be"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VMFIN", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Durch die Tinte binden.", "tokens": ["Durch", "die", "Tin\u00b7te", "bin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.126": {"line.1": {"text": "Leidenschaften werden", "tokens": ["Lei\u00b7den\u00b7schaf\u00b7ten", "wer\u00b7den"], "token_info": ["word", "word"], "pos": ["NN", "VAINF"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "T\u00e4glich unbequemer", "tokens": ["T\u00e4g\u00b7lich", "un\u00b7be\u00b7que\u00b7mer"], "token_info": ["word", "word"], "pos": ["ADJD", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Und geha\u00dft auf Erden.", "tokens": ["Und", "ge\u00b7ha\u00dft", "auf", "Er\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.127": {"line.1": {"text": "Leidenschaftlich lobten", "tokens": ["Lei\u00b7den\u00b7schaft\u00b7lich", "lob\u00b7ten"], "token_info": ["word", "word"], "pos": ["ADJD", "VVFIN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Mich einst frohe Heiden.", "tokens": ["Mich", "einst", "fro\u00b7he", "Hei\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADJA", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.128": {"line.1": {"text": "Selbst k\u00f6nnt ihr euch fluchen;", "tokens": ["Selbst", "k\u00f6nnt", "ihr", "euch", "flu\u00b7chen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Schon im Mutterleibe", "tokens": ["Schon", "im", "Mut\u00b7ter\u00b7lei\u00b7be"], "token_info": ["word", "word", "word"], "pos": ["ADV", "APPRART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Darf euch Fluch aufsuchen.", "tokens": ["Darf", "euch", "Fluch", "auf\u00b7su\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "NN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.129": {"line.1": {"text": "Habt gar viel erfunden.", "tokens": ["Habt", "gar", "viel", "er\u00b7fun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Machtet selbst euch schlechter.", "tokens": ["Mach\u00b7tet", "selbst", "euch", "schlech\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PPER", "ADJD", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Habt die S\u00fcnd' erdichtet.", "tokens": ["Habt", "die", "S\u00fcnd'", "er\u00b7dich\u00b7tet", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Ihr, des Lebens Aechter,", "tokens": ["Ihr", ",", "des", "Le\u00b7bens", "A\u00b7ech\u00b7ter", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "ART", "NN", "NN", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}}, "stanza.130": {"line.1": {"text": "Wollt auch Schuld einimpfen", "tokens": ["Wollt", "auch", "Schuld", "ein\u00b7imp\u00b7fen"], "token_info": ["word", "word", "word", "word"], "pos": ["VMFIN", "ADV", "NN", "VVINF"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Schon den Embryonen,", "tokens": ["Schon", "den", "Emb\u00b7ry\u00b7o\u00b7nen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Unschuld b\u00f6s beschimpfen.", "tokens": ["Un\u00b7schuld", "b\u00f6s", "be\u00b7schimp\u00b7fen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "ADJD", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.131": {"line.1": {"text": "Aber neue Zeiten", "tokens": ["A\u00b7ber", "neu\u00b7e", "Zei\u00b7ten"], "token_info": ["word", "word", "word"], "pos": ["KON", "ADJA", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Treten unter Waffen.", "tokens": ["Tre\u00b7ten", "un\u00b7ter", "Waf\u00b7fen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Frei will sich die Freude", "tokens": ["Frei", "will", "sich", "die", "Freu\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "VMFIN", "PRF", "ART", "NN"], "meter": "+---+-", "measure": "dactylic.init"}, "line.4": {"text": "Neu bei euch erschaffen.", "tokens": ["Neu", "bei", "euch", "er\u00b7schaf\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "PPER", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.132": {"line.1": {"text": "B\u00f6s nicht und nicht besser", "tokens": ["B\u00f6s", "nicht", "und", "nicht", "bes\u00b7ser"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "PTKNEG", "KON", "PTKNEG", "ADJD"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Gleich den anderen Tieren,", "tokens": ["Gleich", "den", "an\u00b7de\u00b7ren", "Tie\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.3": {"text": "Seid ihr, Bratenfresser. \u2013", "tokens": ["Seid", "ihr", ",", "Bra\u00b7ten\u00b7fres\u00b7ser", ".", "\u2013"], "token_info": ["word", "word", "punct", "word", "punct", "punct"], "pos": ["VAIMP", "PPER", "$,", "NN", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.133": {"line.1": {"text": "S\u00f6hnchen Amor, h\u00f6re:", "tokens": ["S\u00f6hn\u00b7chen", "A\u00b7mor", ",", "h\u00f6\u00b7re", ":"], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["NN", "NE", "$,", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Rot wie eine Hummer", "tokens": ["Rot", "wie", "ei\u00b7ne", "Hum\u00b7mer"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "KOKOM", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Schie\u00dft Du Dich nur m\u00fcde,", "tokens": ["Schie\u00dft", "Du", "Dich", "nur", "m\u00fc\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "ADV", "ADJD", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Machst die Pfeil' nur krummer.", "tokens": ["Machst", "die", "Pfeil'", "nur", "krum\u00b7mer", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ADV", "ADJD", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.134": {"line.1": {"text": "Wirf ihn fort den Bogen!", "tokens": ["Wirf", "ihn", "fort", "den", "Bo\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "PTKVZ", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Mit Maschingewehren", "tokens": ["Mit", "Ma\u00b7schin\u00b7ge\u00b7weh\u00b7ren"], "token_info": ["word", "word"], "pos": ["APPR", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Komm vor's Herz gezogen.", "tokens": ["Komm", "vor's", "Herz", "ge\u00b7zo\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPRART", "NN", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.135": {"line.1": {"text": "Menschen tragen Panzer-", "tokens": ["Men\u00b7schen", "tra\u00b7gen", "Pan\u00b7ze\u00b7r"], "token_info": ["word", "word", "word"], "pos": ["NN", "VVINF", "TRUNC"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Platten unter Hemden,", "tokens": ["Plat\u00b7ten", "un\u00b7ter", "Hem\u00b7den", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Drunter da verlachen", "tokens": ["Drun\u00b7ter", "da", "ver\u00b7la\u00b7chen"], "token_info": ["word", "word", "word"], "pos": ["PAV", "ADV", "VVINF"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Dich die Unversch\u00e4mten.", "tokens": ["Dich", "die", "Un\u00b7ver\u00b7sch\u00e4m\u00b7ten", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.136": {"line.1": {"text": "Siehe, wie Verbannte", "tokens": ["Sie\u00b7he", ",", "wie", "Ver\u00b7bann\u00b7te"], "token_info": ["word", "punct", "word", "word"], "pos": ["VVIMP", "$,", "PWAV", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Lebten wir im Berge", "tokens": ["Leb\u00b7ten", "wir", "im", "Ber\u00b7ge"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "APPRART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Von der Welt Verkannte!", "tokens": ["Von", "der", "Welt", "Ver\u00b7kann\u00b7te", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.137": {"line.1": {"text": "La\u00df uns unter Leute", "tokens": ["La\u00df", "uns", "un\u00b7ter", "Leu\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["VVIMP", "PPER", "APPR", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "In die St\u00e4dte gehen!", "tokens": ["In", "die", "St\u00e4d\u00b7te", "ge\u00b7hen", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Zu lang man sich scheute", "tokens": ["Zu", "lang", "man", "sich", "scheu\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PTKA", "ADJD", "PIS", "PRF", "VVFIN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "Uns ins Aug zu sehen.", "tokens": ["Uns", "ins", "Aug", "zu", "se\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPRART", "NN", "PTKZU", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.138": {"line.1": {"text": "Immer nur in Tr\u00e4umen", "tokens": ["Im\u00b7mer", "nur", "in", "Tr\u00e4u\u00b7men"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ADV", "APPR", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Sangen wir verborgen", "tokens": ["San\u00b7gen", "wir", "ver\u00b7bor\u00b7gen"], "token_info": ["word", "word", "word"], "pos": ["VVFIN", "PPER", "VVPP"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Und in Gartenb\u00e4umen.", "tokens": ["Und", "in", "Gar\u00b7ten\u00b7b\u00e4u\u00b7men", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "$."], "meter": "--+-+-", "measure": "anapaest.init"}}, "stanza.139": {"line.1": {"text": "Nur wie Duft der Blumen", "tokens": ["Nur", "wie", "Duft", "der", "Blu\u00b7men"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "KOKOM", "NN", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Die zum Fr\u00fchling kamen,", "tokens": ["Die", "zum", "Fr\u00fch\u00b7ling", "ka\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "APPRART", "NN", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Gar zu zart und s\u00fc\u00dflich", "tokens": ["Gar", "zu", "zart", "und", "s\u00fc\u00df\u00b7lich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "PTKA", "ADJD", "KON", "ADJD"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Wir uns stets benahmen.", "tokens": ["Wir", "uns", "stets", "be\u00b7nah\u00b7men", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "PPER", "ADV", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.140": {"line.1": {"text": "Offen will ich streiten,", "tokens": ["Of\u00b7fen", "will", "ich", "strei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "PPER", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Leibeslust will leben,", "tokens": ["Lei\u00b7bes\u00b7lust", "will", "le\u00b7ben", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Zeit verschiebt die Zeiten!", "tokens": ["Zeit", "ver\u00b7schiebt", "die", "Zei\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.141": {"line.1": {"text": "Eckehardt, Getreuer,", "tokens": ["E\u00b7cke\u00b7hardt", ",", "Ge\u00b7treu\u00b7er", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NE", "$,", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "W\u00e4chter vor dem B\u00f6sen,", "tokens": ["W\u00e4ch\u00b7ter", "vor", "dem", "B\u00f6\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "La\u00df nach Tausend Jahren", "tokens": ["La\u00df", "nach", "Tau\u00b7send", "Jah\u00b7ren"], "token_info": ["word", "word", "word", "word"], "pos": ["VVIMP", "APPR", "CARD", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Deine Wach abl\u00f6sen!", "tokens": ["Dei\u00b7ne", "Wach", "ab\u00b7l\u00f6\u00b7sen", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.142": {"line.1": {"text": "Hast den Berg beh\u00fctet", "tokens": ["Hast", "den", "Berg", "be\u00b7h\u00fc\u00b7tet"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "ART", "NN", "VVFIN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Tausend Jahr vor Argem,", "tokens": ["Tau\u00b7send", "Jahr", "vor", "Ar\u00b7gem", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "APPR", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Sei mit Huld verg\u00fctet!", "tokens": ["Sei", "mit", "Huld", "ver\u00b7g\u00fc\u00b7tet", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "NN", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.143": {"line.1": {"text": "Sei verj\u00fcngt, und folge", "tokens": ["Sei", "ver\u00b7j\u00fcngt", ",", "und", "fol\u00b7ge"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["VAFIN", "VVPP", "$,", "KON", "VVFIN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Ohne graue Falte", "tokens": ["Oh\u00b7ne", "grau\u00b7e", "Fal\u00b7te"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ADJA", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Uns hinaus zum Berge,", "tokens": ["Uns", "hin\u00b7aus", "zum", "Ber\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "APZR", "APPRART", "NN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "La\u00df im Berg das Alte!", "tokens": ["La\u00df", "im", "Berg", "das", "Al\u00b7te", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "APPRART", "NN", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.144": {"line.1": {"text": "Trage jungen Scheitel,", "tokens": ["Tra\u00b7ge", "jun\u00b7gen", "Schei\u00b7tel", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ADJA", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "La\u00df die wei\u00dfen Haare,", "tokens": ["La\u00df", "die", "wei\u00b7\u00dfen", "Haa\u00b7re", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Und werd' etwas eitel.\u00ab", "tokens": ["Und", "werd'", "et\u00b7was", "ei\u00b7tel", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VAFIN", "ADV", "ADJD", "$.", "$("], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.145": {"line.1": {"text": "\u00bbja, wir wollen reisen\u00ab,", "tokens": ["\u00bb", "ja", ",", "wir", "wol\u00b7len", "rei\u00b7sen", "\u00ab", ","], "token_info": ["punct", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PTKANT", "$,", "PPER", "VMFIN", "VVINF", "$(", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Sprach verj\u00fcngt der alte", "tokens": ["Sprach", "ver\u00b7j\u00fcngt", "der", "al\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "VVFIN", "ART", "ADJA"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Eckehardt, der Treue,", "tokens": ["E\u00b7cke\u00b7hardt", ",", "der", "Treu\u00b7e", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Mit der Denkerfalte.", "tokens": ["Mit", "der", "Den\u00b7ker\u00b7fal\u00b7te", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.146": {"line.1": {"text": "\u00bbherrin, der ich diene,", "tokens": ["\u00bb", "her\u00b7rin", ",", "der", "ich", "die\u00b7ne", ","], "token_info": ["punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PTKVZ", "$,", "PRELS", "PPER", "PDS", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Viele Dich verga\u00dfen,", "tokens": ["Vie\u00b7le", "Dich", "ver\u00b7ga\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PIS", "PPER", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Zeig Dich Venusine!", "tokens": ["Zeig", "Dich", "Ve\u00b7nu\u00b7si\u00b7ne", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "PPER", "NE", "$."], "meter": "-+----", "measure": "dactylic.init"}}, "stanza.147": {"line.1": {"text": "Auch der Barbarossa", "tokens": ["Auch", "der", "Bar\u00b7ba\u00b7ros\u00b7sa"], "token_info": ["word", "word", "word"], "pos": ["ADV", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Stieg schon vom Kyffh\u00e4user.", "tokens": ["Stieg", "schon", "vom", "Kyff\u00b7h\u00e4u\u00b7ser", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "APPRART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Heute hinter Bergen", "tokens": ["Heu\u00b7te", "hin\u00b7ter", "Ber\u00b7gen"], "token_info": ["word", "word", "word"], "pos": ["ADV", "APPR", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Wohnen nur Duckm\u00e4user.", "tokens": ["Woh\u00b7nen", "nur", "Duck\u00b7m\u00e4u\u00b7ser", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ADV", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.148": {"line.1": {"text": "Deine roten Schleier", "tokens": ["Dei\u00b7ne", "ro\u00b7ten", "Schlei\u00b7er"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "L\u00fcfte Venusine,", "tokens": ["L\u00fcf\u00b7te", "Ve\u00b7nu\u00b7si\u00b7ne", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "NE", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Trag die H\u00fcften freier!\u00ab", "tokens": ["Trag", "die", "H\u00fcf\u00b7ten", "frei\u00b7er", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "ART", "NN", "ADJD", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.149": {"line.1": {"text": "\u00bbja, getreuer W\u00e4chter,", "tokens": ["\u00bb", "ja", ",", "ge\u00b7treu\u00b7er", "W\u00e4ch\u00b7ter", ","], "token_info": ["punct", "word", "punct", "word", "word", "punct"], "pos": ["$(", "PTKANT", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Fest bin ich entschlossen,", "tokens": ["Fest", "bin", "ich", "ent\u00b7schlos\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "VVPP", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Will zu Menschen gehen,", "tokens": ["Will", "zu", "Men\u00b7schen", "ge\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "APPR", "NN", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Die mich schwer verdrossen,", "tokens": ["Die", "mich", "schwer", "ver\u00b7dros\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADJD", "VVPP", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.150": {"line.1": {"text": "Die mich froh einst lobten", "tokens": ["Die", "mich", "froh", "einst", "lob\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "ADJD", "ADV", "VVFIN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Und dann gegen alle", "tokens": ["Und", "dann", "ge\u00b7gen", "al\u00b7le"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ADV", "APPR", "PIAT"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Fleischesl\u00fcste tobten.", "tokens": ["Flei\u00b7sches\u00b7l\u00fcs\u00b7te", "tob\u00b7ten", "."], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.151": {"line.1": {"text": "Diese armen Menschen", "tokens": ["Die\u00b7se", "ar\u00b7men", "Men\u00b7schen"], "token_info": ["word", "word", "word"], "pos": ["PDAT", "ADJA", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Will ich jetzt begl\u00fccken.", "tokens": ["Will", "ich", "jetzt", "be\u00b7gl\u00fc\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Ohne Leibesliebe", "tokens": ["Oh\u00b7ne", "Lei\u00b7bes\u00b7lie\u00b7be"], "token_info": ["word", "word"], "pos": ["APPR", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Geht die Seel' in St\u00fccken.", "tokens": ["Geht", "die", "Seel'", "in", "St\u00fc\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "APPR", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.152": {"line.1": {"text": "Ich will nicht mehr bangen", "tokens": ["Ich", "will", "nicht", "mehr", "ban\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PTKNEG", "ADV", "VVINF"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Vorm Verstand der Zwerge", "tokens": ["Vorm", "Ver\u00b7stand", "der", "Zwer\u00b7ge"], "token_info": ["word", "word", "word", "word"], "pos": ["APPRART", "NN", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Und vor seinen Zangen.", "tokens": ["Und", "vor", "sei\u00b7nen", "Zan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.153": {"line.1": {"text": "Will mal Rom aufsuchen,", "tokens": ["Will", "mal", "Rom", "auf\u00b7su\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "NE", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Wo man mich versto\u00dfen;", "tokens": ["Wo", "man", "mich", "ver\u00b7sto\u00b7\u00dfen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "PRF", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Wo man einst aus Wollust", "tokens": ["Wo", "man", "einst", "aus", "Wol\u00b7lust"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "PIS", "ADV", "APPR", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "T\u00f6tete mit Rosen.", "tokens": ["T\u00f6\u00b7te\u00b7te", "mit", "Ro\u00b7sen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.154": {"line.1": {"text": "M\u00f6glich, da\u00df ich finde", "tokens": ["M\u00f6g\u00b7lich", ",", "da\u00df", "ich", "fin\u00b7de"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["ADJD", "$,", "KOUS", "PPER", "VVFIN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Dort noch eine Gr\u00f6\u00dfe,", "tokens": ["Dort", "noch", "ei\u00b7ne", "Gr\u00f6\u00b7\u00dfe", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Der ich mich verbinde.", "tokens": ["Der", "ich", "mich", "ver\u00b7bin\u00b7de", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PRF", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.155": {"line.1": {"text": "Erst will ich mich kleiden", "tokens": ["Erst", "will", "ich", "mich", "klei\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PPER", "PRF", "VVINF"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Gleich den Menschenfrauen,", "tokens": ["Gleich", "den", "Men\u00b7schen\u00b7frau\u00b7en", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Die heut in den St\u00e4dten", "tokens": ["Die", "heut", "in", "den", "St\u00e4d\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "APPR", "ART", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "In die Welt sich trauen.", "tokens": ["In", "die", "Welt", "sich", "trau\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PRF", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.156": {"line.1": {"text": "Auch sind stolze Kleider,", "tokens": ["Auch", "sind", "stol\u00b7ze", "Klei\u00b7der", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADJA", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Trotz der G\u00f6tterw\u00fcrde,", "tokens": ["Trotz", "der", "G\u00f6t\u00b7ter\u00b7w\u00fcr\u00b7de", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Keinem Weib zur B\u00fcrde.\u00ab", "tokens": ["Kei\u00b7nem", "Weib", "zur", "B\u00fcr\u00b7de", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["PIAT", "NN", "APPRART", "NN", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.157": {"line.1": {"text": "\u00bbherrin Venusine,", "tokens": ["\u00bb", "her\u00b7rin", "Ve\u00b7nu\u00b7si\u00b7ne", ","], "token_info": ["punct", "word", "word", "punct"], "pos": ["$(", "ADV", "NE", "$,"], "meter": "+--+--", "measure": "dactylic.di.plus"}, "line.2": {"text": "Kleider, die verbergen", "tokens": ["Klei\u00b7der", ",", "die", "ver\u00b7ber\u00b7gen"], "token_info": ["word", "punct", "word", "word"], "pos": ["NN", "$,", "PRELS", "VVINF"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "M\u00e4ngel nur und reizen", "tokens": ["M\u00e4n\u00b7gel", "nur", "und", "rei\u00b7zen"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "ADV", "KON", "VVINF"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Unter Menschenzwergen.\u00ab", "tokens": ["Un\u00b7ter", "Men\u00b7schenz\u00b7wer\u00b7gen", ".", "\u00ab"], "token_info": ["word", "word", "punct", "punct"], "pos": ["APPR", "NN", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.158": {"line.1": {"text": "So sprach wie die Alten", "tokens": ["So", "sprach", "wie", "die", "Al\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "KOKOM", "ART", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Eckehardt der Junge,", "tokens": ["E\u00b7cke\u00b7hardt", "der", "Jun\u00b7ge", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Konnt' den Mund nicht halten.", "tokens": ["Konnt'", "den", "Mund", "nicht", "hal\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ART", "NN", "PTKNEG", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.159": {"line.1": {"text": "\u00bbeckehardt, viel weiser", "tokens": ["\u00bb", "ec\u00b7ke\u00b7hardt", ",", "viel", "wei\u00b7ser"], "token_info": ["punct", "word", "punct", "word", "word"], "pos": ["$(", "ADJD", "$,", "PIAT", "ADJA"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Hast Du sonst geraten.", "tokens": ["Hast", "Du", "sonst", "ge\u00b7ra\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Kleider sind die Sauce", "tokens": ["Klei\u00b7der", "sind", "die", "Sau\u00b7ce"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "VAFIN", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Schmackhaft bei dem Braten.", "tokens": ["Schmack\u00b7haft", "bei", "dem", "Bra\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.160": {"line.1": {"text": "Jederzeit bei Damen", "tokens": ["Je\u00b7der\u00b7zeit", "bei", "Da\u00b7men"], "token_info": ["word", "word", "word"], "pos": ["ADV", "APPR", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Waren Kleider n\u00f6tig,", "tokens": ["Wa\u00b7ren", "Klei\u00b7der", "n\u00f6\u00b7tig", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "ADJD", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Das geh\u00f6rt zum Rahmen.", "tokens": ["Das", "ge\u00b7h\u00f6rt", "zum", "Rah\u00b7men", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPRART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.161": {"line.1": {"text": "In den Tausend Jahren,", "tokens": ["In", "den", "Tau\u00b7send", "Jah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "CARD", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Die ich hier versonnen", "tokens": ["Die", "ich", "hier", "ver\u00b7son\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "PPER", "ADV", "VVINF"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "In dem H\u00f6rselberge,", "tokens": ["In", "dem", "H\u00f6r\u00b7sel\u00b7ber\u00b7ge", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,"], "meter": "+-++-+", "measure": "unknown.measure.tetra"}, "line.4": {"text": "Hab ich's ausgesponnen.", "tokens": ["Hab", "ich's", "aus\u00b7ge\u00b7spon\u00b7nen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PIS", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.162": {"line.1": {"text": "Ja, sogar das Schn\u00fcren", "tokens": ["Ja", ",", "so\u00b7gar", "das", "Schn\u00fc\u00b7ren"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["PTKANT", "$,", "ADV", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Soll die Venus leiden,", "tokens": ["Soll", "die", "Ve\u00b7nus", "lei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Gilt es zu verf\u00fchren.", "tokens": ["Gilt", "es", "zu", "ver\u00b7f\u00fch\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKZU", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.163": {"line.1": {"text": "Enger sind nicht Kleider", "tokens": ["En\u00b7ger", "sind", "nicht", "Klei\u00b7der"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "VAFIN", "PTKNEG", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Als die Einsamkeiten", "tokens": ["Als", "die", "Ein\u00b7sam\u00b7kei\u00b7ten"], "token_info": ["word", "word", "word"], "pos": ["KOUS", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "In dem H\u00f6rselberge,", "tokens": ["In", "dem", "H\u00f6r\u00b7sel\u00b7ber\u00b7ge", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,"], "meter": "+-++-+", "measure": "unknown.measure.tetra"}, "line.4": {"text": "Die mir Qual bereiten.", "tokens": ["Die", "mir", "Qual", "be\u00b7rei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "NN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.164": {"line.1": {"text": "Soll mal was geschehen,", "tokens": ["Soll", "mal", "was", "ge\u00b7sche\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "PIS", "VVPP", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Mu\u00df man nicht nur kritisch", "tokens": ["Mu\u00df", "man", "nicht", "nur", "kri\u00b7tisch"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VMFIN", "PIS", "PTKNEG", "ADV", "ADJD"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Drauf herniedersehen.", "tokens": ["Drauf", "her\u00b7nie\u00b7der\u00b7se\u00b7hen", "."], "token_info": ["word", "word", "punct"], "pos": ["PAV", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.165": {"line.1": {"text": "Bringt mir alle Dinge,", "tokens": ["Bringt", "mir", "al\u00b7le", "Din\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PIAT", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Die ein Weib heut zieren!", "tokens": ["Die", "ein", "Weib", "heut", "zie\u00b7ren", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "ADV", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Alles will ich tragen,", "tokens": ["Al\u00b7les", "will", "ich", "tra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "PPER", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Nichts soll mich genieren.\u00ab", "tokens": ["Nichts", "soll", "mich", "ge\u00b7nie\u00b7ren", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["PIS", "VMFIN", "PPER", "VVINF", "$.", "$("], "meter": "+---+-", "measure": "dactylic.init"}}, "stanza.166": {"line.1": {"text": "Zofe Melusine", "tokens": ["Zo\u00b7fe", "Me\u00b7lu\u00b7si\u00b7ne"], "token_info": ["word", "word"], "pos": ["NN", "NE"], "meter": "+---+-", "measure": "dactylic.init"}, "line.2": {"text": "Naht beim Wink der Wimper,", "tokens": ["Naht", "beim", "Wink", "der", "Wim\u00b7per", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPRART", "NN", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Dient mit kluger Miene.", "tokens": ["Dient", "mit", "klu\u00b7ger", "Mie\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ADJA", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.167": {"line.1": {"text": "Bringt zuerst die Schuhe,", "tokens": ["Bringt", "zu\u00b7erst", "die", "Schu\u00b7he", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Doch die haben T\u00fccken.", "tokens": ["Doch", "die", "ha\u00b7ben", "T\u00fc\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VAFIN", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Ach, von hundert Paaren", "tokens": ["Ach", ",", "von", "hun\u00b7dert", "Paa\u00b7ren"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["ITJ", "$,", "APPR", "CARD", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Will nicht Eines gl\u00fccken.", "tokens": ["Will", "nicht", "Ei\u00b7nes", "gl\u00fc\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PTKNEG", "PIS", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.168": {"line.1": {"text": "Keines will recht sitzen.", "tokens": ["Kei\u00b7nes", "will", "recht", "sit\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "ADJD", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Zof' und G\u00f6ttin zerren,", "tokens": ["Zof'", "und", "G\u00f6t\u00b7tin", "zer\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "NN", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Zof' und G\u00f6ttin schwitzen.", "tokens": ["Zof'", "und", "G\u00f6t\u00b7tin", "schwit\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "NN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.169": {"line.1": {"text": "Venus F\u00fc\u00dfen waren", "tokens": ["Ve\u00b7nus", "F\u00fc\u00b7\u00dfen", "wa\u00b7ren"], "token_info": ["word", "word", "word"], "pos": ["NE", "NN", "VAFIN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Klein noch die Enormen,", "tokens": ["Klein", "noch", "die", "En\u00b7or\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Und man mu\u00dfte extra", "tokens": ["Und", "man", "mu\u00df\u00b7te", "ex\u00b7tra"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PIS", "VMFIN", "ADV"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Neue Schuhe formen.", "tokens": ["Neu\u00b7e", "Schu\u00b7he", "for\u00b7men", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.170": {"line.1": {"text": "F\u00fc\u00dfe leicht sich breiten,", "tokens": ["F\u00fc\u00b7\u00dfe", "leicht", "sich", "brei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "PRF", "ADJA", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Trug man nur Sandalen", "tokens": ["Trug", "man", "nur", "San\u00b7da\u00b7len"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PIS", "ADV", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Seit den Ewigkeiten.", "tokens": ["Seit", "den", "E\u00b7wig\u00b7kei\u00b7ten", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.171": {"line.1": {"text": "Eckhardt konnt' die Trauer", "tokens": ["Eck\u00b7hardt", "konnt'", "die", "Trau\u00b7er"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "VMFIN", "ART", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Nicht gleich \u00fcberwinden,", "tokens": ["Nicht", "gleich", "\u00fc\u00b7berw\u00b7in\u00b7den", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Als der Herrin F\u00fc\u00dfe", "tokens": ["Als", "der", "Her\u00b7rin", "F\u00fc\u00b7\u00dfe"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "In den Schuh'n verschwinden.", "tokens": ["In", "den", "Schuh'n", "ver\u00b7schwin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.172": {"line.1": {"text": "Nachdenklich im Gehen", "tokens": ["Nach\u00b7denk\u00b7lich", "im", "Ge\u00b7hen"], "token_info": ["word", "word", "word"], "pos": ["ADV", "APPRART", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Starrt' er sonst versunken", "tokens": ["Starrt'", "er", "sonst", "ver\u00b7sun\u00b7ken"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "VVINF"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Auf der G\u00f6ttin Zehen.", "tokens": ["Auf", "der", "G\u00f6t\u00b7tin", "Ze\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "CARD", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.173": {"line.1": {"text": "Konnt' sich dran durch Stunden", "tokens": ["Konnt'", "sich", "dran", "durch", "Stun\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VMFIN", "PRF", "PAV", "APPR", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Wie an R\u00f6slein weiden,", "tokens": ["Wie", "an", "R\u00f6s\u00b7lein", "wei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPR", "NN", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Doch jetzt litt sein Auge", "tokens": ["Doch", "jetzt", "litt", "sein", "Au\u00b7ge"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "PPOSAT", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "H\u00fchneraugenleiden.", "tokens": ["H\u00fch\u00b7ner\u00b7au\u00b7gen\u00b7lei\u00b7den", "."], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.174": {"line.1": {"text": "Stets doch blieb der Alte,", "tokens": ["Stets", "doch", "blieb", "der", "Al\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Eckehardt der Junge", "tokens": ["E\u00b7cke\u00b7hardt", "der", "Jun\u00b7ge"], "token_info": ["word", "word", "word"], "pos": ["NE", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Mit der Denkerfalte.", "tokens": ["Mit", "der", "Den\u00b7ker\u00b7fal\u00b7te", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.175": {"line.1": {"text": "Melusine brachte", "tokens": ["Me\u00b7lu\u00b7si\u00b7ne", "brach\u00b7te"], "token_info": ["word", "word"], "pos": ["NE", "VVFIN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Spitzen aus den St\u00e4dten,", "tokens": ["Spit\u00b7zen", "aus", "den", "St\u00e4d\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Die auch h\u00f6chste Damen", "tokens": ["Die", "auch", "h\u00f6chs\u00b7te", "Da\u00b7men"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADV", "ADJA", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Gern getragen h\u00e4tten.", "tokens": ["Gern", "ge\u00b7tra\u00b7gen", "h\u00e4t\u00b7ten", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "VVPP", "VAFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.176": {"line.1": {"text": "Doch die seidnen Faden", "tokens": ["Doch", "die", "seid\u00b7nen", "Fa\u00b7den"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "PPOSAT", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Kitzeln sehr die G\u00f6ttin,", "tokens": ["Kit\u00b7zeln", "sehr", "die", "G\u00f6t\u00b7tin", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Wie ein Nest von Maden.", "tokens": ["Wie", "ein", "Nest", "von", "Ma\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "APPR", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.177": {"line.1": {"text": "Niemals man je besser", "tokens": ["Nie\u00b7mals", "man", "je", "bes\u00b7ser"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "PIS", "ADV", "ADJD"], "meter": "+--+--", "measure": "dactylic.di.plus"}, "line.2": {"text": "Eine Frau frisierte,", "tokens": ["Ei\u00b7ne", "Frau", "fri\u00b7sier\u00b7te", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Als klein Amor selber", "tokens": ["Als", "klein", "A\u00b7mor", "sel\u00b7ber"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ADJD", "NE", "ADV"], "meter": "-++-+-", "measure": "unknown.measure.tri"}, "line.4": {"text": "Die Mama toupierte.", "tokens": ["Die", "Ma\u00b7ma", "tou\u00b7pier\u00b7te", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.178": {"line.1": {"text": "Still h\u00e4lt sie ohn Klagen,", "tokens": ["Still", "h\u00e4lt", "sie", "ohn", "Kla\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "PPER", "APPR", "NN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Trug bald Nadeln, K\u00e4mme", "tokens": ["Trug", "bald", "Na\u00b7deln", ",", "K\u00e4m\u00b7me"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["NN", "ADV", "NN", "$,", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Und auch Haareinlagen.", "tokens": ["Und", "auch", "Haa\u00b7rein\u00b7la\u00b7gen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADV", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.179": {"line.1": {"text": "Zofe Melusine", "tokens": ["Zo\u00b7fe", "Me\u00b7lu\u00b7si\u00b7ne"], "token_info": ["word", "word"], "pos": ["NN", "NE"], "meter": "+---+-", "measure": "dactylic.init"}, "line.2": {"text": "Schn\u00fcrt sie auch ins nette", "tokens": ["Schn\u00fcrt", "sie", "auch", "ins", "net\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "APPRART", "ADJA"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Fischgebeinte schlanke", "tokens": ["Fischge\u00b7bein\u00b7te", "schlan\u00b7ke"], "token_info": ["word", "word"], "pos": ["NN", "VVFIN"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "Seidene Korsette.", "tokens": ["Sei\u00b7de\u00b7ne", "Kor\u00b7set\u00b7te", "."], "token_info": ["word", "word", "punct"], "pos": ["PPOSAT", "NN", "$."], "meter": "+---+-", "measure": "dactylic.init"}}, "stanza.180": {"line.1": {"text": "Eckehardt erbittert", "tokens": ["E\u00b7cke\u00b7hardt", "er\u00b7bit\u00b7tert"], "token_info": ["word", "word"], "pos": ["NE", "VVPP"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Flucht auf seidne Kerker,", "tokens": ["Flucht", "auf", "seid\u00b7ne", "Ker\u00b7ker", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Drin man sich vergittert.", "tokens": ["Drin", "man", "sich", "ver\u00b7git\u00b7tert", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "PRF", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.181": {"line.1": {"text": "\u00bbherrin, Deine Br\u00fcste", "tokens": ["\u00bb", "her\u00b7rin", ",", "Dei\u00b7ne", "Br\u00fcs\u00b7te"], "token_info": ["punct", "word", "punct", "word", "word"], "pos": ["$(", "PTKVZ", "$,", "PPOSAT", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Werden noch zwei Wunden", "tokens": ["Wer\u00b7den", "noch", "zwei", "Wun\u00b7den"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "CARD", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Hinterm Fischbeingitter", "tokens": ["Hin\u00b7term", "Fischbein\u00b7git\u00b7ter"], "token_info": ["word", "word"], "pos": ["APPRART", "NN"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "Lebst Du keine Stunden.\u00ab", "tokens": ["Lebst", "Du", "kei\u00b7ne", "Stun\u00b7den", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PPER", "PIAT", "NN", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.182": {"line.1": {"text": "Kaum hat er's gesprochen", "tokens": ["Kaum", "hat", "er's", "ge\u00b7spro\u00b7chen"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PIS", "VVPP"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Kracht schon das Korsette,", "tokens": ["Kracht", "schon", "das", "Kor\u00b7set\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ART", "NN", "$,"], "meter": "++--+-", "measure": "trochaic.tri.relaxed"}, "line.3": {"text": "Hing geknickt zerbrochen.", "tokens": ["Hing", "ge\u00b7knickt", "zer\u00b7bro\u00b7chen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "VVPP", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.183": {"line.1": {"text": "Wie zwei F\u00fcllen sprangen", "tokens": ["Wie", "zwei", "F\u00fcl\u00b7len", "spran\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "CARD", "NN", "VVINF"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Venusinens Br\u00fcste", "tokens": ["Ve\u00b7nu\u00b7si\u00b7nens", "Br\u00fcs\u00b7te"], "token_info": ["word", "word"], "pos": ["NE", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Bei dem ersten Atem", "tokens": ["Bei", "dem", "ers\u00b7ten", "A\u00b7tem"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Durchs Gebeinger\u00fcste.", "tokens": ["Durchs", "Ge\u00b7bein\u00b7ge\u00b7r\u00fcs\u00b7te", "."], "token_info": ["word", "word", "punct"], "pos": ["APPRART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.184": {"line.1": {"text": "Auch ein neues Mieder", "tokens": ["Auch", "ein", "neu\u00b7es", "Mie\u00b7der"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ART", "ADJA", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Tat nicht lange halten,", "tokens": ["Tat", "nicht", "lan\u00b7ge", "hal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PTKNEG", "ADV", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Leicht knickt sie es nieder.", "tokens": ["Leicht", "knickt", "sie", "es", "nie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "PPER", "PPER", "PTKVZ", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.185": {"line.1": {"text": "Bis man ihr die B\u00fcste", "tokens": ["Bis", "man", "ihr", "die", "B\u00fcs\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PIS", "PPER", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Fa\u00dft in Draht und Banden,", "tokens": ["Fa\u00dft", "in", "Draht", "und", "Ban\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "NN", "KON", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Und die wilden Br\u00fcste", "tokens": ["Und", "die", "wil\u00b7den", "Br\u00fcs\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Sich gel\u00e4hmt dreinfanden.", "tokens": ["Sich", "ge\u00b7l\u00e4hmt", "drein\u00b7fan\u00b7den", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PRF", "ADJD", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.186": {"line.1": {"text": "Strumpfband und auch Kragen,", "tokens": ["Strumpf\u00b7band", "und", "auch", "Kra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "ADV", "NN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Hutnadeln und H\u00fcte", "tokens": ["Hut\u00b7na\u00b7deln", "und", "H\u00fc\u00b7te"], "token_info": ["word", "word", "word"], "pos": ["NN", "KON", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Lernte sie zu tragen.", "tokens": ["Lern\u00b7te", "sie", "zu", "tra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKZU", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.187": {"line.1": {"text": "Venusin studierte", "tokens": ["Ve\u00b7nu\u00b7sin", "stu\u00b7dier\u00b7te"], "token_info": ["word", "word"], "pos": ["NE", "VVFIN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Auch die Umgangsb\u00fccher,", "tokens": ["Auch", "die", "Um\u00b7gangs\u00b7b\u00fc\u00b7cher", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Lernt mit Gabeln essen", "tokens": ["Lernt", "mit", "Ga\u00b7beln", "es\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "NN", "VVINF"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Und braucht Taschent\u00fccher.", "tokens": ["Und", "braucht", "Ta\u00b7schen\u00b7t\u00fc\u00b7cher", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.188": {"line.1": {"text": "So ward sie zur ", "tokens": ["So", "ward", "sie", "zur"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "APPRART"], "meter": "-+-+", "measure": "iambic.di"}, "line.2": {"text": "Bei der Hemdabnahme.", "tokens": ["Bei", "der", "Hemd\u00b7ab\u00b7nah\u00b7me", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.189": {"line.1": {"text": "Eins nur macht ihr Sorge:", "tokens": ["Eins", "nur", "macht", "ihr", "Sor\u00b7ge", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "VVFIN", "PPOSAT", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Kaum ist sie entkleidet,", "tokens": ["Kaum", "ist", "sie", "ent\u00b7klei\u00b7det", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "VVPP", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Seufzt sie, da\u00df sie nirgends", "tokens": ["Seufzt", "sie", ",", "da\u00df", "sie", "nir\u00b7gends"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "PPER", "$,", "KOUS", "PPER", "ADV"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Ach, an Fehlern leidet.", "tokens": ["Ach", ",", "an", "Feh\u00b7lern", "lei\u00b7det", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "APPR", "NN", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.190": {"line.1": {"text": "Nirgends sitzt ein Flecken", "tokens": ["Nir\u00b7gends", "sitzt", "ein", "Fle\u00b7cken"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Irgendwo am Leibe,", "tokens": ["Ir\u00b7gend\u00b7wo", "am", "Lei\u00b7be", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Nichts kann sie entdecken.", "tokens": ["Nichts", "kann", "sie", "ent\u00b7de\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "PPER", "VVINF", "$."], "meter": "++--+-", "measure": "trochaic.tri.relaxed"}}, "stanza.191": {"line.1": {"text": "\u00bbund ich will nicht besser", "tokens": ["\u00bb", "und", "ich", "will", "nicht", "bes\u00b7ser"], "token_info": ["punct", "word", "word", "word", "word", "word"], "pos": ["$(", "KON", "PPER", "VMFIN", "PTKNEG", "ADJD"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Als die Erdenfrauen", "tokens": ["Als", "die", "Er\u00b7den\u00b7frau\u00b7en"], "token_info": ["word", "word", "word"], "pos": ["KOUS", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Mich in M\u00e4nnern\u00e4he", "tokens": ["Mich", "in", "M\u00e4n\u00b7ner\u00b7n\u00e4\u00b7he"], "token_info": ["word", "word", "word"], "pos": ["PPER", "APPR", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Fleckenlos getrauen.", "tokens": ["Fle\u00b7cken\u00b7los", "ge\u00b7trau\u00b7en", "."], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.192": {"line.1": {"text": "Dieses w\u00e4r wie Tadel", "tokens": ["Die\u00b7ses", "w\u00e4r", "wie", "Ta\u00b7del"], "token_info": ["word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "KOKOM", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Schwachen Menschenkindern,", "tokens": ["Schwa\u00b7chen", "Men\u00b7schen\u00b7kin\u00b7dern", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Und ich halt auf Adel.\u00ab", "tokens": ["Und", "ich", "halt", "auf", "A\u00b7del", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "PPER", "VVFIN", "APPR", "NN", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.193": {"line.1": {"text": "Doch die Zofe meinte:", "tokens": ["Doch", "die", "Zo\u00b7fe", "mein\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "\u00bbg\u00f6ttin seid Ihr eben!", "tokens": ["\u00bb", "g\u00f6t\u00b7tin", "seid", "Ihr", "e\u00b7ben", "!"], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "NE", "VAFIN", "PPER", "ADV", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "G\u00f6ttern ist nicht zugleich", "tokens": ["G\u00f6t\u00b7tern", "ist", "nicht", "zu\u00b7gleich"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "VAFIN", "PTKNEG", "ADV"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.4": {"text": "Menschliches gegeben.", "tokens": ["Menschli\u00b7ches", "ge\u00b7ge\u00b7ben", "."], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVPP", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.194": {"line.1": {"text": "Was sollten bezwecken,", "tokens": ["Was", "soll\u00b7ten", "be\u00b7zwe\u00b7cken", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "VVINF", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Herrin Venusine,", "tokens": ["Her\u00b7rin", "Ve\u00b7nu\u00b7si\u00b7ne", ","], "token_info": ["word", "word", "punct"], "pos": ["NE", "NE", "$,"], "meter": "+--+--", "measure": "dactylic.di.plus"}, "line.3": {"text": "Schwarze Leberflecken?\u00ab", "tokens": ["Schwar\u00b7ze", "Le\u00b7ber\u00b7fle\u00b7cken", "?", "\u00ab"], "token_info": ["word", "word", "punct", "punct"], "pos": ["ADJA", "NN", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.195": {"line.1": {"text": "\u00bbwisse,\u00ab spricht die G\u00f6ttin,", "tokens": ["\u00bb", "wis\u00b7se", ",", "\u00ab", "spricht", "die", "G\u00f6t\u00b7tin", ","], "token_info": ["punct", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "$,", "$(", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "\u00bbzu viel Reinheit blendet,", "tokens": ["\u00bb", "zu", "viel", "Rein\u00b7heit", "blen\u00b7det", ","], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "PIAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Da\u00df das Alltagsauge", "tokens": ["Da\u00df", "das", "All\u00b7tags\u00b7au\u00b7ge"], "token_info": ["word", "word", "word"], "pos": ["KOUS", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Sich dann abseits wendet.", "tokens": ["Sich", "dann", "ab\u00b7seits", "wen\u00b7det", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PRF", "ADV", "ADV", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.196": {"line.1": {"text": "Vor dem steifen Strau\u00dfe", "tokens": ["Vor", "dem", "stei\u00b7fen", "Strau\u00b7\u00dfe"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Tadelloser Lilien", "tokens": ["Ta\u00b7del\u00b7lo\u00b7ser", "Li\u00b7li\u00b7en"], "token_info": ["word", "word"], "pos": ["ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ist man nicht zu Hause.", "tokens": ["Ist", "man", "nicht", "zu", "Hau\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "PTKNEG", "APPR", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.197": {"line.1": {"text": "Frauen geben Heimat", "tokens": ["Frau\u00b7en", "ge\u00b7ben", "Hei\u00b7mat"], "token_info": ["word", "word", "word"], "pos": ["NN", "VVINF", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Abgehetzten M\u00e4nnern,", "tokens": ["Ab\u00b7ge\u00b7hetz\u00b7ten", "M\u00e4n\u00b7nern", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Die am Tage starten", "tokens": ["Die", "am", "Ta\u00b7ge", "star\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "APPRART", "NN", "VVFIN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Gleich den besten Rennern,", "tokens": ["Gleich", "den", "bes\u00b7ten", "Ren\u00b7nern", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.198": {"line.1": {"text": "Die gern Hindernisse", "tokens": ["Die", "gern", "Hin\u00b7der\u00b7nis\u00b7se"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Halszerbrechend nehmen", "tokens": ["Hals\u00b7zer\u00b7bre\u00b7chend", "neh\u00b7men"], "token_info": ["word", "word"], "pos": ["ADJD", "VVINF"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Und das Ungewisse.", "tokens": ["Und", "das", "Un\u00b7ge\u00b7wis\u00b7se", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.199": {"line.1": {"text": "Kommen solche m\u00fcde", "tokens": ["Kom\u00b7men", "sol\u00b7che", "m\u00fc\u00b7de"], "token_info": ["word", "word", "word"], "pos": ["NN", "PIAT", "ADJA"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Abends von dem Traben,", "tokens": ["A\u00b7bends", "von", "dem", "Tra\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "St\u00f6rt sie allzu Hohes,", "tokens": ["St\u00f6rt", "sie", "all\u00b7zu", "Ho\u00b7hes", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKA", "ADJA", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Weil sie's Aug voll haben", "tokens": ["Weil", "sie's", "Aug", "voll", "ha\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ADJA", "NN", "ADJD", "VAFIN"], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.200": {"line.1": {"text": "Voll von Staub und Kohlen,", "tokens": ["Voll", "von", "Staub", "und", "Koh\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "NN", "KON", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Sehen oft noch Ziffern,", "tokens": ["Se\u00b7hen", "oft", "noch", "Zif\u00b7fern", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADV", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Die sich \u00fcberholen.", "tokens": ["Die", "sich", "\u00fc\u00b7berh\u00b7o\u00b7len", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "PRF", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.201": {"line.1": {"text": "Eine kurze Spanne", "tokens": ["Ei\u00b7ne", "kur\u00b7ze", "Span\u00b7ne"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Reicht die Nacht zum Morgen.", "tokens": ["Reicht", "die", "Nacht", "zum", "Mor\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "APPRART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Dann pfeift die Maschine \u2013", "tokens": ["Dann", "pfeift", "die", "Ma\u00b7schi\u00b7ne", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$("], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "Feilschend kommen Sorgen.", "tokens": ["Feil\u00b7schend", "kom\u00b7men", "Sor\u00b7gen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.202": {"line.1": {"text": "In ", "tokens": ["In"], "token_info": ["word"], "pos": ["APPR"], "meter": "-", "measure": "single.down"}, "line.2": {"text": "Passen keine ", "tokens": ["Pas\u00b7sen", "kei\u00b7ne"], "token_info": ["word", "word"], "pos": ["NN", "PIAT"], "meter": "+-+-", "measure": "trochaic.di"}}, "stanza.203": {"line.1": {"text": "Mehr denn ", "tokens": ["Mehr", "denn"], "token_info": ["word", "word"], "pos": ["PIAT", "KON"], "meter": "-+", "measure": "iambic.single"}, "line.2": {"text": "Ist dem Herz erquickend,", "tokens": ["Ist", "dem", "Herz", "er\u00b7qui\u00b7ckend", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Stimmt den K\u00f6rper milder.", "tokens": ["Stimmt", "den", "K\u00f6r\u00b7per", "mil\u00b7der", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.204": {"line.1": {"text": "Traulichkeit zu wecken", "tokens": ["Trau\u00b7lich\u00b7keit", "zu", "we\u00b7cken"], "token_info": ["word", "word", "word"], "pos": ["NN", "PTKZU", "VVINF"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Will am G\u00f6tterleibe", "tokens": ["Will", "am", "G\u00f6t\u00b7ter\u00b7lei\u00b7be"], "token_info": ["word", "word", "word"], "pos": ["VMFIN", "APPRART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Ich die Leberflecken.", "tokens": ["Ich", "die", "Le\u00b7ber\u00b7fle\u00b7cken", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.205": {"line.1": {"text": "Eile Melusine,", "tokens": ["Ei\u00b7le", "Me\u00b7lu\u00b7si\u00b7ne", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "NE", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Hol den Mediziner!", "tokens": ["Hol", "den", "Me\u00b7di\u00b7zi\u00b7ner", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Er sei heut nicht Krankheits-", "tokens": ["Er", "sei", "heut", "nicht", "Krank\u00b7heits"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "PTKNEG", "TRUNC"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "Sondern Sch\u00f6nheitsdiener.", "tokens": ["Son\u00b7dern", "Sch\u00f6n\u00b7heits\u00b7die\u00b7ner", "."], "token_info": ["word", "word", "punct"], "pos": ["KON", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.206": {"line.1": {"text": "Soll mir mit Lanzetten", "tokens": ["Soll", "mir", "mit", "Lan\u00b7zet\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["VMFIN", "PPER", "APPR", "NN"], "meter": "+--+--", "measure": "dactylic.di.plus"}, "line.2": {"text": "Leberflecken impfen,", "tokens": ["Le\u00b7ber\u00b7fle\u00b7cken", "imp\u00b7fen", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Von den braunen netten.\u00ab", "tokens": ["Von", "den", "brau\u00b7nen", "net\u00b7ten", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.207": {"line.1": {"text": "\u00bbschwerlich,\u00ab sagt die Zofe,", "tokens": ["\u00bb", "schwer\u00b7lich", ",", "\u00ab", "sagt", "die", "Zo\u00b7fe", ","], "token_info": ["punct", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "$,", "$(", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "\u00bbwird ein Arzt sich finden,", "tokens": ["\u00bb", "wird", "ein", "Arzt", "sich", "fin\u00b7den", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VAFIN", "ART", "NN", "PRF", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Weil die Luft im Berge", "tokens": ["Weil", "die", "Luft", "im", "Ber\u00b7ge"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "APPRART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Menschen nicht verwinden.", "tokens": ["Men\u00b7schen", "nicht", "ver\u00b7win\u00b7den", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PTKNEG", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.208": {"line.1": {"text": "Wer von all den k\u00fchlen,", "tokens": ["Wer", "von", "all", "den", "k\u00fch\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "PIAT", "ART", "ADJA", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Welche Leichen schneiden,", "tokens": ["Wel\u00b7che", "Lei\u00b7chen", "schnei\u00b7den", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PWAT", "NN", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Wird nicht Venus f\u00fchlen?", "tokens": ["Wird", "nicht", "Ve\u00b7nus", "f\u00fch\u00b7len", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PTKNEG", "NN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.209": {"line.1": {"text": "Und dann mu\u00df er sterben,", "tokens": ["Und", "dann", "mu\u00df", "er", "ster\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VMFIN", "PPER", "VVINF", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Kann er nichts erreichen,", "tokens": ["Kann", "er", "nichts", "er\u00b7rei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PIS", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "W\u00fcrde er entlassen", "tokens": ["W\u00fcr\u00b7de", "er", "ent\u00b7las\u00b7sen"], "token_info": ["word", "word", "word"], "pos": ["VAFIN", "PPER", "VVINF"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Ohne Liebeszeichen,", "tokens": ["Oh\u00b7ne", "Lie\u00b7bes\u00b7zei\u00b7chen", ","], "token_info": ["word", "word", "punct"], "pos": ["APPR", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.210": {"line.1": {"text": "W\u00fcrde nie genesen,", "tokens": ["W\u00fcr\u00b7de", "nie", "ge\u00b7ne\u00b7sen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "VVPP", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Weil er hier im Berge", "tokens": ["Weil", "er", "hier", "im", "Ber\u00b7ge"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "APPRART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Ohne Luft gewesen.", "tokens": ["Oh\u00b7ne", "Luft", "ge\u00b7we\u00b7sen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "VAPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.211": {"line.1": {"text": "Darum Herrin sage", "tokens": ["Da\u00b7rum", "Her\u00b7rin", "sa\u00b7ge"], "token_info": ["word", "word", "word"], "pos": ["PAV", "NN", "VVFIN"], "meter": "-+-+--", "measure": "unknown.measure.di"}, "line.2": {"text": "Deine Wunschangaben!", "tokens": ["Dei\u00b7ne", "Wun\u00b7schan\u00b7ga\u00b7ben", "!"], "token_info": ["word", "word", "punct"], "pos": ["PPOSAT", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Wo willst du die Flecken,", "tokens": ["Wo", "willst", "du", "die", "Fle\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "PPER", "ART", "NN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "Die Versch\u00e4mten haben?", "tokens": ["Die", "Ver\u00b7sch\u00e4m\u00b7ten", "ha\u00b7ben", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.212": {"line.1": {"text": "Wie ich es dann mache,", "tokens": ["Wie", "ich", "es", "dann", "ma\u00b7che", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PPER", "ADV", "VVFIN", "$,"], "meter": "+---+-", "measure": "dactylic.init"}, "line.2": {"text": "Dir die Flecklein hole,", "tokens": ["Dir", "die", "Flec\u00b7klein", "ho\u00b7le", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Sei dann meine Sache.\u00ab", "tokens": ["Sei", "dann", "mei\u00b7ne", "Sa\u00b7che", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["VAFIN", "ADV", "PPOSAT", "NN", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.213": {"line.1": {"text": "\u00bbkluge Melusine,\u00ab", "tokens": ["\u00bb", "klu\u00b7ge", "Me\u00b7lu\u00b7si\u00b7ne", ",", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "punct"], "pos": ["$(", "ADJA", "NN", "$,", "$("], "meter": "+---+-", "measure": "dactylic.init"}, "line.2": {"text": "Venusin err\u00f6tet,", "tokens": ["Ve\u00b7nu\u00b7sin", "er\u00b7r\u00f6\u00b7tet", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVPP", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "\u00bbjegliche Sekunde", "tokens": ["\u00bb", "jeg\u00b7li\u00b7che", "Se\u00b7kun\u00b7de"], "token_info": ["punct", "word", "word"], "pos": ["$(", "PIAT", "NN"], "meter": "+---+-", "measure": "dactylic.init"}, "line.4": {"text": "Wird ein Mensch get\u00f6tet.", "tokens": ["Wird", "ein", "Mensch", "ge\u00b7t\u00f6\u00b7tet", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.214": {"line.1": {"text": "Stirbt er mal am Herzen,", "tokens": ["Stirbt", "er", "mal", "am", "Her\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "APPRART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Sind das auch bei G\u00f6ttern", "tokens": ["Sind", "das", "auch", "bei", "G\u00f6t\u00b7tern"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "PDS", "ADV", "APPR", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Einzig echte Schmerzen.", "tokens": ["Ein\u00b7zig", "ech\u00b7te", "Schmer\u00b7zen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "ADJA", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.215": {"line.1": {"text": "Wenn er mir gefiele,", "tokens": ["Wenn", "er", "mir", "ge\u00b7fie\u00b7le", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "W\u00fcrd' ich ihn nicht schonen.", "tokens": ["W\u00fcrd'", "ich", "ihn", "nicht", "scho\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PPER", "PTKNEG", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Aber sollt' er sterben,", "tokens": ["A\u00b7ber", "sollt'", "er", "ster\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Nur weil wir hier wohnen,", "tokens": ["Nur", "weil", "wir", "hier", "woh\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PPER", "ADV", "VVINF", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.216": {"line.1": {"text": "Weil die Luft im Berge", "tokens": ["Weil", "die", "Luft", "im", "Ber\u00b7ge"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "APPRART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Schon den Tod kann bringen", "tokens": ["Schon", "den", "Tod", "kann", "brin\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "VMFIN", "VVINF"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Einem Menschenzwerge?!", "tokens": ["Ei\u00b7nem", "Men\u00b7schenz\u00b7wer\u00b7ge", "?!"], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.217": {"line.1": {"text": "Flott weg mal zu t\u00f6ten", "tokens": ["Flott", "weg", "mal", "zu", "t\u00f6\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "ADV", "ADV", "PTKZU", "VVINF"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Lieb ich sonst ohn' Ma\u00dfen,", "tokens": ["Lieb", "ich", "sonst", "ohn'", "Ma\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "APPR", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Heut' doch will ich Deinem", "tokens": ["Heut'", "doch", "will", "ich", "Dei\u00b7nem"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "VMFIN", "PPER", "PPOSAT"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Rat mich \u00fcberlassen.", "tokens": ["Rat", "mich", "\u00fc\u00b7ber\u00b7las\u00b7sen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PPER", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.218": {"line.1": {"text": "Geh und bring die Flecken!", "tokens": ["Geh", "und", "bring", "die", "Fle\u00b7cken", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Kann ich nicht entdecken\u00ab.", "tokens": ["Kann", "ich", "nicht", "ent\u00b7de\u00b7cken", "\u00ab", "."], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["VMFIN", "PPER", "PTKNEG", "VVINF", "$(", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.219": {"line.1": {"text": "Melusine kichert", "tokens": ["Me\u00b7lu\u00b7si\u00b7ne", "ki\u00b7chert"], "token_info": ["word", "word"], "pos": ["NE", "VVFIN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Und ist schon verschwunden;", "tokens": ["Und", "ist", "schon", "ver\u00b7schwun\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "VVPP", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Hat verj\u00fcngt den Eckhardt", "tokens": ["Hat", "ver\u00b7j\u00fcngt", "den", "Eck\u00b7hardt"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "VVFIN", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Unterm Tor gefunden.", "tokens": ["Un\u00b7term", "Tor", "ge\u00b7fun\u00b7den", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.220": {"line.1": {"text": "Spricht: \u00bbKomm' auf ne Weile!", "tokens": ["Spricht", ":", "\u00bb", "Komm'", "auf", "ne", "Wei\u00b7le", "!"], "token_info": ["word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$.", "$(", "VVIMP", "APPR", "ADJA", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Kannst jetzt etwas lernen.", "tokens": ["Kannst", "jetzt", "et\u00b7was", "ler\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "PIS", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Schnell, ich habe Eile!", "tokens": ["Schnell", ",", "ich", "ha\u00b7be", "Ei\u00b7le", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "PPER", "VAFIN", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.221": {"line.1": {"text": "Sieh, ich will zum Arzte,", "tokens": ["Sieh", ",", "ich", "will", "zum", "Arz\u00b7te", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PPER", "VMFIN", "APPRART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Und er soll mich impfen,", "tokens": ["Und", "er", "soll", "mich", "imp\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VMFIN", "PPER", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Da\u00df uns nicht die Pocken", "tokens": ["Da\u00df", "uns", "nicht", "die", "Po\u00b7cken"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PTKNEG", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Einmal b\u00f6s verglimpfen.", "tokens": ["Ein\u00b7mal", "b\u00f6s", "ver\u00b7glimp\u00b7fen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.222": {"line.1": {"text": "Ist die Impf geschehen,", "tokens": ["Ist", "die", "Impf", "ge\u00b7sche\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Sollst Du's Venus tuen;", "tokens": ["Sollst", "Du's", "Ve\u00b7nus", "tu\u00b7en", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "NE", "NE", "VVINF", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Komm' jetzt, sollst es sehen\u00ab ...", "tokens": ["Komm'", "jetzt", ",", "sollst", "es", "se\u00b7hen", "\u00ab", "..."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["VVIMP", "ADV", "$,", "VMFIN", "PPER", "VVINF", "$(", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.223": {"line.1": {"text": "Venus fragt am Abend:", "tokens": ["Ve\u00b7nus", "fragt", "am", "A\u00b7bend", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPRART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "\u00bbhast Du sie die Flecken?\u00ab", "tokens": ["\u00bb", "hast", "Du", "sie", "die", "Fle\u00b7cken", "?", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VAFIN", "PPER", "PPER", "ART", "NN", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "\u00bbja,\u00ab lacht Melusine,", "tokens": ["\u00bb", "ja", ",", "\u00ab", "lacht", "Me\u00b7lu\u00b7si\u00b7ne", ","], "token_info": ["punct", "word", "punct", "punct", "word", "word", "punct"], "pos": ["$(", "PTKANT", "$,", "$(", "VVFIN", "NE", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "\u00bbkann sie nicht verstecken.", "tokens": ["\u00bb", "kann", "sie", "nicht", "ver\u00b7ste\u00b7cken", "."], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "VMFIN", "PPER", "PTKNEG", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.224": {"line.1": {"text": "Ach, der Arzt nicht ruhte,", "tokens": ["Ach", ",", "der", "Arzt", "nicht", "ruh\u00b7te", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "ART", "NN", "PTKNEG", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Nicht nur bei drei Orten,", "tokens": ["Nicht", "nur", "bei", "drei", "Or\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "APPR", "CARD", "NN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "W\u00fchlte er im Blute.\u00ab", "tokens": ["W\u00fchl\u00b7te", "er", "im", "Blu\u00b7te", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PPER", "APPRART", "NN", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.225": {"line.1": {"text": "Venus, bei der Lampe,", "tokens": ["Ve\u00b7nus", ",", "bei", "der", "Lam\u00b7pe", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "APPR", "ART", "NN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Sieht voll Sommersprossen", "tokens": ["Sieht", "voll", "Som\u00b7mer\u00b7spros\u00b7sen"], "token_info": ["word", "word", "word"], "pos": ["VVFIN", "ADJD", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Ihre h\u00fcbsche Zofe,", "tokens": ["Ih\u00b7re", "h\u00fcb\u00b7sche", "Zo\u00b7fe", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Punkt an Punkt durchschossen.", "tokens": ["Punkt", "an", "Punkt", "durch\u00b7schos\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "NN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.226": {"line.1": {"text": "Venus lacht mit Schallen:", "tokens": ["Ve\u00b7nus", "lacht", "mit", "Schal\u00b7len", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPR", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "\u00bbso gut hat dem Doktor", "tokens": ["\u00bb", "so", "gut", "hat", "dem", "Dok\u00b7tor"], "token_info": ["punct", "word", "word", "word", "word", "word"], "pos": ["$(", "ADV", "ADJD", "VAFIN", "ART", "NN"], "meter": "-++-+-", "measure": "unknown.measure.tri"}, "line.3": {"text": "Jeder Fleck gefallen?", "tokens": ["Je\u00b7der", "Fleck", "ge\u00b7fal\u00b7len", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.227": {"line.1": {"text": "Da\u00df er sich dann \u00fcbte", "tokens": ["Da\u00df", "er", "sich", "dann", "\u00fcb\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PRF", "ADV", "VVFIN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Und Dich ganz bes\u00e4te?", "tokens": ["Und", "Dich", "ganz", "be\u00b7s\u00e4\u00b7te", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ADV", "VVFIN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Ach, wenn ich von Deinen", "tokens": ["Ach", ",", "wenn", "ich", "von", "Dei\u00b7nen"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["ITJ", "$,", "KOUS", "PPER", "APPR", "PPOSAT"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Hundert einen h\u00e4tte!\u00ab", "tokens": ["Hun\u00b7dert", "ei\u00b7nen", "h\u00e4t\u00b7te", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PIS", "VAFIN", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.228": {"line.1": {"text": "Eckehardt, verst\u00e4ndig,", "tokens": ["E\u00b7cke\u00b7hardt", ",", "ver\u00b7st\u00e4n\u00b7dig", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NE", "$,", "ADJD", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Impft sie, \u2013 und im Berge", "tokens": ["Impft", "sie", ",", "\u2013", "und", "im", "Ber\u00b7ge"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word"], "pos": ["VVFIN", "PPER", "$,", "$(", "KON", "APPRART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Lachte man unb\u00e4ndig.", "tokens": ["Lach\u00b7te", "man", "un\u00b7b\u00e4n\u00b7dig", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ADJD", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}}}}