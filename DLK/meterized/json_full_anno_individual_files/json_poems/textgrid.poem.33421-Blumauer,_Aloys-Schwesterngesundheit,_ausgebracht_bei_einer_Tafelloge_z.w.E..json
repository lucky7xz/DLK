{"textgrid.poem.33421": {"metadata": {"author": {"name": "Blumauer, Aloys", "birth": "N.A.", "death": "N.A."}, "title": "Schwesterngesundheit, ausgebracht bei einer Tafelloge z.w.E.", "genre": "verse", "period": "N.A.", "pub_year": 1776, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "H\u00f6ret, Schwestern unser Flehen", "tokens": ["H\u00f6\u00b7ret", ",", "Schwes\u00b7tern", "un\u00b7ser", "Fle\u00b7hen"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["VVFIN", "$,", "NN", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und erbarmt euch uns'rer Noth:", "tokens": ["Und", "er\u00b7barmt", "euch", "un\u00b7s'\u00b7rer", "Noth", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PPOSAT", "NN", "$."], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Stillet uns're Liebeswehen,", "tokens": ["Stil\u00b7let", "un\u00b7s'\u00b7re", "Lie\u00b7bes\u00b7we\u00b7hen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Und beschlie\u00dft nicht unsern Tod!", "tokens": ["Und", "be\u00b7schlie\u00dft", "nicht", "un\u00b7sern", "Tod", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKNEG", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Ach, erh\u00f6ret unsern Jammer,", "tokens": ["Ach", ",", "er\u00b7h\u00f6\u00b7ret", "un\u00b7sern", "Jam\u00b7mer", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Lindert einmal unsern Schmerz;", "tokens": ["Lin\u00b7dert", "ein\u00b7mal", "un\u00b7sern", "Schmerz", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "H\u00f6r't nur, wie der Logenhammer,", "tokens": ["H\u00f6r't", "nur", ",", "wie", "der", "Lo\u00b7gen\u00b7ham\u00b7mer", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "$,", "PWAV", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Klopft und pochet uns das Herz.", "tokens": ["Klopft", "und", "po\u00b7chet", "uns", "das", "Herz", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "O! verschm\u00e4h't uns Maurer nimmer;", "tokens": ["O", "!", "ver\u00b7schm\u00e4h't", "uns", "Mau\u00b7rer", "nim\u00b7mer", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "VVFIN", "PPER", "NN", "ADV", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Die Natur, die niemals l\u00fcgt,", "tokens": ["Die", "Na\u00b7tur", ",", "die", "nie\u00b7mals", "l\u00fcgt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Schuf den Kitt, der uns auf immer", "tokens": ["Schuf", "den", "Kitt", ",", "der", "uns", "auf", "im\u00b7mer"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "ART", "NN", "$,", "PRELS", "PPER", "APPR", "ADV"], "meter": "+-+--+--", "measure": "trochaic.tri.relaxed"}, "line.4": {"text": "Fest mit euch zusammenf\u00fcgt.", "tokens": ["Fest", "mit", "euch", "zu\u00b7sam\u00b7men\u00b7f\u00fcgt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPER", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Wi\u00dft, es ist der Maurerorden", "tokens": ["Wi\u00dft", ",", "es", "ist", "der", "Mau\u00b7rer\u00b7or\u00b7den"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "$,", "PPER", "VAFIN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Einer M\u00e4nnerschule gleich:", "tokens": ["Ei\u00b7ner", "M\u00e4n\u00b7ner\u00b7schu\u00b7le", "gleich", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Was wir da gelehrt sind worden,", "tokens": ["Was", "wir", "da", "ge\u00b7lehrt", "sind", "wor\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "VVPP", "VAFIN", "VAPP", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Lernten wir ja nur f\u00fcr euch.", "tokens": ["Lern\u00b7ten", "wir", "ja", "nur", "f\u00fcr", "euch", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "APPR", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Auf der Maurerreise b\u00fccken", "tokens": ["Auf", "der", "Mau\u00b7rer\u00b7rei\u00b7se", "b\u00fc\u00b7cken"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wir uns nur vor euch so tief,", "tokens": ["Wir", "uns", "nur", "vor", "euch", "so", "tief", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PPER", "ADV", "APPR", "PPER", "ADV", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und ein sanftes H\u00e4ndedr\u00fccken,", "tokens": ["Und", "ein", "sanf\u00b7tes", "H\u00e4n\u00b7de\u00b7dr\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Schwestern, ist der Maurergriff.", "tokens": ["Schwes\u00b7tern", ",", "ist", "der", "Mau\u00b7rer\u00b7griff", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VAFIN", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Will uns eu're Zunge l\u00e4stern,", "tokens": ["Will", "uns", "eu'\u00b7re", "Zun\u00b7ge", "l\u00e4s\u00b7tern", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PPOSAT", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "So bleibt uns're unger\u00fchrt;", "tokens": ["So", "bleibt", "un\u00b7s'\u00b7re", "un\u00b7ge\u00b7r\u00fchrt", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Denn man hat blo\u00df darum, Schwestern,", "tokens": ["Denn", "man", "hat", "blo\u00df", "da\u00b7rum", ",", "Schwes\u00b7tern", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "PIS", "VAFIN", "ADV", "PAV", "$,", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Einst den Mund uns sigillirt.", "tokens": ["Einst", "den", "Mund", "uns", "si\u00b7gil\u00b7lirt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "PPER", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Unser Teppich selbst, an Lehren", "tokens": ["Un\u00b7ser", "Tep\u00b7pich", "selbst", ",", "an", "Leh\u00b7ren"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["PPOSAT", "NN", "ADV", "$,", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und Geheimnissen so reich,", "tokens": ["Und", "Ge\u00b7heim\u00b7nis\u00b7sen", "so", "reich", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ADV", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Predigt, solltet ihr ihn h\u00f6ren,", "tokens": ["Pre\u00b7digt", ",", "soll\u00b7tet", "ihr", "ihn", "h\u00f6\u00b7ren", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VMFIN", "PPER", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Unaufh\u00f6rlich uns von euch.", "tokens": ["Un\u00b7auf\u00b7h\u00f6r\u00b7lich", "uns", "von", "euch", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "PPER", "APPR", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Nimmer wird uns, Schwestern, nimmer", "tokens": ["Nim\u00b7mer", "wird", "uns", ",", "Schwes\u00b7tern", ",", "nim\u00b7mer"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word"], "pos": ["ADV", "VAFIN", "PPER", "$,", "NN", "$,", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Unsers Flammensternes Schein", "tokens": ["Un\u00b7sers", "Flam\u00b7mens\u00b7ter\u00b7nes", "Schein"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Etwas anders, als der Schimmer", "tokens": ["Et\u00b7was", "an\u00b7ders", ",", "als", "der", "Schim\u00b7mer"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "ADV", "$,", "KOUS", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Eu'rer holden Augen sein.", "tokens": ["Eu'\u00b7rer", "hol\u00b7den", "Au\u00b7gen", "sein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Denn der Mond in seiner Lage,", "tokens": ["Denn", "der", "Mond", "in", "sei\u00b7ner", "La\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und die Sonn' in ihrer Pracht", "tokens": ["Und", "die", "Sonn'", "in", "ih\u00b7rer", "Pracht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Prophezeih'n uns Lieb' am Tage,", "tokens": ["Pro\u00b7phe\u00b7zeih'n", "uns", "Lieb'", "am", "Ta\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "NN", "APPRART", "NN", "$,"], "meter": "+---+-+-", "measure": "dactylic.init"}, "line.4": {"text": "Und ein Doppelhorn bei Nacht.", "tokens": ["Und", "ein", "Dop\u00b7pel\u00b7horn", "bei", "Nacht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "APPR", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Selbst bei Tafeln, da wo euer", "tokens": ["Selbst", "bei", "Ta\u00b7feln", ",", "da", "wo", "eu\u00b7er"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "APPR", "NN", "$,", "ADV", "PWAV", "PPOSAT"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Der Profane meist vergi\u00dft,", "tokens": ["Der", "Pro\u00b7fa\u00b7ne", "meist", "ver\u00b7gi\u00dft", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Weih'n wir euch ein eigen Feuer,", "tokens": ["Weih'n", "wir", "euch", "ein", "ei\u00b7gen", "Feu\u00b7er", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ART", "ADJD", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Welches uns're Mahle schlie\u00dft.", "tokens": ["Wel\u00b7ches", "un\u00b7s'\u00b7re", "Mah\u00b7le", "schlie\u00dft", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "PPOSAT", "NN", "VVFIN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.11": {"line.1": {"text": "H\u00f6ret, Schwestern unser Flehen", "tokens": ["H\u00f6\u00b7ret", ",", "Schwes\u00b7tern", "un\u00b7ser", "Fle\u00b7hen"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["VVFIN", "$,", "NN", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und erbarmt euch uns'rer Noth:", "tokens": ["Und", "er\u00b7barmt", "euch", "un\u00b7s'\u00b7rer", "Noth", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PPOSAT", "NN", "$."], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Stillet uns're Liebeswehen,", "tokens": ["Stil\u00b7let", "un\u00b7s'\u00b7re", "Lie\u00b7bes\u00b7we\u00b7hen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Und beschlie\u00dft nicht unsern Tod!", "tokens": ["Und", "be\u00b7schlie\u00dft", "nicht", "un\u00b7sern", "Tod", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKNEG", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Ach, erh\u00f6ret unsern Jammer,", "tokens": ["Ach", ",", "er\u00b7h\u00f6\u00b7ret", "un\u00b7sern", "Jam\u00b7mer", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Lindert einmal unsern Schmerz;", "tokens": ["Lin\u00b7dert", "ein\u00b7mal", "un\u00b7sern", "Schmerz", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "H\u00f6r't nur, wie der Logenhammer,", "tokens": ["H\u00f6r't", "nur", ",", "wie", "der", "Lo\u00b7gen\u00b7ham\u00b7mer", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "$,", "PWAV", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Klopft und pochet uns das Herz.", "tokens": ["Klopft", "und", "po\u00b7chet", "uns", "das", "Herz", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "O! verschm\u00e4h't uns Maurer nimmer;", "tokens": ["O", "!", "ver\u00b7schm\u00e4h't", "uns", "Mau\u00b7rer", "nim\u00b7mer", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "VVFIN", "PPER", "NN", "ADV", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Die Natur, die niemals l\u00fcgt,", "tokens": ["Die", "Na\u00b7tur", ",", "die", "nie\u00b7mals", "l\u00fcgt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Schuf den Kitt, der uns auf immer", "tokens": ["Schuf", "den", "Kitt", ",", "der", "uns", "auf", "im\u00b7mer"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "ART", "NN", "$,", "PRELS", "PPER", "APPR", "ADV"], "meter": "+-+--+--", "measure": "trochaic.tri.relaxed"}, "line.4": {"text": "Fest mit euch zusammenf\u00fcgt.", "tokens": ["Fest", "mit", "euch", "zu\u00b7sam\u00b7men\u00b7f\u00fcgt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPER", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "Wi\u00dft, es ist der Maurerorden", "tokens": ["Wi\u00dft", ",", "es", "ist", "der", "Mau\u00b7rer\u00b7or\u00b7den"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "$,", "PPER", "VAFIN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Einer M\u00e4nnerschule gleich:", "tokens": ["Ei\u00b7ner", "M\u00e4n\u00b7ner\u00b7schu\u00b7le", "gleich", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Was wir da gelehrt sind worden,", "tokens": ["Was", "wir", "da", "ge\u00b7lehrt", "sind", "wor\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "VVPP", "VAFIN", "VAPP", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Lernten wir ja nur f\u00fcr euch.", "tokens": ["Lern\u00b7ten", "wir", "ja", "nur", "f\u00fcr", "euch", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "APPR", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.15": {"line.1": {"text": "Auf der Maurerreise b\u00fccken", "tokens": ["Auf", "der", "Mau\u00b7rer\u00b7rei\u00b7se", "b\u00fc\u00b7cken"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wir uns nur vor euch so tief,", "tokens": ["Wir", "uns", "nur", "vor", "euch", "so", "tief", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PPER", "ADV", "APPR", "PPER", "ADV", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und ein sanftes H\u00e4ndedr\u00fccken,", "tokens": ["Und", "ein", "sanf\u00b7tes", "H\u00e4n\u00b7de\u00b7dr\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Schwestern, ist der Maurergriff.", "tokens": ["Schwes\u00b7tern", ",", "ist", "der", "Mau\u00b7rer\u00b7griff", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VAFIN", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.16": {"line.1": {"text": "Will uns eu're Zunge l\u00e4stern,", "tokens": ["Will", "uns", "eu'\u00b7re", "Zun\u00b7ge", "l\u00e4s\u00b7tern", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PPOSAT", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "So bleibt uns're unger\u00fchrt;", "tokens": ["So", "bleibt", "un\u00b7s'\u00b7re", "un\u00b7ge\u00b7r\u00fchrt", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Denn man hat blo\u00df darum, Schwestern,", "tokens": ["Denn", "man", "hat", "blo\u00df", "da\u00b7rum", ",", "Schwes\u00b7tern", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "PIS", "VAFIN", "ADV", "PAV", "$,", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Einst den Mund uns sigillirt.", "tokens": ["Einst", "den", "Mund", "uns", "si\u00b7gil\u00b7lirt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "PPER", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.17": {"line.1": {"text": "Unser Teppich selbst, an Lehren", "tokens": ["Un\u00b7ser", "Tep\u00b7pich", "selbst", ",", "an", "Leh\u00b7ren"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["PPOSAT", "NN", "ADV", "$,", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und Geheimnissen so reich,", "tokens": ["Und", "Ge\u00b7heim\u00b7nis\u00b7sen", "so", "reich", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ADV", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Predigt, solltet ihr ihn h\u00f6ren,", "tokens": ["Pre\u00b7digt", ",", "soll\u00b7tet", "ihr", "ihn", "h\u00f6\u00b7ren", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VMFIN", "PPER", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Unaufh\u00f6rlich uns von euch.", "tokens": ["Un\u00b7auf\u00b7h\u00f6r\u00b7lich", "uns", "von", "euch", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "PPER", "APPR", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.18": {"line.1": {"text": "Nimmer wird uns, Schwestern, nimmer", "tokens": ["Nim\u00b7mer", "wird", "uns", ",", "Schwes\u00b7tern", ",", "nim\u00b7mer"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word"], "pos": ["ADV", "VAFIN", "PPER", "$,", "NN", "$,", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Unsers Flammensternes Schein", "tokens": ["Un\u00b7sers", "Flam\u00b7mens\u00b7ter\u00b7nes", "Schein"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Etwas anders, als der Schimmer", "tokens": ["Et\u00b7was", "an\u00b7ders", ",", "als", "der", "Schim\u00b7mer"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "ADV", "$,", "KOUS", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Eu'rer holden Augen sein.", "tokens": ["Eu'\u00b7rer", "hol\u00b7den", "Au\u00b7gen", "sein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.19": {"line.1": {"text": "Denn der Mond in seiner Lage,", "tokens": ["Denn", "der", "Mond", "in", "sei\u00b7ner", "La\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und die Sonn' in ihrer Pracht", "tokens": ["Und", "die", "Sonn'", "in", "ih\u00b7rer", "Pracht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Prophezeih'n uns Lieb' am Tage,", "tokens": ["Pro\u00b7phe\u00b7zeih'n", "uns", "Lieb'", "am", "Ta\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "NN", "APPRART", "NN", "$,"], "meter": "+---+-+-", "measure": "dactylic.init"}, "line.4": {"text": "Und ein Doppelhorn bei Nacht.", "tokens": ["Und", "ein", "Dop\u00b7pel\u00b7horn", "bei", "Nacht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "APPR", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.20": {"line.1": {"text": "Selbst bei Tafeln, da wo euer", "tokens": ["Selbst", "bei", "Ta\u00b7feln", ",", "da", "wo", "eu\u00b7er"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "APPR", "NN", "$,", "ADV", "PWAV", "PPOSAT"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Der Profane meist vergi\u00dft,", "tokens": ["Der", "Pro\u00b7fa\u00b7ne", "meist", "ver\u00b7gi\u00dft", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Weih'n wir euch ein eigen Feuer,", "tokens": ["Weih'n", "wir", "euch", "ein", "ei\u00b7gen", "Feu\u00b7er", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ART", "ADJD", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Welches uns're Mahle schlie\u00dft.", "tokens": ["Wel\u00b7ches", "un\u00b7s'\u00b7re", "Mah\u00b7le", "schlie\u00dft", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "PPOSAT", "NN", "VVFIN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}}}}}