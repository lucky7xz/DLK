{"dta.poem.18789": {"metadata": {"author": {"name": "Goethe, Johann Wolfgang von", "birth": "N.A.", "death": "N.A."}, "title": "Hatem .", "genre": "Lyrik", "period": "N.A.", "pub_year": "1819", "urn": "urn:nbn:de:kobv:b4-200905191692", "language": ["de:0.99"], "booktitle": "Goethe, Johann Wolfgang von: West-\u00f6stlicher Divan. Stuttgart, 1819."}, "poem": {"stanza.1": {"line.1": {"text": "Br\u00e4unchen komm! Es wird schon gehen.", "tokens": ["Br\u00e4un\u00b7chen", "komm", "!", "Es", "wird", "schon", "ge\u00b7hen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "$.", "PPER", "VAFIN", "ADV", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Z\u00f6pfe, K\u00e4mme gross und kleine,", "tokens": ["Z\u00f6p\u00b7fe", ",", "K\u00e4m\u00b7me", "gross", "und", "klei\u00b7ne", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "ADJA", "KON", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Zieren K\u00f6pfchens nette Reine", "tokens": ["Zie\u00b7ren", "K\u00f6pf\u00b7chens", "net\u00b7te", "Rei\u00b7ne"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "NN", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wie die Kuppel ziert Moscheen.", "tokens": ["Wie", "die", "Kup\u00b7pel", "ziert", "Mo\u00b7scheen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "VVFIN", "NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Du Blondinchen bist so zierlich,", "tokens": ["Du", "Blon\u00b7din\u00b7chen", "bist", "so", "zier\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "VAFIN", "ADV", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Aller Weis\u2019 und Weg\u2019 so nette,", "tokens": ["Al\u00b7ler", "Weis'", "und", "Weg'", "so", "net\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "KON", "NN", "ADV", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Man gedenkt nicht ungeb\u00fchrlich", "tokens": ["Man", "ge\u00b7denkt", "nicht", "un\u00b7ge\u00b7b\u00fchr\u00b7lich"], "token_info": ["word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "PTKNEG", "ADJD"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Also gleich der Minarette.", "tokens": ["Al\u00b7so", "gleich", "der", "Mi\u00b7na\u00b7ret\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Du dahinten hast der Augen", "tokens": ["Du", "da\u00b7hin\u00b7ten", "hast", "der", "Au\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "PAV", "VAFIN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Zweyerley, du kannst die beyden,", "tokens": ["Zwey\u00b7er\u00b7ley", ",", "du", "kannst", "die", "bey\u00b7den", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PPER", "VMFIN", "ART", "PIAT", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Einzeln, nach Belieben brauchen.", "tokens": ["Ein\u00b7zeln", ",", "nach", "Be\u00b7lie\u00b7ben", "brau\u00b7chen", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "APPR", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Doch ich sollte d", "tokens": ["Doch", "ich", "soll\u00b7te", "d"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PPER", "VMFIN", "XY"], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.4": {"line.1": {"text": "Leichtgedr\u00fcckt die Augenlieder", "tokens": ["Leicht\u00b7ge\u00b7dr\u00fcckt", "die", "Au\u00b7gen\u00b7lie\u00b7der"], "token_info": ["word", "word", "word"], "pos": ["VVFIN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Eines, die den Stern bewhelmen", "tokens": ["Ei\u00b7nes", ",", "die", "den", "Stern", "be\u00b7whel\u00b7men"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["PIS", "$,", "PRELS", "ART", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Deutet auf den Schelm der Schelmen,", "tokens": ["Deu\u00b7tet", "auf", "den", "Schelm", "der", "Schel\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Doch das andre schaut so bieder.", "tokens": ["Doch", "das", "and\u00b7re", "schaut", "so", "bie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "PIS", "VVFIN", "ADV", "ADJD", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Dies, wenn jen\u2019s verwundend angelt,", "tokens": ["Dies", ",", "wenn", "jen's", "ver\u00b7wun\u00b7dend", "an\u00b7gelt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "$,", "KOUS", "PIS", "VVPP", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Heilend, n\u00e4hrend wird sich\u2019s weisen.", "tokens": ["Hei\u00b7lend", ",", "n\u00e4h\u00b7rend", "wird", "sich's", "wei\u00b7sen", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "ADJD", "VAFIN", "PIS", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Niemand kann ich gl\u00fccklich preisen", "tokens": ["Nie\u00b7mand", "kann", "ich", "gl\u00fcck\u00b7lich", "prei\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIS", "VMFIN", "PPER", "ADJD", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Der des Doppelblicks ermangelt.", "tokens": ["Der", "des", "Dop\u00b7pel\u00b7blicks", "er\u00b7man\u00b7gelt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Und so k\u00f6nnt\u2019 ich alle loben", "tokens": ["Und", "so", "k\u00f6nnt'", "ich", "al\u00b7le", "lo\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VMFIN", "PPER", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und so k\u00f6nnt\u2019 ich alle lieben:", "tokens": ["Und", "so", "k\u00f6nnt'", "ich", "al\u00b7le", "lie\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VMFIN", "PPER", "PIS", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Denn so wie ich euch erhoben", "tokens": ["Denn", "so", "wie", "ich", "euch", "er\u00b7ho\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "KOKOM", "PPER", "PPER", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "War die Herrin mit beschrieben.", "tokens": ["War", "die", "Her\u00b7rin", "mit", "be\u00b7schrie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "APPR", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}}}}