{"textgrid.poem.44048": {"metadata": {"author": {"name": "G\u00fcnther, Johann Christian", "birth": "N.A.", "death": "N.A."}, "title": "1L: Nun, lieber Gott, du bleibst ja lange,", "genre": "verse", "period": "N.A.", "pub_year": 1709, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Nun, lieber Gott, du bleibst ja lange,", "tokens": ["Nun", ",", "lie\u00b7ber", "Gott", ",", "du", "bleibst", "ja", "lan\u00b7ge", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "ADV", "NN", "$,", "PPER", "VVFIN", "ADV", "ADV", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ich weis nicht, was ich dencken soll.", "tokens": ["Ich", "weis", "nicht", ",", "was", "ich", "den\u00b7cken", "soll", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKVZ", "PTKNEG", "$,", "PWS", "PPER", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der Zweifel macht der Hofnung bange,", "tokens": ["Der", "Zwei\u00b7fel", "macht", "der", "Hof\u00b7nung", "ban\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "ADV", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ich weine Bett und Biebel voll;", "tokens": ["Ich", "wei\u00b7ne", "Bett", "und", "Bie\u00b7bel", "voll", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "KON", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ach, soll denn ich, nur ich allein", "tokens": ["Ach", ",", "soll", "denn", "ich", ",", "nur", "ich", "al\u00b7lein"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ITJ", "$,", "VMFIN", "KON", "PPER", "$,", "ADV", "PPER", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ein Greuel meines Sch\u00f6pfers seyn?", "tokens": ["Ein", "Greu\u00b7el", "mei\u00b7nes", "Sch\u00f6p\u00b7fers", "seyn", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Ich mag mich schicken, drehn und winden,", "tokens": ["Ich", "mag", "mich", "schi\u00b7cken", ",", "drehn", "und", "win\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PRF", "VVINF", "$,", "CARD", "KON", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Es ist mit allem nichts gethan.", "tokens": ["Es", "ist", "mit", "al\u00b7lem", "nichts", "ge\u00b7than", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "PIS", "PIS", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ein Sperling schl\u00e4ft in hohlen Linden", "tokens": ["Ein", "Sper\u00b7ling", "schl\u00e4ft", "in", "hoh\u00b7len", "Lin\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und findet, wo er f\u00fcttern kan;", "tokens": ["Und", "fin\u00b7det", ",", "wo", "er", "f\u00fct\u00b7tern", "kan", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "PWAV", "PPER", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Mich jagt die Misgunst hin und her", "tokens": ["Mich", "jagt", "die", "Mis\u00b7gunst", "hin", "und", "her"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "PTKVZ", "KON", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und macht mir noch die Armuth schwer.", "tokens": ["Und", "macht", "mir", "noch", "die", "Ar\u00b7muth", "schwer", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Ich habe Freund und hab auch keinen;", "tokens": ["Ich", "ha\u00b7be", "Freund", "und", "hab", "auch", "kei\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NN", "KON", "VAFIN", "ADV", "PIAT", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "O w\u00e4r ich doch ein Rabenkind!", "tokens": ["O", "w\u00e4r", "ich", "doch", "ein", "Ra\u00b7ben\u00b7kind", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PPER", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der Kummer w\u00fchlt in Marck und Beinen,", "tokens": ["Der", "Kum\u00b7mer", "w\u00fchlt", "in", "Marck", "und", "Bei\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die schon von Kranckheit m\u00fcrbe sind;", "tokens": ["Die", "schon", "von", "Kran\u00b7ck\u00b7heit", "m\u00fcr\u00b7be", "sind", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "NN", "ADJA", "VAFIN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Ja, wem ich ehmahls Gute erzeigt,", "tokens": ["Ja", ",", "wem", "ich", "eh\u00b7mahls", "Gu\u00b7te", "er\u00b7zeigt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PWS", "PPER", "ADV", "NN", "VVPP", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.6": {"text": "Der sieht und h\u00f6rt mein Weh und schweigt.", "tokens": ["Der", "sieht", "und", "h\u00f6rt", "mein", "Weh", "und", "schweigt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "KON", "VVFIN", "PPOSAT", "NN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Was helfen mich nun alle Gaben,", "tokens": ["Was", "hel\u00b7fen", "mich", "nun", "al\u00b7le", "Ga\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Verstand und Kunst und Ehrligkeit?", "tokens": ["Ver\u00b7stand", "und", "Kunst", "und", "Ehr\u00b7lig\u00b7keit", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "O h\u00e4tt ich nur mein Pfund vergraben!", "tokens": ["O", "h\u00e4tt", "ich", "nur", "mein", "Pfund", "ver\u00b7gra\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PPER", "ADV", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Es w\u00e4re doch wohl eine Zeit,", "tokens": ["Es", "w\u00e4\u00b7re", "doch", "wohl", "ei\u00b7ne", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Indem man aller Orten sieht,", "tokens": ["In\u00b7dem", "man", "al\u00b7ler", "Or\u00b7ten", "sieht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wie hoch der Thoren Gl\u00fccke bl\u00fcht.", "tokens": ["Wie", "hoch", "der", "Tho\u00b7ren", "Gl\u00fc\u00b7cke", "bl\u00fcht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "ART", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Die Strafe be\u00dfert sonst die S\u00fcnder;", "tokens": ["Die", "Stra\u00b7fe", "be\u00b7\u00dfert", "sonst", "die", "S\u00fcn\u00b7der", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Dies ist mehr Grausamkeit als Zucht.", "tokens": ["Dies", "ist", "mehr", "Grau\u00b7sam\u00b7keit", "als", "Zucht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PIAT", "NN", "KOUS", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Versuch einmahl und geh gelinder,", "tokens": ["Ver\u00b7such", "ein\u00b7mahl", "und", "geh", "ge\u00b7lin\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "KON", "VVFIN", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Vielleicht gewinnt es eher Frucht;", "tokens": ["Viel\u00b7leicht", "ge\u00b7winnt", "es", "e\u00b7her", "Frucht", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ein scharfer Streich und langer Grimm", "tokens": ["Ein", "schar\u00b7fer", "Streich", "und", "lan\u00b7ger", "Grimm"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "KON", "ADJA", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Macht oft die besten Herzen schlimm.", "tokens": ["Macht", "oft", "die", "bes\u00b7ten", "Her\u00b7zen", "schlimm", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ART", "ADJA", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Gefall ich mir in Bo\u00dfheitslastern", "tokens": ["Ge\u00b7fall", "ich", "mir", "in", "Bo\u00df\u00b7heits\u00b7las\u00b7tern"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "PPER", "PRF", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und bin ich eines Menschen Feind,", "tokens": ["Und", "bin", "ich", "ei\u00b7nes", "Men\u00b7schen", "Feind", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So soll mein Haupt die H\u00f6lle pflastern,", "tokens": ["So", "soll", "mein", "Haupt", "die", "H\u00f6l\u00b7le", "pflas\u00b7tern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPOSAT", "NN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Auch eh dein gro\u00dfer Tag erscheint.", "tokens": ["Auch", "eh", "dein", "gro\u00b7\u00dfer", "Tag", "er\u00b7scheint", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PPOSAT", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Du kennst mein Herz, das sonder List,", "tokens": ["Du", "kennst", "mein", "Herz", ",", "das", "son\u00b7der", "List", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Obgleich nicht ohne Schwachheit ist.", "tokens": ["Ob\u00b7gleich", "nicht", "oh\u00b7ne", "Schwach\u00b7heit", "ist", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PTKNEG", "APPR", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Ich r\u00e4che mich am \u00e4rgsten Sp\u00f6tter", "tokens": ["Ich", "r\u00e4\u00b7che", "mich", "am", "\u00e4rgs\u00b7ten", "Sp\u00f6t\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Mit Langmuth, Wohlthun und Gedult.", "tokens": ["Mit", "Lang\u00b7muth", ",", "Wohl\u00b7thun", "und", "Ge\u00b7dult", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mein Glaube steht im h\u00e4rtsten Wetter", "tokens": ["Mein", "Glau\u00b7be", "steht", "im", "h\u00e4rts\u00b7ten", "Wet\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VVFIN", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und denckt: Es ist verdiente Schuld.", "tokens": ["Und", "denckt", ":", "Es", "ist", "ver\u00b7dien\u00b7te", "Schuld", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "PPER", "VAFIN", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ach, aber bey so vieler Schmach", "tokens": ["Ach", ",", "a\u00b7ber", "bey", "so", "vie\u00b7ler", "Schmach"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["ITJ", "$,", "ADV", "APPR", "ADV", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "L\u00e4st endlich auch die Hofnung nach.", "tokens": ["L\u00e4st", "end\u00b7lich", "auch", "die", "Hof\u00b7nung", "nach", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADV", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Geburth, Exempel, Noth und Jugend.", "tokens": ["Ge\u00b7burth", ",", "Ex\u00b7em\u00b7pel", ",", "Noth", "und", "Ju\u00b7gend", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sind Ursach, da\u00df ich fehlen mu\u00df.", "tokens": ["Sind", "Ur\u00b7sach", ",", "da\u00df", "ich", "feh\u00b7len", "mu\u00df", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "$,", "KOUS", "PPER", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wer geht wohl stets den Weg der Tugend?", "tokens": ["Wer", "geht", "wohl", "stets", "den", "Weg", "der", "Tu\u00b7gend", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ADV", "ADV", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ich strauchle selber mit Verdru\u00df", "tokens": ["Ich", "strauch\u00b7le", "sel\u00b7ber", "mit", "Ver\u00b7dru\u00df"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und bin nach schneller Reu und Leid", "tokens": ["Und", "bin", "nach", "schnel\u00b7ler", "Reu", "und", "Leid"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "APPR", "ADJA", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Der erste, der mich straft und zeiht.", "tokens": ["Der", "ers\u00b7te", ",", "der", "mich", "straft", "und", "zeiht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "PRELS", "PPER", "ADJD", "KON", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Was wiltu mit dem Schatten zancken?", "tokens": ["Was", "wil\u00b7tu", "mit", "dem", "Schat\u00b7ten", "zan\u00b7cken", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Beweis an St\u00e4rckern deine Macht!", "tokens": ["Be\u00b7weis", "an", "St\u00e4r\u00b7ckern", "dei\u00b7ne", "Macht", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wer wird dir in der H\u00f6lle dancken?", "tokens": ["Wer", "wird", "dir", "in", "der", "H\u00f6l\u00b7le", "dan\u00b7cken", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ach, hastu dies noch nicht bedacht?", "tokens": ["Ach", ",", "has\u00b7tu", "dies", "noch", "nicht", "be\u00b7dacht", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "VAFIN", "PDS", "ADV", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Du kommst mit Donner, Bliz und Sturm.", "tokens": ["Du", "kommst", "mit", "Don\u00b7ner", ",", "Bliz", "und", "Sturm", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wer ist der gro\u00dfe Feind? Ein Wurm.", "tokens": ["Wer", "ist", "der", "gro\u00b7\u00dfe", "Feind", "?", "Ein", "Wurm", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ART", "ADJA", "NN", "$.", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Nun, lieber Gott, du bleibst ja lange,", "tokens": ["Nun", ",", "lie\u00b7ber", "Gott", ",", "du", "bleibst", "ja", "lan\u00b7ge", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "ADV", "NN", "$,", "PPER", "VVFIN", "ADV", "ADV", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ich weis nicht, was ich dencken soll.", "tokens": ["Ich", "weis", "nicht", ",", "was", "ich", "den\u00b7cken", "soll", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKVZ", "PTKNEG", "$,", "PWS", "PPER", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der Zweifel macht der Hofnung bange,", "tokens": ["Der", "Zwei\u00b7fel", "macht", "der", "Hof\u00b7nung", "ban\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "ADV", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ich weine Bett und Biebel voll;", "tokens": ["Ich", "wei\u00b7ne", "Bett", "und", "Bie\u00b7bel", "voll", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "KON", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ach, soll denn ich, nur ich allein", "tokens": ["Ach", ",", "soll", "denn", "ich", ",", "nur", "ich", "al\u00b7lein"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ITJ", "$,", "VMFIN", "KON", "PPER", "$,", "ADV", "PPER", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ein Greuel meines Sch\u00f6pfers seyn?", "tokens": ["Ein", "Greu\u00b7el", "mei\u00b7nes", "Sch\u00f6p\u00b7fers", "seyn", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Ich mag mich schicken, drehn und winden,", "tokens": ["Ich", "mag", "mich", "schi\u00b7cken", ",", "drehn", "und", "win\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PRF", "VVINF", "$,", "CARD", "KON", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Es ist mit allem nichts gethan.", "tokens": ["Es", "ist", "mit", "al\u00b7lem", "nichts", "ge\u00b7than", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "PIS", "PIS", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ein Sperling schl\u00e4ft in hohlen Linden", "tokens": ["Ein", "Sper\u00b7ling", "schl\u00e4ft", "in", "hoh\u00b7len", "Lin\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und findet, wo er f\u00fcttern kan;", "tokens": ["Und", "fin\u00b7det", ",", "wo", "er", "f\u00fct\u00b7tern", "kan", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "PWAV", "PPER", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Mich jagt die Misgunst hin und her", "tokens": ["Mich", "jagt", "die", "Mis\u00b7gunst", "hin", "und", "her"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "PTKVZ", "KON", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und macht mir noch die Armuth schwer.", "tokens": ["Und", "macht", "mir", "noch", "die", "Ar\u00b7muth", "schwer", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Ich habe Freund und hab auch keinen;", "tokens": ["Ich", "ha\u00b7be", "Freund", "und", "hab", "auch", "kei\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NN", "KON", "VAFIN", "ADV", "PIAT", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "O w\u00e4r ich doch ein Rabenkind!", "tokens": ["O", "w\u00e4r", "ich", "doch", "ein", "Ra\u00b7ben\u00b7kind", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PPER", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der Kummer w\u00fchlt in Marck und Beinen,", "tokens": ["Der", "Kum\u00b7mer", "w\u00fchlt", "in", "Marck", "und", "Bei\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die schon von Kranckheit m\u00fcrbe sind;", "tokens": ["Die", "schon", "von", "Kran\u00b7ck\u00b7heit", "m\u00fcr\u00b7be", "sind", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "NN", "ADJA", "VAFIN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Ja, wem ich ehmahls Gute erzeigt,", "tokens": ["Ja", ",", "wem", "ich", "eh\u00b7mahls", "Gu\u00b7te", "er\u00b7zeigt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PWS", "PPER", "ADV", "NN", "VVPP", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.6": {"text": "Der sieht und h\u00f6rt mein Weh und schweigt.", "tokens": ["Der", "sieht", "und", "h\u00f6rt", "mein", "Weh", "und", "schweigt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "KON", "VVFIN", "PPOSAT", "NN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Was helfen mich nun alle Gaben,", "tokens": ["Was", "hel\u00b7fen", "mich", "nun", "al\u00b7le", "Ga\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Verstand und Kunst und Ehrligkeit?", "tokens": ["Ver\u00b7stand", "und", "Kunst", "und", "Ehr\u00b7lig\u00b7keit", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "O h\u00e4tt ich nur mein Pfund vergraben!", "tokens": ["O", "h\u00e4tt", "ich", "nur", "mein", "Pfund", "ver\u00b7gra\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PPER", "ADV", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Es w\u00e4re doch wohl eine Zeit,", "tokens": ["Es", "w\u00e4\u00b7re", "doch", "wohl", "ei\u00b7ne", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Indem man aller Orten sieht,", "tokens": ["In\u00b7dem", "man", "al\u00b7ler", "Or\u00b7ten", "sieht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wie hoch der Thoren Gl\u00fccke bl\u00fcht.", "tokens": ["Wie", "hoch", "der", "Tho\u00b7ren", "Gl\u00fc\u00b7cke", "bl\u00fcht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "ART", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Die Strafe be\u00dfert sonst die S\u00fcnder;", "tokens": ["Die", "Stra\u00b7fe", "be\u00b7\u00dfert", "sonst", "die", "S\u00fcn\u00b7der", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Dies ist mehr Grausamkeit als Zucht.", "tokens": ["Dies", "ist", "mehr", "Grau\u00b7sam\u00b7keit", "als", "Zucht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PIAT", "NN", "KOUS", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Versuch einmahl und geh gelinder,", "tokens": ["Ver\u00b7such", "ein\u00b7mahl", "und", "geh", "ge\u00b7lin\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "KON", "VVFIN", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Vielleicht gewinnt es eher Frucht;", "tokens": ["Viel\u00b7leicht", "ge\u00b7winnt", "es", "e\u00b7her", "Frucht", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ein scharfer Streich und langer Grimm", "tokens": ["Ein", "schar\u00b7fer", "Streich", "und", "lan\u00b7ger", "Grimm"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "KON", "ADJA", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Macht oft die besten Herzen schlimm.", "tokens": ["Macht", "oft", "die", "bes\u00b7ten", "Her\u00b7zen", "schlimm", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ART", "ADJA", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "Gefall ich mir in Bo\u00dfheitslastern", "tokens": ["Ge\u00b7fall", "ich", "mir", "in", "Bo\u00df\u00b7heits\u00b7las\u00b7tern"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "PPER", "PRF", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und bin ich eines Menschen Feind,", "tokens": ["Und", "bin", "ich", "ei\u00b7nes", "Men\u00b7schen", "Feind", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So soll mein Haupt die H\u00f6lle pflastern,", "tokens": ["So", "soll", "mein", "Haupt", "die", "H\u00f6l\u00b7le", "pflas\u00b7tern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPOSAT", "NN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Auch eh dein gro\u00dfer Tag erscheint.", "tokens": ["Auch", "eh", "dein", "gro\u00b7\u00dfer", "Tag", "er\u00b7scheint", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PPOSAT", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Du kennst mein Herz, das sonder List,", "tokens": ["Du", "kennst", "mein", "Herz", ",", "das", "son\u00b7der", "List", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Obgleich nicht ohne Schwachheit ist.", "tokens": ["Ob\u00b7gleich", "nicht", "oh\u00b7ne", "Schwach\u00b7heit", "ist", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PTKNEG", "APPR", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "Ich r\u00e4che mich am \u00e4rgsten Sp\u00f6tter", "tokens": ["Ich", "r\u00e4\u00b7che", "mich", "am", "\u00e4rgs\u00b7ten", "Sp\u00f6t\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Mit Langmuth, Wohlthun und Gedult.", "tokens": ["Mit", "Lang\u00b7muth", ",", "Wohl\u00b7thun", "und", "Ge\u00b7dult", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mein Glaube steht im h\u00e4rtsten Wetter", "tokens": ["Mein", "Glau\u00b7be", "steht", "im", "h\u00e4rts\u00b7ten", "Wet\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VVFIN", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und denckt: Es ist verdiente Schuld.", "tokens": ["Und", "denckt", ":", "Es", "ist", "ver\u00b7dien\u00b7te", "Schuld", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "PPER", "VAFIN", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ach, aber bey so vieler Schmach", "tokens": ["Ach", ",", "a\u00b7ber", "bey", "so", "vie\u00b7ler", "Schmach"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["ITJ", "$,", "ADV", "APPR", "ADV", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "L\u00e4st endlich auch die Hofnung nach.", "tokens": ["L\u00e4st", "end\u00b7lich", "auch", "die", "Hof\u00b7nung", "nach", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADV", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.17": {"line.1": {"text": "Geburth, Exempel, Noth und Jugend.", "tokens": ["Ge\u00b7burth", ",", "Ex\u00b7em\u00b7pel", ",", "Noth", "und", "Ju\u00b7gend", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sind Ursach, da\u00df ich fehlen mu\u00df.", "tokens": ["Sind", "Ur\u00b7sach", ",", "da\u00df", "ich", "feh\u00b7len", "mu\u00df", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "$,", "KOUS", "PPER", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wer geht wohl stets den Weg der Tugend?", "tokens": ["Wer", "geht", "wohl", "stets", "den", "Weg", "der", "Tu\u00b7gend", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ADV", "ADV", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ich strauchle selber mit Verdru\u00df", "tokens": ["Ich", "strauch\u00b7le", "sel\u00b7ber", "mit", "Ver\u00b7dru\u00df"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und bin nach schneller Reu und Leid", "tokens": ["Und", "bin", "nach", "schnel\u00b7ler", "Reu", "und", "Leid"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "APPR", "ADJA", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Der erste, der mich straft und zeiht.", "tokens": ["Der", "ers\u00b7te", ",", "der", "mich", "straft", "und", "zeiht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "PRELS", "PPER", "ADJD", "KON", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.18": {"line.1": {"text": "Was wiltu mit dem Schatten zancken?", "tokens": ["Was", "wil\u00b7tu", "mit", "dem", "Schat\u00b7ten", "zan\u00b7cken", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Beweis an St\u00e4rckern deine Macht!", "tokens": ["Be\u00b7weis", "an", "St\u00e4r\u00b7ckern", "dei\u00b7ne", "Macht", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wer wird dir in der H\u00f6lle dancken?", "tokens": ["Wer", "wird", "dir", "in", "der", "H\u00f6l\u00b7le", "dan\u00b7cken", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ach, hastu dies noch nicht bedacht?", "tokens": ["Ach", ",", "has\u00b7tu", "dies", "noch", "nicht", "be\u00b7dacht", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "VAFIN", "PDS", "ADV", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Du kommst mit Donner, Bliz und Sturm.", "tokens": ["Du", "kommst", "mit", "Don\u00b7ner", ",", "Bliz", "und", "Sturm", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wer ist der gro\u00dfe Feind? Ein Wurm.", "tokens": ["Wer", "ist", "der", "gro\u00b7\u00dfe", "Feind", "?", "Ein", "Wurm", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ART", "ADJA", "NN", "$.", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}