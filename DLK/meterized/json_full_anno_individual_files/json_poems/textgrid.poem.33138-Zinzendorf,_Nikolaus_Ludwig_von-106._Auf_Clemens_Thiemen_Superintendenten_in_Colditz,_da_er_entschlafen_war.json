{"textgrid.poem.33138": {"metadata": {"author": {"name": "Zinzendorf, Nikolaus Ludwig von", "birth": "N.A.", "death": "N.A."}, "title": "106. Auf Clemens Thiemen Superintendenten in Colditz, da er entschlafen war", "genre": "verse", "period": "N.A.", "pub_year": 1730, "urn": "N.A.", "language": ["de:0.71", "af:0.28"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Mein Clemens! kan das seyn;", "tokens": ["Mein", "Cle\u00b7mens", "!", "kan", "das", "seyn", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NE", "$.", "VMFIN", "PDS", "VAINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Das theu'r erworbne Gut,", "tokens": ["Das", "theu'r", "er\u00b7worb\u00b7ne", "Gut", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Das F\u00fcnklein Abend-Schein,", "tokens": ["Das", "F\u00fcn\u00b7klein", "A\u00b7ben\u00b7dSchein", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Dein liebes Herrenhut,", "tokens": ["Dein", "lie\u00b7bes", "Her\u00b7ren\u00b7hut", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Das mit dir von Gott entglommen,", "tokens": ["Das", "mit", "dir", "von", "Gott", "ent\u00b7glom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "APPR", "PPER", "APPR", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Hat dich nicht zu sehn bekommen?", "tokens": ["Hat", "dich", "nicht", "zu", "sehn", "be\u00b7kom\u00b7men", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PTKNEG", "PTKZU", "VVINF", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Und also hat der Herr", "tokens": ["Und", "al\u00b7so", "hat", "der", "Herr"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VAFIN", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Nur mich so hoch erfreut,", "tokens": ["Nur", "mich", "so", "hoch", "er\u00b7freut", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "ADV", "ADJD", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Zu sehn euch Wanderer", "tokens": ["Zu", "sehn", "euch", "Wan\u00b7de\u00b7rer"], "token_info": ["word", "word", "word", "word"], "pos": ["PTKZU", "VVINF", "PPER", "NN"], "meter": "-+-+--", "measure": "unknown.measure.di"}, "line.4": {"text": "Zur grossen Ewigkeit:", "tokens": ["Zur", "gros\u00b7sen", "E\u00b7wig\u00b7keit", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Denn die Donner unsers Franken", "tokens": ["Denn", "die", "Don\u00b7ner", "un\u00b7sers", "Fran\u00b7ken"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "H\u00f6rte ich in ihren Schranken.", "tokens": ["H\u00f6r\u00b7te", "ich", "in", "ih\u00b7ren", "Schran\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Als ich nach Halle kam,", "tokens": ["Als", "ich", "nach", "Hal\u00b7le", "kam", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NE", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Itzt zwey und zwanzig Jahr,", "tokens": ["Itzt", "zwey", "und", "zwan\u00b7zig", "Jahr", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "CARD", "KON", "CARD", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und meinem Br\u00e4utigam", "tokens": ["Und", "mei\u00b7nem", "Br\u00e4u\u00b7ti\u00b7gam"], "token_info": ["word", "word", "word"], "pos": ["KON", "PPOSAT", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Schon anvertrauet war;", "tokens": ["Schon", "an\u00b7ver\u00b7trau\u00b7et", "war", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Hab ich Elers tiefes Wesen", "tokens": ["Hab", "ich", "E\u00b7lers", "tie\u00b7fes", "We\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "PPER", "NN", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Mir zum Muster auserlesen.", "tokens": ["Mir", "zum", "Mus\u00b7ter", "au\u00b7ser\u00b7le\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "APPRART", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Da sah ich gleicher Weis", "tokens": ["Da", "sah", "ich", "glei\u00b7cher", "Weis"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Den Paul Antonius,", "tokens": ["Den", "Paul", "An\u00b7to\u00b7ni\u00b7us", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NE", "NE", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Weil seiner Br\u00fcder Flei\u00df", "tokens": ["Weil", "sei\u00b7ner", "Br\u00fc\u00b7der", "Flei\u00df"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PPOSAT", "NN", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Viel Menschen fangen mu\u00df,", "tokens": ["Viel", "Men\u00b7schen", "fan\u00b7gen", "mu\u00df", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Sich zu ihrem Netze flikken", "tokens": ["Sich", "zu", "ih\u00b7rem", "Net\u00b7ze", "flik\u00b7ken"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PRF", "APPR", "PPOSAT", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Ohne langes Winken schikken.", "tokens": ["Oh\u00b7ne", "lan\u00b7ges", "Win\u00b7ken", "schik\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Und, o wie freut ich mich!", "tokens": ["Und", ",", "o", "wie", "freut", "ich", "mich", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "FM", "KOKOM", "VVFIN", "PPER", "PRF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Als ich dich auch erblikt.", "tokens": ["Als", "ich", "dich", "auch", "er\u00b7blikt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ADV", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Dich, theurer Thieme, dich,", "tokens": ["Dich", ",", "theu\u00b7rer", "Thie\u00b7me", ",", "dich", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "$,", "ADJD", "NN", "$,", "PPER", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Den Lieb und Ernst geschm\u00fckt;", "tokens": ["Den", "Lieb", "und", "Ernst", "ge\u00b7schm\u00fckt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Colditz, Leipzig, Dresden sahen", "tokens": ["Col\u00b7ditz", ",", "Leip\u00b7zig", ",", "Dres\u00b7den", "sa\u00b7hen"], "token_info": ["word", "punct", "word", "punct", "word", "word"], "pos": ["NE", "$,", "NE", "$,", "NE", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Unser inniges Umfahen.", "tokens": ["Un\u00b7ser", "in\u00b7ni\u00b7ges", "Um\u00b7fa\u00b7hen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$."], "meter": "+-+++-+-", "measure": "unknown.measure.penta"}}, "stanza.6": {"line.1": {"text": "Mein Trieb verschonet gern", "tokens": ["Mein", "Trieb", "ver\u00b7scho\u00b7net", "gern"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VVFIN", "ADV"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "So manchen in der Welt", "tokens": ["So", "man\u00b7chen", "in", "der", "Welt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "PIAT", "APPR", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Verborgnen Knecht des Herrn,", "tokens": ["Ver\u00b7borg\u00b7nen", "Knecht", "des", "Herrn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Der unsern Bund noch h\u00e4lt,", "tokens": ["Der", "un\u00b7sern", "Bund", "noch", "h\u00e4lt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Und ders mit bezeugen k\u00f6nte,", "tokens": ["Und", "ders", "mit", "be\u00b7zeu\u00b7gen", "k\u00f6n\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "VVFIN", "VMFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Was uns da die Liebe g\u00f6nnte.", "tokens": ["Was", "uns", "da", "die", "Lie\u00b7be", "g\u00f6nn\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.7": {"line.1": {"text": "In Colditz hast du mir", "tokens": ["In", "Col\u00b7ditz", "hast", "du", "mir"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "NE", "VAFIN", "PPER", "PPER"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Den Kleinods-Lauf erzehlt", "tokens": ["Den", "Klein\u00b7ods\u00b7Lauf", "er\u00b7zehlt"], "token_info": ["word", "word", "word"], "pos": ["ART", "NN", "VVFIN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Der sonderbaren Vier,", "tokens": ["Der", "son\u00b7der\u00b7ba\u00b7ren", "Vier", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Die sich der Herr erwehlt:", "tokens": ["Die", "sich", "der", "Herr", "er\u00b7wehlt", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Meine Seele mu\u00dfte sagen:", "tokens": ["Mei\u00b7ne", "See\u00b7le", "mu\u00df\u00b7te", "sa\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VMFIN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Das ist Amminadibs Wagen.", "tokens": ["Das", "ist", "Am\u00b7mi\u00b7na\u00b7dibs", "Wa\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "NE", "NN", "$."], "meter": "--+-+-+-", "measure": "anapaest.init"}}, "stanza.8": {"line.1": {"text": "Den Leipziger Besuch", "tokens": ["Den", "Leip\u00b7zi\u00b7ger", "Be\u00b7such"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "(nach unsers Meisters Lehr", "tokens": ["(", "nach", "un\u00b7sers", "Meis\u00b7ters", "Lehr"], "token_info": ["punct", "word", "word", "word", "word"], "pos": ["$(", "APPR", "PPOSAT", "NN", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und dem Concordi-Buch)", "tokens": ["Und", "dem", "Con\u00b7cor\u00b7di\u00b7Buch", ")"], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Verge\u00df ich nimmermehr;", "tokens": ["Ver\u00b7ge\u00df", "ich", "nim\u00b7mer\u00b7mehr", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Den Vergleich der Seligkeiten", "tokens": ["Den", "Ver\u00b7gleich", "der", "Se\u00b7lig\u00b7kei\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Mein Clemens! kan das seyn;", "tokens": ["Mein", "Cle\u00b7mens", "!", "kan", "das", "seyn", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NE", "$.", "VMFIN", "PDS", "VAINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Das theu'r erworbne Gut,", "tokens": ["Das", "theu'r", "er\u00b7worb\u00b7ne", "Gut", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Das F\u00fcnklein Abend-Schein,", "tokens": ["Das", "F\u00fcn\u00b7klein", "A\u00b7ben\u00b7dSchein", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Dein liebes Herrenhut,", "tokens": ["Dein", "lie\u00b7bes", "Her\u00b7ren\u00b7hut", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Das mit dir von Gott entglommen,", "tokens": ["Das", "mit", "dir", "von", "Gott", "ent\u00b7glom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "APPR", "PPER", "APPR", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Hat dich nicht zu sehn bekommen?", "tokens": ["Hat", "dich", "nicht", "zu", "sehn", "be\u00b7kom\u00b7men", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PTKNEG", "PTKZU", "VVINF", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Und also hat der Herr", "tokens": ["Und", "al\u00b7so", "hat", "der", "Herr"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VAFIN", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Nur mich so hoch erfreut,", "tokens": ["Nur", "mich", "so", "hoch", "er\u00b7freut", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "ADV", "ADJD", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Zu sehn euch Wanderer", "tokens": ["Zu", "sehn", "euch", "Wan\u00b7de\u00b7rer"], "token_info": ["word", "word", "word", "word"], "pos": ["PTKZU", "VVINF", "PPER", "NN"], "meter": "-+-+--", "measure": "unknown.measure.di"}, "line.4": {"text": "Zur grossen Ewigkeit:", "tokens": ["Zur", "gros\u00b7sen", "E\u00b7wig\u00b7keit", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Denn die Donner unsers Franken", "tokens": ["Denn", "die", "Don\u00b7ner", "un\u00b7sers", "Fran\u00b7ken"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "H\u00f6rte ich in ihren Schranken.", "tokens": ["H\u00f6r\u00b7te", "ich", "in", "ih\u00b7ren", "Schran\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Als ich nach Halle kam,", "tokens": ["Als", "ich", "nach", "Hal\u00b7le", "kam", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NE", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Itzt zwey und zwanzig Jahr,", "tokens": ["Itzt", "zwey", "und", "zwan\u00b7zig", "Jahr", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "CARD", "KON", "CARD", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und meinem Br\u00e4utigam", "tokens": ["Und", "mei\u00b7nem", "Br\u00e4u\u00b7ti\u00b7gam"], "token_info": ["word", "word", "word"], "pos": ["KON", "PPOSAT", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Schon anvertrauet war;", "tokens": ["Schon", "an\u00b7ver\u00b7trau\u00b7et", "war", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Hab ich Elers tiefes Wesen", "tokens": ["Hab", "ich", "E\u00b7lers", "tie\u00b7fes", "We\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "PPER", "NN", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Mir zum Muster auserlesen.", "tokens": ["Mir", "zum", "Mus\u00b7ter", "au\u00b7ser\u00b7le\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "APPRART", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Da sah ich gleicher Weis", "tokens": ["Da", "sah", "ich", "glei\u00b7cher", "Weis"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Den Paul Antonius,", "tokens": ["Den", "Paul", "An\u00b7to\u00b7ni\u00b7us", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NE", "NE", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Weil seiner Br\u00fcder Flei\u00df", "tokens": ["Weil", "sei\u00b7ner", "Br\u00fc\u00b7der", "Flei\u00df"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PPOSAT", "NN", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Viel Menschen fangen mu\u00df,", "tokens": ["Viel", "Men\u00b7schen", "fan\u00b7gen", "mu\u00df", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Sich zu ihrem Netze flikken", "tokens": ["Sich", "zu", "ih\u00b7rem", "Net\u00b7ze", "flik\u00b7ken"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PRF", "APPR", "PPOSAT", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Ohne langes Winken schikken.", "tokens": ["Oh\u00b7ne", "lan\u00b7ges", "Win\u00b7ken", "schik\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Und, o wie freut ich mich!", "tokens": ["Und", ",", "o", "wie", "freut", "ich", "mich", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "FM", "KOKOM", "VVFIN", "PPER", "PRF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Als ich dich auch erblikt.", "tokens": ["Als", "ich", "dich", "auch", "er\u00b7blikt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ADV", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Dich, theurer Thieme, dich,", "tokens": ["Dich", ",", "theu\u00b7rer", "Thie\u00b7me", ",", "dich", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "$,", "ADJD", "NN", "$,", "PPER", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Den Lieb und Ernst geschm\u00fckt;", "tokens": ["Den", "Lieb", "und", "Ernst", "ge\u00b7schm\u00fckt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Colditz, Leipzig, Dresden sahen", "tokens": ["Col\u00b7ditz", ",", "Leip\u00b7zig", ",", "Dres\u00b7den", "sa\u00b7hen"], "token_info": ["word", "punct", "word", "punct", "word", "word"], "pos": ["NE", "$,", "NE", "$,", "NE", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Unser inniges Umfahen.", "tokens": ["Un\u00b7ser", "in\u00b7ni\u00b7ges", "Um\u00b7fa\u00b7hen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$."], "meter": "+-+++-+-", "measure": "unknown.measure.penta"}}, "stanza.14": {"line.1": {"text": "Mein Trieb verschonet gern", "tokens": ["Mein", "Trieb", "ver\u00b7scho\u00b7net", "gern"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VVFIN", "ADV"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "So manchen in der Welt", "tokens": ["So", "man\u00b7chen", "in", "der", "Welt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "PIAT", "APPR", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Verborgnen Knecht des Herrn,", "tokens": ["Ver\u00b7borg\u00b7nen", "Knecht", "des", "Herrn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Der unsern Bund noch h\u00e4lt,", "tokens": ["Der", "un\u00b7sern", "Bund", "noch", "h\u00e4lt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Und ders mit bezeugen k\u00f6nte,", "tokens": ["Und", "ders", "mit", "be\u00b7zeu\u00b7gen", "k\u00f6n\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "VVFIN", "VMFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Was uns da die Liebe g\u00f6nnte.", "tokens": ["Was", "uns", "da", "die", "Lie\u00b7be", "g\u00f6nn\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.15": {"line.1": {"text": "In Colditz hast du mir", "tokens": ["In", "Col\u00b7ditz", "hast", "du", "mir"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "NE", "VAFIN", "PPER", "PPER"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Den Kleinods-Lauf erzehlt", "tokens": ["Den", "Klein\u00b7ods\u00b7Lauf", "er\u00b7zehlt"], "token_info": ["word", "word", "word"], "pos": ["ART", "NN", "VVFIN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Der sonderbaren Vier,", "tokens": ["Der", "son\u00b7der\u00b7ba\u00b7ren", "Vier", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Die sich der Herr erwehlt:", "tokens": ["Die", "sich", "der", "Herr", "er\u00b7wehlt", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Meine Seele mu\u00dfte sagen:", "tokens": ["Mei\u00b7ne", "See\u00b7le", "mu\u00df\u00b7te", "sa\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VMFIN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Das ist Amminadibs Wagen.", "tokens": ["Das", "ist", "Am\u00b7mi\u00b7na\u00b7dibs", "Wa\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "NE", "NN", "$."], "meter": "--+-+-+-", "measure": "anapaest.init"}}, "stanza.16": {"line.1": {"text": "Den Leipziger Besuch", "tokens": ["Den", "Leip\u00b7zi\u00b7ger", "Be\u00b7such"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "(nach unsers Meisters Lehr", "tokens": ["(", "nach", "un\u00b7sers", "Meis\u00b7ters", "Lehr"], "token_info": ["punct", "word", "word", "word", "word"], "pos": ["$(", "APPR", "PPOSAT", "NN", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und dem Concordi-Buch)", "tokens": ["Und", "dem", "Con\u00b7cor\u00b7di\u00b7Buch", ")"], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Verge\u00df ich nimmermehr;", "tokens": ["Ver\u00b7ge\u00df", "ich", "nim\u00b7mer\u00b7mehr", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Den Vergleich der Seligkeiten", "tokens": ["Den", "Ver\u00b7gleich", "der", "Se\u00b7lig\u00b7kei\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}}}}