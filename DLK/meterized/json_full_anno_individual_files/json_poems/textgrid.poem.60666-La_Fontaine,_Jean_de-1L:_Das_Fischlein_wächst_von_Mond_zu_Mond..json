{"textgrid.poem.60666": {"metadata": {"author": {"name": "La Fontaine, Jean de", "birth": "N.A.", "death": "N.A."}, "title": "1L: Das Fischlein w\u00e4chst von Mond zu Mond.", "genre": "verse", "period": "N.A.", "pub_year": 1658, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Das Fischlein w\u00e4chst von Mond zu Mond.", "tokens": ["Das", "Fisc\u00b7hlein", "w\u00e4chst", "von", "Mond", "zu", "Mond", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Doch wenn man wartend es verschont,", "tokens": ["Doch", "wenn", "man", "war\u00b7tend", "es", "ver\u00b7schont", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PIS", "VAFIN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So scheint mir das durchaus verkehrt;", "tokens": ["So", "scheint", "mir", "das", "durc\u00b7haus", "ver\u00b7kehrt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PDS", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Denn wird man's jemals wiederfangen?", "tokens": ["Denn", "wird", "man's", "je\u00b7mals", "wie\u00b7der\u00b7fan\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PIS", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Ein Karpfen war ins Netz gegangen,", "tokens": ["Ein", "Karp\u00b7fen", "war", "ins", "Netz", "ge\u00b7gan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Noch klein und ohne jeden Wert.", "tokens": ["Noch", "klein", "und", "oh\u00b7ne", "je\u00b7den", "Wert", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KON", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der Fischer sagte: \u00bbImmerhin", "tokens": ["Der", "Fi\u00b7scher", "sag\u00b7te", ":", "\u00bb", "Im\u00b7mer\u00b7hin"], "token_info": ["word", "word", "word", "punct", "punct", "word"], "pos": ["ART", "NN", "VVFIN", "$.", "$(", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ist mir ein Anfang doch beschert", "tokens": ["Ist", "mir", "ein", "An\u00b7fang", "doch", "be\u00b7schert"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "ART", "NN", "ADV", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Zu einem Mahl; auch Kleines z\u00e4hlt.\u00ab", "tokens": ["Zu", "ei\u00b7nem", "Mahl", ";", "auch", "Klei\u00b7nes", "z\u00e4hlt", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "ART", "NN", "$.", "ADV", "NE", "VVFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Das K\u00e4rpfchen flehte angstgequ\u00e4lt:", "tokens": ["Das", "K\u00e4r\u00b7pf\u00b7chen", "fleh\u00b7te", "angst\u00b7ge\u00b7qu\u00e4lt", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "VVPP", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "\u00bbwas hast du, Mensch, mit mir im Sinn?", "tokens": ["\u00bb", "was", "hast", "du", ",", "Mensch", ",", "mit", "mir", "im", "Sinn", "?"], "token_info": ["punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "VAFIN", "PPER", "$,", "NN", "$,", "APPR", "PPER", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Ich f\u00fclle halb dir kaum den Mund.", "tokens": ["Ich", "f\u00fcl\u00b7le", "halb", "dir", "kaum", "den", "Mund", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "PPER", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Wart ab, bis ich erwachsen bin,", "tokens": ["Wart", "ab", ",", "bis", "ich", "er\u00b7wach\u00b7sen", "bin", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKVZ", "$,", "KOUS", "PPER", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Dann zahlt ein Reicher gut f\u00fcr jedes Pfund.", "tokens": ["Dann", "zahlt", "ein", "Rei\u00b7cher", "gut", "f\u00fcr", "je\u00b7des", "Pfund", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ADJD", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Hast du von meiner Gr\u00f6\u00dfe hundert nicht,", "tokens": ["Hast", "du", "von", "mei\u00b7ner", "Gr\u00f6\u00b7\u00dfe", "hun\u00b7dert", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPR", "PPOSAT", "NN", "CARD", "PTKNEG", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "So ist es nur ein mageres Gericht,", "tokens": ["So", "ist", "es", "nur", "ein", "ma\u00b7ge\u00b7res", "Ge\u00b7richt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Und das noch schlecht.\u00ab \u2013 \u00bbNoch schlecht?\u00ab entgegnete der Mann.", "tokens": ["Und", "das", "noch", "schlecht", ".", "\u00ab", "\u2013", "\u00bb", "Noch", "schlecht", "?", "\u00ab", "ent\u00b7geg\u00b7ne\u00b7te", "der", "Mann", "."], "token_info": ["word", "word", "word", "word", "punct", "punct", "punct", "punct", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "ADV", "ADJD", "$.", "$(", "$(", "$(", "ADV", "VVFIN", "$.", "$(", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "\u00bbein Fischlein schlecht, das so vortrefflich predigen kann?", "tokens": ["\u00bb", "ein", "Fisc\u00b7hlein", "schlecht", ",", "das", "so", "vor\u00b7treff\u00b7lich", "pre\u00b7di\u00b7gen", "kann", "?"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "VVFIN", "$,", "PRELS", "ADV", "ADJD", "VVFIN", "VMFIN", "$."], "meter": "-+-+---+-+--+", "measure": "iambic.penta.chol"}}, "stanza.4": {"line.1": {"text": "Zur Pfanne, Freund! Auf meinem Herd", "tokens": ["Zur", "Pfan\u00b7ne", ",", "Freund", "!", "Auf", "mei\u00b7nem", "Herd"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["APPRART", "NN", "$,", "NN", "$.", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sollst braten du und dann mich laben.", "tokens": ["Sollst", "bra\u00b7ten", "du", "und", "dann", "mich", "la\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "VVFIN", "PPER", "KON", "ADV", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Ein \u203aHaben\u2039 ist von gr\u00f6\u00dferm Wert", "tokens": ["Ein", "\u203a", "Ha\u00b7ben", "\u2039", "ist", "von", "gr\u00f6\u00b7\u00dferm", "Wert"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$(", "VAFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Als zwei \u203aIch werde n\u00e4chstens haben\u2039.\u00ab", "tokens": ["Als", "zwei", "\u203a", "Ich", "wer\u00b7de", "n\u00e4chs\u00b7tens", "ha\u00b7ben", "\u2039", ".", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["KOUS", "CARD", "$(", "PPER", "VAFIN", "ADV", "VAFIN", "$(", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Das Fischlein w\u00e4chst von Mond zu Mond.", "tokens": ["Das", "Fisc\u00b7hlein", "w\u00e4chst", "von", "Mond", "zu", "Mond", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Doch wenn man wartend es verschont,", "tokens": ["Doch", "wenn", "man", "war\u00b7tend", "es", "ver\u00b7schont", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PIS", "VAFIN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So scheint mir das durchaus verkehrt;", "tokens": ["So", "scheint", "mir", "das", "durc\u00b7haus", "ver\u00b7kehrt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PDS", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Denn wird man's jemals wiederfangen?", "tokens": ["Denn", "wird", "man's", "je\u00b7mals", "wie\u00b7der\u00b7fan\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PIS", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Ein Karpfen war ins Netz gegangen,", "tokens": ["Ein", "Karp\u00b7fen", "war", "ins", "Netz", "ge\u00b7gan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Noch klein und ohne jeden Wert.", "tokens": ["Noch", "klein", "und", "oh\u00b7ne", "je\u00b7den", "Wert", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KON", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der Fischer sagte: \u00bbImmerhin", "tokens": ["Der", "Fi\u00b7scher", "sag\u00b7te", ":", "\u00bb", "Im\u00b7mer\u00b7hin"], "token_info": ["word", "word", "word", "punct", "punct", "word"], "pos": ["ART", "NN", "VVFIN", "$.", "$(", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ist mir ein Anfang doch beschert", "tokens": ["Ist", "mir", "ein", "An\u00b7fang", "doch", "be\u00b7schert"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "ART", "NN", "ADV", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Zu einem Mahl; auch Kleines z\u00e4hlt.\u00ab", "tokens": ["Zu", "ei\u00b7nem", "Mahl", ";", "auch", "Klei\u00b7nes", "z\u00e4hlt", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "ART", "NN", "$.", "ADV", "NE", "VVFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Das K\u00e4rpfchen flehte angstgequ\u00e4lt:", "tokens": ["Das", "K\u00e4r\u00b7pf\u00b7chen", "fleh\u00b7te", "angst\u00b7ge\u00b7qu\u00e4lt", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "VVPP", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "\u00bbwas hast du, Mensch, mit mir im Sinn?", "tokens": ["\u00bb", "was", "hast", "du", ",", "Mensch", ",", "mit", "mir", "im", "Sinn", "?"], "token_info": ["punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "VAFIN", "PPER", "$,", "NN", "$,", "APPR", "PPER", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Ich f\u00fclle halb dir kaum den Mund.", "tokens": ["Ich", "f\u00fcl\u00b7le", "halb", "dir", "kaum", "den", "Mund", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "PPER", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Wart ab, bis ich erwachsen bin,", "tokens": ["Wart", "ab", ",", "bis", "ich", "er\u00b7wach\u00b7sen", "bin", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKVZ", "$,", "KOUS", "PPER", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Dann zahlt ein Reicher gut f\u00fcr jedes Pfund.", "tokens": ["Dann", "zahlt", "ein", "Rei\u00b7cher", "gut", "f\u00fcr", "je\u00b7des", "Pfund", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ADJD", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Hast du von meiner Gr\u00f6\u00dfe hundert nicht,", "tokens": ["Hast", "du", "von", "mei\u00b7ner", "Gr\u00f6\u00b7\u00dfe", "hun\u00b7dert", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPR", "PPOSAT", "NN", "CARD", "PTKNEG", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "So ist es nur ein mageres Gericht,", "tokens": ["So", "ist", "es", "nur", "ein", "ma\u00b7ge\u00b7res", "Ge\u00b7richt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.7": {"line.1": {"text": "Und das noch schlecht.\u00ab \u2013 \u00bbNoch schlecht?\u00ab entgegnete der Mann.", "tokens": ["Und", "das", "noch", "schlecht", ".", "\u00ab", "\u2013", "\u00bb", "Noch", "schlecht", "?", "\u00ab", "ent\u00b7geg\u00b7ne\u00b7te", "der", "Mann", "."], "token_info": ["word", "word", "word", "word", "punct", "punct", "punct", "punct", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "ADV", "ADJD", "$.", "$(", "$(", "$(", "ADV", "VVFIN", "$.", "$(", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "\u00bbein Fischlein schlecht, das so vortrefflich predigen kann?", "tokens": ["\u00bb", "ein", "Fisc\u00b7hlein", "schlecht", ",", "das", "so", "vor\u00b7treff\u00b7lich", "pre\u00b7di\u00b7gen", "kann", "?"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "VVFIN", "$,", "PRELS", "ADV", "ADJD", "VVFIN", "VMFIN", "$."], "meter": "-+-+---+-+--+", "measure": "iambic.penta.chol"}}, "stanza.8": {"line.1": {"text": "Zur Pfanne, Freund! Auf meinem Herd", "tokens": ["Zur", "Pfan\u00b7ne", ",", "Freund", "!", "Auf", "mei\u00b7nem", "Herd"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["APPRART", "NN", "$,", "NN", "$.", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sollst braten du und dann mich laben.", "tokens": ["Sollst", "bra\u00b7ten", "du", "und", "dann", "mich", "la\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "VVFIN", "PPER", "KON", "ADV", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Ein \u203aHaben\u2039 ist von gr\u00f6\u00dferm Wert", "tokens": ["Ein", "\u203a", "Ha\u00b7ben", "\u2039", "ist", "von", "gr\u00f6\u00b7\u00dferm", "Wert"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$(", "VAFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Als zwei \u203aIch werde n\u00e4chstens haben\u2039.\u00ab", "tokens": ["Als", "zwei", "\u203a", "Ich", "wer\u00b7de", "n\u00e4chs\u00b7tens", "ha\u00b7ben", "\u2039", ".", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["KOUS", "CARD", "$(", "PPER", "VAFIN", "ADV", "VAFIN", "$(", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}