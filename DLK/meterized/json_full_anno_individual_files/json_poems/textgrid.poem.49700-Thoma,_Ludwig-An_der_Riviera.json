{"textgrid.poem.49700": {"metadata": {"author": {"name": "Thoma, Ludwig", "birth": "N.A.", "death": "N.A."}, "title": "An der Riviera", "genre": "verse", "period": "N.A.", "pub_year": 1894, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "An der langen Tafel sind wir gesessen", "tokens": ["An", "der", "lan\u00b7gen", "Ta\u00b7fel", "sind", "wir", "ge\u00b7ses\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "VAFIN", "PPER", "VVPP"], "meter": "--+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Im Hotel. Und ich mu\u00df sagen,", "tokens": ["Im", "Ho\u00b7tel", ".", "Und", "ich", "mu\u00df", "sa\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$.", "KON", "PPER", "VMFIN", "VVINF", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Man hat da wirklich vortrefflich gegessen,", "tokens": ["Man", "hat", "da", "wirk\u00b7lich", "vor\u00b7treff\u00b7lich", "ge\u00b7ges\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "ADV", "ADJD", "ADJD", "VVPP", "$,"], "meter": "-+-+-+---+-", "measure": "unknown.measure.tetra"}, "line.4": {"text": "Auch \u00fcber das Trinken war nicht zu klagen.", "tokens": ["Auch", "\u00fc\u00b7ber", "das", "Trin\u00b7ken", "war", "nicht", "zu", "kla\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "VAFIN", "PTKNEG", "PTKZU", "VVINF", "$."], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}}, "stanza.2": {"line.1": {"text": "Alle Leute, die wir gesehen,", "tokens": ["Al\u00b7le", "Leu\u00b7te", ",", "die", "wir", "ge\u00b7se\u00b7hen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "$,", "PRELS", "PPER", "VVPP", "$,"], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.2": {"text": "\u2013 Man h\u00e4tte das gar nicht zu sagen brauchen \u2013", "tokens": ["\u2013", "Man", "h\u00e4t\u00b7te", "das", "gar", "nicht", "zu", "sa\u00b7gen", "brau\u00b7chen", "\u2013"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PIS", "VAFIN", "PDS", "ADV", "PTKNEG", "PTKZU", "VVINF", "VVFIN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Schifften erst kurz in die H\u00e4fen der Ehen;", "tokens": ["Schiff\u00b7ten", "erst", "kurz", "in", "die", "H\u00e4\u00b7fen", "der", "E\u00b7hen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADJD", "APPR", "ART", "NN", "ART", "NN", "$."], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.4": {"text": "Es waren Deutsche mit ihren Frauchen.", "tokens": ["Es", "wa\u00b7ren", "Deut\u00b7sche", "mit", "ih\u00b7ren", "Frau\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.3": {"line.1": {"text": "Die M\u00e4nnchen sind sichtlich sehr stolz gewesen", "tokens": ["Die", "M\u00e4nn\u00b7chen", "sind", "sicht\u00b7lich", "sehr", "stolz", "ge\u00b7we\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "PRF", "ADV", "ADJD", "VAPP"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "\u00dcber alles, was bereits vorgefallen;", "tokens": ["\u00dc\u00b7ber", "al\u00b7les", ",", "was", "be\u00b7reits", "vor\u00b7ge\u00b7fal\u00b7len", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "$,", "PRELS", "ADV", "VVPP", "$."], "meter": "+-+-+-+--+-", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "In den Siegerblicken war es zu lesen,", "tokens": ["In", "den", "Sie\u00b7ger\u00b7bli\u00b7cken", "war", "es", "zu", "le\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VAFIN", "PPER", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+--+-", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Sie zeigten es gerne und \u00f6ffentlich allen.", "tokens": ["Sie", "zeig\u00b7ten", "es", "ger\u00b7ne", "und", "\u00f6f\u00b7fent\u00b7lich", "al\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "KON", "ADJD", "PIAT", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}}, "stanza.4": {"line.1": {"text": "Die Frauchen bewiesen mit leuchtenden Blicken,", "tokens": ["Die", "Frau\u00b7chen", "be\u00b7wie\u00b7sen", "mit", "leuch\u00b7ten\u00b7den", "Bli\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "APPR", "ADJA", "NN", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.2": {"text": "Da\u00df sie das M\u00e4dchenhafte bezwungen", "tokens": ["Da\u00df", "sie", "das", "M\u00e4d\u00b7chen\u00b7haf\u00b7te", "be\u00b7zwun\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "NN", "VVPP"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Und f\u00e4hig waren, so ganz zu begl\u00fccken", "tokens": ["Und", "f\u00e4\u00b7hig", "wa\u00b7ren", ",", "so", "ganz", "zu", "be\u00b7gl\u00fc\u00b7cken"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "VAFIN", "$,", "ADV", "ADV", "PTKZU", "VVINF"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Die M\u00e4nnchen, welche sie sich errungen.", "tokens": ["Die", "M\u00e4nn\u00b7chen", ",", "wel\u00b7che", "sie", "sich", "er\u00b7run\u00b7gen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "PRF", "VVPP", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.5": {"line.1": {"text": "Und da\u00df sie endlich begehen d\u00fcrften,", "tokens": ["Und", "da\u00df", "sie", "end\u00b7lich", "be\u00b7ge\u00b7hen", "d\u00fcrf\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "VVINF", "VMFIN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Was sie bis jetzt als verboten kannten \u2013", "tokens": ["Was", "sie", "bis", "jetzt", "als", "ver\u00b7bo\u00b7ten", "kann\u00b7ten", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "ADV", "KOKOM", "VVPP", "VVFIN", "$("], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Und da\u00df sie mit Freuden die Wonnen schl\u00fcrften,", "tokens": ["Und", "da\u00df", "sie", "mit", "Freu\u00b7den", "die", "Won\u00b7nen", "schl\u00fcrf\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "APPR", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Auch durchaus nicht abscheulich fanden.", "tokens": ["Auch", "durc\u00b7haus", "nicht", "ab\u00b7scheu\u00b7lich", "fan\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PTKNEG", "ADJD", "VVFIN", "$."], "meter": "-+--++-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.6": {"line.1": {"text": "Es wurde mit Blicken herumgeschmissen,", "tokens": ["Es", "wur\u00b7de", "mit", "Bli\u00b7cken", "her\u00b7um\u00b7ge\u00b7schmis\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "NN", "VVPP", "$,"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "So ganz, als ob sie alleinig seien", "tokens": ["So", "ganz", ",", "als", "ob", "sie", "al\u00b7lei\u00b7nig", "sei\u00b7en"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "$,", "KOKOM", "KOUS", "PPER", "ADJD", "VAFIN"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Mit den geheimen Verst\u00e4ndnissen", "tokens": ["Mit", "den", "ge\u00b7hei\u00b7men", "Ver\u00b7st\u00e4nd\u00b7nis\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "-+-+--+--", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Und den gesetzlichen Schweinigeleien.", "tokens": ["Und", "den", "ge\u00b7setz\u00b7li\u00b7chen", "Schwei\u00b7ni\u00b7ge\u00b7lei\u00b7en", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.7": {"line.1": {"text": "An der langen Tafel sind wir gesessen", "tokens": ["An", "der", "lan\u00b7gen", "Ta\u00b7fel", "sind", "wir", "ge\u00b7ses\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "VAFIN", "PPER", "VVPP"], "meter": "--+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Im Hotel. Und ich mu\u00df sagen,", "tokens": ["Im", "Ho\u00b7tel", ".", "Und", "ich", "mu\u00df", "sa\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$.", "KON", "PPER", "VMFIN", "VVINF", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Man hat da wirklich vortrefflich gegessen,", "tokens": ["Man", "hat", "da", "wirk\u00b7lich", "vor\u00b7treff\u00b7lich", "ge\u00b7ges\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "ADV", "ADJD", "ADJD", "VVPP", "$,"], "meter": "-+-+-+---+-", "measure": "unknown.measure.tetra"}, "line.4": {"text": "Auch \u00fcber das Trinken war nicht zu klagen.", "tokens": ["Auch", "\u00fc\u00b7ber", "das", "Trin\u00b7ken", "war", "nicht", "zu", "kla\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "VAFIN", "PTKNEG", "PTKZU", "VVINF", "$."], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}}, "stanza.8": {"line.1": {"text": "Alle Leute, die wir gesehen,", "tokens": ["Al\u00b7le", "Leu\u00b7te", ",", "die", "wir", "ge\u00b7se\u00b7hen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "$,", "PRELS", "PPER", "VVPP", "$,"], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.2": {"text": "\u2013 Man h\u00e4tte das gar nicht zu sagen brauchen \u2013", "tokens": ["\u2013", "Man", "h\u00e4t\u00b7te", "das", "gar", "nicht", "zu", "sa\u00b7gen", "brau\u00b7chen", "\u2013"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PIS", "VAFIN", "PDS", "ADV", "PTKNEG", "PTKZU", "VVINF", "VVFIN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Schifften erst kurz in die H\u00e4fen der Ehen;", "tokens": ["Schiff\u00b7ten", "erst", "kurz", "in", "die", "H\u00e4\u00b7fen", "der", "E\u00b7hen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADJD", "APPR", "ART", "NN", "ART", "NN", "$."], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.4": {"text": "Es waren Deutsche mit ihren Frauchen.", "tokens": ["Es", "wa\u00b7ren", "Deut\u00b7sche", "mit", "ih\u00b7ren", "Frau\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.9": {"line.1": {"text": "Die M\u00e4nnchen sind sichtlich sehr stolz gewesen", "tokens": ["Die", "M\u00e4nn\u00b7chen", "sind", "sicht\u00b7lich", "sehr", "stolz", "ge\u00b7we\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "PRF", "ADV", "ADJD", "VAPP"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "\u00dcber alles, was bereits vorgefallen;", "tokens": ["\u00dc\u00b7ber", "al\u00b7les", ",", "was", "be\u00b7reits", "vor\u00b7ge\u00b7fal\u00b7len", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "$,", "PRELS", "ADV", "VVPP", "$."], "meter": "+-+-+-+--+-", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "In den Siegerblicken war es zu lesen,", "tokens": ["In", "den", "Sie\u00b7ger\u00b7bli\u00b7cken", "war", "es", "zu", "le\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VAFIN", "PPER", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+--+-", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Sie zeigten es gerne und \u00f6ffentlich allen.", "tokens": ["Sie", "zeig\u00b7ten", "es", "ger\u00b7ne", "und", "\u00f6f\u00b7fent\u00b7lich", "al\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "KON", "ADJD", "PIAT", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}}, "stanza.10": {"line.1": {"text": "Die Frauchen bewiesen mit leuchtenden Blicken,", "tokens": ["Die", "Frau\u00b7chen", "be\u00b7wie\u00b7sen", "mit", "leuch\u00b7ten\u00b7den", "Bli\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "APPR", "ADJA", "NN", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.2": {"text": "Da\u00df sie das M\u00e4dchenhafte bezwungen", "tokens": ["Da\u00df", "sie", "das", "M\u00e4d\u00b7chen\u00b7haf\u00b7te", "be\u00b7zwun\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "NN", "VVPP"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Und f\u00e4hig waren, so ganz zu begl\u00fccken", "tokens": ["Und", "f\u00e4\u00b7hig", "wa\u00b7ren", ",", "so", "ganz", "zu", "be\u00b7gl\u00fc\u00b7cken"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "VAFIN", "$,", "ADV", "ADV", "PTKZU", "VVINF"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Die M\u00e4nnchen, welche sie sich errungen.", "tokens": ["Die", "M\u00e4nn\u00b7chen", ",", "wel\u00b7che", "sie", "sich", "er\u00b7run\u00b7gen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "PRF", "VVPP", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.11": {"line.1": {"text": "Und da\u00df sie endlich begehen d\u00fcrften,", "tokens": ["Und", "da\u00df", "sie", "end\u00b7lich", "be\u00b7ge\u00b7hen", "d\u00fcrf\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "VVINF", "VMFIN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Was sie bis jetzt als verboten kannten \u2013", "tokens": ["Was", "sie", "bis", "jetzt", "als", "ver\u00b7bo\u00b7ten", "kann\u00b7ten", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "ADV", "KOKOM", "VVPP", "VVFIN", "$("], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Und da\u00df sie mit Freuden die Wonnen schl\u00fcrften,", "tokens": ["Und", "da\u00df", "sie", "mit", "Freu\u00b7den", "die", "Won\u00b7nen", "schl\u00fcrf\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "APPR", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Auch durchaus nicht abscheulich fanden.", "tokens": ["Auch", "durc\u00b7haus", "nicht", "ab\u00b7scheu\u00b7lich", "fan\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PTKNEG", "ADJD", "VVFIN", "$."], "meter": "-+--++-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.12": {"line.1": {"text": "Es wurde mit Blicken herumgeschmissen,", "tokens": ["Es", "wur\u00b7de", "mit", "Bli\u00b7cken", "her\u00b7um\u00b7ge\u00b7schmis\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "NN", "VVPP", "$,"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "So ganz, als ob sie alleinig seien", "tokens": ["So", "ganz", ",", "als", "ob", "sie", "al\u00b7lei\u00b7nig", "sei\u00b7en"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "$,", "KOKOM", "KOUS", "PPER", "ADJD", "VAFIN"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Mit den geheimen Verst\u00e4ndnissen", "tokens": ["Mit", "den", "ge\u00b7hei\u00b7men", "Ver\u00b7st\u00e4nd\u00b7nis\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "-+-+--+--", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Und den gesetzlichen Schweinigeleien.", "tokens": ["Und", "den", "ge\u00b7setz\u00b7li\u00b7chen", "Schwei\u00b7ni\u00b7ge\u00b7lei\u00b7en", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}}}}}