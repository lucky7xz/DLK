{"textgrid.poem.33419": {"metadata": {"author": {"name": "Blumauer, Aloys", "birth": "N.A.", "death": "N.A."}, "title": "Schwesterngesundheit, am Namensfeste der Schwester Theresia von S***s", "genre": "verse", "period": "N.A.", "pub_year": 1776, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Aus unser'm Schwestern-", "tokens": ["Aus", "un\u00b7ser'm", "Schwes\u00b7tern"], "token_info": ["word", "word", "word"], "pos": ["APPR", "PPOSAT", "TRUNC"], "meter": "-+-+-", "measure": "iambic.di"}, "line.2": {"text": "Hab' ich euch Br\u00fcder, heute zwo", "tokens": ["Hab'", "ich", "euch", "Br\u00fc\u00b7der", ",", "heu\u00b7te", "zwo"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["NN", "PPER", "PPER", "NN", "$,", "ADV", "CARD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Theresen aufzuf\u00fchren,", "tokens": ["The\u00b7re\u00b7sen", "auf\u00b7zu\u00b7f\u00fch\u00b7ren", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVIZU", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Die beide den verdienten Lohn", "tokens": ["Die", "bei\u00b7de", "den", "ver\u00b7dien\u00b7ten", "Lohn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "PIS", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und die Canonisation", "tokens": ["Und", "die", "Ca\u00b7no\u00b7ni\u00b7sa\u00b7ti\u00b7on"], "token_info": ["word", "word", "word"], "pos": ["KON", "ART", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.6": {"text": "Von uns heut' pr\u00e4tendiren.", "tokens": ["Von", "uns", "heut'", "pr\u00e4\u00b7ten\u00b7di\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Doch weil, zumal zu dieser Frist,", "tokens": ["Doch", "weil", ",", "zu\u00b7mal", "zu", "die\u00b7ser", "Frist", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "$,", "KOUS", "APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das Pulver allzutheuer ist,", "tokens": ["Das", "Pul\u00b7ver", "all\u00b7zu\u00b7theu\u00b7er", "ist", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Das wir dabei verschiessen,", "tokens": ["Das", "wir", "da\u00b7bei", "ver\u00b7schies\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PAV", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "So d\u00e4cht' ich, 's beste w\u00e4r', wenn wir", "tokens": ["So", "d\u00e4cht'", "ich", ",", "'", "s", "bes\u00b7te", "w\u00e4r", "'", ",", "wenn", "wir"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "punct", "punct", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "$,", "$(", "PPER", "VVFIN", "VAFIN", "$(", "$,", "KOUS", "PPER"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Sie nach der heutigen Manier", "tokens": ["Sie", "nach", "der", "heu\u00b7ti\u00b7gen", "Ma\u00b7nier"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "D'rum konkurriren liessen.", "tokens": ["D'\u00b7rum", "kon\u00b7kur\u00b7ri\u00b7ren", "lies\u00b7sen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PAV", "VMFIN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Die eine dieser Schwestern griff", "tokens": ["Die", "ei\u00b7ne", "die\u00b7ser", "Schwes\u00b7tern", "griff"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "PIS", "PDAT", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Nach einer Martyrkron', und lief", "tokens": ["Nach", "ei\u00b7ner", "Mar\u00b7tyr\u00b7kron'", ",", "und", "lief"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "ART", "NN", "$,", "KON", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Bis hin zum Maurenschwarme:", "tokens": ["Bis", "hin", "zum", "Mau\u00b7ren\u00b7schwar\u00b7me", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Die and're, nicht so heilig, floh", "tokens": ["Die", "an\u00b7d'\u00b7re", ",", "nicht", "so", "hei\u00b7lig", ",", "floh"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["ART", "ADJA", "$,", "PTKNEG", "ADV", "ADJD", "$,", "VVFIN"], "meter": "--+-+-+-+", "measure": "anapaest.init"}, "line.5": {"text": "Mit ihrem Jungferkr\u00e4nzchen froh", "tokens": ["Mit", "ih\u00b7rem", "Jung\u00b7fer\u00b7kr\u00e4nz\u00b7chen", "froh"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "In eines Maurers Arme.", "tokens": ["In", "ei\u00b7nes", "Mau\u00b7rers", "Ar\u00b7me", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Die eine hat als Weib sogar", "tokens": ["Die", "ei\u00b7ne", "hat", "als", "Weib", "so\u00b7gar"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "PIS", "VAFIN", "KOKOM", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der ganzen Carmeliterschaar", "tokens": ["Der", "gan\u00b7zen", "Car\u00b7me\u00b7li\u00b7ter\u00b7schaar"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die Hosen weggenommen;", "tokens": ["Die", "Ho\u00b7sen", "weg\u00b7ge\u00b7nom\u00b7men", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Allein der Mann der anderen", "tokens": ["Al\u00b7lein", "der", "Mann", "der", "an\u00b7de\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "ART", "ADJA"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ist um die seinen, wie wir seh'n,", "tokens": ["Ist", "um", "die", "sei\u00b7nen", ",", "wie", "wir", "seh'n", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "PRELS", "PPOSAT", "$,", "PWAV", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Bis dato nicht gekommen.", "tokens": ["Bis", "da\u00b7to", "nicht", "ge\u00b7kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Die eine lie\u00df in dieser Welt,", "tokens": ["Die", "ei\u00b7ne", "lie\u00df", "in", "die\u00b7ser", "Welt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VVFIN", "APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wie die Legende uns erz\u00e4hlt,", "tokens": ["Wie", "die", "Le\u00b7gen\u00b7de", "uns", "er\u00b7z\u00e4hlt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "PPER", "VVFIN", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.3": {"text": "Von ihrem Mann sich kr\u00f6nen:", "tokens": ["Von", "ih\u00b7rem", "Mann", "sich", "kr\u00f6\u00b7nen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PRF", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Die and're w\u00fcnscht sich so was nicht,", "tokens": ["Die", "an\u00b7d'\u00b7re", "w\u00fcnscht", "sich", "so", "was", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VVFIN", "PRF", "ADV", "PWS", "PTKNEG", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Und h\u00e4lt's vielmehr f\u00fcr ihre Pflicht,", "tokens": ["Und", "h\u00e4lt's", "viel\u00b7mehr", "f\u00fcr", "ih\u00b7re", "Pflicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Den ihren nicht zu kr\u00f6nen.", "tokens": ["Den", "ih\u00b7ren", "nicht", "zu", "kr\u00f6\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "PTKNEG", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Die eine tr\u00e4gt Jahr aus Jahr ein", "tokens": ["Die", "ei\u00b7ne", "tr\u00e4gt", "Jahr", "aus", "Jahr", "ein"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "PIS", "VVFIN", "NN", "APPR", "NN", "ART"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.2": {"text": "Am Kopfe einen lichten Schein,", "tokens": ["Am", "Kop\u00b7fe", "ei\u00b7nen", "lich\u00b7ten", "Schein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Viel gr\u00f6sser als ein Teller;", "tokens": ["Viel", "gr\u00f6s\u00b7ser", "als", "ein", "Tel\u00b7ler", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KOKOM", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Doch bei der andern, welche nicht", "tokens": ["Doch", "bei", "der", "an\u00b7dern", ",", "wel\u00b7che", "nicht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "APPR", "ART", "ADJA", "$,", "PRELS", "PTKNEG"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Von aussen leuchtet, ist das Licht", "tokens": ["Von", "aus\u00b7sen", "leuch\u00b7tet", ",", "ist", "das", "Licht"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "NE", "VVFIN", "$,", "VAFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Im Kopfe desto heller.", "tokens": ["Im", "Kop\u00b7fe", "des\u00b7to", "hel\u00b7ler", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADV", "ADJD", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Die eine sieht man nun zum Lohn", "tokens": ["Die", "ei\u00b7ne", "sieht", "man", "nun", "zum", "Lohn"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "PIS", "VVFIN", "PIS", "ADV", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Auf Bildern und Alt\u00e4ren schon", "tokens": ["Auf", "Bil\u00b7dern", "und", "Al\u00b7t\u00e4\u00b7ren", "schon"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Als Heil'ge figuriren;", "tokens": ["Als", "Heil'\u00b7ge", "fi\u00b7gu\u00b7ri\u00b7ren", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["KOUS", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Die and're aber wollen wir", "tokens": ["Die", "an\u00b7d'\u00b7re", "a\u00b7ber", "wol\u00b7len", "wir"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "PIS", "ADV", "VMFIN", "PPER"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.5": {"text": "Mit unseren Kanonen hier", "tokens": ["Mit", "un\u00b7se\u00b7ren", "Ka\u00b7no\u00b7nen", "hier"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Nun auch canonisiren.", "tokens": ["Nun", "auch", "ca\u00b7no\u00b7ni\u00b7si\u00b7ren", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Aus unser'm Schwestern-", "tokens": ["Aus", "un\u00b7ser'm", "Schwes\u00b7tern"], "token_info": ["word", "word", "word"], "pos": ["APPR", "PPOSAT", "TRUNC"], "meter": "-+-+-", "measure": "iambic.di"}, "line.2": {"text": "Hab' ich euch Br\u00fcder, heute zwo", "tokens": ["Hab'", "ich", "euch", "Br\u00fc\u00b7der", ",", "heu\u00b7te", "zwo"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["NN", "PPER", "PPER", "NN", "$,", "ADV", "CARD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Theresen aufzuf\u00fchren,", "tokens": ["The\u00b7re\u00b7sen", "auf\u00b7zu\u00b7f\u00fch\u00b7ren", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVIZU", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Die beide den verdienten Lohn", "tokens": ["Die", "bei\u00b7de", "den", "ver\u00b7dien\u00b7ten", "Lohn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "PIS", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und die Canonisation", "tokens": ["Und", "die", "Ca\u00b7no\u00b7ni\u00b7sa\u00b7ti\u00b7on"], "token_info": ["word", "word", "word"], "pos": ["KON", "ART", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.6": {"text": "Von uns heut' pr\u00e4tendiren.", "tokens": ["Von", "uns", "heut'", "pr\u00e4\u00b7ten\u00b7di\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Doch weil, zumal zu dieser Frist,", "tokens": ["Doch", "weil", ",", "zu\u00b7mal", "zu", "die\u00b7ser", "Frist", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "$,", "KOUS", "APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das Pulver allzutheuer ist,", "tokens": ["Das", "Pul\u00b7ver", "all\u00b7zu\u00b7theu\u00b7er", "ist", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Das wir dabei verschiessen,", "tokens": ["Das", "wir", "da\u00b7bei", "ver\u00b7schies\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PAV", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "So d\u00e4cht' ich, 's beste w\u00e4r', wenn wir", "tokens": ["So", "d\u00e4cht'", "ich", ",", "'", "s", "bes\u00b7te", "w\u00e4r", "'", ",", "wenn", "wir"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "punct", "punct", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "$,", "$(", "PPER", "VVFIN", "VAFIN", "$(", "$,", "KOUS", "PPER"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Sie nach der heutigen Manier", "tokens": ["Sie", "nach", "der", "heu\u00b7ti\u00b7gen", "Ma\u00b7nier"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "D'rum konkurriren liessen.", "tokens": ["D'\u00b7rum", "kon\u00b7kur\u00b7ri\u00b7ren", "lies\u00b7sen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PAV", "VMFIN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Die eine dieser Schwestern griff", "tokens": ["Die", "ei\u00b7ne", "die\u00b7ser", "Schwes\u00b7tern", "griff"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "PIS", "PDAT", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Nach einer Martyrkron', und lief", "tokens": ["Nach", "ei\u00b7ner", "Mar\u00b7tyr\u00b7kron'", ",", "und", "lief"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "ART", "NN", "$,", "KON", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Bis hin zum Maurenschwarme:", "tokens": ["Bis", "hin", "zum", "Mau\u00b7ren\u00b7schwar\u00b7me", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Die and're, nicht so heilig, floh", "tokens": ["Die", "an\u00b7d'\u00b7re", ",", "nicht", "so", "hei\u00b7lig", ",", "floh"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["ART", "ADJA", "$,", "PTKNEG", "ADV", "ADJD", "$,", "VVFIN"], "meter": "--+-+-+-+", "measure": "anapaest.init"}, "line.5": {"text": "Mit ihrem Jungferkr\u00e4nzchen froh", "tokens": ["Mit", "ih\u00b7rem", "Jung\u00b7fer\u00b7kr\u00e4nz\u00b7chen", "froh"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "In eines Maurers Arme.", "tokens": ["In", "ei\u00b7nes", "Mau\u00b7rers", "Ar\u00b7me", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "Die eine hat als Weib sogar", "tokens": ["Die", "ei\u00b7ne", "hat", "als", "Weib", "so\u00b7gar"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "PIS", "VAFIN", "KOKOM", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der ganzen Carmeliterschaar", "tokens": ["Der", "gan\u00b7zen", "Car\u00b7me\u00b7li\u00b7ter\u00b7schaar"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die Hosen weggenommen;", "tokens": ["Die", "Ho\u00b7sen", "weg\u00b7ge\u00b7nom\u00b7men", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Allein der Mann der anderen", "tokens": ["Al\u00b7lein", "der", "Mann", "der", "an\u00b7de\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "ART", "ADJA"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ist um die seinen, wie wir seh'n,", "tokens": ["Ist", "um", "die", "sei\u00b7nen", ",", "wie", "wir", "seh'n", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "PRELS", "PPOSAT", "$,", "PWAV", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Bis dato nicht gekommen.", "tokens": ["Bis", "da\u00b7to", "nicht", "ge\u00b7kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "Die eine lie\u00df in dieser Welt,", "tokens": ["Die", "ei\u00b7ne", "lie\u00df", "in", "die\u00b7ser", "Welt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VVFIN", "APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wie die Legende uns erz\u00e4hlt,", "tokens": ["Wie", "die", "Le\u00b7gen\u00b7de", "uns", "er\u00b7z\u00e4hlt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "PPER", "VVFIN", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.3": {"text": "Von ihrem Mann sich kr\u00f6nen:", "tokens": ["Von", "ih\u00b7rem", "Mann", "sich", "kr\u00f6\u00b7nen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PRF", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Die and're w\u00fcnscht sich so was nicht,", "tokens": ["Die", "an\u00b7d'\u00b7re", "w\u00fcnscht", "sich", "so", "was", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VVFIN", "PRF", "ADV", "PWS", "PTKNEG", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Und h\u00e4lt's vielmehr f\u00fcr ihre Pflicht,", "tokens": ["Und", "h\u00e4lt's", "viel\u00b7mehr", "f\u00fcr", "ih\u00b7re", "Pflicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Den ihren nicht zu kr\u00f6nen.", "tokens": ["Den", "ih\u00b7ren", "nicht", "zu", "kr\u00f6\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "PTKNEG", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.13": {"line.1": {"text": "Die eine tr\u00e4gt Jahr aus Jahr ein", "tokens": ["Die", "ei\u00b7ne", "tr\u00e4gt", "Jahr", "aus", "Jahr", "ein"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "PIS", "VVFIN", "NN", "APPR", "NN", "ART"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.2": {"text": "Am Kopfe einen lichten Schein,", "tokens": ["Am", "Kop\u00b7fe", "ei\u00b7nen", "lich\u00b7ten", "Schein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Viel gr\u00f6sser als ein Teller;", "tokens": ["Viel", "gr\u00f6s\u00b7ser", "als", "ein", "Tel\u00b7ler", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KOKOM", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Doch bei der andern, welche nicht", "tokens": ["Doch", "bei", "der", "an\u00b7dern", ",", "wel\u00b7che", "nicht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "APPR", "ART", "ADJA", "$,", "PRELS", "PTKNEG"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Von aussen leuchtet, ist das Licht", "tokens": ["Von", "aus\u00b7sen", "leuch\u00b7tet", ",", "ist", "das", "Licht"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "NE", "VVFIN", "$,", "VAFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Im Kopfe desto heller.", "tokens": ["Im", "Kop\u00b7fe", "des\u00b7to", "hel\u00b7ler", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADV", "ADJD", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.14": {"line.1": {"text": "Die eine sieht man nun zum Lohn", "tokens": ["Die", "ei\u00b7ne", "sieht", "man", "nun", "zum", "Lohn"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "PIS", "VVFIN", "PIS", "ADV", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Auf Bildern und Alt\u00e4ren schon", "tokens": ["Auf", "Bil\u00b7dern", "und", "Al\u00b7t\u00e4\u00b7ren", "schon"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Als Heil'ge figuriren;", "tokens": ["Als", "Heil'\u00b7ge", "fi\u00b7gu\u00b7ri\u00b7ren", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["KOUS", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Die and're aber wollen wir", "tokens": ["Die", "an\u00b7d'\u00b7re", "a\u00b7ber", "wol\u00b7len", "wir"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "PIS", "ADV", "VMFIN", "PPER"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.5": {"text": "Mit unseren Kanonen hier", "tokens": ["Mit", "un\u00b7se\u00b7ren", "Ka\u00b7no\u00b7nen", "hier"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Nun auch canonisiren.", "tokens": ["Nun", "auch", "ca\u00b7no\u00b7ni\u00b7si\u00b7ren", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}}}}