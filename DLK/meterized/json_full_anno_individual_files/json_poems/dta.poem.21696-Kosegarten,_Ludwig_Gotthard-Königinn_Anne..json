{"dta.poem.21696": {"metadata": {"author": {"name": "Kosegarten, Ludwig Gotthard", "birth": "N.A.", "death": "N.A."}, "title": "K\u00f6niginn Anne.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1802", "urn": "urn:nbn:de:kobv:b4-200905193310", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "K\u00f6niginn Anne liegt zu Rimsted krank,", "tokens": ["K\u00f6\u00b7ni\u00b7ginn", "An\u00b7ne", "liegt", "zu", "Rims\u00b7ted", "krank", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "VVFIN", "APPR", "NE", "ADJD", "$,"], "meter": "---+-+-+-+", "measure": "zehnsilber"}, "line.2": {"text": "Nach Redby man bringen sie musste.", "tokens": ["Nach", "Red\u00b7by", "man", "brin\u00b7gen", "sie", "muss\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "PIS", "VVFIN", "PPER", "VMFIN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "Man musste ihr holen die kl\u00fcgsten Fraun,", "tokens": ["Man", "muss\u00b7te", "ihr", "ho\u00b7len", "die", "kl\u00fcgs\u00b7ten", "Fraun", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "PPER", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "So viel man in D\u00e4nnemark wusste.", "tokens": ["So", "viel", "man", "in", "D\u00e4n\u00b7ne\u00b7mark", "wuss\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PIS", "APPR", "NE", "VVFIN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.5": {"text": "Zu Rimsted ruht K\u00f6niginn Anne.", "tokens": ["Zu", "Rims\u00b7ted", "ruht", "K\u00f6\u00b7ni\u00b7ginn", "An\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VVFIN", "NN", "NE", "$."], "meter": "-+-++--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.2": {"line.1": {"text": "\u201eholt diese mir her, holt jene mir her.", "tokens": ["\u201e", "holt", "die\u00b7se", "mir", "her", ",", "holt", "je\u00b7ne", "mir", "her", "."], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PDAT", "PPER", "PTKVZ", "$,", "VVFIN", "PDS", "PPER", "PTKVZ", "$."], "meter": "+---+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "\u201each holt mir die kl\u00fcgste der Frauen.", "tokens": ["\u201e", "ach", "holt", "mir", "die", "kl\u00fcgs\u00b7te", "der", "Frau\u00b7en", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ITJ", "VVFIN", "PPER", "ART", "ADJA", "ART", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "\u201eholt mir Herrn Ralambs Schwester her,", "tokens": ["\u201e", "holt", "mir", "Herrn", "Ra\u00b7lambs", "Schwes\u00b7ter", "her", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PPER", "NN", "NE", "NN", "PTKVZ", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Mich verlangt lieb Trudchen zu schauen.\u201c", "tokens": ["Mich", "ver\u00b7langt", "lieb", "Trud\u00b7chen", "zu", "schau\u00b7en", ".", "\u201c"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "NN", "PTKZU", "VVINF", "$.", "$("], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.5": {"text": "Zu Rimsted ruht K\u00f6niginn Anne.", "tokens": ["Zu", "Rims\u00b7ted", "ruht", "K\u00f6\u00b7ni\u00b7ginn", "An\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VVFIN", "NN", "NE", "$."], "meter": "-+-++--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.3": {"line.1": {"text": "Lieb Trudchen trat herein zur Th\u00fcr,", "tokens": ["Lieb", "Trud\u00b7chen", "trat", "her\u00b7ein", "zur", "Th\u00fcr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "VVFIN", "PTKVZ", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mit z\u00fcchtigem lieblichem Wesen.", "tokens": ["Mit", "z\u00fcch\u00b7ti\u00b7gem", "lieb\u00b7li\u00b7chem", "We\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "ADJA", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "Gar freundlich die Kranke willkommen sie hiess,", "tokens": ["Gar", "freund\u00b7lich", "die", "Kran\u00b7ke", "will\u00b7kom\u00b7men", "sie", "hiess", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ART", "NN", "ADJD", "PPER", "VVFIN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "Sie freut' sich als sey sie genesen.", "tokens": ["Sie", "freut'", "sich", "als", "sey", "sie", "ge\u00b7ne\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "KOKOM", "VAFIN", "PPER", "VVPP", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.5": {"text": "Zu Rimsted ruht K\u00f6niginn Anne.", "tokens": ["Zu", "Rims\u00b7ted", "ruht", "K\u00f6\u00b7ni\u00b7ginn", "An\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VVFIN", "NN", "NE", "$."], "meter": "-+-++--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.4": {"line.1": {"text": "\u201each k\u00f6nntest du lesen, ach k\u00f6nntest du schreiben,", "tokens": ["\u201e", "ach", "k\u00f6nn\u00b7test", "du", "le\u00b7sen", ",", "ach", "k\u00f6nn\u00b7test", "du", "schrei\u00b7ben", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VMFIN", "PPER", "VVINF", "$,", "ADV", "VMFIN", "PPER", "VVINF", "$,"], "meter": "-+--+-++--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "\u201each k\u00f6nntest du enden mein Leiden.", "tokens": ["\u201e", "ach", "k\u00f6nn\u00b7test", "du", "en\u00b7den", "mein", "Lei\u00b7den", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VMFIN", "PPER", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "\u201eich wollte dir schenken mein sch\u00f6nstes Ross,", "tokens": ["\u201e", "ich", "woll\u00b7te", "dir", "schen\u00b7ken", "mein", "sch\u00f6ns\u00b7tes", "Ross", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VMFIN", "PPER", "VVFIN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "\u201ein rothe Scharlaken dich kleiden.\u201c", "tokens": ["\u201e", "in", "ro\u00b7the", "Schar\u00b7la\u00b7ken", "dich", "klei\u00b7den", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "APPR", "ADJA", "NN", "PPER", "VVINF", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Zu Rimsted ruht K\u00f6niginn Anne.", "tokens": ["Zu", "Rims\u00b7ted", "ruht", "K\u00f6\u00b7ni\u00b7ginn", "An\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VVFIN", "NN", "NE", "$."], "meter": "-+-++--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.5": {"line.1": {"text": "\u201each k\u00f6nnt' ich lesen, ach k\u00f6nnt' ich schreiben,", "tokens": ["\u201e", "ach", "k\u00f6nnt'", "ich", "le\u00b7sen", ",", "ach", "k\u00f6nnt'", "ich", "schrei\u00b7ben", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VMFIN", "PPER", "VVINF", "$,", "ADV", "VMFIN", "PPER", "VVINF", "$,"], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}, "line.2": {"text": "\u201each w\u00e4ret der B\u00fcrden ihr ledig.", "tokens": ["\u201e", "ach", "w\u00e4\u00b7ret", "der", "B\u00fcr\u00b7den", "ihr", "le\u00b7dig", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VAFIN", "ART", "NN", "PPER", "ADJD", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "\u201eerl\u00f6s' euch Gott ins Himmelsthron!", "tokens": ["\u201e", "er\u00b7l\u00f6s'", "euch", "Gott", "ins", "Him\u00b7melst\u00b7hron", "!"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PPER", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "\u201eer ist barmherzig und gn\u00e4dig.\u201c", "tokens": ["\u201e", "er", "ist", "barm\u00b7her\u00b7zig", "und", "gn\u00e4\u00b7dig", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPER", "VAFIN", "ADJD", "KON", "ADJD", "$.", "$("], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Zu Rimsted ruht K\u00f6niginn Anne.", "tokens": ["Zu", "Rims\u00b7ted", "ruht", "K\u00f6\u00b7ni\u00b7ginn", "An\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VVFIN", "NN", "NE", "$."], "meter": "-+-++--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.6": {"line.1": {"text": "Sch\u00f6n Trudchen, sie las im Psalterbuch.", "tokens": ["Sch\u00f6n", "Trud\u00b7chen", ",", "sie", "las", "im", "Psal\u00b7ter\u00b7buch", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "PPER", "VVFIN", "APPRART", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Sie schaut her\u00fcber, hin\u00fcber.", "tokens": ["Sie", "schaut", "her\u00b7\u00fc\u00b7ber", ",", "hin\u00b7\u00fc\u00b7ber", "."], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "ADV", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Die Buchstaben liefen ihr all' in Eins.", "tokens": ["Die", "Buch\u00b7sta\u00b7ben", "lie\u00b7fen", "ihr", "all'", "in", "Eins", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "PIS", "APPR", "NN", "$."], "meter": "-++-+--+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Es gingen die Augen ihr \u00fcber.", "tokens": ["Es", "gin\u00b7gen", "die", "Au\u00b7gen", "ihr", "\u00fc\u00b7ber", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "PPOSAT", "APPR", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.5": {"text": "Zu Rimsted ruht K\u00f6niginn Anne.", "tokens": ["Zu", "Rims\u00b7ted", "ruht", "K\u00f6\u00b7ni\u00b7ginn", "An\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VVFIN", "NN", "NE", "$."], "meter": "-+-++--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.7": {"line.1": {"text": "Sie f\u00fchrten die Kranke hinaus und herein.", "tokens": ["Sie", "f\u00fchr\u00b7ten", "die", "Kran\u00b7ke", "hin\u00b7aus", "und", "her\u00b7ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "PTKVZ", "KON", "PTKVZ", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "Es ward nur schlimmer und schlimmer.", "tokens": ["Es", "ward", "nur", "schlim\u00b7mer", "und", "schlim\u00b7mer", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "\u201eist niemand denn, der meinen Herrn beschickt.", "tokens": ["\u201e", "ist", "nie\u00b7mand", "denn", ",", "der", "mei\u00b7nen", "Herrn", "be\u00b7schickt", "."], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "VAFIN", "PIS", "ADV", "$,", "PRELS", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "\u201egenes' ich doch nimmer und nimmer.\u201c", "tokens": ["\u201e", "ge\u00b7nes'", "ich", "doch", "nim\u00b7mer", "und", "nim\u00b7mer", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VVIMP", "PPER", "ADV", "ADV", "KON", "ADV", "$.", "$("], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.5": {"text": "Zu Rimsted ruht K\u00f6niginn Anne.", "tokens": ["Zu", "Rims\u00b7ted", "ruht", "K\u00f6\u00b7ni\u00b7ginn", "An\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VVFIN", "NN", "NE", "$."], "meter": "-+-++--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.8": {"line.1": {"text": "Das wurde dem flinken Leibburschen gesagt.", "tokens": ["Das", "wur\u00b7de", "dem", "flin\u00b7ken", "Leib\u00b7bur\u00b7schen", "ge\u00b7sagt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Er eilte zum Stalle geschwinde.", "tokens": ["Er", "eil\u00b7te", "zum", "Stal\u00b7le", "ge\u00b7schwin\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "VVPP", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "Er nahm vom Balken den Sattel blank,", "tokens": ["Er", "nahm", "vom", "Bal\u00b7ken", "den", "Sat\u00b7tel", "blank", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Und sprang auf den Klepper behende.", "tokens": ["Und", "sprang", "auf", "den", "Klep\u00b7per", "be\u00b7hen\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "ADJA", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.5": {"text": "Zu Rimsted ruht K\u00f6niginn Anne.", "tokens": ["Zu", "Rims\u00b7ted", "ruht", "K\u00f6\u00b7ni\u00b7ginn", "An\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VVFIN", "NN", "NE", "$."], "meter": "-+-++--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.9": {"line.1": {"text": "Der K\u00f6nig spatzierte auf Skoneborgs Schloss.", "tokens": ["Der", "K\u00f6\u00b7nig", "spat\u00b7zier\u00b7te", "auf", "Sko\u00b7ne\u00b7borgs", "Schloss", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "NE", "NE", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "Er sah ihn reiten von weiten.", "tokens": ["Er", "sah", "ihn", "rei\u00b7ten", "von", "wei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "VVFIN", "APPR", "ADJA", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "\u201ehilf Gott wie mag es um Annen stehn!", "tokens": ["\u201e", "hilf", "Gott", "wie", "mag", "es", "um", "An\u00b7nen", "stehn", "!"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVIMP", "NN", "KOKOM", "VMFIN", "PPER", "APPR", "NN", "VVINF", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "\u201ewas wird mir dies Reiten bedeuten?\u201c", "tokens": ["\u201e", "was", "wird", "mir", "dies", "Rei\u00b7ten", "be\u00b7deu\u00b7ten", "?", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PWS", "VAFIN", "PPER", "PDS", "NN", "VVINF", "$.", "$("], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.5": {"text": "Zu Rimsted ruht K\u00f6niginn Anne.", "tokens": ["Zu", "Rims\u00b7ted", "ruht", "K\u00f6\u00b7ni\u00b7ginn", "An\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VVFIN", "NN", "NE", "$."], "meter": "-+-++--+-", "measure": "iambic.tetra.relaxed"}}}}}