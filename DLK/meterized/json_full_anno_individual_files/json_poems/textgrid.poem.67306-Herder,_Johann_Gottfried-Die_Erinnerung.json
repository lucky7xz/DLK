{"textgrid.poem.67306": {"metadata": {"author": {"name": "Herder, Johann Gottfried", "birth": "N.A.", "death": "N.A."}, "title": "Die Erinnerung", "genre": "verse", "period": "N.A.", "pub_year": 1773, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "\u00bbgute Zeiten, sel'ge Stunden,", "tokens": ["\u00bb", "gu\u00b7te", "Zei\u00b7ten", ",", "sel'\u00b7ge", "Stun\u00b7den", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "ADJA", "NN", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sagt, wo seid Ihr hingeschwunden?", "tokens": ["Sagt", ",", "wo", "seid", "Ihr", "hin\u00b7ge\u00b7schwun\u00b7den", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PWAV", "VAFIN", "PPER", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und zum Ungl\u00fcck oder Gl\u00fcck", "tokens": ["Und", "zum", "Un\u00b7gl\u00fcck", "o\u00b7der", "Gl\u00fcck"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPRART", "NN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Blieb mir Euer Bild zur\u00fcck?\u00ab", "tokens": ["Blieb", "mir", "Eu\u00b7er", "Bild", "zu\u00b7r\u00fcck", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PPER", "PPOSAT", "NN", "PTKVZ", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "\u00bbhin zu neuer Jugend Stunden", "tokens": ["\u00bb", "hin", "zu", "neu\u00b7er", "Ju\u00b7gend", "Stun\u00b7den"], "token_info": ["punct", "word", "word", "word", "word", "word"], "pos": ["$(", "ADV", "APPR", "ADJA", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sind wir leise hingeschwunden;", "tokens": ["Sind", "wir", "lei\u00b7se", "hin\u00b7ge\u00b7schwun\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADJD", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und zur Labung und zum Gl\u00fcck", "tokens": ["Und", "zur", "La\u00b7bung", "und", "zum", "Gl\u00fcck"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPRART", "NN", "KON", "APPRART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Blieb Dir unser Bild zur\u00fcck.\u00ab", "tokens": ["Blieb", "Dir", "un\u00b7ser", "Bild", "zu\u00b7r\u00fcck", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PPER", "PPOSAT", "NN", "PTKVZ", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "\u00bbeuer Bild? Wie ungenossen", "tokens": ["\u00bb", "eu\u00b7er", "Bild", "?", "Wie", "un\u00b7ge\u00b7nos\u00b7sen"], "token_info": ["punct", "word", "word", "punct", "word", "word"], "pos": ["$(", "PPOSAT", "NN", "$.", "PWAV", "ADJD"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sind der Tage viel verflossen!", "tokens": ["Sind", "der", "Ta\u00b7ge", "viel", "ver\u00b7flos\u00b7sen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "ADV", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Tr\u00fcbe kommt dem matten Blick", "tokens": ["Tr\u00fc\u00b7be", "kommt", "dem", "mat\u00b7ten", "Blick"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Reue oft statt Trost zur\u00fcck.\u00ab", "tokens": ["Reu\u00b7e", "oft", "statt", "Trost", "zu\u00b7r\u00fcck", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "ADV", "APPR", "NN", "PTKVZ", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "\u00bbauch der Reue s\u00fc\u00dfe Schmerzen", "tokens": ["\u00bb", "auch", "der", "Reu\u00b7e", "s\u00fc\u00b7\u00dfe", "Schmer\u00b7zen"], "token_info": ["punct", "word", "word", "word", "word", "word"], "pos": ["$(", "ADV", "ART", "NN", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sind ein Balsam kranker Herzen.", "tokens": ["Sind", "ein", "Bal\u00b7sam", "kran\u00b7ker", "Her\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Neuer Muth ist Lebensgl\u00fcck;", "tokens": ["Neu\u00b7er", "Muth", "ist", "Le\u00b7bens\u00b7gl\u00fcck", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VAFIN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Schaue ", "tokens": ["Schau\u00b7e"], "token_info": ["word"], "pos": ["NN"], "meter": "+-", "measure": "trochaic.single"}}, "stanza.5": {"line.1": {"text": "\u00bbvor mich? Sieh, auf jenem H\u00fcgel", "tokens": ["\u00bb", "vor", "mich", "?", "Sieh", ",", "auf", "je\u00b7nem", "H\u00fc\u00b7gel"], "token_info": ["punct", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["$(", "APPR", "PPER", "$.", "NE", "$,", "APPR", "PDAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "In der Abendr\u00f6the Spiegel", "tokens": ["In", "der", "A\u00b7bend\u00b7r\u00f6\u00b7the", "Spie\u00b7gel"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Seh' ich eine Urne stehn;", "tokens": ["Seh'", "ich", "ei\u00b7ne", "Ur\u00b7ne", "stehn", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Darf ich, darf ich zu ihr gehn?\u00ab", "tokens": ["Darf", "ich", ",", "darf", "ich", "zu", "ihr", "gehn", "?", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VMFIN", "PPER", "$,", "VMFIN", "PPER", "APPR", "PPER", "VVINF", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "\u00bbgeh hinan! Die goldnen Stunden", "tokens": ["\u00bb", "geh", "hi\u00b7nan", "!", "Die", "gold\u00b7nen", "Stun\u00b7den"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word"], "pos": ["$(", "VVFIN", "PTKVZ", "$.", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Haben kr\u00e4nzend sie umwunden.", "tokens": ["Ha\u00b7ben", "kr\u00e4n\u00b7zend", "sie", "um\u00b7wun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "VVPP", "PPER", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Lies die Inschrift, gl\u00e4nzend-sch\u00f6n:", "tokens": ["Lies", "die", "In\u00b7schrift", ",", "gl\u00e4n\u00b7zen\u00b7dsch\u00f6n", ":"], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["NE", "ART", "NN", "$,", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "\u00bbgute Zeiten, sel'ge Stunden,", "tokens": ["\u00bb", "gu\u00b7te", "Zei\u00b7ten", ",", "sel'\u00b7ge", "Stun\u00b7den", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "ADJA", "NN", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sagt, wo seid Ihr hingeschwunden?", "tokens": ["Sagt", ",", "wo", "seid", "Ihr", "hin\u00b7ge\u00b7schwun\u00b7den", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PWAV", "VAFIN", "PPER", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und zum Ungl\u00fcck oder Gl\u00fcck", "tokens": ["Und", "zum", "Un\u00b7gl\u00fcck", "o\u00b7der", "Gl\u00fcck"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPRART", "NN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Blieb mir Euer Bild zur\u00fcck?\u00ab", "tokens": ["Blieb", "mir", "Eu\u00b7er", "Bild", "zu\u00b7r\u00fcck", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PPER", "PPOSAT", "NN", "PTKVZ", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "\u00bbhin zu neuer Jugend Stunden", "tokens": ["\u00bb", "hin", "zu", "neu\u00b7er", "Ju\u00b7gend", "Stun\u00b7den"], "token_info": ["punct", "word", "word", "word", "word", "word"], "pos": ["$(", "ADV", "APPR", "ADJA", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sind wir leise hingeschwunden;", "tokens": ["Sind", "wir", "lei\u00b7se", "hin\u00b7ge\u00b7schwun\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADJD", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und zur Labung und zum Gl\u00fcck", "tokens": ["Und", "zur", "La\u00b7bung", "und", "zum", "Gl\u00fcck"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPRART", "NN", "KON", "APPRART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Blieb Dir unser Bild zur\u00fcck.\u00ab", "tokens": ["Blieb", "Dir", "un\u00b7ser", "Bild", "zu\u00b7r\u00fcck", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PPER", "PPOSAT", "NN", "PTKVZ", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "\u00bbeuer Bild? Wie ungenossen", "tokens": ["\u00bb", "eu\u00b7er", "Bild", "?", "Wie", "un\u00b7ge\u00b7nos\u00b7sen"], "token_info": ["punct", "word", "word", "punct", "word", "word"], "pos": ["$(", "PPOSAT", "NN", "$.", "PWAV", "ADJD"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sind der Tage viel verflossen!", "tokens": ["Sind", "der", "Ta\u00b7ge", "viel", "ver\u00b7flos\u00b7sen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "ADV", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Tr\u00fcbe kommt dem matten Blick", "tokens": ["Tr\u00fc\u00b7be", "kommt", "dem", "mat\u00b7ten", "Blick"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Reue oft statt Trost zur\u00fcck.\u00ab", "tokens": ["Reu\u00b7e", "oft", "statt", "Trost", "zu\u00b7r\u00fcck", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "ADV", "APPR", "NN", "PTKVZ", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "\u00bbauch der Reue s\u00fc\u00dfe Schmerzen", "tokens": ["\u00bb", "auch", "der", "Reu\u00b7e", "s\u00fc\u00b7\u00dfe", "Schmer\u00b7zen"], "token_info": ["punct", "word", "word", "word", "word", "word"], "pos": ["$(", "ADV", "ART", "NN", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sind ein Balsam kranker Herzen.", "tokens": ["Sind", "ein", "Bal\u00b7sam", "kran\u00b7ker", "Her\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Neuer Muth ist Lebensgl\u00fcck;", "tokens": ["Neu\u00b7er", "Muth", "ist", "Le\u00b7bens\u00b7gl\u00fcck", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VAFIN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Schaue ", "tokens": ["Schau\u00b7e"], "token_info": ["word"], "pos": ["NN"], "meter": "+-", "measure": "trochaic.single"}}, "stanza.11": {"line.1": {"text": "\u00bbvor mich? Sieh, auf jenem H\u00fcgel", "tokens": ["\u00bb", "vor", "mich", "?", "Sieh", ",", "auf", "je\u00b7nem", "H\u00fc\u00b7gel"], "token_info": ["punct", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["$(", "APPR", "PPER", "$.", "NE", "$,", "APPR", "PDAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "In der Abendr\u00f6the Spiegel", "tokens": ["In", "der", "A\u00b7bend\u00b7r\u00f6\u00b7the", "Spie\u00b7gel"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Seh' ich eine Urne stehn;", "tokens": ["Seh'", "ich", "ei\u00b7ne", "Ur\u00b7ne", "stehn", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Darf ich, darf ich zu ihr gehn?\u00ab", "tokens": ["Darf", "ich", ",", "darf", "ich", "zu", "ihr", "gehn", "?", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VMFIN", "PPER", "$,", "VMFIN", "PPER", "APPR", "PPER", "VVINF", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "\u00bbgeh hinan! Die goldnen Stunden", "tokens": ["\u00bb", "geh", "hi\u00b7nan", "!", "Die", "gold\u00b7nen", "Stun\u00b7den"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word"], "pos": ["$(", "VVFIN", "PTKVZ", "$.", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Haben kr\u00e4nzend sie umwunden.", "tokens": ["Ha\u00b7ben", "kr\u00e4n\u00b7zend", "sie", "um\u00b7wun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "VVPP", "PPER", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Lies die Inschrift, gl\u00e4nzend-sch\u00f6n:", "tokens": ["Lies", "die", "In\u00b7schrift", ",", "gl\u00e4n\u00b7zen\u00b7dsch\u00f6n", ":"], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["NE", "ART", "NN", "$,", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}