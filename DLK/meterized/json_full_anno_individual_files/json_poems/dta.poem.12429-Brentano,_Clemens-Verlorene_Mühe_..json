{"dta.poem.12429": {"metadata": {"author": {"name": "Brentano, Clemens", "birth": "N.A.", "death": "N.A."}, "title": "Verlorene M\u00fche .", "genre": "Lyrik", "period": "N.A.", "pub_year": "1806", "urn": "urn:nbn:de:kobv:b4-20090519157", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Sie. B\u00fcble, wir wollen ausse gehe,               ", "tokens": ["Sie", ".", "B\u00fcb\u00b7le", ",", "wir", "wol\u00b7len", "aus\u00b7se", "ge\u00b7he", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$.", "NN", "$,", "PPER", "VMFIN", "ADV", "VVFIN", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Wollen unsre L\u00e4mmer besehe,", "tokens": ["Wol\u00b7len", "uns\u00b7re", "L\u00e4m\u00b7mer", "be\u00b7se\u00b7he", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "Komm, liebs B\u00fcberle,", "tokens": ["Komm", ",", "liebs", "B\u00fc\u00b7ber\u00b7le", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "$,", "ADJA", "NN", "$,"], "meter": "+-+--", "measure": "unknown.measure.di"}, "line.4": {"text": "Komm, ich bitt.", "tokens": ["Komm", ",", "ich", "bitt", "."], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PPER", "VVFIN", "$."], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.2": {"line.1": {"text": "Er. N\u00e4rrisches Dinterle,               ", "tokens": ["Er", ".", "N\u00e4r\u00b7ri\u00b7sches", "Din\u00b7ter\u00b7le", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["PPER", "$.", "ADJA", "NN", "$,"], "meter": "-+--+--", "measure": "iambic.di.relaxed"}, "line.2": {"text": "Ich geh dir holt nit.", "tokens": ["Ich", "geh", "dir", "holt", "nit", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "VVFIN", "PTKNEG", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}}, "stanza.3": {"line.1": {"text": "Sie. Willst vielleicht a Bissel nasche,               ", "tokens": ["Sie", ".", "Willst", "viel\u00b7leicht", "a", "Bis\u00b7sel", "na\u00b7sche", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$.", "VMFIN", "ADV", "NE", "NE", "ADJA", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Hol dir was aus meiner Tasche;", "tokens": ["Hol", "dir", "was", "aus", "mei\u00b7ner", "Ta\u00b7sche", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PRELS", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Hol, liebs B\u00fcberle,", "tokens": ["Hol", ",", "liebs", "B\u00fc\u00b7ber\u00b7le", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "ADJA", "NN", "$,"], "meter": "+-+--", "measure": "unknown.measure.di"}, "line.4": {"text": "Hol, ich bitt.", "tokens": ["Hol", ",", "ich", "bitt", "."], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "PPER", "VVFIN", "$."], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.4": {"line.1": {"text": "Er. N\u00e4rrisches Dinterle,               ", "tokens": ["Er", ".", "N\u00e4r\u00b7ri\u00b7sches", "Din\u00b7ter\u00b7le", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["PPER", "$.", "ADJA", "NN", "$,"], "meter": "-+--+--", "measure": "iambic.di.relaxed"}, "line.2": {"text": "Ich nasch dir holt nit.", "tokens": ["Ich", "nasch", "dir", "holt", "nit", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "VVFIN", "PTKNEG", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}}, "stanza.5": {"line.1": {"text": "Sie. Thut vielleicht der Durst dich plage,               ", "tokens": ["Sie", ".", "Thut", "viel\u00b7leicht", "der", "Durst", "dich", "pla\u00b7ge", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$.", "NE", "ADV", "ART", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Komm, will dich zum Brunne trage;", "tokens": ["Komm", ",", "will", "dich", "zum", "Brun\u00b7ne", "tra\u00b7ge", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "VMFIN", "PRF", "APPRART", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Trink, liebs B\u00fcberle,", "tokens": ["Trink", ",", "liebs", "B\u00fc\u00b7ber\u00b7le", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "ADJA", "NN", "$,"], "meter": "+-+--", "measure": "unknown.measure.di"}, "line.4": {"text": "Trink, ich bitt.", "tokens": ["Trink", ",", "ich", "bitt", "."], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "PPER", "VVFIN", "$."], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.6": {"line.1": {"text": "Er. N\u00e4rrisches Dinterle,               ", "tokens": ["Er", ".", "N\u00e4r\u00b7ri\u00b7sches", "Din\u00b7ter\u00b7le", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["PPER", "$.", "ADJA", "NN", "$,"], "meter": "-+--+--", "measure": "iambic.di.relaxed"}, "line.2": {"text": "Es d\u00fcrst mich holt nit.", "tokens": ["Es", "d\u00fcrst", "mich", "holt", "nit", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "VVFIN", "PTKNEG", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}}, "stanza.7": {"line.1": {"text": "Sie. Thut vielleicht der Schlaf dich dr\u00fccke,               ", "tokens": ["Sie", ".", "Thut", "viel\u00b7leicht", "der", "Schlaf", "dich", "dr\u00fc\u00b7cke", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$.", "NE", "ADV", "ART", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Schlaf, ich jag dir fort die M\u00fccke;", "tokens": ["Schlaf", ",", "ich", "jag", "dir", "fort", "die", "M\u00fc\u00b7cke", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PPER", "VVFIN", "PPER", "PTKVZ", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Schlaf, liebs B\u00fcberle,", "tokens": ["Schlaf", ",", "liebs", "B\u00fc\u00b7ber\u00b7le", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "ADJA", "NN", "$,"], "meter": "+-+--", "measure": "unknown.measure.di"}, "line.4": {"text": "Schlaf, ich bitt.", "tokens": ["Schlaf", ",", "ich", "bitt", "."], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "PPER", "VVFIN", "$."], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.8": {"line.1": {"text": "Er. N\u00e4rrisches Dinterle,               ", "tokens": ["Er", ".", "N\u00e4r\u00b7ri\u00b7sches", "Din\u00b7ter\u00b7le", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["PPER", "$.", "ADJA", "NN", "$,"], "meter": "-+--+--", "measure": "iambic.di.relaxed"}, "line.2": {"text": "Mich schl\u00e4ferts holt nit.", "tokens": ["Mich", "schl\u00e4\u00b7ferts", "holt", "nit", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "PTKNEG", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}}, "stanza.9": {"line.1": {"text": "Sie. Gelt, ich soll mein Herz dir schenke,               ", "tokens": ["Sie", ".", "Gelt", ",", "ich", "soll", "mein", "Herz", "dir", "schen\u00b7ke", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$.", "NN", "$,", "PPER", "VMFIN", "PPOSAT", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Immer willst an mich gedenke;", "tokens": ["Im\u00b7mer", "willst", "an", "mich", "ge\u00b7den\u00b7ke", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "APPR", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Nimms, lieb B\u00fcberle,", "tokens": ["Nimms", ",", "lieb", "B\u00fc\u00b7ber\u00b7le", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "ADJD", "NN", "$,"], "meter": "+-+--", "measure": "unknown.measure.di"}, "line.4": {"text": "Nimms, ich bitt.", "tokens": ["Nimms", ",", "ich", "bitt", "."], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "PPER", "VVFIN", "$."], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.10": {"line.1": {"text": "Er. N\u00e4rrisches Dinterle,               ", "tokens": ["Er", ".", "N\u00e4r\u00b7ri\u00b7sches", "Din\u00b7ter\u00b7le", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["PPER", "$.", "ADJA", "NN", "$,"], "meter": "-+--+--", "measure": "iambic.di.relaxed"}, "line.2": {"text": "Ich mag es holt nit.", "tokens": ["Ich", "mag", "es", "holt", "nit", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "VVFIN", "PTKNEG", "$."], "meter": "-+---", "measure": "dactylic.init"}}}}}