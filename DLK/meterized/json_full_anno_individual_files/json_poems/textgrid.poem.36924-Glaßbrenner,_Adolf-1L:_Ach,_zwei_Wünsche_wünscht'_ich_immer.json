{"textgrid.poem.36924": {"metadata": {"author": {"name": "Gla\u00dfbrenner, Adolf", "birth": "N.A.", "death": "N.A."}, "title": "1L: Ach, zwei W\u00fcnsche w\u00fcnscht' ich immer", "genre": "verse", "period": "N.A.", "pub_year": 1843, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ach, zwei W\u00fcnsche w\u00fcnscht' ich immer", "tokens": ["Ach", ",", "zwei", "W\u00fcn\u00b7sche", "w\u00fcnscht'", "ich", "im\u00b7mer"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["ITJ", "$,", "CARD", "NN", "VVFIN", "PPER", "ADV"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Leider immer noch vergebens.", "tokens": ["Lei\u00b7der", "im\u00b7mer", "noch", "ver\u00b7ge\u00b7bens", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "ADV", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und doch sind's die innig-frommsten,", "tokens": ["Und", "doch", "sin\u00b7d's", "die", "in\u00b7nig\u00b7fromms\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "ART", "ADJA", "$,"], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Sch\u00f6nsten meines ganzes Lebens!", "tokens": ["Sch\u00f6ns\u00b7ten", "mei\u00b7nes", "gan\u00b7zes", "Le\u00b7bens", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Da\u00df ich alle, alle Menschen", "tokens": ["Da\u00df", "ich", "al\u00b7le", ",", "al\u00b7le", "Men\u00b7schen"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["KOUS", "PPER", "PIS", "$,", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "K\u00f6nnt' mit gleicher Lieb' umfassen,", "tokens": ["K\u00f6nnt'", "mit", "glei\u00b7cher", "Lieb'", "um\u00b7fas\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "APPR", "ADJA", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und da\u00df Ein'ge ich von ihnen", "tokens": ["Und", "da\u00df", "Ein'\u00b7ge", "ich", "von", "ih\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "NN", "PPER", "APPR", "PPER"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Morgen d\u00fcrfte h\u00e4ngen lassen.", "tokens": ["Mor\u00b7gen", "d\u00fcrf\u00b7te", "h\u00e4n\u00b7gen", "las\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "VVINF", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Ach, zwei W\u00fcnsche w\u00fcnscht' ich immer", "tokens": ["Ach", ",", "zwei", "W\u00fcn\u00b7sche", "w\u00fcnscht'", "ich", "im\u00b7mer"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["ITJ", "$,", "CARD", "NN", "VVFIN", "PPER", "ADV"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Leider immer noch vergebens.", "tokens": ["Lei\u00b7der", "im\u00b7mer", "noch", "ver\u00b7ge\u00b7bens", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "ADV", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und doch sind's die innig-frommsten,", "tokens": ["Und", "doch", "sin\u00b7d's", "die", "in\u00b7nig\u00b7fromms\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "ART", "ADJA", "$,"], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Sch\u00f6nsten meines ganzes Lebens!", "tokens": ["Sch\u00f6ns\u00b7ten", "mei\u00b7nes", "gan\u00b7zes", "Le\u00b7bens", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Da\u00df ich alle, alle Menschen", "tokens": ["Da\u00df", "ich", "al\u00b7le", ",", "al\u00b7le", "Men\u00b7schen"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["KOUS", "PPER", "PIS", "$,", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "K\u00f6nnt' mit gleicher Lieb' umfassen,", "tokens": ["K\u00f6nnt'", "mit", "glei\u00b7cher", "Lieb'", "um\u00b7fas\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "APPR", "ADJA", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und da\u00df Ein'ge ich von ihnen", "tokens": ["Und", "da\u00df", "Ein'\u00b7ge", "ich", "von", "ih\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "NN", "PPER", "APPR", "PPER"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Morgen d\u00fcrfte h\u00e4ngen lassen.", "tokens": ["Mor\u00b7gen", "d\u00fcrf\u00b7te", "h\u00e4n\u00b7gen", "las\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "VVINF", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}}}}