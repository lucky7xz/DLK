{"dta.poem.10107": {"metadata": {"author": {"name": "Brockes, Barthold Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "Erwegung einiger von GOTT, auch  \n denen armen Menschen, alle Tage geg\u00f6n-  \n neten Ergetz- und Bequemlich-  \n keiten.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1735", "urn": "urn:nbn:de:kobv:b4-20086-0", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Da wir auf dieser Welt in stetem Unvergn\u00fcgen,", "tokens": ["Da", "wir", "auf", "die\u00b7ser", "Welt", "in", "ste\u00b7tem", "Un\u00b7ver\u00b7gn\u00fc\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PDAT", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Auch selbst im Uberflu\u00df, und wann wir gl\u00fccklich seyn,", "tokens": ["Auch", "selbst", "im", "U\u00b7ber\u00b7flu\u00df", ",", "und", "wann", "wir", "gl\u00fcck\u00b7lich", "seyn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPRART", "NN", "$,", "KON", "PWAV", "PPER", "ADJD", "VAINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Durch Unerkenntlichkeit des guten blo\u00df allein,", "tokens": ["Durch", "Un\u00b7er\u00b7kennt\u00b7lich\u00b7keit", "des", "gu\u00b7ten", "blo\u00df", "al\u00b7lein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ART", "ADJA", "ADV", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So ungl\u00fcckseelig liegen;", "tokens": ["So", "un\u00b7gl\u00fcck\u00b7see\u00b7lig", "lie\u00b7gen", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Auf! auf! mein Geist, die Ordnung der Natur,", "tokens": ["Auf", "!", "auf", "!", "mein", "Geist", ",", "die", "Ord\u00b7nung", "der", "Na\u00b7tur", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "$.", "PTKVZ", "$.", "PPOSAT", "NN", "$,", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Die sie mit Menschen h\u00e4lt, ein wenig zu erwegen!", "tokens": ["Die", "sie", "mit", "Men\u00b7schen", "h\u00e4lt", ",", "ein", "we\u00b7nig", "zu", "er\u00b7we\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "NN", "VVFIN", "$,", "ART", "PIS", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und ob es ihre Schuld, da\u00df so gar wenig nur", "tokens": ["Und", "ob", "es", "ih\u00b7re", "Schuld", ",", "da\u00df", "so", "gar", "we\u00b7nig", "nur"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "PPOSAT", "NN", "$,", "KOUS", "ADV", "ADV", "PIS", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Ohn Unzufriedenheit zu leben pflegen.", "tokens": ["Ohn", "Un\u00b7zu\u00b7frie\u00b7den\u00b7heit", "zu", "le\u00b7ben", "pfle\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PTKZU", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Ich spreche nicht allein von Reichen; auch von denen,", "tokens": ["Ich", "spre\u00b7che", "nicht", "al\u00b7lein", "von", "Rei\u00b7chen", ";", "auch", "von", "de\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "ADV", "APPR", "NN", "$.", "ADV", "APPR", "PRELS", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Die d\u00fcrftig sind, will ich allhier erwehnen.", "tokens": ["Die", "d\u00fcrf\u00b7tig", "sind", ",", "will", "ich", "all\u00b7hier", "er\u00b7weh\u00b7nen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "VAFIN", "$,", "VMFIN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "So f\u00fcr die Armen, als die Reichen,", "tokens": ["So", "f\u00fcr", "die", "Ar\u00b7men", ",", "als", "die", "Rei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "$,", "KOUS", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sieht man des Morgens fr\u00fch die dunckle Nacht", "tokens": ["Sieht", "man", "des", "Mor\u00b7gens", "fr\u00fch", "die", "dunck\u00b7le", "Nacht"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PIS", "ART", "ADV", "ADJD", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Mit ihren falben Schatten weichen.", "tokens": ["Mit", "ih\u00b7ren", "fal\u00b7ben", "Schat\u00b7ten", "wei\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "F\u00fcr beide zeiget sich der Morgen-R\u00f6the Pracht,", "tokens": ["F\u00fcr", "bei\u00b7de", "zei\u00b7get", "sich", "der", "Mor\u00b7gen\u00b7R\u00f6\u00b7the", "Pracht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "VVFIN", "PRF", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "So die nur erst vergehnde Schw\u00e4rtze", "tokens": ["So", "die", "nur", "erst", "ver\u00b7gehn\u00b7de", "Schw\u00e4rt\u00b7ze"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "ADV", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "In der Ver\u00e4nderung \u00fcm so viel sch\u00f6ner macht.", "tokens": ["In", "der", "Ver\u00b7\u00e4n\u00b7de\u00b7rung", "\u00fcm", "so", "viel", "sch\u00f6\u00b7ner", "macht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADV", "ADV", "ADV", "ADJD", "VVFIN", "$."], "meter": "+--+--+--+-+", "measure": "dactylic.tri.plus"}}, "stanza.3": {"line.1": {"text": "Jhr Leib wird alle Nacht ohn Ausnahm ja gest\u00e4rcket", "tokens": ["Ihr", "Leib", "wird", "al\u00b7le", "Nacht", "ohn", "Aus\u00b7nahm", "ja", "ge\u00b7st\u00e4r\u00b7cket"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VAFIN", "PIAT", "NN", "APPR", "NN", "ADV", "VVPP"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Durch dieses Wunder der Natur:", "tokens": ["Durch", "die\u00b7ses", "Wun\u00b7der", "der", "Na\u00b7tur", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wobey der Geist zugleich verneute Kr\u00e4ffte mercket,", "tokens": ["Wo\u00b7bey", "der", "Geist", "zu\u00b7gleich", "ver\u00b7neu\u00b7te", "Kr\u00e4ff\u00b7te", "mer\u00b7cket", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ADV", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Durch einen s\u00fcssen Schlaff, der ihn die Zeit nicht nur", "tokens": ["Durch", "ei\u00b7nen", "s\u00fcs\u00b7sen", "Schlaff", ",", "der", "ihn", "die", "Zeit", "nicht", "nur"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "$,", "PRELS", "PPER", "ART", "NN", "PTKNEG", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Vergn\u00fcgt verbringen l\u00e4sst; der Gram und Leid vermindert,", "tokens": ["Ver\u00b7gn\u00fcgt", "ver\u00b7brin\u00b7gen", "l\u00e4sst", ";", "der", "Gram", "und", "Leid", "ver\u00b7min\u00b7dert", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "VVINF", "VVFIN", "$.", "ART", "NN", "KON", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Ja ihn, in dem schon angefangnen Lauff", "tokens": ["Ja", "ihn", ",", "in", "dem", "schon", "an\u00b7ge\u00b7fang\u00b7nen", "Lauff"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "PPER", "$,", "APPR", "ART", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Der Schwehrmuth, fortzufahren hindert.", "tokens": ["Der", "Schwehr\u00b7muth", ",", "fort\u00b7zu\u00b7fah\u00b7ren", "hin\u00b7dert", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "VVIZU", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Und kurtz: wir stehn, an Leib und Geist verneuet, auf.", "tokens": ["Und", "kurtz", ":", "wir", "stehn", ",", "an", "Leib", "und", "Geist", "ver\u00b7neu\u00b7et", ",", "auf", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "ADJD", "$.", "PPER", "VVFIN", "$,", "APPR", "NN", "KON", "NN", "VVFIN", "$,", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "In dieser Gab\u2019 allein ist, wenn mans recht bedencket,", "tokens": ["In", "die\u00b7ser", "Gab'", "al\u00b7lein", "ist", ",", "wenn", "mans", "recht", "be\u00b7den\u00b7cket", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "ADV", "VAFIN", "$,", "KOUS", "PIS", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Uns ein unsch\u00e4tzbar Gut und grosser Schatz geschencket.", "tokens": ["Uns", "ein", "un\u00b7sch\u00e4tz\u00b7bar", "Gut", "und", "gros\u00b7ser", "Schatz", "ge\u00b7schen\u00b7cket", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "ADJD", "ADJD", "KON", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Die Sinnen sind, wann sie der Schlaf erquickt,", "tokens": ["Die", "Sin\u00b7nen", "sind", ",", "wann", "sie", "der", "Schlaf", "er\u00b7quickt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "$,", "PWAV", "PPER", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Aufs neu gest\u00e4rckt, und mehr, als wie vorhin, geschickt,", "tokens": ["Aufs", "neu", "ge\u00b7st\u00e4rckt", ",", "und", "mehr", ",", "als", "wie", "vor\u00b7hin", ",", "ge\u00b7schickt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPRART", "ADJD", "VVPP", "$,", "KON", "ADV", "$,", "KOUS", "KOKOM", "ADV", "$,", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die Creatur, die durch das Morgen-Licht", "tokens": ["Die", "Crea\u00b7tur", ",", "die", "durch", "das", "Mor\u00b7gen\u00b7Licht"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "APPR", "ART", "NN"], "meter": "--+-+-+-+", "measure": "anapaest.init"}, "line.4": {"text": "Zugleich versch\u00f6nert wird, zu sehn und zu betrachten.", "tokens": ["Zu\u00b7gleich", "ver\u00b7sch\u00f6\u00b7nert", "wird", ",", "zu", "sehn", "und", "zu", "be\u00b7trach\u00b7ten", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVPP", "VAFIN", "$,", "PTKZU", "VVINF", "KON", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ach m\u00f6gten wir dieselbigen nur nicht", "tokens": ["Ach", "m\u00f6g\u00b7ten", "wir", "die\u00b7sel\u00b7bi\u00b7gen", "nur", "nicht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "VMFIN", "PPER", "PDS", "ADV", "PTKNEG"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "So klein, und unsers Blicks nicht w\u00fcrdig achten!", "tokens": ["So", "klein", ",", "und", "un\u00b7sers", "Blicks", "nicht", "w\u00fcr\u00b7dig", "ach\u00b7ten", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "KON", "PPOSAT", "NN", "PTKNEG", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Da die Gewohnheit sonst durch ihre strenge Macht", "tokens": ["Da", "die", "Ge\u00b7wohn\u00b7heit", "sonst", "durch", "ih\u00b7re", "stren\u00b7ge", "Macht"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "ADV", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Uns alles Gute raubt; so wird durch Tag und Nacht", "tokens": ["Uns", "al\u00b7les", "Gu\u00b7te", "raubt", ";", "so", "wird", "durch", "Tag", "und", "Nacht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "PIAT", "NN", "VVFIN", "$.", "ADV", "VAFIN", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Die sch\u00e4dliche Gewalt derselben unterbrochen.", "tokens": ["Die", "sch\u00e4d\u00b7li\u00b7che", "Ge\u00b7walt", "der\u00b7sel\u00b7ben", "un\u00b7ter\u00b7bro\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PDAT", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Jhr Wechsel giebt und nimmt, und zwingt uns fast, von", "tokens": ["Ihr", "Wech\u00b7sel", "giebt", "und", "nimmt", ",", "und", "zwingt", "uns", "fast", ",", "von"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word"], "pos": ["PPOSAT", "NN", "VVFIN", "KON", "VVFIN", "$,", "KON", "VVFIN", "PPER", "ADV", "$,", "APPR"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.11": {"text": "Der Sch\u00f6nheit, die bald kommt, bald weicht, uns zu er-", "tokens": ["Der", "Sch\u00f6n\u00b7heit", ",", "die", "bald", "kommt", ",", "bald", "weicht", ",", "uns", "zu", "er"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "ADV", "VVFIN", "$,", "ADV", "VVFIN", "$,", "PPER", "APPR", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "Bey vielen geht hierauf nun zwar die Arbeit an,", "tokens": ["Bey", "vie\u00b7len", "geht", "hier\u00b7auf", "nun", "zwar", "die", "Ar\u00b7beit", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "VVFIN", "PAV", "ADV", "ADV", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die mancher wol nicht allezeit", "tokens": ["Die", "man\u00b7cher", "wol", "nicht", "al\u00b7le\u00b7zeit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "PIS", "ADV", "PTKNEG", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "F\u00fcr einen Zeit-Vertreib und Anmuth halten kann;", "tokens": ["F\u00fcr", "ei\u00b7nen", "Zeit\u00b7Ver\u00b7treib", "und", "An\u00b7muth", "hal\u00b7ten", "kann", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "KON", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Doch, ausser da\u00df sie ihn ernehret,", "tokens": ["Doch", ",", "aus\u00b7ser", "da\u00df", "sie", "ihn", "er\u00b7neh\u00b7ret", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "APPR", "KOUS", "PPER", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Ist sie auch mehrentheils von der Beschaffenheit,", "tokens": ["Ist", "sie", "auch", "meh\u00b7ren\u00b7theils", "von", "der", "Be\u00b7schaf\u00b7fen\u00b7heit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Da\u00df sie die Essens-Lust vermehret.", "tokens": ["Da\u00df", "sie", "die", "Es\u00b7sens\u00b7Lust", "ver\u00b7meh\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Da schmeckt das Morgen-Brodt. Ist dieses keine Lust?", "tokens": ["Da", "schmeckt", "das", "Mor\u00b7gen\u00b7Brodt", ".", "Ist", "die\u00b7ses", "kei\u00b7ne", "Lust", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$.", "VAFIN", "PDAT", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "F\u00fcrwahr, wer es erwegt,", "tokens": ["F\u00fcr\u00b7wahr", ",", "wer", "es", "er\u00b7wegt", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PWS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "Wie in den Appetit so Nutzen als Ergetzen", "tokens": ["Wie", "in", "den", "Ap\u00b7pe\u00b7tit", "so", "Nut\u00b7zen", "als", "Er\u00b7get\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "APPR", "ART", "NN", "ADV", "NN", "KOUS", "NN"], "meter": "-+-+-+-+-+++-", "measure": "unknown.measure.septa"}, "line.10": {"text": "Von GOTT so wunderbar gelegt,", "tokens": ["Von", "GoTT", "so", "wun\u00b7der\u00b7bar", "ge\u00b7legt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "ADV", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Wird diese Zungen-Lust nicht so geringe sch\u00e4tzen.", "tokens": ["Wird", "die\u00b7se", "Zun\u00b7gen\u00b7Lust", "nicht", "so", "ge\u00b7rin\u00b7ge", "sch\u00e4t\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PDAT", "NN", "PTKNEG", "ADV", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Hat ihm der Morgen nun, der unsers Tages Lentzen,", "tokens": ["Hat", "ihm", "der", "Mor\u00b7gen", "nun", ",", "der", "un\u00b7sers", "Ta\u00b7ges", "Lent\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "NN", "ADV", "$,", "PRELS", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ein\u2019 angenehme Freud\u2019 im Anbi\u00df erst beschehrt;", "tokens": ["Ein'", "an\u00b7ge\u00b7neh\u00b7me", "Freud'", "im", "An\u00b7bi\u00df", "erst", "be\u00b7schehrt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPRART", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "So wird noch eine gr\u00f6ssre Lust,", "tokens": ["So", "wird", "noch", "ei\u00b7ne", "gr\u00f6ss\u00b7re", "Lust", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wann erst des Mittags Strahlen gl\u00e4utzen,", "tokens": ["Wann", "erst", "des", "Mit\u00b7tags", "Strah\u00b7len", "gl\u00e4ut\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "ART", "NN", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Mit noch vergr\u00f6ssertem Vergn\u00fcgen unsrer Brust,", "tokens": ["Mit", "noch", "ver\u00b7gr\u00f6s\u00b7ser\u00b7tem", "Ver\u00b7gn\u00fc\u00b7gen", "uns\u00b7rer", "Brust", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "ADJA", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wann man sein Mittags-Mahl verzehrt,", "tokens": ["Wann", "man", "sein", "Mit\u00b7tags\u00b7Mahl", "ver\u00b7zehrt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Vervielfacht und vermehrt.", "tokens": ["Ver\u00b7viel\u00b7facht", "und", "ver\u00b7mehrt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Nur zu bedauren ists, da\u00df wir, was GOTT ins Essen", "tokens": ["Nur", "zu", "be\u00b7dau\u00b7ren", "ists", ",", "da\u00df", "wir", ",", "was", "GoTT", "ins", "Es\u00b7sen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "PTKZU", "VVINF", "VAFIN", "$,", "KOUS", "PPER", "$,", "PRELS", "NE", "APPRART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "F\u00fcr eine Lust gesenckt, nicht achten, nicht ermessen.", "tokens": ["F\u00fcr", "ei\u00b7ne", "Lust", "ge\u00b7senckt", ",", "nicht", "ach\u00b7ten", ",", "nicht", "er\u00b7mes\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVPP", "$,", "PTKNEG", "VVINF", "$,", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Erstaunens wehrt ist ja des Schmeckens Krafft,", "tokens": ["Er\u00b7stau\u00b7nens", "wehrt", "ist", "ja", "des", "Schme\u00b7ckens", "Krafft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "VAFIN", "ADV", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Erstaunens wehrt der Zungen Eigenschafft,", "tokens": ["Er\u00b7stau\u00b7nens", "wehrt", "der", "Zun\u00b7gen", "Ei\u00b7gen\u00b7schafft", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Erstaunens wehrt, wie viel, wie mancherley", "tokens": ["Er\u00b7stau\u00b7nens", "wehrt", ",", "wie", "viel", ",", "wie", "man\u00b7cher\u00b7ley"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["ADV", "VVFIN", "$,", "PWAV", "PIS", "$,", "PWAV", "PIS"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Ver\u00e4nderung, Empfindlichkeit, Vergn\u00fcgen,", "tokens": ["Ver\u00b7\u00e4n\u00b7de\u00b7rung", ",", "Emp\u00b7find\u00b7lich\u00b7keit", ",", "Ver\u00b7gn\u00fc\u00b7gen", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "In so verschiednen C\u00f6rpern liegen,", "tokens": ["In", "so", "ver\u00b7schied\u00b7nen", "C\u00f6r\u00b7pern", "lie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Und wie so Gaum als Zahn formiret sey,", "tokens": ["Und", "wie", "so", "Gaum", "als", "Zahn", "for\u00b7mi\u00b7ret", "sey", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ADV", "NN", "KOUS", "NN", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Durch ein Zermalmen, pressen, dr\u00fccken,", "tokens": ["Durch", "ein", "Zer\u00b7mal\u00b7men", ",", "pres\u00b7sen", ",", "dr\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "VVFIN", "$,", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Uns zuzueignen, zu entdecken", "tokens": ["Uns", "zu\u00b7zu\u00b7eig\u00b7nen", ",", "zu", "ent\u00b7de\u00b7cken"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["PPER", "VVIZU", "$,", "PTKZU", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Die S\u00e4ffte, die in C\u00f6rpern stecken;", "tokens": ["Die", "S\u00e4ff\u00b7te", ",", "die", "in", "C\u00f6r\u00b7pern", "ste\u00b7cken", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Und die, wann wir den Magen f\u00fcllen,", "tokens": ["Und", "die", ",", "wann", "wir", "den", "Ma\u00b7gen", "f\u00fcl\u00b7len", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "$,", "PWAV", "PPER", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Nicht nur den Durst und Hunger stillen;", "tokens": ["Nicht", "nur", "den", "Durst", "und", "Hun\u00b7ger", "stil\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "ART", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "Nein, die zugleich (o Wunder!) uns erquicken,", "tokens": ["Nein", ",", "die", "zu\u00b7gleich", "(", "o", "Wun\u00b7der", "!", ")", "uns", "er\u00b7qui\u00b7cken", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PRELS", "ADV", "$(", "FM", "NN", "$.", "$(", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.15": {"text": "Und in so sehr verschiednem schmecken,", "tokens": ["Und", "in", "so", "sehr", "ver\u00b7schied\u00b7nem", "schme\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ADV", "ADV", "ADJA", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "Uns so verschiedne Lust erwecken.", "tokens": ["Uns", "so", "ver\u00b7schied\u00b7ne", "Lust", "er\u00b7we\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Ein Handwercks-Mann sollt hier absonderlich be-", "tokens": ["Ein", "Handwercks\u00b7Mann", "sollt", "hier", "ab\u00b7son\u00b7der\u00b7lich", "be"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VMFIN", "ADV", "ADJD", "TRUNC"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Die weise G\u00fctigkeit des Sch\u00f6pfers, der nicht nur", "tokens": ["Die", "wei\u00b7se", "G\u00fc\u00b7tig\u00b7keit", "des", "Sch\u00f6p\u00b7fers", ",", "der", "nicht", "nur"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "$,", "PRELS", "PTKNEG", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Den Reichen solche Lust gew\u00fcrdiget zu schencken,", "tokens": ["Den", "Rei\u00b7chen", "sol\u00b7che", "Lust", "ge\u00b7w\u00fcr\u00b7di\u00b7get", "zu", "schen\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PIAT", "NN", "VVPP", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Da\u00df sie, durch den Gebrauch so mancher Creatur,", "tokens": ["Da\u00df", "sie", ",", "durch", "den", "Ge\u00b7brauch", "so", "man\u00b7cher", "Crea\u00b7tur", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "APPR", "ART", "NN", "ADV", "PIAT", "NN", "$,"], "meter": "--+--+-+--+", "measure": "anapaest.di.plus"}, "line.5": {"text": "Und tausendfach gew\u00fcrtzte Speise,", "tokens": ["Und", "tau\u00b7send\u00b7fach", "ge\u00b7w\u00fcrtz\u00b7te", "Spei\u00b7se", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Absonderlich vergn\u00fcget werden;", "tokens": ["Ab\u00b7son\u00b7der\u00b7lich", "ver\u00b7gn\u00fc\u00b7get", "wer\u00b7den", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Ach nein! er wird vergn\u00fcgt auf gleiche Weise,", "tokens": ["Ach", "nein", "!", "er", "wird", "ver\u00b7gn\u00fcgt", "auf", "glei\u00b7che", "Wei\u00b7se", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKANT", "$.", "PPER", "VAFIN", "VVPP", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Indem der Hunger ja, wie die Erfahrung lehrt,", "tokens": ["In\u00b7dem", "der", "Hun\u00b7ger", "ja", ",", "wie", "die", "Er\u00b7fah\u00b7rung", "lehrt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "PTKANT", "$,", "PWAV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Das niedlichste Gew\u00fcrtz, der beste Koch auf Erden.", "tokens": ["Das", "nied\u00b7lichs\u00b7te", "Ge\u00b7w\u00fcrtz", ",", "der", "bes\u00b7te", "Koch", "auf", "Er\u00b7den", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "ADJA", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Nach den bey Tisch\u2019 erhaltnen neuen Kr\u00e4fften,", "tokens": ["Nach", "den", "bey", "Tisch'", "er\u00b7halt\u00b7nen", "neu\u00b7en", "Kr\u00e4ff\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "APPR", "NN", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Eilt ieder wieder\u00fcm zu seinen Haus-Gesch\u00e4fften,", "tokens": ["Eilt", "ie\u00b7der", "wie\u00b7de\u00b7r\u00fcm", "zu", "sei\u00b7nen", "Haus\u00b7Ge\u00b7sch\u00e4ff\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wer klug ist, wolgemuth.", "tokens": ["Wer", "klug", "ist", ",", "wol\u00b7ge\u00b7muth", "."], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["PWS", "ADJD", "VAFIN", "$,", "PWAV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Denn was man fr\u00f6hlich thut,", "tokens": ["Denn", "was", "man", "fr\u00f6h\u00b7lich", "thut", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PIS", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Geht wolgerathener von staten.", "tokens": ["Geht", "wol\u00b7ge\u00b7ra\u00b7the\u00b7ner", "von", "sta\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "VVFIN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.6": {"text": "Ja ist bey einigen die Arbeit wircklich schwer;", "tokens": ["Ja", "ist", "bey", "ei\u00b7ni\u00b7gen", "die", "Ar\u00b7beit", "wir\u00b7ck\u00b7lich", "schwer", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "VAFIN", "APPR", "PIAT", "ART", "NN", "ADJD", "ADJD", "$."], "meter": "-+--+--+----+", "measure": "amphibrach.tri.plus"}, "line.7": {"text": "Gewohnheit wird sie immer mehr und mehr", "tokens": ["Ge\u00b7wohn\u00b7heit", "wird", "sie", "im\u00b7mer", "mehr", "und", "mehr"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "VAFIN", "PPER", "ADV", "ADV", "KON", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Ertr\u00e4glich machen und vermindern;", "tokens": ["Er\u00b7tr\u00e4g\u00b7lich", "ma\u00b7chen", "und", "ver\u00b7min\u00b7dern", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVINF", "KON", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Zumahlen wenn man, GOTT zur Ehr,", "tokens": ["Zu\u00b7mah\u00b7len", "wenn", "man", ",", "GoTT", "zur", "Ehr", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PIS", "$,", "NE", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Dabey ein fr\u00f6hlich Lob-Lied singet,", "tokens": ["Da\u00b7bey", "ein", "fr\u00f6h\u00b7lich", "Lob\u00b7Lied", "sin\u00b7get", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "ADJD", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Und Jhm, f\u00fcr seine Huld, ein Freuden-Opfer bringet,", "tokens": ["Und", "Jhm", ",", "f\u00fcr", "sei\u00b7ne", "Huld", ",", "ein", "Freu\u00b7den\u00b7Op\u00b7fer", "brin\u00b7get", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "$,", "APPR", "PPOSAT", "NN", "$,", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Wird alle M\u00fch\u2019und Last, verringert, bald sich lindern,", "tokens": ["Wird", "al\u00b7le", "M\u00fch'und", "Last", ",", "ver\u00b7rin\u00b7gert", ",", "bald", "sich", "lin\u00b7dern", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIAT", "NN", "NE", "$,", "VVPP", "$,", "ADV", "PRF", "VVINF", "$,"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.13": {"text": "Und wenigstens ertr\u00e4glich seyn.", "tokens": ["Und", "we\u00b7nigs\u00b7tens", "er\u00b7tr\u00e4g\u00b7lich", "seyn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Bald stellet sich darauf ein k\u00fchler Abend ein,", "tokens": ["Bald", "stel\u00b7let", "sich", "da\u00b7rauf", "ein", "k\u00fch\u00b7ler", "A\u00b7bend", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "PAV", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und unterbricht aufs neu was etwan uns beschwert,", "tokens": ["Und", "un\u00b7ter\u00b7bricht", "aufs", "neu", "was", "et\u00b7wan", "uns", "be\u00b7schwert", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPRART", "ADJD", "PWS", "ADV", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Damit wir nicht dadurch erliegen;", "tokens": ["Da\u00b7mit", "wir", "nicht", "da\u00b7durch", "er\u00b7lie\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "PAV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ja bringet uns annoch ein neu Vergn\u00fcgen,", "tokens": ["Ja", "brin\u00b7get", "uns", "an\u00b7noch", "ein", "neu", "Ver\u00b7gn\u00fc\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "VVFIN", "PPER", "ADV", "ART", "ADJD", "NN", "$,"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.5": {"text": "Wann man die Abend-Kost verzehrt.", "tokens": ["Wann", "man", "die", "A\u00b7ben\u00b7dKost", "ver\u00b7zehrt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Kaum haben wir dieselbige genossen,", "tokens": ["Kaum", "ha\u00b7ben", "wir", "die\u00b7sel\u00b7bi\u00b7ge", "ge\u00b7nos\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PDS", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "So wird uns allererst die gr\u00f6sste S\u00fcssigkeit", "tokens": ["So", "wird", "uns", "al\u00b7le\u00b7rerst", "die", "gr\u00f6ss\u00b7te", "S\u00fcs\u00b7sig\u00b7keit"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Von der gewogenen Natur geschencket,", "tokens": ["Von", "der", "ge\u00b7wo\u00b7ge\u00b7nen", "Na\u00b7tur", "ge\u00b7schen\u00b7cket", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Indem sie uns zu dieser Zeit", "tokens": ["In\u00b7dem", "sie", "uns", "zu", "die\u00b7ser", "Zeit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PRF", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "In einen sanften Schlaff aufs neu versencket.", "tokens": ["In", "ei\u00b7nen", "sanf\u00b7ten", "Schlaff", "aufs", "neu", "ver\u00b7sen\u00b7cket", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "APPRART", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Ja wenn wir etwas m\u00fcd\u2019, und uns nur niedersetzen,", "tokens": ["Ja", "wenn", "wir", "et\u00b7was", "m\u00fcd'", ",", "und", "uns", "nur", "nie\u00b7der\u00b7set\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "KOUS", "PPER", "ADV", "ADJD", "$,", "KON", "PPER", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Empfindet, durch die nachgelassnen Sehnen,", "tokens": ["Emp\u00b7fin\u00b7det", ",", "durch", "die", "nach\u00b7ge\u00b7lass\u00b7nen", "Seh\u00b7nen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Der C\u00f6rper, der sich sonst gewohnt war auszudehnen,", "tokens": ["Der", "C\u00f6r\u00b7per", ",", "der", "sich", "sonst", "ge\u00b7wohnt", "war", "aus\u00b7zu\u00b7deh\u00b7nen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PRF", "ADV", "VVPP", "VAFIN", "VVIZU", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Gedenckt man nur daran, ein ungemein Ergetzen.", "tokens": ["Ge\u00b7denckt", "man", "nur", "da\u00b7ran", ",", "ein", "un\u00b7ge\u00b7mein", "Er\u00b7get\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ADV", "PAV", "$,", "ART", "ADV", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.12": {"line.1": {"text": "Wie wird nicht M\u00fcdigkeit und Kummer,", "tokens": ["Wie", "wird", "nicht", "M\u00fc\u00b7dig\u00b7keit", "und", "Kum\u00b7mer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PTKNEG", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Durch einen sanften Schlummer", "tokens": ["Durch", "ei\u00b7nen", "sanf\u00b7ten", "Schlum\u00b7mer"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Gemindert und verjagt! so da\u00df am fr\u00fchen Morgen", "tokens": ["Ge\u00b7min\u00b7dert", "und", "ver\u00b7jagt", "!", "so", "da\u00df", "am", "fr\u00fc\u00b7hen", "Mor\u00b7gen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVPP", "KON", "VVPP", "$.", "ADV", "KOUS", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Man, meistens frey von Gram und Sorgen,", "tokens": ["Man", ",", "meis\u00b7tens", "frey", "von", "Gram", "und", "Sor\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "$,", "ADV", "ADJD", "APPR", "NE", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Und halb verj\u00fcngt, vom Schlaff erwacht,", "tokens": ["Und", "halb", "ver\u00b7j\u00fcngt", ",", "vom", "Schlaff", "er\u00b7wacht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVPP", "$,", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Sich wieder\u00fcm an seine Arbeit macht.", "tokens": ["Sich", "wie\u00b7de\u00b7r\u00fcm", "an", "sei\u00b7ne", "Ar\u00b7beit", "macht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADJD", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Auf solche Weise wird das Leben,", "tokens": ["Auf", "sol\u00b7che", "Wei\u00b7se", "wird", "das", "Le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Auch von den D\u00fcrfftigen, auf Erden zugebracht.", "tokens": ["Auch", "von", "den", "D\u00fcr\u00b7ff\u00b7ti\u00b7gen", ",", "auf", "Er\u00b7den", "zu\u00b7ge\u00b7bracht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "$,", "APPR", "NN", "VVPP", "$."], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.13": {"line.1": {"text": "Was soll ich nun von denen sagen,", "tokens": ["Was", "soll", "ich", "nun", "von", "de\u00b7nen", "sa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PPER", "ADV", "APPR", "PDS", "VVINF", "$,"], "meter": "-+-+---+-", "measure": "unknown.measure.tri"}, "line.2": {"text": "Die, da sie Geld und Gut besitzen,", "tokens": ["Die", ",", "da", "sie", "Geld", "und", "Gut", "be\u00b7sit\u00b7zen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "KOUS", "PPER", "NN", "KON", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Befreit von Arbeits-Last und Plagen,", "tokens": ["Be\u00b7freit", "von", "Ar\u00b7beits\u00b7Last", "und", "Pla\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NE", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Jhr St\u00fccklein Brodt nicht erst erschwitzen,", "tokens": ["Ihr", "St\u00fcck\u00b7lein", "Brodt", "nicht", "erst", "er\u00b7schwit\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "NN", "PTKNEG", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Und \u00fcm die Kost nicht \u00e4ngstlich wircken d\u00fcrfen?", "tokens": ["Und", "\u00fcm", "die", "Kost", "nicht", "\u00e4ngst\u00b7lich", "wir\u00b7cken", "d\u00fcr\u00b7fen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "PTKNEG", "ADJD", "VVINF", "VMINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Wie mancherley Bequemlichkeiten", "tokens": ["Wie", "man\u00b7cher\u00b7ley", "Be\u00b7quem\u00b7lich\u00b7kei\u00b7ten"], "token_info": ["word", "word", "word"], "pos": ["PWAV", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Kann sich ein Reicher zubereiten!", "tokens": ["Kann", "sich", "ein", "Rei\u00b7cher", "zu\u00b7be\u00b7rei\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PRF", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Es sind dieselben nicht zu zehlen.", "tokens": ["Es", "sind", "die\u00b7sel\u00b7ben", "nicht", "zu", "zeh\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PDS", "PTKNEG", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Von hundert tausenden nur eins zu wehlen,", "tokens": ["Von", "hun\u00b7dert", "tau\u00b7sen\u00b7den", "nur", "eins", "zu", "weh\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "CARD", "ADJA", "ADV", "PIS", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Das, wenn er es nur wol bedenckt,", "tokens": ["Das", ",", "wenn", "er", "es", "nur", "wol", "be\u00b7denckt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "$,", "KOUS", "PPER", "PPER", "ADV", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Jhm tausendfach Vergn\u00fcgen schenckt:", "tokens": ["Jhm", "tau\u00b7send\u00b7fach", "Ver\u00b7gn\u00fc\u00b7gen", "schenckt", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die so verachtete als wunderbare Kunst", "tokens": ["Die", "so", "ver\u00b7ach\u00b7te\u00b7te", "als", "wun\u00b7der\u00b7ba\u00b7re", "Kunst"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "VVFIN", "KOKOM", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Zu schreiben und zu lesen,", "tokens": ["Zu", "schrei\u00b7ben", "und", "zu", "le\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "KON", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Ist ja wol durch des Himmels Gunst", "tokens": ["Ist", "ja", "wol", "durch", "des", "Him\u00b7mels", "Gunst"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "ADV", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Zum ersten uns geschenckt gewesen.", "tokens": ["Zum", "ers\u00b7ten", "uns", "ge\u00b7schenckt", "ge\u00b7we\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "PPER", "VVPP", "VAPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Wie manchen Zeit-Vertreib von so verschiednen Sachen", "tokens": ["Wie", "man\u00b7chen", "Zeit\u00b7Ver\u00b7treib", "von", "so", "ver\u00b7schied\u00b7nen", "Sa\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PIAT", "NN", "APPR", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Kann man sich nicht mit B\u00fccher-lesen machen!", "tokens": ["Kann", "man", "sich", "nicht", "mit", "B\u00fc\u00b7cher\u00b7le\u00b7sen", "ma\u00b7chen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIS", "PRF", "PTKNEG", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Wir gehn durch sie in die vergangne Zeiten:", "tokens": ["Wir", "gehn", "durch", "sie", "in", "die", "ver\u00b7gang\u00b7ne", "Zei\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPER", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "Wir machen uns durch sie derselben gleichsam Meister,", "tokens": ["Wir", "ma\u00b7chen", "uns", "durch", "sie", "der\u00b7sel\u00b7ben", "gleich\u00b7sam", "Meis\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "PPER", "ADV", "ADJD", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Geniessen, durch Erkenntni\u00df fremder Geister,", "tokens": ["Ge\u00b7nies\u00b7sen", ",", "durch", "Er\u00b7kennt\u00b7ni\u00df", "frem\u00b7der", "Geis\u00b7ter", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "APPR", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "Gantz unbekannte S\u00fcssigkeiten.", "tokens": ["Gantz", "un\u00b7be\u00b7kann\u00b7te", "S\u00fcs\u00b7sig\u00b7kei\u00b7ten", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "Wir k\u00f6nnen uns durch sie erbauen und belehren,", "tokens": ["Wir", "k\u00f6n\u00b7nen", "uns", "durch", "sie", "er\u00b7bau\u00b7en", "und", "be\u00b7leh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "APPR", "PPER", "VVINF", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Und fast auf ungezehlte Weise", "tokens": ["Und", "fast", "auf", "un\u00b7ge\u00b7zehl\u00b7te", "Wei\u00b7se"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "Den Nutzen und die Lust vermehren.", "tokens": ["Den", "Nut\u00b7zen", "und", "die", "Lust", "ver\u00b7meh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "Noch mehr: Wie mancherley Vergn\u00fcglichkeiten", "tokens": ["Noch", "mehr", ":", "Wie", "man\u00b7cher\u00b7ley", "Ver\u00b7gn\u00fcg\u00b7lich\u00b7kei\u00b7ten"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "ADV", "$.", "PWAV", "PIAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Vermag, nebst dem Gebrauch der uns geschenckten Sinnen,", "tokens": ["Ver\u00b7mag", ",", "nebst", "dem", "Ge\u00b7brauch", "der", "uns", "ge\u00b7schenck\u00b7ten", "Sin\u00b7nen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "APPR", "ART", "NN", "ART", "PPER", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Uns ungezehlte Lust bereiten)", "tokens": ["Uns", "un\u00b7ge\u00b7zehl\u00b7te", "Lust", "be\u00b7rei\u00b7ten", ")"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die Rede nur allein uns zu gewehren!", "tokens": ["Die", "Re\u00b7de", "nur", "al\u00b7lein", "uns", "zu", "ge\u00b7weh\u00b7ren", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ADV", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "F\u00fcrwahr man mu\u00df daf\u00fcr den Sch\u00f6pfer billig ehren", "tokens": ["F\u00fcr\u00b7wahr", "man", "mu\u00df", "da\u00b7f\u00fcr", "den", "Sch\u00f6p\u00b7fer", "bil\u00b7lig", "eh\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "PIS", "VMFIN", "PAV", "ART", "NN", "ADJD", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Auf eine Art, die unsre Danckbarkeit", "tokens": ["Auf", "ei\u00b7ne", "Art", ",", "die", "uns\u00b7re", "Dan\u00b7ck\u00b7bar\u00b7keit"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "$,", "PRELS", "PPOSAT", "NN"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.7": {"text": "F\u00fcr solch ein w\u00fcrdiges Geschencke", "tokens": ["F\u00fcr", "solch", "ein", "w\u00fcr\u00b7di\u00b7ges", "Ge\u00b7schen\u00b7cke"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PIAT", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "In froher Andacht zeigt. Denn, lieber Mensch, bedencke:", "tokens": ["In", "fro\u00b7her", "An\u00b7dacht", "zeigt", ".", "Denn", ",", "lie\u00b7ber", "Mensch", ",", "be\u00b7den\u00b7cke", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "$.", "KON", "$,", "ADV", "NN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Wenn alle Menschen stumm; w\u00fcrd\u2019 unsre Lebens-Zeit", "tokens": ["Wenn", "al\u00b7le", "Men\u00b7schen", "stumm", ";", "w\u00fcrd'", "uns\u00b7re", "Le\u00b7bens\u00b7Zeit"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "PIAT", "NN", "ADJD", "$.", "VAFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Nicht elend, unser Geist nicht brach, und ohn\u2019 Vergn\u00fcgen,", "tokens": ["Nicht", "e\u00b7lend", ",", "un\u00b7ser", "Geist", "nicht", "brach", ",", "und", "ohn'", "Ver\u00b7gn\u00fc\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADJD", "$,", "PPOSAT", "NN", "PTKNEG", "VVFIN", "$,", "KON", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "In viehischer Unwissenheit,", "tokens": ["In", "vie\u00b7hi\u00b7scher", "Un\u00b7wis\u00b7sen\u00b7heit", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,"], "meter": "+-+-++-+", "measure": "unknown.measure.penta"}, "line.12": {"text": "Ja \u00e4rger fast, als viehisch, liegen?", "tokens": ["Ja", "\u00e4r\u00b7ger", "fast", ",", "als", "vie\u00b7hisch", ",", "lie\u00b7gen", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["PTKANT", "ADJD", "ADV", "$,", "KOUS", "ADJD", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "So aber hat uns GOTT in unserm Leben", "tokens": ["So", "a\u00b7ber", "hat", "uns", "GoTT", "in", "un\u00b7serm", "Le\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "VAFIN", "PPER", "NE", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.14": {"text": "Nicht nur die Red\u2019, einander zu verstehn;", "tokens": ["Nicht", "nur", "die", "Red'", ",", "ein\u00b7an\u00b7der", "zu", "ver\u00b7stehn", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "ART", "NN", "$,", "PRF", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.15": {"text": "Auch eine F\u00e4higkeit, in Schriften zu ersehn", "tokens": ["Auch", "ei\u00b7ne", "F\u00e4\u00b7hig\u00b7keit", ",", "in", "Schrif\u00b7ten", "zu", "er\u00b7sehn"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "$,", "APPR", "NN", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Was eine Seele denckt, o Wunder-Gut! gegeben.", "tokens": ["Was", "ei\u00b7ne", "See\u00b7le", "denckt", ",", "o", "Wun\u00b7der\u00b7Gut", "!", "ge\u00b7ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["PWS", "ART", "NN", "VVFIN", "$,", "FM", "NN", "$.", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.16": {"line.1": {"text": "Ach! lasst uns denn f\u00fcr so viel seltne Gaben,", "tokens": ["Ach", "!", "lasst", "uns", "denn", "f\u00fcr", "so", "viel", "selt\u00b7ne", "Ga\u00b7ben", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$.", "VVFIN", "PPER", "ADV", "APPR", "ADV", "PIAT", "ADJA", "NN", "$,"], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Die wir von GOTT allein empfangen haben,", "tokens": ["Die", "wir", "von", "GoTT", "al\u00b7lein", "emp\u00b7fan\u00b7gen", "ha\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "NE", "ADV", "VVPP", "VAINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Nicht immer unempfindlich seyn!", "tokens": ["Nicht", "im\u00b7mer", "un\u00b7emp\u00b7find\u00b7lich", "seyn", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Erwegt, wenn alles die\u00df uns fehlen", "tokens": ["Er\u00b7wegt", ",", "wenn", "al\u00b7les", "die\u00df", "uns", "feh\u00b7len"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVPP", "$,", "KOUS", "PIS", "PDS", "PPER", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Wie? oder auch entnommen werden sollte;", "tokens": ["Wie", "?", "o\u00b7der", "auch", "ent\u00b7nom\u00b7men", "wer\u00b7den", "soll\u00b7te", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$.", "KON", "ADV", "VVPP", "VAINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Wie man sodann sich finden wollte:", "tokens": ["Wie", "man", "so\u00b7dann", "sich", "fin\u00b7den", "woll\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "VMFIN", "PRF", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Und, da man dennoch leben m\u00fcst\u2019,", "tokens": ["Und", ",", "da", "man", "den\u00b7noch", "le\u00b7ben", "m\u00fcst'", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "PIS", "ADV", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "In wie viel Wieder-Sinn und Unmuth unsre Seelen", "tokens": ["In", "wie", "viel", "Wie\u00b7der\u00b7Sinn", "und", "Un\u00b7muth", "uns\u00b7re", "See\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "KOKOM", "PIAT", "NN", "KON", "NN", "PPOSAT", "NN"], "meter": "--+--+-+-+-+-", "measure": "anapaest.di.plus"}, "line.9": {"text": "Die gantze Zeit von unserm Leben,", "tokens": ["Die", "gant\u00b7ze", "Zeit", "von", "un\u00b7serm", "Le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "F\u00fcr Mangel, Plag\u2019 und Pein, unfehlbar w\u00fcrden schweben.", "tokens": ["F\u00fcr", "Man\u00b7gel", ",", "Plag'", "und", "Pein", ",", "un\u00b7fehl\u00b7bar", "w\u00fcr\u00b7den", "schwe\u00b7ben", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "KON", "NN", "$,", "ADJD", "VAFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}