{"textgrid.poem.49799": {"metadata": {"author": {"name": "Abschatz, Hans A\u00dfmann von", "birth": "N.A.", "death": "N.A."}, "title": "1L: Mit Weinen legt ich hin das erste Lebens-Jahr/", "genre": "verse", "period": "N.A.", "pub_year": 1672, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Mit Weinen legt ich hin das erste Lebens-Jahr/", "tokens": ["Mit", "Wei\u00b7nen", "legt", "ich", "hin", "das", "ers\u00b7te", "Le\u00b7bens\u00b7Jahr", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PPER", "ADV", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Doch wohl mir/ da\u00df ich da von S\u00fcnden freyer war!", "tokens": ["Doch", "wohl", "mir", "/", "da\u00df", "ich", "da", "von", "S\u00fcn\u00b7den", "frey\u00b7er", "war", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PPER", "$(", "KOUS", "PPER", "ADV", "APPR", "NN", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Sie wuchsen mit mir gro\u00df. O Gott/ dein lieber Sohn/", "tokens": ["Sie", "wuch\u00b7sen", "mit", "mir", "gro\u00df", ".", "O", "Gott", "/", "dein", "lie\u00b7ber", "Sohn", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPER", "ADJD", "$.", "NE", "NN", "$(", "PPOSAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Das s\u00fcsse Gnaden-Kind/ befreye mich davon!", "tokens": ["Das", "s\u00fcs\u00b7se", "Gna\u00b7den\u00b7Kind", "/", "be\u00b7fre\u00b7ye", "mich", "da\u00b7von", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$(", "VVFIN", "PRF", "PAV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Zwey Jahre zehlt ich nun und lernte f\u00fcr mich gehn/", "tokens": ["Zwey", "Jah\u00b7re", "zehlt", "ich", "nun", "und", "lern\u00b7te", "f\u00fcr", "mich", "gehn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "VVFIN", "PPER", "ADV", "KON", "VVFIN", "APPR", "PPER", "VVINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Doch kan ich izt noch nicht auff sicherm Fusse stehn.", "tokens": ["Doch", "kan", "ich", "izt", "noch", "nicht", "auff", "si\u00b7cherm", "Fus\u00b7se", "stehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "ADV", "ADV", "PTKNEG", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-++--+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Herr/ la\u00df mich deine Hand als wie die Jugend leiten/", "tokens": ["Herr", "/", "la\u00df", "mich", "dei\u00b7ne", "Hand", "als", "wie", "die", "Ju\u00b7gend", "lei\u00b7ten", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "VVIMP", "PPER", "PPOSAT", "NN", "KOUS", "KOKOM", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So bleibt mein Gang gewi\u00df den Himmel zu beschreiten!", "tokens": ["So", "bleibt", "mein", "Gang", "ge\u00b7wi\u00df", "den", "Him\u00b7mel", "zu", "be\u00b7schrei\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "ADV", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Ich tratt ins dritte Jahr/ und brauchte meinen Mund/", "tokens": ["Ich", "tratt", "ins", "drit\u00b7te", "Jahr", "/", "und", "brauch\u00b7te", "mei\u00b7nen", "Mund", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "ADJA", "NN", "$(", "KON", "VVFIN", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wiewohl ich noch den Brauch der Worte schlecht verstund.", "tokens": ["Wie\u00b7wohl", "ich", "noch", "den", "Brauch", "der", "Wor\u00b7te", "schlecht", "ver\u00b7stund", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ART", "NN", "ART", "NN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wie manch vergeblich Wort schleicht noch wohl t\u00e4glich ein.", "tokens": ["Wie", "manch", "ver\u00b7geb\u00b7lich", "Wort", "schleicht", "noch", "wohl", "t\u00e4g\u00b7lich", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIAT", "ADJD", "NN", "VVFIN", "ADV", "ADV", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Gott/ la\u00df die Rechenschafft daf\u00fcr erloschen seyn!", "tokens": ["Gott", "/", "la\u00df", "die", "Re\u00b7chen\u00b7schafft", "da\u00b7f\u00fcr", "er\u00b7lo\u00b7schen", "seyn", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "VVIMP", "ART", "NN", "PAV", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Als ich das vierdte Jahr des Lebens angeschaut/", "tokens": ["Als", "ich", "das", "vierd\u00b7te", "Jahr", "des", "Le\u00b7bens", "an\u00b7ge\u00b7schaut", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Bedeckte Brand und Wust der Blattern meine Haut/", "tokens": ["Be\u00b7deck\u00b7te", "Brand", "und", "Wust", "der", "Blat\u00b7tern", "mei\u00b7ne", "Haut", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "KON", "NN", "ART", "NN", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Viel Blattern seither dem benarben mein Gewissen:", "tokens": ["Viel", "Blat\u00b7tern", "sei\u00b7ther", "dem", "be\u00b7nar\u00b7ben", "mein", "Ge\u00b7wis\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "APPR", "ART", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ach H\u00f6chster sey du sie zu heilen selbst beflissen.", "tokens": ["Ach", "H\u00f6chs\u00b7ter", "sey", "du", "sie", "zu", "hei\u00b7len", "selbst", "be\u00b7flis\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "NN", "VAFIN", "PPER", "PPER", "PTKZU", "VVINF", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Ich muste Vaters Treu im f\u00fcnfften Jahr entrathen/", "tokens": ["Ich", "mus\u00b7te", "Va\u00b7ters", "Treu", "im", "f\u00fcnff\u00b7ten", "Jahr", "ent\u00b7ra\u00b7then", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "NN", "APPRART", "ADJA", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Sah Hau\u00df und Hoff/ und mich bey nah/ im Feuer braten.", "tokens": ["Sah", "Hau\u00df", "und", "Hoff", "/", "und", "mich", "bey", "nah", "/", "im", "Feu\u00b7er", "bra\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "KON", "VVFIN", "$(", "KON", "PRF", "APPR", "ADJD", "$(", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Gott trat an Vaters Stell/ und seine Wunder-Treu/", "tokens": ["Gott", "trat", "an", "Va\u00b7ters", "Stell", "/", "und", "sei\u00b7ne", "Wun\u00b7der\u00b7Treu", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "APPR", "NN", "NN", "$(", "KON", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ob ich ein freches Kind/ ist mir noch t\u00e4glich neu!", "tokens": ["Ob", "ich", "ein", "fre\u00b7ches", "Kind", "/", "ist", "mir", "noch", "t\u00e4g\u00b7lich", "neu", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "$(", "VAFIN", "PPER", "ADV", "ADJD", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Ich fieng mein A/ B/ Ab/ mit Gott/ sechsj\u00e4hrig an/", "tokens": ["Ich", "fi\u00b7eng", "mein", "A", "/", "B", "/", "Ab", "/", "mit", "Gott", "/", "sechs\u00b7j\u00e4h\u00b7rig", "an", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NE", "$(", "XY", "$(", "APPR", "$(", "APPR", "NN", "$(", "ADJD", "PTKVZ", "$("], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}, "line.2": {"text": "Und baut auff diesen Grund was ich noch heute kan:", "tokens": ["Und", "baut", "auff", "die\u00b7sen", "Grund", "was", "ich", "noch", "heu\u00b7te", "kan", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PDAT", "NN", "PWS", "PPER", "ADV", "ADV", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Doch bin ich erst alsdenn gelehrt und klug zu nennen/", "tokens": ["Doch", "bin", "ich", "erst", "als\u00b7denn", "ge\u00b7lehrt", "und", "klug", "zu", "nen\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ADV", "ADV", "VVPP", "KON", "ADJD", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wenn ich das A und O im Himmel werde kennen.", "tokens": ["Wenn", "ich", "das", "A", "und", "O", "im", "Him\u00b7mel", "wer\u00b7de", "ken\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NE", "KON", "NE", "APPRART", "NN", "VAFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Ich lernte nun den Kiel der leichten Feder f\u00fchren/", "tokens": ["Ich", "lern\u00b7te", "nun", "den", "Kiel", "der", "leich\u00b7ten", "Fe\u00b7der", "f\u00fch\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN", "ART", "ADJA", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Lie\u00df gleiche Fl\u00fcchtigkeit in meinen Sinnen sp\u00fcren.", "tokens": ["Lie\u00df", "glei\u00b7che", "Fl\u00fcch\u00b7tig\u00b7keit", "in", "mei\u00b7nen", "Sin\u00b7nen", "sp\u00fc\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wenn ich/ wie Nero sich gew\u00fcnscht/ niemahls geschrieben/", "tokens": ["Wenn", "ich", "/", "wie", "Ne\u00b7ro", "sich", "ge\u00b7w\u00fcnscht", "/", "nie\u00b7mahls", "ge\u00b7schrie\u00b7ben", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$(", "KOKOM", "NE", "PRF", "VVPP", "$(", "ADV", "VVPP", "$("], "meter": "-+-+-+-++--+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "So w\u00e4re manches B\u00f6\u00df/ auch manches Gutte/ blieben.", "tokens": ["So", "w\u00e4\u00b7re", "man\u00b7ches", "B\u00f6\u00df", "/", "auch", "man\u00b7ches", "Gut\u00b7te", "/", "blie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "VAFIN", "PIAT", "NN", "$(", "ADV", "PIAT", "NN", "$(", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "Ich gieng ins achte Jahr und schritte zum Latein/", "tokens": ["Ich", "gieng", "ins", "ach\u00b7te", "Jahr", "und", "schrit\u00b7te", "zum", "La\u00b7tein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "ADJA", "NN", "KON", "VVFIN", "APPRART", "NN", "$("], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Man fl\u00f6\u00dfte mir den Grund des wahren Glaubens ein;", "tokens": ["Man", "fl\u00f6\u00df\u00b7te", "mir", "den", "Grund", "des", "wah\u00b7ren", "Glau\u00b7bens", "ein", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "ART", "NN", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Di\u00df ist die beste Kunst/ wer Gott und sich wohl kennt/", "tokens": ["Di\u00df", "ist", "die", "bes\u00b7te", "Kunst", "/", "wer", "Gott", "und", "sich", "wohl", "kennt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "ADJA", "NN", "$(", "PWS", "NN", "KON", "PRF", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wohl dem/ der seine Zeit auff di\u00df am meisten wendt!", "tokens": ["Wohl", "dem", "/", "der", "sei\u00b7ne", "Zeit", "auff", "di\u00df", "am", "meis\u00b7ten", "wendt", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "$(", "ART", "PPOSAT", "NN", "APPR", "PDS", "PTKA", "PIS", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Neun Jahre r\u00fcckten an/ da\u00df ich hierbey nahm zu", "tokens": ["Neun", "Jah\u00b7re", "r\u00fcck\u00b7ten", "an", "/", "da\u00df", "ich", "hier\u00b7bey", "nahm", "zu"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["CARD", "NN", "VVFIN", "PTKVZ", "$(", "KOUS", "PPER", "ADV", "VVFIN", "APPR"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "An Alter und Verstand/ o Gott/ verliehest du:", "tokens": ["An", "Al\u00b7ter", "und", "Ver\u00b7stand", "/", "o", "Gott", "/", "ver\u00b7lie\u00b7hest", "du", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$(", "FM", "NN", "$(", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Gieb/ da\u00df ich nicht bey dir mit Neunen geh vorbey/", "tokens": ["Gieb", "/", "da\u00df", "ich", "nicht", "bey", "dir", "mit", "Neu\u00b7nen", "geh", "vor\u00b7bey", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "$(", "KOUS", "PPER", "PTKNEG", "APPR", "PPER", "APPR", "NN", "VVFIN", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Vielmehr in Lob und Danck der Zehnde Reine sey.", "tokens": ["Viel\u00b7mehr", "in", "Lob", "und", "Danck", "der", "Zehn\u00b7de", "Rei\u00b7ne", "sey", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "KON", "APPR", "ART", "ADJA", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.10": {"line.1": {"text": "Der erste Krei\u00df der Zeit und Alter trat zur\u00fccke/", "tokens": ["Der", "ers\u00b7te", "Krei\u00df", "der", "Zeit", "und", "Al\u00b7ter", "trat", "zu\u00b7r\u00fc\u00b7cke", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "KON", "NN", "VVFIN", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ich rei\u00df das schwache Paar der Kinder-Schuh in St\u00fccke.", "tokens": ["Ich", "rei\u00df", "das", "schwa\u00b7che", "Paar", "der", "Kin\u00b7der\u00b7Schuh", "in", "St\u00fc\u00b7cke", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "ART", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Doch wei\u00df ich/ da\u00df ich selbst durch Beyspiel zeigen kan/", "tokens": ["Doch", "wei\u00df", "ich", "/", "da\u00df", "ich", "selbst", "durch", "Bey\u00b7spiel", "zei\u00b7gen", "kan", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "$(", "KOUS", "PPER", "ADV", "APPR", "NN", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Dem Knaben klebe noch manch Thorheits-Fehler an!", "tokens": ["Dem", "Kna\u00b7ben", "kle\u00b7be", "noch", "manch", "Thor\u00b7heits\u00b7Feh\u00b7ler", "an", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "PIAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.11": {"line.1": {"text": "Es wird der zehnden Zahl noch eines beygesezt/", "tokens": ["Es", "wird", "der", "zehn\u00b7den", "Zahl", "noch", "ei\u00b7nes", "bey\u00b7ge\u00b7sezt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "ADV", "PIS", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ach/ da\u00df man doch die Zeit nicht recht nach W\u00fcrden sch\u00e4zt/", "tokens": ["Ach", "/", "da\u00df", "man", "doch", "die", "Zeit", "nicht", "recht", "nach", "W\u00fcr\u00b7den", "sch\u00e4zt", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$(", "KOUS", "PIS", "ADV", "ART", "NN", "PTKNEG", "ADJD", "APPR", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Herr/ geh ich um eilff Uhr in deinen Berg erst ein/", "tokens": ["Herr", "/", "geh", "ich", "um", "eilff", "Uhr", "in", "dei\u00b7nen", "Berg", "erst", "ein", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "VVFIN", "PPER", "APPR", "CARD", "NN", "APPR", "PPOSAT", "NN", "ADV", "ART", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "La\u00df mich vom Gnaden-Lohn nicht ausgeschlossen seyn.", "tokens": ["La\u00df", "mich", "vom", "Gna\u00b7den\u00b7Lohn", "nicht", "aus\u00b7ge\u00b7schlos\u00b7sen", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "APPRART", "NN", "PTKNEG", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.12": {"line.1": {"text": "Als Jesus war zw\u00f6lff Jahr/ so sah ihn Solyms Stadt/", "tokens": ["Als", "Je\u00b7sus", "war", "zw\u00f6lff", "Jahr", "/", "so", "sah", "ihn", "So\u00b7lyms", "Stadt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "VAFIN", "CARD", "NN", "$(", "ADV", "VVFIN", "PPER", "PIAT", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wie er das Gottes-Hau\u00df und Heiligthum betratt/", "tokens": ["Wie", "er", "das", "Got\u00b7tes\u00b7Hau\u00df", "und", "Hei\u00b7lig\u00b7thum", "be\u00b7tratt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "NN", "KON", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ich nahm um diese Zeit das Brod des Lebens ein/", "tokens": ["Ich", "nahm", "um", "die\u00b7se", "Zeit", "das", "Brod", "des", "Le\u00b7bens", "ein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PDAT", "NN", "ART", "NN", "ART", "NN", "ART", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Gott la\u00df mir solche Kost zum Himmel angedeyhn.", "tokens": ["Gott", "la\u00df", "mir", "sol\u00b7che", "Kost", "zum", "Him\u00b7mel", "an\u00b7ge\u00b7deyhn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVIMP", "PPER", "PIAT", "NN", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.13": {"line.1": {"text": "Ein Monat war hinweg von zw\u00f6lff zu dreyzehn Jahren/", "tokens": ["Ein", "Mo\u00b7nat", "war", "hin\u00b7weg", "von", "zw\u00f6lff", "zu", "drey\u00b7zehn", "Jah\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "APPR", "CARD", "APPR", "CARD", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der treuen Mutter Tod mu\u00df ich best\u00fcrzt erfahren/", "tokens": ["Der", "treu\u00b7en", "Mut\u00b7ter", "Tod", "mu\u00df", "ich", "be\u00b7st\u00fcrzt", "er\u00b7fah\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "VMFIN", "PPER", "ADJD", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ihr Beten war mein Schatz/ ihr Segen war mein Theil/", "tokens": ["Ihr", "Be\u00b7ten", "war", "mein", "Schatz", "/", "ihr", "Se\u00b7gen", "war", "mein", "Theil", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "PPOSAT", "NN", "$(", "PPOSAT", "NN", "VAFIN", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ich w\u00fcnsche mir/ was sie geneust/ der Seelen Heyl.", "tokens": ["Ich", "w\u00fcn\u00b7sche", "mir", "/", "was", "sie", "ge\u00b7neust", "/", "der", "See\u00b7len", "Heyl", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$(", "PWS", "PPER", "VVPP", "$(", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.14": {"line.1": {"text": "Wie gehn die Monden hin mit so geschwinder Flucht/", "tokens": ["Wie", "gehn", "die", "Mon\u00b7den", "hin", "mit", "so", "ge\u00b7schwin\u00b7der", "Flucht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "ART", "NN", "ADV", "APPR", "ADV", "ADJA", "NN", "$("], "meter": "-+-+-+---+-+", "measure": "unknown.measure.penta"}, "line.2": {"text": "Mein Knaben-Alter kam aus stiller Kinderzucht.", "tokens": ["Mein", "Kna\u00b7ben\u00b7Al\u00b7ter", "kam", "aus", "stil\u00b7ler", "Kin\u00b7der\u00b7zucht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der Jugend zartes Wachs nimmt Gutt und B\u00f6ses an/", "tokens": ["Der", "Ju\u00b7gend", "zar\u00b7tes", "Wachs", "nimmt", "Gutt", "und", "B\u00f6\u00b7ses", "an", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "VVFIN", "ADJD", "KON", "NN", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ach h\u00e4tt ich dieses nicht/ und jenes nur gethan!", "tokens": ["Ach", "h\u00e4tt", "ich", "die\u00b7ses", "nicht", "/", "und", "je\u00b7nes", "nur", "ge\u00b7than", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "VAFIN", "PPER", "PDS", "PTKNEG", "$(", "KON", "PDS", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.15": {"line.1": {"text": "Zwey Dinge sind/ die sich gar selten reimen k\u00fcnnen/", "tokens": ["Zwey", "Din\u00b7ge", "sind", "/", "die", "sich", "gar", "sel\u00b7ten", "rei\u00b7men", "k\u00fcn\u00b7nen", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "VAFIN", "$(", "PRELS", "PRF", "ADV", "ADJD", "VVINF", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die strengen Zehn Gebot und Freyheit der f\u00fcnff Sinnen/", "tokens": ["Die", "stren\u00b7gen", "Zehn", "Ge\u00b7bot", "und", "Frey\u00b7heit", "der", "f\u00fcnff", "Sin\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "CARD", "NN", "KON", "NN", "ART", "CARD", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Da\u00df bey der Jugend di\u00df wie bey dem Alter war/", "tokens": ["Da\u00df", "bey", "der", "Ju\u00b7gend", "di\u00df", "wie", "bey", "dem", "Al\u00b7ter", "war", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "ART", "NN", "PDS", "KOKOM", "APPR", "ART", "NN", "VAFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Lehrt mich izt f\u00fcnffmahl zehn/ vor zehnd und f\u00fcnfftes Jahr.", "tokens": ["Lehrt", "mich", "izt", "f\u00fcnff\u00b7mahl", "zehn", "/", "vor", "zehnd", "und", "f\u00fcnff\u00b7tes", "Jahr", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "CARD", "$(", "APPR", "CARD", "KON", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.16": {"line.1": {"text": "Ich rechne meine Zeit mit acht und aber achten/", "tokens": ["Ich", "rech\u00b7ne", "mei\u00b7ne", "Zeit", "mit", "acht", "und", "a\u00b7ber", "ach\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "APPR", "CARD", "KON", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Mein Sinn und Sorgen ist nach Wissenschafften trachten.", "tokens": ["Mein", "Sinn", "und", "Sor\u00b7gen", "ist", "nach", "Wis\u00b7sen\u00b7schaff\u00b7ten", "trach\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "NN", "VAFIN", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wohl dem/ der so bedacht die Jugend angewehrt/", "tokens": ["Wohl", "dem", "/", "der", "so", "be\u00b7dacht", "die", "Ju\u00b7gend", "an\u00b7ge\u00b7wehrt", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "$(", "ART", "ADV", "ADJD", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Da\u00df ihn des Richters Spruch nicht in die Acht erkl\u00e4rt.", "tokens": ["Da\u00df", "ihn", "des", "Rich\u00b7ters", "Spruch", "nicht", "in", "die", "Acht", "er\u00b7kl\u00e4rt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "NN", "PTKNEG", "APPR", "ART", "CARD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.17": {"line.1": {"text": "Die Jahre lauffen fort/ nach zehnen zehl ich sieben/", "tokens": ["Die", "Jah\u00b7re", "lauf\u00b7fen", "fort", "/", "nach", "zeh\u00b7nen", "zehl", "ich", "sie\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "$(", "APPR", "ADJA", "NN", "PPER", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Als ich zum andern mahl bin Vater-W\u00e4ise blieben.", "tokens": ["Als", "ich", "zum", "an\u00b7dern", "mahl", "bin", "Va\u00b7ter\u00b7W\u00e4i\u00b7se", "blie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPRART", "ADJA", "ADV", "VAFIN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Mein Pflege-Vater stirbt/ doch nimmt sich meiner an", "tokens": ["Mein", "Pfle\u00b7ge\u00b7Va\u00b7ter", "stirbt", "/", "doch", "nimmt", "sich", "mei\u00b7ner", "an"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VVFIN", "$(", "ADV", "VVFIN", "PRF", "PPOSAT", "APPR"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und unterh\u00e4lt mich noch der nimmer sterben kan.", "tokens": ["Und", "un\u00b7ter\u00b7h\u00e4lt", "mich", "noch", "der", "nim\u00b7mer", "ster\u00b7ben", "kan", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "ART", "ADV", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.18": {"line.1": {"text": "Das dreymahl sechste Jahr weicht meistens hinter sich/", "tokens": ["Das", "drey\u00b7mahl", "sechs\u00b7te", "Jahr", "weicht", "meis\u00b7tens", "hin\u00b7ter", "sich", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "ADJA", "NN", "VVFIN", "ADV", "APPR", "PRF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Als ich Piastens Stadt sechsj\u00e4hrger Gast entwich/", "tokens": ["Als", "ich", "Pi\u00b7as\u00b7tens", "Stadt", "sechs\u00b7j\u00e4hr\u00b7ger", "Gast", "ent\u00b7wich", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NN", "NN", "ADJA", "NN", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Hab ich an Witz und Kunst alldar was zugenommen/", "tokens": ["Hab", "ich", "an", "Witz", "und", "Kunst", "all\u00b7dar", "was", "zu\u00b7ge\u00b7nom\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "APPR", "NN", "KON", "NN", "ADV", "PIS", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So ist die Frucht darvon zu ihrer Wurtzel kommen.", "tokens": ["So", "ist", "die", "Frucht", "dar\u00b7von", "zu", "ih\u00b7rer", "Wurt\u00b7zel", "kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "PAV", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.19": {"line.1": {"text": "Nun schwing' ich in die Welt/ als Icarus/ die Fl\u00fcgel/", "tokens": ["Nun", "schwing'", "ich", "in", "die", "Welt", "/", "als", "I\u00b7ca\u00b7rus", "/", "die", "Fl\u00fc\u00b7gel", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "$(", "KOUS", "NE", "$(", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der Jugend Unbedacht regirt die freyen Z\u00fcgel/", "tokens": ["Der", "Ju\u00b7gend", "Un\u00b7be\u00b7dacht", "re\u00b7girt", "die", "frey\u00b7en", "Z\u00fc\u00b7gel", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Doch ists zuweilen gutt/ wenn solche kurtz geschnitten/", "tokens": ["Doch", "ists", "zu\u00b7wei\u00b7len", "gutt", "/", "wenn", "sol\u00b7che", "kurtz", "ge\u00b7schnit\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "ADJD", "$(", "KOUS", "PIS", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So wird der Tugend-Weg viel minder \u00fcberschritten.", "tokens": ["So", "wird", "der", "Tu\u00b7gen\u00b7dWeg", "viel", "min\u00b7der", "\u00fc\u00b7bersc\u00b7hrit\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "ADV", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.20": {"line.1": {"text": "Mich hegt ins andre Jahr der Musen Silber-Stadt/", "tokens": ["Mich", "hegt", "ins", "and\u00b7re", "Jahr", "der", "Mu\u00b7sen", "Sil\u00b7ber\u00b7Stadt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "ADJA", "NN", "ART", "NN", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die izt der strenge Mars mit Stahl gefesselt hat/", "tokens": ["Die", "izt", "der", "stren\u00b7ge", "Mars", "mit", "Stahl", "ge\u00b7fes\u00b7selt", "hat", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ART", "ADJA", "NN", "APPR", "NN", "VVPP", "VAFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Di\u00df und mein eigen Bild lehrt mich nunmehr erkennen/", "tokens": ["Di\u00df", "und", "mein", "ei\u00b7gen", "Bild", "lehrt", "mich", "nun\u00b7mehr", "er\u00b7ken\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "KON", "PPOSAT", "ADJA", "NN", "VVFIN", "PPER", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Da\u00df nichts auff dieser Welt best\u00e4ndig sey zu nennen.", "tokens": ["Da\u00df", "nichts", "auff", "die\u00b7ser", "Welt", "be\u00b7st\u00e4n\u00b7dig", "sey", "zu", "nen\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "APPR", "PDAT", "NN", "ADJD", "VAFIN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.21": {"line.1": {"text": "Der damahls freye Rhein schickt mich auff engen Nachen/", "tokens": ["Der", "da\u00b7mahls", "frey\u00b7e", "Rhein", "schickt", "mich", "auff", "en\u00b7gen", "Na\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJA", "NE", "VVFIN", "PPER", "APPR", "ADJA", "NN", "$("], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Wo f\u00fcr des Landes Heyl gepichte Schl\u00f6sser wachen:", "tokens": ["Wo", "f\u00fcr", "des", "Lan\u00b7des", "Heyl", "ge\u00b7pich\u00b7te", "Schl\u00f6s\u00b7ser", "wa\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPR", "ART", "NN", "NN", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "F\u00fchrt mich ein grosses Schiff/ tr\u00e4gt mich ein kleiner Kahn/", "tokens": ["F\u00fchrt", "mich", "ein", "gros\u00b7ses", "Schiff", "/", "tr\u00e4gt", "mich", "ein", "klei\u00b7ner", "Kahn", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "NN", "$(", "VVFIN", "PPER", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Es gilt mir beydes gleich/ l\u00e4nd' ich nur sicher an.", "tokens": ["Es", "gilt", "mir", "bey\u00b7des", "gleich", "/", "l\u00e4nd'", "ich", "nur", "si\u00b7cher", "an", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PIS", "ADV", "$(", "VVFIN", "PPER", "ADV", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.22": {"line.1": {"text": "Das freye Niederland/ durchs Land der engen Hosen/", "tokens": ["Das", "frey\u00b7e", "Nie\u00b7der\u00b7land", "/", "durchs", "Land", "der", "en\u00b7gen", "Ho\u00b7sen", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$(", "APPRART", "NN", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Gew\u00e4hrt mich in das Reich der herrschenden Frantzosen.", "tokens": ["Ge\u00b7w\u00e4hrt", "mich", "in", "das", "Reich", "der", "herr\u00b7schen\u00b7den", "Frant\u00b7zo\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "APPR", "ART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Von dar ich kurtze Zeit den Welschen sprechen mu\u00df/", "tokens": ["Von", "dar", "ich", "kurt\u00b7ze", "Zeit", "den", "Wel\u00b7schen", "spre\u00b7chen", "mu\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PTKVZ", "PPER", "ADJA", "NN", "ART", "NN", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Viel sehn/ und \u00fcber nichts sich wundern/ ist mein Schlu\u00df.", "tokens": ["Viel", "sehn", "/", "und", "\u00fc\u00b7ber", "nichts", "sich", "wun\u00b7dern", "/", "ist", "mein", "Schlu\u00df", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVINF", "$(", "KON", "APPR", "PIS", "PRF", "VVINF", "$(", "VAFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.23": {"line.1": {"text": "Ich lange wieder heim nach dreyen Reise-Jahren/", "tokens": ["Ich", "lan\u00b7ge", "wie\u00b7der", "heim", "nach", "drey\u00b7en", "Rei\u00b7se\u00b7Jah\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADV", "PTKVZ", "APPR", "CARD", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und soll nun legen aus/ was ich gebracht an Wahren/", "tokens": ["Und", "soll", "nun", "le\u00b7gen", "aus", "/", "was", "ich", "ge\u00b7bracht", "an", "Wah\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ADV", "VVFIN", "PTKVZ", "$(", "PWS", "PPER", "VVPP", "APPR", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Viel Eiteles gesehn/ viel Th\u00f6richtes gedacht/", "tokens": ["Viel", "Ei\u00b7te\u00b7les", "ge\u00b7sehn", "/", "viel", "Th\u00f6\u00b7rich\u00b7tes", "ge\u00b7dacht", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVPP", "$(", "PIAT", "NN", "VVPP", "$("], "meter": "-+---+--+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Den Leib und Geist bem\u00fcht/ den Beutel leer gemacht.", "tokens": ["Den", "Leib", "und", "Geist", "be\u00b7m\u00fcht", "/", "den", "Beu\u00b7tel", "leer", "ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "VVPP", "$(", "ART", "NN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.24": {"line.1": {"text": "Es soll die Lebens-Art izt gantz ge\u00e4ndert seyn/", "tokens": ["Es", "soll", "die", "Le\u00b7bens\u00b7Art", "izt", "gantz", "ge\u00b7\u00e4n\u00b7dert", "seyn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "NN", "ADV", "ADV", "VVPP", "VAINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Gott will mich in das Joch der Wirthschafft spannen ein/", "tokens": ["Gott", "will", "mich", "in", "das", "Joch", "der", "Wirth\u00b7schafft", "span\u00b7nen", "ein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "PRF", "APPR", "ART", "NN", "ART", "NN", "VVFIN", "ART", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Was meinen Eltern hat entzogen Krieg und Brand/", "tokens": ["Was", "mei\u00b7nen", "El\u00b7tern", "hat", "ent\u00b7zo\u00b7gen", "Krieg", "und", "Brand", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPOSAT", "NN", "VAFIN", "VVPP", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Gew\u00e4hrt mir seine Gunst durch fremde Mutter-Hand.", "tokens": ["Ge\u00b7w\u00e4hrt", "mir", "sei\u00b7ne", "Gunst", "durch", "frem\u00b7de", "Mut\u00b7ter\u00b7Hand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPOSAT", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.25": {"line.1": {"text": "Ich habe nun zu Freud und Leyd Gesellschafft funden/", "tokens": ["Ich", "ha\u00b7be", "nun", "zu", "Freud", "und", "Leyd", "Ge\u00b7sell\u00b7schafft", "fun\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "APPR", "NN", "KON", "NN", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und leb' aus Gottes Rath mit treuer Hand verbunden.", "tokens": ["Und", "leb'", "aus", "Got\u00b7tes", "Rath", "mit", "treu\u00b7er", "Hand", "ver\u00b7bun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "NN", "NN", "APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Erhalt die reine Glutt/ Gott/ die du angebrennt/", "tokens": ["Er\u00b7halt", "die", "rei\u00b7ne", "Glutt", "/", "Gott", "/", "die", "du", "an\u00b7ge\u00b7brennt", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "$(", "NN", "$(", "PRELS", "PPER", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und la\u00df uns dort/ wie hier verbleiben ungetrennt.", "tokens": ["Und", "la\u00df", "uns", "dort", "/", "wie", "hier", "ver\u00b7blei\u00b7ben", "un\u00b7ge\u00b7trennt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVIMP", "PPER", "ADV", "$(", "KOKOM", "ADV", "VVINF", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.26": {"line.1": {"text": "Zwey Br\u00fcder werden mir nicht hochbejahrt zu Leichen/", "tokens": ["Zwey", "Br\u00fc\u00b7der", "wer\u00b7den", "mir", "nicht", "hoch\u00b7be\u00b7jahrt", "zu", "Lei\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "VAFIN", "PPER", "PTKNEG", "ADJD", "APPR", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Mir selber mehren sich die Ungesundheits-Zeichen:", "tokens": ["Mir", "sel\u00b7ber", "meh\u00b7ren", "sich", "die", "Un\u00b7ge\u00b7sund\u00b7heits\u00b7Zei\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "PRF", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "So wechseln Freud und Leyd bey gutt und b\u00f6sen Tagen/", "tokens": ["So", "wech\u00b7seln", "Freud", "und", "Leyd", "bey", "gutt", "und", "b\u00f6\u00b7sen", "Ta\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NN", "KON", "NN", "APPR", "ADJD", "KON", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Doch hilfft auch Gottes Gunst viel Creutze selber tragen.", "tokens": ["Doch", "hilfft", "auch", "Got\u00b7tes", "Gunst", "viel", "Creut\u00b7ze", "sel\u00b7ber", "tra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "NN", "NN", "PIAT", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.27": {"line.1": {"text": "Wie der/ der ob uns wacht/ f\u00fcr Schaden kan bewahren/", "tokens": ["Wie", "der", "/", "der", "ob", "uns", "wacht", "/", "f\u00fcr", "Scha\u00b7den", "kan", "be\u00b7wah\u00b7ren", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "$(", "ART", "KOUS", "PPER", "VVFIN", "$(", "APPR", "NN", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Hab ich di\u00df Jahr drey mahl in naher Glutt erfahren.", "tokens": ["Hab", "ich", "di\u00df", "Jahr", "drey", "mahl", "in", "na\u00b7her", "Glutt", "er\u00b7fah\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PDS", "NN", "CARD", "ADV", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Du H\u00fctter Israels bleib unser Schutz und Schild/", "tokens": ["Du", "H\u00fct\u00b7ter", "Is\u00b7raels", "bleib", "un\u00b7ser", "Schutz", "und", "Schild", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "NE", "VVFIN", "PPOSAT", "NN", "KON", "NN", "$("], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Der bleibet unverlezt/ den du bedecken wilt.", "tokens": ["Der", "blei\u00b7bet", "un\u00b7ver\u00b7lezt", "/", "den", "du", "be\u00b7de\u00b7cken", "wilt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADJD", "$(", "ART", "PPER", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.28": {"line.1": {"text": "Die Kinder keuscher Eh' sind wohl der Augen Lust/", "tokens": ["Die", "Kin\u00b7der", "keu\u00b7scher", "Eh'", "sind", "wohl", "der", "Au\u00b7gen", "Lust", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "VAFIN", "ADV", "ART", "NN", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Doch wird auch offt um sie bekr\u00e4nckt der Eltern Brust/", "tokens": ["Doch", "wird", "auch", "offt", "um", "sie", "be\u00b7kr\u00e4nckt", "der", "El\u00b7tern", "Brust", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "ADV", "APPR", "PPER", "VVFIN", "ART", "NN", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ich stell in Gottes Hand ihr Leben und ihr Sterben/", "tokens": ["Ich", "stell", "in", "Got\u00b7tes", "Hand", "ihr", "Le\u00b7ben", "und", "ihr", "Ster\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "APPR", "NN", "NN", "PPOSAT", "NN", "KON", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Nur da\u00df sie allesamt nebst uns den Himmel erben.", "tokens": ["Nur", "da\u00df", "sie", "al\u00b7le\u00b7samt", "nebst", "uns", "den", "Him\u00b7mel", "er\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PPER", "ADJD", "APPR", "PPER", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.29": {"line.1": {"text": "Das Feld bringt sparsam Frucht/ wiewohl wir m\u00fchsam s\u00e4en/", "tokens": ["Das", "Feld", "bringt", "spar\u00b7sam", "Frucht", "/", "wie\u00b7wohl", "wir", "m\u00fch\u00b7sam", "s\u00e4\u00b7en", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJD", "NN", "$(", "KOUS", "PPER", "ADJD", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und zeigt den Fluch/ der drauff nach erster Schuld geschehen:", "tokens": ["Und", "zeigt", "den", "Fluch", "/", "der", "drauff", "nach", "ers\u00b7ter", "Schuld", "ge\u00b7sche\u00b7hen", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "$(", "ART", "PAV", "APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wir streun auch/ leider! selbst viel S\u00fcnden-Disteln aus/", "tokens": ["Wir", "streun", "auch", "/", "lei\u00b7der", "!", "selbst", "viel", "S\u00fcn\u00b7den\u00b7Dis\u00b7teln", "aus", "/"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$(", "ADV", "$.", "ADV", "PIAT", "NN", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Was Wunder/ wenn uns denn der Mangel k\u00f6mmt ins Hau\u00df.", "tokens": ["Was", "Wun\u00b7der", "/", "wenn", "uns", "denn", "der", "Man\u00b7gel", "k\u00f6mmt", "ins", "Hau\u00df", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "$(", "KOUS", "PPER", "ADV", "ART", "NN", "VVFIN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.30": {"line.1": {"text": "Piastens Enckel stirbt/ dem wir gehuldigt haben/", "tokens": ["Pi\u00b7as\u00b7tens", "En\u00b7ckel", "stirbt", "/", "dem", "wir", "ge\u00b7hul\u00b7digt", "ha\u00b7ben", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "VVFIN", "$(", "PRELS", "PPER", "VVPP", "VAINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die Freyheit Schlesiens wird neben ihm begraben/", "tokens": ["Die", "Frey\u00b7heit", "Schle\u00b7si\u00b7ens", "wird", "ne\u00b7ben", "ihm", "be\u00b7gra\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VAFIN", "APPR", "PPER", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ob seinem Tod erseuffzt manch treuer Unterthan/", "tokens": ["Ob", "sei\u00b7nem", "Tod", "er\u00b7seuffzt", "manch", "treu\u00b7er", "Un\u00b7ter\u00b7than", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "VVFIN", "PIAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der/ was noch k\u00fcnfftig sey/ von weitem sehen kan.", "tokens": ["Der", "/", "was", "noch", "k\u00fcnff\u00b7tig", "sey", "/", "von", "wei\u00b7tem", "se\u00b7hen", "kan", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "$(", "PWS", "ADV", "ADJD", "VAFIN", "$(", "APPR", "PIS", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.31": {"line.1": {"text": "Es heist mich Gottes Ruff aus meinem Winckel gehn/", "tokens": ["Es", "heist", "mich", "Got\u00b7tes", "Ruff", "aus", "mei\u00b7nem", "Win\u00b7ckel", "gehn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "NN", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ich soll mich f\u00fcr das Land zu sorgen unterstehn/", "tokens": ["Ich", "soll", "mich", "f\u00fcr", "das", "Land", "zu", "sor\u00b7gen", "un\u00b7ter\u00b7stehn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PRF", "APPR", "ART", "NN", "APPR", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wie wenig richt offt aus der allerbeste Flei\u00df/", "tokens": ["Wie", "we\u00b7nig", "richt", "offt", "aus", "der", "al\u00b7ler\u00b7bes\u00b7te", "Flei\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "VVFIN", "ADV", "APPR", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wie ruhig ist/ wer nichts von solchen Sorgen wei\u00df?", "tokens": ["Wie", "ru\u00b7hig", "ist", "/", "wer", "nichts", "von", "sol\u00b7chen", "Sor\u00b7gen", "wei\u00df", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VAFIN", "$(", "PWS", "PIS", "APPR", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.32": {"line.1": {"text": "Mir wachsen nun Verdru\u00df und Kummer unter H\u00e4nden/", "tokens": ["Mir", "wach\u00b7sen", "nun", "Ver\u00b7dru\u00df", "und", "Kum\u00b7mer", "un\u00b7ter", "H\u00e4n\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "NN", "KON", "NN", "APPR", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die Welt-Lust will mir auch die schwachen Augen blenden/", "tokens": ["Die", "Welt\u00b7Lust", "will", "mir", "auch", "die", "schwa\u00b7chen", "Au\u00b7gen", "blen\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PPER", "ADV", "ART", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Was ist di\u00df Erden-Rund? Voll Unlust und voll Wust/", "tokens": ["Was", "ist", "di\u00df", "Er\u00b7den\u00b7Rund", "?", "Voll", "Un\u00b7lust", "und", "voll", "Wust", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PDS", "NN", "$.", "ADJD", "NN", "KON", "ADJD", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Im Himmel ist allein zu suchen wahre Lust.", "tokens": ["Im", "Him\u00b7mel", "ist", "al\u00b7lein", "zu", "su\u00b7chen", "wah\u00b7re", "Lust", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VAFIN", "ADV", "PTKZU", "VVINF", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.33": {"line.1": {"text": "Wir haben schlimme Zeit/ ist die gemeine Klage/", "tokens": ["Wir", "ha\u00b7ben", "schlim\u00b7me", "Zeit", "/", "ist", "die", "ge\u00b7mei\u00b7ne", "Kla\u00b7ge", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJA", "NN", "$(", "VAFIN", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Doch schmiedet ihm der Mensch nur selber seine Plage;", "tokens": ["Doch", "schmie\u00b7det", "ihm", "der", "Mensch", "nur", "sel\u00b7ber", "sei\u00b7ne", "Pla\u00b7ge", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ART", "NN", "ADV", "ADV", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ist Zeit und Nahrung schlecht/ wo wir nicht besser werden", "tokens": ["Ist", "Zeit", "und", "Nah\u00b7rung", "schlecht", "/", "wo", "wir", "nicht", "bes\u00b7ser", "wer\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "NN", "KON", "NN", "VVFIN", "$(", "PWAV", "PPER", "PTKNEG", "ADJD", "VAINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So findet sich gewi\u00df nicht Besserung auff Erden!", "tokens": ["So", "fin\u00b7det", "sich", "ge\u00b7wi\u00df", "nicht", "Bes\u00b7se\u00b7rung", "auff", "Er\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "ADV", "PTKNEG", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.34": {"line.1": {"text": "Ich lie\u00df mich weiter ein in Wirthschafft und Gesch\u00e4ffte/", "tokens": ["Ich", "lie\u00df", "mich", "wei\u00b7ter", "ein", "in", "Wirth\u00b7schafft", "und", "Ge\u00b7sch\u00e4ff\u00b7te", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ART", "APPR", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Besegne Gott mein Thun/ und mehre meine Kr\u00e4ffte/", "tokens": ["Be\u00b7seg\u00b7ne", "Gott", "mein", "Thun", "/", "und", "meh\u00b7re", "mei\u00b7ne", "Kr\u00e4ff\u00b7te", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "PPOSAT", "NN", "$(", "KON", "PIAT", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wir bauen ohne dich nur H\u00e4user in den Sand/", "tokens": ["Wir", "bau\u00b7en", "oh\u00b7ne", "dich", "nur", "H\u00e4u\u00b7ser", "in", "den", "Sand", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPER", "ADV", "NN", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und schreiben was nicht taugt/ wo du nicht f\u00fchrst die Hand.", "tokens": ["Und", "schrei\u00b7ben", "was", "nicht", "taugt", "/", "wo", "du", "nicht", "f\u00fchrst", "die", "Hand", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PWS", "PTKNEG", "VVFIN", "$(", "PWAV", "PPER", "PTKNEG", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.35": {"line.1": {"text": "Ich gebe den Bescheid/ wer von mir wissen will", "tokens": ["Ich", "ge\u00b7be", "den", "Be\u00b7scheid", "/", "wer", "von", "mir", "wis\u00b7sen", "will"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "$(", "PWS", "APPR", "PPER", "VVINF", "VMFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Was treu und redlich sey: Der Bo\u00dfheit Spiel und Ziel/", "tokens": ["Was", "treu", "und", "red\u00b7lich", "sey", ":", "Der", "Bo\u00df\u00b7heit", "Spiel", "und", "Ziel", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADJD", "KON", "ADJD", "VAFIN", "$.", "ART", "NN", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Doch wenn besch\u00e4mtes Falsch sein eigen Gifft mu\u00df saugen/", "tokens": ["Doch", "wenn", "be\u00b7sch\u00e4m\u00b7tes", "Falsch", "sein", "ei\u00b7gen", "Gifft", "mu\u00df", "sau\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ADJA", "NN", "PPOSAT", "ADJA", "NN", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Geht jenes iederman auffrichtig unter Augen.", "tokens": ["Geht", "je\u00b7nes", "ie\u00b7der\u00b7man", "auf\u00b7frich\u00b7tig", "un\u00b7ter", "Au\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PDS", "PIS", "ADJD", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.36": {"line.1": {"text": "Die treue Schwester/ und der wohlgerathne Schwager", "tokens": ["Die", "treu\u00b7e", "Schwes\u00b7ter", "/", "und", "der", "wohl\u00b7ge\u00b7rath\u00b7ne", "Schwa\u00b7ger"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$(", "KON", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Begr\u00fcssen fast zugleich das schwartze Todten-Lager/", "tokens": ["Be\u00b7gr\u00fcs\u00b7sen", "fast", "zu\u00b7gleich", "das", "schwart\u00b7ze", "Tod\u00b7ten\u00b7La\u00b7ger", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ADV", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Mich schmerzt/ da\u00df beyder Fall in Monats Frist geschehn/", "tokens": ["Mich", "schmerzt", "/", "da\u00df", "bey\u00b7der", "Fall", "in", "Mo\u00b7nats", "Frist", "ge\u00b7schehn", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$(", "KOUS", "PIAT", "NN", "APPR", "NN", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Gedult! Auff einmahl folgt ein freudigs Wiedersehn.", "tokens": ["Ge\u00b7dult", "!", "Auff", "ein\u00b7mahl", "folgt", "ein", "freu\u00b7digs", "Wie\u00b7der\u00b7sehn", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "APPR", "ADV", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.37": {"line.1": {"text": "Neyd/ tobe wie du wilt/ wenn ich nicht heucheln kan/", "tokens": ["Neyd", "/", "to\u00b7be", "wie", "du", "wilt", "/", "wenn", "ich", "nicht", "heu\u00b7cheln", "kan", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "VVFIN", "KOKOM", "PPER", "VMFIN", "$(", "KOUS", "PPER", "PTKNEG", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Di\u00df geht wohl f\u00fcr der Welt/ doch dort f\u00fcr Gott nicht an/", "tokens": ["Di\u00df", "geht", "wohl", "f\u00fcr", "der", "Welt", "/", "doch", "dort", "f\u00fcr", "Gott", "nicht", "an", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "APPR", "ART", "NN", "$(", "ADV", "ADV", "APPR", "NN", "PTKNEG", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Es ist der beste Ruhm auff kurtzer Grab-Schrifft lesen:", "tokens": ["Es", "ist", "der", "bes\u00b7te", "Ruhm", "auff", "kurt\u00b7zer", "Grab\u00b7Schrifft", "le\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der ist im Vaterland ein ehrlich Mann gewesen.", "tokens": ["Der", "ist", "im", "Va\u00b7ter\u00b7land", "ein", "ehr\u00b7lich", "Mann", "ge\u00b7we\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "APPRART", "NN", "ART", "ADJD", "NN", "VAPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.38": {"line.1": {"text": "Ich lie\u00df mich f\u00fcr das Land berufft/ nach Hofe brauchen/", "tokens": ["Ich", "lie\u00df", "mich", "f\u00fcr", "das", "Land", "be\u00b7rufft", "/", "nach", "Ho\u00b7fe", "brau\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "ART", "NN", "VVFIN", "$(", "APPR", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und sah' unfern von Wien der Tartarn Feuer rauchen/", "tokens": ["Und", "sah'", "un\u00b7fern", "von", "Wi\u00b7en", "der", "Tar\u00b7tarn", "Feu\u00b7er", "rau\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "APPR", "NE", "ART", "NN", "NN", "VVFIN", "$("], "meter": "--+--+--+-+-+-", "measure": "anapaest.tri.plus"}, "line.3": {"text": "Gott ri\u00df mich aus Gefahr/ auch aus des Todes Scho\u00df/", "tokens": ["Gott", "ri\u00df", "mich", "aus", "Ge\u00b7fahr", "/", "auch", "aus", "des", "To\u00b7des", "Scho\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PRF", "APPR", "NN", "$(", "ADV", "APPR", "ART", "NN", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Den ich zu Hause bald gefunden h\u00e4tte lo\u00df.", "tokens": ["Den", "ich", "zu", "Hau\u00b7se", "bald", "ge\u00b7fun\u00b7den", "h\u00e4t\u00b7te", "lo\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "APPR", "NN", "ADV", "VVPP", "VAFIN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.39": {"line.1": {"text": "Man hie\u00df mich noch einmahl an Donau-Strom verreisen/", "tokens": ["Man", "hie\u00df", "mich", "noch", "ein\u00b7mahl", "an", "Do\u00b7nau\u00b7Strom", "ver\u00b7rei\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "ADV", "ADV", "APPR", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Dem grossen Leopold den Landes-Kummer weisen/", "tokens": ["Dem", "gros\u00b7sen", "Leo\u00b7pold", "den", "Lan\u00b7des\u00b7Kum\u00b7mer", "wei\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NE", "ART", "NN", "VVINF", "$("], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Ist was gerichtet aus/ so hat es Gott gethan:", "tokens": ["Ist", "was", "ge\u00b7rich\u00b7tet", "aus", "/", "so", "hat", "es", "Gott", "ge\u00b7than", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "VVPP", "APPR", "$(", "ADV", "VAFIN", "PPER", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Was ist es da\u00df der Mensch durch seine Klugheit kan.", "tokens": ["Was", "ist", "es", "da\u00df", "der", "Mensch", "durch", "sei\u00b7ne", "Klug\u00b7heit", "kan", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "KOUS", "ART", "NN", "APPR", "PPOSAT", "NN", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.40": {"line.1": {"text": "Des treuen Schw\u00e4hers Gunst/ der mich als Sohn geliebt/", "tokens": ["Des", "treu\u00b7en", "Schw\u00e4\u00b7hers", "Gunst", "/", "der", "mich", "als", "Sohn", "ge\u00b7liebt", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "$(", "PRELS", "PPER", "KOUS", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die mir der Tod entzeucht/ macht mich als Sohn betr\u00fcbt.", "tokens": ["Die", "mir", "der", "Tod", "ent\u00b7zeucht", "/", "macht", "mich", "als", "Sohn", "be\u00b7tr\u00fcbt", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ART", "NN", "VVPP", "$(", "VVFIN", "PPER", "KOUS", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "So fallen nach und nach gemeiner Wohlfart Mauren/", "tokens": ["So", "fal\u00b7len", "nach", "und", "nach", "ge\u00b7mei\u00b7ner", "Wohl\u00b7fart", "Mau\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "KON", "APPR", "ADJA", "NN", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ich habe f\u00fcr das Land und auch f\u00fcr mich zu trauren.", "tokens": ["Ich", "ha\u00b7be", "f\u00fcr", "das", "Land", "und", "auch", "f\u00fcr", "mich", "zu", "trau\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "ART", "NN", "KON", "ADV", "APPR", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.41": {"line.1": {"text": "Die lezte Schwester stirbt/ ich halte noch allein", "tokens": ["Die", "lez\u00b7te", "Schwes\u00b7ter", "stirbt", "/", "ich", "hal\u00b7te", "noch", "al\u00b7lein"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$(", "PPER", "VVFIN", "ADV", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Hier Hau\u00df/ so lang' es wird des H\u00f6chsten Wille seyn/", "tokens": ["Hier", "Hau\u00df", "/", "so", "lang'", "es", "wird", "des", "H\u00f6chs\u00b7ten", "Wil\u00b7le", "seyn", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "$(", "ADV", "ADV", "PPER", "VAFIN", "ART", "ADJA", "NN", "VAINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ich bin zum lezten auch in dieses Leben kommen/", "tokens": ["Ich", "bin", "zum", "lez\u00b7ten", "auch", "in", "die\u00b7ses", "Le\u00b7ben", "kom\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPRART", "ADJA", "ADV", "APPR", "PDAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Gott hat uns mehrentheils der Reyhe nach genommen.", "tokens": ["Gott", "hat", "uns", "meh\u00b7ren\u00b7theils", "der", "Rey\u00b7he", "nach", "ge\u00b7nom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "ADV", "ART", "NN", "APPR", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.42": {"line.1": {"text": "Gott segnet Hau\u00df und Hoff/ man neydet mein Gel\u00fccke/", "tokens": ["Gott", "seg\u00b7net", "Hau\u00df", "und", "Hoff", "/", "man", "ney\u00b7det", "mein", "Ge\u00b7l\u00fc\u00b7cke", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "NN", "KON", "VVFIN", "$(", "PIS", "VVFIN", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wei\u00df aber nicht dabey/ wo mich der Schuh hindr\u00fccke/", "tokens": ["Wei\u00df", "a\u00b7ber", "nicht", "da\u00b7bey", "/", "wo", "mich", "der", "Schuh", "hin\u00b7dr\u00fc\u00b7cke", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PTKNEG", "PAV", "$(", "PWAV", "PPER", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Da\u00df wir der Eitelkeit zu viel nicht r\u00e4umen ein/", "tokens": ["Da\u00df", "wir", "der", "Ei\u00b7tel\u00b7keit", "zu", "viel", "nicht", "r\u00e4u\u00b7men", "ein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "APPR", "PIS", "PTKNEG", "VVFIN", "ART", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Mu\u00df stets ein spitzer Dorn mit eingemischet seyn.", "tokens": ["Mu\u00df", "stets", "ein", "spit\u00b7zer", "Dorn", "mit", "ein\u00b7ge\u00b7mi\u00b7schet", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "ART", "ADJA", "NN", "APPR", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.43": {"line.1": {"text": "Uns dr\u00fcckt der schwere Krieg im Beutel/ nicht im Lande/", "tokens": ["Uns", "dr\u00fcckt", "der", "schwe\u00b7re", "Krieg", "im", "Beu\u00b7tel", "/", "nicht", "im", "Lan\u00b7de", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "APPRART", "NN", "$(", "PTKNEG", "APPRART", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und dennoch schickt man sich so schlecht zu solchem Stande/", "tokens": ["Und", "den\u00b7noch", "schickt", "man", "sich", "so", "schlecht", "zu", "sol\u00b7chem", "Stan\u00b7de", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PIS", "PRF", "ADV", "ADJD", "APPR", "PIAT", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Man bauet/ kaufft und prahlt: Gott gebe da\u00df uns nicht", "tokens": ["Man", "bau\u00b7et", "/", "kaufft", "und", "prahlt", ":", "Gott", "ge\u00b7be", "da\u00df", "uns", "nicht"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "$(", "VVFIN", "KON", "VVFIN", "$.", "NN", "VVFIN", "KOUS", "PPER", "PTKNEG"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Zulezt bey vollem Ma\u00df/ als andern/ auch geschicht.", "tokens": ["Zu\u00b7lezt", "bey", "vol\u00b7lem", "Ma\u00df", "/", "als", "an\u00b7dern", "/", "auch", "ge\u00b7schicht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "APPR", "ADJA", "NN", "$(", "KOUS", "PIS", "$(", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.44": {"line.1": {"text": "Die Sorgen nehmen zu/ die Kr\u00e4ffte lassen nach/", "tokens": ["Die", "Sor\u00b7gen", "neh\u00b7men", "zu", "/", "die", "Kr\u00e4ff\u00b7te", "las\u00b7sen", "nach", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "PTKZU", "$(", "ART", "NN", "VVFIN", "APPR", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Es f\u00fchlet Leib und Geist manch stilles Ungemach/", "tokens": ["Es", "f\u00fch\u00b7let", "Leib", "und", "Geist", "manch", "stil\u00b7les", "Un\u00b7ge\u00b7mach", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "KON", "NN", "PIAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Di\u00df ist des H\u00f6chsten Zug/ so will uns Gott bey Zeiten", "tokens": ["Di\u00df", "ist", "des", "H\u00f6chs\u00b7ten", "Zug", "/", "so", "will", "uns", "Gott", "bey", "Zei\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "ART", "ADJA", "NN", "$(", "ADV", "VMFIN", "PPER", "NN", "APPR", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Vom Irrdschen abgewehnt/ zur Himmelfahrt bereiten.", "tokens": ["Vom", "Irrd\u00b7schen", "ab\u00b7ge\u00b7wehnt", "/", "zur", "Him\u00b7mel\u00b7fahrt", "be\u00b7rei\u00b7ten", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVPP", "$(", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.45": {"line.1": {"text": "Man f\u00fchret Sorg' und Flei\u00df das Seine wohl zu n\u00fctzen/", "tokens": ["Man", "f\u00fch\u00b7ret", "Sor\u00b7g'", "und", "Flei\u00df", "das", "Sei\u00b7ne", "wohl", "zu", "n\u00fct\u00b7zen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "NN", "KON", "NN", "ART", "PPOSAT", "ADV", "PTKZU", "VVINF", "$("], "meter": "-+-+--+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Wei\u00df aber doch nicht wer/ und wie ers wird besitzen;", "tokens": ["Wei\u00df", "a\u00b7ber", "doch", "nicht", "wer", "/", "und", "wie", "ers", "wird", "be\u00b7sit\u00b7zen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADV", "PTKNEG", "PWS", "$(", "KON", "PWAV", "PIS", "VAFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Das beste Sorgen ist/ um das zu seyn bem\u00fcht/", "tokens": ["Das", "bes\u00b7te", "Sor\u00b7gen", "ist", "/", "um", "das", "zu", "seyn", "be\u00b7m\u00fcht", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "$(", "APPR", "PDS", "PTKZU", "VAINF", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Was uns kein R\u00e4uber stielt und keine Zeit entzieht.", "tokens": ["Was", "uns", "kein", "R\u00e4u\u00b7ber", "stielt", "und", "kei\u00b7ne", "Zeit", "ent\u00b7zieht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "PIAT", "NN", "VVFIN", "KON", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.46": {"line.1": {"text": "Die Tochter wird verlobt: Gott/ Stiffter keuscher Ehen/", "tokens": ["Die", "Toch\u00b7ter", "wird", "ver\u00b7lobt", ":", "Gott", "/", "Stiff\u00b7ter", "keu\u00b7scher", "E\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVPP", "$.", "NN", "$(", "NN", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Verkn\u00fcpffe dieses Band mit selgem Wohlergehen/", "tokens": ["Ver\u00b7kn\u00fcpf\u00b7fe", "die\u00b7ses", "Band", "mit", "sel\u00b7gem", "Woh\u00b7ler\u00b7ge\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PDAT", "NN", "APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Dir selber ist bewust/ da\u00df ich auff keine Pracht", "tokens": ["Dir", "sel\u00b7ber", "ist", "be\u00b7wust", "/", "da\u00df", "ich", "auff", "kei\u00b7ne", "Pracht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "VAFIN", "ADJD", "$(", "KOUS", "PPER", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Noch Sch\u00e4tze dieser Welt/ wie izt der Brauch/ gedacht.", "tokens": ["Noch", "Sch\u00e4t\u00b7ze", "die\u00b7ser", "Welt", "/", "wie", "izt", "der", "Brauch", "/", "ge\u00b7dacht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "NN", "PDAT", "NN", "$(", "KOKOM", "ADV", "ART", "NN", "$(", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.47": {"line.1": {"text": "Wohin bringt unser Land die \u00fcberh\u00e4uffte Steuer?", "tokens": ["Wo\u00b7hin", "bringt", "un\u00b7ser", "Land", "die", "\u00fc\u00b7berh\u00b7\u00e4uff\u00b7te", "Steu\u00b7er", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPOSAT", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Zu trucknem Saltz und Brod: Doch ist auch di\u00df zu theuer.", "tokens": ["Zu", "truck\u00b7nem", "Saltz", "und", "Brod", ":", "Doch", "ist", "auch", "di\u00df", "zu", "theu\u00b7er", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "KON", "NN", "$.", "KON", "VAFIN", "ADV", "PDS", "PTKA", "ADJD", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Bey seiner Kleyhen-Br\u00fch ist der am besten dran/", "tokens": ["Bey", "sei\u00b7ner", "Kley\u00b7hen\u00b7Br\u00fch", "ist", "der", "am", "bes\u00b7ten", "dran", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VAFIN", "ART", "PTKA", "ADJD", "PAV", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der sich noch mit Gedult und Hoffnung speisen kan.", "tokens": ["Der", "sich", "noch", "mit", "Ge\u00b7dult", "und", "Hoff\u00b7nung", "spei\u00b7sen", "kan", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "ADV", "APPR", "NN", "KON", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.48": {"line.1": {"text": "Das alte Spr\u00fcchwort ist: Das Land ern\u00e4hrt die St\u00e4dte/", "tokens": ["Das", "al\u00b7te", "Spr\u00fcch\u00b7wort", "ist", ":", "Das", "Land", "er\u00b7n\u00e4hrt", "die", "St\u00e4d\u00b7te", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "$.", "ART", "NN", "VVFIN", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wenn izt der St\u00e4dte Geld nicht was zum Besten th\u00e4te/", "tokens": ["Wenn", "izt", "der", "St\u00e4d\u00b7te", "Geld", "nicht", "was", "zum", "Bes\u00b7ten", "th\u00e4\u00b7te", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "NN", "PTKNEG", "PRELS", "APPRART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "So w\u00fcrd erlegnes Land noch sich noch jen' ern\u00e4hren/", "tokens": ["So", "w\u00fcrd", "er\u00b7leg\u00b7nes", "Land", "noch", "sich", "noch", "jen'", "er\u00b7n\u00e4h\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADJA", "NN", "ADV", "PRF", "ADV", "PIS", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ach/ woll uns Fried und Brod der treue Gott bescheren.", "tokens": ["Ach", "/", "woll", "uns", "Fried", "und", "Brod", "der", "treu\u00b7e", "Gott", "be\u00b7sche\u00b7ren", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$(", "VMFIN", "PPER", "NN", "KON", "NN", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.49": {"line.1": {"text": "Es will sich allgemach zur Jahre Neige neigen/", "tokens": ["Es", "will", "sich", "all\u00b7ge\u00b7mach", "zur", "Jah\u00b7re", "Nei\u00b7ge", "nei\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PRF", "ADV", "APPRART", "NN", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ich mu\u00df mit schwerem Tritt auff neun und viertzig steigen/", "tokens": ["Ich", "mu\u00df", "mit", "schwe\u00b7rem", "Tritt", "auff", "neun", "und", "viert\u00b7zig", "stei\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPR", "ADJA", "NN", "APPR", "CARD", "KON", "CARD", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ein doppelt Stuffen-Jahr wird unbegl\u00fcckt geacht/", "tokens": ["Ein", "dop\u00b7pelt", "Stuf\u00b7fen\u00b7Jahr", "wird", "un\u00b7be\u00b7gl\u00fcckt", "ge\u00b7acht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "VAFIN", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Doch mehr die viele Schuld/ die wir bey Gott gemacht.", "tokens": ["Doch", "mehr", "die", "vie\u00b7le", "Schuld", "/", "die", "wir", "bey", "Gott", "ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "PIAT", "NN", "$(", "PRELS", "PPER", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.50": {"line.1": {"text": "Man stehet in der Welt nach Wind/ nach Rauch und Dunst/", "tokens": ["Man", "ste\u00b7het", "in", "der", "Welt", "nach", "Wind", "/", "nach", "Rauch", "und", "Dunst", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "APPR", "ART", "NN", "APPR", "NN", "$(", "APPR", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Verschertzet offt dabey des gr\u00f6sten Herren Gunst:", "tokens": ["Ver\u00b7schert\u00b7zet", "offt", "da\u00b7bey", "des", "gr\u00f6s\u00b7ten", "Her\u00b7ren", "Gunst", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PAV", "ART", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "La\u00df sich die stoltze Welt um Reich und Stelle schmeissen/", "tokens": ["La\u00df", "sich", "die", "stolt\u00b7ze", "Welt", "um", "Reich", "und", "Stel\u00b7le", "schmeis\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PRF", "ART", "ADJA", "NN", "APPR", "NN", "KON", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der beste Titul ist/ von Gottes Gnaden heissen.", "tokens": ["Der", "bes\u00b7te", "Ti\u00b7tul", "ist", "/", "von", "Got\u00b7tes", "Gna\u00b7den", "heis\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "$(", "APPR", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.51": {"line.1": {"text": "Die Helfft' ist hinterlegt mit Gott von hundert Jahren/", "tokens": ["Die", "Helfft'", "ist", "hin\u00b7ter\u00b7legt", "mit", "Gott", "von", "hun\u00b7dert", "Jah\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVPP", "APPR", "NN", "APPR", "CARD", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Gott la\u00df mich Gnad und Schutz auch dieses Jahr erfahren/", "tokens": ["Gott", "la\u00df", "mich", "Gnad", "und", "Schutz", "auch", "die\u00b7ses", "Jahr", "er\u00b7fah\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVIMP", "PPER", "NN", "KON", "NN", "ADV", "PDAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ach nimm/ weil ich dir izt nichts Bessers geben kan/", "tokens": ["Ach", "nimm", "/", "weil", "ich", "dir", "izt", "nichts", "Bes\u00b7sers", "ge\u00b7ben", "kan", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "VVIMP", "$(", "KOUS", "PPER", "PPER", "ADV", "PIAT", "NN", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+-+--", "measure": "unknown.measure.penta"}, "line.4": {"text": "Gereinigt durch dein Blutt/ des Alters H\u00e4fen an.", "tokens": ["Ge\u00b7rei\u00b7nigt", "durch", "dein", "Blutt", "/", "des", "Al\u00b7ters", "H\u00e4\u00b7fen", "an", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "APPR", "PPOSAT", "ADJD", "$(", "ART", "NN", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.52": {"line.1": {"text": "Verm\u00f6gen-Steuer hat Verm\u00f6gen abgezogen/", "tokens": ["Ver\u00b7m\u00f6\u00b7gen\u00b7Steu\u00b7er", "hat", "Ver\u00b7m\u00f6\u00b7gen", "ab\u00b7ge\u00b7zo\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Verm\u00f6gen ist im Rauch und Feuer auffgeflogen/", "tokens": ["Ver\u00b7m\u00f6\u00b7gen", "ist", "im", "Rauch", "und", "Feu\u00b7er", "auff\u00b7ge\u00b7flo\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "APPRART", "NN", "KON", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Gieb/ H\u00f6chster/ da\u00df ich recht in gutt und b\u00f6sen Tag/", "tokens": ["Gieb", "/", "H\u00f6chs\u00b7ter", "/", "da\u00df", "ich", "recht", "in", "gutt", "und", "b\u00f6\u00b7sen", "Tag", "/"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "$(", "NN", "$(", "KOUS", "PPER", "ADV", "APPR", "ADJD", "KON", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Den deine Hand mir schickt/ zu schicken mich vermag.", "tokens": ["Den", "dei\u00b7ne", "Hand", "mir", "schickt", "/", "zu", "schi\u00b7cken", "mich", "ver\u00b7mag", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "PPER", "VVFIN", "$(", "PTKZU", "VVINF", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.53": {"line.1": {"text": "Die Jahre z\u00e4hl ich nun nach Zahl der Jahres-Wochen/", "tokens": ["Die", "Jah\u00b7re", "z\u00e4hl", "ich", "nun", "nach", "Zahl", "der", "Jah\u00b7res\u00b7Wo\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADV", "APPR", "NN", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wie aber z\u00e4hl ich di\u00df/ was ich an Gott verbrochen?", "tokens": ["Wie", "a\u00b7ber", "z\u00e4hl", "ich", "di\u00df", "/", "was", "ich", "an", "Gott", "ver\u00b7bro\u00b7chen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "VVFIN", "PPER", "PDS", "$(", "PWS", "PPER", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "HeRR/ rechne nicht mit mir/ gieb da\u00df mir ieder Tag", "tokens": ["HeRR", "/", "rech\u00b7ne", "nicht", "mit", "mir", "/", "gieb", "da\u00df", "mir", "ie\u00b7der", "Tag"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NE", "$(", "VVFIN", "PTKNEG", "APPR", "PPER", "$(", "VVIMP", "KOUS", "PPER", "PIAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Zur Bu\u00df und Todes-Stund ein Wecker werden mag!", "tokens": ["Zur", "Bu\u00df", "und", "To\u00b7des\u00b7Stund", "ein", "We\u00b7cker", "wer\u00b7den", "mag", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "KON", "NN", "ART", "NN", "VAINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.54": {"line.1": {"text": "Mit Weinen legt ich hin das erste Lebens-Jahr/", "tokens": ["Mit", "Wei\u00b7nen", "legt", "ich", "hin", "das", "ers\u00b7te", "Le\u00b7bens\u00b7Jahr", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PPER", "ADV", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Doch wohl mir/ da\u00df ich da von S\u00fcnden freyer war!", "tokens": ["Doch", "wohl", "mir", "/", "da\u00df", "ich", "da", "von", "S\u00fcn\u00b7den", "frey\u00b7er", "war", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PPER", "$(", "KOUS", "PPER", "ADV", "APPR", "NN", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Sie wuchsen mit mir gro\u00df. O Gott/ dein lieber Sohn/", "tokens": ["Sie", "wuch\u00b7sen", "mit", "mir", "gro\u00df", ".", "O", "Gott", "/", "dein", "lie\u00b7ber", "Sohn", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPER", "ADJD", "$.", "NE", "NN", "$(", "PPOSAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Das s\u00fcsse Gnaden-Kind/ befreye mich davon!", "tokens": ["Das", "s\u00fcs\u00b7se", "Gna\u00b7den\u00b7Kind", "/", "be\u00b7fre\u00b7ye", "mich", "da\u00b7von", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$(", "VVFIN", "PRF", "PAV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.55": {"line.1": {"text": "Zwey Jahre zehlt ich nun und lernte f\u00fcr mich gehn/", "tokens": ["Zwey", "Jah\u00b7re", "zehlt", "ich", "nun", "und", "lern\u00b7te", "f\u00fcr", "mich", "gehn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "VVFIN", "PPER", "ADV", "KON", "VVFIN", "APPR", "PPER", "VVINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Doch kan ich izt noch nicht auff sicherm Fusse stehn.", "tokens": ["Doch", "kan", "ich", "izt", "noch", "nicht", "auff", "si\u00b7cherm", "Fus\u00b7se", "stehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "ADV", "ADV", "PTKNEG", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-++--+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Herr/ la\u00df mich deine Hand als wie die Jugend leiten/", "tokens": ["Herr", "/", "la\u00df", "mich", "dei\u00b7ne", "Hand", "als", "wie", "die", "Ju\u00b7gend", "lei\u00b7ten", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "VVIMP", "PPER", "PPOSAT", "NN", "KOUS", "KOKOM", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So bleibt mein Gang gewi\u00df den Himmel zu beschreiten!", "tokens": ["So", "bleibt", "mein", "Gang", "ge\u00b7wi\u00df", "den", "Him\u00b7mel", "zu", "be\u00b7schrei\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "ADV", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.56": {"line.1": {"text": "Ich tratt ins dritte Jahr/ und brauchte meinen Mund/", "tokens": ["Ich", "tratt", "ins", "drit\u00b7te", "Jahr", "/", "und", "brauch\u00b7te", "mei\u00b7nen", "Mund", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "ADJA", "NN", "$(", "KON", "VVFIN", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wiewohl ich noch den Brauch der Worte schlecht verstund.", "tokens": ["Wie\u00b7wohl", "ich", "noch", "den", "Brauch", "der", "Wor\u00b7te", "schlecht", "ver\u00b7stund", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ART", "NN", "ART", "NN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wie manch vergeblich Wort schleicht noch wohl t\u00e4glich ein.", "tokens": ["Wie", "manch", "ver\u00b7geb\u00b7lich", "Wort", "schleicht", "noch", "wohl", "t\u00e4g\u00b7lich", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIAT", "ADJD", "NN", "VVFIN", "ADV", "ADV", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Gott/ la\u00df die Rechenschafft daf\u00fcr erloschen seyn!", "tokens": ["Gott", "/", "la\u00df", "die", "Re\u00b7chen\u00b7schafft", "da\u00b7f\u00fcr", "er\u00b7lo\u00b7schen", "seyn", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "VVIMP", "ART", "NN", "PAV", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.57": {"line.1": {"text": "Als ich das vierdte Jahr des Lebens angeschaut/", "tokens": ["Als", "ich", "das", "vierd\u00b7te", "Jahr", "des", "Le\u00b7bens", "an\u00b7ge\u00b7schaut", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Bedeckte Brand und Wust der Blattern meine Haut/", "tokens": ["Be\u00b7deck\u00b7te", "Brand", "und", "Wust", "der", "Blat\u00b7tern", "mei\u00b7ne", "Haut", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "KON", "NN", "ART", "NN", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Viel Blattern seither dem benarben mein Gewissen:", "tokens": ["Viel", "Blat\u00b7tern", "sei\u00b7ther", "dem", "be\u00b7nar\u00b7ben", "mein", "Ge\u00b7wis\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "APPR", "ART", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ach H\u00f6chster sey du sie zu heilen selbst beflissen.", "tokens": ["Ach", "H\u00f6chs\u00b7ter", "sey", "du", "sie", "zu", "hei\u00b7len", "selbst", "be\u00b7flis\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "NN", "VAFIN", "PPER", "PPER", "PTKZU", "VVINF", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.58": {"line.1": {"text": "Ich muste Vaters Treu im f\u00fcnfften Jahr entrathen/", "tokens": ["Ich", "mus\u00b7te", "Va\u00b7ters", "Treu", "im", "f\u00fcnff\u00b7ten", "Jahr", "ent\u00b7ra\u00b7then", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "NN", "APPRART", "ADJA", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Sah Hau\u00df und Hoff/ und mich bey nah/ im Feuer braten.", "tokens": ["Sah", "Hau\u00df", "und", "Hoff", "/", "und", "mich", "bey", "nah", "/", "im", "Feu\u00b7er", "bra\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "KON", "VVFIN", "$(", "KON", "PRF", "APPR", "ADJD", "$(", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Gott trat an Vaters Stell/ und seine Wunder-Treu/", "tokens": ["Gott", "trat", "an", "Va\u00b7ters", "Stell", "/", "und", "sei\u00b7ne", "Wun\u00b7der\u00b7Treu", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "APPR", "NN", "NN", "$(", "KON", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ob ich ein freches Kind/ ist mir noch t\u00e4glich neu!", "tokens": ["Ob", "ich", "ein", "fre\u00b7ches", "Kind", "/", "ist", "mir", "noch", "t\u00e4g\u00b7lich", "neu", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "$(", "VAFIN", "PPER", "ADV", "ADJD", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.59": {"line.1": {"text": "Ich fieng mein A/ B/ Ab/ mit Gott/ sechsj\u00e4hrig an/", "tokens": ["Ich", "fi\u00b7eng", "mein", "A", "/", "B", "/", "Ab", "/", "mit", "Gott", "/", "sechs\u00b7j\u00e4h\u00b7rig", "an", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NE", "$(", "XY", "$(", "APPR", "$(", "APPR", "NN", "$(", "ADJD", "PTKVZ", "$("], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}, "line.2": {"text": "Und baut auff diesen Grund was ich noch heute kan:", "tokens": ["Und", "baut", "auff", "die\u00b7sen", "Grund", "was", "ich", "noch", "heu\u00b7te", "kan", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PDAT", "NN", "PWS", "PPER", "ADV", "ADV", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Doch bin ich erst alsdenn gelehrt und klug zu nennen/", "tokens": ["Doch", "bin", "ich", "erst", "als\u00b7denn", "ge\u00b7lehrt", "und", "klug", "zu", "nen\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ADV", "ADV", "VVPP", "KON", "ADJD", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wenn ich das A und O im Himmel werde kennen.", "tokens": ["Wenn", "ich", "das", "A", "und", "O", "im", "Him\u00b7mel", "wer\u00b7de", "ken\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NE", "KON", "NE", "APPRART", "NN", "VAFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.60": {"line.1": {"text": "Ich lernte nun den Kiel der leichten Feder f\u00fchren/", "tokens": ["Ich", "lern\u00b7te", "nun", "den", "Kiel", "der", "leich\u00b7ten", "Fe\u00b7der", "f\u00fch\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN", "ART", "ADJA", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Lie\u00df gleiche Fl\u00fcchtigkeit in meinen Sinnen sp\u00fcren.", "tokens": ["Lie\u00df", "glei\u00b7che", "Fl\u00fcch\u00b7tig\u00b7keit", "in", "mei\u00b7nen", "Sin\u00b7nen", "sp\u00fc\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wenn ich/ wie Nero sich gew\u00fcnscht/ niemahls geschrieben/", "tokens": ["Wenn", "ich", "/", "wie", "Ne\u00b7ro", "sich", "ge\u00b7w\u00fcnscht", "/", "nie\u00b7mahls", "ge\u00b7schrie\u00b7ben", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$(", "KOKOM", "NE", "PRF", "VVPP", "$(", "ADV", "VVPP", "$("], "meter": "-+-+-+-++--+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "So w\u00e4re manches B\u00f6\u00df/ auch manches Gutte/ blieben.", "tokens": ["So", "w\u00e4\u00b7re", "man\u00b7ches", "B\u00f6\u00df", "/", "auch", "man\u00b7ches", "Gut\u00b7te", "/", "blie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "VAFIN", "PIAT", "NN", "$(", "ADV", "PIAT", "NN", "$(", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.61": {"line.1": {"text": "Ich gieng ins achte Jahr und schritte zum Latein/", "tokens": ["Ich", "gieng", "ins", "ach\u00b7te", "Jahr", "und", "schrit\u00b7te", "zum", "La\u00b7tein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "ADJA", "NN", "KON", "VVFIN", "APPRART", "NN", "$("], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Man fl\u00f6\u00dfte mir den Grund des wahren Glaubens ein;", "tokens": ["Man", "fl\u00f6\u00df\u00b7te", "mir", "den", "Grund", "des", "wah\u00b7ren", "Glau\u00b7bens", "ein", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "ART", "NN", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Di\u00df ist die beste Kunst/ wer Gott und sich wohl kennt/", "tokens": ["Di\u00df", "ist", "die", "bes\u00b7te", "Kunst", "/", "wer", "Gott", "und", "sich", "wohl", "kennt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "ADJA", "NN", "$(", "PWS", "NN", "KON", "PRF", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wohl dem/ der seine Zeit auff di\u00df am meisten wendt!", "tokens": ["Wohl", "dem", "/", "der", "sei\u00b7ne", "Zeit", "auff", "di\u00df", "am", "meis\u00b7ten", "wendt", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "$(", "ART", "PPOSAT", "NN", "APPR", "PDS", "PTKA", "PIS", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.62": {"line.1": {"text": "Neun Jahre r\u00fcckten an/ da\u00df ich hierbey nahm zu", "tokens": ["Neun", "Jah\u00b7re", "r\u00fcck\u00b7ten", "an", "/", "da\u00df", "ich", "hier\u00b7bey", "nahm", "zu"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["CARD", "NN", "VVFIN", "PTKVZ", "$(", "KOUS", "PPER", "ADV", "VVFIN", "APPR"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "An Alter und Verstand/ o Gott/ verliehest du:", "tokens": ["An", "Al\u00b7ter", "und", "Ver\u00b7stand", "/", "o", "Gott", "/", "ver\u00b7lie\u00b7hest", "du", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$(", "FM", "NN", "$(", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Gieb/ da\u00df ich nicht bey dir mit Neunen geh vorbey/", "tokens": ["Gieb", "/", "da\u00df", "ich", "nicht", "bey", "dir", "mit", "Neu\u00b7nen", "geh", "vor\u00b7bey", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "$(", "KOUS", "PPER", "PTKNEG", "APPR", "PPER", "APPR", "NN", "VVFIN", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Vielmehr in Lob und Danck der Zehnde Reine sey.", "tokens": ["Viel\u00b7mehr", "in", "Lob", "und", "Danck", "der", "Zehn\u00b7de", "Rei\u00b7ne", "sey", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "KON", "APPR", "ART", "ADJA", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.63": {"line.1": {"text": "Der erste Krei\u00df der Zeit und Alter trat zur\u00fccke/", "tokens": ["Der", "ers\u00b7te", "Krei\u00df", "der", "Zeit", "und", "Al\u00b7ter", "trat", "zu\u00b7r\u00fc\u00b7cke", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "KON", "NN", "VVFIN", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ich rei\u00df das schwache Paar der Kinder-Schuh in St\u00fccke.", "tokens": ["Ich", "rei\u00df", "das", "schwa\u00b7che", "Paar", "der", "Kin\u00b7der\u00b7Schuh", "in", "St\u00fc\u00b7cke", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "ART", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Doch wei\u00df ich/ da\u00df ich selbst durch Beyspiel zeigen kan/", "tokens": ["Doch", "wei\u00df", "ich", "/", "da\u00df", "ich", "selbst", "durch", "Bey\u00b7spiel", "zei\u00b7gen", "kan", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "$(", "KOUS", "PPER", "ADV", "APPR", "NN", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Dem Knaben klebe noch manch Thorheits-Fehler an!", "tokens": ["Dem", "Kna\u00b7ben", "kle\u00b7be", "noch", "manch", "Thor\u00b7heits\u00b7Feh\u00b7ler", "an", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "PIAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.64": {"line.1": {"text": "Es wird der zehnden Zahl noch eines beygesezt/", "tokens": ["Es", "wird", "der", "zehn\u00b7den", "Zahl", "noch", "ei\u00b7nes", "bey\u00b7ge\u00b7sezt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "ADV", "PIS", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ach/ da\u00df man doch die Zeit nicht recht nach W\u00fcrden sch\u00e4zt/", "tokens": ["Ach", "/", "da\u00df", "man", "doch", "die", "Zeit", "nicht", "recht", "nach", "W\u00fcr\u00b7den", "sch\u00e4zt", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$(", "KOUS", "PIS", "ADV", "ART", "NN", "PTKNEG", "ADJD", "APPR", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Herr/ geh ich um eilff Uhr in deinen Berg erst ein/", "tokens": ["Herr", "/", "geh", "ich", "um", "eilff", "Uhr", "in", "dei\u00b7nen", "Berg", "erst", "ein", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "VVFIN", "PPER", "APPR", "CARD", "NN", "APPR", "PPOSAT", "NN", "ADV", "ART", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "La\u00df mich vom Gnaden-Lohn nicht ausgeschlossen seyn.", "tokens": ["La\u00df", "mich", "vom", "Gna\u00b7den\u00b7Lohn", "nicht", "aus\u00b7ge\u00b7schlos\u00b7sen", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "APPRART", "NN", "PTKNEG", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.65": {"line.1": {"text": "Als Jesus war zw\u00f6lff Jahr/ so sah ihn Solyms Stadt/", "tokens": ["Als", "Je\u00b7sus", "war", "zw\u00f6lff", "Jahr", "/", "so", "sah", "ihn", "So\u00b7lyms", "Stadt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "VAFIN", "CARD", "NN", "$(", "ADV", "VVFIN", "PPER", "PIAT", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wie er das Gottes-Hau\u00df und Heiligthum betratt/", "tokens": ["Wie", "er", "das", "Got\u00b7tes\u00b7Hau\u00df", "und", "Hei\u00b7lig\u00b7thum", "be\u00b7tratt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "NN", "KON", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ich nahm um diese Zeit das Brod des Lebens ein/", "tokens": ["Ich", "nahm", "um", "die\u00b7se", "Zeit", "das", "Brod", "des", "Le\u00b7bens", "ein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PDAT", "NN", "ART", "NN", "ART", "NN", "ART", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Gott la\u00df mir solche Kost zum Himmel angedeyhn.", "tokens": ["Gott", "la\u00df", "mir", "sol\u00b7che", "Kost", "zum", "Him\u00b7mel", "an\u00b7ge\u00b7deyhn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVIMP", "PPER", "PIAT", "NN", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.66": {"line.1": {"text": "Ein Monat war hinweg von zw\u00f6lff zu dreyzehn Jahren/", "tokens": ["Ein", "Mo\u00b7nat", "war", "hin\u00b7weg", "von", "zw\u00f6lff", "zu", "drey\u00b7zehn", "Jah\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "APPR", "CARD", "APPR", "CARD", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der treuen Mutter Tod mu\u00df ich best\u00fcrzt erfahren/", "tokens": ["Der", "treu\u00b7en", "Mut\u00b7ter", "Tod", "mu\u00df", "ich", "be\u00b7st\u00fcrzt", "er\u00b7fah\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "VMFIN", "PPER", "ADJD", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ihr Beten war mein Schatz/ ihr Segen war mein Theil/", "tokens": ["Ihr", "Be\u00b7ten", "war", "mein", "Schatz", "/", "ihr", "Se\u00b7gen", "war", "mein", "Theil", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "PPOSAT", "NN", "$(", "PPOSAT", "NN", "VAFIN", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ich w\u00fcnsche mir/ was sie geneust/ der Seelen Heyl.", "tokens": ["Ich", "w\u00fcn\u00b7sche", "mir", "/", "was", "sie", "ge\u00b7neust", "/", "der", "See\u00b7len", "Heyl", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$(", "PWS", "PPER", "VVPP", "$(", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.67": {"line.1": {"text": "Wie gehn die Monden hin mit so geschwinder Flucht/", "tokens": ["Wie", "gehn", "die", "Mon\u00b7den", "hin", "mit", "so", "ge\u00b7schwin\u00b7der", "Flucht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "ART", "NN", "ADV", "APPR", "ADV", "ADJA", "NN", "$("], "meter": "-+-+-+---+-+", "measure": "unknown.measure.penta"}, "line.2": {"text": "Mein Knaben-Alter kam aus stiller Kinderzucht.", "tokens": ["Mein", "Kna\u00b7ben\u00b7Al\u00b7ter", "kam", "aus", "stil\u00b7ler", "Kin\u00b7der\u00b7zucht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der Jugend zartes Wachs nimmt Gutt und B\u00f6ses an/", "tokens": ["Der", "Ju\u00b7gend", "zar\u00b7tes", "Wachs", "nimmt", "Gutt", "und", "B\u00f6\u00b7ses", "an", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "VVFIN", "ADJD", "KON", "NN", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ach h\u00e4tt ich dieses nicht/ und jenes nur gethan!", "tokens": ["Ach", "h\u00e4tt", "ich", "die\u00b7ses", "nicht", "/", "und", "je\u00b7nes", "nur", "ge\u00b7than", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "VAFIN", "PPER", "PDS", "PTKNEG", "$(", "KON", "PDS", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.68": {"line.1": {"text": "Zwey Dinge sind/ die sich gar selten reimen k\u00fcnnen/", "tokens": ["Zwey", "Din\u00b7ge", "sind", "/", "die", "sich", "gar", "sel\u00b7ten", "rei\u00b7men", "k\u00fcn\u00b7nen", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "VAFIN", "$(", "PRELS", "PRF", "ADV", "ADJD", "VVINF", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die strengen Zehn Gebot und Freyheit der f\u00fcnff Sinnen/", "tokens": ["Die", "stren\u00b7gen", "Zehn", "Ge\u00b7bot", "und", "Frey\u00b7heit", "der", "f\u00fcnff", "Sin\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "CARD", "NN", "KON", "NN", "ART", "CARD", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Da\u00df bey der Jugend di\u00df wie bey dem Alter war/", "tokens": ["Da\u00df", "bey", "der", "Ju\u00b7gend", "di\u00df", "wie", "bey", "dem", "Al\u00b7ter", "war", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "ART", "NN", "PDS", "KOKOM", "APPR", "ART", "NN", "VAFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Lehrt mich izt f\u00fcnffmahl zehn/ vor zehnd und f\u00fcnfftes Jahr.", "tokens": ["Lehrt", "mich", "izt", "f\u00fcnff\u00b7mahl", "zehn", "/", "vor", "zehnd", "und", "f\u00fcnff\u00b7tes", "Jahr", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "CARD", "$(", "APPR", "CARD", "KON", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.69": {"line.1": {"text": "Ich rechne meine Zeit mit acht und aber achten/", "tokens": ["Ich", "rech\u00b7ne", "mei\u00b7ne", "Zeit", "mit", "acht", "und", "a\u00b7ber", "ach\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "APPR", "CARD", "KON", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Mein Sinn und Sorgen ist nach Wissenschafften trachten.", "tokens": ["Mein", "Sinn", "und", "Sor\u00b7gen", "ist", "nach", "Wis\u00b7sen\u00b7schaff\u00b7ten", "trach\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "NN", "VAFIN", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wohl dem/ der so bedacht die Jugend angewehrt/", "tokens": ["Wohl", "dem", "/", "der", "so", "be\u00b7dacht", "die", "Ju\u00b7gend", "an\u00b7ge\u00b7wehrt", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "$(", "ART", "ADV", "ADJD", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Da\u00df ihn des Richters Spruch nicht in die Acht erkl\u00e4rt.", "tokens": ["Da\u00df", "ihn", "des", "Rich\u00b7ters", "Spruch", "nicht", "in", "die", "Acht", "er\u00b7kl\u00e4rt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "NN", "PTKNEG", "APPR", "ART", "CARD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.70": {"line.1": {"text": "Die Jahre lauffen fort/ nach zehnen zehl ich sieben/", "tokens": ["Die", "Jah\u00b7re", "lauf\u00b7fen", "fort", "/", "nach", "zeh\u00b7nen", "zehl", "ich", "sie\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "$(", "APPR", "ADJA", "NN", "PPER", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Als ich zum andern mahl bin Vater-W\u00e4ise blieben.", "tokens": ["Als", "ich", "zum", "an\u00b7dern", "mahl", "bin", "Va\u00b7ter\u00b7W\u00e4i\u00b7se", "blie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPRART", "ADJA", "ADV", "VAFIN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Mein Pflege-Vater stirbt/ doch nimmt sich meiner an", "tokens": ["Mein", "Pfle\u00b7ge\u00b7Va\u00b7ter", "stirbt", "/", "doch", "nimmt", "sich", "mei\u00b7ner", "an"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VVFIN", "$(", "ADV", "VVFIN", "PRF", "PPOSAT", "APPR"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und unterh\u00e4lt mich noch der nimmer sterben kan.", "tokens": ["Und", "un\u00b7ter\u00b7h\u00e4lt", "mich", "noch", "der", "nim\u00b7mer", "ster\u00b7ben", "kan", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "ART", "ADV", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.71": {"line.1": {"text": "Das dreymahl sechste Jahr weicht meistens hinter sich/", "tokens": ["Das", "drey\u00b7mahl", "sechs\u00b7te", "Jahr", "weicht", "meis\u00b7tens", "hin\u00b7ter", "sich", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "ADJA", "NN", "VVFIN", "ADV", "APPR", "PRF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Als ich Piastens Stadt sechsj\u00e4hrger Gast entwich/", "tokens": ["Als", "ich", "Pi\u00b7as\u00b7tens", "Stadt", "sechs\u00b7j\u00e4hr\u00b7ger", "Gast", "ent\u00b7wich", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NN", "NN", "ADJA", "NN", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Hab ich an Witz und Kunst alldar was zugenommen/", "tokens": ["Hab", "ich", "an", "Witz", "und", "Kunst", "all\u00b7dar", "was", "zu\u00b7ge\u00b7nom\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "APPR", "NN", "KON", "NN", "ADV", "PIS", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So ist die Frucht darvon zu ihrer Wurtzel kommen.", "tokens": ["So", "ist", "die", "Frucht", "dar\u00b7von", "zu", "ih\u00b7rer", "Wurt\u00b7zel", "kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "PAV", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.72": {"line.1": {"text": "Nun schwing' ich in die Welt/ als Icarus/ die Fl\u00fcgel/", "tokens": ["Nun", "schwing'", "ich", "in", "die", "Welt", "/", "als", "I\u00b7ca\u00b7rus", "/", "die", "Fl\u00fc\u00b7gel", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "$(", "KOUS", "NE", "$(", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der Jugend Unbedacht regirt die freyen Z\u00fcgel/", "tokens": ["Der", "Ju\u00b7gend", "Un\u00b7be\u00b7dacht", "re\u00b7girt", "die", "frey\u00b7en", "Z\u00fc\u00b7gel", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Doch ists zuweilen gutt/ wenn solche kurtz geschnitten/", "tokens": ["Doch", "ists", "zu\u00b7wei\u00b7len", "gutt", "/", "wenn", "sol\u00b7che", "kurtz", "ge\u00b7schnit\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "ADJD", "$(", "KOUS", "PIS", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So wird der Tugend-Weg viel minder \u00fcberschritten.", "tokens": ["So", "wird", "der", "Tu\u00b7gen\u00b7dWeg", "viel", "min\u00b7der", "\u00fc\u00b7bersc\u00b7hrit\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "ADV", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.73": {"line.1": {"text": "Mich hegt ins andre Jahr der Musen Silber-Stadt/", "tokens": ["Mich", "hegt", "ins", "and\u00b7re", "Jahr", "der", "Mu\u00b7sen", "Sil\u00b7ber\u00b7Stadt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "ADJA", "NN", "ART", "NN", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die izt der strenge Mars mit Stahl gefesselt hat/", "tokens": ["Die", "izt", "der", "stren\u00b7ge", "Mars", "mit", "Stahl", "ge\u00b7fes\u00b7selt", "hat", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ART", "ADJA", "NN", "APPR", "NN", "VVPP", "VAFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Di\u00df und mein eigen Bild lehrt mich nunmehr erkennen/", "tokens": ["Di\u00df", "und", "mein", "ei\u00b7gen", "Bild", "lehrt", "mich", "nun\u00b7mehr", "er\u00b7ken\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "KON", "PPOSAT", "ADJA", "NN", "VVFIN", "PPER", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Da\u00df nichts auff dieser Welt best\u00e4ndig sey zu nennen.", "tokens": ["Da\u00df", "nichts", "auff", "die\u00b7ser", "Welt", "be\u00b7st\u00e4n\u00b7dig", "sey", "zu", "nen\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "APPR", "PDAT", "NN", "ADJD", "VAFIN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.74": {"line.1": {"text": "Der damahls freye Rhein schickt mich auff engen Nachen/", "tokens": ["Der", "da\u00b7mahls", "frey\u00b7e", "Rhein", "schickt", "mich", "auff", "en\u00b7gen", "Na\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJA", "NE", "VVFIN", "PPER", "APPR", "ADJA", "NN", "$("], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Wo f\u00fcr des Landes Heyl gepichte Schl\u00f6sser wachen:", "tokens": ["Wo", "f\u00fcr", "des", "Lan\u00b7des", "Heyl", "ge\u00b7pich\u00b7te", "Schl\u00f6s\u00b7ser", "wa\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPR", "ART", "NN", "NN", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "F\u00fchrt mich ein grosses Schiff/ tr\u00e4gt mich ein kleiner Kahn/", "tokens": ["F\u00fchrt", "mich", "ein", "gros\u00b7ses", "Schiff", "/", "tr\u00e4gt", "mich", "ein", "klei\u00b7ner", "Kahn", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "NN", "$(", "VVFIN", "PPER", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Es gilt mir beydes gleich/ l\u00e4nd' ich nur sicher an.", "tokens": ["Es", "gilt", "mir", "bey\u00b7des", "gleich", "/", "l\u00e4nd'", "ich", "nur", "si\u00b7cher", "an", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PIS", "ADV", "$(", "VVFIN", "PPER", "ADV", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.75": {"line.1": {"text": "Das freye Niederland/ durchs Land der engen Hosen/", "tokens": ["Das", "frey\u00b7e", "Nie\u00b7der\u00b7land", "/", "durchs", "Land", "der", "en\u00b7gen", "Ho\u00b7sen", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$(", "APPRART", "NN", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Gew\u00e4hrt mich in das Reich der herrschenden Frantzosen.", "tokens": ["Ge\u00b7w\u00e4hrt", "mich", "in", "das", "Reich", "der", "herr\u00b7schen\u00b7den", "Frant\u00b7zo\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "APPR", "ART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Von dar ich kurtze Zeit den Welschen sprechen mu\u00df/", "tokens": ["Von", "dar", "ich", "kurt\u00b7ze", "Zeit", "den", "Wel\u00b7schen", "spre\u00b7chen", "mu\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PTKVZ", "PPER", "ADJA", "NN", "ART", "NN", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Viel sehn/ und \u00fcber nichts sich wundern/ ist mein Schlu\u00df.", "tokens": ["Viel", "sehn", "/", "und", "\u00fc\u00b7ber", "nichts", "sich", "wun\u00b7dern", "/", "ist", "mein", "Schlu\u00df", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVINF", "$(", "KON", "APPR", "PIS", "PRF", "VVINF", "$(", "VAFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.76": {"line.1": {"text": "Ich lange wieder heim nach dreyen Reise-Jahren/", "tokens": ["Ich", "lan\u00b7ge", "wie\u00b7der", "heim", "nach", "drey\u00b7en", "Rei\u00b7se\u00b7Jah\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADV", "PTKVZ", "APPR", "CARD", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und soll nun legen aus/ was ich gebracht an Wahren/", "tokens": ["Und", "soll", "nun", "le\u00b7gen", "aus", "/", "was", "ich", "ge\u00b7bracht", "an", "Wah\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ADV", "VVFIN", "PTKVZ", "$(", "PWS", "PPER", "VVPP", "APPR", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Viel Eiteles gesehn/ viel Th\u00f6richtes gedacht/", "tokens": ["Viel", "Ei\u00b7te\u00b7les", "ge\u00b7sehn", "/", "viel", "Th\u00f6\u00b7rich\u00b7tes", "ge\u00b7dacht", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVPP", "$(", "PIAT", "NN", "VVPP", "$("], "meter": "-+---+--+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Den Leib und Geist bem\u00fcht/ den Beutel leer gemacht.", "tokens": ["Den", "Leib", "und", "Geist", "be\u00b7m\u00fcht", "/", "den", "Beu\u00b7tel", "leer", "ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "VVPP", "$(", "ART", "NN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.77": {"line.1": {"text": "Es soll die Lebens-Art izt gantz ge\u00e4ndert seyn/", "tokens": ["Es", "soll", "die", "Le\u00b7bens\u00b7Art", "izt", "gantz", "ge\u00b7\u00e4n\u00b7dert", "seyn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "NN", "ADV", "ADV", "VVPP", "VAINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Gott will mich in das Joch der Wirthschafft spannen ein/", "tokens": ["Gott", "will", "mich", "in", "das", "Joch", "der", "Wirth\u00b7schafft", "span\u00b7nen", "ein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "PRF", "APPR", "ART", "NN", "ART", "NN", "VVFIN", "ART", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Was meinen Eltern hat entzogen Krieg und Brand/", "tokens": ["Was", "mei\u00b7nen", "El\u00b7tern", "hat", "ent\u00b7zo\u00b7gen", "Krieg", "und", "Brand", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPOSAT", "NN", "VAFIN", "VVPP", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Gew\u00e4hrt mir seine Gunst durch fremde Mutter-Hand.", "tokens": ["Ge\u00b7w\u00e4hrt", "mir", "sei\u00b7ne", "Gunst", "durch", "frem\u00b7de", "Mut\u00b7ter\u00b7Hand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPOSAT", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.78": {"line.1": {"text": "Ich habe nun zu Freud und Leyd Gesellschafft funden/", "tokens": ["Ich", "ha\u00b7be", "nun", "zu", "Freud", "und", "Leyd", "Ge\u00b7sell\u00b7schafft", "fun\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "APPR", "NN", "KON", "NN", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und leb' aus Gottes Rath mit treuer Hand verbunden.", "tokens": ["Und", "leb'", "aus", "Got\u00b7tes", "Rath", "mit", "treu\u00b7er", "Hand", "ver\u00b7bun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "NN", "NN", "APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Erhalt die reine Glutt/ Gott/ die du angebrennt/", "tokens": ["Er\u00b7halt", "die", "rei\u00b7ne", "Glutt", "/", "Gott", "/", "die", "du", "an\u00b7ge\u00b7brennt", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "$(", "NN", "$(", "PRELS", "PPER", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und la\u00df uns dort/ wie hier verbleiben ungetrennt.", "tokens": ["Und", "la\u00df", "uns", "dort", "/", "wie", "hier", "ver\u00b7blei\u00b7ben", "un\u00b7ge\u00b7trennt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVIMP", "PPER", "ADV", "$(", "KOKOM", "ADV", "VVINF", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.79": {"line.1": {"text": "Zwey Br\u00fcder werden mir nicht hochbejahrt zu Leichen/", "tokens": ["Zwey", "Br\u00fc\u00b7der", "wer\u00b7den", "mir", "nicht", "hoch\u00b7be\u00b7jahrt", "zu", "Lei\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "VAFIN", "PPER", "PTKNEG", "ADJD", "APPR", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Mir selber mehren sich die Ungesundheits-Zeichen:", "tokens": ["Mir", "sel\u00b7ber", "meh\u00b7ren", "sich", "die", "Un\u00b7ge\u00b7sund\u00b7heits\u00b7Zei\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "PRF", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "So wechseln Freud und Leyd bey gutt und b\u00f6sen Tagen/", "tokens": ["So", "wech\u00b7seln", "Freud", "und", "Leyd", "bey", "gutt", "und", "b\u00f6\u00b7sen", "Ta\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NN", "KON", "NN", "APPR", "ADJD", "KON", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Doch hilfft auch Gottes Gunst viel Creutze selber tragen.", "tokens": ["Doch", "hilfft", "auch", "Got\u00b7tes", "Gunst", "viel", "Creut\u00b7ze", "sel\u00b7ber", "tra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "NN", "NN", "PIAT", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.80": {"line.1": {"text": "Wie der/ der ob uns wacht/ f\u00fcr Schaden kan bewahren/", "tokens": ["Wie", "der", "/", "der", "ob", "uns", "wacht", "/", "f\u00fcr", "Scha\u00b7den", "kan", "be\u00b7wah\u00b7ren", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "$(", "ART", "KOUS", "PPER", "VVFIN", "$(", "APPR", "NN", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Hab ich di\u00df Jahr drey mahl in naher Glutt erfahren.", "tokens": ["Hab", "ich", "di\u00df", "Jahr", "drey", "mahl", "in", "na\u00b7her", "Glutt", "er\u00b7fah\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PDS", "NN", "CARD", "ADV", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Du H\u00fctter Israels bleib unser Schutz und Schild/", "tokens": ["Du", "H\u00fct\u00b7ter", "Is\u00b7raels", "bleib", "un\u00b7ser", "Schutz", "und", "Schild", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "NE", "VVFIN", "PPOSAT", "NN", "KON", "NN", "$("], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Der bleibet unverlezt/ den du bedecken wilt.", "tokens": ["Der", "blei\u00b7bet", "un\u00b7ver\u00b7lezt", "/", "den", "du", "be\u00b7de\u00b7cken", "wilt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADJD", "$(", "ART", "PPER", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.81": {"line.1": {"text": "Die Kinder keuscher Eh' sind wohl der Augen Lust/", "tokens": ["Die", "Kin\u00b7der", "keu\u00b7scher", "Eh'", "sind", "wohl", "der", "Au\u00b7gen", "Lust", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "VAFIN", "ADV", "ART", "NN", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Doch wird auch offt um sie bekr\u00e4nckt der Eltern Brust/", "tokens": ["Doch", "wird", "auch", "offt", "um", "sie", "be\u00b7kr\u00e4nckt", "der", "El\u00b7tern", "Brust", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "ADV", "APPR", "PPER", "VVFIN", "ART", "NN", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ich stell in Gottes Hand ihr Leben und ihr Sterben/", "tokens": ["Ich", "stell", "in", "Got\u00b7tes", "Hand", "ihr", "Le\u00b7ben", "und", "ihr", "Ster\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "APPR", "NN", "NN", "PPOSAT", "NN", "KON", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Nur da\u00df sie allesamt nebst uns den Himmel erben.", "tokens": ["Nur", "da\u00df", "sie", "al\u00b7le\u00b7samt", "nebst", "uns", "den", "Him\u00b7mel", "er\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PPER", "ADJD", "APPR", "PPER", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.82": {"line.1": {"text": "Das Feld bringt sparsam Frucht/ wiewohl wir m\u00fchsam s\u00e4en/", "tokens": ["Das", "Feld", "bringt", "spar\u00b7sam", "Frucht", "/", "wie\u00b7wohl", "wir", "m\u00fch\u00b7sam", "s\u00e4\u00b7en", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJD", "NN", "$(", "KOUS", "PPER", "ADJD", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und zeigt den Fluch/ der drauff nach erster Schuld geschehen:", "tokens": ["Und", "zeigt", "den", "Fluch", "/", "der", "drauff", "nach", "ers\u00b7ter", "Schuld", "ge\u00b7sche\u00b7hen", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "$(", "ART", "PAV", "APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wir streun auch/ leider! selbst viel S\u00fcnden-Disteln aus/", "tokens": ["Wir", "streun", "auch", "/", "lei\u00b7der", "!", "selbst", "viel", "S\u00fcn\u00b7den\u00b7Dis\u00b7teln", "aus", "/"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$(", "ADV", "$.", "ADV", "PIAT", "NN", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Was Wunder/ wenn uns denn der Mangel k\u00f6mmt ins Hau\u00df.", "tokens": ["Was", "Wun\u00b7der", "/", "wenn", "uns", "denn", "der", "Man\u00b7gel", "k\u00f6mmt", "ins", "Hau\u00df", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "$(", "KOUS", "PPER", "ADV", "ART", "NN", "VVFIN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.83": {"line.1": {"text": "Piastens Enckel stirbt/ dem wir gehuldigt haben/", "tokens": ["Pi\u00b7as\u00b7tens", "En\u00b7ckel", "stirbt", "/", "dem", "wir", "ge\u00b7hul\u00b7digt", "ha\u00b7ben", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "VVFIN", "$(", "PRELS", "PPER", "VVPP", "VAINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die Freyheit Schlesiens wird neben ihm begraben/", "tokens": ["Die", "Frey\u00b7heit", "Schle\u00b7si\u00b7ens", "wird", "ne\u00b7ben", "ihm", "be\u00b7gra\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VAFIN", "APPR", "PPER", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ob seinem Tod erseuffzt manch treuer Unterthan/", "tokens": ["Ob", "sei\u00b7nem", "Tod", "er\u00b7seuffzt", "manch", "treu\u00b7er", "Un\u00b7ter\u00b7than", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "VVFIN", "PIAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der/ was noch k\u00fcnfftig sey/ von weitem sehen kan.", "tokens": ["Der", "/", "was", "noch", "k\u00fcnff\u00b7tig", "sey", "/", "von", "wei\u00b7tem", "se\u00b7hen", "kan", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "$(", "PWS", "ADV", "ADJD", "VAFIN", "$(", "APPR", "PIS", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.84": {"line.1": {"text": "Es heist mich Gottes Ruff aus meinem Winckel gehn/", "tokens": ["Es", "heist", "mich", "Got\u00b7tes", "Ruff", "aus", "mei\u00b7nem", "Win\u00b7ckel", "gehn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "NN", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ich soll mich f\u00fcr das Land zu sorgen unterstehn/", "tokens": ["Ich", "soll", "mich", "f\u00fcr", "das", "Land", "zu", "sor\u00b7gen", "un\u00b7ter\u00b7stehn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PRF", "APPR", "ART", "NN", "APPR", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wie wenig richt offt aus der allerbeste Flei\u00df/", "tokens": ["Wie", "we\u00b7nig", "richt", "offt", "aus", "der", "al\u00b7ler\u00b7bes\u00b7te", "Flei\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "VVFIN", "ADV", "APPR", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wie ruhig ist/ wer nichts von solchen Sorgen wei\u00df?", "tokens": ["Wie", "ru\u00b7hig", "ist", "/", "wer", "nichts", "von", "sol\u00b7chen", "Sor\u00b7gen", "wei\u00df", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VAFIN", "$(", "PWS", "PIS", "APPR", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.85": {"line.1": {"text": "Mir wachsen nun Verdru\u00df und Kummer unter H\u00e4nden/", "tokens": ["Mir", "wach\u00b7sen", "nun", "Ver\u00b7dru\u00df", "und", "Kum\u00b7mer", "un\u00b7ter", "H\u00e4n\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "NN", "KON", "NN", "APPR", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die Welt-Lust will mir auch die schwachen Augen blenden/", "tokens": ["Die", "Welt\u00b7Lust", "will", "mir", "auch", "die", "schwa\u00b7chen", "Au\u00b7gen", "blen\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PPER", "ADV", "ART", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Was ist di\u00df Erden-Rund? Voll Unlust und voll Wust/", "tokens": ["Was", "ist", "di\u00df", "Er\u00b7den\u00b7Rund", "?", "Voll", "Un\u00b7lust", "und", "voll", "Wust", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PDS", "NN", "$.", "ADJD", "NN", "KON", "ADJD", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Im Himmel ist allein zu suchen wahre Lust.", "tokens": ["Im", "Him\u00b7mel", "ist", "al\u00b7lein", "zu", "su\u00b7chen", "wah\u00b7re", "Lust", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VAFIN", "ADV", "PTKZU", "VVINF", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.86": {"line.1": {"text": "Wir haben schlimme Zeit/ ist die gemeine Klage/", "tokens": ["Wir", "ha\u00b7ben", "schlim\u00b7me", "Zeit", "/", "ist", "die", "ge\u00b7mei\u00b7ne", "Kla\u00b7ge", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJA", "NN", "$(", "VAFIN", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Doch schmiedet ihm der Mensch nur selber seine Plage;", "tokens": ["Doch", "schmie\u00b7det", "ihm", "der", "Mensch", "nur", "sel\u00b7ber", "sei\u00b7ne", "Pla\u00b7ge", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ART", "NN", "ADV", "ADV", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ist Zeit und Nahrung schlecht/ wo wir nicht besser werden", "tokens": ["Ist", "Zeit", "und", "Nah\u00b7rung", "schlecht", "/", "wo", "wir", "nicht", "bes\u00b7ser", "wer\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "NN", "KON", "NN", "VVFIN", "$(", "PWAV", "PPER", "PTKNEG", "ADJD", "VAINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So findet sich gewi\u00df nicht Besserung auff Erden!", "tokens": ["So", "fin\u00b7det", "sich", "ge\u00b7wi\u00df", "nicht", "Bes\u00b7se\u00b7rung", "auff", "Er\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "ADV", "PTKNEG", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.87": {"line.1": {"text": "Ich lie\u00df mich weiter ein in Wirthschafft und Gesch\u00e4ffte/", "tokens": ["Ich", "lie\u00df", "mich", "wei\u00b7ter", "ein", "in", "Wirth\u00b7schafft", "und", "Ge\u00b7sch\u00e4ff\u00b7te", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ART", "APPR", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Besegne Gott mein Thun/ und mehre meine Kr\u00e4ffte/", "tokens": ["Be\u00b7seg\u00b7ne", "Gott", "mein", "Thun", "/", "und", "meh\u00b7re", "mei\u00b7ne", "Kr\u00e4ff\u00b7te", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "PPOSAT", "NN", "$(", "KON", "PIAT", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wir bauen ohne dich nur H\u00e4user in den Sand/", "tokens": ["Wir", "bau\u00b7en", "oh\u00b7ne", "dich", "nur", "H\u00e4u\u00b7ser", "in", "den", "Sand", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPER", "ADV", "NN", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und schreiben was nicht taugt/ wo du nicht f\u00fchrst die Hand.", "tokens": ["Und", "schrei\u00b7ben", "was", "nicht", "taugt", "/", "wo", "du", "nicht", "f\u00fchrst", "die", "Hand", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PWS", "PTKNEG", "VVFIN", "$(", "PWAV", "PPER", "PTKNEG", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.88": {"line.1": {"text": "Ich gebe den Bescheid/ wer von mir wissen will", "tokens": ["Ich", "ge\u00b7be", "den", "Be\u00b7scheid", "/", "wer", "von", "mir", "wis\u00b7sen", "will"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "$(", "PWS", "APPR", "PPER", "VVINF", "VMFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Was treu und redlich sey: Der Bo\u00dfheit Spiel und Ziel/", "tokens": ["Was", "treu", "und", "red\u00b7lich", "sey", ":", "Der", "Bo\u00df\u00b7heit", "Spiel", "und", "Ziel", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADJD", "KON", "ADJD", "VAFIN", "$.", "ART", "NN", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Doch wenn besch\u00e4mtes Falsch sein eigen Gifft mu\u00df saugen/", "tokens": ["Doch", "wenn", "be\u00b7sch\u00e4m\u00b7tes", "Falsch", "sein", "ei\u00b7gen", "Gifft", "mu\u00df", "sau\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ADJA", "NN", "PPOSAT", "ADJA", "NN", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Geht jenes iederman auffrichtig unter Augen.", "tokens": ["Geht", "je\u00b7nes", "ie\u00b7der\u00b7man", "auf\u00b7frich\u00b7tig", "un\u00b7ter", "Au\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PDS", "PIS", "ADJD", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.89": {"line.1": {"text": "Die treue Schwester/ und der wohlgerathne Schwager", "tokens": ["Die", "treu\u00b7e", "Schwes\u00b7ter", "/", "und", "der", "wohl\u00b7ge\u00b7rath\u00b7ne", "Schwa\u00b7ger"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$(", "KON", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Begr\u00fcssen fast zugleich das schwartze Todten-Lager/", "tokens": ["Be\u00b7gr\u00fcs\u00b7sen", "fast", "zu\u00b7gleich", "das", "schwart\u00b7ze", "Tod\u00b7ten\u00b7La\u00b7ger", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ADV", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Mich schmerzt/ da\u00df beyder Fall in Monats Frist geschehn/", "tokens": ["Mich", "schmerzt", "/", "da\u00df", "bey\u00b7der", "Fall", "in", "Mo\u00b7nats", "Frist", "ge\u00b7schehn", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$(", "KOUS", "PIAT", "NN", "APPR", "NN", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Gedult! Auff einmahl folgt ein freudigs Wiedersehn.", "tokens": ["Ge\u00b7dult", "!", "Auff", "ein\u00b7mahl", "folgt", "ein", "freu\u00b7digs", "Wie\u00b7der\u00b7sehn", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "APPR", "ADV", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.90": {"line.1": {"text": "Neyd/ tobe wie du wilt/ wenn ich nicht heucheln kan/", "tokens": ["Neyd", "/", "to\u00b7be", "wie", "du", "wilt", "/", "wenn", "ich", "nicht", "heu\u00b7cheln", "kan", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "VVFIN", "KOKOM", "PPER", "VMFIN", "$(", "KOUS", "PPER", "PTKNEG", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Di\u00df geht wohl f\u00fcr der Welt/ doch dort f\u00fcr Gott nicht an/", "tokens": ["Di\u00df", "geht", "wohl", "f\u00fcr", "der", "Welt", "/", "doch", "dort", "f\u00fcr", "Gott", "nicht", "an", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "APPR", "ART", "NN", "$(", "ADV", "ADV", "APPR", "NN", "PTKNEG", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Es ist der beste Ruhm auff kurtzer Grab-Schrifft lesen:", "tokens": ["Es", "ist", "der", "bes\u00b7te", "Ruhm", "auff", "kurt\u00b7zer", "Grab\u00b7Schrifft", "le\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der ist im Vaterland ein ehrlich Mann gewesen.", "tokens": ["Der", "ist", "im", "Va\u00b7ter\u00b7land", "ein", "ehr\u00b7lich", "Mann", "ge\u00b7we\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "APPRART", "NN", "ART", "ADJD", "NN", "VAPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.91": {"line.1": {"text": "Ich lie\u00df mich f\u00fcr das Land berufft/ nach Hofe brauchen/", "tokens": ["Ich", "lie\u00df", "mich", "f\u00fcr", "das", "Land", "be\u00b7rufft", "/", "nach", "Ho\u00b7fe", "brau\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "ART", "NN", "VVFIN", "$(", "APPR", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und sah' unfern von Wien der Tartarn Feuer rauchen/", "tokens": ["Und", "sah'", "un\u00b7fern", "von", "Wi\u00b7en", "der", "Tar\u00b7tarn", "Feu\u00b7er", "rau\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "APPR", "NE", "ART", "NN", "NN", "VVFIN", "$("], "meter": "--+--+--+-+-+-", "measure": "anapaest.tri.plus"}, "line.3": {"text": "Gott ri\u00df mich aus Gefahr/ auch aus des Todes Scho\u00df/", "tokens": ["Gott", "ri\u00df", "mich", "aus", "Ge\u00b7fahr", "/", "auch", "aus", "des", "To\u00b7des", "Scho\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PRF", "APPR", "NN", "$(", "ADV", "APPR", "ART", "NN", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Den ich zu Hause bald gefunden h\u00e4tte lo\u00df.", "tokens": ["Den", "ich", "zu", "Hau\u00b7se", "bald", "ge\u00b7fun\u00b7den", "h\u00e4t\u00b7te", "lo\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "APPR", "NN", "ADV", "VVPP", "VAFIN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.92": {"line.1": {"text": "Man hie\u00df mich noch einmahl an Donau-Strom verreisen/", "tokens": ["Man", "hie\u00df", "mich", "noch", "ein\u00b7mahl", "an", "Do\u00b7nau\u00b7Strom", "ver\u00b7rei\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "ADV", "ADV", "APPR", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Dem grossen Leopold den Landes-Kummer weisen/", "tokens": ["Dem", "gros\u00b7sen", "Leo\u00b7pold", "den", "Lan\u00b7des\u00b7Kum\u00b7mer", "wei\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NE", "ART", "NN", "VVINF", "$("], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Ist was gerichtet aus/ so hat es Gott gethan:", "tokens": ["Ist", "was", "ge\u00b7rich\u00b7tet", "aus", "/", "so", "hat", "es", "Gott", "ge\u00b7than", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "VVPP", "APPR", "$(", "ADV", "VAFIN", "PPER", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Was ist es da\u00df der Mensch durch seine Klugheit kan.", "tokens": ["Was", "ist", "es", "da\u00df", "der", "Mensch", "durch", "sei\u00b7ne", "Klug\u00b7heit", "kan", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "KOUS", "ART", "NN", "APPR", "PPOSAT", "NN", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.93": {"line.1": {"text": "Des treuen Schw\u00e4hers Gunst/ der mich als Sohn geliebt/", "tokens": ["Des", "treu\u00b7en", "Schw\u00e4\u00b7hers", "Gunst", "/", "der", "mich", "als", "Sohn", "ge\u00b7liebt", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "$(", "PRELS", "PPER", "KOUS", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die mir der Tod entzeucht/ macht mich als Sohn betr\u00fcbt.", "tokens": ["Die", "mir", "der", "Tod", "ent\u00b7zeucht", "/", "macht", "mich", "als", "Sohn", "be\u00b7tr\u00fcbt", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ART", "NN", "VVPP", "$(", "VVFIN", "PPER", "KOUS", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "So fallen nach und nach gemeiner Wohlfart Mauren/", "tokens": ["So", "fal\u00b7len", "nach", "und", "nach", "ge\u00b7mei\u00b7ner", "Wohl\u00b7fart", "Mau\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "KON", "APPR", "ADJA", "NN", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ich habe f\u00fcr das Land und auch f\u00fcr mich zu trauren.", "tokens": ["Ich", "ha\u00b7be", "f\u00fcr", "das", "Land", "und", "auch", "f\u00fcr", "mich", "zu", "trau\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "ART", "NN", "KON", "ADV", "APPR", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.94": {"line.1": {"text": "Die lezte Schwester stirbt/ ich halte noch allein", "tokens": ["Die", "lez\u00b7te", "Schwes\u00b7ter", "stirbt", "/", "ich", "hal\u00b7te", "noch", "al\u00b7lein"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$(", "PPER", "VVFIN", "ADV", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Hier Hau\u00df/ so lang' es wird des H\u00f6chsten Wille seyn/", "tokens": ["Hier", "Hau\u00df", "/", "so", "lang'", "es", "wird", "des", "H\u00f6chs\u00b7ten", "Wil\u00b7le", "seyn", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "$(", "ADV", "ADV", "PPER", "VAFIN", "ART", "ADJA", "NN", "VAINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ich bin zum lezten auch in dieses Leben kommen/", "tokens": ["Ich", "bin", "zum", "lez\u00b7ten", "auch", "in", "die\u00b7ses", "Le\u00b7ben", "kom\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPRART", "ADJA", "ADV", "APPR", "PDAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Gott hat uns mehrentheils der Reyhe nach genommen.", "tokens": ["Gott", "hat", "uns", "meh\u00b7ren\u00b7theils", "der", "Rey\u00b7he", "nach", "ge\u00b7nom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "ADV", "ART", "NN", "APPR", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.95": {"line.1": {"text": "Gott segnet Hau\u00df und Hoff/ man neydet mein Gel\u00fccke/", "tokens": ["Gott", "seg\u00b7net", "Hau\u00df", "und", "Hoff", "/", "man", "ney\u00b7det", "mein", "Ge\u00b7l\u00fc\u00b7cke", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "NN", "KON", "VVFIN", "$(", "PIS", "VVFIN", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wei\u00df aber nicht dabey/ wo mich der Schuh hindr\u00fccke/", "tokens": ["Wei\u00df", "a\u00b7ber", "nicht", "da\u00b7bey", "/", "wo", "mich", "der", "Schuh", "hin\u00b7dr\u00fc\u00b7cke", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PTKNEG", "PAV", "$(", "PWAV", "PPER", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Da\u00df wir der Eitelkeit zu viel nicht r\u00e4umen ein/", "tokens": ["Da\u00df", "wir", "der", "Ei\u00b7tel\u00b7keit", "zu", "viel", "nicht", "r\u00e4u\u00b7men", "ein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "APPR", "PIS", "PTKNEG", "VVFIN", "ART", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Mu\u00df stets ein spitzer Dorn mit eingemischet seyn.", "tokens": ["Mu\u00df", "stets", "ein", "spit\u00b7zer", "Dorn", "mit", "ein\u00b7ge\u00b7mi\u00b7schet", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "ART", "ADJA", "NN", "APPR", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.96": {"line.1": {"text": "Uns dr\u00fcckt der schwere Krieg im Beutel/ nicht im Lande/", "tokens": ["Uns", "dr\u00fcckt", "der", "schwe\u00b7re", "Krieg", "im", "Beu\u00b7tel", "/", "nicht", "im", "Lan\u00b7de", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "APPRART", "NN", "$(", "PTKNEG", "APPRART", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und dennoch schickt man sich so schlecht zu solchem Stande/", "tokens": ["Und", "den\u00b7noch", "schickt", "man", "sich", "so", "schlecht", "zu", "sol\u00b7chem", "Stan\u00b7de", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PIS", "PRF", "ADV", "ADJD", "APPR", "PIAT", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Man bauet/ kaufft und prahlt: Gott gebe da\u00df uns nicht", "tokens": ["Man", "bau\u00b7et", "/", "kaufft", "und", "prahlt", ":", "Gott", "ge\u00b7be", "da\u00df", "uns", "nicht"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "$(", "VVFIN", "KON", "VVFIN", "$.", "NN", "VVFIN", "KOUS", "PPER", "PTKNEG"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Zulezt bey vollem Ma\u00df/ als andern/ auch geschicht.", "tokens": ["Zu\u00b7lezt", "bey", "vol\u00b7lem", "Ma\u00df", "/", "als", "an\u00b7dern", "/", "auch", "ge\u00b7schicht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "APPR", "ADJA", "NN", "$(", "KOUS", "PIS", "$(", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.97": {"line.1": {"text": "Die Sorgen nehmen zu/ die Kr\u00e4ffte lassen nach/", "tokens": ["Die", "Sor\u00b7gen", "neh\u00b7men", "zu", "/", "die", "Kr\u00e4ff\u00b7te", "las\u00b7sen", "nach", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "PTKZU", "$(", "ART", "NN", "VVFIN", "APPR", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Es f\u00fchlet Leib und Geist manch stilles Ungemach/", "tokens": ["Es", "f\u00fch\u00b7let", "Leib", "und", "Geist", "manch", "stil\u00b7les", "Un\u00b7ge\u00b7mach", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "KON", "NN", "PIAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Di\u00df ist des H\u00f6chsten Zug/ so will uns Gott bey Zeiten", "tokens": ["Di\u00df", "ist", "des", "H\u00f6chs\u00b7ten", "Zug", "/", "so", "will", "uns", "Gott", "bey", "Zei\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "ART", "ADJA", "NN", "$(", "ADV", "VMFIN", "PPER", "NN", "APPR", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Vom Irrdschen abgewehnt/ zur Himmelfahrt bereiten.", "tokens": ["Vom", "Irrd\u00b7schen", "ab\u00b7ge\u00b7wehnt", "/", "zur", "Him\u00b7mel\u00b7fahrt", "be\u00b7rei\u00b7ten", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVPP", "$(", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.98": {"line.1": {"text": "Man f\u00fchret Sorg' und Flei\u00df das Seine wohl zu n\u00fctzen/", "tokens": ["Man", "f\u00fch\u00b7ret", "Sor\u00b7g'", "und", "Flei\u00df", "das", "Sei\u00b7ne", "wohl", "zu", "n\u00fct\u00b7zen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "NN", "KON", "NN", "ART", "PPOSAT", "ADV", "PTKZU", "VVINF", "$("], "meter": "-+-+--+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Wei\u00df aber doch nicht wer/ und wie ers wird besitzen;", "tokens": ["Wei\u00df", "a\u00b7ber", "doch", "nicht", "wer", "/", "und", "wie", "ers", "wird", "be\u00b7sit\u00b7zen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADV", "PTKNEG", "PWS", "$(", "KON", "PWAV", "PIS", "VAFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Das beste Sorgen ist/ um das zu seyn bem\u00fcht/", "tokens": ["Das", "bes\u00b7te", "Sor\u00b7gen", "ist", "/", "um", "das", "zu", "seyn", "be\u00b7m\u00fcht", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "$(", "APPR", "PDS", "PTKZU", "VAINF", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Was uns kein R\u00e4uber stielt und keine Zeit entzieht.", "tokens": ["Was", "uns", "kein", "R\u00e4u\u00b7ber", "stielt", "und", "kei\u00b7ne", "Zeit", "ent\u00b7zieht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "PIAT", "NN", "VVFIN", "KON", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.99": {"line.1": {"text": "Die Tochter wird verlobt: Gott/ Stiffter keuscher Ehen/", "tokens": ["Die", "Toch\u00b7ter", "wird", "ver\u00b7lobt", ":", "Gott", "/", "Stiff\u00b7ter", "keu\u00b7scher", "E\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVPP", "$.", "NN", "$(", "NN", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Verkn\u00fcpffe dieses Band mit selgem Wohlergehen/", "tokens": ["Ver\u00b7kn\u00fcpf\u00b7fe", "die\u00b7ses", "Band", "mit", "sel\u00b7gem", "Woh\u00b7ler\u00b7ge\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PDAT", "NN", "APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Dir selber ist bewust/ da\u00df ich auff keine Pracht", "tokens": ["Dir", "sel\u00b7ber", "ist", "be\u00b7wust", "/", "da\u00df", "ich", "auff", "kei\u00b7ne", "Pracht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "VAFIN", "ADJD", "$(", "KOUS", "PPER", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Noch Sch\u00e4tze dieser Welt/ wie izt der Brauch/ gedacht.", "tokens": ["Noch", "Sch\u00e4t\u00b7ze", "die\u00b7ser", "Welt", "/", "wie", "izt", "der", "Brauch", "/", "ge\u00b7dacht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "NN", "PDAT", "NN", "$(", "KOKOM", "ADV", "ART", "NN", "$(", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.100": {"line.1": {"text": "Wohin bringt unser Land die \u00fcberh\u00e4uffte Steuer?", "tokens": ["Wo\u00b7hin", "bringt", "un\u00b7ser", "Land", "die", "\u00fc\u00b7berh\u00b7\u00e4uff\u00b7te", "Steu\u00b7er", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPOSAT", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Zu trucknem Saltz und Brod: Doch ist auch di\u00df zu theuer.", "tokens": ["Zu", "truck\u00b7nem", "Saltz", "und", "Brod", ":", "Doch", "ist", "auch", "di\u00df", "zu", "theu\u00b7er", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "KON", "NN", "$.", "KON", "VAFIN", "ADV", "PDS", "PTKA", "ADJD", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Bey seiner Kleyhen-Br\u00fch ist der am besten dran/", "tokens": ["Bey", "sei\u00b7ner", "Kley\u00b7hen\u00b7Br\u00fch", "ist", "der", "am", "bes\u00b7ten", "dran", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VAFIN", "ART", "PTKA", "ADJD", "PAV", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der sich noch mit Gedult und Hoffnung speisen kan.", "tokens": ["Der", "sich", "noch", "mit", "Ge\u00b7dult", "und", "Hoff\u00b7nung", "spei\u00b7sen", "kan", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "ADV", "APPR", "NN", "KON", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.101": {"line.1": {"text": "Das alte Spr\u00fcchwort ist: Das Land ern\u00e4hrt die St\u00e4dte/", "tokens": ["Das", "al\u00b7te", "Spr\u00fcch\u00b7wort", "ist", ":", "Das", "Land", "er\u00b7n\u00e4hrt", "die", "St\u00e4d\u00b7te", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "$.", "ART", "NN", "VVFIN", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wenn izt der St\u00e4dte Geld nicht was zum Besten th\u00e4te/", "tokens": ["Wenn", "izt", "der", "St\u00e4d\u00b7te", "Geld", "nicht", "was", "zum", "Bes\u00b7ten", "th\u00e4\u00b7te", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "NN", "PTKNEG", "PRELS", "APPRART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "So w\u00fcrd erlegnes Land noch sich noch jen' ern\u00e4hren/", "tokens": ["So", "w\u00fcrd", "er\u00b7leg\u00b7nes", "Land", "noch", "sich", "noch", "jen'", "er\u00b7n\u00e4h\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADJA", "NN", "ADV", "PRF", "ADV", "PIS", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ach/ woll uns Fried und Brod der treue Gott bescheren.", "tokens": ["Ach", "/", "woll", "uns", "Fried", "und", "Brod", "der", "treu\u00b7e", "Gott", "be\u00b7sche\u00b7ren", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$(", "VMFIN", "PPER", "NN", "KON", "NN", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.102": {"line.1": {"text": "Es will sich allgemach zur Jahre Neige neigen/", "tokens": ["Es", "will", "sich", "all\u00b7ge\u00b7mach", "zur", "Jah\u00b7re", "Nei\u00b7ge", "nei\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PRF", "ADV", "APPRART", "NN", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ich mu\u00df mit schwerem Tritt auff neun und viertzig steigen/", "tokens": ["Ich", "mu\u00df", "mit", "schwe\u00b7rem", "Tritt", "auff", "neun", "und", "viert\u00b7zig", "stei\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPR", "ADJA", "NN", "APPR", "CARD", "KON", "CARD", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ein doppelt Stuffen-Jahr wird unbegl\u00fcckt geacht/", "tokens": ["Ein", "dop\u00b7pelt", "Stuf\u00b7fen\u00b7Jahr", "wird", "un\u00b7be\u00b7gl\u00fcckt", "ge\u00b7acht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "VAFIN", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Doch mehr die viele Schuld/ die wir bey Gott gemacht.", "tokens": ["Doch", "mehr", "die", "vie\u00b7le", "Schuld", "/", "die", "wir", "bey", "Gott", "ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "PIAT", "NN", "$(", "PRELS", "PPER", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.103": {"line.1": {"text": "Man stehet in der Welt nach Wind/ nach Rauch und Dunst/", "tokens": ["Man", "ste\u00b7het", "in", "der", "Welt", "nach", "Wind", "/", "nach", "Rauch", "und", "Dunst", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "APPR", "ART", "NN", "APPR", "NN", "$(", "APPR", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Verschertzet offt dabey des gr\u00f6sten Herren Gunst:", "tokens": ["Ver\u00b7schert\u00b7zet", "offt", "da\u00b7bey", "des", "gr\u00f6s\u00b7ten", "Her\u00b7ren", "Gunst", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PAV", "ART", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "La\u00df sich die stoltze Welt um Reich und Stelle schmeissen/", "tokens": ["La\u00df", "sich", "die", "stolt\u00b7ze", "Welt", "um", "Reich", "und", "Stel\u00b7le", "schmeis\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PRF", "ART", "ADJA", "NN", "APPR", "NN", "KON", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der beste Titul ist/ von Gottes Gnaden heissen.", "tokens": ["Der", "bes\u00b7te", "Ti\u00b7tul", "ist", "/", "von", "Got\u00b7tes", "Gna\u00b7den", "heis\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "$(", "APPR", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.104": {"line.1": {"text": "Die Helfft' ist hinterlegt mit Gott von hundert Jahren/", "tokens": ["Die", "Helfft'", "ist", "hin\u00b7ter\u00b7legt", "mit", "Gott", "von", "hun\u00b7dert", "Jah\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVPP", "APPR", "NN", "APPR", "CARD", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Gott la\u00df mich Gnad und Schutz auch dieses Jahr erfahren/", "tokens": ["Gott", "la\u00df", "mich", "Gnad", "und", "Schutz", "auch", "die\u00b7ses", "Jahr", "er\u00b7fah\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVIMP", "PPER", "NN", "KON", "NN", "ADV", "PDAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ach nimm/ weil ich dir izt nichts Bessers geben kan/", "tokens": ["Ach", "nimm", "/", "weil", "ich", "dir", "izt", "nichts", "Bes\u00b7sers", "ge\u00b7ben", "kan", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "VVIMP", "$(", "KOUS", "PPER", "PPER", "ADV", "PIAT", "NN", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+-+--", "measure": "unknown.measure.penta"}, "line.4": {"text": "Gereinigt durch dein Blutt/ des Alters H\u00e4fen an.", "tokens": ["Ge\u00b7rei\u00b7nigt", "durch", "dein", "Blutt", "/", "des", "Al\u00b7ters", "H\u00e4\u00b7fen", "an", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "APPR", "PPOSAT", "ADJD", "$(", "ART", "NN", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.105": {"line.1": {"text": "Verm\u00f6gen-Steuer hat Verm\u00f6gen abgezogen/", "tokens": ["Ver\u00b7m\u00f6\u00b7gen\u00b7Steu\u00b7er", "hat", "Ver\u00b7m\u00f6\u00b7gen", "ab\u00b7ge\u00b7zo\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Verm\u00f6gen ist im Rauch und Feuer auffgeflogen/", "tokens": ["Ver\u00b7m\u00f6\u00b7gen", "ist", "im", "Rauch", "und", "Feu\u00b7er", "auff\u00b7ge\u00b7flo\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "APPRART", "NN", "KON", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Gieb/ H\u00f6chster/ da\u00df ich recht in gutt und b\u00f6sen Tag/", "tokens": ["Gieb", "/", "H\u00f6chs\u00b7ter", "/", "da\u00df", "ich", "recht", "in", "gutt", "und", "b\u00f6\u00b7sen", "Tag", "/"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "$(", "NN", "$(", "KOUS", "PPER", "ADV", "APPR", "ADJD", "KON", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Den deine Hand mir schickt/ zu schicken mich vermag.", "tokens": ["Den", "dei\u00b7ne", "Hand", "mir", "schickt", "/", "zu", "schi\u00b7cken", "mich", "ver\u00b7mag", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "PPER", "VVFIN", "$(", "PTKZU", "VVINF", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.106": {"line.1": {"text": "Die Jahre z\u00e4hl ich nun nach Zahl der Jahres-Wochen/", "tokens": ["Die", "Jah\u00b7re", "z\u00e4hl", "ich", "nun", "nach", "Zahl", "der", "Jah\u00b7res\u00b7Wo\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADV", "APPR", "NN", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wie aber z\u00e4hl ich di\u00df/ was ich an Gott verbrochen?", "tokens": ["Wie", "a\u00b7ber", "z\u00e4hl", "ich", "di\u00df", "/", "was", "ich", "an", "Gott", "ver\u00b7bro\u00b7chen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "VVFIN", "PPER", "PDS", "$(", "PWS", "PPER", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "HeRR/ rechne nicht mit mir/ gieb da\u00df mir ieder Tag", "tokens": ["HeRR", "/", "rech\u00b7ne", "nicht", "mit", "mir", "/", "gieb", "da\u00df", "mir", "ie\u00b7der", "Tag"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NE", "$(", "VVFIN", "PTKNEG", "APPR", "PPER", "$(", "VVIMP", "KOUS", "PPER", "PIAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Zur Bu\u00df und Todes-Stund ein Wecker werden mag!", "tokens": ["Zur", "Bu\u00df", "und", "To\u00b7des\u00b7Stund", "ein", "We\u00b7cker", "wer\u00b7den", "mag", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "KON", "NN", "ART", "NN", "VAINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}