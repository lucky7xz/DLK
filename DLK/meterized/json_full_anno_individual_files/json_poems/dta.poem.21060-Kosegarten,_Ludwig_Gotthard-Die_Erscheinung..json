{"dta.poem.21060": {"metadata": {"author": {"name": "Kosegarten, Ludwig Gotthard", "birth": "N.A.", "death": "N.A."}, "title": "Die Erscheinung.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1798", "urn": "urn:nbn:de:kobv:b4-200905193300", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Schaurig ist die Nacht.               ", "tokens": ["Schau\u00b7rig", "ist", "die", "Nacht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "ART", "NN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.2": {"text": "Nasskalt haucht der Herbstwind", "tokens": ["Nass\u00b7kalt", "haucht", "der", "Herbst\u00b7wind"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "VVFIN", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "\u00dcber die falbe Stoppel.", "tokens": ["\u00dc\u00b7ber", "die", "fal\u00b7be", "Stop\u00b7pel", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.4": {"text": "M\u00fchsam rollt der Vollmond", "tokens": ["M\u00fch\u00b7sam", "rollt", "der", "Voll\u00b7mond"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "VVFIN", "ART", "NN"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.5": {"text": "Durch zerrissne Wolken", "tokens": ["Durch", "zer\u00b7riss\u00b7ne", "Wol\u00b7ken"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ADJA", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.6": {"text": "Seine Silberscheibe.", "tokens": ["Sei\u00b7ne", "Sil\u00b7ber\u00b7schei\u00b7be", "."], "token_info": ["word", "word", "punct"], "pos": ["PPOSAT", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.7": {"text": "Schaurig ist die Nacht!", "tokens": ["Schau\u00b7rig", "ist", "die", "Nacht", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "ART", "NN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.2": {"line.1": {"text": "Schaurig ist die Nacht.", "tokens": ["Schau\u00b7rig", "ist", "die", "Nacht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "ART", "NN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.2": {"text": "Wie heult es auf der Hayde!", "tokens": ["Wie", "heult", "es", "auf", "der", "Hay\u00b7de", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Wie pfeift es durch die Stoppel!", "tokens": ["Wie", "pfeift", "es", "durch", "die", "Stop\u00b7pel", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Wie sausen die Tannen!", "tokens": ["Wie", "sau\u00b7sen", "die", "Tan\u00b7nen", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "ART", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.5": {"text": "Wie flisterts im Haselbusch!", "tokens": ["Wie", "flis\u00b7terts", "im", "Ha\u00b7sel\u00b7busch", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "APPRART", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Schaurig ist die Nacht.", "tokens": ["Schau\u00b7rig", "ist", "die", "Nacht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "ART", "NN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.3": {"line.1": {"text": "Warum str\u00e4ubt sich mein Haar?", "tokens": ["Wa\u00b7rum", "str\u00e4ubt", "sich", "mein", "Haar", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PRF", "PPOSAT", "NN", "$."], "meter": "--+--+", "measure": "anapaest.di.plus"}, "line.2": {"text": "Warum sch\u00fcttelt mich Grauen?", "tokens": ["Wa\u00b7rum", "sch\u00fct\u00b7telt", "mich", "Grau\u00b7en", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "NN", "$."], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "Ists nur Bl\u00e4ttergeflister,", "tokens": ["Ists", "nur", "Bl\u00e4t\u00b7ter\u00b7ge\u00b7flis\u00b7ter", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "ADV", "NN", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.4": {"text": "Was die Haseln durchschwirrt?", "tokens": ["Was", "die", "Ha\u00b7seln", "durch\u00b7schwirrt", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "NN", "VVPP", "$."], "meter": "--+--+", "measure": "anapaest.di.plus"}, "line.5": {"text": "Ists nur S\u00e4useln der Tangeln,", "tokens": ["Ists", "nur", "S\u00e4u\u00b7seln", "der", "Tan\u00b7geln", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "NN", "ART", "NN", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.6": {"text": "Was die Tannen durchschwirrt?", "tokens": ["Was", "die", "Tan\u00b7nen", "durch\u00b7schwirrt", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "NN", "VVFIN", "$."], "meter": "--+--+", "measure": "anapaest.di.plus"}}, "stanza.4": {"line.1": {"text": "Schau!", "tokens": ["Schau", "!"], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "+", "measure": "single.up"}, "line.2": {"text": "Am fernen H\u00fcgel", "tokens": ["Am", "fer\u00b7nen", "H\u00fc\u00b7gel"], "token_info": ["word", "word", "word"], "pos": ["APPRART", "ADJA", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.3": {"text": "Hebt sichs, wie Flamme,", "tokens": ["Hebt", "sichs", ",", "wie", "Flam\u00b7me", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "$,", "PWAV", "NN", "$,"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "Flattert \u00fcber die Hayde;", "tokens": ["Flat\u00b7tert", "\u00fc\u00b7ber", "die", "Hay\u00b7de", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.5": {"text": "Wandelt n\u00e4her im Nachthauch \u2014", "tokens": ["Wan\u00b7delt", "n\u00e4\u00b7her", "im", "Nacht\u00b7hauch"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "APPRART", "NN", "$("], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.6": {"text": "Nachtsohn, wer bist du?", "tokens": ["Nacht\u00b7sohn", ",", "wer", "bist", "du", "?"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PWS", "VAFIN", "PPER", "$."], "meter": "++--+", "measure": "iambic.tri.chol"}, "line.7": {"text": "Bist du Mondengeflitter?", "tokens": ["Bist", "du", "Mon\u00b7den\u00b7ge\u00b7flit\u00b7ter", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "NN", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.8": {"text": "Bist du streifender Schatten?", "tokens": ["Bist", "du", "strei\u00b7fen\u00b7der", "Schat\u00b7ten", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADJA", "NN", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.9": {"text": "Bist du t\u00e4uschender Irrschein?", "tokens": ["Bist", "du", "t\u00e4u\u00b7schen\u00b7der", "Irr\u00b7schein", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADJA", "NN", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.10": {"text": "Rede, Nachtsohn, wer bist du?", "tokens": ["Re\u00b7de", ",", "Nacht\u00b7sohn", ",", "wer", "bist", "du", "?"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "PWS", "VAFIN", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "\u201eund kennet Telynhard, des Liedes Sohn,", "tokens": ["\u201e", "und", "ken\u00b7net", "Te\u00b7lyn\u00b7hard", ",", "des", "Lie\u00b7des", "Sohn", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "KON", "VVFIN", "NE", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Nicht Elwill mehr, den fr\u00fchgewelkten J\u00fcngling?", "tokens": ["Nicht", "El\u00b7will", "mehr", ",", "den", "fr\u00fch\u00b7ge\u00b7welk\u00b7ten", "J\u00fcng\u00b7ling", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "NE", "ADV", "$,", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Der Neumond sah mich bl\u00fchn in meiner Kraft,", "tokens": ["Der", "Neu\u00b7mond", "sah", "mich", "bl\u00fchn", "in", "mei\u00b7ner", "Kraft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Der Halbmond flimmert' auf mein Sterbelager,", "tokens": ["Der", "Halb\u00b7mond", "flim\u00b7mert'", "auf", "mein", "Ster\u00b7be\u00b7la\u00b7ger", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Noch weint der Vollmond auf mein frisches Grab \u2014", "tokens": ["Noch", "weint", "der", "Voll\u00b7mond", "auf", "mein", "fri\u00b7sches", "Grab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPR", "PPOSAT", "ADJA", "NN", "$("], "meter": "-+-+---+-+", "measure": "zehnsilber"}, "line.6": {"text": "Und Telynhard, des Thr\u00e4nenliedes Sohn,", "tokens": ["Und", "Te\u00b7lyn\u00b7hard", ",", "des", "Thr\u00e4\u00b7nen\u00b7lie\u00b7des", "Sohn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "NE", "$,", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Der Gr\u00e4ber Freund, der Geister Liebling, kennet", "tokens": ["Der", "Gr\u00e4\u00b7ber", "Freund", ",", "der", "Geis\u00b7ter", "Lieb\u00b7ling", ",", "ken\u00b7net"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["ART", "NN", "NN", "$,", "ART", "NN", "NN", "$,", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Nicht Elwill mehr, den fr\u00fchgewelkten J\u00fcngling?\u201c", "tokens": ["Nicht", "El\u00b7will", "mehr", ",", "den", "fr\u00fch\u00b7ge\u00b7welk\u00b7ten", "J\u00fcng\u00b7ling", "?", "\u201c"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["PTKNEG", "NE", "ADV", "$,", "ART", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "Elwill, Elwill, bist du's?", "tokens": ["El\u00b7will", ",", "El\u00b7will", ",", "bist", "du's", "?"], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "NE", "$,", "VAFIN", "PIS", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Fr\u00fchgewelkter, woher", "tokens": ["Fr\u00fch\u00b7ge\u00b7welk\u00b7ter", ",", "wo\u00b7her"], "token_info": ["word", "punct", "word"], "pos": ["NN", "$,", "PWAV"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Rauscht dein einsamer Flug?", "tokens": ["Rauscht", "dein", "ein\u00b7sa\u00b7mer", "Flug", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Rede, Elwill, woher?", "tokens": ["Re\u00b7de", ",", "El\u00b7will", ",", "wo\u00b7her", "?"], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "NE", "$,", "PWAV", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}}, "stanza.7": {"line.1": {"text": "\u201evon jenem Lande komm' ich hergeschwebet,", "tokens": ["\u201e", "von", "je\u00b7nem", "Lan\u00b7de", "komm'", "ich", "her\u00b7ge\u00b7schwe\u00b7bet", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "PDAT", "NN", "VVFIN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Von welchem Kunde nie dem Staube scholl,", "tokens": ["Von", "wel\u00b7chem", "Kun\u00b7de", "nie", "dem", "Stau\u00b7be", "scholl", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PWAT", "NN", "ADV", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Von welchem Antwort nie den k\u00fchnen Frager", "tokens": ["Von", "wel\u00b7chem", "Ant\u00b7wort", "nie", "den", "k\u00fch\u00b7nen", "Fra\u00b7ger"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PWAT", "NN", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Rechtfertigte \u2014 drum frage, Telynhard,", "tokens": ["Recht\u00b7fer\u00b7tig\u00b7te", "drum", "fra\u00b7ge", ",", "Te\u00b7lyn\u00b7hard", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["VVFIN", "$(", "PAV", "VVFIN", "$,", "NE", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.5": {"text": "Nicht nach dem Lande mich, dem ich entschwebe.\u201c", "tokens": ["Nicht", "nach", "dem", "Lan\u00b7de", "mich", ",", "dem", "ich", "ent\u00b7schwe\u00b7be", ".", "\u201c"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["PTKNEG", "APPR", "ART", "NN", "PPER", "$,", "PRELS", "PPER", "VVFIN", "$.", "$("], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}}, "stanza.8": {"line.1": {"text": "Elwill, ist dir wohl", "tokens": ["El\u00b7will", ",", "ist", "dir", "wohl"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NE", "$,", "VAFIN", "PPER", "ADV"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.2": {"text": "In deinem fernen Lande?", "tokens": ["In", "dei\u00b7nem", "fer\u00b7nen", "Lan\u00b7de", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Deiner Tr\u00fcmmer wohl", "tokens": ["Dei\u00b7ner", "Tr\u00fcm\u00b7mer", "wohl"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "NN", "ADV"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.4": {"text": "In ihrer engen Klause?", "tokens": ["In", "ih\u00b7rer", "en\u00b7gen", "Klau\u00b7se", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "\u201eob nah, ob fern, ob hier, ob da, ob dort?", "tokens": ["\u201e", "ob", "nah", ",", "ob", "fern", ",", "ob", "hier", ",", "ob", "da", ",", "ob", "dort", "?"], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "KOUS", "ADJD", "$,", "KOUS", "ADJD", "$,", "KOUS", "ADV", "$,", "KOUS", "ADV", "$,", "KOUS", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Mag gleich dir gelten, Harfensohn \u2014 Doch wohl,", "tokens": ["Mag", "gleich", "dir", "gel\u00b7ten", ",", "Har\u00b7fen\u00b7sohn", "Doch", "wohl", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "PPER", "VVINF", "$,", "NN", "$(", "KON", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Wohl ist der Tr\u00fcmmer in der engen Klause,", "tokens": ["Wohl", "ist", "der", "Tr\u00fcm\u00b7mer", "in", "der", "en\u00b7gen", "Klau\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Viel wohler noch dem Fremdling, der verwiesen", "tokens": ["Viel", "woh\u00b7ler", "noch", "dem", "Fremd\u00b7ling", ",", "der", "ver\u00b7wie\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "ADJD", "ADV", "ART", "NN", "$,", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Aus seiner Heimath in der Tr\u00fcmmer hauste,", "tokens": ["Aus", "sei\u00b7ner", "Hei\u00b7math", "in", "der", "Tr\u00fcm\u00b7mer", "haus\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Viel wohler, Dichter, als es dein Gesang,", "tokens": ["Viel", "woh\u00b7ler", ",", "Dich\u00b7ter", ",", "als", "es", "dein", "Ge\u00b7sang", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "NN", "$,", "KOUS", "PPER", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Als deiner Fantasieen Adlerschwung,", "tokens": ["Als", "dei\u00b7ner", "Fan\u00b7ta\u00b7si\u00b7e\u00b7en", "Ad\u00b7ler\u00b7schwung", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "NN", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.8": {"text": "Als deines Flammenliedes Schwanenflug", "tokens": ["Als", "dei\u00b7nes", "Flam\u00b7men\u00b7lie\u00b7des", "Schwa\u00b7nen\u00b7flug"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Erfliegen mag. Viel wohler, Freund, ist mir.\u201c", "tokens": ["Er\u00b7flie\u00b7gen", "mag.", "Viel", "woh\u00b7ler", ",", "Freund", ",", "ist", "mir", ".", "\u201c"], "token_info": ["word", "abbreviation", "word", "word", "punct", "word", "punct", "word", "word", "punct", "punct"], "pos": ["NN", "NE", "ADV", "ADJD", "$,", "NN", "$,", "VAFIN", "PPER", "$.", "$("], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.10": {"line.1": {"text": "Elwill, ist dir helle,", "tokens": ["El\u00b7will", ",", "ist", "dir", "hel\u00b7le", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "VAFIN", "PPER", "ADJA", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Wo uns Dunkel h\u00fcllt?", "tokens": ["Wo", "uns", "Dun\u00b7kel", "h\u00fcllt", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "NN", "VVFIN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "Ist dir Wahrheit, Elwill,", "tokens": ["Ist", "dir", "Wahr\u00b7heit", ",", "El\u00b7will", ","], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["VAFIN", "PPER", "NN", "$,", "NE", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Was uns Wahrheit d\u00e4ucht?", "tokens": ["Was", "uns", "Wahr\u00b7heit", "d\u00e4ucht", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "NN", "VVFIN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.11": {"line.1": {"text": "\u201ewohl Manches, was dem eingekerkerten", "tokens": ["\u201e", "wohl", "Man\u00b7ches", ",", "was", "dem", "ein\u00b7ge\u00b7ker\u00b7ker\u00b7ten"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word"], "pos": ["$(", "ADV", "PIS", "$,", "PRELS", "ART", "ADJA"], "meter": "-+-+-+----", "measure": "unknown.measure.tri"}, "line.2": {"text": "Durch enge Gitter m\u00fchsam sp\u00e4henden,", "tokens": ["Durch", "en\u00b7ge", "Git\u00b7ter", "m\u00fch\u00b7sam", "sp\u00e4\u00b7hen\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ADJD", "VVINF", "$,"], "meter": "+--+-+-+--", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Durch weite Fernen \u00e4ngstlich horchenden,", "tokens": ["Durch", "wei\u00b7te", "Fer\u00b7nen", "\u00e4ngst\u00b7lich", "hor\u00b7chen\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Verwiesnen Geiste Blitz der Wahrheit d\u00e4uchte,", "tokens": ["Ver\u00b7wies\u00b7nen", "Geis\u00b7te", "Blitz", "der", "Wahr\u00b7heit", "d\u00e4uch\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Was Denker mit der Schl\u00fcsse Kettenringen,", "tokens": ["Was", "Den\u00b7ker", "mit", "der", "Schl\u00fcs\u00b7se", "Ket\u00b7ten\u00b7rin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "APPR", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Was Priesterwuth mit Bann und Beil und Holzstoss,", "tokens": ["Was", "Pries\u00b7ter\u00b7wuth", "mit", "Bann", "und", "Beil", "und", "Holz\u00b7stoss", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "APPR", "NN", "KON", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Was M\u00e4rtyrer mit hingebognem Nacken", "tokens": ["Was", "M\u00e4r\u00b7ty\u00b7rer", "mit", "hin\u00b7ge\u00b7bog\u00b7nem", "Na\u00b7cken"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Erwiesen, oder zu erweisen w\u00e4hnten,", "tokens": ["Er\u00b7wie\u00b7sen", ",", "o\u00b7der", "zu", "er\u00b7wei\u00b7sen", "w\u00e4hn\u00b7ten", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "KON", "PTKZU", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Ist dennoch Traum.", "tokens": ["Ist", "den\u00b7noch", "Traum", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "NN", "$."], "meter": "+--+", "measure": "iambic.di.chol"}, "line.10": {"text": "Wohl Manches, was der selbstzufriedne Gr\u00fcbler", "tokens": ["Wohl", "Man\u00b7ches", ",", "was", "der", "selbst\u00b7zu\u00b7fried\u00b7ne", "Gr\u00fcb\u00b7ler"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "PIS", "$,", "PRELS", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "Als Dichtertraum verlacht, der eitle Sp\u00f6tter", "tokens": ["Als", "Dich\u00b7ter\u00b7traum", "ver\u00b7lacht", ",", "der", "eit\u00b7le", "Sp\u00f6t\u00b7ter"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "NN", "VVPP", "$,", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Als Priesterm\u00e4hrchen h\u00f6hnt, der kalte Gr\u00fcbler", "tokens": ["Als", "Pries\u00b7ter\u00b7m\u00e4hr\u00b7chen", "h\u00f6hnt", ",", "der", "kal\u00b7te", "Gr\u00fcb\u00b7ler"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "NN", "VVFIN", "$,", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "Gar in der Unding' \u00f6de Nacht verbannt,", "tokens": ["Gar", "in", "der", "Un\u00b7ding'", "\u00f6\u00b7de", "Nacht", "ver\u00b7bannt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "Ist dennoch Wahrheit.", "tokens": ["Ist", "den\u00b7noch", "Wahr\u00b7heit", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "NN", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.15": {"text": "Eins ist mir helle, was mir dunkel war.", "tokens": ["Eins", "ist", "mir", "hel\u00b7le", ",", "was", "mir", "dun\u00b7kel", "war", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "ADJA", "$,", "PWS", "PPER", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.16": {"text": "Das Andre d\u00e4mmert mir nur noch. Das Dritte", "tokens": ["Das", "And\u00b7re", "d\u00e4m\u00b7mert", "mir", "nur", "noch", ".", "Das", "Drit\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PDS", "PIS", "VVFIN", "PPER", "ADV", "ADV", "$.", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.17": {"text": "Ist rabenschwarze Mitternacht noch immer.", "tokens": ["Ist", "ra\u00b7ben\u00b7schwar\u00b7ze", "Mit\u00b7ter\u00b7nacht", "noch", "im\u00b7mer", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJA", "NN", "ADV", "ADV", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.18": {"text": "Viel sind der langen Ewigkeit \u00c4onen.", "tokens": ["Viel", "sind", "der", "lan\u00b7gen", "E\u00b7wig\u00b7keit", "\u00c4\u00b7o\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.19": {"text": "Viel Zeit ist hier zu lernen. Vieles ist", "tokens": ["Viel", "Zeit", "ist", "hier", "zu", "ler\u00b7nen", ".", "Vie\u00b7les", "ist"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PIAT", "NN", "VAFIN", "ADV", "PTKZU", "VVINF", "$.", "PIS", "VAFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.20": {"text": "Dem ersten Seraph noch zu lernen \u00fcbrig.\u201c", "tokens": ["Dem", "ers\u00b7ten", "Se\u00b7raph", "noch", "zu", "ler\u00b7nen", "\u00fcb\u00b7rig", ".", "\u201c"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "PTKZU", "VVINF", "PTKVZ", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.12": {"line.1": {"text": "Elwill ist euch Tugend,", "tokens": ["El\u00b7will", "ist", "euch", "Tu\u00b7gend", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PPER", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Was uns Tugend d\u00e4ucht?", "tokens": ["Was", "uns", "Tu\u00b7gend", "d\u00e4ucht", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "NN", "VVFIN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "Wiegt mit Menschenwage", "tokens": ["Wiegt", "mit", "Men\u00b7schen\u00b7wa\u00b7ge"], "token_info": ["word", "word", "word"], "pos": ["VVFIN", "APPR", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Ihr des Menschen Werth?", "tokens": ["Ihr", "des", "Men\u00b7schen", "Werth", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "NN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.13": {"line.1": {"text": "\u201ewohl anders ist des staubverh\u00fclleten,", "tokens": ["\u201e", "wohl", "an\u00b7ders", "ist", "des", "staub\u00b7ver\u00b7h\u00fcl\u00b7le\u00b7ten", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "ADV", "VAFIN", "ART", "ADJA", "$,"], "meter": "-+-+-+-+--", "measure": "unknown.measure.tetra"}, "line.2": {"text": "Wohl anders des enth\u00fcllten Geistes Tugend;", "tokens": ["Wohl", "an\u00b7ders", "des", "ent\u00b7h\u00fcll\u00b7ten", "Geis\u00b7tes", "Tu\u00b7gend", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Doch tr\u00f6ste dich. Mit Menschenwage w\u00e4gen", "tokens": ["Doch", "tr\u00f6s\u00b7te", "dich", ".", "Mit", "Men\u00b7schen\u00b7wa\u00b7ge", "w\u00e4\u00b7gen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "$.", "APPR", "NN", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Den Werth der Menschen die gerechten G\u00f6tter.", "tokens": ["Den", "Werth", "der", "Men\u00b7schen", "die", "ge\u00b7rech\u00b7ten", "G\u00f6t\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Nach Einsicht richten sie, nach treugesuchter,", "tokens": ["Nach", "Ein\u00b7sicht", "rich\u00b7ten", "sie", ",", "nach", "treu\u00b7ge\u00b7such\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PPER", "$,", "APPR", "ADJA", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Nach heisserrungner, ernstbefolgter Einsicht,", "tokens": ["Nach", "heis\u00b7ser\u00b7rung\u00b7ner", ",", "ernst\u00b7be\u00b7folg\u00b7ter", "Ein\u00b7sicht", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ADJA", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "W\u00e4r gleich die Einsicht Irre \u2014 Telynhard,", "tokens": ["W\u00e4r", "gleich", "die", "Ein\u00b7sicht", "Ir\u00b7re", "Te\u00b7lyn\u00b7hard", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "NN", "$(", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Drum sey getrost, und nimmer lass zu forschen,", "tokens": ["Drum", "sey", "ge\u00b7trost", ",", "und", "nim\u00b7mer", "lass", "zu", "for\u00b7schen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "VVPP", "$,", "KON", "ADV", "VVFIN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Und nimmer lass zu lehren, was du forschtest,", "tokens": ["Und", "nim\u00b7mer", "lass", "zu", "leh\u00b7ren", ",", "was", "du", "forschtest", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PTKZU", "VVINF", "$,", "PWS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Und nimmer lass zu \u00fcben, was du lehrtest.\u201c", "tokens": ["Und", "nim\u00b7mer", "lass", "zu", "\u00fc\u00b7ben", ",", "was", "du", "lehr\u00b7test", ".", "\u201c"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ADV", "VVFIN", "PTKZU", "VVINF", "$,", "PWS", "PPER", "VVFIN", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.14": {"line.1": {"text": "Elwill, harrt Vergeltung", "tokens": ["El\u00b7will", ",", "harrt", "Ver\u00b7gel\u00b7tung"], "token_info": ["word", "punct", "word", "word"], "pos": ["NE", "$,", "VVFIN", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "In der Schatten Reich?", "tokens": ["In", "der", "Schat\u00b7ten", "Reich", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "$."], "meter": "--+-+", "measure": "anapaest.init"}, "line.3": {"text": "Spenden eure G\u00f6tter", "tokens": ["Spen\u00b7den", "eu\u00b7re", "G\u00f6t\u00b7ter"], "token_info": ["word", "word", "word"], "pos": ["NN", "PPOSAT", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Lohn und Strafen aus?", "tokens": ["Lohn", "und", "Stra\u00b7fen", "aus", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "PTKVZ", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.15": {"line.1": {"text": "\u201ebelehrung harret hier. Aus schlimmer Thaten", "tokens": ["\u201e", "be\u00b7leh\u00b7rung", "har\u00b7ret", "hier", ".", "Aus", "schlim\u00b7mer", "Tha\u00b7ten"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["$(", "ADJD", "VVFIN", "ADV", "$.", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Gleich schlimmen Folgen keimt des Bessern Ein-", "tokens": ["Gleich", "schlim\u00b7men", "Fol\u00b7gen", "keimt", "des", "Bes\u00b7sern", "Ein"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJA", "NN", "VVFIN", "ART", "NN", "TRUNC"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "sicht.", "tokens": ["sicht", "."], "token_info": ["word", "punct"], "pos": ["VVFIN", "$."], "meter": "+", "measure": "single.up"}, "line.4": {"text": "Des Bessern Einsicht knospt zur That des Bessern.", "tokens": ["Des", "Bes\u00b7sern", "Ein\u00b7sicht", "knospt", "zur", "That", "des", "Bes\u00b7sern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "APPRART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Der sch\u00f6nen Knosp' entbl\u00fchn des Wohlseyns", "tokens": ["Der", "sch\u00f6\u00b7nen", "Knosp'", "ent\u00b7bl\u00fchn", "des", "Wohl\u00b7seyns"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Halme,", "tokens": ["Hal\u00b7me", ","], "token_info": ["word", "punct"], "pos": ["NN", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.7": {"text": "Stets h\u00f6her, voller, dranger, k\u00f6rniger,", "tokens": ["Stets", "h\u00f6\u00b7her", ",", "vol\u00b7ler", ",", "dran\u00b7ger", ",", "k\u00f6r\u00b7ni\u00b7ger", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "ADJA", "$,", "ADJA", "$,", "ADJA", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Der Ewigkeiten weite Felder durch.", "tokens": ["Der", "E\u00b7wig\u00b7kei\u00b7ten", "wei\u00b7te", "Fel\u00b7der", "durch", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "So lohnen, strafen, so vergelten G\u00f6tter,", "tokens": ["So", "loh\u00b7nen", ",", "stra\u00b7fen", ",", "so", "ver\u00b7gel\u00b7ten", "G\u00f6t\u00b7ter", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVINF", "$,", "VVFIN", "$,", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Viel anders zwar, als eure Priester lehren,", "tokens": ["Viel", "an\u00b7ders", "zwar", ",", "als", "eu\u00b7re", "Pries\u00b7ter", "leh\u00b7ren", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "$,", "KOUS", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "Viel anders zwar, als eure Dichter singen.", "tokens": ["Viel", "an\u00b7ders", "zwar", ",", "als", "eu\u00b7re", "Dich\u00b7ter", "sin\u00b7gen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "$,", "KOUS", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.16": {"line.1": {"text": "Elwill, w\u00e4rmt auch Liebe", "tokens": ["El\u00b7will", ",", "w\u00e4rmt", "auch", "Lie\u00b7be"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NE", "$,", "VAFIN", "ADV", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Euer \u00f6des Reich?", "tokens": ["Eu\u00b7er", "\u00f6\u00b7des", "Reich", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "Weht auch Liebesodem", "tokens": ["Weht", "auch", "Lie\u00b7be\u00b7so\u00b7dem"], "token_info": ["word", "word", "word"], "pos": ["VVFIN", "ADV", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Durch die Schattenwelt?", "tokens": ["Durch", "die", "Schat\u00b7ten\u00b7welt", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.17": {"line.1": {"text": "\u201ewohl w\u00e4rmet Liebe auch die Schattenwelt;", "tokens": ["\u201e", "wohl", "w\u00e4r\u00b7met", "Lie\u00b7be", "auch", "die", "Schat\u00b7ten\u00b7welt", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VAFIN", "NN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Wohl haucht ihr Lebensathem Geister an.", "tokens": ["Wohl", "haucht", "ihr", "Le\u00b7ben\u00b7sa\u00b7them", "Geis\u00b7ter", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Doch jene arme Erdenliebe nicht,", "tokens": ["Doch", "je\u00b7ne", "ar\u00b7me", "Er\u00b7den\u00b7lie\u00b7be", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDAT", "ADJA", "NN", "PTKNEG", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Die durch der Formen sanfte Schwingungen,", "tokens": ["Die", "durch", "der", "For\u00b7men", "sanf\u00b7te", "Schwin\u00b7gun\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+--", "measure": "unknown.measure.tetra"}, "line.5": {"text": "Und durch der Farben holde Mischungen,", "tokens": ["Und", "durch", "der", "Far\u00b7ben", "hol\u00b7de", "Misc\u00b7hun\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Durch Umriss, F\u00fcll' und Bl\u00fcth' und Gluth geweckt,", "tokens": ["Durch", "Um\u00b7riss", ",", "F\u00fcll'", "und", "Bl\u00fcth'", "und", "Gluth", "ge\u00b7weckt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "KON", "NN", "KON", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Den Staub zu Staube zieht, dem Einzigen", "tokens": ["Den", "Staub", "zu", "Stau\u00b7be", "zieht", ",", "dem", "Ein\u00b7zi\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "APPR", "NN", "VVFIN", "$,", "ART", "NN"], "meter": "-+-+-+-+--", "measure": "unknown.measure.tetra"}, "line.8": {"text": "Sich eignet, und die ganze weite Welt", "tokens": ["Sich", "eig\u00b7net", ",", "und", "die", "gan\u00b7ze", "wei\u00b7te", "Welt"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PRF", "VVFIN", "$,", "KON", "ART", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Armselig in dem Einzigen vergisst \u2014", "tokens": ["Arm\u00b7se\u00b7lig", "in", "dem", "Ein\u00b7zi\u00b7gen", "ver\u00b7gisst"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "ART", "NN", "VVFIN", "$("], "meter": "+--+-+---+", "measure": "iambic.tetra.invert"}, "line.10": {"text": "Die arme enge Liebe wohnt nicht hier,", "tokens": ["Die", "ar\u00b7me", "en\u00b7ge", "Lie\u00b7be", "wohnt", "nicht", "hier", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "VVFIN", "PTKNEG", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Wohl aber jene reichre, edlere,", "tokens": ["Wohl", "a\u00b7ber", "je\u00b7ne", "reich\u00b7re", ",", "ed\u00b7le\u00b7re", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "ADV", "PDS", "VVFIN", "$,", "ADJA", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "Die nur dem All sich eignet, sich das All,", "tokens": ["Die", "nur", "dem", "All", "sich", "eig\u00b7net", ",", "sich", "das", "All", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ART", "NN", "PRF", "VVFIN", "$,", "PRF", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "Sich selig f\u00fchlt, nur in der Seligkeit", "tokens": ["Sich", "se\u00b7lig", "f\u00fchlt", ",", "nur", "in", "der", "Se\u00b7lig\u00b7keit"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PRF", "ADJD", "VVFIN", "$,", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "Des grossen Alls, und dessen Seligkeit", "tokens": ["Des", "gros\u00b7sen", "Alls", ",", "und", "des\u00b7sen", "Se\u00b7lig\u00b7keit"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "KON", "PRELAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.15": {"text": "Rastlos zu f\u00f6rdern, h\u00f6chste Wollust achtet.", "tokens": ["Rast\u00b7los", "zu", "f\u00f6r\u00b7dern", ",", "h\u00f6chs\u00b7te", "Wol\u00b7lust", "ach\u00b7tet", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "PTKZU", "VVINF", "$,", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.16": {"text": "Die Liebe kennen wir. Sie gastet nicht,               ", "tokens": ["Die", "Lie\u00b7be", "ken\u00b7nen", "wir", ".", "Sie", "gas\u00b7tet", "nicht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "$.", "PPER", "VVFIN", "PTKNEG", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.17": {"text": "Sie wohnt und hauset unter uns. Sie ist", "tokens": ["Sie", "wohnt", "und", "hau\u00b7set", "un\u00b7ter", "uns", ".", "Sie", "ist"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "APPR", "PPER", "$.", "PPER", "VAFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.18": {"text": "Bey uns daheim \u2014 Doch Telynhard, fahr wohl!", "tokens": ["Bey", "uns", "da\u00b7heim", "Doch", "Te\u00b7lyn\u00b7hard", ",", "fahr", "wohl", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PPER", "ADV", "$(", "KON", "NE", "$,", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.19": {"text": "Fahr wohl! Des Hades Zug entzeucht mich dir.", "tokens": ["Fahr", "wohl", "!", "Des", "Ha\u00b7des", "Zug", "ent\u00b7zeucht", "mich", "dir", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$.", "ART", "NN", "NN", "VVFIN", "PPER", "PPER", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.20": {"text": "Fahr wohl! und nimmer werde lass zu forschen,", "tokens": ["Fahr", "wohl", "!", "und", "nim\u00b7mer", "wer\u00b7de", "lass", "zu", "for\u00b7schen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$.", "KON", "ADV", "VAFIN", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.21": {"text": "Und nimmer lass zu lehren, was du forschtest,", "tokens": ["Und", "nim\u00b7mer", "lass", "zu", "leh\u00b7ren", ",", "was", "du", "forschtest", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PTKZU", "VVINF", "$,", "PWS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.22": {"text": "Und nimmer lass zu \u00fcben, was du lehrtest,", "tokens": ["Und", "nim\u00b7mer", "lass", "zu", "\u00fc\u00b7ben", ",", "was", "du", "lehr\u00b7test", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PTKZU", "VVINF", "$,", "PWS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.23": {"text": "Bis dir der Wahrheit Urlicht strahlt, der hohen", "tokens": ["Bis", "dir", "der", "Wahr\u00b7heit", "Ur\u00b7licht", "strahlt", ",", "der", "ho\u00b7hen"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "PPER", "ART", "NN", "NN", "VVFIN", "$,", "ART", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.24": {"text": "Ursch\u00f6nheit Anschaun dich entz\u00fcckt, das Urgut", "tokens": ["Ur\u00b7sch\u00f6n\u00b7heit", "An\u00b7schaun", "dich", "ent\u00b7z\u00fcckt", ",", "das", "Ur\u00b7gut"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["NN", "NN", "PPER", "VVFIN", "$,", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.25": {"text": "Aus seines Bechers reinem Wein dich tr\u00e4nkt \u2014", "tokens": ["Aus", "sei\u00b7nes", "Be\u00b7chers", "rei\u00b7nem", "Wein", "dich", "tr\u00e4nkt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADJA", "NN", "PPER", "VVFIN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.26": {"text": "Fahr wohl! Ich scheide. Denke mein! Fahr wohl!\u201c", "tokens": ["Fahr", "wohl", "!", "Ich", "schei\u00b7de", ".", "Den\u00b7ke", "mein", "!", "Fahr", "wohl", "!", "\u201c"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["ADV", "ADV", "$.", "PPER", "VVFIN", "$.", "NN", "PPOSAT", "$.", "NN", "ADV", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.18": {"line.1": {"text": "Fahr wohl! Fahr wohl!", "tokens": ["Fahr", "wohl", "!", "Fahr", "wohl", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ADV", "$.", "NN", "ADV", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.2": {"text": "Sch\u00f6n ist dein Scheiden,", "tokens": ["Sch\u00f6n", "ist", "dein", "Schei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Im Blitz des Mondes,", "tokens": ["Im", "Blitz", "des", "Mon\u00b7des", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.4": {"text": "Im Hauch der Nacht.", "tokens": ["Im", "Hauch", "der", "Nacht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.5": {"text": "Fahr wohl! Fahr wohl!", "tokens": ["Fahr", "wohl", "!", "Fahr", "wohl", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ADV", "$.", "NN", "ADV", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.19": {"line.1": {"text": "Dir strahlt der Wahrheit Urlicht.", "tokens": ["Dir", "strahlt", "der", "Wahr\u00b7heit", "Ur\u00b7licht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Dir gl\u00e4nzt das hohe Ursch\u00f6n.", "tokens": ["Dir", "gl\u00e4nzt", "das", "ho\u00b7he", "Ur\u00b7sch\u00f6n", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Dich tr\u00e4nkt des ewgen Urguts", "tokens": ["Dich", "tr\u00e4nkt", "des", "ew\u00b7gen", "Ur\u00b7guts"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "Goldener Becher \u2014", "tokens": ["Gol\u00b7de\u00b7ner", "Be\u00b7cher"], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$("], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.5": {"text": "Fahr wohl! Fahr wohl!", "tokens": ["Fahr", "wohl", "!", "Fahr", "wohl", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ADV", "$.", "NN", "ADV", "$."], "meter": "-+-+", "measure": "iambic.di"}}}}}