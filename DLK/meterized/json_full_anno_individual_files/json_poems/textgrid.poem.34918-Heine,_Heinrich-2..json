{"textgrid.poem.34918": {"metadata": {"author": {"name": "Heine, Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "2.", "genre": "verse", "period": "N.A.", "pub_year": 1826, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Nach des Kampfes Schreckenstag,", "tokens": ["Nach", "des", "Kamp\u00b7fes", "Schre\u00b7ckens\u00b7tag", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Kommt die Spuknacht des Triumphes;", "tokens": ["Kommt", "die", "Spuk\u00b7nacht", "des", "Tri\u00b7um\u00b7phes", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Hunderttausend Freudenlampen", "tokens": ["Hun\u00b7dert\u00b7tau\u00b7send", "Freu\u00b7den\u00b7lam\u00b7pen"], "token_info": ["word", "word"], "pos": ["CARD", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Lodern auf in Mexiko.", "tokens": ["Lo\u00b7dern", "auf", "in", "Me\u00b7xi\u00b7ko", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "APPR", "NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Hunderttausend Freudenlampen,", "tokens": ["Hun\u00b7dert\u00b7tau\u00b7send", "Freu\u00b7den\u00b7lam\u00b7pen", ","], "token_info": ["word", "word", "punct"], "pos": ["CARD", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Waldharzfackeln, Pechkranzfeuer,", "tokens": ["Wald\u00b7harz\u00b7fa\u00b7ckeln", ",", "Pech\u00b7kranz\u00b7feu\u00b7er", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Werfen grell ihr Tageslicht", "tokens": ["Wer\u00b7fen", "grell", "ihr", "Ta\u00b7ges\u00b7licht"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "ADJD", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Auf Pal\u00e4ste, G\u00f6tterhallen,", "tokens": ["Auf", "Pa\u00b7l\u00e4s\u00b7te", ",", "G\u00f6t\u00b7ter\u00b7hal\u00b7len", ","], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Gildenh\u00e4user und zumal", "tokens": ["Gil\u00b7den\u00b7h\u00e4u\u00b7ser", "und", "zu\u00b7mal"], "token_info": ["word", "word", "word"], "pos": ["NE", "KON", "KOUS"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Auf den Tempel Vitzliputzlis,", "tokens": ["Auf", "den", "Tem\u00b7pel", "Vitz\u00b7li\u00b7putz\u00b7lis", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NE", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "G\u00f6tzenburg von rotem Backstein,", "tokens": ["G\u00f6t\u00b7zen\u00b7burg", "von", "ro\u00b7tem", "Back\u00b7stein", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Seltsam mahnend an \u00e4gyptisch,", "tokens": ["Selt\u00b7sam", "mah\u00b7nend", "an", "\u00e4\u00b7gypt\u00b7isch", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "ADJD", "APPR", "ADJD", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.4": {"line.1": {"text": "Babylonisch und assyrisch", "tokens": ["Ba\u00b7by\u00b7lo\u00b7nisch", "und", "as\u00b7sy\u00b7risch"], "token_info": ["word", "word", "word"], "pos": ["NE", "KON", "ADJD"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Kolossalen Bauwerkmonstren,", "tokens": ["Ko\u00b7los\u00b7sa\u00b7len", "Bau\u00b7werk\u00b7monst\u00b7ren", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Die wir schauen auf den Bildern", "tokens": ["Die", "wir", "schau\u00b7en", "auf", "den", "Bil\u00b7dern"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "VVFIN", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Unsers Briten Henri Martin.", "tokens": ["Un\u00b7sers", "Bri\u00b7ten", "Hen\u00b7ri", "Mar\u00b7tin", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "NE", "NE", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Ja, das sind dieselben breiten", "tokens": ["Ja", ",", "das", "sind", "die\u00b7sel\u00b7ben", "brei\u00b7ten"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["PTKANT", "$,", "PDS", "VAFIN", "PDAT", "ADJA"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Rampentreppen, also breit,", "tokens": ["Ram\u00b7pen\u00b7trep\u00b7pen", ",", "al\u00b7so", "breit", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "ADV", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df dort auf und nieder wallen", "tokens": ["Da\u00df", "dort", "auf", "und", "nie\u00b7der", "wal\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "PTKVZ", "KON", "PTKVZ", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Viele tausend Mexikaner,", "tokens": ["Vie\u00b7le", "tau\u00b7send", "Me\u00b7xi\u00b7ka\u00b7ner", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PIAT", "CARD", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "W\u00e4hrend auf den Stufen lagern", "tokens": ["W\u00e4h\u00b7rend", "auf", "den", "Stu\u00b7fen", "la\u00b7gern"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "APPR", "ART", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Rottenweis die wilden Krieger,", "tokens": ["Rot\u00b7ten\u00b7weis", "die", "wil\u00b7den", "Krie\u00b7ger", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Welche lustig bankettieren,", "tokens": ["Wel\u00b7che", "lus\u00b7tig", "ban\u00b7ket\u00b7tie\u00b7ren", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PWS", "ADJD", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Hochberauscht von Sieg und Palmwein.", "tokens": ["Hoch\u00b7be\u00b7rauscht", "von", "Sieg", "und", "Palm\u00b7wein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "KON", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Diese Rampentreppen leiten,", "tokens": ["Die\u00b7se", "Ram\u00b7pen\u00b7trep\u00b7pen", "lei\u00b7ten", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PDAT", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wie ein Zickzack, nach der Plattform,", "tokens": ["Wie", "ein", "Zick\u00b7zack", ",", "nach", "der", "Platt\u00b7form", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "$,", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Einem balustradenart'gen", "tokens": ["Ei\u00b7nem", "ba\u00b7lus\u00b7tra\u00b7den\u00b7art'\u00b7gen"], "token_info": ["word", "word"], "pos": ["ART", "NN"], "meter": "+---+-+-", "measure": "dactylic.init"}, "line.4": {"text": "Ungeheuern Tempeldach.", "tokens": ["Un\u00b7ge\u00b7heu\u00b7ern", "Tem\u00b7pel\u00b7dach", "."], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Dort auf seinem Thronaltar", "tokens": ["Dort", "auf", "sei\u00b7nem", "Thro\u00b7nal\u00b7tar"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Sitzt der gro\u00dfe Vitzliputzli,", "tokens": ["Sitzt", "der", "gro\u00b7\u00dfe", "Vitz\u00b7li\u00b7putz\u00b7li", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Mexikos blutd\u00fcrst'ger Kriegsgott.", "tokens": ["Me\u00b7xi\u00b7kos", "blut\u00b7d\u00fcr\u00b7st'\u00b7ger", "Kriegs\u00b7gott", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Ist ein b\u00f6ses Unget\u00fcm,", "tokens": ["Ist", "ein", "b\u00f6\u00b7ses", "Un\u00b7ge\u00b7t\u00fcm", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Doch sein \u00c4u\u00dfres ist so putzig,", "tokens": ["Doch", "sein", "\u00c4u\u00df\u00b7res", "ist", "so", "put\u00b7zig", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VAFIN", "ADV", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "So verschn\u00f6rkelt und so kindisch,", "tokens": ["So", "ver\u00b7schn\u00f6r\u00b7kelt", "und", "so", "kin\u00b7disch", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "KON", "ADV", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df er trotz des innern Grausens", "tokens": ["Da\u00df", "er", "trotz", "des", "in\u00b7nern", "Grau\u00b7sens"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Dennoch unsre Lachlust kitzelt \u2013", "tokens": ["Den\u00b7noch", "uns\u00b7re", "Lach\u00b7lust", "kit\u00b7zelt", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "VVFIN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Und bei seinem Anblick denken", "tokens": ["Und", "bei", "sei\u00b7nem", "An\u00b7blick", "den\u00b7ken"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "PPOSAT", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wir zu gleicher Zeit etwa", "tokens": ["Wir", "zu", "glei\u00b7cher", "Zeit", "et\u00b7wa"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "APPR", "ADJA", "NN", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "An den blassen Tod von Basel", "tokens": ["An", "den", "blas\u00b7sen", "Tod", "von", "Ba\u00b7sel"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "APPR", "NE"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Und an Br\u00fcssels Mankepi\u00df.", "tokens": ["Und", "an", "Br\u00fcs\u00b7sels", "Man\u00b7ke\u00b7pi\u00df", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NE", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "An des Gottes Seite stehen", "tokens": ["An", "des", "Got\u00b7tes", "Sei\u00b7te", "ste\u00b7hen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Rechts die Laien, links die Pfaffen;", "tokens": ["Rechts", "die", "Lai\u00b7en", ",", "links", "die", "Pfaf\u00b7fen", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "$,", "ADV", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Im Ornat von bunten Federn", "tokens": ["Im", "Or\u00b7nat", "von", "bun\u00b7ten", "Fe\u00b7dern"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "APPR", "ADJA", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Spreizt sich heut die Klerisei.", "tokens": ["Spreizt", "sich", "heut", "die", "Kle\u00b7ri\u00b7sei", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ADV", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Auf des Altars Marmorstufen", "tokens": ["Auf", "des", "Al\u00b7tars", "Mar\u00b7mor\u00b7stu\u00b7fen"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Hockt ein hundertj\u00e4hrig M\u00e4nnlein,", "tokens": ["Hockt", "ein", "hun\u00b7dert\u00b7j\u00e4h\u00b7rig", "M\u00e4nn\u00b7lein", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJD", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Ohne Haar an Kinn und Sch\u00e4del;", "tokens": ["Oh\u00b7ne", "Haar", "an", "Kinn", "und", "Sch\u00e4\u00b7del", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "NN", "KON", "NE", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Tr\u00e4gt ein scharlach Kamis\u00f6lchen.", "tokens": ["Tr\u00e4gt", "ein", "schar\u00b7lach", "Ka\u00b7mi\u00b7s\u00f6l\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Dieses ist der Opferpriester,", "tokens": ["Die\u00b7ses", "ist", "der", "Op\u00b7fer\u00b7pries\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und er wetzet seine Messer,", "tokens": ["Und", "er", "wet\u00b7zet", "sei\u00b7ne", "Mes\u00b7ser", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wetzt sie l\u00e4chelnd, und er schielet", "tokens": ["Wetzt", "sie", "l\u00e4\u00b7chelnd", ",", "und", "er", "schie\u00b7let"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADJD", "$,", "KON", "PPER", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Manchmal nach dem Gott hinauf.", "tokens": ["Manch\u00b7mal", "nach", "dem", "Gott", "hin\u00b7auf", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "Vitzliputzli scheint den Blick", "tokens": ["Vitz\u00b7li\u00b7putz\u00b7li", "scheint", "den", "Blick"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "VVFIN", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Seines Dieners zu verstehen,", "tokens": ["Sei\u00b7nes", "Die\u00b7ners", "zu", "ver\u00b7ste\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Zwinkert mit den Augenwimpern", "tokens": ["Zwin\u00b7kert", "mit", "den", "Au\u00b7gen\u00b7wim\u00b7pern"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "ART", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Und bewegt sogar die Lippen.", "tokens": ["Und", "be\u00b7wegt", "so\u00b7gar", "die", "Lip\u00b7pen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.15": {"line.1": {"text": "Auf des Altars Stufen kauern", "tokens": ["Auf", "des", "Al\u00b7tars", "Stu\u00b7fen", "kau\u00b7ern"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Auch die Tempelmusici,", "tokens": ["Auch", "die", "Tem\u00b7pel\u00b7mu\u00b7si\u00b7ci", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ART", "NE", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Paukenschl\u00e4ger, Kuhhornbl\u00e4ser \u2013", "tokens": ["Pau\u00b7ken\u00b7schl\u00e4\u00b7ger", ",", "Kuh\u00b7horn\u00b7bl\u00e4\u00b7ser", "\u2013"], "token_info": ["word", "punct", "word", "punct"], "pos": ["NE", "$,", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ein Gerassel und Getute \u2013", "tokens": ["Ein", "Ge\u00b7ras\u00b7sel", "und", "Ge\u00b7tu\u00b7te", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.16": {"line.1": {"text": "Ein Gerassel und Getute,", "tokens": ["Ein", "Ge\u00b7ras\u00b7sel", "und", "Ge\u00b7tu\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und es stimmet ein des Chores", "tokens": ["Und", "es", "stim\u00b7met", "ein", "des", "Cho\u00b7res"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "ART", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Mexikanisches Tedeum \u2013", "tokens": ["Me\u00b7xi\u00b7ka\u00b7ni\u00b7sches", "Te\u00b7de\u00b7um", "\u2013"], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$("], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Ein Miaulen wie von Katzen \u2013", "tokens": ["Ein", "Mi\u00b7au\u00b7len", "wie", "von", "Kat\u00b7zen", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KOKOM", "APPR", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.17": {"line.1": {"text": "Ein Miaulen wie von Katzen,", "tokens": ["Ein", "Mi\u00b7au\u00b7len", "wie", "von", "Kat\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KOKOM", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Doch von jener gro\u00dfen Sorte,", "tokens": ["Doch", "von", "je\u00b7ner", "gro\u00b7\u00dfen", "Sor\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PDAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Welche Tigerkatzen hei\u00dfen", "tokens": ["Wel\u00b7che", "Ti\u00b7ger\u00b7kat\u00b7zen", "hei\u00b7\u00dfen"], "token_info": ["word", "word", "word"], "pos": ["PWAT", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und statt M\u00e4use Menschen fressen!", "tokens": ["Und", "statt", "M\u00e4u\u00b7se", "Men\u00b7schen", "fres\u00b7sen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.18": {"line.1": {"text": "Wenn der Nachtwind diese T\u00f6ne", "tokens": ["Wenn", "der", "Nacht\u00b7wind", "die\u00b7se", "T\u00f6\u00b7ne"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "PDAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Hinwirft nach dem Seegestade,", "tokens": ["Hin\u00b7wirft", "nach", "dem", "See\u00b7ge\u00b7sta\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Wird den Spaniern, die dort lagern,", "tokens": ["Wird", "den", "Spa\u00b7ni\u00b7ern", ",", "die", "dort", "la\u00b7gern", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "$,", "PRELS", "ADV", "VVFIN", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.4": {"text": "Katzenj\u00e4mmerlich zumute.", "tokens": ["Kat\u00b7zen\u00b7j\u00e4m\u00b7mer\u00b7lich", "zu\u00b7mu\u00b7te", "."], "token_info": ["word", "word", "punct"], "pos": ["NE", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.19": {"line.1": {"text": "Traurig unter Trauerweiden,", "tokens": ["Trau\u00b7rig", "un\u00b7ter", "Trau\u00b7er\u00b7wei\u00b7den", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Stehen diese dort noch immer,", "tokens": ["Ste\u00b7hen", "die\u00b7se", "dort", "noch", "im\u00b7mer", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PDAT", "ADV", "ADV", "ADV", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Und sie starren nach der Stadt,", "tokens": ["Und", "sie", "star\u00b7ren", "nach", "der", "Stadt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Die im dunkeln Seegew\u00e4sser", "tokens": ["Die", "im", "dun\u00b7keln", "See\u00b7ge\u00b7w\u00e4s\u00b7ser"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "APPRART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.20": {"line.1": {"text": "Widerspiegelt, schier verh\u00f6hnend,", "tokens": ["Wi\u00b7der\u00b7spie\u00b7gelt", ",", "schier", "ver\u00b7h\u00f6h\u00b7nend", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "$,", "ADJD", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Alle Flammen ihrer Freude \u2013", "tokens": ["Al\u00b7le", "Flam\u00b7men", "ih\u00b7rer", "Freu\u00b7de", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "PPOSAT", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Stehen dort wie im Parterre", "tokens": ["Ste\u00b7hen", "dort", "wie", "im", "Par\u00b7ter\u00b7re"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "ADV", "KOKOM", "APPRART", "NN"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.4": {"text": "Eines gro\u00dfen Schauspielhauses,", "tokens": ["Ei\u00b7nes", "gro\u00b7\u00dfen", "Schau\u00b7spiel\u00b7hau\u00b7ses", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.21": {"line.1": {"text": "Und des Vitzliputzli-Tempels", "tokens": ["Und", "des", "Vitz\u00b7li\u00b7putz\u00b7li\u00b7Tem\u00b7pels"], "token_info": ["word", "word", "word"], "pos": ["KON", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Helle Plattform ist die B\u00fchne,", "tokens": ["Hel\u00b7le", "Platt\u00b7form", "ist", "die", "B\u00fch\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "VAFIN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wo zur Siegesfeier jetzt", "tokens": ["Wo", "zur", "Sie\u00b7ge\u00b7sfei\u00b7er", "jetzt"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "APPRART", "NN", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Ein Mysterium tragiert wird.", "tokens": ["Ein", "Mys\u00b7te\u00b7ri\u00b7um", "tra\u00b7giert", "wird", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.22": {"line.1": {"text": "\u00bbmenschenopfer\u00ab hei\u00dft das St\u00fcck.", "tokens": ["\u00bb", "men\u00b7schen\u00b7op\u00b7fer", "\u00ab", "hei\u00dft", "das", "St\u00fcck", "."], "token_info": ["punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "NN", "$(", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Uralt ist der Stoff, die Fabel;", "tokens": ["Ur\u00b7alt", "ist", "der", "Stoff", ",", "die", "Fa\u00b7bel", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ART", "NN", "$,", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "In der christlichen Behandlung", "tokens": ["In", "der", "christ\u00b7li\u00b7chen", "Be\u00b7hand\u00b7lung"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ist das Schauspiel nicht so gr\u00e4\u00dflich.", "tokens": ["Ist", "das", "Schau\u00b7spiel", "nicht", "so", "gr\u00e4\u00df\u00b7lich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "PTKNEG", "ADV", "ADJD", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.23": {"line.1": {"text": "Denn dem Blute wurde Rotwein,", "tokens": ["Denn", "dem", "Blu\u00b7te", "wur\u00b7de", "Rot\u00b7wein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VAFIN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und dem Leichnam, welcher vorkam,", "tokens": ["Und", "dem", "Leich\u00b7nam", ",", "wel\u00b7cher", "vor\u00b7kam", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "PRELS", "VVFIN", "$,"], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Wurde eine harmlos d\u00fcnne", "tokens": ["Wur\u00b7de", "ei\u00b7ne", "harm\u00b7los", "d\u00fcn\u00b7ne"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "ART", "ADJD", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Mehlbreispeis' transsubstituieret \u2013", "tokens": ["Mehl\u00b7breispeis'", "trans\u00b7subs\u00b7ti\u00b7tu\u00b7ie\u00b7ret", "\u2013"], "token_info": ["word", "word", "punct"], "pos": ["NE", "VVFIN", "$("], "meter": "+--+--+-", "measure": "dactylic.tri"}}, "stanza.24": {"line.1": {"text": "Diesmal aber, bei den Wilden,", "tokens": ["Dies\u00b7mal", "a\u00b7ber", ",", "bei", "den", "Wil\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$,", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "War der Spa\u00df sehr roh und ernsthaft", "tokens": ["War", "der", "Spa\u00df", "sehr", "roh", "und", "ernst\u00b7haft"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ART", "NN", "ADV", "ADJD", "KON", "ADJD"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Aufgefa\u00dft: man speiste Fleisch,", "tokens": ["Auf\u00b7ge\u00b7fa\u00dft", ":", "man", "speis\u00b7te", "Fleisch", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["VVPP", "$.", "PIS", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und das Blut war Menschenblut.", "tokens": ["Und", "das", "Blut", "war", "Men\u00b7schen\u00b7blut", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VAFIN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.25": {"line.1": {"text": "Diesmal war es gar das Vollblut", "tokens": ["Dies\u00b7mal", "war", "es", "gar", "das", "Voll\u00b7blut"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Von Altchristen, das sich nie,", "tokens": ["Von", "A\u00b7ltchris\u00b7ten", ",", "das", "sich", "nie", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "PRELS", "PRF", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Nie vermischt hat mit dem Blute", "tokens": ["Nie", "ver\u00b7mischt", "hat", "mit", "dem", "Blu\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVPP", "VAFIN", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Der Moresken und der Juden.", "tokens": ["Der", "Mo\u00b7res\u00b7ken", "und", "der", "Ju\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.26": {"line.1": {"text": "Freu dich, Vitzliputzli, freu dich,", "tokens": ["Freu", "dich", ",", "Vitz\u00b7li\u00b7putz\u00b7li", ",", "freu", "dich", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "NE", "$,", "VVFIN", "PPER", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Heute gibt es Spanierblut,", "tokens": ["Heu\u00b7te", "gibt", "es", "Spa\u00b7nier\u00b7blut", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und am warmen Dufte wirst du", "tokens": ["Und", "am", "war\u00b7men", "Duf\u00b7te", "wirst", "du"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPRART", "ADJA", "NN", "VAFIN", "PPER"], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "Gierig laben deine Nase.", "tokens": ["Gie\u00b7rig", "la\u00b7ben", "dei\u00b7ne", "Na\u00b7se", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.27": {"line.1": {"text": "Heute werden dir geschlachtet", "tokens": ["Heu\u00b7te", "wer\u00b7den", "dir", "ge\u00b7schlach\u00b7tet"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Achtzig Spanier, stolze Braten", "tokens": ["Acht\u00b7zig", "Spa\u00b7nier", ",", "stol\u00b7ze", "Bra\u00b7ten"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["CARD", "NN", "$,", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "F\u00fcr die Tafel deiner Priester,", "tokens": ["F\u00fcr", "die", "Ta\u00b7fel", "dei\u00b7ner", "Pries\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Die sich an dem Fleisch erquicken.", "tokens": ["Die", "sich", "an", "dem", "Fleisch", "er\u00b7qui\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "APPR", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.28": {"line.1": {"text": "Denn der Priester ist ein Mensch,", "tokens": ["Denn", "der", "Pries\u00b7ter", "ist", "ein", "Mensch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VAFIN", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Und der Mensch, der arme Fresser,", "tokens": ["Und", "der", "Mensch", ",", "der", "ar\u00b7me", "Fres\u00b7ser", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Kann nicht blo\u00df vom Riechen leben", "tokens": ["Kann", "nicht", "blo\u00df", "vom", "Rie\u00b7chen", "le\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "PTKNEG", "ADV", "APPRART", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und vom Dufte, wie die G\u00f6tter.", "tokens": ["Und", "vom", "Duf\u00b7te", ",", "wie", "die", "G\u00f6t\u00b7ter", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "NN", "$,", "PWAV", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.29": {"line.1": {"text": "Horch! die Todespauke dr\u00f6hnt schon,", "tokens": ["Horch", "!", "die", "To\u00b7des\u00b7pau\u00b7ke", "dr\u00f6hnt", "schon", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "ART", "NN", "VVFIN", "ADV", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und es kreischt das b\u00f6se Kuhhorn!", "tokens": ["Und", "es", "kreischt", "das", "b\u00f6\u00b7se", "Kuh\u00b7horn", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Sie verk\u00fcnden, da\u00df heraufsteigt", "tokens": ["Sie", "ver\u00b7k\u00fcn\u00b7den", ",", "da\u00df", "her\u00b7auf\u00b7steigt"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "VVPP"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Jetzt der Zug der Sterbem\u00e4nner.", "tokens": ["Jetzt", "der", "Zug", "der", "Ster\u00b7be\u00b7m\u00e4n\u00b7ner", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.30": {"line.1": {"text": "Achtzig Spanier, schm\u00e4hlich nackend,", "tokens": ["Acht\u00b7zig", "Spa\u00b7nier", ",", "schm\u00e4h\u00b7lich", "na\u00b7ckend", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["CARD", "NN", "$,", "ADJD", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ihre H\u00e4nde auf dem R\u00fccken", "tokens": ["Ih\u00b7re", "H\u00e4n\u00b7de", "auf", "dem", "R\u00fc\u00b7cken"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Festgebunden, schleppt und schleift man", "tokens": ["Fest\u00b7ge\u00b7bun\u00b7den", ",", "schleppt", "und", "schleift", "man"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$,", "VVFIN", "KON", "VVFIN", "PIS"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Hoch hinauf die Tempeltreppe.", "tokens": ["Hoch", "hin\u00b7auf", "die", "Tem\u00b7pel\u00b7trep\u00b7pe", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADV", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.31": {"line.1": {"text": "Vor dem Vitzliputzli-Bilde", "tokens": ["Vor", "dem", "Vitz\u00b7li\u00b7putz\u00b7li\u00b7Bil\u00b7de"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Zwingt man sie, das Knie zu beugen", "tokens": ["Zwingt", "man", "sie", ",", "das", "Knie", "zu", "beu\u00b7gen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "PIS", "PPER", "$,", "ART", "NN", "PTKZU", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und zu tanzen Possent\u00e4nze,", "tokens": ["Und", "zu", "tan\u00b7zen", "Pos\u00b7sen\u00b7t\u00e4n\u00b7ze", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PTKZU", "VVINF", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und man zwingt sie durch Torturen,", "tokens": ["Und", "man", "zwingt", "sie", "durch", "Tor\u00b7tu\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "PPER", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.32": {"line.1": {"text": "Die so grausam und entsetzlich,", "tokens": ["Die", "so", "grau\u00b7sam", "und", "ent\u00b7setz\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJD", "KON", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Da\u00df der Angstschrei der Gequ\u00e4lten", "tokens": ["Da\u00df", "der", "Angst\u00b7schrei", "der", "Ge\u00b7qu\u00e4l\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "ART", "NN"], "meter": "+-+---+-", "measure": "unknown.measure.tri"}, "line.3": {"text": "\u00dcberheulet das gesamte", "tokens": ["\u00dc\u00b7berh\u00b7eu\u00b7let", "das", "ge\u00b7sam\u00b7te"], "token_info": ["word", "word", "word"], "pos": ["VVFIN", "ART", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Kannibalencharivari. \u2013", "tokens": ["Kan\u00b7ni\u00b7ba\u00b7len\u00b7cha\u00b7ri\u00b7va\u00b7ri", ".", "\u2013"], "token_info": ["word", "punct", "punct"], "pos": ["NE", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.33": {"line.1": {"text": "Armes Publikum am See!", "tokens": ["Ar\u00b7mes", "Pub\u00b7li\u00b7kum", "am", "See", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "APPRART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Cortez und die Kriegsgef\u00e4hrten,", "tokens": ["Cor\u00b7tez", "und", "die", "Kriegs\u00b7ge\u00b7f\u00e4hr\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "ART", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Sie vernahmen und erkannten", "tokens": ["Sie", "ver\u00b7nah\u00b7men", "und", "er\u00b7kann\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "KON", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ihrer Freunde Angstrufstimmen \u2013", "tokens": ["Ih\u00b7rer", "Freun\u00b7de", "Angs\u00b7trufs\u00b7tim\u00b7men", "\u2013"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.34": {"line.1": {"text": "Auf der B\u00fchne, grellbeleuchtet,", "tokens": ["Auf", "der", "B\u00fch\u00b7ne", ",", "grell\u00b7be\u00b7leuch\u00b7tet", ","], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sahen sie auch ganz genau", "tokens": ["Sa\u00b7hen", "sie", "auch", "ganz", "ge\u00b7nau"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Die Gestalten und die Mienen \u2013", "tokens": ["Die", "Ge\u00b7stal\u00b7ten", "und", "die", "Mie\u00b7nen", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Sahn das Messer, sahn das Blut \u2013", "tokens": ["Sahn", "das", "Mes\u00b7ser", ",", "sahn", "das", "Blut", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$,", "VVFIN", "ART", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.35": {"line.1": {"text": "Und sie nahmen ab die Helme", "tokens": ["Und", "sie", "nah\u00b7men", "ab", "die", "Hel\u00b7me"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Von den H\u00e4uptern, knieten nieder,", "tokens": ["Von", "den", "H\u00e4up\u00b7tern", ",", "knie\u00b7ten", "nie\u00b7der", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "VVFIN", "PTKVZ", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Stimmten an den Psalm der Toten,", "tokens": ["Stimm\u00b7ten", "an", "den", "Psalm", "der", "To\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und sie sangen: \u00bbDe profundis!\u00ab", "tokens": ["Und", "sie", "san\u00b7gen", ":", "\u00bb", "De", "pro\u00b7fun\u00b7dis", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "punct", "punct"], "pos": ["KON", "PPER", "VVFIN", "$.", "$(", "FM", "FM", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.36": {"line.1": {"text": "Unter jenen, welche starben,", "tokens": ["Un\u00b7ter", "je\u00b7nen", ",", "wel\u00b7che", "star\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PDAT", "$,", "PRELS", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "War auch Raimond de Mendoza,", "tokens": ["War", "auch", "Rai\u00b7mond", "de", "Men\u00b7do\u00b7za", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "NN", "NE", "NE", "$,"], "meter": "--++-+-+", "measure": "anapaest.init"}, "line.3": {"text": "Sohn der sch\u00f6nen Abbatissin,", "tokens": ["Sohn", "der", "sch\u00f6\u00b7nen", "Ab\u00b7ba\u00b7tis\u00b7sin", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Cortez' erste Jugendliebe.", "tokens": ["Cor\u00b7te\u00b7z'", "ers\u00b7te", "Ju\u00b7gend\u00b7lie\u00b7be", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}}, "stanza.37": {"line.1": {"text": "Als er auf der Brust des J\u00fcnglings", "tokens": ["Als", "er", "auf", "der", "Brust", "des", "J\u00fcng\u00b7lings"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "ART", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Jenes Medaillon gewahrte,", "tokens": ["Je\u00b7nes", "Me\u00b7dail\u00b7lon", "ge\u00b7wahr\u00b7te", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PDAT", "NN", "VVFIN", "$,"], "meter": "+--++-+-", "measure": "dactylic.init"}, "line.3": {"text": "Das der Mutter Bildnis einschlo\u00df,", "tokens": ["Das", "der", "Mut\u00b7ter", "Bild\u00b7nis", "ein\u00b7schlo\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ART", "NN", "NN", "VVFIN", "$,"], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "Weinte Cortez helle Tr\u00e4nen \u2013", "tokens": ["Wein\u00b7te", "Cor\u00b7tez", "hel\u00b7le", "Tr\u00e4\u00b7nen", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "ADJA", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.38": {"line.1": {"text": "Doch er wischt' sie ab vom Auge", "tokens": ["Doch", "er", "wischt'", "sie", "ab", "vom", "Au\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "PPER", "PTKVZ", "APPRART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Mit dem harten B\u00fcffelhandschuh,", "tokens": ["Mit", "dem", "har\u00b7ten", "B\u00fcf\u00b7fel\u00b7hand\u00b7schuh", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Seufzte tief und sang im Chore", "tokens": ["Seufz\u00b7te", "tief", "und", "sang", "im", "Cho\u00b7re"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADJD", "KON", "VVFIN", "APPRART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Mit den andern: \u00bbMiserere!\u00ab", "tokens": ["Mit", "den", "an\u00b7dern", ":", "\u00bb", "Mi\u00b7se\u00b7re\u00b7re", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct", "word", "punct", "punct"], "pos": ["APPR", "ART", "ADJA", "$.", "$(", "NN", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.39": {"line.1": {"text": "Nach des Kampfes Schreckenstag,", "tokens": ["Nach", "des", "Kamp\u00b7fes", "Schre\u00b7ckens\u00b7tag", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Kommt die Spuknacht des Triumphes;", "tokens": ["Kommt", "die", "Spuk\u00b7nacht", "des", "Tri\u00b7um\u00b7phes", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Hunderttausend Freudenlampen", "tokens": ["Hun\u00b7dert\u00b7tau\u00b7send", "Freu\u00b7den\u00b7lam\u00b7pen"], "token_info": ["word", "word"], "pos": ["CARD", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Lodern auf in Mexiko.", "tokens": ["Lo\u00b7dern", "auf", "in", "Me\u00b7xi\u00b7ko", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "APPR", "NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.40": {"line.1": {"text": "Hunderttausend Freudenlampen,", "tokens": ["Hun\u00b7dert\u00b7tau\u00b7send", "Freu\u00b7den\u00b7lam\u00b7pen", ","], "token_info": ["word", "word", "punct"], "pos": ["CARD", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Waldharzfackeln, Pechkranzfeuer,", "tokens": ["Wald\u00b7harz\u00b7fa\u00b7ckeln", ",", "Pech\u00b7kranz\u00b7feu\u00b7er", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Werfen grell ihr Tageslicht", "tokens": ["Wer\u00b7fen", "grell", "ihr", "Ta\u00b7ges\u00b7licht"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "ADJD", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Auf Pal\u00e4ste, G\u00f6tterhallen,", "tokens": ["Auf", "Pa\u00b7l\u00e4s\u00b7te", ",", "G\u00f6t\u00b7ter\u00b7hal\u00b7len", ","], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.41": {"line.1": {"text": "Gildenh\u00e4user und zumal", "tokens": ["Gil\u00b7den\u00b7h\u00e4u\u00b7ser", "und", "zu\u00b7mal"], "token_info": ["word", "word", "word"], "pos": ["NE", "KON", "KOUS"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Auf den Tempel Vitzliputzlis,", "tokens": ["Auf", "den", "Tem\u00b7pel", "Vitz\u00b7li\u00b7putz\u00b7lis", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NE", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "G\u00f6tzenburg von rotem Backstein,", "tokens": ["G\u00f6t\u00b7zen\u00b7burg", "von", "ro\u00b7tem", "Back\u00b7stein", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Seltsam mahnend an \u00e4gyptisch,", "tokens": ["Selt\u00b7sam", "mah\u00b7nend", "an", "\u00e4\u00b7gypt\u00b7isch", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "ADJD", "APPR", "ADJD", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.42": {"line.1": {"text": "Babylonisch und assyrisch", "tokens": ["Ba\u00b7by\u00b7lo\u00b7nisch", "und", "as\u00b7sy\u00b7risch"], "token_info": ["word", "word", "word"], "pos": ["NE", "KON", "ADJD"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Kolossalen Bauwerkmonstren,", "tokens": ["Ko\u00b7los\u00b7sa\u00b7len", "Bau\u00b7werk\u00b7monst\u00b7ren", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Die wir schauen auf den Bildern", "tokens": ["Die", "wir", "schau\u00b7en", "auf", "den", "Bil\u00b7dern"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "VVFIN", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Unsers Briten Henri Martin.", "tokens": ["Un\u00b7sers", "Bri\u00b7ten", "Hen\u00b7ri", "Mar\u00b7tin", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "NE", "NE", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.43": {"line.1": {"text": "Ja, das sind dieselben breiten", "tokens": ["Ja", ",", "das", "sind", "die\u00b7sel\u00b7ben", "brei\u00b7ten"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["PTKANT", "$,", "PDS", "VAFIN", "PDAT", "ADJA"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Rampentreppen, also breit,", "tokens": ["Ram\u00b7pen\u00b7trep\u00b7pen", ",", "al\u00b7so", "breit", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "ADV", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df dort auf und nieder wallen", "tokens": ["Da\u00df", "dort", "auf", "und", "nie\u00b7der", "wal\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "PTKVZ", "KON", "PTKVZ", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Viele tausend Mexikaner,", "tokens": ["Vie\u00b7le", "tau\u00b7send", "Me\u00b7xi\u00b7ka\u00b7ner", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PIAT", "CARD", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.44": {"line.1": {"text": "W\u00e4hrend auf den Stufen lagern", "tokens": ["W\u00e4h\u00b7rend", "auf", "den", "Stu\u00b7fen", "la\u00b7gern"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "APPR", "ART", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Rottenweis die wilden Krieger,", "tokens": ["Rot\u00b7ten\u00b7weis", "die", "wil\u00b7den", "Krie\u00b7ger", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Welche lustig bankettieren,", "tokens": ["Wel\u00b7che", "lus\u00b7tig", "ban\u00b7ket\u00b7tie\u00b7ren", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PWS", "ADJD", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Hochberauscht von Sieg und Palmwein.", "tokens": ["Hoch\u00b7be\u00b7rauscht", "von", "Sieg", "und", "Palm\u00b7wein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "KON", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.45": {"line.1": {"text": "Diese Rampentreppen leiten,", "tokens": ["Die\u00b7se", "Ram\u00b7pen\u00b7trep\u00b7pen", "lei\u00b7ten", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PDAT", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wie ein Zickzack, nach der Plattform,", "tokens": ["Wie", "ein", "Zick\u00b7zack", ",", "nach", "der", "Platt\u00b7form", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "$,", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Einem balustradenart'gen", "tokens": ["Ei\u00b7nem", "ba\u00b7lus\u00b7tra\u00b7den\u00b7art'\u00b7gen"], "token_info": ["word", "word"], "pos": ["ART", "NN"], "meter": "+---+-+-", "measure": "dactylic.init"}, "line.4": {"text": "Ungeheuern Tempeldach.", "tokens": ["Un\u00b7ge\u00b7heu\u00b7ern", "Tem\u00b7pel\u00b7dach", "."], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.46": {"line.1": {"text": "Dort auf seinem Thronaltar", "tokens": ["Dort", "auf", "sei\u00b7nem", "Thro\u00b7nal\u00b7tar"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Sitzt der gro\u00dfe Vitzliputzli,", "tokens": ["Sitzt", "der", "gro\u00b7\u00dfe", "Vitz\u00b7li\u00b7putz\u00b7li", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Mexikos blutd\u00fcrst'ger Kriegsgott.", "tokens": ["Me\u00b7xi\u00b7kos", "blut\u00b7d\u00fcr\u00b7st'\u00b7ger", "Kriegs\u00b7gott", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Ist ein b\u00f6ses Unget\u00fcm,", "tokens": ["Ist", "ein", "b\u00f6\u00b7ses", "Un\u00b7ge\u00b7t\u00fcm", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.47": {"line.1": {"text": "Doch sein \u00c4u\u00dfres ist so putzig,", "tokens": ["Doch", "sein", "\u00c4u\u00df\u00b7res", "ist", "so", "put\u00b7zig", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VAFIN", "ADV", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "So verschn\u00f6rkelt und so kindisch,", "tokens": ["So", "ver\u00b7schn\u00f6r\u00b7kelt", "und", "so", "kin\u00b7disch", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "KON", "ADV", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df er trotz des innern Grausens", "tokens": ["Da\u00df", "er", "trotz", "des", "in\u00b7nern", "Grau\u00b7sens"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Dennoch unsre Lachlust kitzelt \u2013", "tokens": ["Den\u00b7noch", "uns\u00b7re", "Lach\u00b7lust", "kit\u00b7zelt", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "VVFIN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.48": {"line.1": {"text": "Und bei seinem Anblick denken", "tokens": ["Und", "bei", "sei\u00b7nem", "An\u00b7blick", "den\u00b7ken"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "PPOSAT", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wir zu gleicher Zeit etwa", "tokens": ["Wir", "zu", "glei\u00b7cher", "Zeit", "et\u00b7wa"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "APPR", "ADJA", "NN", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "An den blassen Tod von Basel", "tokens": ["An", "den", "blas\u00b7sen", "Tod", "von", "Ba\u00b7sel"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "APPR", "NE"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Und an Br\u00fcssels Mankepi\u00df.", "tokens": ["Und", "an", "Br\u00fcs\u00b7sels", "Man\u00b7ke\u00b7pi\u00df", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NE", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.49": {"line.1": {"text": "An des Gottes Seite stehen", "tokens": ["An", "des", "Got\u00b7tes", "Sei\u00b7te", "ste\u00b7hen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Rechts die Laien, links die Pfaffen;", "tokens": ["Rechts", "die", "Lai\u00b7en", ",", "links", "die", "Pfaf\u00b7fen", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "$,", "ADV", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Im Ornat von bunten Federn", "tokens": ["Im", "Or\u00b7nat", "von", "bun\u00b7ten", "Fe\u00b7dern"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "APPR", "ADJA", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Spreizt sich heut die Klerisei.", "tokens": ["Spreizt", "sich", "heut", "die", "Kle\u00b7ri\u00b7sei", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ADV", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.50": {"line.1": {"text": "Auf des Altars Marmorstufen", "tokens": ["Auf", "des", "Al\u00b7tars", "Mar\u00b7mor\u00b7stu\u00b7fen"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Hockt ein hundertj\u00e4hrig M\u00e4nnlein,", "tokens": ["Hockt", "ein", "hun\u00b7dert\u00b7j\u00e4h\u00b7rig", "M\u00e4nn\u00b7lein", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJD", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Ohne Haar an Kinn und Sch\u00e4del;", "tokens": ["Oh\u00b7ne", "Haar", "an", "Kinn", "und", "Sch\u00e4\u00b7del", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "NN", "KON", "NE", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Tr\u00e4gt ein scharlach Kamis\u00f6lchen.", "tokens": ["Tr\u00e4gt", "ein", "schar\u00b7lach", "Ka\u00b7mi\u00b7s\u00f6l\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.51": {"line.1": {"text": "Dieses ist der Opferpriester,", "tokens": ["Die\u00b7ses", "ist", "der", "Op\u00b7fer\u00b7pries\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und er wetzet seine Messer,", "tokens": ["Und", "er", "wet\u00b7zet", "sei\u00b7ne", "Mes\u00b7ser", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wetzt sie l\u00e4chelnd, und er schielet", "tokens": ["Wetzt", "sie", "l\u00e4\u00b7chelnd", ",", "und", "er", "schie\u00b7let"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADJD", "$,", "KON", "PPER", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Manchmal nach dem Gott hinauf.", "tokens": ["Manch\u00b7mal", "nach", "dem", "Gott", "hin\u00b7auf", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.52": {"line.1": {"text": "Vitzliputzli scheint den Blick", "tokens": ["Vitz\u00b7li\u00b7putz\u00b7li", "scheint", "den", "Blick"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "VVFIN", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Seines Dieners zu verstehen,", "tokens": ["Sei\u00b7nes", "Die\u00b7ners", "zu", "ver\u00b7ste\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Zwinkert mit den Augenwimpern", "tokens": ["Zwin\u00b7kert", "mit", "den", "Au\u00b7gen\u00b7wim\u00b7pern"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "ART", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Und bewegt sogar die Lippen.", "tokens": ["Und", "be\u00b7wegt", "so\u00b7gar", "die", "Lip\u00b7pen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.53": {"line.1": {"text": "Auf des Altars Stufen kauern", "tokens": ["Auf", "des", "Al\u00b7tars", "Stu\u00b7fen", "kau\u00b7ern"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Auch die Tempelmusici,", "tokens": ["Auch", "die", "Tem\u00b7pel\u00b7mu\u00b7si\u00b7ci", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ART", "NE", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Paukenschl\u00e4ger, Kuhhornbl\u00e4ser \u2013", "tokens": ["Pau\u00b7ken\u00b7schl\u00e4\u00b7ger", ",", "Kuh\u00b7horn\u00b7bl\u00e4\u00b7ser", "\u2013"], "token_info": ["word", "punct", "word", "punct"], "pos": ["NE", "$,", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ein Gerassel und Getute \u2013", "tokens": ["Ein", "Ge\u00b7ras\u00b7sel", "und", "Ge\u00b7tu\u00b7te", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.54": {"line.1": {"text": "Ein Gerassel und Getute,", "tokens": ["Ein", "Ge\u00b7ras\u00b7sel", "und", "Ge\u00b7tu\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und es stimmet ein des Chores", "tokens": ["Und", "es", "stim\u00b7met", "ein", "des", "Cho\u00b7res"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "ART", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Mexikanisches Tedeum \u2013", "tokens": ["Me\u00b7xi\u00b7ka\u00b7ni\u00b7sches", "Te\u00b7de\u00b7um", "\u2013"], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$("], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Ein Miaulen wie von Katzen \u2013", "tokens": ["Ein", "Mi\u00b7au\u00b7len", "wie", "von", "Kat\u00b7zen", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KOKOM", "APPR", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.55": {"line.1": {"text": "Ein Miaulen wie von Katzen,", "tokens": ["Ein", "Mi\u00b7au\u00b7len", "wie", "von", "Kat\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KOKOM", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Doch von jener gro\u00dfen Sorte,", "tokens": ["Doch", "von", "je\u00b7ner", "gro\u00b7\u00dfen", "Sor\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PDAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Welche Tigerkatzen hei\u00dfen", "tokens": ["Wel\u00b7che", "Ti\u00b7ger\u00b7kat\u00b7zen", "hei\u00b7\u00dfen"], "token_info": ["word", "word", "word"], "pos": ["PWAT", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und statt M\u00e4use Menschen fressen!", "tokens": ["Und", "statt", "M\u00e4u\u00b7se", "Men\u00b7schen", "fres\u00b7sen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.56": {"line.1": {"text": "Wenn der Nachtwind diese T\u00f6ne", "tokens": ["Wenn", "der", "Nacht\u00b7wind", "die\u00b7se", "T\u00f6\u00b7ne"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "PDAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Hinwirft nach dem Seegestade,", "tokens": ["Hin\u00b7wirft", "nach", "dem", "See\u00b7ge\u00b7sta\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Wird den Spaniern, die dort lagern,", "tokens": ["Wird", "den", "Spa\u00b7ni\u00b7ern", ",", "die", "dort", "la\u00b7gern", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "$,", "PRELS", "ADV", "VVFIN", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.4": {"text": "Katzenj\u00e4mmerlich zumute.", "tokens": ["Kat\u00b7zen\u00b7j\u00e4m\u00b7mer\u00b7lich", "zu\u00b7mu\u00b7te", "."], "token_info": ["word", "word", "punct"], "pos": ["NE", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.57": {"line.1": {"text": "Traurig unter Trauerweiden,", "tokens": ["Trau\u00b7rig", "un\u00b7ter", "Trau\u00b7er\u00b7wei\u00b7den", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Stehen diese dort noch immer,", "tokens": ["Ste\u00b7hen", "die\u00b7se", "dort", "noch", "im\u00b7mer", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PDAT", "ADV", "ADV", "ADV", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Und sie starren nach der Stadt,", "tokens": ["Und", "sie", "star\u00b7ren", "nach", "der", "Stadt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Die im dunkeln Seegew\u00e4sser", "tokens": ["Die", "im", "dun\u00b7keln", "See\u00b7ge\u00b7w\u00e4s\u00b7ser"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "APPRART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.58": {"line.1": {"text": "Widerspiegelt, schier verh\u00f6hnend,", "tokens": ["Wi\u00b7der\u00b7spie\u00b7gelt", ",", "schier", "ver\u00b7h\u00f6h\u00b7nend", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "$,", "ADJD", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Alle Flammen ihrer Freude \u2013", "tokens": ["Al\u00b7le", "Flam\u00b7men", "ih\u00b7rer", "Freu\u00b7de", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "PPOSAT", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Stehen dort wie im Parterre", "tokens": ["Ste\u00b7hen", "dort", "wie", "im", "Par\u00b7ter\u00b7re"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "ADV", "KOKOM", "APPRART", "NN"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.4": {"text": "Eines gro\u00dfen Schauspielhauses,", "tokens": ["Ei\u00b7nes", "gro\u00b7\u00dfen", "Schau\u00b7spiel\u00b7hau\u00b7ses", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.59": {"line.1": {"text": "Und des Vitzliputzli-Tempels", "tokens": ["Und", "des", "Vitz\u00b7li\u00b7putz\u00b7li\u00b7Tem\u00b7pels"], "token_info": ["word", "word", "word"], "pos": ["KON", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Helle Plattform ist die B\u00fchne,", "tokens": ["Hel\u00b7le", "Platt\u00b7form", "ist", "die", "B\u00fch\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "VAFIN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wo zur Siegesfeier jetzt", "tokens": ["Wo", "zur", "Sie\u00b7ge\u00b7sfei\u00b7er", "jetzt"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "APPRART", "NN", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Ein Mysterium tragiert wird.", "tokens": ["Ein", "Mys\u00b7te\u00b7ri\u00b7um", "tra\u00b7giert", "wird", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.60": {"line.1": {"text": "\u00bbmenschenopfer\u00ab hei\u00dft das St\u00fcck.", "tokens": ["\u00bb", "men\u00b7schen\u00b7op\u00b7fer", "\u00ab", "hei\u00dft", "das", "St\u00fcck", "."], "token_info": ["punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "NN", "$(", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Uralt ist der Stoff, die Fabel;", "tokens": ["Ur\u00b7alt", "ist", "der", "Stoff", ",", "die", "Fa\u00b7bel", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ART", "NN", "$,", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "In der christlichen Behandlung", "tokens": ["In", "der", "christ\u00b7li\u00b7chen", "Be\u00b7hand\u00b7lung"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ist das Schauspiel nicht so gr\u00e4\u00dflich.", "tokens": ["Ist", "das", "Schau\u00b7spiel", "nicht", "so", "gr\u00e4\u00df\u00b7lich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "PTKNEG", "ADV", "ADJD", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.61": {"line.1": {"text": "Denn dem Blute wurde Rotwein,", "tokens": ["Denn", "dem", "Blu\u00b7te", "wur\u00b7de", "Rot\u00b7wein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VAFIN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und dem Leichnam, welcher vorkam,", "tokens": ["Und", "dem", "Leich\u00b7nam", ",", "wel\u00b7cher", "vor\u00b7kam", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "PRELS", "VVFIN", "$,"], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Wurde eine harmlos d\u00fcnne", "tokens": ["Wur\u00b7de", "ei\u00b7ne", "harm\u00b7los", "d\u00fcn\u00b7ne"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "ART", "ADJD", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Mehlbreispeis' transsubstituieret \u2013", "tokens": ["Mehl\u00b7breispeis'", "trans\u00b7subs\u00b7ti\u00b7tu\u00b7ie\u00b7ret", "\u2013"], "token_info": ["word", "word", "punct"], "pos": ["NE", "VVFIN", "$("], "meter": "+--+--+-", "measure": "dactylic.tri"}}, "stanza.62": {"line.1": {"text": "Diesmal aber, bei den Wilden,", "tokens": ["Dies\u00b7mal", "a\u00b7ber", ",", "bei", "den", "Wil\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$,", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "War der Spa\u00df sehr roh und ernsthaft", "tokens": ["War", "der", "Spa\u00df", "sehr", "roh", "und", "ernst\u00b7haft"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ART", "NN", "ADV", "ADJD", "KON", "ADJD"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Aufgefa\u00dft: man speiste Fleisch,", "tokens": ["Auf\u00b7ge\u00b7fa\u00dft", ":", "man", "speis\u00b7te", "Fleisch", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["VVPP", "$.", "PIS", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und das Blut war Menschenblut.", "tokens": ["Und", "das", "Blut", "war", "Men\u00b7schen\u00b7blut", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VAFIN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.63": {"line.1": {"text": "Diesmal war es gar das Vollblut", "tokens": ["Dies\u00b7mal", "war", "es", "gar", "das", "Voll\u00b7blut"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Von Altchristen, das sich nie,", "tokens": ["Von", "A\u00b7ltchris\u00b7ten", ",", "das", "sich", "nie", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "PRELS", "PRF", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Nie vermischt hat mit dem Blute", "tokens": ["Nie", "ver\u00b7mischt", "hat", "mit", "dem", "Blu\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVPP", "VAFIN", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Der Moresken und der Juden.", "tokens": ["Der", "Mo\u00b7res\u00b7ken", "und", "der", "Ju\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.64": {"line.1": {"text": "Freu dich, Vitzliputzli, freu dich,", "tokens": ["Freu", "dich", ",", "Vitz\u00b7li\u00b7putz\u00b7li", ",", "freu", "dich", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "NE", "$,", "VVFIN", "PPER", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Heute gibt es Spanierblut,", "tokens": ["Heu\u00b7te", "gibt", "es", "Spa\u00b7nier\u00b7blut", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und am warmen Dufte wirst du", "tokens": ["Und", "am", "war\u00b7men", "Duf\u00b7te", "wirst", "du"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPRART", "ADJA", "NN", "VAFIN", "PPER"], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "Gierig laben deine Nase.", "tokens": ["Gie\u00b7rig", "la\u00b7ben", "dei\u00b7ne", "Na\u00b7se", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.65": {"line.1": {"text": "Heute werden dir geschlachtet", "tokens": ["Heu\u00b7te", "wer\u00b7den", "dir", "ge\u00b7schlach\u00b7tet"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Achtzig Spanier, stolze Braten", "tokens": ["Acht\u00b7zig", "Spa\u00b7nier", ",", "stol\u00b7ze", "Bra\u00b7ten"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["CARD", "NN", "$,", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "F\u00fcr die Tafel deiner Priester,", "tokens": ["F\u00fcr", "die", "Ta\u00b7fel", "dei\u00b7ner", "Pries\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Die sich an dem Fleisch erquicken.", "tokens": ["Die", "sich", "an", "dem", "Fleisch", "er\u00b7qui\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "APPR", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.66": {"line.1": {"text": "Denn der Priester ist ein Mensch,", "tokens": ["Denn", "der", "Pries\u00b7ter", "ist", "ein", "Mensch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VAFIN", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Und der Mensch, der arme Fresser,", "tokens": ["Und", "der", "Mensch", ",", "der", "ar\u00b7me", "Fres\u00b7ser", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Kann nicht blo\u00df vom Riechen leben", "tokens": ["Kann", "nicht", "blo\u00df", "vom", "Rie\u00b7chen", "le\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "PTKNEG", "ADV", "APPRART", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und vom Dufte, wie die G\u00f6tter.", "tokens": ["Und", "vom", "Duf\u00b7te", ",", "wie", "die", "G\u00f6t\u00b7ter", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "NN", "$,", "PWAV", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.67": {"line.1": {"text": "Horch! die Todespauke dr\u00f6hnt schon,", "tokens": ["Horch", "!", "die", "To\u00b7des\u00b7pau\u00b7ke", "dr\u00f6hnt", "schon", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "ART", "NN", "VVFIN", "ADV", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und es kreischt das b\u00f6se Kuhhorn!", "tokens": ["Und", "es", "kreischt", "das", "b\u00f6\u00b7se", "Kuh\u00b7horn", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Sie verk\u00fcnden, da\u00df heraufsteigt", "tokens": ["Sie", "ver\u00b7k\u00fcn\u00b7den", ",", "da\u00df", "her\u00b7auf\u00b7steigt"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "VVPP"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Jetzt der Zug der Sterbem\u00e4nner.", "tokens": ["Jetzt", "der", "Zug", "der", "Ster\u00b7be\u00b7m\u00e4n\u00b7ner", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.68": {"line.1": {"text": "Achtzig Spanier, schm\u00e4hlich nackend,", "tokens": ["Acht\u00b7zig", "Spa\u00b7nier", ",", "schm\u00e4h\u00b7lich", "na\u00b7ckend", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["CARD", "NN", "$,", "ADJD", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ihre H\u00e4nde auf dem R\u00fccken", "tokens": ["Ih\u00b7re", "H\u00e4n\u00b7de", "auf", "dem", "R\u00fc\u00b7cken"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Festgebunden, schleppt und schleift man", "tokens": ["Fest\u00b7ge\u00b7bun\u00b7den", ",", "schleppt", "und", "schleift", "man"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$,", "VVFIN", "KON", "VVFIN", "PIS"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Hoch hinauf die Tempeltreppe.", "tokens": ["Hoch", "hin\u00b7auf", "die", "Tem\u00b7pel\u00b7trep\u00b7pe", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADV", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.69": {"line.1": {"text": "Vor dem Vitzliputzli-Bilde", "tokens": ["Vor", "dem", "Vitz\u00b7li\u00b7putz\u00b7li\u00b7Bil\u00b7de"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Zwingt man sie, das Knie zu beugen", "tokens": ["Zwingt", "man", "sie", ",", "das", "Knie", "zu", "beu\u00b7gen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "PIS", "PPER", "$,", "ART", "NN", "PTKZU", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und zu tanzen Possent\u00e4nze,", "tokens": ["Und", "zu", "tan\u00b7zen", "Pos\u00b7sen\u00b7t\u00e4n\u00b7ze", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PTKZU", "VVINF", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und man zwingt sie durch Torturen,", "tokens": ["Und", "man", "zwingt", "sie", "durch", "Tor\u00b7tu\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "PPER", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.70": {"line.1": {"text": "Die so grausam und entsetzlich,", "tokens": ["Die", "so", "grau\u00b7sam", "und", "ent\u00b7setz\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJD", "KON", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Da\u00df der Angstschrei der Gequ\u00e4lten", "tokens": ["Da\u00df", "der", "Angst\u00b7schrei", "der", "Ge\u00b7qu\u00e4l\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "ART", "NN"], "meter": "+-+---+-", "measure": "unknown.measure.tri"}, "line.3": {"text": "\u00dcberheulet das gesamte", "tokens": ["\u00dc\u00b7berh\u00b7eu\u00b7let", "das", "ge\u00b7sam\u00b7te"], "token_info": ["word", "word", "word"], "pos": ["VVFIN", "ART", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Kannibalencharivari. \u2013", "tokens": ["Kan\u00b7ni\u00b7ba\u00b7len\u00b7cha\u00b7ri\u00b7va\u00b7ri", ".", "\u2013"], "token_info": ["word", "punct", "punct"], "pos": ["NE", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.71": {"line.1": {"text": "Armes Publikum am See!", "tokens": ["Ar\u00b7mes", "Pub\u00b7li\u00b7kum", "am", "See", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "APPRART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Cortez und die Kriegsgef\u00e4hrten,", "tokens": ["Cor\u00b7tez", "und", "die", "Kriegs\u00b7ge\u00b7f\u00e4hr\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "ART", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Sie vernahmen und erkannten", "tokens": ["Sie", "ver\u00b7nah\u00b7men", "und", "er\u00b7kann\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "KON", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ihrer Freunde Angstrufstimmen \u2013", "tokens": ["Ih\u00b7rer", "Freun\u00b7de", "Angs\u00b7trufs\u00b7tim\u00b7men", "\u2013"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.72": {"line.1": {"text": "Auf der B\u00fchne, grellbeleuchtet,", "tokens": ["Auf", "der", "B\u00fch\u00b7ne", ",", "grell\u00b7be\u00b7leuch\u00b7tet", ","], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sahen sie auch ganz genau", "tokens": ["Sa\u00b7hen", "sie", "auch", "ganz", "ge\u00b7nau"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Die Gestalten und die Mienen \u2013", "tokens": ["Die", "Ge\u00b7stal\u00b7ten", "und", "die", "Mie\u00b7nen", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Sahn das Messer, sahn das Blut \u2013", "tokens": ["Sahn", "das", "Mes\u00b7ser", ",", "sahn", "das", "Blut", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$,", "VVFIN", "ART", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.73": {"line.1": {"text": "Und sie nahmen ab die Helme", "tokens": ["Und", "sie", "nah\u00b7men", "ab", "die", "Hel\u00b7me"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Von den H\u00e4uptern, knieten nieder,", "tokens": ["Von", "den", "H\u00e4up\u00b7tern", ",", "knie\u00b7ten", "nie\u00b7der", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "VVFIN", "PTKVZ", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Stimmten an den Psalm der Toten,", "tokens": ["Stimm\u00b7ten", "an", "den", "Psalm", "der", "To\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und sie sangen: \u00bbDe profundis!\u00ab", "tokens": ["Und", "sie", "san\u00b7gen", ":", "\u00bb", "De", "pro\u00b7fun\u00b7dis", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "punct", "punct"], "pos": ["KON", "PPER", "VVFIN", "$.", "$(", "FM", "FM", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.74": {"line.1": {"text": "Unter jenen, welche starben,", "tokens": ["Un\u00b7ter", "je\u00b7nen", ",", "wel\u00b7che", "star\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PDAT", "$,", "PRELS", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "War auch Raimond de Mendoza,", "tokens": ["War", "auch", "Rai\u00b7mond", "de", "Men\u00b7do\u00b7za", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "NN", "NE", "NE", "$,"], "meter": "--++-+-+", "measure": "anapaest.init"}, "line.3": {"text": "Sohn der sch\u00f6nen Abbatissin,", "tokens": ["Sohn", "der", "sch\u00f6\u00b7nen", "Ab\u00b7ba\u00b7tis\u00b7sin", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Cortez' erste Jugendliebe.", "tokens": ["Cor\u00b7te\u00b7z'", "ers\u00b7te", "Ju\u00b7gend\u00b7lie\u00b7be", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}}, "stanza.75": {"line.1": {"text": "Als er auf der Brust des J\u00fcnglings", "tokens": ["Als", "er", "auf", "der", "Brust", "des", "J\u00fcng\u00b7lings"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "ART", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Jenes Medaillon gewahrte,", "tokens": ["Je\u00b7nes", "Me\u00b7dail\u00b7lon", "ge\u00b7wahr\u00b7te", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PDAT", "NN", "VVFIN", "$,"], "meter": "+--++-+-", "measure": "dactylic.init"}, "line.3": {"text": "Das der Mutter Bildnis einschlo\u00df,", "tokens": ["Das", "der", "Mut\u00b7ter", "Bild\u00b7nis", "ein\u00b7schlo\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ART", "NN", "NN", "VVFIN", "$,"], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "Weinte Cortez helle Tr\u00e4nen \u2013", "tokens": ["Wein\u00b7te", "Cor\u00b7tez", "hel\u00b7le", "Tr\u00e4\u00b7nen", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "ADJA", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.76": {"line.1": {"text": "Doch er wischt' sie ab vom Auge", "tokens": ["Doch", "er", "wischt'", "sie", "ab", "vom", "Au\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "PPER", "PTKVZ", "APPRART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Mit dem harten B\u00fcffelhandschuh,", "tokens": ["Mit", "dem", "har\u00b7ten", "B\u00fcf\u00b7fel\u00b7hand\u00b7schuh", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Seufzte tief und sang im Chore", "tokens": ["Seufz\u00b7te", "tief", "und", "sang", "im", "Cho\u00b7re"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADJD", "KON", "VVFIN", "APPRART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Mit den andern: \u00bbMiserere!\u00ab", "tokens": ["Mit", "den", "an\u00b7dern", ":", "\u00bb", "Mi\u00b7se\u00b7re\u00b7re", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct", "word", "punct", "punct"], "pos": ["APPR", "ART", "ADJA", "$.", "$(", "NN", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}}}}