{"textgrid.poem.48446": {"metadata": {"author": {"name": "Fleming, Paul", "birth": "N.A.", "death": "N.A."}, "title": "17. Lob der Druckerei an Gregorius Ritschen", "genre": "verse", "period": "N.A.", "pub_year": 1624, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Warumb nicht, werter Freund, solt' ich euch nicht zu Willen", "tokens": ["Wa\u00b7rumb", "nicht", ",", "wer\u00b7ter", "Freund", ",", "solt'", "ich", "euch", "nicht", "zu", "Wil\u00b7len"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PTKNEG", "$,", "ADJA", "NN", "$,", "VMFIN", "PPER", "PPER", "PTKNEG", "APPR", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "auf euer Bitten sein? Ich will den Wundsch erf\u00fcllen,", "tokens": ["auf", "eu\u00b7er", "Bit\u00b7ten", "sein", "?", "Ich", "will", "den", "Wund\u00b7sch", "er\u00b7f\u00fcl\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VAINF", "$.", "PPER", "VMFIN", "ART", "NN", "VVINF", "$,"], "meter": "++-+-+-+-+--+-", "measure": "trochaic.septa.relaxed"}, "line.3": {"text": "den Andere getan. Die edle Druckerei", "tokens": ["den", "An\u00b7de\u00b7re", "ge\u00b7tan", ".", "Die", "ed\u00b7le", "Dru\u00b7cke\u00b7rei"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "PIS", "VVPP", "$.", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "ist wol der Ehren wert, da\u00df sie gelobet sei.", "tokens": ["ist", "wol", "der", "Eh\u00b7ren", "wert", ",", "da\u00df", "sie", "ge\u00b7lo\u00b7bet", "sei", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "VVFIN", "$,", "KOUS", "PPER", "VVFIN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wo k\u00f6mpt sie aber her? Soll sie aus Catay kommen?", "tokens": ["Wo", "k\u00f6mpt", "sie", "a\u00b7ber", "her", "?", "Soll", "sie", "aus", "Ca\u00b7tay", "kom\u00b7men", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "ADV", "PTKVZ", "$.", "VMFIN", "PPER", "APPR", "NE", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Soll bei den Scythen sie sein erstlich vorgenommen?", "tokens": ["Soll", "bei", "den", "Scyt\u00b7hen", "sie", "sein", "erst\u00b7lich", "vor\u00b7ge\u00b7nom\u00b7men", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "APPR", "ART", "NN", "PPER", "PPOSAT", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Es will mir gar nicht ein, da\u00df in der Barbarei", "tokens": ["Es", "will", "mir", "gar", "nicht", "ein", ",", "da\u00df", "in", "der", "Bar\u00b7ba\u00b7rei"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "PTKNEG", "PTKVZ", "$,", "KOUS", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "ein solches edles Kind erzeuget worden sei.", "tokens": ["ein", "sol\u00b7ches", "ed\u00b7les", "Kind", "er\u00b7zeu\u00b7get", "wor\u00b7den", "sei", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "ADJA", "NN", "VVFIN", "VAPP", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Nein! was man auch hier sagt, uns ", "tokens": ["Nein", "!", "was", "man", "auch", "hier", "sagt", ",", "uns"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["PTKANT", "$.", "PWS", "PIS", "ADV", "ADV", "VVFIN", "$,", "PPER"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.10": {"text": "Wir haben es erdacht. Ihr Andern, gebt Geh\u00f6re", "tokens": ["Wir", "ha\u00b7ben", "es", "er\u00b7dacht", ".", "Ihr", "An\u00b7dern", ",", "gebt", "Ge\u00b7h\u00f6\u00b7re"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VAFIN", "PPER", "VVPP", "$.", "PPOSAT", "ADJA", "$,", "VVFIN", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "und g\u00f6nnt uns diesen Ruhm! Der gute Guttenberg", "tokens": ["und", "g\u00f6nnt", "uns", "die\u00b7sen", "Ruhm", "!", "Der", "gu\u00b7te", "Gut\u00b7ten\u00b7berg"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "PDAT", "NN", "$.", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "hat bei uns aufgebracht ein rechtes gutes Werk", "tokens": ["hat", "bei", "uns", "auf\u00b7ge\u00b7bracht", "ein", "rech\u00b7tes", "gu\u00b7tes", "Werk"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "APPR", "PPER", "VVFIN", "ART", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "und das sich selbst gut preist. Die Sequan und die Tiber,", "tokens": ["und", "das", "sich", "selbst", "gut", "preist", ".", "Die", "Se\u00b7quan", "und", "die", "Ti\u00b7ber", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRELS", "PRF", "ADV", "ADJD", "VVFIN", "$.", "ART", "NN", "KON", "ART", "NE", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "die F\u00fcrsten ihrer Fl\u00fcss', erz\u00fcrnen sich hier\u00fcber,", "tokens": ["die", "F\u00fcrs\u00b7ten", "ih\u00b7rer", "Fl\u00fcss'", ",", "er\u00b7z\u00fcr\u00b7nen", "sich", "hier\u00b7\u00fc\u00b7ber", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "$,", "VVFIN", "PRF", "PAV", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "da\u00df unter anderen der Necker und der Rhein", "tokens": ["da\u00df", "un\u00b7ter", "an\u00b7de\u00b7ren", "der", "Ne\u00b7cker", "und", "der", "Rhein"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "APPR", "PIS", "ART", "NN", "KON", "ART", "NE"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "gl\u00fcckseliger als sie hierbei gewesen sein.", "tokens": ["gl\u00fcck\u00b7se\u00b7li\u00b7ger", "als", "sie", "hier\u00b7bei", "ge\u00b7we\u00b7sen", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "KOKOM", "PPER", "ADV", "VAPP", "VAINF", "$."], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.17": {"text": "Sie r\u00fchmen, was es sei, die andern Nationen,", "tokens": ["Sie", "r\u00fch\u00b7men", ",", "was", "es", "sei", ",", "die", "an\u00b7dern", "Na\u00b7ti\u00b7o\u00b7nen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PWS", "PPER", "VAFIN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "was sie auch auserdacht. Wer will uns recht belohnen,", "tokens": ["was", "sie", "auch", "au\u00b7ser\u00b7dacht", ".", "Wer", "will", "uns", "recht", "be\u00b7loh\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "VVPP", "$.", "PWS", "VMFIN", "PPER", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "uns Teutschen, das Gesch\u00fctz' und hohe Druckerei,", "tokens": ["uns", "Teut\u00b7schen", ",", "das", "Ge\u00b7sch\u00fctz'", "und", "ho\u00b7he", "Dru\u00b7cke\u00b7rei", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "$,", "ART", "NN", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "als unser duppelt Lob? Di\u00df sind dieselbten zwei,", "tokens": ["als", "un\u00b7ser", "dup\u00b7pelt", "Lob", "?", "Di\u00df", "sind", "die\u00b7selb\u00b7ten", "zwei", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "NN", "$.", "PDS", "VAFIN", "PDAT", "CARD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "darmit wir Jupitern auch selbst wie furchtsam machen,", "tokens": ["dar\u00b7mit", "wir", "Ju\u00b7pi\u00b7tern", "auch", "selbst", "wie", "furcht\u00b7sam", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NN", "ADV", "ADV", "KOKOM", "ADJD", "VVINF", "$,"], "meter": "-+-+---+-+-+-", "measure": "unknown.measure.penta"}, "line.22": {"text": "wenn wir die Feurwerk' und St\u00fccken lassen krachen", "tokens": ["wenn", "wir", "die", "Feur\u00b7werk'", "und", "St\u00fc\u00b7cken", "las\u00b7sen", "kra\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "NN", "KON", "NN", "VVINF", "VVINF"], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.23": {"text": "und donnern gleich wie er. Minerven und Mercur", "tokens": ["und", "don\u00b7nern", "gleich", "wie", "er", ".", "Mi\u00b7ner\u00b7ven", "und", "Mer\u00b7cur"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "NN", "ADV", "KOKOM", "PPER", "$.", "NN", "KON", "NN"], "meter": "-+-+--+-+--+", "measure": "iambic.penta.relaxed"}, "line.24": {"text": "verdreusts, da\u00df wir gelangt auf eine h\u00f6hre Spur,", "tokens": ["ver\u00b7dreusts", ",", "da\u00df", "wir", "ge\u00b7langt", "auf", "ei\u00b7ne", "h\u00f6h\u00b7re", "Spur", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "KOUS", "PPER", "VVPP", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "sind weiser noch als sie. Die freien Druckereien", "tokens": ["sind", "wei\u00b7ser", "noch", "als", "sie", ".", "Die", "frei\u00b7en", "Dru\u00b7cke\u00b7rei\u00b7en"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VAFIN", "ADJD", "ADV", "KOUS", "PPER", "$.", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "sind reger Sinnen Trost, dar\u00fcber sie sich freuen,", "tokens": ["sind", "re\u00b7ger", "Sin\u00b7nen", "Trost", ",", "da\u00b7r\u00fc\u00b7ber", "sie", "sich", "freu\u00b7en", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJA", "NN", "NN", "$,", "PAV", "PPER", "PRF", "VVINF", "$,"], "meter": "---+-+-+-+-+-", "measure": "unknown.measure.penta"}, "line.27": {"text": "da\u00df nun, was l\u00f6blich ist, nicht unter k\u00f6nne gehn,", "tokens": ["da\u00df", "nun", ",", "was", "l\u00f6b\u00b7lich", "ist", ",", "nicht", "un\u00b7ter", "k\u00f6n\u00b7ne", "gehn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "$,", "PRELS", "ADJD", "VAFIN", "$,", "PTKNEG", "APPR", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "da\u00df Kunst nun mit der Welt kan in die Wette stehn.", "tokens": ["da\u00df", "Kunst", "nun", "mit", "der", "Welt", "kan", "in", "die", "Wet\u00b7te", "stehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "ADV", "APPR", "ART", "NN", "VMFIN", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Du g\u00f6ttliches Gesch\u00f6pf\u00ab ach, da\u00df du nicht gewesen", "tokens": ["Du", "g\u00f6tt\u00b7li\u00b7ches", "Ge\u00b7sch\u00f6pf", "\u00ab", "ach", ",", "da\u00df", "du", "nicht", "ge\u00b7we\u00b7sen"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "ADJA", "NN", "$(", "ITJ", "$,", "KOUS", "PPER", "PTKNEG", "VAPP"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "zu der Gelehrten Zeit! Wir wollen ietzo lesen", "tokens": ["zu", "der", "Ge\u00b7lehr\u00b7ten", "Zeit", "!", "Wir", "wol\u00b7len", "iet\u00b7zo", "le\u00b7sen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "NN", "$.", "PPER", "VMFIN", "ADV", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "so manche sch\u00f6ne Schrift, die so kaum wird bedacht", "tokens": ["so", "man\u00b7che", "sch\u00f6\u00b7ne", "Schrift", ",", "die", "so", "kaum", "wird", "be\u00b7dacht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "PIAT", "ADJA", "NN", "$,", "PRELS", "ADV", "ADV", "VAFIN", "VVPP"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "und uns nach ihrer Zier ein eitels Sehnen macht.", "tokens": ["und", "uns", "nach", "ih\u00b7rer", "Zier", "ein", "ei\u00b7tels", "Seh\u00b7nen", "macht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "APPR", "PPOSAT", "NN", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "Du bist dieselbe Kunst, durch die wir das erlangen,", "tokens": ["Du", "bist", "die\u00b7sel\u00b7be", "Kunst", ",", "durch", "die", "wir", "das", "er\u00b7lan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PDAT", "NN", "$,", "APPR", "PRELS", "PPER", "PDS", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "was wir vom Himmel selbst gedenken zu empfangen,", "tokens": ["was", "wir", "vom", "Him\u00b7mel", "selbst", "ge\u00b7den\u00b7ken", "zu", "emp\u00b7fan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "APPRART", "NN", "ADV", "VVINF", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "als ders uns durch dich gibt: des Namens Ewigkeit,", "tokens": ["als", "ders", "uns", "durch", "dich", "gibt", ":", "des", "Na\u00b7mens", "E\u00b7wig\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PRF", "APPR", "PPER", "VVFIN", "$.", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "und was sonst nach uns bleibt, wann wir von keiner Zeit,", "tokens": ["und", "was", "sonst", "nach", "uns", "bleibt", ",", "wann", "wir", "von", "kei\u00b7ner", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ADV", "APPR", "PPER", "VVFIN", "$,", "PWAV", "PPER", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "doch aber alle Zeit von uns wird k\u00f6nnen wissen.", "tokens": ["doch", "a\u00b7ber", "al\u00b7le", "Zeit", "von", "uns", "wird", "k\u00f6n\u00b7nen", "wis\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PIAT", "NN", "APPR", "PPER", "VAFIN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.38": {"text": "Wir sind in Absein da. Wir haben uns beflissen", "tokens": ["Wir", "sind", "in", "Ab\u00b7sein", "da", ".", "Wir", "ha\u00b7ben", "uns", "be\u00b7flis\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "APPR", "NN", "PTKVZ", "$.", "PPER", "VAFIN", "PPER", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.39": {"text": "mit Nutz', o Kunst, auf dich. Was war es doch vorhin?", "tokens": ["mit", "Nutz'", ",", "o", "Kunst", ",", "auf", "dich", ".", "Was", "war", "es", "doch", "vor\u00b7hin", "?"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "FM", "NN", "$,", "APPR", "PPER", "$.", "PWS", "VAFIN", "PPER", "ADV", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.40": {"text": "(da\u00df wir die alte Zeit recht in Betrachtung ziehn!)", "tokens": ["(", "da\u00df", "wir", "die", "al\u00b7te", "Zeit", "recht", "in", "Be\u00b7trach\u00b7tung", "ziehn", "!", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "KOUS", "PPER", "ART", "ADJA", "NN", "ADV", "APPR", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.41": {"text": "Es war ein schweres Tun. Man sch\u00e4lete die Linden", "tokens": ["Es", "war", "ein", "schwe\u00b7res", "Tun", ".", "Man", "sch\u00e4\u00b7le\u00b7te", "die", "Lin\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "$.", "PIS", "VVFIN", "ART", "NE"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.42": {"text": "und schriebe, was man wolt', in die gewichsten Rinden", "tokens": ["und", "schrie\u00b7be", ",", "was", "man", "wolt'", ",", "in", "die", "ge\u00b7wichs\u00b7ten", "Rin\u00b7den"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "$,", "PRELS", "PIS", "VMFIN", "$,", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.43": {"text": "mit gro\u00dfer M\u00fch' und Kost. Tuch, Holz, Erz, Blei und Stein", "tokens": ["mit", "gro\u00b7\u00dfer", "M\u00fch'", "und", "Kost", ".", "Tuch", ",", "Holz", ",", "Erz", ",", "Blei", "und", "Stein"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "KON", "NN", "$.", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.44": {"text": "must' ihnen an der Statt, was uns Papir ist, sein.", "tokens": ["must'", "ih\u00b7nen", "an", "der", "Statt", ",", "was", "uns", "Pa\u00b7pir", "ist", ",", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["VMFIN", "PPER", "APPR", "ART", "NN", "$,", "PRELS", "PPER", "NN", "VAFIN", "$,", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.45": {"text": "Wie seliger sind wir, die wir ein Ding ersinnen,", "tokens": ["Wie", "se\u00b7li\u00b7ger", "sind", "wir", ",", "die", "wir", "ein", "Ding", "er\u00b7sin\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VAFIN", "PPER", "$,", "PRELS", "PPER", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.46": {"text": "das uns nicht viel gesteht, damit wir prangen k\u00f6nnen!", "tokens": ["das", "uns", "nicht", "viel", "ge\u00b7steht", ",", "da\u00b7mit", "wir", "pran\u00b7gen", "k\u00f6n\u00b7nen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PTKNEG", "ADV", "VVPP", "$,", "KOUS", "PPER", "VVFIN", "VMINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.47": {"text": "Was keinen Nutz' mehr gibt, das kompt zu unserm Nutz'.", "tokens": ["Was", "kei\u00b7nen", "Nutz'", "mehr", "gibt", ",", "das", "kompt", "zu", "un\u00b7serm", "Nutz'", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PIAT", "NN", "ADV", "VVFIN", "$,", "PDS", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.48": {"text": "Ein abgerissner Fleck beut Stahl und Eisen Trutz", "tokens": ["Ein", "ab\u00b7ge\u00b7riss\u00b7ner", "Fleck", "beut", "Stahl", "und", "Ei\u00b7sen", "Trutz"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN", "NN", "KON", "NN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.49": {"text": "und nennt sich ewiger. Die taurenden Metallen", "tokens": ["und", "nennt", "sich", "e\u00b7wi\u00b7ger", ".", "Die", "tau\u00b7ren\u00b7den", "Me\u00b7tal\u00b7len"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "VVFIN", "PRF", "ADJD", "$.", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.50": {"text": "sind durch das Ungemach des Himmels eingefallen!", "tokens": ["sind", "durch", "das", "Un\u00b7ge\u00b7mach", "des", "Him\u00b7mels", "ein\u00b7ge\u00b7fal\u00b7len", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "ART", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.51": {"text": "Des Cariens Beruf und Nilus Wunderbau", "tokens": ["Des", "Ca\u00b7ri\u00b7ens", "Be\u00b7ruf", "und", "Ni\u00b7lus", "Wun\u00b7der\u00b7bau"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "NN", "KON", "NE", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.52": {"text": "sind mit der alten Zeit auch worden faul und grau,", "tokens": ["sind", "mit", "der", "al\u00b7ten", "Zeit", "auch", "wor\u00b7den", "faul", "und", "grau", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "ART", "ADJA", "NN", "ADV", "VAPP", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.53": {"text": "gewesen Sterbliche, wie ihre Meister waren", "tokens": ["ge\u00b7we\u00b7sen", "Sterb\u00b7li\u00b7che", ",", "wie", "ih\u00b7re", "Meis\u00b7ter", "wa\u00b7ren"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["VAPP", "NN", "$,", "PWAV", "PPOSAT", "NN", "VAFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.54": {"text": "und alle Sachen sein. Wir haben erst erfahren", "tokens": ["und", "al\u00b7le", "Sa\u00b7chen", "sein", ".", "Wir", "ha\u00b7ben", "erst", "er\u00b7fah\u00b7ren"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "PIAT", "NN", "VAINF", "$.", "PPER", "VAFIN", "ADV", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.55": {"text": "im Alter dieser Welt, was es f\u00fcr Sachen sind,", "tokens": ["im", "Al\u00b7ter", "die\u00b7ser", "Welt", ",", "was", "es", "f\u00fcr", "Sa\u00b7chen", "sind", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PDAT", "NN", "$,", "PWS", "PPER", "APPR", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.56": {"text": "so f\u00fcr der Jahre Rost, Brand, Wasser, Schnee und Wind,", "tokens": ["so", "f\u00fcr", "der", "Jah\u00b7re", "Rost", ",", "Brand", ",", "Was\u00b7ser", ",", "Schnee", "und", "Wind", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.57": {"text": "und f\u00fcr das Sterben sein. Wir lassen Schriften gie\u00dfen,", "tokens": ["und", "f\u00fcr", "das", "Ster\u00b7ben", "sein", ".", "Wir", "las\u00b7sen", "Schrif\u00b7ten", "gie\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VAINF", "$.", "PPER", "VVFIN", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.58": {"text": "wir setzen nach der Kunst, wir ordnen, klopfen, schlie\u00dfen,", "tokens": ["wir", "set\u00b7zen", "nach", "der", "Kunst", ",", "wir", "ord\u00b7nen", ",", "klop\u00b7fen", ",", "schlie\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "$,", "PPER", "VVINF", "$,", "VVFIN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.59": {"text": "und lassen tragen auf. Ein Junge, der fast nicht,", "tokens": ["und", "las\u00b7sen", "tra\u00b7gen", "auf", ".", "Ein", "Jun\u00b7ge", ",", "der", "fast", "nicht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVINF", "VVFIN", "PTKVZ", "$.", "ART", "NN", "$,", "PRELS", "ADV", "PTKNEG", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.60": {"text": "was Schreiben ist, versteht, trutzt Boten ietzt und spricht,", "tokens": ["was", "Schrei\u00b7ben", "ist", ",", "ver\u00b7steht", ",", "trutzt", "Bo\u00b7ten", "ietzt", "und", "spricht", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "VAFIN", "$,", "VVFIN", "$,", "VVFIN", "NN", "ADV", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.61": {"text": "er k\u00f6nn' auf einen Tag mehr, als er in zwei Jahren,", "tokens": ["er", "k\u00f6nn'", "auf", "ei\u00b7nen", "Tag", "mehr", ",", "als", "er", "in", "zwei", "Jah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPR", "ART", "NN", "ADV", "$,", "KOUS", "PPER", "APPR", "CARD", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.62": {"text": "verschaffen aufs Papir. Wir d\u00fcrfen schlechter Waren.", "tokens": ["ver\u00b7schaf\u00b7fen", "aufs", "Pa\u00b7pir", ".", "Wir", "d\u00fcr\u00b7fen", "schlech\u00b7ter", "Wa\u00b7ren", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "APPRART", "NN", "$.", "PPER", "VMFIN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.63": {"text": "Die Feder ist hier Zeug, die Dinte Ru\u00df und \u00d6l,", "tokens": ["Die", "Fe\u00b7der", "ist", "hier", "Zeug", ",", "die", "Din\u00b7te", "Ru\u00df", "und", "\u00d6l", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "NN", "$,", "ART", "NN", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.64": {"text": "die Presse Schreiberin, der Drucker ihre Seel',", "tokens": ["die", "Pres\u00b7se", "Schrei\u00b7be\u00b7rin", ",", "der", "Dru\u00b7cker", "ih\u00b7re", "Seel'", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$,", "ART", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.65": {"text": "als der sie rege macht. Geh' Einer nun und schaue,", "tokens": ["als", "der", "sie", "re\u00b7ge", "macht", ".", "Geh'", "Ei\u00b7ner", "nun", "und", "schau\u00b7e", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "PPER", "ADJA", "VVFIN", "$.", "NE", "PIS", "ADV", "KON", "VVFIN", "$,"], "meter": "--+--+-+-+-+-", "measure": "anapaest.di.plus"}, "line.66": {"text": "wie er Gold, Eisen, Erz' und Marmeln das vertraue,", "tokens": ["wie", "er", "Gold", ",", "Ei\u00b7sen", ",", "Er\u00b7z'", "und", "Mar\u00b7meln", "das", "ver\u00b7trau\u00b7e", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "NN", "$,", "NN", "$,", "NN", "KON", "NN", "ART", "ADJA", "$,"], "meter": "+-++--+-+-+-+-", "measure": "trochaic.septa.relaxed"}, "line.67": {"text": "was ewig bleiben soll! Wir nehmen das Papier.", "tokens": ["was", "e\u00b7wig", "blei\u00b7ben", "soll", "!", "Wir", "neh\u00b7men", "das", "Pa\u00b7pier", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADJD", "VVINF", "VMFIN", "$.", "PPER", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.68": {"text": "Was ihm an St\u00e4rke fehlt, ersetzt die Menge hier", "tokens": ["Was", "ihm", "an", "St\u00e4r\u00b7ke", "fehlt", ",", "er\u00b7setzt", "die", "Men\u00b7ge", "hier"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWS", "PPER", "APPR", "NN", "VVFIN", "$,", "VVFIN", "ART", "NN", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.69": {"text": "und bringt es redlich ein. Es ist umb ein Verderben,", "tokens": ["und", "bringt", "es", "red\u00b7lich", "ein", ".", "Es", "ist", "umb", "ein", "Ver\u00b7der\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADJD", "PTKVZ", "$.", "PPER", "VAFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.70": {"text": "so mu\u00df ein einzeln Ding, wie stark es ist, doch sterben.", "tokens": ["so", "mu\u00df", "ein", "ein\u00b7zeln", "Ding", ",", "wie", "stark", "es", "ist", ",", "doch", "ster\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "ADJA", "NN", "$,", "PWAV", "ADJD", "PPER", "VAFIN", "$,", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.71": {"text": "Kein Ort ist gut darf\u00fcr, da\u00df seiner Wunder Schein,", "tokens": ["Kein", "Ort", "ist", "gut", "dar\u00b7f\u00fcr", ",", "da\u00df", "sei\u00b7ner", "Wun\u00b7der", "Schein", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "ADJD", "PAV", "$,", "KOUS", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.72": {"text": "den er alleine hat, bei ihm kan sicher sein.", "tokens": ["den", "er", "al\u00b7lei\u00b7ne", "hat", ",", "bei", "ihm", "kan", "si\u00b7cher", "sein", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "VAFIN", "$,", "APPR", "PPER", "VMFIN", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.73": {"text": "Wir setzen unsern Bau an tausent tausent Enden", "tokens": ["Wir", "set\u00b7zen", "un\u00b7sern", "Bau", "an", "tau\u00b7sent", "tau\u00b7sent", "En\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "APPR", "CARD", "CARD", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.74": {"text": "mit leichter M\u00fch' und Kost. Wohin wir was versenden,", "tokens": ["mit", "leich\u00b7ter", "M\u00fch'", "und", "Kost", ".", "Wo\u00b7hin", "wir", "was", "ver\u00b7sen\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "KON", "NN", "$.", "PWAV", "PPER", "PIS", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.75": {"text": "das mehret sich durch sich. Wir trauen uns der Welt,", "tokens": ["das", "meh\u00b7ret", "sich", "durch", "sich", ".", "Wir", "trau\u00b7en", "uns", "der", "Welt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PRF", "APPR", "PRF", "$.", "PPER", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.76": {"text": "so gehn wir nicht eh' ein, bi\u00df sie zu Grunde f\u00e4lt.", "tokens": ["so", "gehn", "wir", "nicht", "eh'", "ein", ",", "bi\u00df", "sie", "zu", "Grun\u00b7de", "f\u00e4lt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PTKNEG", "ADV", "PTKVZ", "$,", "KOUS", "PPER", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+---+-+", "measure": "unknown.measure.penta"}, "line.77": {"text": "Ihr unbedachtes Volk, was wolt ihr viel verreisen", "tokens": ["Ihr", "un\u00b7be\u00b7dach\u00b7tes", "Volk", ",", "was", "wolt", "ihr", "viel", "ver\u00b7rei\u00b7sen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN", "$,", "PWS", "VMFIN", "PPER", "ADV", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.78": {"text": "in die gevierte Welt? Wir k\u00f6nnen Alles weisen,", "tokens": ["in", "die", "ge\u00b7vier\u00b7te", "Welt", "?", "Wir", "k\u00f6n\u00b7nen", "Al\u00b7les", "wei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$.", "PPER", "VMFIN", "PIS", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.79": {"text": "was ihr seht \u00fcberall und doch wol kaum noch wi\u00dft,", "tokens": ["was", "ihr", "seht", "\u00fc\u00b7be\u00b7rall", "und", "doch", "wol", "kaum", "noch", "wi\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVFIN", "ADV", "KON", "ADV", "ADV", "ADV", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.80": {"text": "wenn ihr herwieder kompt, darauf ihr wagen m\u00fc\u00dft", "tokens": ["wenn", "ihr", "her\u00b7wie\u00b7der", "kompt", ",", "da\u00b7rauf", "ihr", "wa\u00b7gen", "m\u00fc\u00dft"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "VVFIN", "$,", "PAV", "PPER", "VVINF", "VMFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.81": {"text": "Zeit, Kosten, Leib und mehr. Den Ruhm von solchen Sachen", "tokens": ["Zeit", ",", "Kos\u00b7ten", ",", "Leib", "und", "mehr", ".", "Den", "Ruhm", "von", "sol\u00b7chen", "Sa\u00b7chen"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "NN", "$,", "NN", "KON", "ADV", "$.", "ART", "NN", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.82": {"text": "pflegt die Anwesenheit geringer stets zu machen.", "tokens": ["pflegt", "die", "An\u00b7we\u00b7sen\u00b7heit", "ge\u00b7rin\u00b7ger", "stets", "zu", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ADJD", "ADV", "PTKZU", "VVINF", "$."], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.83": {"text": "Was der verbrante Mohr und Grieche lobt' so sehr,", "tokens": ["Was", "der", "ver\u00b7bran\u00b7te", "Mohr", "und", "Grie\u00b7che", "lobt'", "so", "sehr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "ADJA", "NN", "KON", "NN", "VVFIN", "ADV", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.84": {"text": "das ist nun meistenteils nichts als ein Name mehr,", "tokens": ["das", "ist", "nun", "meis\u00b7ten\u00b7teils", "nichts", "als", "ein", "Na\u00b7me", "mehr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "ADV", "PIS", "KOKOM", "ART", "NN", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.85": {"text": "der keinen Sinn vergn\u00fcgt. Wir nehmens von den Steinen", "tokens": ["der", "kei\u00b7nen", "Sinn", "ver\u00b7gn\u00fcgt", ".", "Wir", "neh\u00b7mens", "von", "den", "Stei\u00b7nen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "PIAT", "NN", "VVPP", "$.", "PPER", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.86": {"text": "und bringens in ein Buch, das unser gutes Meinen", "tokens": ["und", "brin\u00b7gens", "in", "ein", "Buch", ",", "das", "un\u00b7ser", "gu\u00b7tes", "Mei\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "ADV", "APPR", "ART", "NN", "$,", "PRELS", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.87": {"text": "gibt kl\u00e4rlich an den Tag. Wir dienen Iederman,", "tokens": ["gibt", "kl\u00e4r\u00b7lich", "an", "den", "Tag", ".", "Wir", "die\u00b7nen", "Ie\u00b7der\u00b7man", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "APPR", "ART", "NN", "$.", "PPER", "VVFIN", "NE", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.88": {"text": "und was uns n\u00fctzlich ist, dem tun wir W\u00fcrden an.", "tokens": ["und", "was", "uns", "n\u00fctz\u00b7lich", "ist", ",", "dem", "tun", "wir", "W\u00fcr\u00b7den", "an", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "ADJD", "VAFIN", "$,", "PRELS", "VVFIN", "PPER", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.89": {"text": "Wer wird hier euren Flei\u00df, Herr ", "tokens": ["Wer", "wird", "hier", "eu\u00b7ren", "Flei\u00df", ",", "Herr"], "token_info": ["word", "word", "word", "word", "word", "punct", "word"], "pos": ["PWS", "VAFIN", "ADV", "PPOSAT", "NN", "$,", "NN"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.90": {"text": "da\u00df ihr euch auf den Nutz' der K\u00fcnftigen befliessen", "tokens": ["da\u00df", "ihr", "euch", "auf", "den", "Nutz'", "der", "K\u00fcnf\u00b7ti\u00b7gen", "be\u00b7flies\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PRF", "APPR", "ART", "NN", "ART", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.91": {"text": "und hoch umb uns verdient? Wir schreiben auf Papir,", "tokens": ["und", "hoch", "umb", "uns", "ver\u00b7dient", "?", "Wir", "schrei\u00b7ben", "auf", "Pa\u00b7pir", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "APPR", "PPER", "VVPP", "$.", "PPER", "VVFIN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.92": {"text": "und di\u00df k\u00f6mpt nicht weit aus. Ihr tragts der Sonnen f\u00fcr,", "tokens": ["und", "di\u00df", "k\u00f6mpt", "nicht", "weit", "aus", ".", "Ihr", "tragts", "der", "Son\u00b7nen", "f\u00fcr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VVFIN", "PTKNEG", "ADJD", "PTKVZ", "$.", "PPER", "VVFIN", "ART", "NN", "APPR", "$,"], "meter": "-+--++-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.93": {"text": "und bringets in die Welt. So lange man wird schreiben", "tokens": ["und", "brin\u00b7gets", "in", "die", "Welt", ".", "So", "lan\u00b7ge", "man", "wird", "schrei\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "$.", "ADV", "ADV", "PIS", "VAFIN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.94": {"text": "und die gelobte Kunst der Druckereien treiben,", "tokens": ["und", "die", "ge\u00b7lob\u00b7te", "Kunst", "der", "Dru\u00b7cke\u00b7rei\u00b7en", "trei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.95": {"text": "so lange wird di\u00df Werk, das ihr habt aufgef\u00fchrt,", "tokens": ["so", "lan\u00b7ge", "wird", "di\u00df", "Werk", ",", "das", "ihr", "habt", "auf\u00b7ge\u00b7f\u00fchrt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VAFIN", "PDS", "NN", "$,", "PRELS", "PPER", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.96": {"text": "mit immer frischern Lob' und Ehren sein geziert.", "tokens": ["mit", "im\u00b7mer", "fri\u00b7schern", "Lob'", "und", "Eh\u00b7ren", "sein", "ge\u00b7ziert", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "ADJA", "NN", "KON", "NN", "PPOSAT", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Warumb nicht, werter Freund, solt' ich euch nicht zu Willen", "tokens": ["Wa\u00b7rumb", "nicht", ",", "wer\u00b7ter", "Freund", ",", "solt'", "ich", "euch", "nicht", "zu", "Wil\u00b7len"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PTKNEG", "$,", "ADJA", "NN", "$,", "VMFIN", "PPER", "PPER", "PTKNEG", "APPR", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "auf euer Bitten sein? Ich will den Wundsch erf\u00fcllen,", "tokens": ["auf", "eu\u00b7er", "Bit\u00b7ten", "sein", "?", "Ich", "will", "den", "Wund\u00b7sch", "er\u00b7f\u00fcl\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VAINF", "$.", "PPER", "VMFIN", "ART", "NN", "VVINF", "$,"], "meter": "++-+-+-+-+--+-", "measure": "trochaic.septa.relaxed"}, "line.3": {"text": "den Andere getan. Die edle Druckerei", "tokens": ["den", "An\u00b7de\u00b7re", "ge\u00b7tan", ".", "Die", "ed\u00b7le", "Dru\u00b7cke\u00b7rei"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "PIS", "VVPP", "$.", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "ist wol der Ehren wert, da\u00df sie gelobet sei.", "tokens": ["ist", "wol", "der", "Eh\u00b7ren", "wert", ",", "da\u00df", "sie", "ge\u00b7lo\u00b7bet", "sei", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "VVFIN", "$,", "KOUS", "PPER", "VVFIN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wo k\u00f6mpt sie aber her? Soll sie aus Catay kommen?", "tokens": ["Wo", "k\u00f6mpt", "sie", "a\u00b7ber", "her", "?", "Soll", "sie", "aus", "Ca\u00b7tay", "kom\u00b7men", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "ADV", "PTKVZ", "$.", "VMFIN", "PPER", "APPR", "NE", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Soll bei den Scythen sie sein erstlich vorgenommen?", "tokens": ["Soll", "bei", "den", "Scyt\u00b7hen", "sie", "sein", "erst\u00b7lich", "vor\u00b7ge\u00b7nom\u00b7men", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "APPR", "ART", "NN", "PPER", "PPOSAT", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Es will mir gar nicht ein, da\u00df in der Barbarei", "tokens": ["Es", "will", "mir", "gar", "nicht", "ein", ",", "da\u00df", "in", "der", "Bar\u00b7ba\u00b7rei"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "PTKNEG", "PTKVZ", "$,", "KOUS", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "ein solches edles Kind erzeuget worden sei.", "tokens": ["ein", "sol\u00b7ches", "ed\u00b7les", "Kind", "er\u00b7zeu\u00b7get", "wor\u00b7den", "sei", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "ADJA", "NN", "VVFIN", "VAPP", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Nein! was man auch hier sagt, uns ", "tokens": ["Nein", "!", "was", "man", "auch", "hier", "sagt", ",", "uns"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["PTKANT", "$.", "PWS", "PIS", "ADV", "ADV", "VVFIN", "$,", "PPER"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.10": {"text": "Wir haben es erdacht. Ihr Andern, gebt Geh\u00f6re", "tokens": ["Wir", "ha\u00b7ben", "es", "er\u00b7dacht", ".", "Ihr", "An\u00b7dern", ",", "gebt", "Ge\u00b7h\u00f6\u00b7re"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VAFIN", "PPER", "VVPP", "$.", "PPOSAT", "ADJA", "$,", "VVFIN", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "und g\u00f6nnt uns diesen Ruhm! Der gute Guttenberg", "tokens": ["und", "g\u00f6nnt", "uns", "die\u00b7sen", "Ruhm", "!", "Der", "gu\u00b7te", "Gut\u00b7ten\u00b7berg"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "PDAT", "NN", "$.", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "hat bei uns aufgebracht ein rechtes gutes Werk", "tokens": ["hat", "bei", "uns", "auf\u00b7ge\u00b7bracht", "ein", "rech\u00b7tes", "gu\u00b7tes", "Werk"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "APPR", "PPER", "VVFIN", "ART", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "und das sich selbst gut preist. Die Sequan und die Tiber,", "tokens": ["und", "das", "sich", "selbst", "gut", "preist", ".", "Die", "Se\u00b7quan", "und", "die", "Ti\u00b7ber", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRELS", "PRF", "ADV", "ADJD", "VVFIN", "$.", "ART", "NN", "KON", "ART", "NE", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "die F\u00fcrsten ihrer Fl\u00fcss', erz\u00fcrnen sich hier\u00fcber,", "tokens": ["die", "F\u00fcrs\u00b7ten", "ih\u00b7rer", "Fl\u00fcss'", ",", "er\u00b7z\u00fcr\u00b7nen", "sich", "hier\u00b7\u00fc\u00b7ber", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "$,", "VVFIN", "PRF", "PAV", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "da\u00df unter anderen der Necker und der Rhein", "tokens": ["da\u00df", "un\u00b7ter", "an\u00b7de\u00b7ren", "der", "Ne\u00b7cker", "und", "der", "Rhein"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "APPR", "PIS", "ART", "NN", "KON", "ART", "NE"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "gl\u00fcckseliger als sie hierbei gewesen sein.", "tokens": ["gl\u00fcck\u00b7se\u00b7li\u00b7ger", "als", "sie", "hier\u00b7bei", "ge\u00b7we\u00b7sen", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "KOKOM", "PPER", "ADV", "VAPP", "VAINF", "$."], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.17": {"text": "Sie r\u00fchmen, was es sei, die andern Nationen,", "tokens": ["Sie", "r\u00fch\u00b7men", ",", "was", "es", "sei", ",", "die", "an\u00b7dern", "Na\u00b7ti\u00b7o\u00b7nen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PWS", "PPER", "VAFIN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "was sie auch auserdacht. Wer will uns recht belohnen,", "tokens": ["was", "sie", "auch", "au\u00b7ser\u00b7dacht", ".", "Wer", "will", "uns", "recht", "be\u00b7loh\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "VVPP", "$.", "PWS", "VMFIN", "PPER", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "uns Teutschen, das Gesch\u00fctz' und hohe Druckerei,", "tokens": ["uns", "Teut\u00b7schen", ",", "das", "Ge\u00b7sch\u00fctz'", "und", "ho\u00b7he", "Dru\u00b7cke\u00b7rei", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "$,", "ART", "NN", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "als unser duppelt Lob? Di\u00df sind dieselbten zwei,", "tokens": ["als", "un\u00b7ser", "dup\u00b7pelt", "Lob", "?", "Di\u00df", "sind", "die\u00b7selb\u00b7ten", "zwei", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "NN", "$.", "PDS", "VAFIN", "PDAT", "CARD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "darmit wir Jupitern auch selbst wie furchtsam machen,", "tokens": ["dar\u00b7mit", "wir", "Ju\u00b7pi\u00b7tern", "auch", "selbst", "wie", "furcht\u00b7sam", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NN", "ADV", "ADV", "KOKOM", "ADJD", "VVINF", "$,"], "meter": "-+-+---+-+-+-", "measure": "unknown.measure.penta"}, "line.22": {"text": "wenn wir die Feurwerk' und St\u00fccken lassen krachen", "tokens": ["wenn", "wir", "die", "Feur\u00b7werk'", "und", "St\u00fc\u00b7cken", "las\u00b7sen", "kra\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "NN", "KON", "NN", "VVINF", "VVINF"], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.23": {"text": "und donnern gleich wie er. Minerven und Mercur", "tokens": ["und", "don\u00b7nern", "gleich", "wie", "er", ".", "Mi\u00b7ner\u00b7ven", "und", "Mer\u00b7cur"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "NN", "ADV", "KOKOM", "PPER", "$.", "NN", "KON", "NN"], "meter": "-+-+--+-+--+", "measure": "iambic.penta.relaxed"}, "line.24": {"text": "verdreusts, da\u00df wir gelangt auf eine h\u00f6hre Spur,", "tokens": ["ver\u00b7dreusts", ",", "da\u00df", "wir", "ge\u00b7langt", "auf", "ei\u00b7ne", "h\u00f6h\u00b7re", "Spur", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "KOUS", "PPER", "VVPP", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "sind weiser noch als sie. Die freien Druckereien", "tokens": ["sind", "wei\u00b7ser", "noch", "als", "sie", ".", "Die", "frei\u00b7en", "Dru\u00b7cke\u00b7rei\u00b7en"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VAFIN", "ADJD", "ADV", "KOUS", "PPER", "$.", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "sind reger Sinnen Trost, dar\u00fcber sie sich freuen,", "tokens": ["sind", "re\u00b7ger", "Sin\u00b7nen", "Trost", ",", "da\u00b7r\u00fc\u00b7ber", "sie", "sich", "freu\u00b7en", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJA", "NN", "NN", "$,", "PAV", "PPER", "PRF", "VVINF", "$,"], "meter": "---+-+-+-+-+-", "measure": "unknown.measure.penta"}, "line.27": {"text": "da\u00df nun, was l\u00f6blich ist, nicht unter k\u00f6nne gehn,", "tokens": ["da\u00df", "nun", ",", "was", "l\u00f6b\u00b7lich", "ist", ",", "nicht", "un\u00b7ter", "k\u00f6n\u00b7ne", "gehn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "$,", "PRELS", "ADJD", "VAFIN", "$,", "PTKNEG", "APPR", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "da\u00df Kunst nun mit der Welt kan in die Wette stehn.", "tokens": ["da\u00df", "Kunst", "nun", "mit", "der", "Welt", "kan", "in", "die", "Wet\u00b7te", "stehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "ADV", "APPR", "ART", "NN", "VMFIN", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Du g\u00f6ttliches Gesch\u00f6pf\u00ab ach, da\u00df du nicht gewesen", "tokens": ["Du", "g\u00f6tt\u00b7li\u00b7ches", "Ge\u00b7sch\u00f6pf", "\u00ab", "ach", ",", "da\u00df", "du", "nicht", "ge\u00b7we\u00b7sen"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "ADJA", "NN", "$(", "ITJ", "$,", "KOUS", "PPER", "PTKNEG", "VAPP"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "zu der Gelehrten Zeit! Wir wollen ietzo lesen", "tokens": ["zu", "der", "Ge\u00b7lehr\u00b7ten", "Zeit", "!", "Wir", "wol\u00b7len", "iet\u00b7zo", "le\u00b7sen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "NN", "$.", "PPER", "VMFIN", "ADV", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "so manche sch\u00f6ne Schrift, die so kaum wird bedacht", "tokens": ["so", "man\u00b7che", "sch\u00f6\u00b7ne", "Schrift", ",", "die", "so", "kaum", "wird", "be\u00b7dacht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "PIAT", "ADJA", "NN", "$,", "PRELS", "ADV", "ADV", "VAFIN", "VVPP"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "und uns nach ihrer Zier ein eitels Sehnen macht.", "tokens": ["und", "uns", "nach", "ih\u00b7rer", "Zier", "ein", "ei\u00b7tels", "Seh\u00b7nen", "macht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "APPR", "PPOSAT", "NN", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "Du bist dieselbe Kunst, durch die wir das erlangen,", "tokens": ["Du", "bist", "die\u00b7sel\u00b7be", "Kunst", ",", "durch", "die", "wir", "das", "er\u00b7lan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PDAT", "NN", "$,", "APPR", "PRELS", "PPER", "PDS", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "was wir vom Himmel selbst gedenken zu empfangen,", "tokens": ["was", "wir", "vom", "Him\u00b7mel", "selbst", "ge\u00b7den\u00b7ken", "zu", "emp\u00b7fan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "APPRART", "NN", "ADV", "VVINF", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "als ders uns durch dich gibt: des Namens Ewigkeit,", "tokens": ["als", "ders", "uns", "durch", "dich", "gibt", ":", "des", "Na\u00b7mens", "E\u00b7wig\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PRF", "APPR", "PPER", "VVFIN", "$.", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "und was sonst nach uns bleibt, wann wir von keiner Zeit,", "tokens": ["und", "was", "sonst", "nach", "uns", "bleibt", ",", "wann", "wir", "von", "kei\u00b7ner", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ADV", "APPR", "PPER", "VVFIN", "$,", "PWAV", "PPER", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "doch aber alle Zeit von uns wird k\u00f6nnen wissen.", "tokens": ["doch", "a\u00b7ber", "al\u00b7le", "Zeit", "von", "uns", "wird", "k\u00f6n\u00b7nen", "wis\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PIAT", "NN", "APPR", "PPER", "VAFIN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.38": {"text": "Wir sind in Absein da. Wir haben uns beflissen", "tokens": ["Wir", "sind", "in", "Ab\u00b7sein", "da", ".", "Wir", "ha\u00b7ben", "uns", "be\u00b7flis\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "APPR", "NN", "PTKVZ", "$.", "PPER", "VAFIN", "PPER", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.39": {"text": "mit Nutz', o Kunst, auf dich. Was war es doch vorhin?", "tokens": ["mit", "Nutz'", ",", "o", "Kunst", ",", "auf", "dich", ".", "Was", "war", "es", "doch", "vor\u00b7hin", "?"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "FM", "NN", "$,", "APPR", "PPER", "$.", "PWS", "VAFIN", "PPER", "ADV", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.40": {"text": "(da\u00df wir die alte Zeit recht in Betrachtung ziehn!)", "tokens": ["(", "da\u00df", "wir", "die", "al\u00b7te", "Zeit", "recht", "in", "Be\u00b7trach\u00b7tung", "ziehn", "!", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "KOUS", "PPER", "ART", "ADJA", "NN", "ADV", "APPR", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.41": {"text": "Es war ein schweres Tun. Man sch\u00e4lete die Linden", "tokens": ["Es", "war", "ein", "schwe\u00b7res", "Tun", ".", "Man", "sch\u00e4\u00b7le\u00b7te", "die", "Lin\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "$.", "PIS", "VVFIN", "ART", "NE"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.42": {"text": "und schriebe, was man wolt', in die gewichsten Rinden", "tokens": ["und", "schrie\u00b7be", ",", "was", "man", "wolt'", ",", "in", "die", "ge\u00b7wichs\u00b7ten", "Rin\u00b7den"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "$,", "PRELS", "PIS", "VMFIN", "$,", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.43": {"text": "mit gro\u00dfer M\u00fch' und Kost. Tuch, Holz, Erz, Blei und Stein", "tokens": ["mit", "gro\u00b7\u00dfer", "M\u00fch'", "und", "Kost", ".", "Tuch", ",", "Holz", ",", "Erz", ",", "Blei", "und", "Stein"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "KON", "NN", "$.", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.44": {"text": "must' ihnen an der Statt, was uns Papir ist, sein.", "tokens": ["must'", "ih\u00b7nen", "an", "der", "Statt", ",", "was", "uns", "Pa\u00b7pir", "ist", ",", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["VMFIN", "PPER", "APPR", "ART", "NN", "$,", "PRELS", "PPER", "NN", "VAFIN", "$,", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.45": {"text": "Wie seliger sind wir, die wir ein Ding ersinnen,", "tokens": ["Wie", "se\u00b7li\u00b7ger", "sind", "wir", ",", "die", "wir", "ein", "Ding", "er\u00b7sin\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VAFIN", "PPER", "$,", "PRELS", "PPER", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.46": {"text": "das uns nicht viel gesteht, damit wir prangen k\u00f6nnen!", "tokens": ["das", "uns", "nicht", "viel", "ge\u00b7steht", ",", "da\u00b7mit", "wir", "pran\u00b7gen", "k\u00f6n\u00b7nen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PTKNEG", "ADV", "VVPP", "$,", "KOUS", "PPER", "VVFIN", "VMINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.47": {"text": "Was keinen Nutz' mehr gibt, das kompt zu unserm Nutz'.", "tokens": ["Was", "kei\u00b7nen", "Nutz'", "mehr", "gibt", ",", "das", "kompt", "zu", "un\u00b7serm", "Nutz'", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PIAT", "NN", "ADV", "VVFIN", "$,", "PDS", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.48": {"text": "Ein abgerissner Fleck beut Stahl und Eisen Trutz", "tokens": ["Ein", "ab\u00b7ge\u00b7riss\u00b7ner", "Fleck", "beut", "Stahl", "und", "Ei\u00b7sen", "Trutz"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN", "NN", "KON", "NN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.49": {"text": "und nennt sich ewiger. Die taurenden Metallen", "tokens": ["und", "nennt", "sich", "e\u00b7wi\u00b7ger", ".", "Die", "tau\u00b7ren\u00b7den", "Me\u00b7tal\u00b7len"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "VVFIN", "PRF", "ADJD", "$.", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.50": {"text": "sind durch das Ungemach des Himmels eingefallen!", "tokens": ["sind", "durch", "das", "Un\u00b7ge\u00b7mach", "des", "Him\u00b7mels", "ein\u00b7ge\u00b7fal\u00b7len", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "ART", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.51": {"text": "Des Cariens Beruf und Nilus Wunderbau", "tokens": ["Des", "Ca\u00b7ri\u00b7ens", "Be\u00b7ruf", "und", "Ni\u00b7lus", "Wun\u00b7der\u00b7bau"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "NN", "KON", "NE", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.52": {"text": "sind mit der alten Zeit auch worden faul und grau,", "tokens": ["sind", "mit", "der", "al\u00b7ten", "Zeit", "auch", "wor\u00b7den", "faul", "und", "grau", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "ART", "ADJA", "NN", "ADV", "VAPP", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.53": {"text": "gewesen Sterbliche, wie ihre Meister waren", "tokens": ["ge\u00b7we\u00b7sen", "Sterb\u00b7li\u00b7che", ",", "wie", "ih\u00b7re", "Meis\u00b7ter", "wa\u00b7ren"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["VAPP", "NN", "$,", "PWAV", "PPOSAT", "NN", "VAFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.54": {"text": "und alle Sachen sein. Wir haben erst erfahren", "tokens": ["und", "al\u00b7le", "Sa\u00b7chen", "sein", ".", "Wir", "ha\u00b7ben", "erst", "er\u00b7fah\u00b7ren"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "PIAT", "NN", "VAINF", "$.", "PPER", "VAFIN", "ADV", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.55": {"text": "im Alter dieser Welt, was es f\u00fcr Sachen sind,", "tokens": ["im", "Al\u00b7ter", "die\u00b7ser", "Welt", ",", "was", "es", "f\u00fcr", "Sa\u00b7chen", "sind", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PDAT", "NN", "$,", "PWS", "PPER", "APPR", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.56": {"text": "so f\u00fcr der Jahre Rost, Brand, Wasser, Schnee und Wind,", "tokens": ["so", "f\u00fcr", "der", "Jah\u00b7re", "Rost", ",", "Brand", ",", "Was\u00b7ser", ",", "Schnee", "und", "Wind", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.57": {"text": "und f\u00fcr das Sterben sein. Wir lassen Schriften gie\u00dfen,", "tokens": ["und", "f\u00fcr", "das", "Ster\u00b7ben", "sein", ".", "Wir", "las\u00b7sen", "Schrif\u00b7ten", "gie\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VAINF", "$.", "PPER", "VVFIN", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.58": {"text": "wir setzen nach der Kunst, wir ordnen, klopfen, schlie\u00dfen,", "tokens": ["wir", "set\u00b7zen", "nach", "der", "Kunst", ",", "wir", "ord\u00b7nen", ",", "klop\u00b7fen", ",", "schlie\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "$,", "PPER", "VVINF", "$,", "VVFIN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.59": {"text": "und lassen tragen auf. Ein Junge, der fast nicht,", "tokens": ["und", "las\u00b7sen", "tra\u00b7gen", "auf", ".", "Ein", "Jun\u00b7ge", ",", "der", "fast", "nicht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVINF", "VVFIN", "PTKVZ", "$.", "ART", "NN", "$,", "PRELS", "ADV", "PTKNEG", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.60": {"text": "was Schreiben ist, versteht, trutzt Boten ietzt und spricht,", "tokens": ["was", "Schrei\u00b7ben", "ist", ",", "ver\u00b7steht", ",", "trutzt", "Bo\u00b7ten", "ietzt", "und", "spricht", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "VAFIN", "$,", "VVFIN", "$,", "VVFIN", "NN", "ADV", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.61": {"text": "er k\u00f6nn' auf einen Tag mehr, als er in zwei Jahren,", "tokens": ["er", "k\u00f6nn'", "auf", "ei\u00b7nen", "Tag", "mehr", ",", "als", "er", "in", "zwei", "Jah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPR", "ART", "NN", "ADV", "$,", "KOUS", "PPER", "APPR", "CARD", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.62": {"text": "verschaffen aufs Papir. Wir d\u00fcrfen schlechter Waren.", "tokens": ["ver\u00b7schaf\u00b7fen", "aufs", "Pa\u00b7pir", ".", "Wir", "d\u00fcr\u00b7fen", "schlech\u00b7ter", "Wa\u00b7ren", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "APPRART", "NN", "$.", "PPER", "VMFIN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.63": {"text": "Die Feder ist hier Zeug, die Dinte Ru\u00df und \u00d6l,", "tokens": ["Die", "Fe\u00b7der", "ist", "hier", "Zeug", ",", "die", "Din\u00b7te", "Ru\u00df", "und", "\u00d6l", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "NN", "$,", "ART", "NN", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.64": {"text": "die Presse Schreiberin, der Drucker ihre Seel',", "tokens": ["die", "Pres\u00b7se", "Schrei\u00b7be\u00b7rin", ",", "der", "Dru\u00b7cker", "ih\u00b7re", "Seel'", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$,", "ART", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.65": {"text": "als der sie rege macht. Geh' Einer nun und schaue,", "tokens": ["als", "der", "sie", "re\u00b7ge", "macht", ".", "Geh'", "Ei\u00b7ner", "nun", "und", "schau\u00b7e", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "PPER", "ADJA", "VVFIN", "$.", "NE", "PIS", "ADV", "KON", "VVFIN", "$,"], "meter": "--+--+-+-+-+-", "measure": "anapaest.di.plus"}, "line.66": {"text": "wie er Gold, Eisen, Erz' und Marmeln das vertraue,", "tokens": ["wie", "er", "Gold", ",", "Ei\u00b7sen", ",", "Er\u00b7z'", "und", "Mar\u00b7meln", "das", "ver\u00b7trau\u00b7e", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "NN", "$,", "NN", "$,", "NN", "KON", "NN", "ART", "ADJA", "$,"], "meter": "+-++--+-+-+-+-", "measure": "trochaic.septa.relaxed"}, "line.67": {"text": "was ewig bleiben soll! Wir nehmen das Papier.", "tokens": ["was", "e\u00b7wig", "blei\u00b7ben", "soll", "!", "Wir", "neh\u00b7men", "das", "Pa\u00b7pier", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADJD", "VVINF", "VMFIN", "$.", "PPER", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.68": {"text": "Was ihm an St\u00e4rke fehlt, ersetzt die Menge hier", "tokens": ["Was", "ihm", "an", "St\u00e4r\u00b7ke", "fehlt", ",", "er\u00b7setzt", "die", "Men\u00b7ge", "hier"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWS", "PPER", "APPR", "NN", "VVFIN", "$,", "VVFIN", "ART", "NN", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.69": {"text": "und bringt es redlich ein. Es ist umb ein Verderben,", "tokens": ["und", "bringt", "es", "red\u00b7lich", "ein", ".", "Es", "ist", "umb", "ein", "Ver\u00b7der\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADJD", "PTKVZ", "$.", "PPER", "VAFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.70": {"text": "so mu\u00df ein einzeln Ding, wie stark es ist, doch sterben.", "tokens": ["so", "mu\u00df", "ein", "ein\u00b7zeln", "Ding", ",", "wie", "stark", "es", "ist", ",", "doch", "ster\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "ADJA", "NN", "$,", "PWAV", "ADJD", "PPER", "VAFIN", "$,", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.71": {"text": "Kein Ort ist gut darf\u00fcr, da\u00df seiner Wunder Schein,", "tokens": ["Kein", "Ort", "ist", "gut", "dar\u00b7f\u00fcr", ",", "da\u00df", "sei\u00b7ner", "Wun\u00b7der", "Schein", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "ADJD", "PAV", "$,", "KOUS", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.72": {"text": "den er alleine hat, bei ihm kan sicher sein.", "tokens": ["den", "er", "al\u00b7lei\u00b7ne", "hat", ",", "bei", "ihm", "kan", "si\u00b7cher", "sein", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "VAFIN", "$,", "APPR", "PPER", "VMFIN", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.73": {"text": "Wir setzen unsern Bau an tausent tausent Enden", "tokens": ["Wir", "set\u00b7zen", "un\u00b7sern", "Bau", "an", "tau\u00b7sent", "tau\u00b7sent", "En\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "APPR", "CARD", "CARD", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.74": {"text": "mit leichter M\u00fch' und Kost. Wohin wir was versenden,", "tokens": ["mit", "leich\u00b7ter", "M\u00fch'", "und", "Kost", ".", "Wo\u00b7hin", "wir", "was", "ver\u00b7sen\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "KON", "NN", "$.", "PWAV", "PPER", "PIS", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.75": {"text": "das mehret sich durch sich. Wir trauen uns der Welt,", "tokens": ["das", "meh\u00b7ret", "sich", "durch", "sich", ".", "Wir", "trau\u00b7en", "uns", "der", "Welt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PRF", "APPR", "PRF", "$.", "PPER", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.76": {"text": "so gehn wir nicht eh' ein, bi\u00df sie zu Grunde f\u00e4lt.", "tokens": ["so", "gehn", "wir", "nicht", "eh'", "ein", ",", "bi\u00df", "sie", "zu", "Grun\u00b7de", "f\u00e4lt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PTKNEG", "ADV", "PTKVZ", "$,", "KOUS", "PPER", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+---+-+", "measure": "unknown.measure.penta"}, "line.77": {"text": "Ihr unbedachtes Volk, was wolt ihr viel verreisen", "tokens": ["Ihr", "un\u00b7be\u00b7dach\u00b7tes", "Volk", ",", "was", "wolt", "ihr", "viel", "ver\u00b7rei\u00b7sen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN", "$,", "PWS", "VMFIN", "PPER", "ADV", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.78": {"text": "in die gevierte Welt? Wir k\u00f6nnen Alles weisen,", "tokens": ["in", "die", "ge\u00b7vier\u00b7te", "Welt", "?", "Wir", "k\u00f6n\u00b7nen", "Al\u00b7les", "wei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$.", "PPER", "VMFIN", "PIS", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.79": {"text": "was ihr seht \u00fcberall und doch wol kaum noch wi\u00dft,", "tokens": ["was", "ihr", "seht", "\u00fc\u00b7be\u00b7rall", "und", "doch", "wol", "kaum", "noch", "wi\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVFIN", "ADV", "KON", "ADV", "ADV", "ADV", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.80": {"text": "wenn ihr herwieder kompt, darauf ihr wagen m\u00fc\u00dft", "tokens": ["wenn", "ihr", "her\u00b7wie\u00b7der", "kompt", ",", "da\u00b7rauf", "ihr", "wa\u00b7gen", "m\u00fc\u00dft"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "VVFIN", "$,", "PAV", "PPER", "VVINF", "VMFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.81": {"text": "Zeit, Kosten, Leib und mehr. Den Ruhm von solchen Sachen", "tokens": ["Zeit", ",", "Kos\u00b7ten", ",", "Leib", "und", "mehr", ".", "Den", "Ruhm", "von", "sol\u00b7chen", "Sa\u00b7chen"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "NN", "$,", "NN", "KON", "ADV", "$.", "ART", "NN", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.82": {"text": "pflegt die Anwesenheit geringer stets zu machen.", "tokens": ["pflegt", "die", "An\u00b7we\u00b7sen\u00b7heit", "ge\u00b7rin\u00b7ger", "stets", "zu", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ADJD", "ADV", "PTKZU", "VVINF", "$."], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.83": {"text": "Was der verbrante Mohr und Grieche lobt' so sehr,", "tokens": ["Was", "der", "ver\u00b7bran\u00b7te", "Mohr", "und", "Grie\u00b7che", "lobt'", "so", "sehr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "ADJA", "NN", "KON", "NN", "VVFIN", "ADV", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.84": {"text": "das ist nun meistenteils nichts als ein Name mehr,", "tokens": ["das", "ist", "nun", "meis\u00b7ten\u00b7teils", "nichts", "als", "ein", "Na\u00b7me", "mehr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "ADV", "PIS", "KOKOM", "ART", "NN", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.85": {"text": "der keinen Sinn vergn\u00fcgt. Wir nehmens von den Steinen", "tokens": ["der", "kei\u00b7nen", "Sinn", "ver\u00b7gn\u00fcgt", ".", "Wir", "neh\u00b7mens", "von", "den", "Stei\u00b7nen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "PIAT", "NN", "VVPP", "$.", "PPER", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.86": {"text": "und bringens in ein Buch, das unser gutes Meinen", "tokens": ["und", "brin\u00b7gens", "in", "ein", "Buch", ",", "das", "un\u00b7ser", "gu\u00b7tes", "Mei\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "ADV", "APPR", "ART", "NN", "$,", "PRELS", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.87": {"text": "gibt kl\u00e4rlich an den Tag. Wir dienen Iederman,", "tokens": ["gibt", "kl\u00e4r\u00b7lich", "an", "den", "Tag", ".", "Wir", "die\u00b7nen", "Ie\u00b7der\u00b7man", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "APPR", "ART", "NN", "$.", "PPER", "VVFIN", "NE", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.88": {"text": "und was uns n\u00fctzlich ist, dem tun wir W\u00fcrden an.", "tokens": ["und", "was", "uns", "n\u00fctz\u00b7lich", "ist", ",", "dem", "tun", "wir", "W\u00fcr\u00b7den", "an", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "ADJD", "VAFIN", "$,", "PRELS", "VVFIN", "PPER", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.89": {"text": "Wer wird hier euren Flei\u00df, Herr ", "tokens": ["Wer", "wird", "hier", "eu\u00b7ren", "Flei\u00df", ",", "Herr"], "token_info": ["word", "word", "word", "word", "word", "punct", "word"], "pos": ["PWS", "VAFIN", "ADV", "PPOSAT", "NN", "$,", "NN"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.90": {"text": "da\u00df ihr euch auf den Nutz' der K\u00fcnftigen befliessen", "tokens": ["da\u00df", "ihr", "euch", "auf", "den", "Nutz'", "der", "K\u00fcnf\u00b7ti\u00b7gen", "be\u00b7flies\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PRF", "APPR", "ART", "NN", "ART", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.91": {"text": "und hoch umb uns verdient? Wir schreiben auf Papir,", "tokens": ["und", "hoch", "umb", "uns", "ver\u00b7dient", "?", "Wir", "schrei\u00b7ben", "auf", "Pa\u00b7pir", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "APPR", "PPER", "VVPP", "$.", "PPER", "VVFIN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.92": {"text": "und di\u00df k\u00f6mpt nicht weit aus. Ihr tragts der Sonnen f\u00fcr,", "tokens": ["und", "di\u00df", "k\u00f6mpt", "nicht", "weit", "aus", ".", "Ihr", "tragts", "der", "Son\u00b7nen", "f\u00fcr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VVFIN", "PTKNEG", "ADJD", "PTKVZ", "$.", "PPER", "VVFIN", "ART", "NN", "APPR", "$,"], "meter": "-+--++-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.93": {"text": "und bringets in die Welt. So lange man wird schreiben", "tokens": ["und", "brin\u00b7gets", "in", "die", "Welt", ".", "So", "lan\u00b7ge", "man", "wird", "schrei\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "$.", "ADV", "ADV", "PIS", "VAFIN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.94": {"text": "und die gelobte Kunst der Druckereien treiben,", "tokens": ["und", "die", "ge\u00b7lob\u00b7te", "Kunst", "der", "Dru\u00b7cke\u00b7rei\u00b7en", "trei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.95": {"text": "so lange wird di\u00df Werk, das ihr habt aufgef\u00fchrt,", "tokens": ["so", "lan\u00b7ge", "wird", "di\u00df", "Werk", ",", "das", "ihr", "habt", "auf\u00b7ge\u00b7f\u00fchrt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VAFIN", "PDS", "NN", "$,", "PRELS", "PPER", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.96": {"text": "mit immer frischern Lob' und Ehren sein geziert.", "tokens": ["mit", "im\u00b7mer", "fri\u00b7schern", "Lob'", "und", "Eh\u00b7ren", "sein", "ge\u00b7ziert", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "ADJA", "NN", "KON", "NN", "PPOSAT", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}