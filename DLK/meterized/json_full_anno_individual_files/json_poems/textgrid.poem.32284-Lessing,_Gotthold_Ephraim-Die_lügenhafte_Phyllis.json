{"textgrid.poem.32284": {"metadata": {"author": {"name": "Lessing, Gotthold Ephraim", "birth": "N.A.", "death": "N.A."}, "title": "Die l\u00fcgenhafte Phyllis", "genre": "verse", "period": "N.A.", "pub_year": 1755, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Mein D\u00e4mon spricht:", "tokens": ["Mein", "D\u00e4\u00b7mon", "spricht", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.2": {"text": "Kind, l\u00fcge nicht!", "tokens": ["Kind", ",", "l\u00fc\u00b7ge", "nicht", "!"], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "PTKNEG", "$."], "meter": "++-+", "measure": "iambic.di"}, "line.3": {"text": "Sonst werd' ich strafen m\u00fcssen,", "tokens": ["Sonst", "werd'", "ich", "stra\u00b7fen", "m\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "VVINF", "VMINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und dich zur Strafe k\u00fcssen.", "tokens": ["Und", "dich", "zur", "Stra\u00b7fe", "k\u00fcs\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Er droht mir, sieht verdr\u00fc\u00dflich aus,", "tokens": ["Er", "droht", "mir", ",", "sieht", "ver\u00b7dr\u00fc\u00df\u00b7lich", "aus", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$,", "VVFIN", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und strafet mich schon im voraus.", "tokens": ["Und", "stra\u00b7fet", "mich", "schon", "im", "vo\u00b7raus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "APPRART", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Sonst log ich nicht.", "tokens": ["Sonst", "log", "ich", "nicht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.2": {"text": "Nun seit er spricht:", "tokens": ["Nun", "seit", "er", "spricht", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PPER", "VVFIN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "Du sollst mir fein mit K\u00fcssen", "tokens": ["Du", "sollst", "mir", "fein", "mit", "K\u00fcs\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PPER", "ADJD", "APPR", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Die losen L\u00fcgen b\u00fc\u00dfen,", "tokens": ["Die", "lo\u00b7sen", "L\u00fc\u00b7gen", "b\u00fc\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Red' ich kein wahres W\u00f6rtchen mehr.", "tokens": ["Red'", "ich", "kein", "wah\u00b7res", "W\u00f6rt\u00b7chen", "mehr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PIAT", "ADJA", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Nun, Schwestern, sagt, wo k\u00f6mmt das her?", "tokens": ["Nun", ",", "Schwes\u00b7tern", ",", "sagt", ",", "wo", "k\u00f6mmt", "das", "her", "?"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "NN", "$,", "VVFIN", "$,", "PWAV", "VVFIN", "PDS", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Mein D\u00e4mon spricht:", "tokens": ["Mein", "D\u00e4\u00b7mon", "spricht", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.2": {"text": "Kind, l\u00fcge nicht!", "tokens": ["Kind", ",", "l\u00fc\u00b7ge", "nicht", "!"], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "PTKNEG", "$."], "meter": "++-+", "measure": "iambic.di"}, "line.3": {"text": "Sonst werd' ich strafen m\u00fcssen,", "tokens": ["Sonst", "werd'", "ich", "stra\u00b7fen", "m\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "VVINF", "VMINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und dich zur Strafe k\u00fcssen.", "tokens": ["Und", "dich", "zur", "Stra\u00b7fe", "k\u00fcs\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Er droht mir, sieht verdr\u00fc\u00dflich aus,", "tokens": ["Er", "droht", "mir", ",", "sieht", "ver\u00b7dr\u00fc\u00df\u00b7lich", "aus", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$,", "VVFIN", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und strafet mich schon im voraus.", "tokens": ["Und", "stra\u00b7fet", "mich", "schon", "im", "vo\u00b7raus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "APPRART", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Sonst log ich nicht.", "tokens": ["Sonst", "log", "ich", "nicht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.2": {"text": "Nun seit er spricht:", "tokens": ["Nun", "seit", "er", "spricht", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PPER", "VVFIN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "Du sollst mir fein mit K\u00fcssen", "tokens": ["Du", "sollst", "mir", "fein", "mit", "K\u00fcs\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PPER", "ADJD", "APPR", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Die losen L\u00fcgen b\u00fc\u00dfen,", "tokens": ["Die", "lo\u00b7sen", "L\u00fc\u00b7gen", "b\u00fc\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Red' ich kein wahres W\u00f6rtchen mehr.", "tokens": ["Red'", "ich", "kein", "wah\u00b7res", "W\u00f6rt\u00b7chen", "mehr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PIAT", "ADJA", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Nun, Schwestern, sagt, wo k\u00f6mmt das her?", "tokens": ["Nun", ",", "Schwes\u00b7tern", ",", "sagt", ",", "wo", "k\u00f6mmt", "das", "her", "?"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "NN", "$,", "VVFIN", "$,", "PWAV", "VVFIN", "PDS", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}