{"textgrid.poem.63293": {"metadata": {"author": {"name": "Klabund", "birth": "N.A.", "death": "N.A."}, "title": "Der geistige Arbeiter in der Inflation", "genre": "verse", "period": "N.A.", "pub_year": 1909, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wer nur den lieben Gott l\u00e4\u00dft walten \u2013", "tokens": ["Wer", "nur", "den", "lie\u00b7ben", "Gott", "l\u00e4\u00dft", "wal\u00b7ten", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "ART", "ADJA", "NN", "VVFIN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ich arbeite an einer Monographie \u00fcber die r\u00f6mischen Laren.", "tokens": ["Ich", "ar\u00b7bei\u00b7te", "an", "ei\u00b7ner", "Mo\u00b7no\u00b7gra\u00b7phie", "\u00fc\u00b7ber", "die", "r\u00f6\u00b7mi\u00b7schen", "La\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+--+--+-+-+--+--+-", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Am Tage liege ich im Bett, um Kohlen zu sparen.", "tokens": ["Am", "Ta\u00b7ge", "lie\u00b7ge", "ich", "im", "Bett", ",", "um", "Koh\u00b7len", "zu", "spa\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PPER", "APPRART", "NN", "$,", "KOUI", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Ich werde ein Honorar von drei Mark erhalten.", "tokens": ["Ich", "wer\u00b7de", "ein", "Ho\u00b7no\u00b7rar", "von", "drei", "Mark", "er\u00b7hal\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "APPR", "CARD", "NN", "VVPP", "$."], "meter": "-+--+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Drei Mark! Das schwellt meine H\u00fchnerbrust wie ein Segel.", "tokens": ["Drei", "Mark", "!", "Das", "schwellt", "mei\u00b7ne", "H\u00fch\u00b7ner\u00b7brust", "wie", "ein", "Se\u00b7gel", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "$.", "PDS", "VVFIN", "PPOSAT", "NN", "KOKOM", "ART", "NN", "$."], "meter": "-+-+--+-+--+-", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Ein kleines Verm\u00f6gen. Ich werde es in einem Taschentuch anlegen.", "tokens": ["Ein", "klei\u00b7nes", "Ver\u00b7m\u00f6\u00b7gen", ".", "Ich", "wer\u00b7de", "es", "in", "ei\u00b7nem", "Ta\u00b7schen\u00b7tuch", "an\u00b7le\u00b7gen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$.", "PPER", "VAFIN", "PPER", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+--+--+-+-+-+-+-+-", "measure": "amphibrach.tri.plus"}, "line.7": {"text": "Wie ich es fr\u00fcher trug und wie die reichen Leute es heute noch tragen.", "tokens": ["Wie", "ich", "es", "fr\u00fc\u00b7her", "trug", "und", "wie", "die", "rei\u00b7chen", "Leu\u00b7te", "es", "heu\u00b7te", "noch", "tra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PPER", "ADJD", "VVFIN", "KON", "PWAV", "ART", "ADJA", "NN", "PPER", "ADV", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+--+--+-", "measure": "iambic.octa.plus.relaxed"}, "line.8": {"text": "Um vorw\u00e4rts zu kommen, mu\u00df man eben mal leichtsinnig sein und was wagen.", "tokens": ["Um", "vor\u00b7w\u00e4rts", "zu", "kom\u00b7men", ",", "mu\u00df", "man", "e\u00b7ben", "mal", "leicht\u00b7sin\u00b7nig", "sein", "und", "was", "wa\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "ADV", "PTKZU", "VVINF", "$,", "VMFIN", "PIS", "ADV", "ADV", "ADJD", "VAINF", "KON", "PWS", "VVINF", "$."], "meter": "-+--+-+-+--+--+--+-", "measure": "iambic.septa.relaxed"}}, "stanza.2": {"line.1": {"text": "Ein Jahr schon schneuze ich mich in die H\u00e4nde,", "tokens": ["Ein", "Jahr", "schon", "schneu\u00b7ze", "ich", "mich", "in", "die", "H\u00e4n\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVFIN", "PPER", "PRF", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Nun f\u00fchrt der Allerbarmer noch alles zum guten Ende.", "tokens": ["Nun", "f\u00fchrt", "der", "Al\u00b7ler\u00b7bar\u00b7mer", "noch", "al\u00b7les", "zum", "gu\u00b7ten", "En\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ADV", "PIS", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+--+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Abends, wenn die Sterne und elektrischen Lichter erwachen,", "tokens": ["A\u00b7bends", ",", "wenn", "die", "Ster\u00b7ne", "und", "e\u00b7lekt\u00b7ri\u00b7schen", "Lich\u00b7ter", "er\u00b7wa\u00b7chen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "ART", "NN", "KON", "ADJA", "NN", "VVINF", "$,"], "meter": "+---+--+---+--+-", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Da besteige ich des Gl\u00fcckes goldnen Nachen.", "tokens": ["Da", "be\u00b7stei\u00b7ge", "ich", "des", "Gl\u00fc\u00b7ckes", "gold\u00b7nen", "Na\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "ADJA", "NN", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}}, "stanza.3": {"line.1": {"text": "Ich stehe am Anhalter Bahnhof. Ergebenster Diener!", "tokens": ["Ich", "ste\u00b7he", "am", "An\u00b7hal\u00b7ter", "Bahn\u00b7hof", ".", "Er\u00b7ge\u00b7bens\u00b7ter", "Die\u00b7ner", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "ADJA", "NN", "$.", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.2": {"text": "Ich biete Delikate\u00dfbockwurst feil und die ff. hei\u00dfen Wiener.", "tokens": ["Ich", "bie\u00b7te", "De\u00b7li\u00b7ka\u00b7te\u00df\u00b7bock\u00b7wurst", "feil", "und", "die", "ff.", "hei\u00b7\u00dfen", "Wie\u00b7ner", "."], "token_info": ["word", "word", "word", "word", "word", "word", "abbreviation", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADJD", "KON", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+---+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Manchmal hab' ich einen Reingewinn von einer halben Mark.", "tokens": ["Manch\u00b7mal", "hab'", "ich", "ei\u00b7nen", "Rein\u00b7ge\u00b7winn", "von", "ei\u00b7ner", "hal\u00b7ben", "Mark", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ART", "NN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.4": {"text": "Ich lege das Geld auf die hohe Kante. Ich spare f\u00fcr meinen Sarg.", "tokens": ["Ich", "le\u00b7ge", "das", "Geld", "auf", "die", "ho\u00b7he", "Kan\u00b7te", ".", "Ich", "spa\u00b7re", "f\u00fcr", "mei\u00b7nen", "Sarg", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "ART", "ADJA", "NN", "$.", "PPER", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+--++-+-+--+--+-+", "measure": "iambic.octa.plus.relaxed"}}, "stanza.4": {"line.1": {"text": "Aus Eschen- oder Eichenholz,", "tokens": ["Aus", "E\u00b7schen", "o\u00b7der", "Ei\u00b7chen\u00b7holz", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "TRUNC", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Aus deutscher Eiche. Das Vaterland", "tokens": ["Aus", "deut\u00b7scher", "Ei\u00b7che", ".", "Das", "Va\u00b7ter\u00b7land"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "ADJA", "NN", "$.", "ART", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Reichte mir hilfreich stets die Vaterhand.", "tokens": ["Reich\u00b7te", "mir", "hilf\u00b7reich", "stets", "die", "Va\u00b7ter\u00b7hand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "ART", "NN", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.4": {"text": "Begrabt mich in deutschem Holz, in deutscher Erde, im deutschen Wald.", "tokens": ["Be\u00b7grabt", "mich", "in", "deut\u00b7schem", "Holz", ",", "in", "deut\u00b7scher", "Er\u00b7de", ",", "im", "deut\u00b7schen", "Wald", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "APPR", "ADJA", "NN", "$,", "APPR", "ADJA", "NN", "$,", "APPRART", "ADJA", "NN", "$."], "meter": "-+--+-+-+-+--+-+", "measure": "iambic.septa.relaxed"}, "line.5": {"text": "Aber bald!", "tokens": ["A\u00b7ber", "bald", "!"], "token_info": ["word", "word", "punct"], "pos": ["KON", "ADV", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.6": {"text": "Wie schl\u00e4ft sich's sanft, wie ruht sich's gut,", "tokens": ["Wie", "schl\u00e4ft", "sich's", "sanft", ",", "wie", "ruht", "sich's", "gut", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PIS", "ADJD", "$,", "PWAV", "VVFIN", "PIS", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Erl\u00f6st von Schwindsucht und Skorbut.", "tokens": ["Er\u00b7l\u00f6st", "von", "Schwind\u00b7sucht", "und", "Skor\u00b7but", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "Herrgott im Himmel, erwache ich zu neuem Leben noch einmal auf Erden:", "tokens": ["Herr\u00b7gott", "im", "Him\u00b7mel", ",", "er\u00b7wa\u00b7che", "ich", "zu", "neu\u00b7em", "Le\u00b7ben", "noch", "ein\u00b7mal", "auf", "Er\u00b7den", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPRART", "NN", "$,", "VVFIN", "PPER", "APPR", "ADJA", "NN", "ADV", "ADV", "APPR", "NN", "$."], "meter": "+--+--+-+-+-+-+-+-+-", "measure": "dactylic.di.plus"}, "line.9": {"text": "La\u00df mich Devisenh\u00e4ndler, Diamantenschleifer oder Kanalreiniger werden!", "tokens": ["La\u00df", "mich", "De\u00b7vi\u00b7sen\u00b7h\u00e4nd\u00b7ler", ",", "Di\u00b7a\u00b7man\u00b7ten\u00b7schlei\u00b7fer", "o\u00b7der", "Ka\u00b7nal\u00b7rei\u00b7ni\u00b7ger", "wer\u00b7den", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "NE", "$,", "NE", "KON", "NN", "VAINF", "$."], "meter": "+--+-+-+-+-+-+--+-+-+-", "measure": "iambic.octa.plus.invert"}}, "stanza.5": {"line.1": {"text": "Wer nur den lieben Gott l\u00e4\u00dft walten \u2013", "tokens": ["Wer", "nur", "den", "lie\u00b7ben", "Gott", "l\u00e4\u00dft", "wal\u00b7ten", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "ART", "ADJA", "NN", "VVFIN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ich arbeite an einer Monographie \u00fcber die r\u00f6mischen Laren.", "tokens": ["Ich", "ar\u00b7bei\u00b7te", "an", "ei\u00b7ner", "Mo\u00b7no\u00b7gra\u00b7phie", "\u00fc\u00b7ber", "die", "r\u00f6\u00b7mi\u00b7schen", "La\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+--+--+-+-+--+--+-", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Am Tage liege ich im Bett, um Kohlen zu sparen.", "tokens": ["Am", "Ta\u00b7ge", "lie\u00b7ge", "ich", "im", "Bett", ",", "um", "Koh\u00b7len", "zu", "spa\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PPER", "APPRART", "NN", "$,", "KOUI", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Ich werde ein Honorar von drei Mark erhalten.", "tokens": ["Ich", "wer\u00b7de", "ein", "Ho\u00b7no\u00b7rar", "von", "drei", "Mark", "er\u00b7hal\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "APPR", "CARD", "NN", "VVPP", "$."], "meter": "-+--+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Drei Mark! Das schwellt meine H\u00fchnerbrust wie ein Segel.", "tokens": ["Drei", "Mark", "!", "Das", "schwellt", "mei\u00b7ne", "H\u00fch\u00b7ner\u00b7brust", "wie", "ein", "Se\u00b7gel", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "$.", "PDS", "VVFIN", "PPOSAT", "NN", "KOKOM", "ART", "NN", "$."], "meter": "-+-+--+-+--+-", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Ein kleines Verm\u00f6gen. Ich werde es in einem Taschentuch anlegen.", "tokens": ["Ein", "klei\u00b7nes", "Ver\u00b7m\u00f6\u00b7gen", ".", "Ich", "wer\u00b7de", "es", "in", "ei\u00b7nem", "Ta\u00b7schen\u00b7tuch", "an\u00b7le\u00b7gen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$.", "PPER", "VAFIN", "PPER", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+--+--+-+-+-+-+-+-", "measure": "amphibrach.tri.plus"}, "line.7": {"text": "Wie ich es fr\u00fcher trug und wie die reichen Leute es heute noch tragen.", "tokens": ["Wie", "ich", "es", "fr\u00fc\u00b7her", "trug", "und", "wie", "die", "rei\u00b7chen", "Leu\u00b7te", "es", "heu\u00b7te", "noch", "tra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PPER", "ADJD", "VVFIN", "KON", "PWAV", "ART", "ADJA", "NN", "PPER", "ADV", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+--+--+-", "measure": "iambic.octa.plus.relaxed"}, "line.8": {"text": "Um vorw\u00e4rts zu kommen, mu\u00df man eben mal leichtsinnig sein und was wagen.", "tokens": ["Um", "vor\u00b7w\u00e4rts", "zu", "kom\u00b7men", ",", "mu\u00df", "man", "e\u00b7ben", "mal", "leicht\u00b7sin\u00b7nig", "sein", "und", "was", "wa\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "ADV", "PTKZU", "VVINF", "$,", "VMFIN", "PIS", "ADV", "ADV", "ADJD", "VAINF", "KON", "PWS", "VVINF", "$."], "meter": "-+--+-+-+--+--+--+-", "measure": "iambic.septa.relaxed"}}, "stanza.6": {"line.1": {"text": "Ein Jahr schon schneuze ich mich in die H\u00e4nde,", "tokens": ["Ein", "Jahr", "schon", "schneu\u00b7ze", "ich", "mich", "in", "die", "H\u00e4n\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVFIN", "PPER", "PRF", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Nun f\u00fchrt der Allerbarmer noch alles zum guten Ende.", "tokens": ["Nun", "f\u00fchrt", "der", "Al\u00b7ler\u00b7bar\u00b7mer", "noch", "al\u00b7les", "zum", "gu\u00b7ten", "En\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ADV", "PIS", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+--+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Abends, wenn die Sterne und elektrischen Lichter erwachen,", "tokens": ["A\u00b7bends", ",", "wenn", "die", "Ster\u00b7ne", "und", "e\u00b7lekt\u00b7ri\u00b7schen", "Lich\u00b7ter", "er\u00b7wa\u00b7chen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "ART", "NN", "KON", "ADJA", "NN", "VVINF", "$,"], "meter": "+---+--+---+--+-", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Da besteige ich des Gl\u00fcckes goldnen Nachen.", "tokens": ["Da", "be\u00b7stei\u00b7ge", "ich", "des", "Gl\u00fc\u00b7ckes", "gold\u00b7nen", "Na\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "ADJA", "NN", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}}, "stanza.7": {"line.1": {"text": "Ich stehe am Anhalter Bahnhof. Ergebenster Diener!", "tokens": ["Ich", "ste\u00b7he", "am", "An\u00b7hal\u00b7ter", "Bahn\u00b7hof", ".", "Er\u00b7ge\u00b7bens\u00b7ter", "Die\u00b7ner", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "ADJA", "NN", "$.", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.2": {"text": "Ich biete Delikate\u00dfbockwurst feil und die ff. hei\u00dfen Wiener.", "tokens": ["Ich", "bie\u00b7te", "De\u00b7li\u00b7ka\u00b7te\u00df\u00b7bock\u00b7wurst", "feil", "und", "die", "ff.", "hei\u00b7\u00dfen", "Wie\u00b7ner", "."], "token_info": ["word", "word", "word", "word", "word", "word", "abbreviation", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADJD", "KON", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+---+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Manchmal hab' ich einen Reingewinn von einer halben Mark.", "tokens": ["Manch\u00b7mal", "hab'", "ich", "ei\u00b7nen", "Rein\u00b7ge\u00b7winn", "von", "ei\u00b7ner", "hal\u00b7ben", "Mark", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ART", "NN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.4": {"text": "Ich lege das Geld auf die hohe Kante. Ich spare f\u00fcr meinen Sarg.", "tokens": ["Ich", "le\u00b7ge", "das", "Geld", "auf", "die", "ho\u00b7he", "Kan\u00b7te", ".", "Ich", "spa\u00b7re", "f\u00fcr", "mei\u00b7nen", "Sarg", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "ART", "ADJA", "NN", "$.", "PPER", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+--++-+-+--+--+-+", "measure": "iambic.octa.plus.relaxed"}}, "stanza.8": {"line.1": {"text": "Aus Eschen- oder Eichenholz,", "tokens": ["Aus", "E\u00b7schen", "o\u00b7der", "Ei\u00b7chen\u00b7holz", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "TRUNC", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Aus deutscher Eiche. Das Vaterland", "tokens": ["Aus", "deut\u00b7scher", "Ei\u00b7che", ".", "Das", "Va\u00b7ter\u00b7land"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "ADJA", "NN", "$.", "ART", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Reichte mir hilfreich stets die Vaterhand.", "tokens": ["Reich\u00b7te", "mir", "hilf\u00b7reich", "stets", "die", "Va\u00b7ter\u00b7hand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "ART", "NN", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.4": {"text": "Begrabt mich in deutschem Holz, in deutscher Erde, im deutschen Wald.", "tokens": ["Be\u00b7grabt", "mich", "in", "deut\u00b7schem", "Holz", ",", "in", "deut\u00b7scher", "Er\u00b7de", ",", "im", "deut\u00b7schen", "Wald", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "APPR", "ADJA", "NN", "$,", "APPR", "ADJA", "NN", "$,", "APPRART", "ADJA", "NN", "$."], "meter": "-+--+-+-+-+--+-+", "measure": "iambic.septa.relaxed"}, "line.5": {"text": "Aber bald!", "tokens": ["A\u00b7ber", "bald", "!"], "token_info": ["word", "word", "punct"], "pos": ["KON", "ADV", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.6": {"text": "Wie schl\u00e4ft sich's sanft, wie ruht sich's gut,", "tokens": ["Wie", "schl\u00e4ft", "sich's", "sanft", ",", "wie", "ruht", "sich's", "gut", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PIS", "ADJD", "$,", "PWAV", "VVFIN", "PIS", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Erl\u00f6st von Schwindsucht und Skorbut.", "tokens": ["Er\u00b7l\u00f6st", "von", "Schwind\u00b7sucht", "und", "Skor\u00b7but", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "Herrgott im Himmel, erwache ich zu neuem Leben noch einmal auf Erden:", "tokens": ["Herr\u00b7gott", "im", "Him\u00b7mel", ",", "er\u00b7wa\u00b7che", "ich", "zu", "neu\u00b7em", "Le\u00b7ben", "noch", "ein\u00b7mal", "auf", "Er\u00b7den", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPRART", "NN", "$,", "VVFIN", "PPER", "APPR", "ADJA", "NN", "ADV", "ADV", "APPR", "NN", "$."], "meter": "+--+--+-+-+-+-+-+-+-", "measure": "dactylic.di.plus"}, "line.9": {"text": "La\u00df mich Devisenh\u00e4ndler, Diamantenschleifer oder Kanalreiniger werden!", "tokens": ["La\u00df", "mich", "De\u00b7vi\u00b7sen\u00b7h\u00e4nd\u00b7ler", ",", "Di\u00b7a\u00b7man\u00b7ten\u00b7schlei\u00b7fer", "o\u00b7der", "Ka\u00b7nal\u00b7rei\u00b7ni\u00b7ger", "wer\u00b7den", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "NE", "$,", "NE", "KON", "NN", "VAINF", "$."], "meter": "+--+-+-+-+-+-+--+-+-+-", "measure": "iambic.octa.plus.invert"}}}}}