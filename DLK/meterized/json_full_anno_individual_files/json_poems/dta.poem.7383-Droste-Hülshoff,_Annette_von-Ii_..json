{"dta.poem.7383": {"metadata": {"author": {"name": "Droste-H\u00fclshoff, Annette von", "birth": "N.A.", "death": "N.A."}, "title": "Ii .", "genre": "Lyrik", "period": "N.A.", "pub_year": "1844", "urn": "urn:nbn:de:kobv:b4-20090519994", "language": ["de:0.99"], "booktitle": "Droste-H\u00fclshoff, Annette von: Gedichte. Stuttgart u. a., 1844."}, "poem": {"stanza.1": {"line.1": {"text": "Drei kurze Monde sind verronnen,", "tokens": ["Drei", "kur\u00b7ze", "Mon\u00b7de", "sind", "ver\u00b7ron\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "ADJA", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und die Fregatte liegt am Strand,", "tokens": ["Und", "die", "Fre\u00b7gat\u00b7te", "liegt", "am", "Strand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wo Mittags sich die Robben sonnen,", "tokens": ["Wo", "Mit\u00b7tags", "sich", "die", "Rob\u00b7ben", "son\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "PRF", "ART", "NN", "VVINF", "$,"], "meter": "-++--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Und Bursche klettern \u00fcber'n Rand,", "tokens": ["Und", "Bur\u00b7sche", "klet\u00b7tern", "\u00fc\u00b7ber'n", "Rand", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Den M\u00e4dchen ist's ein Abentheuer", "tokens": ["Den", "M\u00e4d\u00b7chen", "ist's", "ein", "A\u00b7bent\u00b7heu\u00b7er"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Es zu erschaun vom fernen Riff,", "tokens": ["Es", "zu", "er\u00b7schaun", "vom", "fer\u00b7nen", "Riff", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKZU", "VVINF", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Denn noch zerst\u00f6rt ist nicht geheuer", "tokens": ["Denn", "noch", "zer\u00b7st\u00f6rt", "ist", "nicht", "ge\u00b7heu\u00b7er"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVPP", "VAFIN", "PTKNEG", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Das gr\u00e4uliche Corsarenschiff.", "tokens": ["Das", "gr\u00e4u\u00b7li\u00b7che", "Cor\u00b7sa\u00b7ren\u00b7schiff", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Und vor der Stadt da ist ein Waten,", "tokens": ["Und", "vor", "der", "Stadt", "da", "ist", "ein", "Wa\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "ADV", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ein W\u00fchlen durch das Kiesgeschrill,", "tokens": ["Ein", "W\u00fch\u00b7len", "durch", "das", "Kies\u00b7ge\u00b7schrill", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da die verrufenen Piraten", "tokens": ["Da", "die", "ver\u00b7ru\u00b7fe\u00b7nen", "Pi\u00b7ra\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ein Jeder sterben sehen will.", "tokens": ["Ein", "Je\u00b7der", "ster\u00b7ben", "se\u00b7hen", "will", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VVINF", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Aus Strandgeb\u00e4lken, morsch, zertr\u00fcmmert,", "tokens": ["Aus", "Strand\u00b7ge\u00b7b\u00e4l\u00b7ken", ",", "morsch", ",", "zer\u00b7tr\u00fcm\u00b7mert", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["APPR", "NN", "$,", "ADJD", "$,", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Hat man den Galgen, dicht am Meer,", "tokens": ["Hat", "man", "den", "Gal\u00b7gen", ",", "dicht", "am", "Meer", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "ART", "NN", "$,", "ADJD", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "In w\u00fcster Eile aufgezimmert.", "tokens": ["In", "w\u00fcs\u00b7ter", "Ei\u00b7le", "auf\u00b7ge\u00b7zim\u00b7mert", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Dort dr\u00e4ut er von der D\u00fcne her!", "tokens": ["Dort", "dr\u00e4ut", "er", "von", "der", "D\u00fc\u00b7ne", "her", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Welch ein Get\u00fcmmel an den Schranken! \u2014", "tokens": ["Welch", "ein", "Ge\u00b7t\u00fcm\u00b7mel", "an", "den", "Schran\u00b7ken", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PIAT", "ART", "NN", "APPR", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "\u201eda k\u00f6mmt der Frei \u2014 der Hessel jetzt \u2014", "tokens": ["\u201e", "da", "k\u00f6mmt", "der", "Frei", "der", "Hes\u00b7sel", "jetzt"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VVFIN", "ART", "NN", "$(", "ART", "NN", "ADV", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Da bringen sie den schwarzen Franken,", "tokens": ["Da", "brin\u00b7gen", "sie", "den", "schwar\u00b7zen", "Fran\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Der hat gel\u00e4ugnet bis zuletzt.\u201c", "tokens": ["Der", "hat", "ge\u00b7l\u00e4ug\u00b7net", "bis", "zu\u00b7letzt", ".", "\u201c"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PDS", "VAFIN", "VVPP", "KON", "ADV", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "\u201eschiffbr\u00fcchig sey er hergeschwommen,\u201c", "tokens": ["\u201e", "schiff\u00b7br\u00fc\u00b7chig", "sey", "er", "her\u00b7ge\u00b7schwom\u00b7men", ",", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADJD", "VAFIN", "PPER", "VVINF", "$,", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "H\u00f6hnt eine Alte: \u201eEi, wie k\u00fchn!", "tokens": ["H\u00f6hnt", "ei\u00b7ne", "Al\u00b7te", ":", "\u201e", "Ei", ",", "wie", "k\u00fchn", "!"], "token_info": ["word", "word", "word", "punct", "punct", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$.", "$(", "NN", "$,", "PWAV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Doch Keiner sprach zu seinem Frommen,", "tokens": ["Doch", "Kei\u00b7ner", "sprach", "zu", "sei\u00b7nem", "From\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Die ganze Bande gegen ihn.\u201c", "tokens": ["Die", "gan\u00b7ze", "Ban\u00b7de", "ge\u00b7gen", "ihn", ".", "\u201c"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "PPER", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Der Passagier, am Galgen stehend,", "tokens": ["Der", "Pas\u00b7sa\u00b7gier", ",", "am", "Gal\u00b7gen", "ste\u00b7hend", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Hohl\u00e4ugig, mit zerbrochnem Muth,", "tokens": ["Hoh\u00b7l\u00e4u\u00b7gig", ",", "mit", "zer\u00b7broch\u00b7nem", "Muth", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Zu jedem R\u00e4uber fl\u00fcstert flehend:", "tokens": ["Zu", "je\u00b7dem", "R\u00e4u\u00b7ber", "fl\u00fcs\u00b7tert", "fle\u00b7hend", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVFIN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "\u201ewas that dir mein unschuldig Blut!", "tokens": ["\u201e", "was", "that", "dir", "mein", "un\u00b7schul\u00b7dig", "Blut", "!"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "VVFIN", "PPER", "PPOSAT", "ADJD", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Barmherzigkeit! \u2014 so mu\u00df ich sterben", "tokens": ["Barm\u00b7her\u00b7zig\u00b7keit", "!", "so", "mu\u00df", "ich", "ster\u00b7ben"], "token_info": ["word", "punct", "punct", "word", "word", "word", "word"], "pos": ["NN", "$.", "$(", "ADV", "VMFIN", "PPER", "VVINF"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Durch des Gesindels L\u00fcgenwort,", "tokens": ["Durch", "des", "Ge\u00b7sin\u00b7dels", "L\u00fc\u00b7gen\u00b7wort", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "$,"], "meter": "++-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "O m\u00f6g' die Seele euch verderben!\u201c", "tokens": ["O", "m\u00f6g'", "die", "See\u00b7le", "euch", "ver\u00b7der\u00b7ben", "!", "\u201c"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "VMFIN", "ART", "NN", "PPER", "VVFIN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Da zieht ihn schon der Scherge fort.", "tokens": ["Da", "zieht", "ihn", "schon", "der", "Scher\u00b7ge", "fort", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Er sieht die Menge wogend spalten \u2014", "tokens": ["Er", "sieht", "die", "Men\u00b7ge", "wo\u00b7gend", "spal\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "VVPP", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Er h\u00f6rt das Summen im Gew\u00fchl \u2014", "tokens": ["Er", "h\u00f6rt", "das", "Sum\u00b7men", "im", "Ge\u00b7w\u00fchl"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPRART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Nun wei\u00df er, da\u00df des Himmels Walten", "tokens": ["Nun", "wei\u00df", "er", ",", "da\u00df", "des", "Him\u00b7mels", "Wal\u00b7ten"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "$,", "KOUS", "ART", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Nur seiner Pfaffen Gaukelspiel!", "tokens": ["Nur", "sei\u00b7ner", "Pfaf\u00b7fen", "Gau\u00b7kel\u00b7spiel", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und als er in des Hohnes Stolze", "tokens": ["Und", "als", "er", "in", "des", "Hoh\u00b7nes", "Stol\u00b7ze"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Will starren nach den Aetherh\u00f6hn,", "tokens": ["Will", "star\u00b7ren", "nach", "den", "A\u00b7e\u00b7ther\u00b7h\u00f6hn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.7": {"text": "Da liest er an des Galgens Holze:", "tokens": ["Da", "liest", "er", "an", "des", "Gal\u00b7gens", "Hol\u00b7ze", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "\u201e", "tokens": ["\u201e"], "token_info": ["punct"], "pos": ["$("]}}}}}