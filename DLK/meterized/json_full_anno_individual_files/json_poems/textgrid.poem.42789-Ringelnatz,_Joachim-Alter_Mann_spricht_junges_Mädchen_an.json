{"textgrid.poem.42789": {"metadata": {"author": {"name": "Ringelnatz, Joachim", "birth": "N.A.", "death": "N.A."}, "title": "Alter Mann spricht junges M\u00e4dchen an", "genre": "verse", "period": "N.A.", "pub_year": 1908, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Guten Tag! \u2013 Wie du dich bem\u00fchst,", "tokens": ["Gu\u00b7ten", "Tag", "!", "\u2013", "Wie", "du", "dich", "be\u00b7m\u00fchst", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$.", "$(", "PWAV", "PPER", "PRF", "VVFIN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Keine Antwort auszusprechen.", "tokens": ["Kei\u00b7ne", "Ant\u00b7wort", "aus\u00b7zu\u00b7spre\u00b7chen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVIZU", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "\u00bbguten Tag\u00ab in die Luft gegr\u00fc\u00dft,", "tokens": ["\u00bb", "gu\u00b7ten", "Tag", "\u00ab", "in", "die", "Luft", "ge\u00b7gr\u00fc\u00dft", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJA", "NN", "$(", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.4": {"text": "Ist das wohl ein Sittlichkeitsverbrechen?", "tokens": ["Ist", "das", "wohl", "ein", "Sitt\u00b7lich\u00b7keits\u00b7ver\u00b7bre\u00b7chen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PDS", "ADV", "ART", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.2": {"line.1": {"text": "Jage mich nicht fort.", "tokens": ["Ja\u00b7ge", "mich", "nicht", "fort", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PTKNEG", "PTKVZ", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.2": {"text": "Ich will dich nicht verjagen.", "tokens": ["Ich", "will", "dich", "nicht", "ver\u00b7ja\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Nun werde ich jedes weitere Wort", "tokens": ["Nun", "wer\u00b7de", "ich", "je\u00b7des", "wei\u00b7te\u00b7re", "Wort"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "PIAT", "ADJA", "NN"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Zu meinem Spazierstock sagen:", "tokens": ["Zu", "mei\u00b7nem", "Spa\u00b7zier\u00b7stock", "sa\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.3": {"line.1": {"text": "Sprich mich nicht an und sieh mich nicht,", "tokens": ["Sprich", "mich", "nicht", "an", "und", "sieh", "mich", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "PTKNEG", "PTKVZ", "KON", "VVIMP", "PPER", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Du Schlankes.", "tokens": ["Du", "Schlan\u00b7kes", "."], "token_info": ["word", "word", "punct"], "pos": ["PPER", "NN", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.3": {"text": "Ich hatte auch einmal ein so blankes,", "tokens": ["Ich", "hat\u00b7te", "auch", "ein\u00b7mal", "ein", "so", "blan\u00b7kes", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "ART", "ADV", "ADJA", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Junges Gesicht.", "tokens": ["Jun\u00b7ges", "Ge\u00b7sicht", "."], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "+--+", "measure": "iambic.di.chol"}}, "stanza.4": {"line.1": {"text": "Wie viele hatten,", "tokens": ["Wie", "vie\u00b7le", "hat\u00b7ten", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "VAFIN", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.2": {"text": "Was du noch hast.", "tokens": ["Was", "du", "noch", "hast", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "VAFIN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "Schenke mir nur deinen Schatten", "tokens": ["Schen\u00b7ke", "mir", "nur", "dei\u00b7nen", "Schat\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "F\u00fcr eine kurze Rast.", "tokens": ["F\u00fcr", "ei\u00b7ne", "kur\u00b7ze", "Rast", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Guten Tag! \u2013 Wie du dich bem\u00fchst,", "tokens": ["Gu\u00b7ten", "Tag", "!", "\u2013", "Wie", "du", "dich", "be\u00b7m\u00fchst", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$.", "$(", "PWAV", "PPER", "PRF", "VVFIN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Keine Antwort auszusprechen.", "tokens": ["Kei\u00b7ne", "Ant\u00b7wort", "aus\u00b7zu\u00b7spre\u00b7chen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVIZU", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "\u00bbguten Tag\u00ab in die Luft gegr\u00fc\u00dft,", "tokens": ["\u00bb", "gu\u00b7ten", "Tag", "\u00ab", "in", "die", "Luft", "ge\u00b7gr\u00fc\u00dft", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJA", "NN", "$(", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.4": {"text": "Ist das wohl ein Sittlichkeitsverbrechen?", "tokens": ["Ist", "das", "wohl", "ein", "Sitt\u00b7lich\u00b7keits\u00b7ver\u00b7bre\u00b7chen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PDS", "ADV", "ART", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.6": {"line.1": {"text": "Jage mich nicht fort.", "tokens": ["Ja\u00b7ge", "mich", "nicht", "fort", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PTKNEG", "PTKVZ", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.2": {"text": "Ich will dich nicht verjagen.", "tokens": ["Ich", "will", "dich", "nicht", "ver\u00b7ja\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Nun werde ich jedes weitere Wort", "tokens": ["Nun", "wer\u00b7de", "ich", "je\u00b7des", "wei\u00b7te\u00b7re", "Wort"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "PIAT", "ADJA", "NN"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Zu meinem Spazierstock sagen:", "tokens": ["Zu", "mei\u00b7nem", "Spa\u00b7zier\u00b7stock", "sa\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.7": {"line.1": {"text": "Sprich mich nicht an und sieh mich nicht,", "tokens": ["Sprich", "mich", "nicht", "an", "und", "sieh", "mich", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "PTKNEG", "PTKVZ", "KON", "VVIMP", "PPER", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Du Schlankes.", "tokens": ["Du", "Schlan\u00b7kes", "."], "token_info": ["word", "word", "punct"], "pos": ["PPER", "NN", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.3": {"text": "Ich hatte auch einmal ein so blankes,", "tokens": ["Ich", "hat\u00b7te", "auch", "ein\u00b7mal", "ein", "so", "blan\u00b7kes", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "ART", "ADV", "ADJA", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Junges Gesicht.", "tokens": ["Jun\u00b7ges", "Ge\u00b7sicht", "."], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "+--+", "measure": "iambic.di.chol"}}, "stanza.8": {"line.1": {"text": "Wie viele hatten,", "tokens": ["Wie", "vie\u00b7le", "hat\u00b7ten", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "VAFIN", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.2": {"text": "Was du noch hast.", "tokens": ["Was", "du", "noch", "hast", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "VAFIN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "Schenke mir nur deinen Schatten", "tokens": ["Schen\u00b7ke", "mir", "nur", "dei\u00b7nen", "Schat\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "F\u00fcr eine kurze Rast.", "tokens": ["F\u00fcr", "ei\u00b7ne", "kur\u00b7ze", "Rast", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}}}}