{"textgrid.poem.63005": {"metadata": {"author": {"name": "Pfeffel, Gottlieb Konrad", "birth": "N.A.", "death": "N.A."}, "title": "1L: Der Thiere Gro\u00dfherr starb. Die hohe Facult\u00e4t", "genre": "verse", "period": "N.A.", "pub_year": 1785, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Der Thiere Gro\u00dfherr starb. Die hohe Facult\u00e4t", "tokens": ["Der", "Thie\u00b7re", "Gro\u00df\u00b7herr", "starb", ".", "Die", "ho\u00b7he", "Fa\u00b7cul\u00b7t\u00e4t"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "NN", "VVFIN", "$.", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Vereinte sich, um seine Majest\u00e4t", "tokens": ["Ver\u00b7ein\u00b7te", "sich", ",", "um", "sei\u00b7ne", "Ma\u00b7jes\u00b7t\u00e4t"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "PRF", "$,", "KOUI", "PPOSAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Nach Standsgeb\u00fchr zu balsamieren.", "tokens": ["Nach", "Stands\u00b7ge\u00b7b\u00fchr", "zu", "bal\u00b7sa\u00b7mie\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Man schnitt den Leichnam auf. Doch, welch ein Ph\u00e4nomen!", "tokens": ["Man", "schnitt", "den", "Leich\u00b7nam", "auf", ".", "Doch", ",", "welch", "ein", "Ph\u00e4\u00b7no\u00b7men", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ART", "NN", "PTKVZ", "$.", "KON", "$,", "PWAT", "ART", "NN", "$."], "meter": "-+-+-+-+-+--", "measure": "unknown.measure.penta"}, "line.5": {"text": "Man fand kein Herz. Die Aerzte disputieren", "tokens": ["Man", "fand", "kein", "Herz", ".", "Die", "A\u00b7erz\u00b7te", "dis\u00b7pu\u00b7tie\u00b7ren"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PIS", "VVFIN", "PIAT", "NN", "$.", "ART", "NN", "VVINF"], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Sich braun und blau; Hippokrates, Galen", "tokens": ["Sich", "braun", "und", "blau", ";", "Hip\u00b7po\u00b7kra\u00b7tes", ",", "Ga\u00b7len"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word"], "pos": ["PRF", "ADJD", "KON", "ADJD", "$.", "NE", "$,", "NN"], "meter": "-+-++-+-+-", "measure": "unknown.measure.penta"}, "line.7": {"text": "Und Avicenna siegt: die Herren demonstrieren", "tokens": ["Und", "A\u00b7vi\u00b7cen\u00b7na", "siegt", ":", "die", "Her\u00b7ren", "de\u00b7monst\u00b7rie\u00b7ren"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "NE", "VVFIN", "$.", "ART", "NN", "VVINF"], "meter": "-+---+-+---+-", "measure": "dactylic.init"}, "line.8": {"text": "Das Gegentheil von dem, was sie vor Augen sehn,", "tokens": ["Das", "Ge\u00b7gen\u00b7theil", "von", "dem", ",", "was", "sie", "vor", "Au\u00b7gen", "sehn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "$,", "PRELS", "PPER", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Und streichen sich den Bart. Den Unfug zu vermeiden,", "tokens": ["Und", "strei\u00b7chen", "sich", "den", "Bart", ".", "Den", "Un\u00b7fug", "zu", "ver\u00b7mei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "ART", "NN", "$.", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Verbot der junge Schach aus weiser Politik", "tokens": ["Ver\u00b7bot", "der", "jun\u00b7ge", "Schach", "aus", "wei\u00b7ser", "Po\u00b7li\u00b7tik"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "ADJA", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Der Fakult\u00e4t bey Knut und Strick", "tokens": ["Der", "Fa\u00b7kul\u00b7t\u00e4t", "bey", "Knut", "und", "Strick"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "In Zukunft die Monarchen auszuweiden;", "tokens": ["In", "Zu\u00b7kunft", "die", "Mon\u00b7ar\u00b7chen", "aus\u00b7zu\u00b7wei\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "Und lie\u00df auf allen Fall sich an des Herzens Platz", "tokens": ["Und", "lie\u00df", "auf", "al\u00b7len", "Fall", "sich", "an", "des", "Her\u00b7zens", "Platz"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "PIAT", "NN", "PRF", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Auf seinen neuen Purpurlatz", "tokens": ["Auf", "sei\u00b7nen", "neu\u00b7en", "Pur\u00b7pur\u00b7latz"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Ein Supplement von Silberfaden sticken.", "tokens": ["Ein", "Sup\u00b7ple\u00b7ment", "von", "Sil\u00b7ber\u00b7fa\u00b7den", "sti\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.16": {"text": "Sein Sohn umgab das Ding mit einem Strahlenkranz.", "tokens": ["Sein", "Sohn", "um\u00b7gab", "das", "Ding", "mit", "ei\u00b7nem", "Strah\u00b7len\u00b7kranz", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Sein Enkel wandelte, vielleicht aus Ignoranz,", "tokens": ["Sein", "En\u00b7kel", "wan\u00b7del\u00b7te", ",", "viel\u00b7leicht", "aus", "Ig\u00b7no\u00b7ranz", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "$,", "ADV", "APPR", "NE", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Vielleicht aus bloser Lust zu flicken,", "tokens": ["Viel\u00b7leicht", "aus", "blo\u00b7ser", "Lust", "zu", "fli\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ADJA", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.19": {"text": "Das abgenutzte Herz in einen Stern.", "tokens": ["Das", "ab\u00b7ge\u00b7nutz\u00b7te", "Herz", "in", "ei\u00b7nen", "Stern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.20": {"text": "Und so entstand der Klecks, womit die gro\u00dfen Herrn", "tokens": ["Und", "so", "ent\u00b7stand", "der", "Klecks", ",", "wo\u00b7mit", "die", "gro\u00b7\u00dfen", "Herrn"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "ART", "NN", "$,", "PWAV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Sich noch auf diesen Tag den leeren Busen schm\u00fccken.", "tokens": ["Sich", "noch", "auf", "die\u00b7sen", "Tag", "den", "lee\u00b7ren", "Bu\u00b7sen", "schm\u00fc\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADV", "APPR", "PDAT", "NN", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Heil denen Freund! die weder Stuhl noch Band", "tokens": ["Heil", "de\u00b7nen", "Freund", "!", "die", "we\u00b7der", "Stuhl", "noch", "Band"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "PDS", "NN", "$.", "ART", "KON", "NN", "ADV", "NN"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.2": {"text": "Erh\u00f6hen kann, die uns, wie du, durch Thaten sagen,", "tokens": ["Er\u00b7h\u00f6\u00b7hen", "kann", ",", "die", "uns", ",", "wie", "du", ",", "durch", "Tha\u00b7ten", "sa\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "$,", "PRELS", "PPER", "$,", "PWAV", "PPER", "$,", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Da\u00df sie ein Herz f\u00fcrs Vaterland", "tokens": ["Da\u00df", "sie", "ein", "Herz", "f\u00fcrs", "Va\u00b7ter\u00b7land"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "NN", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und f\u00fcr die Freundschaft in sich tragen.", "tokens": ["Und", "f\u00fcr", "die", "Freund\u00b7schaft", "in", "sich", "tra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "APPR", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Der Thiere Gro\u00dfherr starb. Die hohe Facult\u00e4t", "tokens": ["Der", "Thie\u00b7re", "Gro\u00df\u00b7herr", "starb", ".", "Die", "ho\u00b7he", "Fa\u00b7cul\u00b7t\u00e4t"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "NN", "VVFIN", "$.", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Vereinte sich, um seine Majest\u00e4t", "tokens": ["Ver\u00b7ein\u00b7te", "sich", ",", "um", "sei\u00b7ne", "Ma\u00b7jes\u00b7t\u00e4t"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "PRF", "$,", "KOUI", "PPOSAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Nach Standsgeb\u00fchr zu balsamieren.", "tokens": ["Nach", "Stands\u00b7ge\u00b7b\u00fchr", "zu", "bal\u00b7sa\u00b7mie\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Man schnitt den Leichnam auf. Doch, welch ein Ph\u00e4nomen!", "tokens": ["Man", "schnitt", "den", "Leich\u00b7nam", "auf", ".", "Doch", ",", "welch", "ein", "Ph\u00e4\u00b7no\u00b7men", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ART", "NN", "PTKVZ", "$.", "KON", "$,", "PWAT", "ART", "NN", "$."], "meter": "-+-+-+-+-+--", "measure": "unknown.measure.penta"}, "line.5": {"text": "Man fand kein Herz. Die Aerzte disputieren", "tokens": ["Man", "fand", "kein", "Herz", ".", "Die", "A\u00b7erz\u00b7te", "dis\u00b7pu\u00b7tie\u00b7ren"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PIS", "VVFIN", "PIAT", "NN", "$.", "ART", "NN", "VVINF"], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Sich braun und blau; Hippokrates, Galen", "tokens": ["Sich", "braun", "und", "blau", ";", "Hip\u00b7po\u00b7kra\u00b7tes", ",", "Ga\u00b7len"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word"], "pos": ["PRF", "ADJD", "KON", "ADJD", "$.", "NE", "$,", "NN"], "meter": "-+-++-+-+-", "measure": "unknown.measure.penta"}, "line.7": {"text": "Und Avicenna siegt: die Herren demonstrieren", "tokens": ["Und", "A\u00b7vi\u00b7cen\u00b7na", "siegt", ":", "die", "Her\u00b7ren", "de\u00b7monst\u00b7rie\u00b7ren"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "NE", "VVFIN", "$.", "ART", "NN", "VVINF"], "meter": "-+---+-+---+-", "measure": "dactylic.init"}, "line.8": {"text": "Das Gegentheil von dem, was sie vor Augen sehn,", "tokens": ["Das", "Ge\u00b7gen\u00b7theil", "von", "dem", ",", "was", "sie", "vor", "Au\u00b7gen", "sehn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "$,", "PRELS", "PPER", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Und streichen sich den Bart. Den Unfug zu vermeiden,", "tokens": ["Und", "strei\u00b7chen", "sich", "den", "Bart", ".", "Den", "Un\u00b7fug", "zu", "ver\u00b7mei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "ART", "NN", "$.", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Verbot der junge Schach aus weiser Politik", "tokens": ["Ver\u00b7bot", "der", "jun\u00b7ge", "Schach", "aus", "wei\u00b7ser", "Po\u00b7li\u00b7tik"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "ADJA", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Der Fakult\u00e4t bey Knut und Strick", "tokens": ["Der", "Fa\u00b7kul\u00b7t\u00e4t", "bey", "Knut", "und", "Strick"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "In Zukunft die Monarchen auszuweiden;", "tokens": ["In", "Zu\u00b7kunft", "die", "Mon\u00b7ar\u00b7chen", "aus\u00b7zu\u00b7wei\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "Und lie\u00df auf allen Fall sich an des Herzens Platz", "tokens": ["Und", "lie\u00df", "auf", "al\u00b7len", "Fall", "sich", "an", "des", "Her\u00b7zens", "Platz"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "PIAT", "NN", "PRF", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Auf seinen neuen Purpurlatz", "tokens": ["Auf", "sei\u00b7nen", "neu\u00b7en", "Pur\u00b7pur\u00b7latz"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Ein Supplement von Silberfaden sticken.", "tokens": ["Ein", "Sup\u00b7ple\u00b7ment", "von", "Sil\u00b7ber\u00b7fa\u00b7den", "sti\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.16": {"text": "Sein Sohn umgab das Ding mit einem Strahlenkranz.", "tokens": ["Sein", "Sohn", "um\u00b7gab", "das", "Ding", "mit", "ei\u00b7nem", "Strah\u00b7len\u00b7kranz", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Sein Enkel wandelte, vielleicht aus Ignoranz,", "tokens": ["Sein", "En\u00b7kel", "wan\u00b7del\u00b7te", ",", "viel\u00b7leicht", "aus", "Ig\u00b7no\u00b7ranz", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "$,", "ADV", "APPR", "NE", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Vielleicht aus bloser Lust zu flicken,", "tokens": ["Viel\u00b7leicht", "aus", "blo\u00b7ser", "Lust", "zu", "fli\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ADJA", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.19": {"text": "Das abgenutzte Herz in einen Stern.", "tokens": ["Das", "ab\u00b7ge\u00b7nutz\u00b7te", "Herz", "in", "ei\u00b7nen", "Stern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.20": {"text": "Und so entstand der Klecks, womit die gro\u00dfen Herrn", "tokens": ["Und", "so", "ent\u00b7stand", "der", "Klecks", ",", "wo\u00b7mit", "die", "gro\u00b7\u00dfen", "Herrn"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "ART", "NN", "$,", "PWAV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Sich noch auf diesen Tag den leeren Busen schm\u00fccken.", "tokens": ["Sich", "noch", "auf", "die\u00b7sen", "Tag", "den", "lee\u00b7ren", "Bu\u00b7sen", "schm\u00fc\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADV", "APPR", "PDAT", "NN", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Heil denen Freund! die weder Stuhl noch Band", "tokens": ["Heil", "de\u00b7nen", "Freund", "!", "die", "we\u00b7der", "Stuhl", "noch", "Band"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "PDS", "NN", "$.", "ART", "KON", "NN", "ADV", "NN"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.2": {"text": "Erh\u00f6hen kann, die uns, wie du, durch Thaten sagen,", "tokens": ["Er\u00b7h\u00f6\u00b7hen", "kann", ",", "die", "uns", ",", "wie", "du", ",", "durch", "Tha\u00b7ten", "sa\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "$,", "PRELS", "PPER", "$,", "PWAV", "PPER", "$,", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Da\u00df sie ein Herz f\u00fcrs Vaterland", "tokens": ["Da\u00df", "sie", "ein", "Herz", "f\u00fcrs", "Va\u00b7ter\u00b7land"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "NN", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und f\u00fcr die Freundschaft in sich tragen.", "tokens": ["Und", "f\u00fcr", "die", "Freund\u00b7schaft", "in", "sich", "tra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "APPR", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}