{"textgrid.poem.64768": {"metadata": {"author": {"name": "K\u00e4stner, Abraham Gotthelf", "birth": "N.A.", "death": "N.A."}, "title": "15. Auf den Taback", "genre": "verse", "period": "N.A.", "pub_year": 1741, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "O Pflanze voller Trefflichkeiten!", "tokens": ["O", "Pflan\u00b7ze", "vol\u00b7ler", "Treff\u00b7lich\u00b7kei\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Kraut, dessen Kenntni\u00df nie das Alterthum begl\u00fcckt,", "tokens": ["Kraut", ",", "des\u00b7sen", "Kennt\u00b7ni\u00df", "nie", "das", "Al\u00b7ter\u00b7thum", "be\u00b7gl\u00fcckt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PRELAT", "NN", "ADV", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Das uns, zur Ehre neuer Zeiten,", "tokens": ["Das", "uns", ",", "zur", "Eh\u00b7re", "neu\u00b7er", "Zei\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "$,", "APPRART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die neuentdeckte Welt, wie Peru's Gold, geschickt.", "tokens": ["Die", "neu\u00b7ent\u00b7deck\u00b7te", "Welt", ",", "wie", "Pe\u00b7ru's", "Gold", ",", "ge\u00b7schickt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PWAV", "NE", "NN", "$,", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Dein Rauch, durch hohlen Thon gesogen,", "tokens": ["Dein", "Rauch", ",", "durch", "hoh\u00b7len", "Thon", "ge\u00b7so\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "APPR", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Erg\u00f6tzt, wem m\u00e4nnlich Blut in seinen Adern flie\u00dft;", "tokens": ["Er\u00b7g\u00f6tzt", ",", "wem", "m\u00e4nn\u00b7lich", "Blut", "in", "sei\u00b7nen", "A\u00b7dern", "flie\u00dft", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "PWS", "ADJD", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die Sch\u00f6nen selbst sind dir gewogen,", "tokens": ["Die", "Sch\u00f6\u00b7nen", "selbst", "sind", "dir", "ge\u00b7wo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VAFIN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und \u00f6fters hat dein Rohr ein zarter Mund gek\u00fc\u00dft.", "tokens": ["Und", "\u00f6f\u00b7ters", "hat", "dein", "Rohr", "ein", "zar\u00b7ter", "Mund", "ge\u00b7k\u00fc\u00dft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "PPOSAT", "NN", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Durch kurzen Weg nicht sehr gel\u00e4utert,", "tokens": ["Durch", "kur\u00b7zen", "Weg", "nicht", "sehr", "ge\u00b7l\u00e4u\u00b7tert", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "PTKNEG", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Verleiht dein grober Theil dem Arbeitsmanne Kraft;", "tokens": ["Ver\u00b7leiht", "dein", "gro\u00b7ber", "Theil", "dem", "Ar\u00b7beits\u00b7man\u00b7ne", "Kraft", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "ADJA", "NN", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Manch weises Hirn hast du erheitert,", "tokens": ["Manch", "wei\u00b7ses", "Hirn", "hast", "du", "er\u00b7hei\u00b7tert", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "VAFIN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wenn dir ein l\u00e4ngrer Zug mehr Reinigkeit verschafft.", "tokens": ["Wenn", "dir", "ein", "l\u00e4ng\u00b7rer", "Zug", "mehr", "Rei\u00b7nig\u00b7keit", "ver\u00b7schafft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "PIAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Zu wenig, w\u00e4rst du zum Erg\u00f6tzen", "tokens": ["Zu", "we\u00b7nig", ",", "w\u00e4rst", "du", "zum", "Er\u00b7g\u00f6t\u00b7zen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "PIS", "$,", "VAFIN", "PPER", "APPRART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "In einerley Gestalt, im Dampfe nur bereit;", "tokens": ["In", "ei\u00b7ner\u00b7ley", "Ge\u00b7stalt", ",", "im", "Damp\u00b7fe", "nur", "be\u00b7reit", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "$,", "APPRART", "NN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Du bist gedoppelt mehr zu sch\u00e4tzen,", "tokens": ["Du", "bist", "ge\u00b7dop\u00b7pelt", "mehr", "zu", "sch\u00e4t\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Da uns zugleich dein Staub, dein edler Staub erfreut.", "tokens": ["Da", "uns", "zu\u00b7gleich", "dein", "Staub", ",", "dein", "ed\u00b7ler", "Staub", "er\u00b7freut", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PPOSAT", "NN", "$,", "PPOSAT", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Ihm ein Beh\u00e4ltni\u00df zu bereiten,", "tokens": ["Ihm", "ein", "Be\u00b7h\u00e4lt\u00b7ni\u00df", "zu", "be\u00b7rei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sind kostbares Metall und theurer Stein bestimmt;", "tokens": ["Sind", "kost\u00b7ba\u00b7res", "Me\u00b7tall", "und", "theu\u00b7rer", "Stein", "be\u00b7stimmt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJA", "NN", "KON", "ADJD", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Er zeigt des Stutzers Artigkeiten,", "tokens": ["Er", "zeigt", "des", "Stut\u00b7zers", "Ar\u00b7tig\u00b7kei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Der mit geschickter Hand ihn giebet oder nimmt.", "tokens": ["Der", "mit", "ge\u00b7schick\u00b7ter", "Hand", "ihn", "gie\u00b7bet", "o\u00b7der", "nimmt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ADJA", "NN", "PPER", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Viel Dichter haben dich erhoben,", "tokens": ["Viel", "Dich\u00b7ter", "ha\u00b7ben", "dich", "er\u00b7ho\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Doch ich kann unparteyisch loben,", "tokens": ["Doch", "ich", "kann", "un\u00b7par\u00b7tey\u00b7isch", "lo\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VMFIN", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Der selten deinen Staub, nie deinen Rauch genie\u00dft.", "tokens": ["Der", "sel\u00b7ten", "dei\u00b7nen", "Staub", ",", "nie", "dei\u00b7nen", "Rauch", "ge\u00b7nie\u00dft", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "PPOSAT", "NN", "$,", "ADV", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "So singt, vom Ph\u00f6bus unterwiesen,", "tokens": ["So", "singt", ",", "vom", "Ph\u00f6\u00b7bus", "un\u00b7ter\u00b7wie\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Mein ", "tokens": ["Mein"], "token_info": ["word"], "pos": ["PPOSAT"], "meter": "-", "measure": "single.down"}, "line.3": {"text": "So hab ich dich, Taback, gepriesen,", "tokens": ["So", "hab", "ich", "dich", ",", "Ta\u00b7back", ",", "ge\u00b7prie\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PRF", "$,", "NN", "$,", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Kraut, dessen Dampf und Staub gelehrt und artig macht.", "tokens": ["Kraut", ",", "des\u00b7sen", "Dampf", "und", "Staub", "ge\u00b7lehrt", "und", "ar\u00b7tig", "macht", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PRELAT", "NN", "KON", "NN", "VVPP", "KON", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "O Pflanze voller Trefflichkeiten!", "tokens": ["O", "Pflan\u00b7ze", "vol\u00b7ler", "Treff\u00b7lich\u00b7kei\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Kraut, dessen Kenntni\u00df nie das Alterthum begl\u00fcckt,", "tokens": ["Kraut", ",", "des\u00b7sen", "Kennt\u00b7ni\u00df", "nie", "das", "Al\u00b7ter\u00b7thum", "be\u00b7gl\u00fcckt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PRELAT", "NN", "ADV", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Das uns, zur Ehre neuer Zeiten,", "tokens": ["Das", "uns", ",", "zur", "Eh\u00b7re", "neu\u00b7er", "Zei\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "$,", "APPRART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die neuentdeckte Welt, wie Peru's Gold, geschickt.", "tokens": ["Die", "neu\u00b7ent\u00b7deck\u00b7te", "Welt", ",", "wie", "Pe\u00b7ru's", "Gold", ",", "ge\u00b7schickt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PWAV", "NE", "NN", "$,", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Dein Rauch, durch hohlen Thon gesogen,", "tokens": ["Dein", "Rauch", ",", "durch", "hoh\u00b7len", "Thon", "ge\u00b7so\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "APPR", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Erg\u00f6tzt, wem m\u00e4nnlich Blut in seinen Adern flie\u00dft;", "tokens": ["Er\u00b7g\u00f6tzt", ",", "wem", "m\u00e4nn\u00b7lich", "Blut", "in", "sei\u00b7nen", "A\u00b7dern", "flie\u00dft", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "PWS", "ADJD", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die Sch\u00f6nen selbst sind dir gewogen,", "tokens": ["Die", "Sch\u00f6\u00b7nen", "selbst", "sind", "dir", "ge\u00b7wo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VAFIN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und \u00f6fters hat dein Rohr ein zarter Mund gek\u00fc\u00dft.", "tokens": ["Und", "\u00f6f\u00b7ters", "hat", "dein", "Rohr", "ein", "zar\u00b7ter", "Mund", "ge\u00b7k\u00fc\u00dft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "PPOSAT", "NN", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.10": {"line.1": {"text": "Durch kurzen Weg nicht sehr gel\u00e4utert,", "tokens": ["Durch", "kur\u00b7zen", "Weg", "nicht", "sehr", "ge\u00b7l\u00e4u\u00b7tert", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "PTKNEG", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Verleiht dein grober Theil dem Arbeitsmanne Kraft;", "tokens": ["Ver\u00b7leiht", "dein", "gro\u00b7ber", "Theil", "dem", "Ar\u00b7beits\u00b7man\u00b7ne", "Kraft", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "ADJA", "NN", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Manch weises Hirn hast du erheitert,", "tokens": ["Manch", "wei\u00b7ses", "Hirn", "hast", "du", "er\u00b7hei\u00b7tert", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "VAFIN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wenn dir ein l\u00e4ngrer Zug mehr Reinigkeit verschafft.", "tokens": ["Wenn", "dir", "ein", "l\u00e4ng\u00b7rer", "Zug", "mehr", "Rei\u00b7nig\u00b7keit", "ver\u00b7schafft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "PIAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.11": {"line.1": {"text": "Zu wenig, w\u00e4rst du zum Erg\u00f6tzen", "tokens": ["Zu", "we\u00b7nig", ",", "w\u00e4rst", "du", "zum", "Er\u00b7g\u00f6t\u00b7zen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "PIS", "$,", "VAFIN", "PPER", "APPRART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "In einerley Gestalt, im Dampfe nur bereit;", "tokens": ["In", "ei\u00b7ner\u00b7ley", "Ge\u00b7stalt", ",", "im", "Damp\u00b7fe", "nur", "be\u00b7reit", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "$,", "APPRART", "NN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Du bist gedoppelt mehr zu sch\u00e4tzen,", "tokens": ["Du", "bist", "ge\u00b7dop\u00b7pelt", "mehr", "zu", "sch\u00e4t\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Da uns zugleich dein Staub, dein edler Staub erfreut.", "tokens": ["Da", "uns", "zu\u00b7gleich", "dein", "Staub", ",", "dein", "ed\u00b7ler", "Staub", "er\u00b7freut", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PPOSAT", "NN", "$,", "PPOSAT", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.12": {"line.1": {"text": "Ihm ein Beh\u00e4ltni\u00df zu bereiten,", "tokens": ["Ihm", "ein", "Be\u00b7h\u00e4lt\u00b7ni\u00df", "zu", "be\u00b7rei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sind kostbares Metall und theurer Stein bestimmt;", "tokens": ["Sind", "kost\u00b7ba\u00b7res", "Me\u00b7tall", "und", "theu\u00b7rer", "Stein", "be\u00b7stimmt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJA", "NN", "KON", "ADJD", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Er zeigt des Stutzers Artigkeiten,", "tokens": ["Er", "zeigt", "des", "Stut\u00b7zers", "Ar\u00b7tig\u00b7kei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Der mit geschickter Hand ihn giebet oder nimmt.", "tokens": ["Der", "mit", "ge\u00b7schick\u00b7ter", "Hand", "ihn", "gie\u00b7bet", "o\u00b7der", "nimmt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ADJA", "NN", "PPER", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.13": {"line.1": {"text": "Viel Dichter haben dich erhoben,", "tokens": ["Viel", "Dich\u00b7ter", "ha\u00b7ben", "dich", "er\u00b7ho\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Doch ich kann unparteyisch loben,", "tokens": ["Doch", "ich", "kann", "un\u00b7par\u00b7tey\u00b7isch", "lo\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VMFIN", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Der selten deinen Staub, nie deinen Rauch genie\u00dft.", "tokens": ["Der", "sel\u00b7ten", "dei\u00b7nen", "Staub", ",", "nie", "dei\u00b7nen", "Rauch", "ge\u00b7nie\u00dft", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "PPOSAT", "NN", "$,", "ADV", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.14": {"line.1": {"text": "So singt, vom Ph\u00f6bus unterwiesen,", "tokens": ["So", "singt", ",", "vom", "Ph\u00f6\u00b7bus", "un\u00b7ter\u00b7wie\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Mein ", "tokens": ["Mein"], "token_info": ["word"], "pos": ["PPOSAT"], "meter": "-", "measure": "single.down"}, "line.3": {"text": "So hab ich dich, Taback, gepriesen,", "tokens": ["So", "hab", "ich", "dich", ",", "Ta\u00b7back", ",", "ge\u00b7prie\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PRF", "$,", "NN", "$,", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Kraut, dessen Dampf und Staub gelehrt und artig macht.", "tokens": ["Kraut", ",", "des\u00b7sen", "Dampf", "und", "Staub", "ge\u00b7lehrt", "und", "ar\u00b7tig", "macht", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PRELAT", "NN", "KON", "NN", "VVPP", "KON", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}