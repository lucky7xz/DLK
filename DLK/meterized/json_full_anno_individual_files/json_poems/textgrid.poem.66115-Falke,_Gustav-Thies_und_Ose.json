{"textgrid.poem.66115": {"metadata": {"author": {"name": "Falke, Gustav", "birth": "N.A.", "death": "N.A."}, "title": "Thies und Ose", "genre": "verse", "period": "N.A.", "pub_year": 1884, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "In Wenningstedt bei Karten und Korn", "tokens": ["In", "Wen\u00b7nings\u00b7tedt", "bei", "Kar\u00b7ten", "und", "Korn"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NE", "APPR", "NN", "KON", "NN"], "meter": "---+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Erschlug einst ein Bauer in j\u00e4hem Zorn", "tokens": ["Er\u00b7schlug", "einst", "ein", "Bau\u00b7er", "in", "j\u00e4\u00b7hem", "Zorn"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "ART", "NN", "APPR", "ADJA", "NN"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Seinen Gast. Thies Thie\u00dfen war stark,", "tokens": ["Sei\u00b7nen", "Gast", ".", "Thies", "Thie\u00b7\u00dfen", "war", "stark", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$.", "NE", "NN", "VAFIN", "ADJD", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Und der Hansen ein St\u00e4nker um jeden Quark.", "tokens": ["Und", "der", "Han\u00b7sen", "ein", "St\u00e4n\u00b7ker", "um", "je\u00b7den", "Quark", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ART", "NN", "APPR", "PIAT", "NN", "$."], "meter": "--+--+--+-+", "measure": "anapaest.tri.plus"}}, "stanza.2": {"line.1": {"text": "Nun lag er bleich und im Blut auf dem Stroh.", "tokens": ["Nun", "lag", "er", "bleich", "und", "im", "Blut", "auf", "dem", "Stroh", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "KON", "APPRART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Aber wo war Thies Thie\u00dfen? Wo?", "tokens": ["A\u00b7ber", "wo", "war", "Thies", "Thie\u00b7\u00dfen", "?", "Wo", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "PWAV", "VAFIN", "NE", "NN", "$.", "PWAV", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Sie suchten ihn und fanden ihn nicht,", "tokens": ["Sie", "such\u00b7ten", "ihn", "und", "fan\u00b7den", "ihn", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "KON", "VVFIN", "PPER", "PTKNEG", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Und der Galgen machte ein langes Gesicht.", "tokens": ["Und", "der", "Gal\u00b7gen", "mach\u00b7te", "ein", "lan\u00b7ges", "Ge\u00b7sicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "--+-+--+--+", "measure": "iambic.tetra.relaxed"}}, "stanza.3": {"line.1": {"text": "Ose, des M\u00f6rders Weib, kam in Not.", "tokens": ["O\u00b7se", ",", "des", "M\u00f6r\u00b7ders", "Weib", ",", "kam", "in", "Not", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ART", "NN", "NN", "$,", "VVFIN", "APPR", "NN", "$."], "meter": "+--+-+--+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Vier Kinder wollten von ihr Brot.", "tokens": ["Vier", "Kin\u00b7der", "woll\u00b7ten", "von", "ihr", "Brot", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "VMFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ihr Kram ging zur\u00fcck. St\u00fcck f\u00fcr St\u00fcck", "tokens": ["Ihr", "Kram", "ging", "zu\u00b7r\u00fcck", ".", "St\u00fcck", "f\u00fcr", "St\u00fcck"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VVFIN", "PTKVZ", "$.", "NN", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ward verkauft, und sie suchte bei Fremden ihr Gl\u00fcck.", "tokens": ["Ward", "ver\u00b7kauft", ",", "und", "sie", "such\u00b7te", "bei", "Frem\u00b7den", "ihr", "Gl\u00fcck", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "VVPP", "$,", "KON", "PPER", "VVFIN", "APPR", "NN", "PPOSAT", "NN", "$."], "meter": "--+--+--+--+", "measure": "anapaest.tetra.plus"}}, "stanza.4": {"line.1": {"text": "Doch stand sie in Ehren bei jedermann", "tokens": ["Doch", "stand", "sie", "in", "Eh\u00b7ren", "bei", "je\u00b7der\u00b7mann"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "APPR", "NN", "APPR", "PIS"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Und tat ihnen leid. Die Zeit verrann,", "tokens": ["Und", "tat", "ih\u00b7nen", "leid", ".", "Die", "Zeit", "ver\u00b7rann", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADJD", "$.", "ART", "NN", "VVFIN", "$,"], "meter": "----+-+-+", "measure": "unknown.measure.tri"}, "line.3": {"text": "Und Thies Thie\u00dfen war und blieb", "tokens": ["Und", "Thies", "Thie\u00b7\u00dfen", "war", "und", "blieb"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "NE", "NN", "VAFIN", "KON", "VVFIN"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.4": {"text": "Weg, als w\u00e4re die Welt ein Sieb.", "tokens": ["Weg", ",", "als", "w\u00e4\u00b7re", "die", "Welt", "ein", "Sieb", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KOKOM", "VAFIN", "ART", "NN", "ART", "NN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.5": {"line.1": {"text": "So wurden es Jahre. Auf einmal fings", "tokens": ["So", "wur\u00b7den", "es", "Jah\u00b7re", ".", "Auf", "ein\u00b7mal", "fings"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "NN", "$.", "APPR", "ADV", "NE"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Zu tuscheln an, bis nach Rantum gings:", "tokens": ["Zu", "tu\u00b7scheln", "an", ",", "bis", "nach", "Ran\u00b7tum", "gings", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "PTKVZ", "$,", "KOUS", "APPR", "NE", "VVFIN", "$."], "meter": "-+----+-+", "measure": "dactylic.init"}, "line.3": {"text": "Habt ihr gesehn? Schon lange. Nanu!", "tokens": ["Habt", "ihr", "ge\u00b7sehn", "?", "Schon", "lan\u00b7ge", ".", "Na\u00b7nu", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["VAFIN", "PPER", "VVPP", "$.", "ADV", "ADV", "$.", "NE", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Meint ihr? Und sie nickten sich zu.", "tokens": ["Meint", "ihr", "?", "Und", "sie", "nick\u00b7ten", "sich", "zu", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$.", "KON", "PPER", "VVFIN", "PRF", "PTKVZ", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.6": {"line.1": {"text": "Sie war doch sonst ein ehrlich Weib,", "tokens": ["Sie", "war", "doch", "sonst", "ein", "ehr\u00b7lich", "Weib", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "ART", "ADJD", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Nun schreit ihre Schande das Kind im Leib.", "tokens": ["Nun", "schreit", "ih\u00b7re", "Schan\u00b7de", "das", "Kind", "im", "Leib", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "ART", "NN", "APPRART", "NN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Mit wem sies wohl h\u00e4lt? Das Mannsvolk ist toll!", "tokens": ["Mit", "wem", "sies", "wohl", "h\u00e4lt", "?", "Das", "Manns\u00b7volk", "ist", "toll", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PWS", "PPER", "ADV", "VVFIN", "$.", "ART", "NN", "VAFIN", "ADJD", "$."], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "\u2013 Das war ein Geschw\u00e4tz, alle Stuben voll.", "tokens": ["\u2013", "Das", "war", "ein", "Ge\u00b7schw\u00e4tz", ",", "al\u00b7le", "Stu\u00b7ben", "voll", "."], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PDS", "VAFIN", "ART", "NN", "$,", "PIAT", "NN", "ADJD", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}}, "stanza.7": {"line.1": {"text": "Die fromme Ose ertrug es in Scham,", "tokens": ["Die", "from\u00b7me", "O\u00b7se", "er\u00b7trug", "es", "in", "Scham", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PPER", "APPR", "NN", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Kein Wort \u00fcber ihre Lippen kam.", "tokens": ["Kein", "Wort", "\u00fc\u00b7ber", "ih\u00b7re", "Lip\u00b7pen", "kam", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Nur einem fra\u00df es am Herzen und fra\u00df,", "tokens": ["Nur", "ei\u00b7nem", "fra\u00df", "es", "am", "Her\u00b7zen", "und", "fra\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "VVFIN", "PPER", "APPRART", "NN", "KON", "VVFIN", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Bis ihm der Schmerz in den F\u00e4usten sa\u00df.", "tokens": ["Bis", "ihm", "der", "Schmerz", "in", "den", "F\u00e4us\u00b7ten", "sa\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ART", "NN", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.8": {"line.1": {"text": "Und eh sichs die L\u00e4sterm\u00e4uler versahn,", "tokens": ["Und", "eh", "sichs", "die", "L\u00e4s\u00b7ter\u00b7m\u00e4u\u00b7ler", "ver\u00b7sahn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PIS", "ART", "NN", "VVPP", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Stand er auf: Ich habs getan!", "tokens": ["Stand", "er", "auf", ":", "Ich", "habs", "ge\u00b7tan", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKVZ", "$.", "PPER", "NE", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und standen alle und glotzten sehr:", "tokens": ["Und", "stan\u00b7den", "al\u00b7le", "und", "glotz\u00b7ten", "sehr", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIS", "KON", "VVFIN", "ADV", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Thies Thie\u00dfen? Gott sei bei uns! Woher?", "tokens": ["Thies", "Thie\u00b7\u00dfen", "?", "Gott", "sei", "bei", "uns", "!", "Wo\u00b7her", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["NE", "NN", "$.", "NN", "VAFIN", "APPR", "PPER", "$.", "PWAV", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.9": {"line.1": {"text": "Nicht verrat ich das D\u00fcnenloch,", "tokens": ["Nicht", "ver\u00b7rat", "ich", "das", "D\u00fc\u00b7nen\u00b7loch", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.2": {"text": "Und ihr findet es nimmer. Sie aber fands doch.", "tokens": ["Und", "ihr", "fin\u00b7det", "es", "nim\u00b7mer", ".", "Sie", "a\u00b7ber", "fands", "doch", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPER", "ADV", "$.", "PPER", "ADV", "VVFIN", "ADV", "$."], "meter": "+-+--+--+---", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "Und gehts um den Hals, das Kind ist mein.", "tokens": ["Und", "gehts", "um", "den", "Hals", ",", "das", "Kind", "ist", "mein", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "$,", "ART", "NN", "VAFIN", "PPOSAT", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Und verdammt, wers nicht glaubt. Ich bl\u00e4us ihm ein.", "tokens": ["Und", "ver\u00b7dammt", ",", "wers", "nicht", "glaubt", ".", "Ich", "bl\u00e4us", "ihm", "ein", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVPP", "$,", "PWS", "PTKNEG", "VVFIN", "$.", "PPER", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "--+--+-+-+", "measure": "anapaest.di.plus"}}, "stanza.10": {"line.1": {"text": "Und er sah elend aus und schwach,", "tokens": ["Und", "er", "sah", "e\u00b7lend", "aus", "und", "schwach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ADJD", "PTKVZ", "KON", "ADJD", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.2": {"text": "Und er hielt sie wie ein Gespenst in Schach,", "tokens": ["Und", "er", "hielt", "sie", "wie", "ein", "Ge\u00b7spenst", "in", "Schach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPER", "KOKOM", "ART", "NN", "APPR", "NE", "$,"], "meter": "--+--+-+-+", "measure": "anapaest.di.plus"}, "line.3": {"text": "Bis ihnen allen allm\u00e4hlich klar,", "tokens": ["Bis", "ih\u00b7nen", "al\u00b7len", "all\u00b7m\u00e4h\u00b7lich", "klar", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "PIAT", "ADJD", "ADJD", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Da\u00df der da wirklich Thies Thie\u00dfen war. \u2013", "tokens": ["Da\u00df", "der", "da", "wirk\u00b7lich", "Thies", "Thie\u00b7\u00dfen", "war", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "ART", "ADV", "ADJD", "NN", "NN", "VAFIN", "$.", "$("], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.11": {"line.1": {"text": "Der Hansen war tot, von keinem vermi\u00dft,", "tokens": ["Der", "Han\u00b7sen", "war", "tot", ",", "von", "kei\u00b7nem", "ver\u00b7mi\u00dft", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "$,", "APPR", "PIS", "VVPP", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Ein S\u00e4ufer war er und schlechter Christ.", "tokens": ["Ein", "S\u00e4u\u00b7fer", "war", "er", "und", "schlech\u00b7ter", "Christ", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "KON", "ADJA", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Aber der Thie\u00dfen, ein Kerl ist er doch!", "tokens": ["A\u00b7ber", "der", "Thie\u00b7\u00dfen", ",", "ein", "Kerl", "ist", "er", "doch", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "ART", "NN", "VAFIN", "PPER", "ADV", "$."], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.4": {"text": "Und die Ose, gibts eine Bravere noch?", "tokens": ["Und", "die", "O\u00b7se", ",", "gibts", "ei\u00b7ne", "Bra\u00b7ve\u00b7re", "noch", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "VVFIN", "ART", "NN", "ADV", "$."], "meter": "--+--+--+-+", "measure": "anapaest.tri.plus"}}, "stanza.12": {"line.1": {"text": "Alle die Jahre in Elend und Not", "tokens": ["Al\u00b7le", "die", "Jah\u00b7re", "in", "E\u00b7lend", "und", "Not"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PIS", "ART", "NN", "APPR", "NN", "KON", "NN"], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.2": {"text": "Teilte sie ihr Hungerbrot", "tokens": ["Teil\u00b7te", "sie", "ihr", "Hun\u00b7ger\u00b7brot"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Treulich ihm mit. Und jetzt weinte sie da", "tokens": ["Treu\u00b7lich", "ihm", "mit", ".", "Und", "jetzt", "wein\u00b7te", "sie", "da"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NE", "PPER", "PTKVZ", "$.", "KON", "ADV", "VVFIN", "PPER", "ADV"], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.4": {"text": "An seinem Hals. Es ging allen nah.", "tokens": ["An", "sei\u00b7nem", "Hals", ".", "Es", "ging", "al\u00b7len", "nah", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$.", "PPER", "VVFIN", "PIAT", "ADJD", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.13": {"line.1": {"text": "Sie kauten und spuckten und sahen sich an", "tokens": ["Sie", "kau\u00b7ten", "und", "spuck\u00b7ten", "und", "sa\u00b7hen", "sich", "an"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "KON", "VVFIN", "PRF", "APPR"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "Und schoben sich sacht an Thie\u00dfen heran", "tokens": ["Und", "scho\u00b7ben", "sich", "sacht", "an", "Thie\u00b7\u00dfen", "he\u00b7ran"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PRF", "ADJD", "APPR", "NN", "PTKVZ"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Und brummten und sch\u00fcttelten ihm die Hand.", "tokens": ["Und", "brumm\u00b7ten", "und", "sch\u00fct\u00b7tel\u00b7ten", "ihm", "die", "Hand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "KON", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Das war ihr Gericht. Und so blieb er im Land.", "tokens": ["Das", "war", "ihr", "Ge\u00b7richt", ".", "Und", "so", "blieb", "er", "im", "Land", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPOSAT", "NN", "$.", "KON", "ADV", "VVFIN", "PPER", "APPRART", "NN", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}}, "stanza.14": {"line.1": {"text": "In Wenningstedt bei Karten und Korn", "tokens": ["In", "Wen\u00b7nings\u00b7tedt", "bei", "Kar\u00b7ten", "und", "Korn"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NE", "APPR", "NN", "KON", "NN"], "meter": "---+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Erschlug einst ein Bauer in j\u00e4hem Zorn", "tokens": ["Er\u00b7schlug", "einst", "ein", "Bau\u00b7er", "in", "j\u00e4\u00b7hem", "Zorn"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "ART", "NN", "APPR", "ADJA", "NN"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Seinen Gast. Thies Thie\u00dfen war stark,", "tokens": ["Sei\u00b7nen", "Gast", ".", "Thies", "Thie\u00b7\u00dfen", "war", "stark", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$.", "NE", "NN", "VAFIN", "ADJD", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Und der Hansen ein St\u00e4nker um jeden Quark.", "tokens": ["Und", "der", "Han\u00b7sen", "ein", "St\u00e4n\u00b7ker", "um", "je\u00b7den", "Quark", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ART", "NN", "APPR", "PIAT", "NN", "$."], "meter": "--+--+--+-+", "measure": "anapaest.tri.plus"}}, "stanza.15": {"line.1": {"text": "Nun lag er bleich und im Blut auf dem Stroh.", "tokens": ["Nun", "lag", "er", "bleich", "und", "im", "Blut", "auf", "dem", "Stroh", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "KON", "APPRART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Aber wo war Thies Thie\u00dfen? Wo?", "tokens": ["A\u00b7ber", "wo", "war", "Thies", "Thie\u00b7\u00dfen", "?", "Wo", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "PWAV", "VAFIN", "NE", "NN", "$.", "PWAV", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Sie suchten ihn und fanden ihn nicht,", "tokens": ["Sie", "such\u00b7ten", "ihn", "und", "fan\u00b7den", "ihn", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "KON", "VVFIN", "PPER", "PTKNEG", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Und der Galgen machte ein langes Gesicht.", "tokens": ["Und", "der", "Gal\u00b7gen", "mach\u00b7te", "ein", "lan\u00b7ges", "Ge\u00b7sicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "--+-+--+--+", "measure": "iambic.tetra.relaxed"}}, "stanza.16": {"line.1": {"text": "Ose, des M\u00f6rders Weib, kam in Not.", "tokens": ["O\u00b7se", ",", "des", "M\u00f6r\u00b7ders", "Weib", ",", "kam", "in", "Not", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ART", "NN", "NN", "$,", "VVFIN", "APPR", "NN", "$."], "meter": "+--+-+--+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Vier Kinder wollten von ihr Brot.", "tokens": ["Vier", "Kin\u00b7der", "woll\u00b7ten", "von", "ihr", "Brot", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "VMFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ihr Kram ging zur\u00fcck. St\u00fcck f\u00fcr St\u00fcck", "tokens": ["Ihr", "Kram", "ging", "zu\u00b7r\u00fcck", ".", "St\u00fcck", "f\u00fcr", "St\u00fcck"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VVFIN", "PTKVZ", "$.", "NN", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ward verkauft, und sie suchte bei Fremden ihr Gl\u00fcck.", "tokens": ["Ward", "ver\u00b7kauft", ",", "und", "sie", "such\u00b7te", "bei", "Frem\u00b7den", "ihr", "Gl\u00fcck", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "VVPP", "$,", "KON", "PPER", "VVFIN", "APPR", "NN", "PPOSAT", "NN", "$."], "meter": "--+--+--+--+", "measure": "anapaest.tetra.plus"}}, "stanza.17": {"line.1": {"text": "Doch stand sie in Ehren bei jedermann", "tokens": ["Doch", "stand", "sie", "in", "Eh\u00b7ren", "bei", "je\u00b7der\u00b7mann"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "APPR", "NN", "APPR", "PIS"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Und tat ihnen leid. Die Zeit verrann,", "tokens": ["Und", "tat", "ih\u00b7nen", "leid", ".", "Die", "Zeit", "ver\u00b7rann", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADJD", "$.", "ART", "NN", "VVFIN", "$,"], "meter": "----+-+-+", "measure": "unknown.measure.tri"}, "line.3": {"text": "Und Thies Thie\u00dfen war und blieb", "tokens": ["Und", "Thies", "Thie\u00b7\u00dfen", "war", "und", "blieb"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "NE", "NN", "VAFIN", "KON", "VVFIN"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.4": {"text": "Weg, als w\u00e4re die Welt ein Sieb.", "tokens": ["Weg", ",", "als", "w\u00e4\u00b7re", "die", "Welt", "ein", "Sieb", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KOKOM", "VAFIN", "ART", "NN", "ART", "NN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.18": {"line.1": {"text": "So wurden es Jahre. Auf einmal fings", "tokens": ["So", "wur\u00b7den", "es", "Jah\u00b7re", ".", "Auf", "ein\u00b7mal", "fings"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "NN", "$.", "APPR", "ADV", "NE"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Zu tuscheln an, bis nach Rantum gings:", "tokens": ["Zu", "tu\u00b7scheln", "an", ",", "bis", "nach", "Ran\u00b7tum", "gings", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "PTKVZ", "$,", "KOUS", "APPR", "NE", "VVFIN", "$."], "meter": "-+----+-+", "measure": "dactylic.init"}, "line.3": {"text": "Habt ihr gesehn? Schon lange. Nanu!", "tokens": ["Habt", "ihr", "ge\u00b7sehn", "?", "Schon", "lan\u00b7ge", ".", "Na\u00b7nu", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["VAFIN", "PPER", "VVPP", "$.", "ADV", "ADV", "$.", "NE", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Meint ihr? Und sie nickten sich zu.", "tokens": ["Meint", "ihr", "?", "Und", "sie", "nick\u00b7ten", "sich", "zu", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$.", "KON", "PPER", "VVFIN", "PRF", "PTKVZ", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.19": {"line.1": {"text": "Sie war doch sonst ein ehrlich Weib,", "tokens": ["Sie", "war", "doch", "sonst", "ein", "ehr\u00b7lich", "Weib", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "ART", "ADJD", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Nun schreit ihre Schande das Kind im Leib.", "tokens": ["Nun", "schreit", "ih\u00b7re", "Schan\u00b7de", "das", "Kind", "im", "Leib", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "ART", "NN", "APPRART", "NN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Mit wem sies wohl h\u00e4lt? Das Mannsvolk ist toll!", "tokens": ["Mit", "wem", "sies", "wohl", "h\u00e4lt", "?", "Das", "Manns\u00b7volk", "ist", "toll", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PWS", "PPER", "ADV", "VVFIN", "$.", "ART", "NN", "VAFIN", "ADJD", "$."], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "\u2013 Das war ein Geschw\u00e4tz, alle Stuben voll.", "tokens": ["\u2013", "Das", "war", "ein", "Ge\u00b7schw\u00e4tz", ",", "al\u00b7le", "Stu\u00b7ben", "voll", "."], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PDS", "VAFIN", "ART", "NN", "$,", "PIAT", "NN", "ADJD", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}}, "stanza.20": {"line.1": {"text": "Die fromme Ose ertrug es in Scham,", "tokens": ["Die", "from\u00b7me", "O\u00b7se", "er\u00b7trug", "es", "in", "Scham", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PPER", "APPR", "NN", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Kein Wort \u00fcber ihre Lippen kam.", "tokens": ["Kein", "Wort", "\u00fc\u00b7ber", "ih\u00b7re", "Lip\u00b7pen", "kam", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Nur einem fra\u00df es am Herzen und fra\u00df,", "tokens": ["Nur", "ei\u00b7nem", "fra\u00df", "es", "am", "Her\u00b7zen", "und", "fra\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "VVFIN", "PPER", "APPRART", "NN", "KON", "VVFIN", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Bis ihm der Schmerz in den F\u00e4usten sa\u00df.", "tokens": ["Bis", "ihm", "der", "Schmerz", "in", "den", "F\u00e4us\u00b7ten", "sa\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ART", "NN", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.21": {"line.1": {"text": "Und eh sichs die L\u00e4sterm\u00e4uler versahn,", "tokens": ["Und", "eh", "sichs", "die", "L\u00e4s\u00b7ter\u00b7m\u00e4u\u00b7ler", "ver\u00b7sahn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PIS", "ART", "NN", "VVPP", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Stand er auf: Ich habs getan!", "tokens": ["Stand", "er", "auf", ":", "Ich", "habs", "ge\u00b7tan", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKVZ", "$.", "PPER", "NE", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und standen alle und glotzten sehr:", "tokens": ["Und", "stan\u00b7den", "al\u00b7le", "und", "glotz\u00b7ten", "sehr", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIS", "KON", "VVFIN", "ADV", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Thies Thie\u00dfen? Gott sei bei uns! Woher?", "tokens": ["Thies", "Thie\u00b7\u00dfen", "?", "Gott", "sei", "bei", "uns", "!", "Wo\u00b7her", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["NE", "NN", "$.", "NN", "VAFIN", "APPR", "PPER", "$.", "PWAV", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.22": {"line.1": {"text": "Nicht verrat ich das D\u00fcnenloch,", "tokens": ["Nicht", "ver\u00b7rat", "ich", "das", "D\u00fc\u00b7nen\u00b7loch", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.2": {"text": "Und ihr findet es nimmer. Sie aber fands doch.", "tokens": ["Und", "ihr", "fin\u00b7det", "es", "nim\u00b7mer", ".", "Sie", "a\u00b7ber", "fands", "doch", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPER", "ADV", "$.", "PPER", "ADV", "VVFIN", "ADV", "$."], "meter": "+-+--+--+---", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "Und gehts um den Hals, das Kind ist mein.", "tokens": ["Und", "gehts", "um", "den", "Hals", ",", "das", "Kind", "ist", "mein", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "$,", "ART", "NN", "VAFIN", "PPOSAT", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Und verdammt, wers nicht glaubt. Ich bl\u00e4us ihm ein.", "tokens": ["Und", "ver\u00b7dammt", ",", "wers", "nicht", "glaubt", ".", "Ich", "bl\u00e4us", "ihm", "ein", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVPP", "$,", "PWS", "PTKNEG", "VVFIN", "$.", "PPER", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "--+--+-+-+", "measure": "anapaest.di.plus"}}, "stanza.23": {"line.1": {"text": "Und er sah elend aus und schwach,", "tokens": ["Und", "er", "sah", "e\u00b7lend", "aus", "und", "schwach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ADJD", "PTKVZ", "KON", "ADJD", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.2": {"text": "Und er hielt sie wie ein Gespenst in Schach,", "tokens": ["Und", "er", "hielt", "sie", "wie", "ein", "Ge\u00b7spenst", "in", "Schach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPER", "KOKOM", "ART", "NN", "APPR", "NE", "$,"], "meter": "--+--+-+-+", "measure": "anapaest.di.plus"}, "line.3": {"text": "Bis ihnen allen allm\u00e4hlich klar,", "tokens": ["Bis", "ih\u00b7nen", "al\u00b7len", "all\u00b7m\u00e4h\u00b7lich", "klar", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "PIAT", "ADJD", "ADJD", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Da\u00df der da wirklich Thies Thie\u00dfen war. \u2013", "tokens": ["Da\u00df", "der", "da", "wirk\u00b7lich", "Thies", "Thie\u00b7\u00dfen", "war", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "ART", "ADV", "ADJD", "NN", "NN", "VAFIN", "$.", "$("], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.24": {"line.1": {"text": "Der Hansen war tot, von keinem vermi\u00dft,", "tokens": ["Der", "Han\u00b7sen", "war", "tot", ",", "von", "kei\u00b7nem", "ver\u00b7mi\u00dft", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "$,", "APPR", "PIS", "VVPP", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Ein S\u00e4ufer war er und schlechter Christ.", "tokens": ["Ein", "S\u00e4u\u00b7fer", "war", "er", "und", "schlech\u00b7ter", "Christ", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "KON", "ADJA", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Aber der Thie\u00dfen, ein Kerl ist er doch!", "tokens": ["A\u00b7ber", "der", "Thie\u00b7\u00dfen", ",", "ein", "Kerl", "ist", "er", "doch", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "ART", "NN", "VAFIN", "PPER", "ADV", "$."], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.4": {"text": "Und die Ose, gibts eine Bravere noch?", "tokens": ["Und", "die", "O\u00b7se", ",", "gibts", "ei\u00b7ne", "Bra\u00b7ve\u00b7re", "noch", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "VVFIN", "ART", "NN", "ADV", "$."], "meter": "--+--+--+-+", "measure": "anapaest.tri.plus"}}, "stanza.25": {"line.1": {"text": "Alle die Jahre in Elend und Not", "tokens": ["Al\u00b7le", "die", "Jah\u00b7re", "in", "E\u00b7lend", "und", "Not"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PIS", "ART", "NN", "APPR", "NN", "KON", "NN"], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.2": {"text": "Teilte sie ihr Hungerbrot", "tokens": ["Teil\u00b7te", "sie", "ihr", "Hun\u00b7ger\u00b7brot"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Treulich ihm mit. Und jetzt weinte sie da", "tokens": ["Treu\u00b7lich", "ihm", "mit", ".", "Und", "jetzt", "wein\u00b7te", "sie", "da"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NE", "PPER", "PTKVZ", "$.", "KON", "ADV", "VVFIN", "PPER", "ADV"], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.4": {"text": "An seinem Hals. Es ging allen nah.", "tokens": ["An", "sei\u00b7nem", "Hals", ".", "Es", "ging", "al\u00b7len", "nah", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$.", "PPER", "VVFIN", "PIAT", "ADJD", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.26": {"line.1": {"text": "Sie kauten und spuckten und sahen sich an", "tokens": ["Sie", "kau\u00b7ten", "und", "spuck\u00b7ten", "und", "sa\u00b7hen", "sich", "an"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "KON", "VVFIN", "PRF", "APPR"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "Und schoben sich sacht an Thie\u00dfen heran", "tokens": ["Und", "scho\u00b7ben", "sich", "sacht", "an", "Thie\u00b7\u00dfen", "he\u00b7ran"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PRF", "ADJD", "APPR", "NN", "PTKVZ"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Und brummten und sch\u00fcttelten ihm die Hand.", "tokens": ["Und", "brumm\u00b7ten", "und", "sch\u00fct\u00b7tel\u00b7ten", "ihm", "die", "Hand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "KON", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Das war ihr Gericht. Und so blieb er im Land.", "tokens": ["Das", "war", "ihr", "Ge\u00b7richt", ".", "Und", "so", "blieb", "er", "im", "Land", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPOSAT", "NN", "$.", "KON", "ADV", "VVFIN", "PPER", "APPRART", "NN", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}}}}}