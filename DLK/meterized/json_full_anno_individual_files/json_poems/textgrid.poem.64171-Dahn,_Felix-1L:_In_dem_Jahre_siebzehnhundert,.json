{"textgrid.poem.64171": {"metadata": {"author": {"name": "Dahn, Felix", "birth": "N.A.", "death": "N.A."}, "title": "1L: In dem Jahre siebzehnhundert,", "genre": "verse", "period": "N.A.", "pub_year": 1873, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "In dem Jahre siebzehnhundert,", "tokens": ["In", "dem", "Jah\u00b7re", "sieb\u00b7zehn\u00b7hun\u00b7dert", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Vierundzwanzig Jahre z\u00e4hlend,", "tokens": ["Vie\u00b7rund\u00b7zwan\u00b7zig", "Jah\u00b7re", "z\u00e4h\u00b7lend", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["CARD", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Ausstudiert zu Salamanca", "tokens": ["Aus\u00b7stu\u00b7diert", "zu", "Sa\u00b7la\u00b7man\u00b7ca"], "token_info": ["word", "word", "word"], "pos": ["VVPP", "APPR", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Hat Alfonso de Vidal. \u2013", "tokens": ["Hat", "Al\u00b7fon\u00b7so", "de", "Vi\u00b7dal", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["VAFIN", "NE", "NE", "NE", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Oheims Muntschaft ist zu Ende:", "tokens": ["O\u00b7heims", "Munt\u00b7schaft", "ist", "zu", "En\u00b7de", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "VAFIN", "APPR", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und zur\u00fcck ins Schlo\u00df der V\u00e4ter", "tokens": ["Und", "zu\u00b7r\u00fcck", "ins", "Schlo\u00df", "der", "V\u00e4\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "APPRART", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "An dem blauen Manzanares", "tokens": ["An", "dem", "blau\u00b7en", "Man\u00b7za\u00b7na\u00b7res"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Kehrt er als sein eigner Herr.", "tokens": ["Kehrt", "er", "als", "sein", "eig\u00b7ner", "Herr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "KOUS", "PPOSAT", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Aber vor dem Scheiden will er", "tokens": ["A\u00b7ber", "vor", "dem", "Schei\u00b7den", "will", "er"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "VMFIN", "PPER"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Noch das Abenteuer kr\u00f6nen,", "tokens": ["Noch", "das", "A\u00b7bent\u00b7eu\u00b7er", "kr\u00f6\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Das geheimnisvoll schon lang' ihm", "tokens": ["Das", "ge\u00b7heim\u00b7nis\u00b7voll", "schon", "lang'", "ihm"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "ADV", "ADV", "PPER"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Aus dem \u00bbHaus der Sch\u00f6nen\u00ab winkt.", "tokens": ["Aus", "dem", "\u00bb", "Haus", "der", "Sch\u00f6\u00b7nen", "\u00ab", "winkt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "ART", "$(", "NN", "ART", "NN", "$(", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "\u00bbhaus der Sch\u00f6nen\u00ab hei\u00dft die Villa,", "tokens": ["\u00bb", "haus", "der", "Sch\u00f6\u00b7nen", "\u00ab", "hei\u00dft", "die", "Vil\u00b7la", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "ART", "NN", "$(", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Lauschend in Granatenb\u00fcschen,", "tokens": ["Lau\u00b7schend", "in", "Gra\u00b7na\u00b7ten\u00b7b\u00fc\u00b7schen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "NN", "$,"], "meter": "+-+++-+-", "measure": "unknown.measure.penta"}, "line.3": {"text": "Daran t\u00e4glich die Studenten", "tokens": ["Da\u00b7ran", "t\u00e4g\u00b7lich", "die", "Stu\u00b7den\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["PAV", "ADJD", "ART", "NN"], "meter": "--+--+--", "measure": "anapaest.di.plus"}, "line.4": {"text": "Gehn vor\u00fcber ins Kolleg.", "tokens": ["Gehn", "vor\u00b7\u00fc\u00b7ber", "ins", "Kol\u00b7leg", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "APPRART", "NN", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}}, "stanza.5": {"line.1": {"text": "\u00bbhaus der Dreie\u00ab: denn es wohnen \u2013", "tokens": ["\u00bb", "haus", "der", "Drei\u00b7e", "\u00ab", ":", "denn", "es", "woh\u00b7nen", "\u2013"], "token_info": ["punct", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "ART", "NN", "$(", "$.", "KON", "PPER", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Die Studenten wissen's! \u2013 drinnen", "tokens": ["Die", "Stu\u00b7den\u00b7ten", "wis\u00b7sen's", "!", "\u2013", "drin\u00b7nen"], "token_info": ["word", "word", "word", "punct", "punct", "word"], "pos": ["ART", "NN", "VVFIN", "$.", "$(", "ADV"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Eine Tante und zwei Nichten: \u2013", "tokens": ["Ei\u00b7ne", "Tan\u00b7te", "und", "zwei", "Nich\u00b7ten", ":", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "KON", "CARD", "NN", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Alle drei bezaubernd sch\u00f6n!", "tokens": ["Al\u00b7le", "drei", "be\u00b7zau\u00b7bernd", "sch\u00f6n", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "CARD", "VVPP", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Donna Laura hei\u00dft die Tante:", "tokens": ["Don\u00b7na", "Lau\u00b7ra", "hei\u00dft", "die", "Tan\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Junge Witwe, feurig, \u00fcppig,", "tokens": ["Jun\u00b7ge", "Wit\u00b7we", ",", "feu\u00b7rig", ",", "\u00fcp\u00b7pig", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ADJA", "NN", "$,", "ADJD", "$,", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Schwarzgelockt: da\u00df sie zu mager, \u2013", "tokens": ["Schwarz\u00b7ge\u00b7lockt", ":", "da\u00df", "sie", "zu", "ma\u00b7ger", ",", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "$.", "KOUS", "PPER", "PTKA", "ADJD", "$,", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Selbst der Neid behauptet's nicht.", "tokens": ["Selbst", "der", "Neid", "be\u00b7haup\u00b7tet's", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVFIN", "PTKNEG", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Braune Z\u00f6pfe tr\u00e4gt Ximene,", "tokens": ["Brau\u00b7ne", "Z\u00f6p\u00b7fe", "tr\u00e4gt", "Xi\u00b7me\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "VVFIN", "NE", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Rote Flechten Donna Sancha:", "tokens": ["Ro\u00b7te", "Flech\u00b7ten", "Don\u00b7na", "San\u00b7cha", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "NE", "NE", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Ob die Tante, ob die Nichten,", "tokens": ["Ob", "die", "Tan\u00b7te", ",", "ob", "die", "Nich\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "$,", "KOUS", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Zwei Gemester disputierten", "tokens": ["Zwei", "Ge\u00b7mes\u00b7ter", "dis\u00b7pu\u00b7tier\u00b7ten"], "token_info": ["word", "word", "word"], "pos": ["CARD", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Die Studenten Salamancas", "tokens": ["Die", "Stu\u00b7den\u00b7ten", "Sa\u00b7la\u00b7man\u00b7cas"], "token_info": ["word", "word", "word"], "pos": ["ART", "NN", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Eifriger um diese Frage,", "tokens": ["Eif\u00b7ri\u00b7ger", "um", "die\u00b7se", "Fra\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PDAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Als um Aristoteles.", "tokens": ["Als", "um", "A\u00b7ris\u00b7to\u00b7te\u00b7les", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "NE", "$."], "meter": "+-+-+--", "measure": "unknown.measure.tri"}}, "stanza.9": {"line.1": {"text": "Und so oft Alfons vor\u00fcber", "tokens": ["Und", "so", "oft", "Al\u00b7fons", "vor\u00b7\u00fc\u00b7ber"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "ADV", "NE", "PTKVZ"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Schritt den gr\u00fcnen Gitterl\u00e4den,", "tokens": ["Schritt", "den", "gr\u00fc\u00b7nen", "Git\u00b7ter\u00b7l\u00e4\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "War es Morgens, war es Abends, \u2013", "tokens": ["War", "es", "Mor\u00b7gens", ",", "war", "es", "A\u00b7bends", ",", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["VAFIN", "PPER", "ADV", "$,", "VAFIN", "PPER", "NN", "$,", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Eine Blume glitt herab.", "tokens": ["Ei\u00b7ne", "Blu\u00b7me", "glitt", "her\u00b7ab", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "(daran war nun nichts Besondres:", "tokens": ["(", "da\u00b7ran", "war", "nun", "nichts", "Be\u00b7sond\u00b7res", ":"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PAV", "VAFIN", "ADV", "PIS", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Weil Alfonso, wie wir sehen", "tokens": ["Weil", "Al\u00b7fon\u00b7so", ",", "wie", "wir", "se\u00b7hen"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "NE", "$,", "PWAV", "PPER", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Werden, wie in anderm Muster,", "tokens": ["Wer\u00b7den", ",", "wie", "in", "an\u00b7derm", "Mus\u00b7ter", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "$,", "PWAV", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Sch\u00f6n von Wuchs und Antlitz war.)", "tokens": ["Sch\u00f6n", "von", "Wuchs", "und", "Ant\u00b7litz", "war", ".", ")"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "APPR", "NN", "KON", "NN", "VAFIN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Aber welche von den dreien", "tokens": ["A\u00b7ber", "wel\u00b7che", "von", "den", "drei\u00b7en"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PWAT", "APPR", "ART", "CARD"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Lohnt den flei\u00dfigen Studenten", "tokens": ["Lohnt", "den", "flei\u00b7\u00dfi\u00b7gen", "Stu\u00b7den\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "ART", "ADJA", "NN"], "meter": "+-+--+--", "measure": "trochaic.tri.relaxed"}, "line.3": {"text": "So f\u00fcr seinen Flei\u00df allt\u00e4glich?", "tokens": ["So", "f\u00fcr", "sei\u00b7nen", "Flei\u00df", "all\u00b7t\u00e4g\u00b7lich", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPOSAT", "NN", "ADJD", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Dies ergr\u00fcnden mu\u00df Alfons.", "tokens": ["Dies", "er\u00b7gr\u00fcn\u00b7den", "mu\u00df", "Al\u00b7fons", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VVINF", "VMFIN", "NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Und er nimmt die treue Zither \u2013", "tokens": ["Und", "er", "nimmt", "die", "treu\u00b7e", "Zi\u00b7ther", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ART", "ADJA", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "(denn auch musikalisch war er,", "tokens": ["(", "denn", "auch", "mu\u00b7si\u00b7ka\u00b7lisch", "war", "er", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KON", "ADV", "ADJD", "VAFIN", "PPER", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Dieser reichbegabte J\u00fcngling)", "tokens": ["Die\u00b7ser", "reich\u00b7be\u00b7gab\u00b7te", "J\u00fcng\u00b7ling", ")"], "token_info": ["word", "word", "word", "punct"], "pos": ["PDAT", "ADJA", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und er singt im Mondenschein:", "tokens": ["Und", "er", "singt", "im", "Mon\u00b7den\u00b7schein", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "APPRART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "\u00bbedle Donna, \u00fcbermorgen", "tokens": ["\u00bb", "ed\u00b7le", "Don\u00b7na", ",", "\u00fc\u00b7ber\u00b7mor\u00b7gen"], "token_info": ["punct", "word", "word", "punct", "word"], "pos": ["$(", "ADJA", "NN", "$,", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Mu\u00df ich ziehn aus Salamanca:", "tokens": ["Mu\u00df", "ich", "ziehn", "aus", "Sa\u00b7la\u00b7man\u00b7ca", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "VVFIN", "APPR", "NE", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.3": {"text": "Darf ich morgen nacht es wagen, \u2013", "tokens": ["Darf", "ich", "mor\u00b7gen", "nacht", "es", "wa\u00b7gen", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VMFIN", "PPER", "ADV", "VVFIN", "PPER", "VVINF", "$,", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Eine Blume wirf herab!\u00ab", "tokens": ["Ei\u00b7ne", "Blu\u00b7me", "wirf", "her\u00b7ab", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "Und bevor der Ton verhallt ist,", "tokens": ["Und", "be\u00b7vor", "der", "Ton", "ver\u00b7hallt", "ist", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "VVPP", "VAFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sieh, schon \u00f6ffnen sich drei L\u00e4dchen,", "tokens": ["Sieh", ",", "schon", "\u00f6ff\u00b7nen", "sich", "drei", "L\u00e4d\u00b7chen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ADV", "VVFIN", "PRF", "CARD", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und es sinken ihm zu F\u00fc\u00dfen", "tokens": ["Und", "es", "sin\u00b7ken", "ihm", "zu", "F\u00fc\u00b7\u00dfen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "PPER", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wundersch\u00f6ner Blumen drei.", "tokens": ["Wun\u00b7der\u00b7sch\u00f6\u00b7ner", "Blu\u00b7men", "drei", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "CARD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.15": {"line.1": {"text": "Eine rabenschwarze Malve:", "tokens": ["Ei\u00b7ne", "ra\u00b7ben\u00b7schwar\u00b7ze", "Mal\u00b7ve", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "\u00bbdas ist von der Tante Laura!\u00ab", "tokens": ["\u00bb", "das", "ist", "von", "der", "Tan\u00b7te", "Lau\u00b7ra", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PDS", "VAFIN", "APPR", "ART", "NN", "NE", "$.", "$("], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Eine dunkelbraune Nelke:", "tokens": ["Ei\u00b7ne", "dun\u00b7kel\u00b7brau\u00b7ne", "Nel\u00b7ke", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "\u00bbvon Ximene dies, dem Br\u00e4unchen!\u00ab", "tokens": ["\u00bb", "von", "Xi\u00b7me\u00b7ne", "dies", ",", "dem", "Br\u00e4un\u00b7chen", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["$(", "APPR", "NE", "PDS", "$,", "ART", "NN", "$.", "$("], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Rotes R\u00f6slein: \u00bbSancha rot!\u00ab", "tokens": ["Ro\u00b7tes", "R\u00f6s\u00b7lein", ":", "\u00bb", "San\u00b7cha", "rot", "!", "\u00ab"], "token_info": ["word", "word", "punct", "punct", "word", "word", "punct", "punct"], "pos": ["ADJA", "NN", "$.", "$(", "NE", "ADJD", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.16": {"line.1": {"text": "Schwer betroffen steht der J\u00fcngling!", "tokens": ["Schwer", "be\u00b7trof\u00b7fen", "steht", "der", "J\u00fcng\u00b7ling", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVPP", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "\u00bballe drei? Wie soll das werden?\u00ab", "tokens": ["\u00bb", "al\u00b7le", "drei", "?", "Wie", "soll", "das", "wer\u00b7den", "?", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PIAT", "CARD", "$.", "PWAV", "VMFIN", "PDS", "VAFIN", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Auf den Hut steckt er die Malve,", "tokens": ["Auf", "den", "Hut", "steckt", "er", "die", "Mal\u00b7ve", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "An das Wams die Nelke braun!", "tokens": ["An", "das", "Wams", "die", "Nel\u00b7ke", "braun", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.17": {"line.1": {"text": "Doch wie er die rote Rose", "tokens": ["Doch", "wie", "er", "die", "ro\u00b7te", "Ro\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "PPER", "ART", "ADJA", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Mit der Hand f\u00fchrt an die Nase,", "tokens": ["Mit", "der", "Hand", "f\u00fchrt", "an", "die", "Na\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Sieh, aus schmaler Mauerritze", "tokens": ["Sieh", ",", "aus", "schma\u00b7ler", "Mau\u00b7er\u00b7rit\u00b7ze"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NE", "$,", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Eine vierte Blume f\u00e4llt.", "tokens": ["Ei\u00b7ne", "vier\u00b7te", "Blu\u00b7me", "f\u00e4llt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.18": {"line.1": {"text": "Eine kleine, wei\u00dfe Bl\u00fcte:", "tokens": ["Ei\u00b7ne", "klei\u00b7ne", ",", "wei\u00b7\u00dfe", "Bl\u00fc\u00b7te", ":"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Niemals sah er ihresgleichen,", "tokens": ["Nie\u00b7mals", "sah", "er", "ih\u00b7res\u00b7glei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und ein Duft entstr\u00f6mt der wei\u00dfen,", "tokens": ["Und", "ein", "Duft", "ent\u00b7str\u00f6mt", "der", "wei\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "ART", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wie er niemals ihn geno\u00df.", "tokens": ["Wie", "er", "nie\u00b7mals", "ihn", "ge\u00b7no\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "PPER", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.19": {"line.1": {"text": "An den Hut steckt zu der Malve", "tokens": ["An", "den", "Hut", "steckt", "zu", "der", "Mal\u00b7ve"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "VVFIN", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Er die Rose: nur der wei\u00dfen", "tokens": ["Er", "die", "Ro\u00b7se", ":", "nur", "der", "wei\u00b7\u00dfen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "ART", "NN", "$.", "ADV", "ART", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Bl\u00fcte Duft verlangt er sehnlich,", "tokens": ["Bl\u00fc\u00b7te", "Duft", "ver\u00b7langt", "er", "sehn\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVFIN", "PPER", "ADV", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Die er h\u00e4lt in seiner Hand.", "tokens": ["Die", "er", "h\u00e4lt", "in", "sei\u00b7ner", "Hand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.20": {"line.1": {"text": "In der n\u00e4chsten Nacht im runden", "tokens": ["In", "der", "n\u00e4chs\u00b7ten", "Nacht", "im", "run\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "APPRART", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Saale steht des ersten Stockwerks", "tokens": ["Saa\u00b7le", "steht", "des", "ers\u00b7ten", "Stock\u00b7werks"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Don Alfons, die seidne Leiter", "tokens": ["Don", "Al\u00b7fons", ",", "die", "seid\u00b7ne", "Lei\u00b7ter"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["NE", "NE", "$,", "PRELS", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Zieht er nach auf den Balkon.", "tokens": ["Zieht", "er", "nach", "auf", "den", "Bal\u00b7kon", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "APPR", "ART", "NN", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}}, "stanza.21": {"line.1": {"text": "(nun darf das euch nicht befremden,", "tokens": ["(", "nun", "darf", "das", "euch", "nicht", "be\u00b7frem\u00b7den", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VMFIN", "ART", "PPER", "PTKNEG", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Da\u00df er solch ein Werkzeug hatte:", "tokens": ["Da\u00df", "er", "solch", "ein", "Werk\u00b7zeug", "hat\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIAT", "ART", "NN", "VAFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Dies geh\u00f6rt in Salamanca", "tokens": ["Dies", "ge\u00b7h\u00f6rt", "in", "Sa\u00b7la\u00b7man\u00b7ca"], "token_info": ["word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "APPR", "NE"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.4": {"text": "Nun einmal zum Studium.)", "tokens": ["Nun", "ein\u00b7mal", "zum", "Stu\u00b7di\u00b7um", ".", ")"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "ADV", "APPRART", "NN", "$.", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.22": {"line.1": {"text": "Sieh, drei Schlafgem\u00e4cher m\u00fcnden", "tokens": ["Sieh", ",", "drei", "Schlaf\u00b7ge\u00b7m\u00e4\u00b7cher", "m\u00fcn\u00b7den"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NE", "$,", "CARD", "NN", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Mit den T\u00fcren in den Rundsaal,", "tokens": ["Mit", "den", "T\u00fc\u00b7ren", "in", "den", "Rund\u00b7saal", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Nur ein Vorhang deckt die \u00d6ffnung,", "tokens": ["Nur", "ein", "Vor\u00b7hang", "deckt", "die", "\u00d6ff\u00b7nung", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Welche zu der Treppe f\u00fchrt.", "tokens": ["Wel\u00b7che", "zu", "der", "Trep\u00b7pe", "f\u00fchrt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAT", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.23": {"line.1": {"text": "Aus der Ostt\u00fcr tritt in roten", "tokens": ["Aus", "der", "Ost\u00b7t\u00fcr", "tritt", "in", "ro\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "VVFIN", "APPR", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Flechten Sancha: \u2013 doch der Vorhang", "tokens": ["Flech\u00b7ten", "San\u00b7cha", ":", "\u2013", "doch", "der", "Vor\u00b7hang"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word"], "pos": ["NN", "NE", "$.", "$(", "ADV", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wallt so seltsam: \u2013 er verscheucht sie.", "tokens": ["Wallt", "so", "selt\u00b7sam", ":", "\u2013", "er", "ver\u00b7scheucht", "sie", "."], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADJD", "$.", "$(", "PPER", "VVFIN", "PPER", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Auf die Schwelle nun im West", "tokens": ["Auf", "die", "Schwel\u00b7le", "nun", "im", "West"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ADV", "APPRART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.24": {"line.1": {"text": "Schwebt die br\u00e4unliche Ximene:", "tokens": ["Schwebt", "die", "br\u00e4un\u00b7li\u00b7che", "Xi\u00b7me\u00b7ne", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Doch ein wei\u00dfes F\u00fc\u00dflein streckt sich", "tokens": ["Doch", "ein", "wei\u00b7\u00dfes", "F\u00fc\u00df\u00b7lein", "streckt", "sich"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN", "VVFIN", "PRF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Sch\u00fcchtern unterm Vorhang in den", "tokens": ["Sch\u00fcch\u00b7tern", "un\u00b7term", "Vor\u00b7hang", "in", "den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "APPRART", "NN", "APPR", "ART"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Rundsaal, und Ximene flieht.", "tokens": ["Rund\u00b7saal", ",", "und", "Xi\u00b7me\u00b7ne", "flieht", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KON", "NN", "VVFIN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.25": {"line.1": {"text": "Aus der S\u00fcdt\u00fcr st\u00fcrmt da gl\u00fchend", "tokens": ["Aus", "der", "S\u00fcd\u00b7t\u00fcr", "st\u00fcrmt", "da", "gl\u00fc\u00b7hend"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "VVFIN", "ADV", "ADJD"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Im Gewog der schwarzen Locken", "tokens": ["Im", "Ge\u00b7wog", "der", "schwar\u00b7zen", "Lo\u00b7cken"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Tante Laura: besser als die", "tokens": ["Tan\u00b7te", "Lau\u00b7ra", ":", "bes\u00b7ser", "als", "die"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["NN", "NE", "$.", "ADJD", "KOKOM", "ART"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "M\u00e4dchen wei\u00df sie, was sie will.", "tokens": ["M\u00e4d\u00b7chen", "wei\u00df", "sie", ",", "was", "sie", "will", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "$,", "PRELS", "PPER", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.26": {"line.1": {"text": "Mag der Vorhang wehn, das F\u00fc\u00dflein", "tokens": ["Mag", "der", "Vor\u00b7hang", "wehn", ",", "das", "F\u00fc\u00df\u00b7lein"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["VMFIN", "ART", "NN", "VVINF", "$,", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Kecker auf der Schwelle spielen,", "tokens": ["Ke\u00b7cker", "auf", "der", "Schwel\u00b7le", "spie\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Sie erschlie\u00dft ihm weit die Arme:", "tokens": ["Sie", "er\u00b7schlie\u00dft", "ihm", "weit", "die", "Ar\u00b7me", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADJD", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "\u00bb", "tokens": ["\u00bb"], "token_info": ["punct"], "pos": ["$("]}}, "stanza.27": {"line.1": {"text": "Aus dem Vorhang s\u00fc\u00df ein Stimmlein", "tokens": ["Aus", "dem", "Vor\u00b7hang", "s\u00fc\u00df", "ein", "Stimm\u00b7lein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "VVFIN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und die Tante fl\u00fcchtet z\u00fcrnend.", "tokens": ["Und", "die", "Tan\u00b7te", "fl\u00fcch\u00b7tet", "z\u00fcr\u00b7nend", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Aber aus dem Vorhang schwebt nun", "tokens": ["A\u00b7ber", "aus", "dem", "Vor\u00b7hang", "schwebt", "nun"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "VVFIN", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "In den Saal ein Zaubertraum:", "tokens": ["In", "den", "Saal", "ein", "Zau\u00b7ber\u00b7traum", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.28": {"line.1": {"text": "Ganz geh\u00fcllt in wei\u00dfe Schleier,", "tokens": ["Ganz", "ge\u00b7h\u00fcllt", "in", "wei\u00b7\u00dfe", "Schlei\u00b7er", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVPP", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Schwebt ein Kind von f\u00fcnfzehn Lenzen,", "tokens": ["Schwebt", "ein", "Kind", "von", "f\u00fcnf\u00b7zehn", "Len\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "APPR", "CARD", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Schlank und schmal und zart und zaghaft,", "tokens": ["Schlank", "und", "schmal", "und", "zart", "und", "zag\u00b7haft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "ADJD", "KON", "ADJD", "KON", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wie ein frommes Heil'genbild.", "tokens": ["Wie", "ein", "from\u00b7mes", "Heil'\u00b7gen\u00b7bild", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.29": {"line.1": {"text": "Lichte goldne Locken fluten", "tokens": ["Lich\u00b7te", "gold\u00b7ne", "Lo\u00b7cken", "flu\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "ADJA", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Auf den kaum entknospten Busen,", "tokens": ["Auf", "den", "kaum", "ent\u00b7knosp\u00b7ten", "Bu\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADV", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und Madonnenaugen schl\u00e4gt sie", "tokens": ["Und", "Ma\u00b7don\u00b7nen\u00b7au\u00b7gen", "schl\u00e4gt", "sie"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "NN", "VVFIN", "PPER"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.4": {"text": "Sch\u00e4mig zu dem J\u00fcngling auf.", "tokens": ["Sch\u00e4\u00b7mig", "zu", "dem", "J\u00fcng\u00b7ling", "auf", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.30": {"line.1": {"text": "Dieser sinkt aufs Knie vor Staunen,", "tokens": ["Die\u00b7ser", "sinkt", "aufs", "Knie", "vor", "Stau\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPRART", "NN", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "S\u00fc\u00dfe Glut durchrinnt ihn leise:", "tokens": ["S\u00fc\u00b7\u00dfe", "Glut", "durch\u00b7rinnt", "ihn", "lei\u00b7se", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVFIN", "PPER", "ADJD", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "\u00bbsprich, wer bist du? Und wie hei\u00dft du?\u00ab", "tokens": ["\u00bb", "sprich", ",", "wer", "bist", "du", "?", "Und", "wie", "hei\u00dft", "du", "?", "\u00ab"], "token_info": ["punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADJD", "$,", "PWS", "VAFIN", "PPER", "$.", "KON", "PWAV", "VVFIN", "PPER", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "\u00bbach, Maria bin ich nur,", "tokens": ["\u00bb", "ach", ",", "Ma\u00b7ria", "bin", "ich", "nur", ","], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ITJ", "$,", "NE", "VAFIN", "PPER", "ADV", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.31": {"line.1": {"text": "Bin das B\u00e4slein aus Asturien.", "tokens": ["Bin", "das", "B\u00e4s\u00b7lein", "aus", "As\u00b7tu\u00b7ri\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "APPR", "NE", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Tante haben und Kusinen", "tokens": ["Tan\u00b7te", "ha\u00b7ben", "und", "Ku\u00b7si\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "VAFIN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Immer mich versteckt gehalten,", "tokens": ["Im\u00b7mer", "mich", "ver\u00b7steckt", "ge\u00b7hal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VVFIN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wohl weil sie sich sch\u00e4mten mein.", "tokens": ["Wohl", "weil", "sie", "sich", "sch\u00e4m\u00b7ten", "mein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PPER", "PRF", "VVFIN", "PPOSAT", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.32": {"line.1": {"text": "Wann sie aus den L\u00e4den gr\u00fc\u00dften", "tokens": ["Wann", "sie", "aus", "den", "L\u00e4\u00b7den", "gr\u00fc\u00df\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "APPR", "ART", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Alle Herrn von Salamanca,", "tokens": ["Al\u00b7le", "Herrn", "von", "Sa\u00b7la\u00b7man\u00b7ca", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "APPR", "NE", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.3": {"text": "Ich \u2013 aus meiner Mauerritze \u2013", "tokens": ["Ich", "\u2013", "aus", "mei\u00b7ner", "Mau\u00b7er\u00b7rit\u00b7ze", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "$(", "APPR", "PPOSAT", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Sah verstohlen nur nach Euch!", "tokens": ["Sah", "ver\u00b7stoh\u00b7len", "nur", "nach", "Euch", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADV", "APPR", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.33": {"line.1": {"text": "In den Bergen von Asturien", "tokens": ["In", "den", "Ber\u00b7gen", "von", "As\u00b7tu\u00b7ri\u00b7en"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "APPR", "NE"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Lernt' ich K\u00fcnste nicht, noch Feinheit,", "tokens": ["Lernt'", "ich", "K\u00fcns\u00b7te", "nicht", ",", "noch", "Fein\u00b7heit", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "PTKNEG", "$,", "ADV", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und ich wei\u00df nicht viel zu sagen \u2013:", "tokens": ["Und", "ich", "wei\u00df", "nicht", "viel", "zu", "sa\u00b7gen", "\u2013", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "PPER", "VVFIN", "PTKNEG", "ADV", "PTKZU", "VVINF", "$(", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Doch ich sterbe, scheidest du!\u00ab", "tokens": ["Doch", "ich", "ster\u00b7be", ",", "schei\u00b7dest", "du", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["KON", "PPER", "VVFIN", "$,", "VVFIN", "PPER", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.34": {"line.1": {"text": "Auf vom Boden sprang Alfonso,", "tokens": ["Auf", "vom", "Bo\u00b7den", "sprang", "Al\u00b7fon\u00b7so", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "APPRART", "NN", "VVFIN", "NE", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "An die Brust ri\u00df er die Blonde:", "tokens": ["An", "die", "Brust", "ri\u00df", "er", "die", "Blon\u00b7de", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "\u00bbo, Maria! Wei\u00dfe Blume!", "tokens": ["\u00bb", "o", ",", "Ma\u00b7ria", "!", "Wei\u00b7\u00dfe", "Blu\u00b7me", "!"], "token_info": ["punct", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["$(", "FM", "$,", "NE", "$.", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Ewig, ewig bist du mein!\u00ab", "tokens": ["E\u00b7wig", ",", "e\u00b7wig", "bist", "du", "mein", "!", "\u00ab"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADJD", "$,", "ADJD", "VAFIN", "PPER", "PPOSAT", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.35": {"line.1": {"text": "Und herab die seidne Leiter", "tokens": ["Und", "her\u00b7ab", "die", "seid\u00b7ne", "Lei\u00b7ter"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Trug er die versch\u00e4mte Kleine,", "tokens": ["Trug", "er", "die", "ver\u00b7sch\u00e4m\u00b7te", "Klei\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und er hob sie auf sein R\u00f6\u00dflein", "tokens": ["Und", "er", "hob", "sie", "auf", "sein", "R\u00f6\u00df\u00b7lein"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "PPER", "APPR", "PPOSAT", "NN"], "meter": "--+---+-", "measure": "anapaest.init"}, "line.4": {"text": "Im Geb\u00fcsche von Jasmin.", "tokens": ["Im", "Ge\u00b7b\u00fc\u00b7sche", "von", "Jas\u00b7min", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPR", "NE", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}}, "stanza.36": {"line.1": {"text": "\u00bbach, wohin, wohin, Geliebter?\u00ab", "tokens": ["\u00bb", "ach", ",", "wo\u00b7hin", ",", "wo\u00b7hin", ",", "Ge\u00b7lieb\u00b7ter", "?", "\u00ab"], "token_info": ["punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "punct"], "pos": ["$(", "ITJ", "$,", "PWAV", "$,", "PWAV", "$,", "NN", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "\u00bbauf mein Schlo\u00df am Manzanares!\u00ab", "tokens": ["\u00bb", "auf", "mein", "Schlo\u00df", "am", "Man\u00b7za\u00b7na\u00b7res", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "APPR", "PPOSAT", "NN", "APPRART", "NN", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Doch am Kloster in der Vorstadt", "tokens": ["Doch", "am", "Klos\u00b7ter", "in", "der", "Vor\u00b7stadt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPRART", "NN", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Hielt er an. Nun sagt: weshalb?", "tokens": ["Hielt", "er", "an", ".", "Nun", "sagt", ":", "we\u00b7shalb", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKVZ", "$.", "ADV", "VVFIN", "$.", "PWAV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.37": {"line.1": {"text": "Er hielt an vor jenem Kloster,", "tokens": ["Er", "hielt", "an", "vor", "je\u00b7nem", "Klos\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "APPR", "PDAT", "NN", "$,"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.2": {"text": "Um sich schleunigst traun zu lassen,", "tokens": ["Um", "sich", "schleu\u00b7nigst", "traun", "zu", "las\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PRF", "ADJD", "VVINF", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Weil er nicht nur musikalisch,", "tokens": ["Weil", "er", "nicht", "nur", "mu\u00b7si\u00b7ka\u00b7lisch", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "ADV", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Sondern auch moralisch war.", "tokens": ["Son\u00b7dern", "auch", "mo\u00b7ra\u00b7lisch", "war", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJD", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.38": {"line.1": {"text": "In dem Jahre siebzehnhundert,", "tokens": ["In", "dem", "Jah\u00b7re", "sieb\u00b7zehn\u00b7hun\u00b7dert", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Vierundzwanzig Jahre z\u00e4hlend,", "tokens": ["Vie\u00b7rund\u00b7zwan\u00b7zig", "Jah\u00b7re", "z\u00e4h\u00b7lend", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["CARD", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Ausstudiert zu Salamanca", "tokens": ["Aus\u00b7stu\u00b7diert", "zu", "Sa\u00b7la\u00b7man\u00b7ca"], "token_info": ["word", "word", "word"], "pos": ["VVPP", "APPR", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Hat Alfonso de Vidal. \u2013", "tokens": ["Hat", "Al\u00b7fon\u00b7so", "de", "Vi\u00b7dal", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["VAFIN", "NE", "NE", "NE", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.39": {"line.1": {"text": "Oheims Muntschaft ist zu Ende:", "tokens": ["O\u00b7heims", "Munt\u00b7schaft", "ist", "zu", "En\u00b7de", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "VAFIN", "APPR", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und zur\u00fcck ins Schlo\u00df der V\u00e4ter", "tokens": ["Und", "zu\u00b7r\u00fcck", "ins", "Schlo\u00df", "der", "V\u00e4\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "APPRART", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "An dem blauen Manzanares", "tokens": ["An", "dem", "blau\u00b7en", "Man\u00b7za\u00b7na\u00b7res"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Kehrt er als sein eigner Herr.", "tokens": ["Kehrt", "er", "als", "sein", "eig\u00b7ner", "Herr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "KOUS", "PPOSAT", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.40": {"line.1": {"text": "Aber vor dem Scheiden will er", "tokens": ["A\u00b7ber", "vor", "dem", "Schei\u00b7den", "will", "er"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "VMFIN", "PPER"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Noch das Abenteuer kr\u00f6nen,", "tokens": ["Noch", "das", "A\u00b7bent\u00b7eu\u00b7er", "kr\u00f6\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Das geheimnisvoll schon lang' ihm", "tokens": ["Das", "ge\u00b7heim\u00b7nis\u00b7voll", "schon", "lang'", "ihm"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "ADV", "ADV", "PPER"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Aus dem \u00bbHaus der Sch\u00f6nen\u00ab winkt.", "tokens": ["Aus", "dem", "\u00bb", "Haus", "der", "Sch\u00f6\u00b7nen", "\u00ab", "winkt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "ART", "$(", "NN", "ART", "NN", "$(", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.41": {"line.1": {"text": "\u00bbhaus der Sch\u00f6nen\u00ab hei\u00dft die Villa,", "tokens": ["\u00bb", "haus", "der", "Sch\u00f6\u00b7nen", "\u00ab", "hei\u00dft", "die", "Vil\u00b7la", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "ART", "NN", "$(", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Lauschend in Granatenb\u00fcschen,", "tokens": ["Lau\u00b7schend", "in", "Gra\u00b7na\u00b7ten\u00b7b\u00fc\u00b7schen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "NN", "$,"], "meter": "+-+++-+-", "measure": "unknown.measure.penta"}, "line.3": {"text": "Daran t\u00e4glich die Studenten", "tokens": ["Da\u00b7ran", "t\u00e4g\u00b7lich", "die", "Stu\u00b7den\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["PAV", "ADJD", "ART", "NN"], "meter": "--+--+--", "measure": "anapaest.di.plus"}, "line.4": {"text": "Gehn vor\u00fcber ins Kolleg.", "tokens": ["Gehn", "vor\u00b7\u00fc\u00b7ber", "ins", "Kol\u00b7leg", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "APPRART", "NN", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}}, "stanza.42": {"line.1": {"text": "\u00bbhaus der Dreie\u00ab: denn es wohnen \u2013", "tokens": ["\u00bb", "haus", "der", "Drei\u00b7e", "\u00ab", ":", "denn", "es", "woh\u00b7nen", "\u2013"], "token_info": ["punct", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "ART", "NN", "$(", "$.", "KON", "PPER", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Die Studenten wissen's! \u2013 drinnen", "tokens": ["Die", "Stu\u00b7den\u00b7ten", "wis\u00b7sen's", "!", "\u2013", "drin\u00b7nen"], "token_info": ["word", "word", "word", "punct", "punct", "word"], "pos": ["ART", "NN", "VVFIN", "$.", "$(", "ADV"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Eine Tante und zwei Nichten: \u2013", "tokens": ["Ei\u00b7ne", "Tan\u00b7te", "und", "zwei", "Nich\u00b7ten", ":", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "KON", "CARD", "NN", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Alle drei bezaubernd sch\u00f6n!", "tokens": ["Al\u00b7le", "drei", "be\u00b7zau\u00b7bernd", "sch\u00f6n", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "CARD", "VVPP", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.43": {"line.1": {"text": "Donna Laura hei\u00dft die Tante:", "tokens": ["Don\u00b7na", "Lau\u00b7ra", "hei\u00dft", "die", "Tan\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Junge Witwe, feurig, \u00fcppig,", "tokens": ["Jun\u00b7ge", "Wit\u00b7we", ",", "feu\u00b7rig", ",", "\u00fcp\u00b7pig", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ADJA", "NN", "$,", "ADJD", "$,", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Schwarzgelockt: da\u00df sie zu mager, \u2013", "tokens": ["Schwarz\u00b7ge\u00b7lockt", ":", "da\u00df", "sie", "zu", "ma\u00b7ger", ",", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "$.", "KOUS", "PPER", "PTKA", "ADJD", "$,", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Selbst der Neid behauptet's nicht.", "tokens": ["Selbst", "der", "Neid", "be\u00b7haup\u00b7tet's", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVFIN", "PTKNEG", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.44": {"line.1": {"text": "Braune Z\u00f6pfe tr\u00e4gt Ximene,", "tokens": ["Brau\u00b7ne", "Z\u00f6p\u00b7fe", "tr\u00e4gt", "Xi\u00b7me\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "VVFIN", "NE", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Rote Flechten Donna Sancha:", "tokens": ["Ro\u00b7te", "Flech\u00b7ten", "Don\u00b7na", "San\u00b7cha", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "NE", "NE", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Ob die Tante, ob die Nichten,", "tokens": ["Ob", "die", "Tan\u00b7te", ",", "ob", "die", "Nich\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "$,", "KOUS", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.45": {"line.1": {"text": "Zwei Gemester disputierten", "tokens": ["Zwei", "Ge\u00b7mes\u00b7ter", "dis\u00b7pu\u00b7tier\u00b7ten"], "token_info": ["word", "word", "word"], "pos": ["CARD", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Die Studenten Salamancas", "tokens": ["Die", "Stu\u00b7den\u00b7ten", "Sa\u00b7la\u00b7man\u00b7cas"], "token_info": ["word", "word", "word"], "pos": ["ART", "NN", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Eifriger um diese Frage,", "tokens": ["Eif\u00b7ri\u00b7ger", "um", "die\u00b7se", "Fra\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PDAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Als um Aristoteles.", "tokens": ["Als", "um", "A\u00b7ris\u00b7to\u00b7te\u00b7les", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "NE", "$."], "meter": "+-+-+--", "measure": "unknown.measure.tri"}}, "stanza.46": {"line.1": {"text": "Und so oft Alfons vor\u00fcber", "tokens": ["Und", "so", "oft", "Al\u00b7fons", "vor\u00b7\u00fc\u00b7ber"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "ADV", "NE", "PTKVZ"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Schritt den gr\u00fcnen Gitterl\u00e4den,", "tokens": ["Schritt", "den", "gr\u00fc\u00b7nen", "Git\u00b7ter\u00b7l\u00e4\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "War es Morgens, war es Abends, \u2013", "tokens": ["War", "es", "Mor\u00b7gens", ",", "war", "es", "A\u00b7bends", ",", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["VAFIN", "PPER", "ADV", "$,", "VAFIN", "PPER", "NN", "$,", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Eine Blume glitt herab.", "tokens": ["Ei\u00b7ne", "Blu\u00b7me", "glitt", "her\u00b7ab", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.47": {"line.1": {"text": "(daran war nun nichts Besondres:", "tokens": ["(", "da\u00b7ran", "war", "nun", "nichts", "Be\u00b7sond\u00b7res", ":"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PAV", "VAFIN", "ADV", "PIS", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Weil Alfonso, wie wir sehen", "tokens": ["Weil", "Al\u00b7fon\u00b7so", ",", "wie", "wir", "se\u00b7hen"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "NE", "$,", "PWAV", "PPER", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Werden, wie in anderm Muster,", "tokens": ["Wer\u00b7den", ",", "wie", "in", "an\u00b7derm", "Mus\u00b7ter", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "$,", "PWAV", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Sch\u00f6n von Wuchs und Antlitz war.)", "tokens": ["Sch\u00f6n", "von", "Wuchs", "und", "Ant\u00b7litz", "war", ".", ")"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "APPR", "NN", "KON", "NN", "VAFIN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.48": {"line.1": {"text": "Aber welche von den dreien", "tokens": ["A\u00b7ber", "wel\u00b7che", "von", "den", "drei\u00b7en"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PWAT", "APPR", "ART", "CARD"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Lohnt den flei\u00dfigen Studenten", "tokens": ["Lohnt", "den", "flei\u00b7\u00dfi\u00b7gen", "Stu\u00b7den\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "ART", "ADJA", "NN"], "meter": "+-+--+--", "measure": "trochaic.tri.relaxed"}, "line.3": {"text": "So f\u00fcr seinen Flei\u00df allt\u00e4glich?", "tokens": ["So", "f\u00fcr", "sei\u00b7nen", "Flei\u00df", "all\u00b7t\u00e4g\u00b7lich", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPOSAT", "NN", "ADJD", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Dies ergr\u00fcnden mu\u00df Alfons.", "tokens": ["Dies", "er\u00b7gr\u00fcn\u00b7den", "mu\u00df", "Al\u00b7fons", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VVINF", "VMFIN", "NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.49": {"line.1": {"text": "Und er nimmt die treue Zither \u2013", "tokens": ["Und", "er", "nimmt", "die", "treu\u00b7e", "Zi\u00b7ther", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ART", "ADJA", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "(denn auch musikalisch war er,", "tokens": ["(", "denn", "auch", "mu\u00b7si\u00b7ka\u00b7lisch", "war", "er", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KON", "ADV", "ADJD", "VAFIN", "PPER", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Dieser reichbegabte J\u00fcngling)", "tokens": ["Die\u00b7ser", "reich\u00b7be\u00b7gab\u00b7te", "J\u00fcng\u00b7ling", ")"], "token_info": ["word", "word", "word", "punct"], "pos": ["PDAT", "ADJA", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und er singt im Mondenschein:", "tokens": ["Und", "er", "singt", "im", "Mon\u00b7den\u00b7schein", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "APPRART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.50": {"line.1": {"text": "\u00bbedle Donna, \u00fcbermorgen", "tokens": ["\u00bb", "ed\u00b7le", "Don\u00b7na", ",", "\u00fc\u00b7ber\u00b7mor\u00b7gen"], "token_info": ["punct", "word", "word", "punct", "word"], "pos": ["$(", "ADJA", "NN", "$,", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Mu\u00df ich ziehn aus Salamanca:", "tokens": ["Mu\u00df", "ich", "ziehn", "aus", "Sa\u00b7la\u00b7man\u00b7ca", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "VVFIN", "APPR", "NE", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.3": {"text": "Darf ich morgen nacht es wagen, \u2013", "tokens": ["Darf", "ich", "mor\u00b7gen", "nacht", "es", "wa\u00b7gen", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VMFIN", "PPER", "ADV", "VVFIN", "PPER", "VVINF", "$,", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Eine Blume wirf herab!\u00ab", "tokens": ["Ei\u00b7ne", "Blu\u00b7me", "wirf", "her\u00b7ab", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.51": {"line.1": {"text": "Und bevor der Ton verhallt ist,", "tokens": ["Und", "be\u00b7vor", "der", "Ton", "ver\u00b7hallt", "ist", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "VVPP", "VAFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sieh, schon \u00f6ffnen sich drei L\u00e4dchen,", "tokens": ["Sieh", ",", "schon", "\u00f6ff\u00b7nen", "sich", "drei", "L\u00e4d\u00b7chen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ADV", "VVFIN", "PRF", "CARD", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und es sinken ihm zu F\u00fc\u00dfen", "tokens": ["Und", "es", "sin\u00b7ken", "ihm", "zu", "F\u00fc\u00b7\u00dfen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "PPER", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wundersch\u00f6ner Blumen drei.", "tokens": ["Wun\u00b7der\u00b7sch\u00f6\u00b7ner", "Blu\u00b7men", "drei", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "CARD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.52": {"line.1": {"text": "Eine rabenschwarze Malve:", "tokens": ["Ei\u00b7ne", "ra\u00b7ben\u00b7schwar\u00b7ze", "Mal\u00b7ve", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "\u00bbdas ist von der Tante Laura!\u00ab", "tokens": ["\u00bb", "das", "ist", "von", "der", "Tan\u00b7te", "Lau\u00b7ra", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PDS", "VAFIN", "APPR", "ART", "NN", "NE", "$.", "$("], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Eine dunkelbraune Nelke:", "tokens": ["Ei\u00b7ne", "dun\u00b7kel\u00b7brau\u00b7ne", "Nel\u00b7ke", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "\u00bbvon Ximene dies, dem Br\u00e4unchen!\u00ab", "tokens": ["\u00bb", "von", "Xi\u00b7me\u00b7ne", "dies", ",", "dem", "Br\u00e4un\u00b7chen", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["$(", "APPR", "NE", "PDS", "$,", "ART", "NN", "$.", "$("], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Rotes R\u00f6slein: \u00bbSancha rot!\u00ab", "tokens": ["Ro\u00b7tes", "R\u00f6s\u00b7lein", ":", "\u00bb", "San\u00b7cha", "rot", "!", "\u00ab"], "token_info": ["word", "word", "punct", "punct", "word", "word", "punct", "punct"], "pos": ["ADJA", "NN", "$.", "$(", "NE", "ADJD", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.53": {"line.1": {"text": "Schwer betroffen steht der J\u00fcngling!", "tokens": ["Schwer", "be\u00b7trof\u00b7fen", "steht", "der", "J\u00fcng\u00b7ling", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVPP", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "\u00bballe drei? Wie soll das werden?\u00ab", "tokens": ["\u00bb", "al\u00b7le", "drei", "?", "Wie", "soll", "das", "wer\u00b7den", "?", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PIAT", "CARD", "$.", "PWAV", "VMFIN", "PDS", "VAFIN", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Auf den Hut steckt er die Malve,", "tokens": ["Auf", "den", "Hut", "steckt", "er", "die", "Mal\u00b7ve", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "An das Wams die Nelke braun!", "tokens": ["An", "das", "Wams", "die", "Nel\u00b7ke", "braun", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.54": {"line.1": {"text": "Doch wie er die rote Rose", "tokens": ["Doch", "wie", "er", "die", "ro\u00b7te", "Ro\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "PPER", "ART", "ADJA", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Mit der Hand f\u00fchrt an die Nase,", "tokens": ["Mit", "der", "Hand", "f\u00fchrt", "an", "die", "Na\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Sieh, aus schmaler Mauerritze", "tokens": ["Sieh", ",", "aus", "schma\u00b7ler", "Mau\u00b7er\u00b7rit\u00b7ze"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NE", "$,", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Eine vierte Blume f\u00e4llt.", "tokens": ["Ei\u00b7ne", "vier\u00b7te", "Blu\u00b7me", "f\u00e4llt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.55": {"line.1": {"text": "Eine kleine, wei\u00dfe Bl\u00fcte:", "tokens": ["Ei\u00b7ne", "klei\u00b7ne", ",", "wei\u00b7\u00dfe", "Bl\u00fc\u00b7te", ":"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Niemals sah er ihresgleichen,", "tokens": ["Nie\u00b7mals", "sah", "er", "ih\u00b7res\u00b7glei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und ein Duft entstr\u00f6mt der wei\u00dfen,", "tokens": ["Und", "ein", "Duft", "ent\u00b7str\u00f6mt", "der", "wei\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "ART", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wie er niemals ihn geno\u00df.", "tokens": ["Wie", "er", "nie\u00b7mals", "ihn", "ge\u00b7no\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "PPER", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.56": {"line.1": {"text": "An den Hut steckt zu der Malve", "tokens": ["An", "den", "Hut", "steckt", "zu", "der", "Mal\u00b7ve"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "VVFIN", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Er die Rose: nur der wei\u00dfen", "tokens": ["Er", "die", "Ro\u00b7se", ":", "nur", "der", "wei\u00b7\u00dfen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "ART", "NN", "$.", "ADV", "ART", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Bl\u00fcte Duft verlangt er sehnlich,", "tokens": ["Bl\u00fc\u00b7te", "Duft", "ver\u00b7langt", "er", "sehn\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVFIN", "PPER", "ADV", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Die er h\u00e4lt in seiner Hand.", "tokens": ["Die", "er", "h\u00e4lt", "in", "sei\u00b7ner", "Hand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.57": {"line.1": {"text": "In der n\u00e4chsten Nacht im runden", "tokens": ["In", "der", "n\u00e4chs\u00b7ten", "Nacht", "im", "run\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "APPRART", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Saale steht des ersten Stockwerks", "tokens": ["Saa\u00b7le", "steht", "des", "ers\u00b7ten", "Stock\u00b7werks"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Don Alfons, die seidne Leiter", "tokens": ["Don", "Al\u00b7fons", ",", "die", "seid\u00b7ne", "Lei\u00b7ter"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["NE", "NE", "$,", "PRELS", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Zieht er nach auf den Balkon.", "tokens": ["Zieht", "er", "nach", "auf", "den", "Bal\u00b7kon", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "APPR", "ART", "NN", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}}, "stanza.58": {"line.1": {"text": "(nun darf das euch nicht befremden,", "tokens": ["(", "nun", "darf", "das", "euch", "nicht", "be\u00b7frem\u00b7den", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VMFIN", "ART", "PPER", "PTKNEG", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Da\u00df er solch ein Werkzeug hatte:", "tokens": ["Da\u00df", "er", "solch", "ein", "Werk\u00b7zeug", "hat\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIAT", "ART", "NN", "VAFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Dies geh\u00f6rt in Salamanca", "tokens": ["Dies", "ge\u00b7h\u00f6rt", "in", "Sa\u00b7la\u00b7man\u00b7ca"], "token_info": ["word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "APPR", "NE"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.4": {"text": "Nun einmal zum Studium.)", "tokens": ["Nun", "ein\u00b7mal", "zum", "Stu\u00b7di\u00b7um", ".", ")"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "ADV", "APPRART", "NN", "$.", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.59": {"line.1": {"text": "Sieh, drei Schlafgem\u00e4cher m\u00fcnden", "tokens": ["Sieh", ",", "drei", "Schlaf\u00b7ge\u00b7m\u00e4\u00b7cher", "m\u00fcn\u00b7den"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NE", "$,", "CARD", "NN", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Mit den T\u00fcren in den Rundsaal,", "tokens": ["Mit", "den", "T\u00fc\u00b7ren", "in", "den", "Rund\u00b7saal", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Nur ein Vorhang deckt die \u00d6ffnung,", "tokens": ["Nur", "ein", "Vor\u00b7hang", "deckt", "die", "\u00d6ff\u00b7nung", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Welche zu der Treppe f\u00fchrt.", "tokens": ["Wel\u00b7che", "zu", "der", "Trep\u00b7pe", "f\u00fchrt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAT", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.60": {"line.1": {"text": "Aus der Ostt\u00fcr tritt in roten", "tokens": ["Aus", "der", "Ost\u00b7t\u00fcr", "tritt", "in", "ro\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "VVFIN", "APPR", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Flechten Sancha: \u2013 doch der Vorhang", "tokens": ["Flech\u00b7ten", "San\u00b7cha", ":", "\u2013", "doch", "der", "Vor\u00b7hang"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word"], "pos": ["NN", "NE", "$.", "$(", "ADV", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wallt so seltsam: \u2013 er verscheucht sie.", "tokens": ["Wallt", "so", "selt\u00b7sam", ":", "\u2013", "er", "ver\u00b7scheucht", "sie", "."], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADJD", "$.", "$(", "PPER", "VVFIN", "PPER", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Auf die Schwelle nun im West", "tokens": ["Auf", "die", "Schwel\u00b7le", "nun", "im", "West"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ADV", "APPRART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.61": {"line.1": {"text": "Schwebt die br\u00e4unliche Ximene:", "tokens": ["Schwebt", "die", "br\u00e4un\u00b7li\u00b7che", "Xi\u00b7me\u00b7ne", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Doch ein wei\u00dfes F\u00fc\u00dflein streckt sich", "tokens": ["Doch", "ein", "wei\u00b7\u00dfes", "F\u00fc\u00df\u00b7lein", "streckt", "sich"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN", "VVFIN", "PRF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Sch\u00fcchtern unterm Vorhang in den", "tokens": ["Sch\u00fcch\u00b7tern", "un\u00b7term", "Vor\u00b7hang", "in", "den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "APPRART", "NN", "APPR", "ART"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Rundsaal, und Ximene flieht.", "tokens": ["Rund\u00b7saal", ",", "und", "Xi\u00b7me\u00b7ne", "flieht", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KON", "NN", "VVFIN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.62": {"line.1": {"text": "Aus der S\u00fcdt\u00fcr st\u00fcrmt da gl\u00fchend", "tokens": ["Aus", "der", "S\u00fcd\u00b7t\u00fcr", "st\u00fcrmt", "da", "gl\u00fc\u00b7hend"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "VVFIN", "ADV", "ADJD"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Im Gewog der schwarzen Locken", "tokens": ["Im", "Ge\u00b7wog", "der", "schwar\u00b7zen", "Lo\u00b7cken"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Tante Laura: besser als die", "tokens": ["Tan\u00b7te", "Lau\u00b7ra", ":", "bes\u00b7ser", "als", "die"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["NN", "NE", "$.", "ADJD", "KOKOM", "ART"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "M\u00e4dchen wei\u00df sie, was sie will.", "tokens": ["M\u00e4d\u00b7chen", "wei\u00df", "sie", ",", "was", "sie", "will", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "$,", "PRELS", "PPER", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.63": {"line.1": {"text": "Mag der Vorhang wehn, das F\u00fc\u00dflein", "tokens": ["Mag", "der", "Vor\u00b7hang", "wehn", ",", "das", "F\u00fc\u00df\u00b7lein"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["VMFIN", "ART", "NN", "VVINF", "$,", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Kecker auf der Schwelle spielen,", "tokens": ["Ke\u00b7cker", "auf", "der", "Schwel\u00b7le", "spie\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Sie erschlie\u00dft ihm weit die Arme:", "tokens": ["Sie", "er\u00b7schlie\u00dft", "ihm", "weit", "die", "Ar\u00b7me", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADJD", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "\u00bb", "tokens": ["\u00bb"], "token_info": ["punct"], "pos": ["$("]}}, "stanza.64": {"line.1": {"text": "Aus dem Vorhang s\u00fc\u00df ein Stimmlein", "tokens": ["Aus", "dem", "Vor\u00b7hang", "s\u00fc\u00df", "ein", "Stimm\u00b7lein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "VVFIN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und die Tante fl\u00fcchtet z\u00fcrnend.", "tokens": ["Und", "die", "Tan\u00b7te", "fl\u00fcch\u00b7tet", "z\u00fcr\u00b7nend", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Aber aus dem Vorhang schwebt nun", "tokens": ["A\u00b7ber", "aus", "dem", "Vor\u00b7hang", "schwebt", "nun"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "VVFIN", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "In den Saal ein Zaubertraum:", "tokens": ["In", "den", "Saal", "ein", "Zau\u00b7ber\u00b7traum", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.65": {"line.1": {"text": "Ganz geh\u00fcllt in wei\u00dfe Schleier,", "tokens": ["Ganz", "ge\u00b7h\u00fcllt", "in", "wei\u00b7\u00dfe", "Schlei\u00b7er", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVPP", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Schwebt ein Kind von f\u00fcnfzehn Lenzen,", "tokens": ["Schwebt", "ein", "Kind", "von", "f\u00fcnf\u00b7zehn", "Len\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "APPR", "CARD", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Schlank und schmal und zart und zaghaft,", "tokens": ["Schlank", "und", "schmal", "und", "zart", "und", "zag\u00b7haft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "ADJD", "KON", "ADJD", "KON", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wie ein frommes Heil'genbild.", "tokens": ["Wie", "ein", "from\u00b7mes", "Heil'\u00b7gen\u00b7bild", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.66": {"line.1": {"text": "Lichte goldne Locken fluten", "tokens": ["Lich\u00b7te", "gold\u00b7ne", "Lo\u00b7cken", "flu\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "ADJA", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Auf den kaum entknospten Busen,", "tokens": ["Auf", "den", "kaum", "ent\u00b7knosp\u00b7ten", "Bu\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADV", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und Madonnenaugen schl\u00e4gt sie", "tokens": ["Und", "Ma\u00b7don\u00b7nen\u00b7au\u00b7gen", "schl\u00e4gt", "sie"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "NN", "VVFIN", "PPER"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.4": {"text": "Sch\u00e4mig zu dem J\u00fcngling auf.", "tokens": ["Sch\u00e4\u00b7mig", "zu", "dem", "J\u00fcng\u00b7ling", "auf", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.67": {"line.1": {"text": "Dieser sinkt aufs Knie vor Staunen,", "tokens": ["Die\u00b7ser", "sinkt", "aufs", "Knie", "vor", "Stau\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPRART", "NN", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "S\u00fc\u00dfe Glut durchrinnt ihn leise:", "tokens": ["S\u00fc\u00b7\u00dfe", "Glut", "durch\u00b7rinnt", "ihn", "lei\u00b7se", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVFIN", "PPER", "ADJD", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "\u00bbsprich, wer bist du? Und wie hei\u00dft du?\u00ab", "tokens": ["\u00bb", "sprich", ",", "wer", "bist", "du", "?", "Und", "wie", "hei\u00dft", "du", "?", "\u00ab"], "token_info": ["punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADJD", "$,", "PWS", "VAFIN", "PPER", "$.", "KON", "PWAV", "VVFIN", "PPER", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "\u00bbach, Maria bin ich nur,", "tokens": ["\u00bb", "ach", ",", "Ma\u00b7ria", "bin", "ich", "nur", ","], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ITJ", "$,", "NE", "VAFIN", "PPER", "ADV", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.68": {"line.1": {"text": "Bin das B\u00e4slein aus Asturien.", "tokens": ["Bin", "das", "B\u00e4s\u00b7lein", "aus", "As\u00b7tu\u00b7ri\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "APPR", "NE", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Tante haben und Kusinen", "tokens": ["Tan\u00b7te", "ha\u00b7ben", "und", "Ku\u00b7si\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "VAFIN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Immer mich versteckt gehalten,", "tokens": ["Im\u00b7mer", "mich", "ver\u00b7steckt", "ge\u00b7hal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VVFIN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wohl weil sie sich sch\u00e4mten mein.", "tokens": ["Wohl", "weil", "sie", "sich", "sch\u00e4m\u00b7ten", "mein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PPER", "PRF", "VVFIN", "PPOSAT", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.69": {"line.1": {"text": "Wann sie aus den L\u00e4den gr\u00fc\u00dften", "tokens": ["Wann", "sie", "aus", "den", "L\u00e4\u00b7den", "gr\u00fc\u00df\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "APPR", "ART", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Alle Herrn von Salamanca,", "tokens": ["Al\u00b7le", "Herrn", "von", "Sa\u00b7la\u00b7man\u00b7ca", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "APPR", "NE", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.3": {"text": "Ich \u2013 aus meiner Mauerritze \u2013", "tokens": ["Ich", "\u2013", "aus", "mei\u00b7ner", "Mau\u00b7er\u00b7rit\u00b7ze", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "$(", "APPR", "PPOSAT", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Sah verstohlen nur nach Euch!", "tokens": ["Sah", "ver\u00b7stoh\u00b7len", "nur", "nach", "Euch", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADV", "APPR", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.70": {"line.1": {"text": "In den Bergen von Asturien", "tokens": ["In", "den", "Ber\u00b7gen", "von", "As\u00b7tu\u00b7ri\u00b7en"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "APPR", "NE"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Lernt' ich K\u00fcnste nicht, noch Feinheit,", "tokens": ["Lernt'", "ich", "K\u00fcns\u00b7te", "nicht", ",", "noch", "Fein\u00b7heit", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "PTKNEG", "$,", "ADV", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und ich wei\u00df nicht viel zu sagen \u2013:", "tokens": ["Und", "ich", "wei\u00df", "nicht", "viel", "zu", "sa\u00b7gen", "\u2013", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "PPER", "VVFIN", "PTKNEG", "ADV", "PTKZU", "VVINF", "$(", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Doch ich sterbe, scheidest du!\u00ab", "tokens": ["Doch", "ich", "ster\u00b7be", ",", "schei\u00b7dest", "du", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["KON", "PPER", "VVFIN", "$,", "VVFIN", "PPER", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.71": {"line.1": {"text": "Auf vom Boden sprang Alfonso,", "tokens": ["Auf", "vom", "Bo\u00b7den", "sprang", "Al\u00b7fon\u00b7so", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "APPRART", "NN", "VVFIN", "NE", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "An die Brust ri\u00df er die Blonde:", "tokens": ["An", "die", "Brust", "ri\u00df", "er", "die", "Blon\u00b7de", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "\u00bbo, Maria! Wei\u00dfe Blume!", "tokens": ["\u00bb", "o", ",", "Ma\u00b7ria", "!", "Wei\u00b7\u00dfe", "Blu\u00b7me", "!"], "token_info": ["punct", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["$(", "FM", "$,", "NE", "$.", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Ewig, ewig bist du mein!\u00ab", "tokens": ["E\u00b7wig", ",", "e\u00b7wig", "bist", "du", "mein", "!", "\u00ab"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADJD", "$,", "ADJD", "VAFIN", "PPER", "PPOSAT", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.72": {"line.1": {"text": "Und herab die seidne Leiter", "tokens": ["Und", "her\u00b7ab", "die", "seid\u00b7ne", "Lei\u00b7ter"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Trug er die versch\u00e4mte Kleine,", "tokens": ["Trug", "er", "die", "ver\u00b7sch\u00e4m\u00b7te", "Klei\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und er hob sie auf sein R\u00f6\u00dflein", "tokens": ["Und", "er", "hob", "sie", "auf", "sein", "R\u00f6\u00df\u00b7lein"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "PPER", "APPR", "PPOSAT", "NN"], "meter": "--+---+-", "measure": "anapaest.init"}, "line.4": {"text": "Im Geb\u00fcsche von Jasmin.", "tokens": ["Im", "Ge\u00b7b\u00fc\u00b7sche", "von", "Jas\u00b7min", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPR", "NE", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}}, "stanza.73": {"line.1": {"text": "\u00bbach, wohin, wohin, Geliebter?\u00ab", "tokens": ["\u00bb", "ach", ",", "wo\u00b7hin", ",", "wo\u00b7hin", ",", "Ge\u00b7lieb\u00b7ter", "?", "\u00ab"], "token_info": ["punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "punct"], "pos": ["$(", "ITJ", "$,", "PWAV", "$,", "PWAV", "$,", "NN", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "\u00bbauf mein Schlo\u00df am Manzanares!\u00ab", "tokens": ["\u00bb", "auf", "mein", "Schlo\u00df", "am", "Man\u00b7za\u00b7na\u00b7res", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "APPR", "PPOSAT", "NN", "APPRART", "NN", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Doch am Kloster in der Vorstadt", "tokens": ["Doch", "am", "Klos\u00b7ter", "in", "der", "Vor\u00b7stadt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPRART", "NN", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Hielt er an. Nun sagt: weshalb?", "tokens": ["Hielt", "er", "an", ".", "Nun", "sagt", ":", "we\u00b7shalb", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKVZ", "$.", "ADV", "VVFIN", "$.", "PWAV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.74": {"line.1": {"text": "Er hielt an vor jenem Kloster,", "tokens": ["Er", "hielt", "an", "vor", "je\u00b7nem", "Klos\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "APPR", "PDAT", "NN", "$,"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.2": {"text": "Um sich schleunigst traun zu lassen,", "tokens": ["Um", "sich", "schleu\u00b7nigst", "traun", "zu", "las\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PRF", "ADJD", "VVINF", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Weil er nicht nur musikalisch,", "tokens": ["Weil", "er", "nicht", "nur", "mu\u00b7si\u00b7ka\u00b7lisch", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "ADV", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Sondern auch moralisch war.", "tokens": ["Son\u00b7dern", "auch", "mo\u00b7ra\u00b7lisch", "war", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJD", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}