{"textgrid.poem.57104": {"metadata": {"author": {"name": "Morgenstern, Christian", "birth": "N.A.", "death": "N.A."}, "title": "1L: Spann dein kleines Schirmchen auf;", "genre": "verse", "period": "N.A.", "pub_year": 1892, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Spann dein kleines Schirmchen auf;", "tokens": ["Spann", "dein", "klei\u00b7nes", "Schirm\u00b7chen", "auf", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPOSAT", "ADJA", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "denn es m\u00f6chte regnen drauf.", "tokens": ["denn", "es", "m\u00f6ch\u00b7te", "reg\u00b7nen", "drauf", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VMFIN", "VVINF", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Denn es m\u00f6chte regnen drauf,", "tokens": ["Denn", "es", "m\u00f6ch\u00b7te", "reg\u00b7nen", "drauf", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VMFIN", "VVINF", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "halt nur fest den Schirmchen-Knauf.", "tokens": ["halt", "nur", "fest", "den", "Schirm\u00b7chen\u00b7Knauf", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADJD", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Halt nur fest den Schirmchen-Knauf \u2013", "tokens": ["Halt", "nur", "fest", "den", "Schirm\u00b7chen\u00b7Knauf", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ADV", "ADJD", "ART", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "und jetzt lauf! und jetzt lauf!", "tokens": ["und", "jetzt", "lauf", "!", "und", "jetzt", "lauf", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PTKVZ", "$.", "KON", "ADV", "PTKVZ", "$."], "meter": "--+--+", "measure": "anapaest.di.plus"}}, "stanza.4": {"line.1": {"text": "Und jetzt lauf! und jetzt lauf!", "tokens": ["Und", "jetzt", "lauf", "!", "und", "jetzt", "lauf", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PTKVZ", "$.", "KON", "ADV", "PTKVZ", "$."], "meter": "--+--+", "measure": "anapaest.di.plus"}, "line.2": {"text": "Lauf zum Kaufmann hin und kauf!", "tokens": ["Lauf", "zum", "Kauf\u00b7mann", "hin", "und", "kauf", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPRART", "NN", "PTKVZ", "KON", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Lauf zum Kaufmann hin und sag:", "tokens": ["Lauf", "zum", "Kauf\u00b7mann", "hin", "und", "sag", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPRART", "NN", "PTKVZ", "KON", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Guten Tag! guten Tag!", "tokens": ["Gu\u00b7ten", "Tag", "!", "gu\u00b7ten", "Tag", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADJA", "NN", "$.", "ADJA", "NN", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}}, "stanza.6": {"line.1": {"text": "Guten Tag, Herr Kaufmann mein,", "tokens": ["Gu\u00b7ten", "Tag", ",", "Herr", "Kauf\u00b7mann", "mein", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "NN", "NN", "PPOSAT", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "gib mir doch ein St\u00fcckchen Sonnenschein.", "tokens": ["gib", "mir", "doch", "ein", "St\u00fcck\u00b7chen", "Son\u00b7nen\u00b7schein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ADV", "ART", "NN", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.7": {"line.1": {"text": "Gib mir doch ein St\u00fcckchen Sonnenschin;", "tokens": ["Gib", "mir", "doch", "ein", "St\u00fcck\u00b7chen", "Son\u00b7nen\u00b7schin", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ADV", "ART", "NN", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "denn ich will mein Schirmchen trocknen fein.", "tokens": ["denn", "ich", "will", "mein", "Schirm\u00b7chen", "trock\u00b7nen", "fein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VMFIN", "PPOSAT", "NN", "ADJA", "ADJD", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.8": {"line.1": {"text": "Denn ich will mein Schirmchen trocknen fein.", "tokens": ["Denn", "ich", "will", "mein", "Schirm\u00b7chen", "trock\u00b7nen", "fein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VMFIN", "PPOSAT", "NN", "ADJA", "ADJD", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Und der Kaufmann geht ins Haus hinein.", "tokens": ["Und", "der", "Kauf\u00b7mann", "geht", "ins", "Haus", "hin\u00b7ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "APPRART", "NN", "PTKVZ", "$."], "meter": "--+-+-+-+", "measure": "anapaest.init"}}, "stanza.9": {"line.1": {"text": "Und der Kaufmann geht hinein ins Haus,", "tokens": ["Und", "der", "Kauf\u00b7mann", "geht", "hin\u00b7ein", "ins", "Haus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "ADV", "APPRART", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "und er bringt ein St\u00fcckchen Sonne heraus.", "tokens": ["und", "er", "bringt", "ein", "St\u00fcck\u00b7chen", "Son\u00b7ne", "he\u00b7raus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ART", "NN", "NN", "PTKVZ", "$."], "meter": "+-+-+-+--+", "measure": "iambic.penta.chol"}}, "stanza.10": {"line.1": {"text": "Und er bringt ein St\u00fcckchen Sonne heraus.", "tokens": ["Und", "er", "bringt", "ein", "St\u00fcck\u00b7chen", "Son\u00b7ne", "he\u00b7raus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ART", "NN", "NN", "PTKVZ", "$."], "meter": "--+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Sicht es nicht wie gelber Honig aus?", "tokens": ["Sicht", "es", "nicht", "wie", "gel\u00b7ber", "Ho\u00b7nig", "aus", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKNEG", "KOKOM", "ADJA", "NN", "PTKVZ", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.11": {"line.1": {"text": "Sieht es nicht wie gelber Honig schier?", "tokens": ["Sieht", "es", "nicht", "wie", "gel\u00b7ber", "Ho\u00b7nig", "schier", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKNEG", "KOKOM", "ADJA", "NN", "ADJD", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Und er tut es sorgsam in Papier.", "tokens": ["Und", "er", "tut", "es", "sorg\u00b7sam", "in", "Pa\u00b7pier", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPER", "ADJD", "APPR", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.12": {"line.1": {"text": "Und er tut es sorgsam in Papier.", "tokens": ["Und", "er", "tut", "es", "sorg\u00b7sam", "in", "Pa\u00b7pier", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPER", "ADJD", "APPR", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Und dies P\u00e4ckchen dann, das bringst du mir.", "tokens": ["Und", "dies", "P\u00e4ck\u00b7chen", "dann", ",", "das", "bringst", "du", "mir", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "NN", "ADV", "$,", "PDS", "VVFIN", "PPER", "PPER", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.13": {"line.1": {"text": "Und zu Haus da packen wir es aus \u2013", "tokens": ["Und", "zu", "Haus", "da", "pa\u00b7cken", "wir", "es", "aus", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "ADV", "VVFIN", "PPER", "PPER", "APPR", "$("], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "sieht es nicht wie gelber Honig aus?", "tokens": ["sieht", "es", "nicht", "wie", "gel\u00b7ber", "Ho\u00b7nig", "aus", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKNEG", "KOKOM", "ADJA", "NN", "PTKVZ", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.14": {"line.1": {"text": "Und die H\u00e4lfte kriegst dann Du, mein Irmchen,", "tokens": ["Und", "die", "H\u00e4lf\u00b7te", "kriegst", "dann", "Du", ",", "mein", "Irm\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "ADV", "PPER", "$,", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "und die andre H\u00e4lfte kriegt das Schirmchen.", "tokens": ["und", "die", "and\u00b7re", "H\u00e4lf\u00b7te", "kriegt", "das", "Schirm\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.15": {"line.1": {"text": "Und jetzt spann dein Schirmchen auf \u2013", "tokens": ["Und", "jetzt", "spann", "dein", "Schirm\u00b7chen", "auf", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPOSAT", "NN", "APPR", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "und lauf! und lauf!", "tokens": ["und", "lauf", "!", "und", "lauf", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "NN", "$.", "KON", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.16": {"line.1": {"text": "Spann dein kleines Schirmchen auf;", "tokens": ["Spann", "dein", "klei\u00b7nes", "Schirm\u00b7chen", "auf", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPOSAT", "ADJA", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "denn es m\u00f6chte regnen drauf.", "tokens": ["denn", "es", "m\u00f6ch\u00b7te", "reg\u00b7nen", "drauf", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VMFIN", "VVINF", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.17": {"line.1": {"text": "Denn es m\u00f6chte regnen drauf,", "tokens": ["Denn", "es", "m\u00f6ch\u00b7te", "reg\u00b7nen", "drauf", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VMFIN", "VVINF", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "halt nur fest den Schirmchen-Knauf.", "tokens": ["halt", "nur", "fest", "den", "Schirm\u00b7chen\u00b7Knauf", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADJD", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.18": {"line.1": {"text": "Halt nur fest den Schirmchen-Knauf \u2013", "tokens": ["Halt", "nur", "fest", "den", "Schirm\u00b7chen\u00b7Knauf", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ADV", "ADJD", "ART", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "und jetzt lauf! und jetzt lauf!", "tokens": ["und", "jetzt", "lauf", "!", "und", "jetzt", "lauf", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PTKVZ", "$.", "KON", "ADV", "PTKVZ", "$."], "meter": "--+--+", "measure": "anapaest.di.plus"}}, "stanza.19": {"line.1": {"text": "Und jetzt lauf! und jetzt lauf!", "tokens": ["Und", "jetzt", "lauf", "!", "und", "jetzt", "lauf", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PTKVZ", "$.", "KON", "ADV", "PTKVZ", "$."], "meter": "--+--+", "measure": "anapaest.di.plus"}, "line.2": {"text": "Lauf zum Kaufmann hin und kauf!", "tokens": ["Lauf", "zum", "Kauf\u00b7mann", "hin", "und", "kauf", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPRART", "NN", "PTKVZ", "KON", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.20": {"line.1": {"text": "Lauf zum Kaufmann hin und sag:", "tokens": ["Lauf", "zum", "Kauf\u00b7mann", "hin", "und", "sag", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPRART", "NN", "PTKVZ", "KON", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Guten Tag! guten Tag!", "tokens": ["Gu\u00b7ten", "Tag", "!", "gu\u00b7ten", "Tag", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADJA", "NN", "$.", "ADJA", "NN", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}}, "stanza.21": {"line.1": {"text": "Guten Tag, Herr Kaufmann mein,", "tokens": ["Gu\u00b7ten", "Tag", ",", "Herr", "Kauf\u00b7mann", "mein", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "NN", "NN", "PPOSAT", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "gib mir doch ein St\u00fcckchen Sonnenschein.", "tokens": ["gib", "mir", "doch", "ein", "St\u00fcck\u00b7chen", "Son\u00b7nen\u00b7schein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ADV", "ART", "NN", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.22": {"line.1": {"text": "Gib mir doch ein St\u00fcckchen Sonnenschin;", "tokens": ["Gib", "mir", "doch", "ein", "St\u00fcck\u00b7chen", "Son\u00b7nen\u00b7schin", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ADV", "ART", "NN", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "denn ich will mein Schirmchen trocknen fein.", "tokens": ["denn", "ich", "will", "mein", "Schirm\u00b7chen", "trock\u00b7nen", "fein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VMFIN", "PPOSAT", "NN", "ADJA", "ADJD", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.23": {"line.1": {"text": "Denn ich will mein Schirmchen trocknen fein.", "tokens": ["Denn", "ich", "will", "mein", "Schirm\u00b7chen", "trock\u00b7nen", "fein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VMFIN", "PPOSAT", "NN", "ADJA", "ADJD", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Und der Kaufmann geht ins Haus hinein.", "tokens": ["Und", "der", "Kauf\u00b7mann", "geht", "ins", "Haus", "hin\u00b7ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "APPRART", "NN", "PTKVZ", "$."], "meter": "--+-+-+-+", "measure": "anapaest.init"}}, "stanza.24": {"line.1": {"text": "Und der Kaufmann geht hinein ins Haus,", "tokens": ["Und", "der", "Kauf\u00b7mann", "geht", "hin\u00b7ein", "ins", "Haus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "ADV", "APPRART", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "und er bringt ein St\u00fcckchen Sonne heraus.", "tokens": ["und", "er", "bringt", "ein", "St\u00fcck\u00b7chen", "Son\u00b7ne", "he\u00b7raus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ART", "NN", "NN", "PTKVZ", "$."], "meter": "+-+-+-+--+", "measure": "iambic.penta.chol"}}, "stanza.25": {"line.1": {"text": "Und er bringt ein St\u00fcckchen Sonne heraus.", "tokens": ["Und", "er", "bringt", "ein", "St\u00fcck\u00b7chen", "Son\u00b7ne", "he\u00b7raus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ART", "NN", "NN", "PTKVZ", "$."], "meter": "--+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Sicht es nicht wie gelber Honig aus?", "tokens": ["Sicht", "es", "nicht", "wie", "gel\u00b7ber", "Ho\u00b7nig", "aus", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKNEG", "KOKOM", "ADJA", "NN", "PTKVZ", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.26": {"line.1": {"text": "Sieht es nicht wie gelber Honig schier?", "tokens": ["Sieht", "es", "nicht", "wie", "gel\u00b7ber", "Ho\u00b7nig", "schier", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKNEG", "KOKOM", "ADJA", "NN", "ADJD", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Und er tut es sorgsam in Papier.", "tokens": ["Und", "er", "tut", "es", "sorg\u00b7sam", "in", "Pa\u00b7pier", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPER", "ADJD", "APPR", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.27": {"line.1": {"text": "Und er tut es sorgsam in Papier.", "tokens": ["Und", "er", "tut", "es", "sorg\u00b7sam", "in", "Pa\u00b7pier", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPER", "ADJD", "APPR", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Und dies P\u00e4ckchen dann, das bringst du mir.", "tokens": ["Und", "dies", "P\u00e4ck\u00b7chen", "dann", ",", "das", "bringst", "du", "mir", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "NN", "ADV", "$,", "PDS", "VVFIN", "PPER", "PPER", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.28": {"line.1": {"text": "Und zu Haus da packen wir es aus \u2013", "tokens": ["Und", "zu", "Haus", "da", "pa\u00b7cken", "wir", "es", "aus", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "ADV", "VVFIN", "PPER", "PPER", "APPR", "$("], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "sieht es nicht wie gelber Honig aus?", "tokens": ["sieht", "es", "nicht", "wie", "gel\u00b7ber", "Ho\u00b7nig", "aus", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKNEG", "KOKOM", "ADJA", "NN", "PTKVZ", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.29": {"line.1": {"text": "Und die H\u00e4lfte kriegst dann Du, mein Irmchen,", "tokens": ["Und", "die", "H\u00e4lf\u00b7te", "kriegst", "dann", "Du", ",", "mein", "Irm\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "ADV", "PPER", "$,", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "und die andre H\u00e4lfte kriegt das Schirmchen.", "tokens": ["und", "die", "and\u00b7re", "H\u00e4lf\u00b7te", "kriegt", "das", "Schirm\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.30": {"line.1": {"text": "Und jetzt spann dein Schirmchen auf \u2013", "tokens": ["Und", "jetzt", "spann", "dein", "Schirm\u00b7chen", "auf", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPOSAT", "NN", "APPR", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "und lauf! und lauf!", "tokens": ["und", "lauf", "!", "und", "lauf", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "NN", "$.", "KON", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}}}}}