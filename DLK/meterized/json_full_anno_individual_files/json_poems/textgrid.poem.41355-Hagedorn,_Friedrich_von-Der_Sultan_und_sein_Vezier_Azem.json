{"textgrid.poem.41355": {"metadata": {"author": {"name": "Hagedorn, Friedrich von", "birth": "N.A.", "death": "N.A."}, "title": "Der Sultan und sein Vezier Azem", "genre": "verse", "period": "N.A.", "pub_year": 1731, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Es ward ein Suliman nur durch den Krieg erg\u00f6tzt,", "tokens": ["Es", "ward", "ein", "Su\u00b7li\u00b7man", "nur", "durch", "den", "Krieg", "er\u00b7g\u00f6tzt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "ADV", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der seinen Ro\u00dfschweif oft mit frischem Blut benetzt;", "tokens": ["Der", "sei\u00b7nen", "Ro\u00df\u00b7schweif", "oft", "mit", "fri\u00b7schem", "Blut", "be\u00b7netzt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "ADV", "APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Sein und der Feinde Land ward siegreich aufgerieben;", "tokens": ["Sein", "und", "der", "Fein\u00b7de", "Land", "ward", "sieg\u00b7reich", "auf\u00b7ge\u00b7rie\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "KON", "ART", "NN", "NN", "VAFIN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "(o lernten Helden doch die leichte Wohlfahrt lieben!)", "tokens": ["(", "o", "lern\u00b7ten", "Hel\u00b7den", "doch", "die", "leich\u00b7te", "Wohl\u00b7fahrt", "lie\u00b7ben", "!", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "FM", "ADJA", "NN", "ADV", "ART", "ADJA", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Dem tapfern Pyrrhus gleich stritt er ohn' Unterla\u00df;", "tokens": ["Dem", "tap\u00b7fern", "Pyrr\u00b7hus", "gleich", "stritt", "er", "ohn'", "Un\u00b7ter\u00b7la\u00df", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NE", "ADV", "VVFIN", "PPER", "APPR", "NN", "$."], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Jedoch sah der Vezier, ein andrer Cineas,", "tokens": ["Je\u00b7doch", "sah", "der", "Ve\u00b7zier", ",", "ein", "an\u00b7drer", "Ci\u00b7ne\u00b7as", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$,", "ART", "ADJA", "NE", "$,"], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.3": {"text": "Der wahren Gr\u00f6\u00dfe Freund, mit heimlichem Erbarmen", "tokens": ["Der", "wah\u00b7ren", "Gr\u00f6\u00b7\u00dfe", "Freund", ",", "mit", "heim\u00b7li\u00b7chem", "Er\u00b7bar\u00b7men"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "NN", "$,", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der Herrschsucht Opferherd, das sch\u00f6ne Reich, verarmen,", "tokens": ["Der", "Herrschsucht", "Op\u00b7fer\u00b7herd", ",", "das", "sch\u00f6\u00b7ne", "Reich", ",", "ver\u00b7ar\u00b7men", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "NN", "$,", "ART", "ADJA", "NN", "$,", "VVPP", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.5": {"text": "Hier Felder unbes\u00e4't, dort St\u00e4dt' in Flammen stehn,", "tokens": ["Hier", "Fel\u00b7der", "un\u00b7be\u00b7s\u00e4't", ",", "dort", "St\u00e4dt'", "in", "Flam\u00b7men", "stehn", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "ADJD", "$,", "ADV", "NN", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und, den kein S\u00e4bel f\u00e4llt, in Sklavenfesseln gehn.", "tokens": ["Und", ",", "den", "kein", "S\u00e4\u00b7bel", "f\u00e4llt", ",", "in", "Skla\u00b7ven\u00b7fes\u00b7seln", "gehn", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "$,", "PRELS", "PIAT", "NN", "VVFIN", "$,", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Dies sah er seufzend an, nur durft' er es nicht wagen,", "tokens": ["Dies", "sah", "er", "seuf\u00b7zend", "an", ",", "nur", "durft'", "er", "es", "nicht", "wa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADJD", "PTKVZ", "$,", "ADV", "VMFIN", "PPER", "PPER", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Bei Kriegesr\u00fcstungen den Frieden vorzuschlagen.", "tokens": ["Bei", "Krie\u00b7ges\u00b7r\u00fcs\u00b7tun\u00b7gen", "den", "Frie\u00b7den", "vor\u00b7zu\u00b7schla\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+-+---+-+-+-", "measure": "unknown.measure.penta"}, "line.3": {"text": "Doch seines Sultans Huld half dieser Bl\u00f6digkeit,", "tokens": ["Doch", "sei\u00b7nes", "Sul\u00b7tans", "Huld", "half", "die\u00b7ser", "Bl\u00f6\u00b7dig\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "VVFIN", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und gab auf einer Jagd hierzu Gelegenheit.", "tokens": ["Und", "gab", "auf", "ei\u00b7ner", "Jagd", "hier\u00b7zu", "Ge\u00b7le\u00b7gen\u00b7heit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "PAV", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Es hatte Suliman die Beyen, Aga's, Bassen,", "tokens": ["Es", "hat\u00b7te", "Su\u00b7li\u00b7man", "die", "Be\u00b7yen", ",", "A\u00b7ga's", ",", "Bas\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PPER", "VAFIN", "NE", "ART", "NN", "$,", "NE", "$,", "NE", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Des ganzen Hofstaat Zug, in schnellem Ritt verlassen.", "tokens": ["Des", "gan\u00b7zen", "Hof\u00b7staat", "Zug", ",", "in", "schnel\u00b7lem", "Ritt", "ver\u00b7las\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "$,", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ihm folgte der Vezier, weil es sein Herr befahl,", "tokens": ["Ihm", "folg\u00b7te", "der", "Ve\u00b7zier", ",", "weil", "es", "sein", "Herr", "be\u00b7fahl", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "KOUS", "PPER", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und beide kamen bald in ein geweihtes Thal,", "tokens": ["Und", "bei\u00b7de", "ka\u00b7men", "bald", "in", "ein", "ge\u00b7weih\u00b7tes", "Thal", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "ADV", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wo noch zu O\u00dfmanns Zeit ein alter Santon wohnte,", "tokens": ["Wo", "noch", "zu", "O\u00df\u00b7manns", "Zeit", "ein", "al\u00b7ter", "San\u00b7ton", "wohn\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "APPR", "NE", "NN", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Abdallah, der Prophet, in dem die Weisheit thronte,", "tokens": ["Ab\u00b7dal\u00b7lah", ",", "der", "Pro\u00b7phet", ",", "in", "dem", "die", "Weis\u00b7heit", "thron\u00b7te", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ART", "NN", "$,", "APPR", "PRELS", "ART", "NN", "VVFIN", "$,"], "meter": "+-+--+-+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.7": {"text": "Der Omars gro\u00dfen Sohn, ein Haubt der frommen Schaar,", "tokens": ["Der", "O\u00b7mars", "gro\u00b7\u00dfen", "Sohn", ",", "ein", "Haubt", "der", "from\u00b7men", "Schaar", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$,", "ART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Der Todes-Engel Freund, Azraels Liebling, war,", "tokens": ["Der", "To\u00b7des\u00b7En\u00b7gel", "Freund", ",", "Az\u00b7ra\u00b7els", "Lieb\u00b7ling", ",", "war", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "NN", "$,", "NE", "NN", "$,", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Der fast, wie Mahomet, die sieben Himmel kannte,", "tokens": ["Der", "fast", ",", "wie", "Ma\u00b7ho\u00b7met", ",", "die", "sie\u00b7ben", "Him\u00b7mel", "kann\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "$,", "PWAV", "NE", "$,", "PRELS", "CARD", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Und den ganz Asien vor vielen heilig nannte.", "tokens": ["Und", "den", "ganz", "A\u00b7sien", "vor", "vie\u00b7len", "hei\u00b7lig", "nann\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADV", "NE", "APPR", "PIAT", "ADJD", "VVFIN", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}}, "stanza.5": {"line.1": {"text": "Sie wuschen sich allhier Gesicht und Arm und Hand,", "tokens": ["Sie", "wu\u00b7schen", "sich", "all\u00b7hier", "Ge\u00b7sicht", "und", "Arm", "und", "Hand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "ADV", "NN", "KON", "NN", "KON", "NN", "$,"], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Nach Art des Muselmanns, mit d\u00fcrrem, reinem Sand,", "tokens": ["Nach", "Art", "des", "Mu\u00b7sel\u00b7manns", ",", "mit", "d\u00fcr\u00b7rem", ",", "rei\u00b7nem", "Sand", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "NN", "ART", "NN", "$,", "APPR", "NE", "$,", "ADJA", "NN", "$,"], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Und ehrten andachtvoll, an der best\u00e4ubten St\u00e4te,", "tokens": ["Und", "ehr\u00b7ten", "an\u00b7dacht\u00b7voll", ",", "an", "der", "be\u00b7st\u00e4ub\u00b7ten", "St\u00e4\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "$,", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+--+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Abdallahs hohen Ruhm mit eifrigem Gebete.", "tokens": ["Ab\u00b7dal\u00b7lahs", "ho\u00b7hen", "Ruhm", "mit", "eif\u00b7ri\u00b7gem", "Ge\u00b7be\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "APPR", "ADJA", "NN", "$."], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}}, "stanza.6": {"line.1": {"text": "Drauf hebt sich ein Gespr\u00e4ch von dessen Wundern an;", "tokens": ["Drauf", "hebt", "sich", "ein", "Ge\u00b7spr\u00e4ch", "von", "des\u00b7sen", "Wun\u00b7dern", "an", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PRF", "ART", "NN", "APPR", "PRELAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Da l\u00e4chelt der Vezier, und spricht zum Suliman:", "tokens": ["Da", "l\u00e4\u00b7chelt", "der", "Ve\u00b7zier", ",", "und", "spricht", "zum", "Su\u00b7li\u00b7man", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$,", "KON", "VVFIN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ich habe, gro\u00dfer Held, bereits vor vielen Jahren", "tokens": ["Ich", "ha\u00b7be", ",", "gro\u00b7\u00dfer", "Held", ",", "be\u00b7reits", "vor", "vie\u00b7len", "Jah\u00b7ren"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "$,", "ADJA", "NN", "$,", "ADV", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die schwerste Wissenschaft des Orients erfahren.", "tokens": ["Die", "schwers\u00b7te", "Wis\u00b7sen\u00b7schaft", "des", "O\u00b7rients", "er\u00b7fah\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Und welche? Die vielleicht kein Imam eingesehn,", "tokens": ["Und", "wel\u00b7che", "?", "Die", "viel\u00b7leicht", "kein", "I\u00b7mam", "ein\u00b7ge\u00b7sehn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAT", "$.", "ART", "ADV", "PIAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Kein Mufti lehren kann: Die V\u00f6gel zu verstehn.", "tokens": ["Kein", "Muf\u00b7ti", "leh\u00b7ren", "kann", ":", "Die", "V\u00f6\u00b7gel", "zu", "ver\u00b7stehn", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVINF", "VMFIN", "$.", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Der Schwanen Sterbelied, was Staar und Aelster schwatzen.", "tokens": ["Der", "Schwa\u00b7nen", "Ster\u00b7be\u00b7lied", ",", "was", "Staar", "und", "A\u00b7els\u00b7ter", "schwat\u00b7zen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$,", "PWS", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.8": {"text": "Der Adler heisern Ruf, die Strau\u00dfen und die Spatzen,", "tokens": ["Der", "Ad\u00b7ler", "hei\u00b7sern", "Ruf", ",", "die", "Strau\u00b7\u00dfen", "und", "die", "Spat\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$,", "ART", "NN", "KON", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Des Pelikans Geschrei, selbst des Humai", "tokens": ["Des", "Pe\u00b7li\u00b7kans", "Ge\u00b7schrei", ",", "selbst", "des", "Hu\u00b7mai"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "NN", "$,", "ADV", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "O Herr der K\u00f6nige! versteht dein Ibrahim.", "tokens": ["O", "Herr", "der", "K\u00f6\u00b7ni\u00b7ge", "!", "ver\u00b7steht", "dein", "Ib\u00b7ra\u00b7him", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NN", "ART", "NN", "$.", "VVFIN", "PPOSAT", "NE", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Ein Dervis hat mir das in Bagdad einst entdecket,", "tokens": ["Ein", "Der\u00b7vis", "hat", "mir", "das", "in", "Bag\u00b7dad", "einst", "ent\u00b7de\u00b7cket", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PDS", "VAFIN", "PPER", "ART", "APPR", "NE", "ADV", "VVFIN", "$,"], "meter": "--+--+-+-+-+-", "measure": "anapaest.di.plus"}, "line.12": {"text": "In dem Abdallahs Geist und Kraft zu Wundern stecket,", "tokens": ["In", "dem", "Ab\u00b7dal\u00b7lahs", "Geist", "und", "Kraft", "zu", "Wun\u00b7dern", "ste\u00b7cket", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "KON", "NN", "APPR", "NN", "VVFIN", "$,"], "meter": "--+--+-+-+-+-", "measure": "anapaest.di.plus"}, "line.13": {"text": "Der kennt den Alcoran; und der besitzt dabei", "tokens": ["Der", "kennt", "den", "Al\u00b7co\u00b7ran", ";", "und", "der", "be\u00b7sitzt", "da\u00b7bei"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "ART", "NN", "$.", "KON", "ART", "VVFIN", "PAV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Die etwas schwarze Kunst der Cabalisterei.", "tokens": ["Die", "et\u00b7was", "schwar\u00b7ze", "Kunst", "der", "Ca\u00b7ba\u00b7lis\u00b7te\u00b7rei", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "ADJA", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Die Probe f\u00e4llt mir leicht, und die soll nimmer tr\u00fcgen.", "tokens": ["Die", "Pro\u00b7be", "f\u00e4llt", "mir", "leicht", ",", "und", "die", "soll", "nim\u00b7mer", "tr\u00fc\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADJD", "$,", "KON", "PDS", "VMFIN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Der Sultan h\u00f6ret dies mit innigem Vergn\u00fcgen,", "tokens": ["Der", "Sul\u00b7tan", "h\u00f6\u00b7ret", "dies", "mit", "in\u00b7ni\u00b7gem", "Ver\u00b7gn\u00fc\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PDS", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Und kehrt bei Nacht zur\u00fcck; da ihn Dianens Schein", "tokens": ["Und", "kehrt", "bei", "Nacht", "zu\u00b7r\u00fcck", ";", "da", "ihn", "Di\u00b7a\u00b7nens", "Schein"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "NN", "PTKVZ", "$.", "KOUS", "PPER", "NE", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Zwo Eulen sehen l\u00e4\u00dft, die unaufh\u00f6rlich schrein.", "tokens": ["Zwo", "Eu\u00b7len", "se\u00b7hen", "l\u00e4\u00dft", ",", "die", "un\u00b7auf\u00b7h\u00f6r\u00b7lich", "schrein", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "VVINF", "VVFIN", "$,", "PRELS", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Auf! ruft er, Ibrahim, du wirst dich zeigen m\u00fcssen,", "tokens": ["Auf", "!", "ruft", "er", ",", "Ib\u00b7ra\u00b7him", ",", "du", "wirst", "dich", "zei\u00b7gen", "m\u00fcs\u00b7sen", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "$.", "VVFIN", "PPER", "$,", "NE", "$,", "PPER", "VAFIN", "PPER", "VVINF", "VMINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Was gibt's? Was wollen die? Ich mu\u00df es alles wissen.", "tokens": ["Was", "gibt's", "?", "Was", "wol\u00b7len", "die", "?", "Ich", "mu\u00df", "es", "al\u00b7les", "wis\u00b7sen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "$.", "PWS", "VMFIN", "ART", "$.", "PPER", "VMFIN", "PPER", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "Der Gro\u00dfvezier gehorcht, und thut, als g\u00e4b' er Acht", "tokens": ["Der", "Gro\u00df\u00b7ve\u00b7zier", "ge\u00b7horcht", ",", "und", "thut", ",", "als", "g\u00e4b'", "er", "Acht"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVPP", "$,", "KON", "VVFIN", "$,", "KOUS", "VVFIN", "PPER", "CARD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Zu forschen, was allhier die V\u00f6gel schwatzen macht;", "tokens": ["Zu", "for\u00b7schen", ",", "was", "all\u00b7hier", "die", "V\u00f6\u00b7gel", "schwat\u00b7zen", "macht", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "$,", "PRELS", "ADV", "ART", "NN", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und endlich k\u00f6mmt er schnell, als h\u00f6chst best\u00fcrzt, zur\u00fccke.", "tokens": ["Und", "end\u00b7lich", "k\u00f6mmt", "er", "schnell", ",", "als", "h\u00f6chst", "be\u00b7st\u00fcrzt", ",", "zu\u00b7r\u00fc\u00b7cke", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "ADJD", "$,", "KOUS", "ADV", "ADJD", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "O, spricht er: da\u00df dein Reich der Mahomet begl\u00fccke!", "tokens": ["O", ",", "spricht", "er", ":", "da\u00df", "dein", "Reich", "der", "Ma\u00b7ho\u00b7met", "be\u00b7gl\u00fc\u00b7cke", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "VVFIN", "PPER", "$.", "KOUS", "PPOSAT", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Ich k\u00fcss' in tiefem Staub, Herr, deines Rockes Saum:", "tokens": ["Ich", "k\u00fcss'", "in", "tie\u00b7fem", "Staub", ",", "Herr", ",", "dei\u00b7nes", "Ro\u00b7ckes", "Saum", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ADJA", "NN", "$,", "NN", "$,", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Nur gib, dein Azem fleht, gib einer Bitte Raum.", "tokens": ["Nur", "gib", ",", "dein", "A\u00b7zem", "fleht", ",", "gib", "ei\u00b7ner", "Bit\u00b7te", "Raum", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVIMP", "$,", "PPOSAT", "NN", "VVFIN", "$,", "VVIMP", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Ver\u00e4ndre das Gebot: will ihm dein Wink befehlen,", "tokens": ["Ver\u00b7\u00e4nd\u00b7re", "das", "Ge\u00b7bot", ":", "will", "ihm", "dein", "Wink", "be\u00b7feh\u00b7len", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$.", "VMFIN", "PPER", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "So sei es, was er h\u00f6rt, dir ewig zu verhehlen,", "tokens": ["So", "sei", "es", ",", "was", "er", "h\u00f6rt", ",", "dir", "e\u00b7wig", "zu", "ver\u00b7heh\u00b7len", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "$,", "PWS", "PPER", "VVFIN", "$,", "PPER", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Und ...", "tokens": ["Und", "..."], "token_info": ["word", "punct"], "pos": ["KON", "$("], "meter": "+", "measure": "single.up"}}, "stanza.9": {"line.1": {"text": "Was du jetzt geh\u00f6rt, soll mir verborgen sein?", "tokens": ["Was", "du", "jetzt", "ge\u00b7h\u00f6rt", ",", "soll", "mir", "ver\u00b7bor\u00b7gen", "sein", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "VVFIN", "$,", "VMFIN", "PPER", "VVPP", "VAINF", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.2": {"text": "Mir! einem Suliman! Nein! bei dem Allah! nein.", "tokens": ["Mir", "!", "ei\u00b7nem", "Su\u00b7li\u00b7man", "!", "Nein", "!", "bei", "dem", "Al\u00b7lah", "!", "nein", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["NE", "$.", "ART", "NN", "$.", "PTKANT", "$.", "APPR", "ART", "NN", "$.", "PTKANT", "$."], "meter": "+--+---+-+-+", "measure": "dactylic.di.plus"}, "line.3": {"text": "Sag' an!", "tokens": ["Sag'", "an", "!"], "token_info": ["word", "word", "punct"], "pos": ["NN", "PTKVZ", "$."], "meter": "-+", "measure": "iambic.single"}}, "stanza.10": {"line.1": {"text": "Der ganze L\u00e4rm betrifft nur Heirathsachen.", "tokens": ["Der", "gan\u00b7ze", "L\u00e4rm", "be\u00b7tr\u00b7ifft", "nur", "Hei\u00b7rath\u00b7sa\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ADV", "NN", "$."], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Zween V\u00e4ter sind bem\u00fcht, den Mahlschatz auszumachen,", "tokens": ["Zween", "V\u00e4\u00b7ter", "sind", "be\u00b7m\u00fcht", ",", "den", "Mahl\u00b7schatz", "aus\u00b7zu\u00b7ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "NN", "VAFIN", "VVPP", "$,", "ART", "NN", "VVIZU", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Womit des einen Sohn, zu beider H\u00e4user Wohl,", "tokens": ["Wo\u00b7mit", "des", "ei\u00b7nen", "Sohn", ",", "zu", "bei\u00b7der", "H\u00e4u\u00b7ser", "Wohl", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ART", "NN", "$,", "APPR", "PIAT", "NN", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Des andern einzig Kind in kurzem freien soll.", "tokens": ["Des", "an\u00b7dern", "ein\u00b7zig", "Kind", "in", "kur\u00b7zem", "frei\u00b7en", "soll", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJD", "NN", "APPR", "ADJA", "ADJA", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Er mu\u00df, spricht dieser Greis, vor allen andern Dingen", "tokens": ["Er", "mu\u00df", ",", "spricht", "die\u00b7ser", "Greis", ",", "vor", "al\u00b7len", "an\u00b7dern", "Din\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "$,", "VVFIN", "PDAT", "NN", "$,", "APPR", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Der Braut ein Heirathgut von f\u00fcnfzig D\u00f6rfern bringen,", "tokens": ["Der", "Braut", "ein", "Hei\u00b7rath\u00b7gut", "von", "f\u00fcnf\u00b7zig", "D\u00f6r\u00b7fern", "brin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "APPR", "CARD", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Nebst einer w\u00fcsten Stadt, die, raubt der Tod den Mann,", "tokens": ["Nebst", "ei\u00b7ner", "w\u00fcs\u00b7ten", "Stadt", ",", "die", ",", "raubt", "der", "Tod", "den", "Mann", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,", "PRELS", "$,", "VVFIN", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Ihr Wittwensitz verbleibt. Und wie? (hebt jener an)", "tokens": ["Ihr", "Witt\u00b7wen\u00b7sitz", "ver\u00b7bleibt", ".", "Und", "wie", "?", "(", "hebt", "je\u00b7ner", "an", ")"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "$.", "KON", "PWAV", "$.", "$(", "VVFIN", "PDS", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Nur f\u00fcnfzig? O wie leicht ist dieses einzugehen!", "tokens": ["Nur", "f\u00fcnf\u00b7zig", "?", "O", "wie", "leicht", "ist", "die\u00b7ses", "ein\u00b7zu\u00b7ge\u00b7hen", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "CARD", "$.", "NE", "KOKOM", "ADJD", "VAFIN", "PDAT", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Zweihundert sollen dir, mein Freund, zu Diensten stehen.", "tokens": ["Zwei\u00b7hun\u00b7dert", "sol\u00b7len", "dir", ",", "mein", "Freund", ",", "zu", "Diens\u00b7ten", "ste\u00b7hen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["CARD", "VMFIN", "PPER", "$,", "PPOSAT", "NN", "$,", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Seit des Propheten Flucht war keine bess're Zeit:", "tokens": ["Seit", "des", "Pro\u00b7phe\u00b7ten", "Flucht", "war", "kei\u00b7ne", "bess'\u00b7re", "Zeit", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "VAFIN", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Der Janitschar verheert die L\u00e4nder weit und breit.", "tokens": ["Der", "Ja\u00b7nit\u00b7schar", "ver\u00b7heert", "die", "L\u00e4n\u00b7der", "weit", "und", "breit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Es lebe Suliman! er m\u00fcsse lange leben!", "tokens": ["Es", "le\u00b7be", "Su\u00b7li\u00b7man", "!", "er", "m\u00fcs\u00b7se", "lan\u00b7ge", "le\u00b7ben", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NE", "$.", "PPER", "VMFIN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "So wird uns jedes Jahr schon W\u00fcsteneien geben.", "tokens": ["So", "wird", "uns", "je\u00b7des", "Jahr", "schon", "W\u00fcs\u00b7te\u00b7nei\u00b7en", "ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PIAT", "NN", "ADV", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.11": {"line.1": {"text": "Hier schweiget der Vezier: der Kaiser merkt es sich;", "tokens": ["Hier", "schwei\u00b7get", "der", "Ve\u00b7zier", ":", "der", "Kai\u00b7ser", "merkt", "es", "sich", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$.", "ART", "NN", "VVFIN", "PPER", "PRF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Er wei\u00df ihm heimlich Dank, und folgt ihm \u00f6ffentlich,", "tokens": ["Er", "wei\u00df", "ihm", "heim\u00b7lich", "Dank", ",", "und", "folgt", "ihm", "\u00f6f\u00b7fent\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADJD", "NN", "$,", "KON", "VVFIN", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Beschleu\u00dft, der Menschen Werth nie weiter zu vergessen,", "tokens": ["Be\u00b7schleu\u00dft", ",", "der", "Men\u00b7schen", "Werth", "nie", "wei\u00b7ter", "zu", "ver\u00b7ges\u00b7sen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "ART", "NN", "NN", "ADV", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und lernt der L\u00e4nder Heil nicht nach den Siegen messen.", "tokens": ["Und", "lernt", "der", "L\u00e4n\u00b7der", "Heil", "nicht", "nach", "den", "Sie\u00b7gen", "mes\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "NN", "PTKNEG", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.12": {"line.1": {"text": "Ein guter Rath ist immer gut;", "tokens": ["Ein", "gu\u00b7ter", "Rath", "ist", "im\u00b7mer", "gut", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Doch lerne man die Wahrheit kl\u00fcglich sagen.", "tokens": ["Doch", "ler\u00b7ne", "man", "die", "Wahr\u00b7heit", "kl\u00fcg\u00b7lich", "sa\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIS", "ART", "NN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Der Lehren Kraft und Gl\u00fcck beruht", "tokens": ["Der", "Leh\u00b7ren", "Kraft", "und", "Gl\u00fcck", "be\u00b7ruht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "NN", "KON", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Nur auf der Kunst, sie vorzutragen.", "tokens": ["Nur", "auf", "der", "Kunst", ",", "sie", "vor\u00b7zu\u00b7tra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "$,", "PPER", "VVIZU", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Es ward ein Suliman nur durch den Krieg erg\u00f6tzt,", "tokens": ["Es", "ward", "ein", "Su\u00b7li\u00b7man", "nur", "durch", "den", "Krieg", "er\u00b7g\u00f6tzt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "ADV", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der seinen Ro\u00dfschweif oft mit frischem Blut benetzt;", "tokens": ["Der", "sei\u00b7nen", "Ro\u00df\u00b7schweif", "oft", "mit", "fri\u00b7schem", "Blut", "be\u00b7netzt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "ADV", "APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Sein und der Feinde Land ward siegreich aufgerieben;", "tokens": ["Sein", "und", "der", "Fein\u00b7de", "Land", "ward", "sieg\u00b7reich", "auf\u00b7ge\u00b7rie\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "KON", "ART", "NN", "NN", "VAFIN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "(o lernten Helden doch die leichte Wohlfahrt lieben!)", "tokens": ["(", "o", "lern\u00b7ten", "Hel\u00b7den", "doch", "die", "leich\u00b7te", "Wohl\u00b7fahrt", "lie\u00b7ben", "!", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "FM", "ADJA", "NN", "ADV", "ART", "ADJA", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.14": {"line.1": {"text": "Dem tapfern Pyrrhus gleich stritt er ohn' Unterla\u00df;", "tokens": ["Dem", "tap\u00b7fern", "Pyrr\u00b7hus", "gleich", "stritt", "er", "ohn'", "Un\u00b7ter\u00b7la\u00df", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NE", "ADV", "VVFIN", "PPER", "APPR", "NN", "$."], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Jedoch sah der Vezier, ein andrer Cineas,", "tokens": ["Je\u00b7doch", "sah", "der", "Ve\u00b7zier", ",", "ein", "an\u00b7drer", "Ci\u00b7ne\u00b7as", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$,", "ART", "ADJA", "NE", "$,"], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.3": {"text": "Der wahren Gr\u00f6\u00dfe Freund, mit heimlichem Erbarmen", "tokens": ["Der", "wah\u00b7ren", "Gr\u00f6\u00b7\u00dfe", "Freund", ",", "mit", "heim\u00b7li\u00b7chem", "Er\u00b7bar\u00b7men"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "NN", "$,", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der Herrschsucht Opferherd, das sch\u00f6ne Reich, verarmen,", "tokens": ["Der", "Herrschsucht", "Op\u00b7fer\u00b7herd", ",", "das", "sch\u00f6\u00b7ne", "Reich", ",", "ver\u00b7ar\u00b7men", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "NN", "$,", "ART", "ADJA", "NN", "$,", "VVPP", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.5": {"text": "Hier Felder unbes\u00e4't, dort St\u00e4dt' in Flammen stehn,", "tokens": ["Hier", "Fel\u00b7der", "un\u00b7be\u00b7s\u00e4't", ",", "dort", "St\u00e4dt'", "in", "Flam\u00b7men", "stehn", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "ADJD", "$,", "ADV", "NN", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und, den kein S\u00e4bel f\u00e4llt, in Sklavenfesseln gehn.", "tokens": ["Und", ",", "den", "kein", "S\u00e4\u00b7bel", "f\u00e4llt", ",", "in", "Skla\u00b7ven\u00b7fes\u00b7seln", "gehn", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "$,", "PRELS", "PIAT", "NN", "VVFIN", "$,", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.15": {"line.1": {"text": "Dies sah er seufzend an, nur durft' er es nicht wagen,", "tokens": ["Dies", "sah", "er", "seuf\u00b7zend", "an", ",", "nur", "durft'", "er", "es", "nicht", "wa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADJD", "PTKVZ", "$,", "ADV", "VMFIN", "PPER", "PPER", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Bei Kriegesr\u00fcstungen den Frieden vorzuschlagen.", "tokens": ["Bei", "Krie\u00b7ges\u00b7r\u00fcs\u00b7tun\u00b7gen", "den", "Frie\u00b7den", "vor\u00b7zu\u00b7schla\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+-+---+-+-+-", "measure": "unknown.measure.penta"}, "line.3": {"text": "Doch seines Sultans Huld half dieser Bl\u00f6digkeit,", "tokens": ["Doch", "sei\u00b7nes", "Sul\u00b7tans", "Huld", "half", "die\u00b7ser", "Bl\u00f6\u00b7dig\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "VVFIN", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und gab auf einer Jagd hierzu Gelegenheit.", "tokens": ["Und", "gab", "auf", "ei\u00b7ner", "Jagd", "hier\u00b7zu", "Ge\u00b7le\u00b7gen\u00b7heit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "PAV", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.16": {"line.1": {"text": "Es hatte Suliman die Beyen, Aga's, Bassen,", "tokens": ["Es", "hat\u00b7te", "Su\u00b7li\u00b7man", "die", "Be\u00b7yen", ",", "A\u00b7ga's", ",", "Bas\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PPER", "VAFIN", "NE", "ART", "NN", "$,", "NE", "$,", "NE", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Des ganzen Hofstaat Zug, in schnellem Ritt verlassen.", "tokens": ["Des", "gan\u00b7zen", "Hof\u00b7staat", "Zug", ",", "in", "schnel\u00b7lem", "Ritt", "ver\u00b7las\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "$,", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ihm folgte der Vezier, weil es sein Herr befahl,", "tokens": ["Ihm", "folg\u00b7te", "der", "Ve\u00b7zier", ",", "weil", "es", "sein", "Herr", "be\u00b7fahl", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "KOUS", "PPER", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und beide kamen bald in ein geweihtes Thal,", "tokens": ["Und", "bei\u00b7de", "ka\u00b7men", "bald", "in", "ein", "ge\u00b7weih\u00b7tes", "Thal", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "ADV", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wo noch zu O\u00dfmanns Zeit ein alter Santon wohnte,", "tokens": ["Wo", "noch", "zu", "O\u00df\u00b7manns", "Zeit", "ein", "al\u00b7ter", "San\u00b7ton", "wohn\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "APPR", "NE", "NN", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Abdallah, der Prophet, in dem die Weisheit thronte,", "tokens": ["Ab\u00b7dal\u00b7lah", ",", "der", "Pro\u00b7phet", ",", "in", "dem", "die", "Weis\u00b7heit", "thron\u00b7te", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ART", "NN", "$,", "APPR", "PRELS", "ART", "NN", "VVFIN", "$,"], "meter": "+-+--+-+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.7": {"text": "Der Omars gro\u00dfen Sohn, ein Haubt der frommen Schaar,", "tokens": ["Der", "O\u00b7mars", "gro\u00b7\u00dfen", "Sohn", ",", "ein", "Haubt", "der", "from\u00b7men", "Schaar", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$,", "ART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Der Todes-Engel Freund, Azraels Liebling, war,", "tokens": ["Der", "To\u00b7des\u00b7En\u00b7gel", "Freund", ",", "Az\u00b7ra\u00b7els", "Lieb\u00b7ling", ",", "war", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "NN", "$,", "NE", "NN", "$,", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Der fast, wie Mahomet, die sieben Himmel kannte,", "tokens": ["Der", "fast", ",", "wie", "Ma\u00b7ho\u00b7met", ",", "die", "sie\u00b7ben", "Him\u00b7mel", "kann\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "$,", "PWAV", "NE", "$,", "PRELS", "CARD", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Und den ganz Asien vor vielen heilig nannte.", "tokens": ["Und", "den", "ganz", "A\u00b7sien", "vor", "vie\u00b7len", "hei\u00b7lig", "nann\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADV", "NE", "APPR", "PIAT", "ADJD", "VVFIN", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}}, "stanza.17": {"line.1": {"text": "Sie wuschen sich allhier Gesicht und Arm und Hand,", "tokens": ["Sie", "wu\u00b7schen", "sich", "all\u00b7hier", "Ge\u00b7sicht", "und", "Arm", "und", "Hand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "ADV", "NN", "KON", "NN", "KON", "NN", "$,"], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Nach Art des Muselmanns, mit d\u00fcrrem, reinem Sand,", "tokens": ["Nach", "Art", "des", "Mu\u00b7sel\u00b7manns", ",", "mit", "d\u00fcr\u00b7rem", ",", "rei\u00b7nem", "Sand", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "NN", "ART", "NN", "$,", "APPR", "NE", "$,", "ADJA", "NN", "$,"], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Und ehrten andachtvoll, an der best\u00e4ubten St\u00e4te,", "tokens": ["Und", "ehr\u00b7ten", "an\u00b7dacht\u00b7voll", ",", "an", "der", "be\u00b7st\u00e4ub\u00b7ten", "St\u00e4\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "$,", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+--+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Abdallahs hohen Ruhm mit eifrigem Gebete.", "tokens": ["Ab\u00b7dal\u00b7lahs", "ho\u00b7hen", "Ruhm", "mit", "eif\u00b7ri\u00b7gem", "Ge\u00b7be\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "APPR", "ADJA", "NN", "$."], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}}, "stanza.18": {"line.1": {"text": "Drauf hebt sich ein Gespr\u00e4ch von dessen Wundern an;", "tokens": ["Drauf", "hebt", "sich", "ein", "Ge\u00b7spr\u00e4ch", "von", "des\u00b7sen", "Wun\u00b7dern", "an", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PRF", "ART", "NN", "APPR", "PRELAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Da l\u00e4chelt der Vezier, und spricht zum Suliman:", "tokens": ["Da", "l\u00e4\u00b7chelt", "der", "Ve\u00b7zier", ",", "und", "spricht", "zum", "Su\u00b7li\u00b7man", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$,", "KON", "VVFIN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ich habe, gro\u00dfer Held, bereits vor vielen Jahren", "tokens": ["Ich", "ha\u00b7be", ",", "gro\u00b7\u00dfer", "Held", ",", "be\u00b7reits", "vor", "vie\u00b7len", "Jah\u00b7ren"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "$,", "ADJA", "NN", "$,", "ADV", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die schwerste Wissenschaft des Orients erfahren.", "tokens": ["Die", "schwers\u00b7te", "Wis\u00b7sen\u00b7schaft", "des", "O\u00b7rients", "er\u00b7fah\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Und welche? Die vielleicht kein Imam eingesehn,", "tokens": ["Und", "wel\u00b7che", "?", "Die", "viel\u00b7leicht", "kein", "I\u00b7mam", "ein\u00b7ge\u00b7sehn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAT", "$.", "ART", "ADV", "PIAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Kein Mufti lehren kann: Die V\u00f6gel zu verstehn.", "tokens": ["Kein", "Muf\u00b7ti", "leh\u00b7ren", "kann", ":", "Die", "V\u00f6\u00b7gel", "zu", "ver\u00b7stehn", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVINF", "VMFIN", "$.", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Der Schwanen Sterbelied, was Staar und Aelster schwatzen.", "tokens": ["Der", "Schwa\u00b7nen", "Ster\u00b7be\u00b7lied", ",", "was", "Staar", "und", "A\u00b7els\u00b7ter", "schwat\u00b7zen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$,", "PWS", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.8": {"text": "Der Adler heisern Ruf, die Strau\u00dfen und die Spatzen,", "tokens": ["Der", "Ad\u00b7ler", "hei\u00b7sern", "Ruf", ",", "die", "Strau\u00b7\u00dfen", "und", "die", "Spat\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$,", "ART", "NN", "KON", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Des Pelikans Geschrei, selbst des Humai", "tokens": ["Des", "Pe\u00b7li\u00b7kans", "Ge\u00b7schrei", ",", "selbst", "des", "Hu\u00b7mai"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "NN", "$,", "ADV", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "O Herr der K\u00f6nige! versteht dein Ibrahim.", "tokens": ["O", "Herr", "der", "K\u00f6\u00b7ni\u00b7ge", "!", "ver\u00b7steht", "dein", "Ib\u00b7ra\u00b7him", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NN", "ART", "NN", "$.", "VVFIN", "PPOSAT", "NE", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Ein Dervis hat mir das in Bagdad einst entdecket,", "tokens": ["Ein", "Der\u00b7vis", "hat", "mir", "das", "in", "Bag\u00b7dad", "einst", "ent\u00b7de\u00b7cket", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PDS", "VAFIN", "PPER", "ART", "APPR", "NE", "ADV", "VVFIN", "$,"], "meter": "--+--+-+-+-+-", "measure": "anapaest.di.plus"}, "line.12": {"text": "In dem Abdallahs Geist und Kraft zu Wundern stecket,", "tokens": ["In", "dem", "Ab\u00b7dal\u00b7lahs", "Geist", "und", "Kraft", "zu", "Wun\u00b7dern", "ste\u00b7cket", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "KON", "NN", "APPR", "NN", "VVFIN", "$,"], "meter": "--+--+-+-+-+-", "measure": "anapaest.di.plus"}, "line.13": {"text": "Der kennt den Alcoran; und der besitzt dabei", "tokens": ["Der", "kennt", "den", "Al\u00b7co\u00b7ran", ";", "und", "der", "be\u00b7sitzt", "da\u00b7bei"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "ART", "NN", "$.", "KON", "ART", "VVFIN", "PAV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Die etwas schwarze Kunst der Cabalisterei.", "tokens": ["Die", "et\u00b7was", "schwar\u00b7ze", "Kunst", "der", "Ca\u00b7ba\u00b7lis\u00b7te\u00b7rei", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "ADJA", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Die Probe f\u00e4llt mir leicht, und die soll nimmer tr\u00fcgen.", "tokens": ["Die", "Pro\u00b7be", "f\u00e4llt", "mir", "leicht", ",", "und", "die", "soll", "nim\u00b7mer", "tr\u00fc\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADJD", "$,", "KON", "PDS", "VMFIN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.19": {"line.1": {"text": "Der Sultan h\u00f6ret dies mit innigem Vergn\u00fcgen,", "tokens": ["Der", "Sul\u00b7tan", "h\u00f6\u00b7ret", "dies", "mit", "in\u00b7ni\u00b7gem", "Ver\u00b7gn\u00fc\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PDS", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Und kehrt bei Nacht zur\u00fcck; da ihn Dianens Schein", "tokens": ["Und", "kehrt", "bei", "Nacht", "zu\u00b7r\u00fcck", ";", "da", "ihn", "Di\u00b7a\u00b7nens", "Schein"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "NN", "PTKVZ", "$.", "KOUS", "PPER", "NE", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Zwo Eulen sehen l\u00e4\u00dft, die unaufh\u00f6rlich schrein.", "tokens": ["Zwo", "Eu\u00b7len", "se\u00b7hen", "l\u00e4\u00dft", ",", "die", "un\u00b7auf\u00b7h\u00f6r\u00b7lich", "schrein", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "VVINF", "VVFIN", "$,", "PRELS", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Auf! ruft er, Ibrahim, du wirst dich zeigen m\u00fcssen,", "tokens": ["Auf", "!", "ruft", "er", ",", "Ib\u00b7ra\u00b7him", ",", "du", "wirst", "dich", "zei\u00b7gen", "m\u00fcs\u00b7sen", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "$.", "VVFIN", "PPER", "$,", "NE", "$,", "PPER", "VAFIN", "PPER", "VVINF", "VMINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Was gibt's? Was wollen die? Ich mu\u00df es alles wissen.", "tokens": ["Was", "gibt's", "?", "Was", "wol\u00b7len", "die", "?", "Ich", "mu\u00df", "es", "al\u00b7les", "wis\u00b7sen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "$.", "PWS", "VMFIN", "ART", "$.", "PPER", "VMFIN", "PPER", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.20": {"line.1": {"text": "Der Gro\u00dfvezier gehorcht, und thut, als g\u00e4b' er Acht", "tokens": ["Der", "Gro\u00df\u00b7ve\u00b7zier", "ge\u00b7horcht", ",", "und", "thut", ",", "als", "g\u00e4b'", "er", "Acht"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVPP", "$,", "KON", "VVFIN", "$,", "KOUS", "VVFIN", "PPER", "CARD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Zu forschen, was allhier die V\u00f6gel schwatzen macht;", "tokens": ["Zu", "for\u00b7schen", ",", "was", "all\u00b7hier", "die", "V\u00f6\u00b7gel", "schwat\u00b7zen", "macht", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "$,", "PRELS", "ADV", "ART", "NN", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und endlich k\u00f6mmt er schnell, als h\u00f6chst best\u00fcrzt, zur\u00fccke.", "tokens": ["Und", "end\u00b7lich", "k\u00f6mmt", "er", "schnell", ",", "als", "h\u00f6chst", "be\u00b7st\u00fcrzt", ",", "zu\u00b7r\u00fc\u00b7cke", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "ADJD", "$,", "KOUS", "ADV", "ADJD", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "O, spricht er: da\u00df dein Reich der Mahomet begl\u00fccke!", "tokens": ["O", ",", "spricht", "er", ":", "da\u00df", "dein", "Reich", "der", "Ma\u00b7ho\u00b7met", "be\u00b7gl\u00fc\u00b7cke", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "VVFIN", "PPER", "$.", "KOUS", "PPOSAT", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Ich k\u00fcss' in tiefem Staub, Herr, deines Rockes Saum:", "tokens": ["Ich", "k\u00fcss'", "in", "tie\u00b7fem", "Staub", ",", "Herr", ",", "dei\u00b7nes", "Ro\u00b7ckes", "Saum", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ADJA", "NN", "$,", "NN", "$,", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Nur gib, dein Azem fleht, gib einer Bitte Raum.", "tokens": ["Nur", "gib", ",", "dein", "A\u00b7zem", "fleht", ",", "gib", "ei\u00b7ner", "Bit\u00b7te", "Raum", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVIMP", "$,", "PPOSAT", "NN", "VVFIN", "$,", "VVIMP", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Ver\u00e4ndre das Gebot: will ihm dein Wink befehlen,", "tokens": ["Ver\u00b7\u00e4nd\u00b7re", "das", "Ge\u00b7bot", ":", "will", "ihm", "dein", "Wink", "be\u00b7feh\u00b7len", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$.", "VMFIN", "PPER", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "So sei es, was er h\u00f6rt, dir ewig zu verhehlen,", "tokens": ["So", "sei", "es", ",", "was", "er", "h\u00f6rt", ",", "dir", "e\u00b7wig", "zu", "ver\u00b7heh\u00b7len", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "$,", "PWS", "PPER", "VVFIN", "$,", "PPER", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Und ...", "tokens": ["Und", "..."], "token_info": ["word", "punct"], "pos": ["KON", "$("], "meter": "+", "measure": "single.up"}}, "stanza.21": {"line.1": {"text": "Was du jetzt geh\u00f6rt, soll mir verborgen sein?", "tokens": ["Was", "du", "jetzt", "ge\u00b7h\u00f6rt", ",", "soll", "mir", "ver\u00b7bor\u00b7gen", "sein", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "VVFIN", "$,", "VMFIN", "PPER", "VVPP", "VAINF", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.2": {"text": "Mir! einem Suliman! Nein! bei dem Allah! nein.", "tokens": ["Mir", "!", "ei\u00b7nem", "Su\u00b7li\u00b7man", "!", "Nein", "!", "bei", "dem", "Al\u00b7lah", "!", "nein", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["NE", "$.", "ART", "NN", "$.", "PTKANT", "$.", "APPR", "ART", "NN", "$.", "PTKANT", "$."], "meter": "+--+---+-+-+", "measure": "dactylic.di.plus"}, "line.3": {"text": "Sag' an!", "tokens": ["Sag'", "an", "!"], "token_info": ["word", "word", "punct"], "pos": ["NN", "PTKVZ", "$."], "meter": "-+", "measure": "iambic.single"}}, "stanza.22": {"line.1": {"text": "Der ganze L\u00e4rm betrifft nur Heirathsachen.", "tokens": ["Der", "gan\u00b7ze", "L\u00e4rm", "be\u00b7tr\u00b7ifft", "nur", "Hei\u00b7rath\u00b7sa\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ADV", "NN", "$."], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Zween V\u00e4ter sind bem\u00fcht, den Mahlschatz auszumachen,", "tokens": ["Zween", "V\u00e4\u00b7ter", "sind", "be\u00b7m\u00fcht", ",", "den", "Mahl\u00b7schatz", "aus\u00b7zu\u00b7ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "NN", "VAFIN", "VVPP", "$,", "ART", "NN", "VVIZU", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Womit des einen Sohn, zu beider H\u00e4user Wohl,", "tokens": ["Wo\u00b7mit", "des", "ei\u00b7nen", "Sohn", ",", "zu", "bei\u00b7der", "H\u00e4u\u00b7ser", "Wohl", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ART", "NN", "$,", "APPR", "PIAT", "NN", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Des andern einzig Kind in kurzem freien soll.", "tokens": ["Des", "an\u00b7dern", "ein\u00b7zig", "Kind", "in", "kur\u00b7zem", "frei\u00b7en", "soll", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJD", "NN", "APPR", "ADJA", "ADJA", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Er mu\u00df, spricht dieser Greis, vor allen andern Dingen", "tokens": ["Er", "mu\u00df", ",", "spricht", "die\u00b7ser", "Greis", ",", "vor", "al\u00b7len", "an\u00b7dern", "Din\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "$,", "VVFIN", "PDAT", "NN", "$,", "APPR", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Der Braut ein Heirathgut von f\u00fcnfzig D\u00f6rfern bringen,", "tokens": ["Der", "Braut", "ein", "Hei\u00b7rath\u00b7gut", "von", "f\u00fcnf\u00b7zig", "D\u00f6r\u00b7fern", "brin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "APPR", "CARD", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Nebst einer w\u00fcsten Stadt, die, raubt der Tod den Mann,", "tokens": ["Nebst", "ei\u00b7ner", "w\u00fcs\u00b7ten", "Stadt", ",", "die", ",", "raubt", "der", "Tod", "den", "Mann", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,", "PRELS", "$,", "VVFIN", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Ihr Wittwensitz verbleibt. Und wie? (hebt jener an)", "tokens": ["Ihr", "Witt\u00b7wen\u00b7sitz", "ver\u00b7bleibt", ".", "Und", "wie", "?", "(", "hebt", "je\u00b7ner", "an", ")"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "$.", "KON", "PWAV", "$.", "$(", "VVFIN", "PDS", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Nur f\u00fcnfzig? O wie leicht ist dieses einzugehen!", "tokens": ["Nur", "f\u00fcnf\u00b7zig", "?", "O", "wie", "leicht", "ist", "die\u00b7ses", "ein\u00b7zu\u00b7ge\u00b7hen", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "CARD", "$.", "NE", "KOKOM", "ADJD", "VAFIN", "PDAT", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Zweihundert sollen dir, mein Freund, zu Diensten stehen.", "tokens": ["Zwei\u00b7hun\u00b7dert", "sol\u00b7len", "dir", ",", "mein", "Freund", ",", "zu", "Diens\u00b7ten", "ste\u00b7hen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["CARD", "VMFIN", "PPER", "$,", "PPOSAT", "NN", "$,", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Seit des Propheten Flucht war keine bess're Zeit:", "tokens": ["Seit", "des", "Pro\u00b7phe\u00b7ten", "Flucht", "war", "kei\u00b7ne", "bess'\u00b7re", "Zeit", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "VAFIN", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Der Janitschar verheert die L\u00e4nder weit und breit.", "tokens": ["Der", "Ja\u00b7nit\u00b7schar", "ver\u00b7heert", "die", "L\u00e4n\u00b7der", "weit", "und", "breit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Es lebe Suliman! er m\u00fcsse lange leben!", "tokens": ["Es", "le\u00b7be", "Su\u00b7li\u00b7man", "!", "er", "m\u00fcs\u00b7se", "lan\u00b7ge", "le\u00b7ben", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NE", "$.", "PPER", "VMFIN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "So wird uns jedes Jahr schon W\u00fcsteneien geben.", "tokens": ["So", "wird", "uns", "je\u00b7des", "Jahr", "schon", "W\u00fcs\u00b7te\u00b7nei\u00b7en", "ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PIAT", "NN", "ADV", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.23": {"line.1": {"text": "Hier schweiget der Vezier: der Kaiser merkt es sich;", "tokens": ["Hier", "schwei\u00b7get", "der", "Ve\u00b7zier", ":", "der", "Kai\u00b7ser", "merkt", "es", "sich", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$.", "ART", "NN", "VVFIN", "PPER", "PRF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Er wei\u00df ihm heimlich Dank, und folgt ihm \u00f6ffentlich,", "tokens": ["Er", "wei\u00df", "ihm", "heim\u00b7lich", "Dank", ",", "und", "folgt", "ihm", "\u00f6f\u00b7fent\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADJD", "NN", "$,", "KON", "VVFIN", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Beschleu\u00dft, der Menschen Werth nie weiter zu vergessen,", "tokens": ["Be\u00b7schleu\u00dft", ",", "der", "Men\u00b7schen", "Werth", "nie", "wei\u00b7ter", "zu", "ver\u00b7ges\u00b7sen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "ART", "NN", "NN", "ADV", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und lernt der L\u00e4nder Heil nicht nach den Siegen messen.", "tokens": ["Und", "lernt", "der", "L\u00e4n\u00b7der", "Heil", "nicht", "nach", "den", "Sie\u00b7gen", "mes\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "NN", "PTKNEG", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.24": {"line.1": {"text": "Ein guter Rath ist immer gut;", "tokens": ["Ein", "gu\u00b7ter", "Rath", "ist", "im\u00b7mer", "gut", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Doch lerne man die Wahrheit kl\u00fcglich sagen.", "tokens": ["Doch", "ler\u00b7ne", "man", "die", "Wahr\u00b7heit", "kl\u00fcg\u00b7lich", "sa\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIS", "ART", "NN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Der Lehren Kraft und Gl\u00fcck beruht", "tokens": ["Der", "Leh\u00b7ren", "Kraft", "und", "Gl\u00fcck", "be\u00b7ruht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "NN", "KON", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Nur auf der Kunst, sie vorzutragen.", "tokens": ["Nur", "auf", "der", "Kunst", ",", "sie", "vor\u00b7zu\u00b7tra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "$,", "PPER", "VVIZU", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}