{"dta.poem.3927": {"metadata": {"author": {"name": "Spindler, Christian Gotthold", "birth": "N.A.", "death": "N.A."}, "title": "22) Schreiben an einen Freund,  \n dem er Neuigkeiten \u00fcbersendete.", "genre": "Lyrik, Drama", "period": "N.A.", "pub_year": "1745", "urn": "urn:nbn:de:kobv:b4-20581-9", "language": ["de:0.99"], "booktitle": "Spindler, Christian Gotthold: Unschuldige Jugend-Fr\u00fcchte. Leipzig, 1745."}, "poem": {"stanza.1": {"line.1": {"text": "Ein neues Zeitungs-Blat,", "tokens": ["Ein", "neu\u00b7es", "Zei\u00b7tungs\u00b7Blat", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Das mich vergn\u00fcget hat,", "tokens": ["Das", "mich", "ver\u00b7gn\u00fc\u00b7get", "hat", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "VVFIN", "VAFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ist bey mir angekommen,", "tokens": ["Ist", "bey", "mir", "an\u00b7ge\u00b7kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "PPER", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Da ich dein Diener bin,", "tokens": ["Da", "ich", "dein", "Die\u00b7ner", "bin", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "VAFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Schick ich dir solches hin,", "tokens": ["Schick", "ich", "dir", "sol\u00b7ches", "hin", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "PPER", "PIS", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Du wilst, wie ich vernommen,", "tokens": ["Du", "wilst", ",", "wie", "ich", "ver\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "$,", "PWAV", "PPER", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Auch balde bey mir seyn;", "tokens": ["Auch", "bal\u00b7de", "bey", "mir", "seyn", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "PPER", "VAINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "O Freund! sprich morgen ein,", "tokens": ["O", "Freund", "!", "sprich", "mor\u00b7gen", "ein", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$.", "ADV", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "Erquicke Geist und Glieder,", "tokens": ["Er\u00b7qui\u00b7cke", "Geist", "und", "Glie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.10": {"text": "Bring meine Zeitung wieder.", "tokens": ["Bring", "mei\u00b7ne", "Zei\u00b7tung", "wie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "ADV", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.11": {"text": "Ich aber bin zum Schlu\u00df,", "tokens": ["Ich", "a\u00b7ber", "bin", "zum", "Schlu\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VAFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.12": {"text": "Dein treuer ", "tokens": ["Dein", "treu\u00b7er"], "token_info": ["word", "word"], "pos": ["PPOSAT", "ADJA"], "meter": "-+-", "measure": "amphibrach.single"}}, "stanza.2": {"line.1": {"text": "Da\u00df itzung Winters-Zeit/ ist aller Welt bekannt,", "tokens": ["Da\u00df", "it\u00b7zung", "Win\u00b7ter\u00b7sZeit", "/", "ist", "al\u00b7ler", "Welt", "be\u00b7kannt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "NN", "$(", "VAFIN", "PIAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und mir absonderlich, weil ich viel Holtz ver-", "tokens": ["Und", "mir", "ab\u00b7son\u00b7der\u00b7lich", ",", "weil", "ich", "viel", "Holtz", "ver"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "ADJD", "$,", "KOUS", "PPER", "PIAT", "NN", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "brannt.", "tokens": ["brannt", "."], "token_info": ["word", "punct"], "pos": ["VVFIN", "$."], "meter": "-", "measure": "single.down"}, "line.4": {"text": "Indessen h\u00f6ret man aus ", "tokens": ["In\u00b7des\u00b7sen", "h\u00f6\u00b7ret", "man", "aus"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PIS", "APPR"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.5": {"text": "Da\u00df sich was seltsames daselbsten zugetragen;", "tokens": ["Da\u00df", "sich", "was", "selt\u00b7sa\u00b7mes", "da\u00b7selbs\u00b7ten", "zu\u00b7ge\u00b7tra\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "PWS", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und weil man solchen Fall nicht alle Tage hat,", "tokens": ["Und", "weil", "man", "sol\u00b7chen", "Fall", "nicht", "al\u00b7le", "Ta\u00b7ge", "hat", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PIS", "PIAT", "NN", "PTKNEG", "PIAT", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "So lese, wer es sieht, hier dieses kurtze Blat:", "tokens": ["So", "le\u00b7se", ",", "wer", "es", "sieht", ",", "hier", "die\u00b7ses", "kurt\u00b7ze", "Blat", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "PWS", "PPER", "VVFIN", "$,", "ADV", "PDAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "So bald das neue Jahr, der Jenner, angekommen,", "tokens": ["So", "bald", "das", "neu\u00b7e", "Jahr", ",", "der", "Jen\u00b7ner", ",", "an\u00b7ge\u00b7kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "ADV", "ART", "ADJA", "NN", "$,", "ART", "NN", "$,", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Hat auch die K\u00e4lt und Frost erschrecklich zugenom\u0303en;", "tokens": ["Hat", "auch", "die", "K\u00e4lt", "und", "Frost", "er\u00b7schreck\u00b7lich", "zu\u00b7ge\u00b7nom\u0303en", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "KON", "NN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die F\u00fcchse sturben weg, die W\u00f6lffe wurden zahm,", "tokens": ["Die", "F\u00fcch\u00b7se", "stur\u00b7ben", "weg", ",", "die", "W\u00f6lf\u00b7fe", "wur\u00b7den", "zahm", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "$,", "ART", "NN", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So, da\u00df man Peltz genung von solchem Vieh bekam.", "tokens": ["So", ",", "da\u00df", "man", "Peltz", "ge\u00b7nung", "von", "sol\u00b7chem", "Vieh", "be\u00b7kam", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "PIS", "NN", "ADV", "APPR", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}