{"textgrid.poem.52330": {"metadata": {"author": {"name": "Reuter, Fritz", "birth": "N.A.", "death": "N.A."}, "title": "1.", "genre": "verse", "period": "N.A.", "pub_year": 1842, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Nicks geiht \u00e4wer v\u00f6rnem Wesen!", "tokens": ["Nicks", "geiht", "\u00e4\u00b7wer", "v\u00f6r\u00b7nem", "We\u00b7sen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADJD", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Beten Schriwen, beten Lesen", "tokens": ["Be\u00b7ten", "Schri\u00b7wen", ",", "be\u00b7ten", "Le\u00b7sen"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ADJA", "NN", "$,", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Un de Bibel af un an", "tokens": ["Un", "de", "Bi\u00b7bel", "af", "un", "an"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Lihrt ok woll de Bursmann;", "tokens": ["Lihrt", "ok", "woll", "de", "Burs\u00b7mann", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "ADV", "NE", "NE", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.5": {"text": "Mit de H\u00f6flichkeit, dor weit", "tokens": ["Mit", "de", "H\u00f6f\u00b7lich\u00b7keit", ",", "dor", "weit"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "NE", "NN", "$,", "ADV", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Blot de Eddelmann Bescheid.", "tokens": ["Blot", "de", "Ed\u00b7del\u00b7mann", "Be\u00b7scheid", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "NE", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "All von l\u00fctt up ward dat tagen,", "tokens": ["All", "von", "l\u00fctt", "up", "ward", "dat", "ta\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NE", "NE", "VAFIN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sick recht h\u00f6flich tau bedragen.", "tokens": ["Sick", "recht", "h\u00f6f\u00b7lich", "tau", "be\u00b7dra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ADV", "ADJD", "ADJD", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Dat m\u00f6t glik franz\u00f6sch parlieren,", "tokens": ["Dat", "m\u00f6t", "glik", "fran\u00b7z\u00f6sch", "par\u00b7lie\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "In de Weig' all danzen lihren,", "tokens": ["In", "de", "Weig'", "all", "dan\u00b7zen", "lih\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "NE", "PIAT", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Kratzfaut maken, Reverenz,", "tokens": ["Kratz\u00b7faut", "ma\u00b7ken", ",", "Re\u00b7ve\u00b7renz", ","], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["NN", "VVINF", "$,", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Dat du kriggst de Swenzelenz!", "tokens": ["Dat", "du", "kriggst", "de", "Swen\u00b7ze\u00b7lenz", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "VVFIN", "NE", "NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Was mal ens en Herr von Degen;", "tokens": ["Was", "mal", "ens", "en", "Herr", "von", "De\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "ADV", "ADJA", "NN", "APPR", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "As hei Vaders Gaud hadd kregen,", "tokens": ["As", "hei", "Va\u00b7ders", "Gaud", "hadd", "kre\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Hett hei sick 'ne Fru ok namen,", "tokens": ["Hett", "hei", "sick", "'ne", "Fru", "ok", "na\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM", "FM", "FM", "FM", "FM", "FM", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Is ok bald en Junker kamen.", "tokens": ["Is", "ok", "bald", "en", "Jun\u00b7ker", "ka\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "ADV", "NE", "NE", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "De kamm, as sie mi vertellt,", "tokens": ["De", "kamm", ",", "as", "sie", "mi", "ver\u00b7tellt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "$,", "PRELS", "PPER", "NE", "VVFIN", "$,"], "meter": "-+-++-+", "measure": "unknown.measure.tetra"}, "line.6": {"text": "Mit en Sn\u00fcrliw up de Welt.", "tokens": ["Mit", "en", "Sn\u00fcr\u00b7liw", "up", "de", "Welt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "FM", "FM", "FM", "FM", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Hei ward nu nah allen Kanten", "tokens": ["Hei", "ward", "nu", "nah", "al\u00b7len", "Kan\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "VAFIN", "ADV", "ADJD", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Von Bekannten un Verwandten,", "tokens": ["Von", "Be\u00b7kann\u00b7ten", "un", "Ver\u00b7wand\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "FM", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Von de kl\u00e4uksten Guwernanten", "tokens": ["Von", "de", "kl\u00e4uks\u00b7ten", "Gu\u00b7wern\u00b7an\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NE", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Un von s\u00e4hen olle Tanten,", "tokens": ["Un", "von", "s\u00e4\u00b7hen", "ol\u00b7le", "Tan\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ADJA", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Adelig heruteputzt", "tokens": ["A\u00b7de\u00b7lig", "he\u00b7ru\u00b7te\u00b7putzt"], "token_info": ["word", "word"], "pos": ["ADJD", "VVPP"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Un taum smucken Junker stutzt.", "tokens": ["Un", "taum", "smu\u00b7cken", "Jun\u00b7ker", "stutzt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "VVFIN", "NE", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "As uns' Junker nu w\u00fcrd gr\u00f6ter,", "tokens": ["As", "un\u00b7s'", "Jun\u00b7ker", "nu", "w\u00fcrd", "gr\u00f6\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "NE", "ADV", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "All de H\u00f6flichkeit verget 'e:", "tokens": ["All", "de", "H\u00f6f\u00b7lich\u00b7keit", "ver\u00b7get", "'e", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "VVFIN", "NE", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Hei lep v\u00f6r de Guwernanten", "tokens": ["Hei", "lep", "v\u00f6r", "de", "Gu\u00b7wern\u00b7an\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["FM", "FM", "FM", "FM", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Un v\u00f6r sine s\u00e4ben Tanten", "tokens": ["Un", "v\u00f6r", "si\u00b7ne", "s\u00e4\u00b7ben", "Tan\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["FM", "FM", "FM", "FM", "NN"], "meter": "+---+-+-", "measure": "dactylic.init"}, "line.5": {"text": "Un lep in den Pirdstall rin,", "tokens": ["Un", "lep", "in", "den", "Pird\u00b7stall", "rin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "APPR", "ART", "NN", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Drew sick mit de Stallknechts r\u00fcm.", "tokens": ["Drew", "sick", "mit", "de", "Stall\u00b7knechts", "r\u00fcm", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Bald w\u00fcrd hei denn ehres Gliken,", "tokens": ["Bald", "w\u00fcrd", "hei", "denn", "eh\u00b7res", "Gli\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "NE", "KON", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "W\u00fcrd sihr nah den Pirdstall r\u00fcken,", "tokens": ["W\u00fcrd", "sihr", "nah", "den", "Pird\u00b7stall", "r\u00fc\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADJD", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Un de gned'ge Fru Mama", "tokens": ["Un", "de", "gne\u00b7d'\u00b7ge", "Fru", "Ma\u00b7ma"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "NE", "ADJA", "NN", "NN"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.4": {"text": "S\u00e4d taum gned'gen Herrn Papa:", "tokens": ["S\u00e4d", "taum", "gne\u00b7d'\u00b7gen", "Herrn", "Pa\u00b7pa", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "\u00bbsetz dich hier mal zu mir her;", "tokens": ["\u00bb", "setz", "dich", "hier", "mal", "zu", "mir", "her", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVIMP", "PPER", "ADV", "ADV", "APPR", "PPER", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Sag', was meinst du woll, mon cher,", "tokens": ["Sag'", ",", "was", "meinst", "du", "woll", ",", "mon", "cher", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "PWS", "VVFIN", "PPER", "VMFIN", "$,", "NE", "NE", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}}, "stanza.7": {"line.1": {"text": "W\u00e4r' es jetzo woll nich Zeit,", "tokens": ["W\u00e4r'", "es", "jet\u00b7zo", "woll", "nich", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ADV", "PTKNEG", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Da\u00df er noch mehr H\u00f6flichkeit", "tokens": ["Da\u00df", "er", "noch", "mehr", "H\u00f6f\u00b7lich\u00b7keit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "PIAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Lerne und franz\u00f6sch parlieren", "tokens": ["Ler\u00b7ne", "und", "fran\u00b7z\u00f6sch", "par\u00b7lie\u00b7ren"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "KON", "ADJD", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und franz\u00f6sische Manieren?\u00ab", "tokens": ["Und", "fran\u00b7z\u00f6\u00b7si\u00b7sche", "Ma\u00b7nie\u00b7ren", "?", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["KON", "ADJA", "NN", "$.", "$("], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Herr von Degen seggt: \u00bbAuf Ehr!", "tokens": ["Herr", "von", "De\u00b7gen", "seggt", ":", "\u00bb", "Auf", "Ehr", "!"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "VVFIN", "$.", "$(", "APPR", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Du hast immer recht, ma ch\u00e8re.\u00ab", "tokens": ["Du", "hast", "im\u00b7mer", "recht", ",", "ma", "ch\u00e8\u00b7re", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "$,", "NE", "NE", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Nu w\u00fcrd denn f\u00f6r hogen Lohn", "tokens": ["Nu", "w\u00fcrd", "denn", "f\u00f6r", "ho\u00b7gen", "Lohn"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ADV", "ADJD", "ADJA", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Richtig 'ne franz\u00f6sch Person", "tokens": ["Rich\u00b7tig", "'ne", "fran\u00b7z\u00f6sch", "Per\u00b7son"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJD", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ut en fr\u00f6mden Land verschrewen", "tokens": ["Ut", "en", "fr\u00f6m\u00b7den", "Land", "ver\u00b7schre\u00b7wen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "NE", "ADJA", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Un de Bildung stark bedrewen.", "tokens": ["Un", "de", "Bil\u00b7dung", "stark", "be\u00b7dre\u00b7wen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "NN", "ADJD", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Fru von Degen seggt: \u00bbAuf Ehr!", "tokens": ["Fru", "von", "De\u00b7gen", "seggt", ":", "\u00bb", "Auf", "Ehr", "!"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "VVFIN", "$.", "$(", "APPR", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Magniperbement, mon eher.\u00ab", "tokens": ["Mag\u00b7ni\u00b7per\u00b7be\u00b7ment", ",", "mon", "e\u00b7her", ".", "\u00ab"], "token_info": ["word", "punct", "word", "word", "punct", "punct"], "pos": ["NN", "$,", "NE", "ADV", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Einmal gaww denn ok von wegen", "tokens": ["Ein\u00b7mal", "gaww", "denn", "ok", "von", "we\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "KON", "NE", "APPR", "APPR"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Festdag unse Herr von Degen", "tokens": ["Fest\u00b7dag", "un\u00b7se", "Herr", "von", "De\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "PPOSAT", "NN", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "En gef\u00e4hrlich Middageten;", "tokens": ["En", "ge\u00b7f\u00e4hr\u00b7lich", "Mid\u00b7da\u00b7ge\u00b7ten", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "ADJD", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Junker Korl hett ok dor seten,", "tokens": ["Jun\u00b7ker", "Korl", "hett", "ok", "dor", "se\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VAFIN", "NE", "NE", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Un satt dor in gaude Ruh,", "tokens": ["Un", "satt", "dor", "in", "gau\u00b7de", "Ruh", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADJD", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Bi em Mamsell Parlewuh.", "tokens": ["Bi", "em", "Mam\u00b7sell", "Par\u00b7le\u00b7wuh", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "De Mama fung an tau lawen,", "tokens": ["De", "Ma\u00b7ma", "fung", "an", "tau", "la\u00b7wen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM", "FM", "NN", "APPR", "NE", "VVINF", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.2": {"text": "Wat ehr Junker hadd f\u00f6r Gawen", "tokens": ["Wat", "ehr", "Jun\u00b7ker", "hadd", "f\u00f6r", "Ga\u00b7wen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.3": {"text": "Un wat saubere Manieren", "tokens": ["Un", "wat", "sau\u00b7be\u00b7re", "Ma\u00b7nie\u00b7ren"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "VVFIN", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Un wat hei franz\u00f6sch ded lihren.", "tokens": ["Un", "wat", "hei", "fran\u00b7z\u00f6sch", "ded", "lih\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Korl satt dor as in'n D\u00e4s',", "tokens": ["Korl", "satt", "dor", "as", "in'n", "D\u00e4s'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Mit 'ne lange, snappig N\u00e4s'.", "tokens": ["Mit", "'", "ne", "lan\u00b7ge", ",", "snap\u00b7pig", "N\u00e4s", "'", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["APPR", "$(", "NE", "ADV", "$,", "ADJD", "NN", "$(", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Dit sach Mamsell Parlewuh,", "tokens": ["Dit", "sach", "Mam\u00b7sell", "Par\u00b7le\u00b7wuh", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "NN", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Weckte em ut sine Ruh:", "tokens": ["Weck\u00b7te", "em", "ut", "si\u00b7ne", "Ruh", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.3": {"text": "\u00bbmonsieur Charles, mouchez-vous!\u00ab", "tokens": ["\u00bb", "mon\u00b7si\u00b7eur", "Char\u00b7les", ",", "mou\u00b7che\u00b7zvous", "!", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "word", "punct", "punct"], "pos": ["$(", "FM.fr", "FM.fr", "$,", "NE", "$.", "$("], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.4": {"text": "\u00bbje! s\u00fch! kik! Wat, mouchez-vous?", "tokens": ["\u00bb", "je", "!", "s\u00fch", "!", "kik", "!", "Wat", ",", "mou\u00b7che\u00b7zvous", "?"], "token_info": ["punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["$(", "ADV", "$.", "ADJD", "$.", "NN", "$.", "NN", "$,", "NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Sei is ok woll nich recht klauk?", "tokens": ["Sei", "is", "ok", "woll", "nich", "recht", "klauk", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "FM", "FM", "ADV", "PTKNEG", "ADJD", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Heww'ck ok all en Snuwdauk?\u00ab", "tokens": ["Hew\u00b7w'ck", "ok", "all", "en", "Snuw\u00b7dauk", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "NE", "PIAT", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "Nicks geiht \u00e4wer v\u00f6rnem Wesen!", "tokens": ["Nicks", "geiht", "\u00e4\u00b7wer", "v\u00f6r\u00b7nem", "We\u00b7sen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADJD", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Beten Schriwen, beten Lesen", "tokens": ["Be\u00b7ten", "Schri\u00b7wen", ",", "be\u00b7ten", "Le\u00b7sen"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ADJA", "NN", "$,", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Un de Bibel af un an", "tokens": ["Un", "de", "Bi\u00b7bel", "af", "un", "an"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Lihrt ok woll de Bursmann;", "tokens": ["Lihrt", "ok", "woll", "de", "Burs\u00b7mann", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "ADV", "NE", "NE", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.5": {"text": "Mit de H\u00f6flichkeit, dor weit", "tokens": ["Mit", "de", "H\u00f6f\u00b7lich\u00b7keit", ",", "dor", "weit"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "NE", "NN", "$,", "ADV", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Blot de Eddelmann Bescheid.", "tokens": ["Blot", "de", "Ed\u00b7del\u00b7mann", "Be\u00b7scheid", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "NE", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "All von l\u00fctt up ward dat tagen,", "tokens": ["All", "von", "l\u00fctt", "up", "ward", "dat", "ta\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NE", "NE", "VAFIN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sick recht h\u00f6flich tau bedragen.", "tokens": ["Sick", "recht", "h\u00f6f\u00b7lich", "tau", "be\u00b7dra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ADV", "ADJD", "ADJD", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Dat m\u00f6t glik franz\u00f6sch parlieren,", "tokens": ["Dat", "m\u00f6t", "glik", "fran\u00b7z\u00f6sch", "par\u00b7lie\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "In de Weig' all danzen lihren,", "tokens": ["In", "de", "Weig'", "all", "dan\u00b7zen", "lih\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "NE", "PIAT", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Kratzfaut maken, Reverenz,", "tokens": ["Kratz\u00b7faut", "ma\u00b7ken", ",", "Re\u00b7ve\u00b7renz", ","], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["NN", "VVINF", "$,", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Dat du kriggst de Swenzelenz!", "tokens": ["Dat", "du", "kriggst", "de", "Swen\u00b7ze\u00b7lenz", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "VVFIN", "NE", "NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "Was mal ens en Herr von Degen;", "tokens": ["Was", "mal", "ens", "en", "Herr", "von", "De\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "ADV", "ADJA", "NN", "APPR", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "As hei Vaders Gaud hadd kregen,", "tokens": ["As", "hei", "Va\u00b7ders", "Gaud", "hadd", "kre\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Hett hei sick 'ne Fru ok namen,", "tokens": ["Hett", "hei", "sick", "'ne", "Fru", "ok", "na\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM", "FM", "FM", "FM", "FM", "FM", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Is ok bald en Junker kamen.", "tokens": ["Is", "ok", "bald", "en", "Jun\u00b7ker", "ka\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "ADV", "NE", "NE", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "De kamm, as sie mi vertellt,", "tokens": ["De", "kamm", ",", "as", "sie", "mi", "ver\u00b7tellt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "$,", "PRELS", "PPER", "NE", "VVFIN", "$,"], "meter": "-+-++-+", "measure": "unknown.measure.tetra"}, "line.6": {"text": "Mit en Sn\u00fcrliw up de Welt.", "tokens": ["Mit", "en", "Sn\u00fcr\u00b7liw", "up", "de", "Welt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "FM", "FM", "FM", "FM", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.15": {"line.1": {"text": "Hei ward nu nah allen Kanten", "tokens": ["Hei", "ward", "nu", "nah", "al\u00b7len", "Kan\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "VAFIN", "ADV", "ADJD", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Von Bekannten un Verwandten,", "tokens": ["Von", "Be\u00b7kann\u00b7ten", "un", "Ver\u00b7wand\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "FM", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Von de kl\u00e4uksten Guwernanten", "tokens": ["Von", "de", "kl\u00e4uks\u00b7ten", "Gu\u00b7wern\u00b7an\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NE", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Un von s\u00e4hen olle Tanten,", "tokens": ["Un", "von", "s\u00e4\u00b7hen", "ol\u00b7le", "Tan\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ADJA", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Adelig heruteputzt", "tokens": ["A\u00b7de\u00b7lig", "he\u00b7ru\u00b7te\u00b7putzt"], "token_info": ["word", "word"], "pos": ["ADJD", "VVPP"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Un taum smucken Junker stutzt.", "tokens": ["Un", "taum", "smu\u00b7cken", "Jun\u00b7ker", "stutzt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "VVFIN", "NE", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.16": {"line.1": {"text": "As uns' Junker nu w\u00fcrd gr\u00f6ter,", "tokens": ["As", "un\u00b7s'", "Jun\u00b7ker", "nu", "w\u00fcrd", "gr\u00f6\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "NE", "ADV", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "All de H\u00f6flichkeit verget 'e:", "tokens": ["All", "de", "H\u00f6f\u00b7lich\u00b7keit", "ver\u00b7get", "'e", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "VVFIN", "NE", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Hei lep v\u00f6r de Guwernanten", "tokens": ["Hei", "lep", "v\u00f6r", "de", "Gu\u00b7wern\u00b7an\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["FM", "FM", "FM", "FM", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Un v\u00f6r sine s\u00e4ben Tanten", "tokens": ["Un", "v\u00f6r", "si\u00b7ne", "s\u00e4\u00b7ben", "Tan\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["FM", "FM", "FM", "FM", "NN"], "meter": "+---+-+-", "measure": "dactylic.init"}, "line.5": {"text": "Un lep in den Pirdstall rin,", "tokens": ["Un", "lep", "in", "den", "Pird\u00b7stall", "rin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "APPR", "ART", "NN", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Drew sick mit de Stallknechts r\u00fcm.", "tokens": ["Drew", "sick", "mit", "de", "Stall\u00b7knechts", "r\u00fcm", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.17": {"line.1": {"text": "Bald w\u00fcrd hei denn ehres Gliken,", "tokens": ["Bald", "w\u00fcrd", "hei", "denn", "eh\u00b7res", "Gli\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "NE", "KON", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "W\u00fcrd sihr nah den Pirdstall r\u00fcken,", "tokens": ["W\u00fcrd", "sihr", "nah", "den", "Pird\u00b7stall", "r\u00fc\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADJD", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Un de gned'ge Fru Mama", "tokens": ["Un", "de", "gne\u00b7d'\u00b7ge", "Fru", "Ma\u00b7ma"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "NE", "ADJA", "NN", "NN"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.4": {"text": "S\u00e4d taum gned'gen Herrn Papa:", "tokens": ["S\u00e4d", "taum", "gne\u00b7d'\u00b7gen", "Herrn", "Pa\u00b7pa", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "\u00bbsetz dich hier mal zu mir her;", "tokens": ["\u00bb", "setz", "dich", "hier", "mal", "zu", "mir", "her", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVIMP", "PPER", "ADV", "ADV", "APPR", "PPER", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Sag', was meinst du woll, mon cher,", "tokens": ["Sag'", ",", "was", "meinst", "du", "woll", ",", "mon", "cher", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "PWS", "VVFIN", "PPER", "VMFIN", "$,", "NE", "NE", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}}, "stanza.18": {"line.1": {"text": "W\u00e4r' es jetzo woll nich Zeit,", "tokens": ["W\u00e4r'", "es", "jet\u00b7zo", "woll", "nich", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ADV", "PTKNEG", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Da\u00df er noch mehr H\u00f6flichkeit", "tokens": ["Da\u00df", "er", "noch", "mehr", "H\u00f6f\u00b7lich\u00b7keit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "PIAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Lerne und franz\u00f6sch parlieren", "tokens": ["Ler\u00b7ne", "und", "fran\u00b7z\u00f6sch", "par\u00b7lie\u00b7ren"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "KON", "ADJD", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und franz\u00f6sische Manieren?\u00ab", "tokens": ["Und", "fran\u00b7z\u00f6\u00b7si\u00b7sche", "Ma\u00b7nie\u00b7ren", "?", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["KON", "ADJA", "NN", "$.", "$("], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Herr von Degen seggt: \u00bbAuf Ehr!", "tokens": ["Herr", "von", "De\u00b7gen", "seggt", ":", "\u00bb", "Auf", "Ehr", "!"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "VVFIN", "$.", "$(", "APPR", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Du hast immer recht, ma ch\u00e8re.\u00ab", "tokens": ["Du", "hast", "im\u00b7mer", "recht", ",", "ma", "ch\u00e8\u00b7re", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "$,", "NE", "NE", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.19": {"line.1": {"text": "Nu w\u00fcrd denn f\u00f6r hogen Lohn", "tokens": ["Nu", "w\u00fcrd", "denn", "f\u00f6r", "ho\u00b7gen", "Lohn"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ADV", "ADJD", "ADJA", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Richtig 'ne franz\u00f6sch Person", "tokens": ["Rich\u00b7tig", "'ne", "fran\u00b7z\u00f6sch", "Per\u00b7son"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJD", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ut en fr\u00f6mden Land verschrewen", "tokens": ["Ut", "en", "fr\u00f6m\u00b7den", "Land", "ver\u00b7schre\u00b7wen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "NE", "ADJA", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Un de Bildung stark bedrewen.", "tokens": ["Un", "de", "Bil\u00b7dung", "stark", "be\u00b7dre\u00b7wen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "NN", "ADJD", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Fru von Degen seggt: \u00bbAuf Ehr!", "tokens": ["Fru", "von", "De\u00b7gen", "seggt", ":", "\u00bb", "Auf", "Ehr", "!"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "VVFIN", "$.", "$(", "APPR", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Magniperbement, mon eher.\u00ab", "tokens": ["Mag\u00b7ni\u00b7per\u00b7be\u00b7ment", ",", "mon", "e\u00b7her", ".", "\u00ab"], "token_info": ["word", "punct", "word", "word", "punct", "punct"], "pos": ["NN", "$,", "NE", "ADV", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.20": {"line.1": {"text": "Einmal gaww denn ok von wegen", "tokens": ["Ein\u00b7mal", "gaww", "denn", "ok", "von", "we\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "KON", "NE", "APPR", "APPR"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Festdag unse Herr von Degen", "tokens": ["Fest\u00b7dag", "un\u00b7se", "Herr", "von", "De\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "PPOSAT", "NN", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "En gef\u00e4hrlich Middageten;", "tokens": ["En", "ge\u00b7f\u00e4hr\u00b7lich", "Mid\u00b7da\u00b7ge\u00b7ten", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "ADJD", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Junker Korl hett ok dor seten,", "tokens": ["Jun\u00b7ker", "Korl", "hett", "ok", "dor", "se\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VAFIN", "NE", "NE", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Un satt dor in gaude Ruh,", "tokens": ["Un", "satt", "dor", "in", "gau\u00b7de", "Ruh", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADJD", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Bi em Mamsell Parlewuh.", "tokens": ["Bi", "em", "Mam\u00b7sell", "Par\u00b7le\u00b7wuh", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.21": {"line.1": {"text": "De Mama fung an tau lawen,", "tokens": ["De", "Ma\u00b7ma", "fung", "an", "tau", "la\u00b7wen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM", "FM", "NN", "APPR", "NE", "VVINF", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.2": {"text": "Wat ehr Junker hadd f\u00f6r Gawen", "tokens": ["Wat", "ehr", "Jun\u00b7ker", "hadd", "f\u00f6r", "Ga\u00b7wen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.3": {"text": "Un wat saubere Manieren", "tokens": ["Un", "wat", "sau\u00b7be\u00b7re", "Ma\u00b7nie\u00b7ren"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "VVFIN", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Un wat hei franz\u00f6sch ded lihren.", "tokens": ["Un", "wat", "hei", "fran\u00b7z\u00f6sch", "ded", "lih\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Korl satt dor as in'n D\u00e4s',", "tokens": ["Korl", "satt", "dor", "as", "in'n", "D\u00e4s'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Mit 'ne lange, snappig N\u00e4s'.", "tokens": ["Mit", "'", "ne", "lan\u00b7ge", ",", "snap\u00b7pig", "N\u00e4s", "'", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["APPR", "$(", "NE", "ADV", "$,", "ADJD", "NN", "$(", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.22": {"line.1": {"text": "Dit sach Mamsell Parlewuh,", "tokens": ["Dit", "sach", "Mam\u00b7sell", "Par\u00b7le\u00b7wuh", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "NN", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Weckte em ut sine Ruh:", "tokens": ["Weck\u00b7te", "em", "ut", "si\u00b7ne", "Ruh", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.3": {"text": "\u00bbmonsieur Charles, mouchez-vous!\u00ab", "tokens": ["\u00bb", "mon\u00b7si\u00b7eur", "Char\u00b7les", ",", "mou\u00b7che\u00b7zvous", "!", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "word", "punct", "punct"], "pos": ["$(", "FM.fr", "FM.fr", "$,", "NE", "$.", "$("], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.4": {"text": "\u00bbje! s\u00fch! kik! Wat, mouchez-vous?", "tokens": ["\u00bb", "je", "!", "s\u00fch", "!", "kik", "!", "Wat", ",", "mou\u00b7che\u00b7zvous", "?"], "token_info": ["punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["$(", "ADV", "$.", "ADJD", "$.", "NN", "$.", "NN", "$,", "NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Sei is ok woll nich recht klauk?", "tokens": ["Sei", "is", "ok", "woll", "nich", "recht", "klauk", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "FM", "FM", "ADV", "PTKNEG", "ADJD", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Heww'ck ok all en Snuwdauk?\u00ab", "tokens": ["Hew\u00b7w'ck", "ok", "all", "en", "Snuw\u00b7dauk", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "NE", "PIAT", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}}}}