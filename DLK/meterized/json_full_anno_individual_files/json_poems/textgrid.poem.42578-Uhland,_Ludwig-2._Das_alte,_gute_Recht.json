{"textgrid.poem.42578": {"metadata": {"author": {"name": "Uhland, Ludwig", "birth": "N.A.", "death": "N.A."}, "title": "2. Das alte, gute Recht", "genre": "verse", "period": "N.A.", "pub_year": 1816, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wo je bei altem, gutem Wein", "tokens": ["Wo", "je", "bei", "al\u00b7tem", ",", "gu\u00b7tem", "Wein"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["PWAV", "ADV", "APPR", "ADJA", "$,", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der W\u00fcrttemberger zecht,", "tokens": ["Der", "W\u00fcrt\u00b7tem\u00b7ber\u00b7ger", "zecht", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Da soll der erste Trinkspruch sein:", "tokens": ["Da", "soll", "der", "ers\u00b7te", "Trinks\u00b7pruch", "sein", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "ADJA", "NN", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Das ", "tokens": ["Das"], "token_info": ["word"], "pos": ["PDS"], "meter": "-", "measure": "single.down"}}, "stanza.2": {"line.1": {"text": "Das Recht, das unsres F\u00fcrsten Haus", "tokens": ["Das", "Recht", ",", "das", "uns\u00b7res", "F\u00fcrs\u00b7ten", "Haus"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Als starker Pfeiler st\u00fctzt", "tokens": ["Als", "star\u00b7ker", "Pfei\u00b7ler", "st\u00fctzt"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und das im Lande ein und aus", "tokens": ["Und", "das", "im", "Lan\u00b7de", "ein", "und", "aus"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "APPRART", "NN", "PTKVZ", "KON", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der Armut H\u00fctten sch\u00fctzt.", "tokens": ["Der", "Ar\u00b7mut", "H\u00fct\u00b7ten", "sch\u00fctzt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Das Recht, das uns Gesetze gibt,", "tokens": ["Das", "Recht", ",", "das", "uns", "Ge\u00b7set\u00b7ze", "gibt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die keine Willk\u00fcr bricht;", "tokens": ["Die", "kei\u00b7ne", "Will\u00b7k\u00fcr", "bricht", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Das offene Gerichte liebt", "tokens": ["Das", "of\u00b7fe\u00b7ne", "Ge\u00b7rich\u00b7te", "liebt"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN"], "meter": "-+---+-+", "measure": "dactylic.init"}, "line.4": {"text": "Und giltig Urteil spricht.", "tokens": ["Und", "gil\u00b7tig", "Ur\u00b7teil", "spricht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Das Recht, das m\u00e4\u00dfig Steuern schreibt", "tokens": ["Das", "Recht", ",", "das", "m\u00e4\u00b7\u00dfig", "Steu\u00b7ern", "schreibt"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "ADJD", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und wohl zu rechnen wei\u00df,", "tokens": ["Und", "wohl", "zu", "rech\u00b7nen", "wei\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PTKZU", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Das an der Kasse sitzen bleibt", "tokens": ["Das", "an", "der", "Kas\u00b7se", "sit\u00b7zen", "bleibt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "APPR", "ART", "NN", "VVINF", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und kargt mit unsrem Schwei\u00df.", "tokens": ["Und", "kargt", "mit", "uns\u00b7rem", "Schwei\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Das unser heil'ges Kirchengut", "tokens": ["Das", "un\u00b7ser", "heil'\u00b7ges", "Kir\u00b7chen\u00b7gut"], "token_info": ["word", "word", "word", "word"], "pos": ["PDS", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Als Schutzpatron bewacht,", "tokens": ["Als", "Schutz\u00b7pat\u00b7ron", "be\u00b7wacht", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KOUS", "NN", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Das Wissenschaft und Geistesglut", "tokens": ["Das", "Wis\u00b7sen\u00b7schaft", "und", "Geis\u00b7tes\u00b7glut"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Getreulich n\u00e4hrt und facht.", "tokens": ["Ge\u00b7treu\u00b7lich", "n\u00e4hrt", "und", "facht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Das Recht, das jedem freien Mann", "tokens": ["Das", "Recht", ",", "das", "je\u00b7dem", "frei\u00b7en", "Mann"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Waffen gibt zur Hand,", "tokens": ["Die", "Waf\u00b7fen", "gibt", "zur", "Hand", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Damit er stets verfechten kann", "tokens": ["Da\u00b7mit", "er", "stets", "ver\u00b7fech\u00b7ten", "kann"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "VVINF", "VMFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Den F\u00fcrsten und das Land.", "tokens": ["Den", "F\u00fcrs\u00b7ten", "und", "das", "Land", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Das Recht, das jedem offen l\u00e4\u00dft", "tokens": ["Das", "Recht", ",", "das", "je\u00b7dem", "of\u00b7fen", "l\u00e4\u00dft"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "PIS", "ADJD", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Den Zug in alle Welt,", "tokens": ["Den", "Zug", "in", "al\u00b7le", "Welt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Das uns allein durch Liebe fest", "tokens": ["Das", "uns", "al\u00b7lein", "durch", "Lie\u00b7be", "fest"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "PPER", "ADV", "APPR", "NN", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Am Mutterboden h\u00e4lt.", "tokens": ["Am", "Mut\u00b7ter\u00b7bo\u00b7den", "h\u00e4lt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Das Recht, des wohlverdienten Ruhm", "tokens": ["Das", "Recht", ",", "des", "wohl\u00b7ver\u00b7dien\u00b7ten", "Ruhm"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "$,", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Jahrhunderte bew\u00e4hrt,", "tokens": ["Jahr\u00b7hun\u00b7der\u00b7te", "be\u00b7w\u00e4hrt", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Das jeder, wie sein Christentum,", "tokens": ["Das", "je\u00b7der", ",", "wie", "sein", "Chris\u00b7ten\u00b7tum", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "PIS", "$,", "PWAV", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Von Herzen liebt und ehrt.", "tokens": ["Von", "Her\u00b7zen", "liebt", "und", "ehrt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Das Recht, das eine schlimme Zeit", "tokens": ["Das", "Recht", ",", "das", "ei\u00b7ne", "schlim\u00b7me", "Zeit"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Lebendig uns begrub,", "tokens": ["Le\u00b7ben\u00b7dig", "uns", "be\u00b7grub", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "PPER", "VVFIN", "$,"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.3": {"text": "Das jetzt mit neuer Regsamkeit", "tokens": ["Das", "jetzt", "mit", "neu\u00b7er", "Reg\u00b7sam\u00b7keit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "ADV", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sich aus dem Grab erhub.", "tokens": ["Sich", "aus", "dem", "Grab", "er\u00b7hub", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "Ja! wenn auch wir von hinnen sind,", "tokens": ["Ja", "!", "wenn", "auch", "wir", "von", "hin\u00b7nen", "sind", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$.", "KOUS", "ADV", "PPER", "APPR", "ADV", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Besteh es fort und fort", "tokens": ["Be\u00b7steh", "es", "fort", "und", "fort"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "PTKVZ", "KON", "PTKVZ"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und sei f\u00fcr Kind und Kindeskind", "tokens": ["Und", "sei", "f\u00fcr", "Kind", "und", "Kin\u00b7des\u00b7kind"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Des sch\u00f6nsten Gl\u00fcckes Hort!", "tokens": ["Des", "sch\u00f6ns\u00b7ten", "Gl\u00fc\u00b7ckes", "Hort", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NE", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "Und wo bei altem, gutem Wein", "tokens": ["Und", "wo", "bei", "al\u00b7tem", ",", "gu\u00b7tem", "Wein"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "PWAV", "APPR", "ADJA", "$,", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der W\u00fcrttemberger zecht,", "tokens": ["Der", "W\u00fcrt\u00b7tem\u00b7ber\u00b7ger", "zecht", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Soll stets der erste Trinkspruch sein:", "tokens": ["Soll", "stets", "der", "ers\u00b7te", "Trinks\u00b7pruch", "sein", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "ART", "ADJA", "NN", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Wo je bei altem, gutem Wein", "tokens": ["Wo", "je", "bei", "al\u00b7tem", ",", "gu\u00b7tem", "Wein"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["PWAV", "ADV", "APPR", "ADJA", "$,", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der W\u00fcrttemberger zecht,", "tokens": ["Der", "W\u00fcrt\u00b7tem\u00b7ber\u00b7ger", "zecht", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Da soll der erste Trinkspruch sein:", "tokens": ["Da", "soll", "der", "ers\u00b7te", "Trinks\u00b7pruch", "sein", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "ADJA", "NN", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Das ", "tokens": ["Das"], "token_info": ["word"], "pos": ["PDS"], "meter": "-", "measure": "single.down"}}, "stanza.13": {"line.1": {"text": "Das Recht, das unsres F\u00fcrsten Haus", "tokens": ["Das", "Recht", ",", "das", "uns\u00b7res", "F\u00fcrs\u00b7ten", "Haus"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Als starker Pfeiler st\u00fctzt", "tokens": ["Als", "star\u00b7ker", "Pfei\u00b7ler", "st\u00fctzt"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und das im Lande ein und aus", "tokens": ["Und", "das", "im", "Lan\u00b7de", "ein", "und", "aus"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "APPRART", "NN", "PTKVZ", "KON", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der Armut H\u00fctten sch\u00fctzt.", "tokens": ["Der", "Ar\u00b7mut", "H\u00fct\u00b7ten", "sch\u00fctzt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.14": {"line.1": {"text": "Das Recht, das uns Gesetze gibt,", "tokens": ["Das", "Recht", ",", "das", "uns", "Ge\u00b7set\u00b7ze", "gibt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die keine Willk\u00fcr bricht;", "tokens": ["Die", "kei\u00b7ne", "Will\u00b7k\u00fcr", "bricht", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Das offene Gerichte liebt", "tokens": ["Das", "of\u00b7fe\u00b7ne", "Ge\u00b7rich\u00b7te", "liebt"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN"], "meter": "-+---+-+", "measure": "dactylic.init"}, "line.4": {"text": "Und giltig Urteil spricht.", "tokens": ["Und", "gil\u00b7tig", "Ur\u00b7teil", "spricht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.15": {"line.1": {"text": "Das Recht, das m\u00e4\u00dfig Steuern schreibt", "tokens": ["Das", "Recht", ",", "das", "m\u00e4\u00b7\u00dfig", "Steu\u00b7ern", "schreibt"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "ADJD", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und wohl zu rechnen wei\u00df,", "tokens": ["Und", "wohl", "zu", "rech\u00b7nen", "wei\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PTKZU", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Das an der Kasse sitzen bleibt", "tokens": ["Das", "an", "der", "Kas\u00b7se", "sit\u00b7zen", "bleibt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "APPR", "ART", "NN", "VVINF", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und kargt mit unsrem Schwei\u00df.", "tokens": ["Und", "kargt", "mit", "uns\u00b7rem", "Schwei\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.16": {"line.1": {"text": "Das unser heil'ges Kirchengut", "tokens": ["Das", "un\u00b7ser", "heil'\u00b7ges", "Kir\u00b7chen\u00b7gut"], "token_info": ["word", "word", "word", "word"], "pos": ["PDS", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Als Schutzpatron bewacht,", "tokens": ["Als", "Schutz\u00b7pat\u00b7ron", "be\u00b7wacht", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KOUS", "NN", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Das Wissenschaft und Geistesglut", "tokens": ["Das", "Wis\u00b7sen\u00b7schaft", "und", "Geis\u00b7tes\u00b7glut"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Getreulich n\u00e4hrt und facht.", "tokens": ["Ge\u00b7treu\u00b7lich", "n\u00e4hrt", "und", "facht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.17": {"line.1": {"text": "Das Recht, das jedem freien Mann", "tokens": ["Das", "Recht", ",", "das", "je\u00b7dem", "frei\u00b7en", "Mann"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Waffen gibt zur Hand,", "tokens": ["Die", "Waf\u00b7fen", "gibt", "zur", "Hand", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Damit er stets verfechten kann", "tokens": ["Da\u00b7mit", "er", "stets", "ver\u00b7fech\u00b7ten", "kann"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "VVINF", "VMFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Den F\u00fcrsten und das Land.", "tokens": ["Den", "F\u00fcrs\u00b7ten", "und", "das", "Land", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.18": {"line.1": {"text": "Das Recht, das jedem offen l\u00e4\u00dft", "tokens": ["Das", "Recht", ",", "das", "je\u00b7dem", "of\u00b7fen", "l\u00e4\u00dft"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "PIS", "ADJD", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Den Zug in alle Welt,", "tokens": ["Den", "Zug", "in", "al\u00b7le", "Welt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Das uns allein durch Liebe fest", "tokens": ["Das", "uns", "al\u00b7lein", "durch", "Lie\u00b7be", "fest"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "PPER", "ADV", "APPR", "NN", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Am Mutterboden h\u00e4lt.", "tokens": ["Am", "Mut\u00b7ter\u00b7bo\u00b7den", "h\u00e4lt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.19": {"line.1": {"text": "Das Recht, des wohlverdienten Ruhm", "tokens": ["Das", "Recht", ",", "des", "wohl\u00b7ver\u00b7dien\u00b7ten", "Ruhm"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "$,", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Jahrhunderte bew\u00e4hrt,", "tokens": ["Jahr\u00b7hun\u00b7der\u00b7te", "be\u00b7w\u00e4hrt", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Das jeder, wie sein Christentum,", "tokens": ["Das", "je\u00b7der", ",", "wie", "sein", "Chris\u00b7ten\u00b7tum", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "PIS", "$,", "PWAV", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Von Herzen liebt und ehrt.", "tokens": ["Von", "Her\u00b7zen", "liebt", "und", "ehrt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.20": {"line.1": {"text": "Das Recht, das eine schlimme Zeit", "tokens": ["Das", "Recht", ",", "das", "ei\u00b7ne", "schlim\u00b7me", "Zeit"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Lebendig uns begrub,", "tokens": ["Le\u00b7ben\u00b7dig", "uns", "be\u00b7grub", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "PPER", "VVFIN", "$,"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.3": {"text": "Das jetzt mit neuer Regsamkeit", "tokens": ["Das", "jetzt", "mit", "neu\u00b7er", "Reg\u00b7sam\u00b7keit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "ADV", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sich aus dem Grab erhub.", "tokens": ["Sich", "aus", "dem", "Grab", "er\u00b7hub", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.21": {"line.1": {"text": "Ja! wenn auch wir von hinnen sind,", "tokens": ["Ja", "!", "wenn", "auch", "wir", "von", "hin\u00b7nen", "sind", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$.", "KOUS", "ADV", "PPER", "APPR", "ADV", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Besteh es fort und fort", "tokens": ["Be\u00b7steh", "es", "fort", "und", "fort"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "PTKVZ", "KON", "PTKVZ"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und sei f\u00fcr Kind und Kindeskind", "tokens": ["Und", "sei", "f\u00fcr", "Kind", "und", "Kin\u00b7des\u00b7kind"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Des sch\u00f6nsten Gl\u00fcckes Hort!", "tokens": ["Des", "sch\u00f6ns\u00b7ten", "Gl\u00fc\u00b7ckes", "Hort", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NE", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.22": {"line.1": {"text": "Und wo bei altem, gutem Wein", "tokens": ["Und", "wo", "bei", "al\u00b7tem", ",", "gu\u00b7tem", "Wein"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "PWAV", "APPR", "ADJA", "$,", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der W\u00fcrttemberger zecht,", "tokens": ["Der", "W\u00fcrt\u00b7tem\u00b7ber\u00b7ger", "zecht", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Soll stets der erste Trinkspruch sein:", "tokens": ["Soll", "stets", "der", "ers\u00b7te", "Trinks\u00b7pruch", "sein", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "ART", "ADJA", "NN", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}