{"textgrid.poem.48752": {"metadata": {"author": {"name": "Fleming, Paul", "birth": "N.A.", "death": "N.A."}, "title": "39. \u00dcber einen andern, unferne von diesem gegen\u00fcber", "genre": "verse", "period": "N.A.", "pub_year": 1624, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Der kahle Sandhauf' hier, der auch den d\u00fcrren Reisern", "tokens": ["Der", "kah\u00b7le", "Sand\u00b7hauf'", "hier", ",", "der", "auch", "den", "d\u00fcr\u00b7ren", "Rei\u00b7sern"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "ADV", "$,", "PRELS", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "nicht halbe Nahrung gibt, der seine Glitz' entbl\u00f6\u00dft,", "tokens": ["nicht", "hal\u00b7be", "Nah\u00b7rung", "gibt", ",", "der", "sei\u00b7ne", "Glitz'", "ent\u00b7bl\u00f6\u00dft", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADJA", "NN", "VVFIN", "$,", "PRELS", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Latona, hoch f\u00fcr dir, an die er selbst fast st\u00f6\u00dft,", "tokens": ["La\u00b7to\u00b7na", ",", "hoch", "f\u00fcr", "dir", ",", "an", "die", "er", "selbst", "fast", "st\u00f6\u00dft", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ADJD", "APPR", "PPER", "$,", "APPR", "PRELS", "PPER", "ADV", "ADV", "VVFIN", "$,"], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.4": {"text": "der ist ", "tokens": ["der", "ist"], "token_info": ["word", "word"], "pos": ["ART", "VAFIN"], "meter": "-+", "measure": "iambic.single"}}, "stanza.2": {"line.1": {"text": "die er mit sich bracht her aus gro\u00dfen", "tokens": ["die", "er", "mit", "sich", "bracht", "her", "aus", "gro\u00b7\u00dfen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PRELS", "PPER", "APPR", "PRF", "VVFIN", "ADV", "APPR", "ADJA"], "meter": "--+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Hier liegt der Sand und Wust, auch fast nicht halb bem\u00f6st,", "tokens": ["Hier", "liegt", "der", "Sand", "und", "Wust", ",", "auch", "fast", "nicht", "halb", "be\u00b7m\u00f6st", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "KON", "NN", "$,", "ADV", "ADV", "PTKNEG", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "was Blei und Pulver war, was st\u00e4hlern war und eisern.", "tokens": ["was", "Blei", "und", "Pul\u00b7ver", "war", ",", "was", "st\u00e4h\u00b7lern", "war", "und", "ei\u00b7sern", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "KON", "NN", "VAFIN", "$,", "PRELS", "ADJD", "VAFIN", "KON", "ADJD", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "O ein verg\u00e4nglichs Tun! Ist das der ganze Rest", "tokens": ["O", "ein", "ver\u00b7g\u00e4ng\u00b7lichs", "Tun", "!", "Ist", "das", "der", "gan\u00b7ze", "Rest"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NE", "ART", "ADJA", "NN", "$.", "VAFIN", "PDS", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "von so viel Tausenden? Wie da\u00df denn ein Mensch l\u00e4\u00dft", "tokens": ["von", "so", "viel", "Tau\u00b7sen\u00b7den", "?", "Wie", "da\u00df", "denn", "ein", "Mensch", "l\u00e4\u00dft"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADV", "PIAT", "NN", "$.", "KOKOM", "KOUS", "ADV", "ART", "NN", "VVFIN"], "meter": "+--+--+-+-+-", "measure": "dactylic.di.plus"}, "line.3": {"text": "so viel bed\u00fcnken sich, als woll' er Alle fressen?", "tokens": ["so", "viel", "be\u00b7d\u00fcn\u00b7ken", "sich", ",", "als", "woll'", "er", "Al\u00b7le", "fres\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PRF", "$,", "KOUS", "VMFIN", "PPER", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Vor war hier Alles voll, itzt ist hier alles leer.", "tokens": ["Vor", "war", "hier", "Al\u00b7les", "voll", ",", "itzt", "ist", "hier", "al\u00b7les", "leer", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "VAFIN", "ADV", "PIS", "ADJD", "$,", "ADV", "VAFIN", "ADV", "PIS", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Di\u00df gehet in der Welt noch itzund also her.", "tokens": ["Di\u00df", "ge\u00b7het", "in", "der", "Welt", "noch", "it\u00b7zund", "al\u00b7so", "her", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPR", "ART", "NN", "ADV", "ADV", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Was itzt wird so gescheut, wird bald sein ganz vergessen.", "tokens": ["Was", "itzt", "wird", "so", "ge\u00b7scheut", ",", "wird", "bald", "sein", "ganz", "ver\u00b7ges\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "VAFIN", "ADV", "VVPP", "$,", "VAFIN", "ADV", "PPOSAT", "ADV", "VVPP", "$."], "meter": "-+---+-+-+-+-", "measure": "dactylic.init"}}, "stanza.5": {"line.1": {"text": "Der kahle Sandhauf' hier, der auch den d\u00fcrren Reisern", "tokens": ["Der", "kah\u00b7le", "Sand\u00b7hauf'", "hier", ",", "der", "auch", "den", "d\u00fcr\u00b7ren", "Rei\u00b7sern"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "ADV", "$,", "PRELS", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "nicht halbe Nahrung gibt, der seine Glitz' entbl\u00f6\u00dft,", "tokens": ["nicht", "hal\u00b7be", "Nah\u00b7rung", "gibt", ",", "der", "sei\u00b7ne", "Glitz'", "ent\u00b7bl\u00f6\u00dft", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADJA", "NN", "VVFIN", "$,", "PRELS", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Latona, hoch f\u00fcr dir, an die er selbst fast st\u00f6\u00dft,", "tokens": ["La\u00b7to\u00b7na", ",", "hoch", "f\u00fcr", "dir", ",", "an", "die", "er", "selbst", "fast", "st\u00f6\u00dft", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ADJD", "APPR", "PPER", "$,", "APPR", "PRELS", "PPER", "ADV", "ADV", "VVFIN", "$,"], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.4": {"text": "der ist ", "tokens": ["der", "ist"], "token_info": ["word", "word"], "pos": ["ART", "VAFIN"], "meter": "-+", "measure": "iambic.single"}}, "stanza.6": {"line.1": {"text": "die er mit sich bracht her aus gro\u00dfen", "tokens": ["die", "er", "mit", "sich", "bracht", "her", "aus", "gro\u00b7\u00dfen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PRELS", "PPER", "APPR", "PRF", "VVFIN", "ADV", "APPR", "ADJA"], "meter": "--+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Hier liegt der Sand und Wust, auch fast nicht halb bem\u00f6st,", "tokens": ["Hier", "liegt", "der", "Sand", "und", "Wust", ",", "auch", "fast", "nicht", "halb", "be\u00b7m\u00f6st", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "KON", "NN", "$,", "ADV", "ADV", "PTKNEG", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "was Blei und Pulver war, was st\u00e4hlern war und eisern.", "tokens": ["was", "Blei", "und", "Pul\u00b7ver", "war", ",", "was", "st\u00e4h\u00b7lern", "war", "und", "ei\u00b7sern", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "KON", "NN", "VAFIN", "$,", "PRELS", "ADJD", "VAFIN", "KON", "ADJD", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "O ein verg\u00e4nglichs Tun! Ist das der ganze Rest", "tokens": ["O", "ein", "ver\u00b7g\u00e4ng\u00b7lichs", "Tun", "!", "Ist", "das", "der", "gan\u00b7ze", "Rest"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NE", "ART", "ADJA", "NN", "$.", "VAFIN", "PDS", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "von so viel Tausenden? Wie da\u00df denn ein Mensch l\u00e4\u00dft", "tokens": ["von", "so", "viel", "Tau\u00b7sen\u00b7den", "?", "Wie", "da\u00df", "denn", "ein", "Mensch", "l\u00e4\u00dft"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADV", "PIAT", "NN", "$.", "KOKOM", "KOUS", "ADV", "ART", "NN", "VVFIN"], "meter": "+--+--+-+-+-", "measure": "dactylic.di.plus"}, "line.3": {"text": "so viel bed\u00fcnken sich, als woll' er Alle fressen?", "tokens": ["so", "viel", "be\u00b7d\u00fcn\u00b7ken", "sich", ",", "als", "woll'", "er", "Al\u00b7le", "fres\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PRF", "$,", "KOUS", "VMFIN", "PPER", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "Vor war hier Alles voll, itzt ist hier alles leer.", "tokens": ["Vor", "war", "hier", "Al\u00b7les", "voll", ",", "itzt", "ist", "hier", "al\u00b7les", "leer", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "VAFIN", "ADV", "PIS", "ADJD", "$,", "ADV", "VAFIN", "ADV", "PIS", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Di\u00df gehet in der Welt noch itzund also her.", "tokens": ["Di\u00df", "ge\u00b7het", "in", "der", "Welt", "noch", "it\u00b7zund", "al\u00b7so", "her", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPR", "ART", "NN", "ADV", "ADV", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Was itzt wird so gescheut, wird bald sein ganz vergessen.", "tokens": ["Was", "itzt", "wird", "so", "ge\u00b7scheut", ",", "wird", "bald", "sein", "ganz", "ver\u00b7ges\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "VAFIN", "ADV", "VVPP", "$,", "VAFIN", "ADV", "PPOSAT", "ADV", "VVPP", "$."], "meter": "-+---+-+-+-+-", "measure": "dactylic.init"}}}}}