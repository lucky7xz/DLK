{"dta.poem.5314": {"metadata": {"author": {"name": "Brockes, Barthold Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "J rdisches  \n  V ergn\u00fcgen  \n in  \n  GOTT .  \n  F \u00fcnfter  T heil.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1736", "urn": "urn:nbn:de:kobv:b4-200905198582", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Ja, es streckt sich die Betrachtung nicht blo\u00df auf die Wol-", "tokens": ["Ja", ",", "es", "streckt", "sich", "die", "Be\u00b7trach\u00b7tung", "nicht", "blo\u00df", "auf", "die", "Wol"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "$,", "PPER", "VVFIN", "PRF", "ART", "NN", "PTKNEG", "ADV", "APPR", "ART", "TRUNC"], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}, "line.2": {"text": "lust nur,", "tokens": ["lust", "nur", ","], "token_info": ["word", "word", "punct"], "pos": ["VVFIN", "ADV", "$,"], "meter": "--", "measure": "unknown.measure.zero"}, "line.3": {"text": "Wenn uns Ehr- und Geld-Geitz t\u00e4uschen, uns zu Lastern", "tokens": ["Wenn", "uns", "Ehr", "und", "Geld\u00b7Geitz", "t\u00e4u\u00b7schen", ",", "uns", "zu", "Las\u00b7tern"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "PPER", "TRUNC", "KON", "NN", "VVINF", "$,", "PPER", "APPR", "NN"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.4": {"text": "oft verf\u00fchren,", "tokens": ["oft", "ver\u00b7f\u00fch\u00b7ren", ","], "token_info": ["word", "word", "punct"], "pos": ["ADV", "VVINF", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.5": {"text": "Und wir den Besitz erhalten; finden wir in der Natur", "tokens": ["Und", "wir", "den", "Be\u00b7sitz", "er\u00b7hal\u00b7ten", ";", "fin\u00b7den", "wir", "in", "der", "Na\u00b7tur"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "ART", "NN", "VVPP", "$.", "VVFIN", "PPER", "APPR", "ART", "NN"], "meter": "-+--+-+-+-+-+-+", "measure": "iambic.septa.relaxed"}, "line.6": {"text": "In der Unempfindlichkeit der darin gehoften Lust", "tokens": ["In", "der", "Un\u00b7emp\u00b7find\u00b7lich\u00b7keit", "der", "da\u00b7rin", "ge\u00b7hof\u00b7ten", "Lust"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ART", "PAV", "ADJA", "NN"], "meter": "+-+-+-+--+-+-+", "measure": "trochaic.septa.relaxed"}, "line.7": {"text": "Unsern Jrrthum; und so dann wird uns allererst bewust", "tokens": ["Un\u00b7sern", "Jrr\u00b7thum", ";", "und", "so", "dann", "wird", "uns", "al\u00b7le\u00b7rerst", "be\u00b7wust"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "$.", "KON", "ADV", "ADV", "VAFIN", "PPER", "ADV", "VVFIN"], "meter": "+--+-+-+-+-+-+", "measure": "iambic.septa.invert"}, "line.8": {"text": "Die durch Menschliche Gesetze drauf gesetzte Straf und", "tokens": ["Die", "durch", "Menschli\u00b7che", "Ge\u00b7set\u00b7ze", "drauf", "ge\u00b7setz\u00b7te", "Straf", "und"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "ADJA", "NN", "PAV", "ADJA", "NN", "KON"], "meter": "+-+--+-+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.9": {"text": "Schande,", "tokens": ["Schan\u00b7de", ","], "token_info": ["word", "punct"], "pos": ["NN", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.10": {"text": "Die man, vor vollbrachter That,", "tokens": ["Die", "man", ",", "vor", "voll\u00b7brach\u00b7ter", "That", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.11": {"text": "Durch gehofte Lust, verachtet,", "tokens": ["Durch", "ge\u00b7hof\u00b7te", "Lust", ",", "ver\u00b7ach\u00b7tet", ","], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.12": {"text": "Und, durch die Begierden blind, nicht erwogen, nicht be-", "tokens": ["Und", ",", "durch", "die", "Be\u00b7gier\u00b7den", "blind", ",", "nicht", "er\u00b7wo\u00b7gen", ",", "nicht", "be"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["KON", "$,", "APPR", "ART", "NN", "ADJD", "$,", "PTKNEG", "VVPP", "$,", "PTKNEG", "TRUNC"], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.13": {"text": "trachtet,", "tokens": ["trach\u00b7tet", ","], "token_info": ["word", "punct"], "pos": ["VVFIN", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.14": {"text": "Weniger gescheuet hat.", "tokens": ["We\u00b7ni\u00b7ger", "ge\u00b7scheu\u00b7et", "hat", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "VVPP", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.15": {"text": "Dieses alles zeigt uns deutlich, und macht \u00fcberzeuglich", "tokens": ["Die\u00b7ses", "al\u00b7les", "zeigt", "uns", "deut\u00b7lich", ",", "und", "macht", "\u00fc\u00b7berz\u00b7eug\u00b7lich"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PDS", "PIS", "VVFIN", "PPER", "ADJD", "$,", "KON", "VVFIN", "ADJD"], "meter": "+-+-+-+--++-+-", "measure": "trochaic.septa.relaxed"}, "line.16": {"text": "klar", "tokens": ["klar"], "token_info": ["word"], "pos": ["ADJD"], "meter": "+", "measure": "single.up"}, "line.17": {"text": "Des allm\u00e4chtigen Regierers tieffe Weisheit offenbar,", "tokens": ["Des", "all\u00b7m\u00e4ch\u00b7ti\u00b7gen", "Re\u00b7gie\u00b7rers", "tief\u00b7fe", "Weis\u00b7heit", "of\u00b7fen\u00b7bar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADJA", "NN", "ADJD", "$,"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.18": {"text": "Da er selbst in unser Wesen eine Eigenschaft gesencket,", "tokens": ["Da", "er", "selbst", "in", "un\u00b7ser", "We\u00b7sen", "ei\u00b7ne", "Ei\u00b7gen\u00b7schaft", "ge\u00b7sen\u00b7cket", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "APPR", "PPOSAT", "NN", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.19": {"text": "Da\u00df man nach vollbrachter That anders, als vorher, ge-", "tokens": ["Da\u00df", "man", "nach", "voll\u00b7brach\u00b7ter", "That", "an\u00b7ders", ",", "als", "vor\u00b7her", ",", "ge"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word"], "pos": ["KOUS", "PIS", "APPR", "ADJA", "NN", "ADV", "$,", "KOUS", "ADV", "$,", "TRUNC"], "meter": "--+-+-+-+-+--", "measure": "anapaest.init"}, "line.20": {"text": "dencket", "tokens": ["den\u00b7cket"], "token_info": ["word"], "pos": ["VVFIN"], "meter": "+-", "measure": "trochaic.single"}, "line.21": {"text": "Und, so wol durch Furcht, als Eckel, den man in sich selbst", "tokens": ["Und", ",", "so", "wol", "durch", "Furcht", ",", "als", "E\u00b7ckel", ",", "den", "man", "in", "sich", "selbst"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "$,", "ADV", "ADV", "APPR", "NN", "$,", "KOUS", "NN", "$,", "PRELS", "PIS", "APPR", "PRF", "ADV"], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}, "line.22": {"text": "entdeckt,", "tokens": ["ent\u00b7deckt", ","], "token_info": ["word", "punct"], "pos": ["VVPP", "$,"], "meter": "-+", "measure": "iambic.single"}, "line.23": {"text": "Vom Verbothnen abgehalten, von den Lastern abgeschreckt", "tokens": ["Vom", "Ver\u00b7both\u00b7nen", "ab\u00b7ge\u00b7hal\u00b7ten", ",", "von", "den", "Las\u00b7tern", "ab\u00b7ge\u00b7schreckt"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "VVPP", "$,", "APPR", "ART", "NN", "VVPP"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.24": {"text": "Und zur Reu getrieben wird. Da man also deutlich findet", "tokens": ["Und", "zur", "Reu", "ge\u00b7trie\u00b7ben", "wird", ".", "Da", "man", "al\u00b7so", "deut\u00b7lich", "fin\u00b7det"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "APPRART", "NN", "VVPP", "VAFIN", "$.", "KOUS", "PIS", "ADV", "ADJD", "VVFIN"], "meter": "--+-+--+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.25": {"text": "Da\u00df der Ursprung des Gewissens selbst in der Natur ge-", "tokens": ["Da\u00df", "der", "Ur\u00b7sprung", "des", "Ge\u00b7wis\u00b7sens", "selbst", "in", "der", "Na\u00b7tur", "ge"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "ART", "NN", "ADV", "APPR", "ART", "NN", "TRUNC"], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}, "line.26": {"text": "gr\u00fcndet", "tokens": ["gr\u00fcn\u00b7det"], "token_info": ["word"], "pos": ["VVFIN"], "meter": "+-", "measure": "trochaic.single"}, "line.27": {"text": "Und nicht im Gehirn allein: la\u00df uns denn des Sch\u00f6pfers", "tokens": ["Und", "nicht", "im", "Ge\u00b7hirn", "al\u00b7lein", ":", "la\u00df", "uns", "denn", "des", "Sch\u00f6p\u00b7fers"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "PTKNEG", "APPRART", "NN", "ADV", "$.", "VVIMP", "PPER", "ADV", "ART", "NN"], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.28": {"text": "Willen,", "tokens": ["Wil\u00b7len", ","], "token_info": ["word", "punct"], "pos": ["NN", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.29": {"text": "Der sich in Enthaltung \u00e4ussert, uns bestreben zu erf\u00fcllen!", "tokens": ["Der", "sich", "in", "Ent\u00b7hal\u00b7tung", "\u00e4us\u00b7sert", ",", "uns", "be\u00b7stre\u00b7ben", "zu", "er\u00b7f\u00fcl\u00b7len", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "APPR", "NN", "VVFIN", "$,", "PPER", "VVINF", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}}}}}