{"textgrid.poem.33452": {"metadata": {"author": {"name": "Lichtenstein, Alfred", "birth": "N.A.", "death": "N.A."}, "title": "Der Barbier des Hugo von Hofmannsthal", "genre": "verse", "period": "N.A.", "pub_year": 1912, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "So steh ich nun die tr\u00fcben Wintertage", "tokens": ["So", "steh", "ich", "nun", "die", "tr\u00fc\u00b7ben", "Win\u00b7ter\u00b7ta\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Von fr\u00fch bis sp\u00e4t und seife K\u00f6pfe ein,", "tokens": ["Von", "fr\u00fch", "bis", "sp\u00e4t", "und", "sei\u00b7fe", "K\u00f6p\u00b7fe", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJD", "APPR", "ADJD", "KON", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Rasiere sie und pudre sie und sage", "tokens": ["Ra\u00b7sie\u00b7re", "sie", "und", "pud\u00b7re", "sie", "und", "sa\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "KON", "VVFIN", "PPER", "KON", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Gleichg\u00fcltge Worte, dumme, Spielerein.", "tokens": ["Gleich\u00b7g\u00fclt\u00b7ge", "Wor\u00b7te", ",", "dum\u00b7me", ",", "Spie\u00b7ler\u00b7ein", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ADJA", "NN", "$,", "ADJA", "$,", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Die meisten K\u00f6pfe sind ganz zugeschlossen,", "tokens": ["Die", "meis\u00b7ten", "K\u00f6p\u00b7fe", "sind", "ganz", "zu\u00b7ge\u00b7schlos\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VAFIN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Sie schlafen schlaff. Und andre lesen wieder", "tokens": ["Sie", "schla\u00b7fen", "schlaff", ".", "Und", "and\u00b7re", "le\u00b7sen", "wie\u00b7der"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADJD", "$.", "KON", "PIS", "VVFIN", "ADV"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Und blicken langsam durch die langen Lider,", "tokens": ["Und", "bli\u00b7cken", "lang\u00b7sam", "durch", "die", "lan\u00b7gen", "Li\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Als h\u00e4tten sie schon alles ausgenossen.", "tokens": ["Als", "h\u00e4t\u00b7ten", "sie", "schon", "al\u00b7les", "aus\u00b7ge\u00b7nos\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VAFIN", "PPER", "ADV", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Noch andre \u00f6ffnen weit die rote Ritze", "tokens": ["Noch", "and\u00b7re", "\u00f6ff\u00b7nen", "weit", "die", "ro\u00b7te", "Rit\u00b7ze"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "PIS", "VVFIN", "ADJD", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Des Mundes und verk\u00fcnden viele Witze.", "tokens": ["Des", "Mun\u00b7des", "und", "ver\u00b7k\u00fcn\u00b7den", "vie\u00b7le", "Wit\u00b7ze", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "VVFIN", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Ich aber l\u00e4chle h\u00f6flich. Ach, ich berge", "tokens": ["Ich", "a\u00b7ber", "l\u00e4ch\u00b7le", "h\u00f6f\u00b7lich", ".", "Ach", ",", "ich", "ber\u00b7ge"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["PPER", "ADV", "VVFIN", "ADJD", "$.", "ITJ", "$,", "PPER", "VVFIN"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Tief unter diesem L\u00e4cheln wie in S\u00e4rge", "tokens": ["Tief", "un\u00b7ter", "die\u00b7sem", "L\u00e4\u00b7cheln", "wie", "in", "S\u00e4r\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADJD", "APPR", "PDAT", "NN", "KOKOM", "APPR", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Die schlimmen, \u00fcberwachen, weisen Klagen,", "tokens": ["Die", "schlim\u00b7men", ",", "\u00fc\u00b7ber\u00b7wa\u00b7chen", ",", "wei\u00b7sen", "Kla\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "VVPP", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Da\u00df wir in dieses Dasein eingepre\u00dft,", "tokens": ["Da\u00df", "wir", "in", "die\u00b7ses", "Da\u00b7sein", "ein\u00b7ge\u00b7pre\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PDAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Hineingezw\u00e4ngt sind, unentrinnbar fest", "tokens": ["Hin\u00b7ein\u00b7ge\u00b7zw\u00e4ngt", "sind", ",", "un\u00b7en\u00b7trinn\u00b7bar", "fest"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["VVPP", "VAFIN", "$,", "ADJD", "PTKVZ"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Wie in Gef\u00e4ngnisse, und Ketten tragen,", "tokens": ["Wie", "in", "Ge\u00b7f\u00e4ng\u00b7nis\u00b7se", ",", "und", "Ket\u00b7ten", "tra\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "APPR", "NN", "$,", "KON", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Verworrne, harte, die wir nicht verstehen.", "tokens": ["Ver\u00b7worr\u00b7ne", ",", "har\u00b7te", ",", "die", "wir", "nicht", "ver\u00b7ste\u00b7hen", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "$,", "PRELS", "PPER", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Und da\u00df ein jeder fern sich ist und fremd", "tokens": ["Und", "da\u00df", "ein", "je\u00b7der", "fern", "sich", "ist", "und", "fremd"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "ART", "PIAT", "ADJD", "PRF", "VAFIN", "KON", "ADJD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Wie einem Nachbar, den er gar nicht kennt.", "tokens": ["Wie", "ei\u00b7nem", "Nach\u00b7bar", ",", "den", "er", "gar", "nicht", "kennt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "$,", "PRELS", "PPER", "ADV", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Und dessen Haus er immer nur gesehen hat.", "tokens": ["Und", "des\u00b7sen", "Haus", "er", "im\u00b7mer", "nur", "ge\u00b7se\u00b7hen", "hat", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRELAT", "NN", "PPER", "ADV", "ADV", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Manchmal, w\u00e4hrend ich an einem Kinn rasiere,", "tokens": ["Manch\u00b7mal", ",", "w\u00e4h\u00b7rend", "ich", "an", "ei\u00b7nem", "Kinn", "ra\u00b7sie\u00b7re", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "PPER", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.2": {"text": "Wissend, da\u00df ein ganzes Leben", "tokens": ["Wis\u00b7send", ",", "da\u00df", "ein", "gan\u00b7zes", "Le\u00b7ben"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["ADJD", "$,", "KOUS", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "In meiner Macht ist, da\u00df ich Herr nun bin,", "tokens": ["In", "mei\u00b7ner", "Macht", "ist", ",", "da\u00df", "ich", "Herr", "nun", "bin", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VAFIN", "$,", "KOUS", "PPER", "NN", "ADV", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Ich, ein Barbier, und da\u00df ein Schnitt daneben,", "tokens": ["Ich", ",", "ein", "Bar\u00b7bier", ",", "und", "da\u00df", "ein", "Schnitt", "da\u00b7ne\u00b7ben", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "ART", "NN", "$,", "KON", "KOUS", "ART", "NN", "PAV", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Ein Schnitt zu tief, den runden frohen Kopf,", "tokens": ["Ein", "Schnitt", "zu", "tief", ",", "den", "run\u00b7den", "fro\u00b7hen", "Kopf", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKA", "ADJD", "$,", "ART", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Der vor mir liegt [er denkt jetzt an ein Weib,", "tokens": ["Der", "vor", "mir", "liegt", "er", "denkt", "jetzt", "an", "ein", "Weib", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "PPER", "VVFIN", "$(", "PPER", "VVFIN", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "An B\u00fccher, ans Gesch\u00e4ft] abrei\u00dft von seinem Leib,", "tokens": ["An", "B\u00fc\u00b7cher", ",", "ans", "Ge\u00b7sch\u00e4ft", "ab\u00b7rei\u00dft", "von", "sei\u00b7nem", "Leib", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "APPRART", "NN", "$(", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Als w\u00e4re er ein lockrer Westenknopf \u2013", "tokens": ["Als", "w\u00e4\u00b7re", "er", "ein", "lock\u00b7rer", "Wes\u00b7ten\u00b7knopf", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VAFIN", "PPER", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Dann \u00fcberkommts mich. Pl\u00f6tzlich ... Dieses Tier.", "tokens": ["Dann", "\u00fc\u00b7ber\u00b7kommts", "mich", ".", "Pl\u00f6tz\u00b7lich", "...", "Die\u00b7ses", "Tier", "."], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$.", "ADJD", "$(", "PDAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Ist da. Das Tier ... Mir zittern beide Knie.", "tokens": ["Ist", "da", ".", "Das", "Tier", "...", "Mir", "zit\u00b7tern", "bei\u00b7de", "Knie", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "$.", "ART", "NN", "$(", "PPER", "VVFIN", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Und wie ein kleiner Knabe, der Papier", "tokens": ["Und", "wie", "ein", "klei\u00b7ner", "Kna\u00b7be", ",", "der", "Pa\u00b7pier"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "PWAV", "ART", "ADJA", "NN", "$,", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Zerrei\u00dft [und wei\u00df es nicht, warum],", "tokens": ["Zer\u00b7rei\u00dft", "und", "wei\u00df", "es", "nicht", ",", "wa\u00b7rum", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "punct", "punct"], "pos": ["VVFIN", "$(", "KON", "VVFIN", "PPER", "PTKNEG", "$,", "PWAV", "$(", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und wie Studenten, die viel Gaslaternen t\u00f6ten,", "tokens": ["Und", "wie", "Stu\u00b7den\u00b7ten", ",", "die", "viel", "Gas\u00b7la\u00b7ter\u00b7nen", "t\u00f6\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "NN", "$,", "PRELS", "PIAT", "NN", "VVFIN", "$,"], "meter": "--+---+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Und wie die Kinder, die so sehr err\u00f6ten,", "tokens": ["Und", "wie", "die", "Kin\u00b7der", ",", "die", "so", "sehr", "er\u00b7r\u00f6\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ART", "NN", "$,", "PRELS", "ADV", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Wenn sie gefangner Fliegen Fl\u00fcgel brechen,", "tokens": ["Wenn", "sie", "ge\u00b7fang\u00b7ner", "Flie\u00b7gen", "Fl\u00fc\u00b7gel", "bre\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJA", "NN", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "So m\u00f6chte ich oft wie von ungef\u00e4hr,", "tokens": ["So", "m\u00f6ch\u00b7te", "ich", "oft", "wie", "von", "un\u00b7ge\u00b7f\u00e4hr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "KOKOM", "APPR", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Wie wenn es eine Art versehen w\u00e4r,", "tokens": ["Wie", "wenn", "es", "ei\u00b7ne", "Art", "ver\u00b7se\u00b7hen", "w\u00e4r", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOKOM", "KOUS", "PPER", "ART", "NN", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "An solchem Kinn mit meinem Messer ritzen.", "tokens": ["An", "sol\u00b7chem", "Kinn", "mit", "mei\u00b7nem", "Mes\u00b7ser", "rit\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Ich s\u00e4h zu gern den roten Blutstrahl spritzen.", "tokens": ["Ich", "s\u00e4h", "zu", "gern", "den", "ro\u00b7ten", "Bluts\u00b7trahl", "sprit\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ADV", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "So steh ich nun die tr\u00fcben Wintertage", "tokens": ["So", "steh", "ich", "nun", "die", "tr\u00fc\u00b7ben", "Win\u00b7ter\u00b7ta\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Von fr\u00fch bis sp\u00e4t und seife K\u00f6pfe ein,", "tokens": ["Von", "fr\u00fch", "bis", "sp\u00e4t", "und", "sei\u00b7fe", "K\u00f6p\u00b7fe", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJD", "APPR", "ADJD", "KON", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Rasiere sie und pudre sie und sage", "tokens": ["Ra\u00b7sie\u00b7re", "sie", "und", "pud\u00b7re", "sie", "und", "sa\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "KON", "VVFIN", "PPER", "KON", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Gleichg\u00fcltge Worte, dumme, Spielerein.", "tokens": ["Gleich\u00b7g\u00fclt\u00b7ge", "Wor\u00b7te", ",", "dum\u00b7me", ",", "Spie\u00b7ler\u00b7ein", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ADJA", "NN", "$,", "ADJA", "$,", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Die meisten K\u00f6pfe sind ganz zugeschlossen,", "tokens": ["Die", "meis\u00b7ten", "K\u00f6p\u00b7fe", "sind", "ganz", "zu\u00b7ge\u00b7schlos\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VAFIN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Sie schlafen schlaff. Und andre lesen wieder", "tokens": ["Sie", "schla\u00b7fen", "schlaff", ".", "Und", "and\u00b7re", "le\u00b7sen", "wie\u00b7der"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADJD", "$.", "KON", "PIS", "VVFIN", "ADV"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Und blicken langsam durch die langen Lider,", "tokens": ["Und", "bli\u00b7cken", "lang\u00b7sam", "durch", "die", "lan\u00b7gen", "Li\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Als h\u00e4tten sie schon alles ausgenossen.", "tokens": ["Als", "h\u00e4t\u00b7ten", "sie", "schon", "al\u00b7les", "aus\u00b7ge\u00b7nos\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VAFIN", "PPER", "ADV", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Noch andre \u00f6ffnen weit die rote Ritze", "tokens": ["Noch", "and\u00b7re", "\u00f6ff\u00b7nen", "weit", "die", "ro\u00b7te", "Rit\u00b7ze"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "PIS", "VVFIN", "ADJD", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Des Mundes und verk\u00fcnden viele Witze.", "tokens": ["Des", "Mun\u00b7des", "und", "ver\u00b7k\u00fcn\u00b7den", "vie\u00b7le", "Wit\u00b7ze", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "VVFIN", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "Ich aber l\u00e4chle h\u00f6flich. Ach, ich berge", "tokens": ["Ich", "a\u00b7ber", "l\u00e4ch\u00b7le", "h\u00f6f\u00b7lich", ".", "Ach", ",", "ich", "ber\u00b7ge"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["PPER", "ADV", "VVFIN", "ADJD", "$.", "ITJ", "$,", "PPER", "VVFIN"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Tief unter diesem L\u00e4cheln wie in S\u00e4rge", "tokens": ["Tief", "un\u00b7ter", "die\u00b7sem", "L\u00e4\u00b7cheln", "wie", "in", "S\u00e4r\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADJD", "APPR", "PDAT", "NN", "KOKOM", "APPR", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Die schlimmen, \u00fcberwachen, weisen Klagen,", "tokens": ["Die", "schlim\u00b7men", ",", "\u00fc\u00b7ber\u00b7wa\u00b7chen", ",", "wei\u00b7sen", "Kla\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "VVPP", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Da\u00df wir in dieses Dasein eingepre\u00dft,", "tokens": ["Da\u00df", "wir", "in", "die\u00b7ses", "Da\u00b7sein", "ein\u00b7ge\u00b7pre\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PDAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Hineingezw\u00e4ngt sind, unentrinnbar fest", "tokens": ["Hin\u00b7ein\u00b7ge\u00b7zw\u00e4ngt", "sind", ",", "un\u00b7en\u00b7trinn\u00b7bar", "fest"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["VVPP", "VAFIN", "$,", "ADJD", "PTKVZ"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Wie in Gef\u00e4ngnisse, und Ketten tragen,", "tokens": ["Wie", "in", "Ge\u00b7f\u00e4ng\u00b7nis\u00b7se", ",", "und", "Ket\u00b7ten", "tra\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "APPR", "NN", "$,", "KON", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Verworrne, harte, die wir nicht verstehen.", "tokens": ["Ver\u00b7worr\u00b7ne", ",", "har\u00b7te", ",", "die", "wir", "nicht", "ver\u00b7ste\u00b7hen", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "$,", "PRELS", "PPER", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Und da\u00df ein jeder fern sich ist und fremd", "tokens": ["Und", "da\u00df", "ein", "je\u00b7der", "fern", "sich", "ist", "und", "fremd"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "ART", "PIAT", "ADJD", "PRF", "VAFIN", "KON", "ADJD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Wie einem Nachbar, den er gar nicht kennt.", "tokens": ["Wie", "ei\u00b7nem", "Nach\u00b7bar", ",", "den", "er", "gar", "nicht", "kennt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "$,", "PRELS", "PPER", "ADV", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Und dessen Haus er immer nur gesehen hat.", "tokens": ["Und", "des\u00b7sen", "Haus", "er", "im\u00b7mer", "nur", "ge\u00b7se\u00b7hen", "hat", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRELAT", "NN", "PPER", "ADV", "ADV", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Manchmal, w\u00e4hrend ich an einem Kinn rasiere,", "tokens": ["Manch\u00b7mal", ",", "w\u00e4h\u00b7rend", "ich", "an", "ei\u00b7nem", "Kinn", "ra\u00b7sie\u00b7re", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "PPER", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.2": {"text": "Wissend, da\u00df ein ganzes Leben", "tokens": ["Wis\u00b7send", ",", "da\u00df", "ein", "gan\u00b7zes", "Le\u00b7ben"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["ADJD", "$,", "KOUS", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "In meiner Macht ist, da\u00df ich Herr nun bin,", "tokens": ["In", "mei\u00b7ner", "Macht", "ist", ",", "da\u00df", "ich", "Herr", "nun", "bin", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VAFIN", "$,", "KOUS", "PPER", "NN", "ADV", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Ich, ein Barbier, und da\u00df ein Schnitt daneben,", "tokens": ["Ich", ",", "ein", "Bar\u00b7bier", ",", "und", "da\u00df", "ein", "Schnitt", "da\u00b7ne\u00b7ben", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "ART", "NN", "$,", "KON", "KOUS", "ART", "NN", "PAV", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Ein Schnitt zu tief, den runden frohen Kopf,", "tokens": ["Ein", "Schnitt", "zu", "tief", ",", "den", "run\u00b7den", "fro\u00b7hen", "Kopf", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKA", "ADJD", "$,", "ART", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Der vor mir liegt [er denkt jetzt an ein Weib,", "tokens": ["Der", "vor", "mir", "liegt", "er", "denkt", "jetzt", "an", "ein", "Weib", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "PPER", "VVFIN", "$(", "PPER", "VVFIN", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "An B\u00fccher, ans Gesch\u00e4ft] abrei\u00dft von seinem Leib,", "tokens": ["An", "B\u00fc\u00b7cher", ",", "ans", "Ge\u00b7sch\u00e4ft", "ab\u00b7rei\u00dft", "von", "sei\u00b7nem", "Leib", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "APPRART", "NN", "$(", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Als w\u00e4re er ein lockrer Westenknopf \u2013", "tokens": ["Als", "w\u00e4\u00b7re", "er", "ein", "lock\u00b7rer", "Wes\u00b7ten\u00b7knopf", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VAFIN", "PPER", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Dann \u00fcberkommts mich. Pl\u00f6tzlich ... Dieses Tier.", "tokens": ["Dann", "\u00fc\u00b7ber\u00b7kommts", "mich", ".", "Pl\u00f6tz\u00b7lich", "...", "Die\u00b7ses", "Tier", "."], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$.", "ADJD", "$(", "PDAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Ist da. Das Tier ... Mir zittern beide Knie.", "tokens": ["Ist", "da", ".", "Das", "Tier", "...", "Mir", "zit\u00b7tern", "bei\u00b7de", "Knie", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "$.", "ART", "NN", "$(", "PPER", "VVFIN", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.8": {"line.1": {"text": "Und wie ein kleiner Knabe, der Papier", "tokens": ["Und", "wie", "ein", "klei\u00b7ner", "Kna\u00b7be", ",", "der", "Pa\u00b7pier"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "PWAV", "ART", "ADJA", "NN", "$,", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Zerrei\u00dft [und wei\u00df es nicht, warum],", "tokens": ["Zer\u00b7rei\u00dft", "und", "wei\u00df", "es", "nicht", ",", "wa\u00b7rum", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "punct", "punct"], "pos": ["VVFIN", "$(", "KON", "VVFIN", "PPER", "PTKNEG", "$,", "PWAV", "$(", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und wie Studenten, die viel Gaslaternen t\u00f6ten,", "tokens": ["Und", "wie", "Stu\u00b7den\u00b7ten", ",", "die", "viel", "Gas\u00b7la\u00b7ter\u00b7nen", "t\u00f6\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "NN", "$,", "PRELS", "PIAT", "NN", "VVFIN", "$,"], "meter": "--+---+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Und wie die Kinder, die so sehr err\u00f6ten,", "tokens": ["Und", "wie", "die", "Kin\u00b7der", ",", "die", "so", "sehr", "er\u00b7r\u00f6\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ART", "NN", "$,", "PRELS", "ADV", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Wenn sie gefangner Fliegen Fl\u00fcgel brechen,", "tokens": ["Wenn", "sie", "ge\u00b7fang\u00b7ner", "Flie\u00b7gen", "Fl\u00fc\u00b7gel", "bre\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJA", "NN", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "So m\u00f6chte ich oft wie von ungef\u00e4hr,", "tokens": ["So", "m\u00f6ch\u00b7te", "ich", "oft", "wie", "von", "un\u00b7ge\u00b7f\u00e4hr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "KOKOM", "APPR", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Wie wenn es eine Art versehen w\u00e4r,", "tokens": ["Wie", "wenn", "es", "ei\u00b7ne", "Art", "ver\u00b7se\u00b7hen", "w\u00e4r", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOKOM", "KOUS", "PPER", "ART", "NN", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "An solchem Kinn mit meinem Messer ritzen.", "tokens": ["An", "sol\u00b7chem", "Kinn", "mit", "mei\u00b7nem", "Mes\u00b7ser", "rit\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Ich s\u00e4h zu gern den roten Blutstrahl spritzen.", "tokens": ["Ich", "s\u00e4h", "zu", "gern", "den", "ro\u00b7ten", "Bluts\u00b7trahl", "sprit\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ADV", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}}}}