{"textgrid.poem.62816": {"metadata": {"author": {"name": "Pfeffel, Gottlieb Konrad", "birth": "N.A.", "death": "N.A."}, "title": "1L: J\u00fcngst bi\u00df ein Floh ein altes Weib", "genre": "verse", "period": "N.A.", "pub_year": 1764, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "J\u00fcngst bi\u00df ein Floh ein altes Weib", "tokens": ["J\u00fcngst", "bi\u00df", "ein", "Floh", "ein", "al\u00b7tes", "Weib"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "ART", "NN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Gerade da sie beten wollte:", "tokens": ["Ge\u00b7ra\u00b7de", "da", "sie", "be\u00b7ten", "woll\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PPER", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Sie fuhr ihn nach, packt ihn beym Leib", "tokens": ["Sie", "fuhr", "ihn", "nach", ",", "packt", "ihn", "beym", "Leib"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "PTKVZ", "$,", "VVFIN", "PPER", "APPRART", "NN"], "meter": "-+-+---+", "measure": "unknown.measure.tri"}, "line.4": {"text": "Und schwor ihm, da\u00df er sterben sollte.", "tokens": ["Und", "schwor", "ihm", ",", "da\u00df", "er", "ster\u00b7ben", "soll\u00b7te", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "$,", "KOUS", "PPER", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Ach, fieng der arme S\u00fcnder an,", "tokens": ["Ach", ",", "fi\u00b7eng", "der", "ar\u00b7me", "S\u00fcn\u00b7der", "an", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "VVFIN", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Gestrenge Mutter, Gnade, Gnade!", "tokens": ["Ge\u00b7stren\u00b7ge", "Mut\u00b7ter", ",", "Gna\u00b7de", ",", "Gna\u00b7de", "!"], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "NN", "$,", "NN", "$,", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Ich habe dir ja nichts gethan;", "tokens": ["Ich", "ha\u00b7be", "dir", "ja", "nichts", "ge\u00b7than", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "PIS", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ein Flohstich ist ein kleiner Schade.", "tokens": ["Ein", "Floh\u00b7stich", "ist", "ein", "klei\u00b7ner", "Scha\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Nein, sprach sie, hoffe nichts von mir!", "tokens": ["Nein", ",", "sprach", "sie", ",", "hof\u00b7fe", "nichts", "von", "mir", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "VVFIN", "PPER", "$,", "VVFIN", "PIS", "APPR", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das Ungl\u00fcck ist zwar klein zu nennen;", "tokens": ["Das", "Un\u00b7gl\u00fcck", "ist", "zwar", "klein", "zu", "nen\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Allein die Schuld lag nicht an dir,", "tokens": ["Al\u00b7lein", "die", "Schuld", "lag", "nicht", "an", "dir", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVFIN", "PTKNEG", "APPR", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Du hast mir mehr nicht schaden k\u00f6nnen.", "tokens": ["Du", "hast", "mir", "mehr", "nicht", "scha\u00b7den", "k\u00f6n\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "PTKNEG", "VVINF", "VMINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "J\u00fcngst bi\u00df ein Floh ein altes Weib", "tokens": ["J\u00fcngst", "bi\u00df", "ein", "Floh", "ein", "al\u00b7tes", "Weib"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "ART", "NN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Gerade da sie beten wollte:", "tokens": ["Ge\u00b7ra\u00b7de", "da", "sie", "be\u00b7ten", "woll\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PPER", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Sie fuhr ihn nach, packt ihn beym Leib", "tokens": ["Sie", "fuhr", "ihn", "nach", ",", "packt", "ihn", "beym", "Leib"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "PTKVZ", "$,", "VVFIN", "PPER", "APPRART", "NN"], "meter": "-+-+---+", "measure": "unknown.measure.tri"}, "line.4": {"text": "Und schwor ihm, da\u00df er sterben sollte.", "tokens": ["Und", "schwor", "ihm", ",", "da\u00df", "er", "ster\u00b7ben", "soll\u00b7te", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "$,", "KOUS", "PPER", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Ach, fieng der arme S\u00fcnder an,", "tokens": ["Ach", ",", "fi\u00b7eng", "der", "ar\u00b7me", "S\u00fcn\u00b7der", "an", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "VVFIN", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Gestrenge Mutter, Gnade, Gnade!", "tokens": ["Ge\u00b7stren\u00b7ge", "Mut\u00b7ter", ",", "Gna\u00b7de", ",", "Gna\u00b7de", "!"], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "NN", "$,", "NN", "$,", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Ich habe dir ja nichts gethan;", "tokens": ["Ich", "ha\u00b7be", "dir", "ja", "nichts", "ge\u00b7than", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "PIS", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ein Flohstich ist ein kleiner Schade.", "tokens": ["Ein", "Floh\u00b7stich", "ist", "ein", "klei\u00b7ner", "Scha\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Nein, sprach sie, hoffe nichts von mir!", "tokens": ["Nein", ",", "sprach", "sie", ",", "hof\u00b7fe", "nichts", "von", "mir", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "VVFIN", "PPER", "$,", "VVFIN", "PIS", "APPR", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das Ungl\u00fcck ist zwar klein zu nennen;", "tokens": ["Das", "Un\u00b7gl\u00fcck", "ist", "zwar", "klein", "zu", "nen\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Allein die Schuld lag nicht an dir,", "tokens": ["Al\u00b7lein", "die", "Schuld", "lag", "nicht", "an", "dir", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVFIN", "PTKNEG", "APPR", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Du hast mir mehr nicht schaden k\u00f6nnen.", "tokens": ["Du", "hast", "mir", "mehr", "nicht", "scha\u00b7den", "k\u00f6n\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "PTKNEG", "VVINF", "VMINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}