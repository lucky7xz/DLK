{"textgrid.poem.37822": {"metadata": {"author": {"name": "Arnim, Ludwig Achim von", "birth": "N.A.", "death": "N.A."}, "title": "Die Diebsstellung", "genre": "verse", "period": "N.A.", "pub_year": 1806, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Maria in den Garten trat,", "tokens": ["Ma\u00b7ria", "in", "den", "Gar\u00b7ten", "trat", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Begegnen ihr drey J\u00fcngling zart.", "tokens": ["Be\u00b7geg\u00b7nen", "ihr", "drey", "J\u00fcng\u00b7ling", "zart", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "CARD", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Der erste war Sankt Daniel,", "tokens": ["Der", "ers\u00b7te", "war", "Sankt", "Da\u00b7ni\u00b7el", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VAFIN", "VVFIN", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dann Raphael, dann Michael.", "tokens": ["Dann", "Ra\u00b7phael", ",", "dann", "Mic\u00b7hael", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "NE", "$,", "ADV", "NE", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.3": {"line.1": {"text": "Sankt Daniel zu ihr da lacht,", "tokens": ["Sankt", "Da\u00b7ni\u00b7el", "zu", "ihr", "da", "lacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "APPR", "PPER", "ADV", "VVFIN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Die Jungfrau spricht: \u00bbWas hast gelacht?", "tokens": ["Die", "Jung\u00b7frau", "spricht", ":", "\u00bb", "Was", "hast", "ge\u00b7lacht", "?"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$.", "$(", "PWS", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Sankt Daniel spricht: \u00bbIch wacht zu Nacht,", "tokens": ["Sankt", "Da\u00b7ni\u00b7el", "spricht", ":", "\u00bb", "Ich", "wacht", "zu", "Nacht", ","], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "VVFIN", "$.", "$(", "PPER", "VVFIN", "APPR", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Zwey Dieb die hatten sich erdacht:", "tokens": ["Zwey", "Dieb", "die", "hat\u00b7ten", "sich", "er\u00b7dacht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "ART", "VAFIN", "PRF", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Vermassen sich wohl zu geschwind,", "tokens": ["Ver\u00b7mas\u00b7sen", "sich", "wohl", "zu", "ge\u00b7schwind", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ADV", "PTKA", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Zu stehln dein allerliebstes Kind.\u00ab", "tokens": ["Zu", "stehln", "dein", "al\u00b7ler\u00b7liebs\u00b7tes", "Kind", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PTKZU", "VVINF", "PPOSAT", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Sie spricht: \u00bbDas wird nun werden gut,", "tokens": ["Sie", "spricht", ":", "\u00bb", "Das", "wird", "nun", "wer\u00b7den", "gut", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "$(", "PDS", "VAFIN", "ADV", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dann wer mein Kindlein stehlen thut,", "tokens": ["Dann", "wer", "mein", "Kin\u00b7dlein", "steh\u00b7len", "thut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PWS", "PPOSAT", "NN", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Den m\u00fcst ihr binden an die Schwell,", "tokens": ["Den", "m\u00fcst", "ihr", "bin\u00b7den", "an", "die", "Schwell", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VMFIN", "PPER", "VVINF", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df er nicht kann von seiner Stell.\u00ab", "tokens": ["Da\u00df", "er", "nicht", "kann", "von", "sei\u00b7ner", "Stell", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "VMFIN", "APPR", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "\u00bbsankt Raphael, Sankt Michael,", "tokens": ["\u00bb", "sankt", "Ra\u00b7phael", ",", "Sankt", "Mic\u00b7hael", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "VVFIN", "NE", "$,", "VVFIN", "NE", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Ihr bindet ihn da an die Stell.\u00ab", "tokens": ["Ihr", "bin\u00b7det", "ihn", "da", "an", "die", "Stell", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "APPR", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Sankt Daniel sprach: \u00bbEy seht nur an,", "tokens": ["Sankt", "Da\u00b7ni\u00b7el", "sprach", ":", "\u00bb", "Ey", "seht", "nur", "an", ","], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "VVFIN", "$.", "$(", "NN", "VVFIN", "ADV", "PTKVZ", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Da stehen sie noch Mann f\u00fcr Mann.", "tokens": ["Da", "ste\u00b7hen", "sie", "noch", "Mann", "f\u00fcr", "Mann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Der Schwei\u00df der l\u00e4uft von ihnen sehr,", "tokens": ["Der", "Schwei\u00df", "der", "l\u00e4uft", "von", "ih\u00b7nen", "sehr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "VVFIN", "APPR", "PPER", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die wagen umzusehn nicht mehr,", "tokens": ["Die", "wa\u00b7gen", "um\u00b7zu\u00b7sehn", "nicht", "mehr", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "VVINF", "VVIZU", "PTKNEG", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Gebunden sind in eiserm Band,", "tokens": ["Ge\u00b7bun\u00b7den", "sind", "in", "ei\u00b7serm", "Band", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "An Gottes Erd, von Gottes Hand,", "tokens": ["An", "Got\u00b7tes", "Erd", ",", "von", "Got\u00b7tes", "Hand", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "NN", "$,", "APPR", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Sie stehen da wie Stock und Stein,", "tokens": ["Sie", "ste\u00b7hen", "da", "wie", "Stock", "und", "Stein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "KOKOM", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Bis sie die Stern gez\u00e4hlet ein,", "tokens": ["Bis", "sie", "die", "Stern", "ge\u00b7z\u00e4h\u00b7let", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVPP", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Bis sie den Sand am Meer gez\u00e4hlt,", "tokens": ["Bis", "sie", "den", "Sand", "am", "Meer", "ge\u00b7z\u00e4hlt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die ungebornen Kind der Welt.\u00ab", "tokens": ["Die", "un\u00b7ge\u00b7bor\u00b7nen", "Kind", "der", "Welt", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Maria sie aus Banden nahm,", "tokens": ["Ma\u00b7ria", "sie", "aus", "Ban\u00b7den", "nahm", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "APPR", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Wer Rechtes thut hat keine Scham.", "tokens": ["Wer", "Rech\u00b7tes", "thut", "hat", "kei\u00b7ne", "Scham", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "VVFIN", "VAFIN", "PIAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "Maria in den Garten trat,", "tokens": ["Ma\u00b7ria", "in", "den", "Gar\u00b7ten", "trat", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Begegnen ihr drey J\u00fcngling zart.", "tokens": ["Be\u00b7geg\u00b7nen", "ihr", "drey", "J\u00fcng\u00b7ling", "zart", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "CARD", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "Der erste war Sankt Daniel,", "tokens": ["Der", "ers\u00b7te", "war", "Sankt", "Da\u00b7ni\u00b7el", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VAFIN", "VVFIN", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dann Raphael, dann Michael.", "tokens": ["Dann", "Ra\u00b7phael", ",", "dann", "Mic\u00b7hael", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "NE", "$,", "ADV", "NE", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.17": {"line.1": {"text": "Sankt Daniel zu ihr da lacht,", "tokens": ["Sankt", "Da\u00b7ni\u00b7el", "zu", "ihr", "da", "lacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "APPR", "PPER", "ADV", "VVFIN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Die Jungfrau spricht: \u00bbWas hast gelacht?", "tokens": ["Die", "Jung\u00b7frau", "spricht", ":", "\u00bb", "Was", "hast", "ge\u00b7lacht", "?"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$.", "$(", "PWS", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.18": {"line.1": {"text": "Sankt Daniel spricht: \u00bbIch wacht zu Nacht,", "tokens": ["Sankt", "Da\u00b7ni\u00b7el", "spricht", ":", "\u00bb", "Ich", "wacht", "zu", "Nacht", ","], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "VVFIN", "$.", "$(", "PPER", "VVFIN", "APPR", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Zwey Dieb die hatten sich erdacht:", "tokens": ["Zwey", "Dieb", "die", "hat\u00b7ten", "sich", "er\u00b7dacht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "ART", "VAFIN", "PRF", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.19": {"line.1": {"text": "Vermassen sich wohl zu geschwind,", "tokens": ["Ver\u00b7mas\u00b7sen", "sich", "wohl", "zu", "ge\u00b7schwind", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ADV", "PTKA", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Zu stehln dein allerliebstes Kind.\u00ab", "tokens": ["Zu", "stehln", "dein", "al\u00b7ler\u00b7liebs\u00b7tes", "Kind", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PTKZU", "VVINF", "PPOSAT", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.20": {"line.1": {"text": "Sie spricht: \u00bbDas wird nun werden gut,", "tokens": ["Sie", "spricht", ":", "\u00bb", "Das", "wird", "nun", "wer\u00b7den", "gut", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "$(", "PDS", "VAFIN", "ADV", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dann wer mein Kindlein stehlen thut,", "tokens": ["Dann", "wer", "mein", "Kin\u00b7dlein", "steh\u00b7len", "thut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PWS", "PPOSAT", "NN", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.21": {"line.1": {"text": "Den m\u00fcst ihr binden an die Schwell,", "tokens": ["Den", "m\u00fcst", "ihr", "bin\u00b7den", "an", "die", "Schwell", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VMFIN", "PPER", "VVINF", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df er nicht kann von seiner Stell.\u00ab", "tokens": ["Da\u00df", "er", "nicht", "kann", "von", "sei\u00b7ner", "Stell", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "VMFIN", "APPR", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.22": {"line.1": {"text": "\u00bbsankt Raphael, Sankt Michael,", "tokens": ["\u00bb", "sankt", "Ra\u00b7phael", ",", "Sankt", "Mic\u00b7hael", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "VVFIN", "NE", "$,", "VVFIN", "NE", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Ihr bindet ihn da an die Stell.\u00ab", "tokens": ["Ihr", "bin\u00b7det", "ihn", "da", "an", "die", "Stell", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "APPR", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.23": {"line.1": {"text": "Sankt Daniel sprach: \u00bbEy seht nur an,", "tokens": ["Sankt", "Da\u00b7ni\u00b7el", "sprach", ":", "\u00bb", "Ey", "seht", "nur", "an", ","], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "VVFIN", "$.", "$(", "NN", "VVFIN", "ADV", "PTKVZ", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Da stehen sie noch Mann f\u00fcr Mann.", "tokens": ["Da", "ste\u00b7hen", "sie", "noch", "Mann", "f\u00fcr", "Mann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.24": {"line.1": {"text": "Der Schwei\u00df der l\u00e4uft von ihnen sehr,", "tokens": ["Der", "Schwei\u00df", "der", "l\u00e4uft", "von", "ih\u00b7nen", "sehr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "VVFIN", "APPR", "PPER", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die wagen umzusehn nicht mehr,", "tokens": ["Die", "wa\u00b7gen", "um\u00b7zu\u00b7sehn", "nicht", "mehr", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "VVINF", "VVIZU", "PTKNEG", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.25": {"line.1": {"text": "Gebunden sind in eiserm Band,", "tokens": ["Ge\u00b7bun\u00b7den", "sind", "in", "ei\u00b7serm", "Band", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "An Gottes Erd, von Gottes Hand,", "tokens": ["An", "Got\u00b7tes", "Erd", ",", "von", "Got\u00b7tes", "Hand", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "NN", "$,", "APPR", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.26": {"line.1": {"text": "Sie stehen da wie Stock und Stein,", "tokens": ["Sie", "ste\u00b7hen", "da", "wie", "Stock", "und", "Stein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "KOKOM", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Bis sie die Stern gez\u00e4hlet ein,", "tokens": ["Bis", "sie", "die", "Stern", "ge\u00b7z\u00e4h\u00b7let", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVPP", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.27": {"line.1": {"text": "Bis sie den Sand am Meer gez\u00e4hlt,", "tokens": ["Bis", "sie", "den", "Sand", "am", "Meer", "ge\u00b7z\u00e4hlt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die ungebornen Kind der Welt.\u00ab", "tokens": ["Die", "un\u00b7ge\u00b7bor\u00b7nen", "Kind", "der", "Welt", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.28": {"line.1": {"text": "Maria sie aus Banden nahm,", "tokens": ["Ma\u00b7ria", "sie", "aus", "Ban\u00b7den", "nahm", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "APPR", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Wer Rechtes thut hat keine Scham.", "tokens": ["Wer", "Rech\u00b7tes", "thut", "hat", "kei\u00b7ne", "Scham", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "VVFIN", "VAFIN", "PIAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}