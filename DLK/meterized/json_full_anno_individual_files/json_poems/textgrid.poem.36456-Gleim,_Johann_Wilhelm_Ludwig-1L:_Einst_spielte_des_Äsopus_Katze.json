{"textgrid.poem.36456": {"metadata": {"author": {"name": "Gleim, Johann Wilhelm Ludwig", "birth": "N.A.", "death": "N.A."}, "title": "1L: Einst spielte des \u00c4sopus Katze", "genre": "verse", "period": "N.A.", "pub_year": 1761, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Einst spielte des \u00c4sopus Katze", "tokens": ["Einst", "spiel\u00b7te", "des", "\u00c4\u00b7so\u00b7pus", "Kat\u00b7ze"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Mit einer kleinen Maus.", "tokens": ["Mit", "ei\u00b7ner", "klei\u00b7nen", "Maus", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Lauf, M\u00e4uschen! sagte sie, und warf die scharfe Tatze", "tokens": ["Lauf", ",", "M\u00e4u\u00b7schen", "!", "sag\u00b7te", "sie", ",", "und", "warf", "die", "schar\u00b7fe", "Tat\u00b7ze"], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "NN", "$.", "VVFIN", "PPER", "$,", "KON", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Liebkosend nach, lie\u00df auf und nieder", "tokens": ["Lieb\u00b7ko\u00b7send", "nach", ",", "lie\u00df", "auf", "und", "nie\u00b7der"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADJD", "PTKVZ", "$,", "VVFIN", "PTKVZ", "KON", "PTKVZ"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Sie laufen, fing sie wieder,", "tokens": ["Sie", "lau\u00b7fen", ",", "fing", "sie", "wie\u00b7der", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "VVFIN", "PPER", "ADV", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und sah' vergn\u00fcgt und freundlich aus.", "tokens": ["Und", "sah'", "ver\u00b7gn\u00fcgt", "und", "freund\u00b7lich", "aus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "VVPP", "KON", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Ach liebe Katze! sprach die Maus,", "tokens": ["Ach", "lie\u00b7be", "Kat\u00b7ze", "!", "sprach", "die", "Maus", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ITJ", "VVFIN", "NN", "$.", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ich kenne diese Schmeicheleien", "tokens": ["Ich", "ken\u00b7ne", "die\u00b7se", "Schmei\u00b7che\u00b7lei\u00b7en"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PDAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und diese Scherze; ach! sie dr\u00e4uen", "tokens": ["Und", "die\u00b7se", "Scher\u00b7ze", ";", "ach", "!", "sie", "dr\u00e4u\u00b7en"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["KON", "PDAT", "NN", "$.", "XY", "$.", "PPER", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Mir armen M\u00e4uschen meinen Tod!", "tokens": ["Mir", "ar\u00b7men", "M\u00e4u\u00b7schen", "mei\u00b7nen", "Tod", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Was? sprach die Katze, das ist Spott!", "tokens": ["Was", "?", "sprach", "die", "Kat\u00b7ze", ",", "das", "ist", "Spott", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "$.", "VVFIN", "ART", "NN", "$,", "PDS", "VAFIN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und bi\u00df sie tot!", "tokens": ["Und", "bi\u00df", "sie", "tot", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADJD", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.5": {"line.1": {"text": "Einst spielte des \u00c4sopus Katze", "tokens": ["Einst", "spiel\u00b7te", "des", "\u00c4\u00b7so\u00b7pus", "Kat\u00b7ze"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Mit einer kleinen Maus.", "tokens": ["Mit", "ei\u00b7ner", "klei\u00b7nen", "Maus", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Lauf, M\u00e4uschen! sagte sie, und warf die scharfe Tatze", "tokens": ["Lauf", ",", "M\u00e4u\u00b7schen", "!", "sag\u00b7te", "sie", ",", "und", "warf", "die", "schar\u00b7fe", "Tat\u00b7ze"], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "NN", "$.", "VVFIN", "PPER", "$,", "KON", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Liebkosend nach, lie\u00df auf und nieder", "tokens": ["Lieb\u00b7ko\u00b7send", "nach", ",", "lie\u00df", "auf", "und", "nie\u00b7der"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADJD", "PTKVZ", "$,", "VVFIN", "PTKVZ", "KON", "PTKVZ"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Sie laufen, fing sie wieder,", "tokens": ["Sie", "lau\u00b7fen", ",", "fing", "sie", "wie\u00b7der", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "VVFIN", "PPER", "ADV", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und sah' vergn\u00fcgt und freundlich aus.", "tokens": ["Und", "sah'", "ver\u00b7gn\u00fcgt", "und", "freund\u00b7lich", "aus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "VVPP", "KON", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Ach liebe Katze! sprach die Maus,", "tokens": ["Ach", "lie\u00b7be", "Kat\u00b7ze", "!", "sprach", "die", "Maus", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ITJ", "VVFIN", "NN", "$.", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ich kenne diese Schmeicheleien", "tokens": ["Ich", "ken\u00b7ne", "die\u00b7se", "Schmei\u00b7che\u00b7lei\u00b7en"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PDAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und diese Scherze; ach! sie dr\u00e4uen", "tokens": ["Und", "die\u00b7se", "Scher\u00b7ze", ";", "ach", "!", "sie", "dr\u00e4u\u00b7en"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["KON", "PDAT", "NN", "$.", "XY", "$.", "PPER", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Mir armen M\u00e4uschen meinen Tod!", "tokens": ["Mir", "ar\u00b7men", "M\u00e4u\u00b7schen", "mei\u00b7nen", "Tod", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Was? sprach die Katze, das ist Spott!", "tokens": ["Was", "?", "sprach", "die", "Kat\u00b7ze", ",", "das", "ist", "Spott", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "$.", "VVFIN", "ART", "NN", "$,", "PDS", "VAFIN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und bi\u00df sie tot!", "tokens": ["Und", "bi\u00df", "sie", "tot", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADJD", "$."], "meter": "-+-+", "measure": "iambic.di"}}}}}