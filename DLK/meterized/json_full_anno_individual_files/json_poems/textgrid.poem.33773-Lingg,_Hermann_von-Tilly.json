{"textgrid.poem.33773": {"metadata": {"author": {"name": "Lingg, Hermann von", "birth": "N.A.", "death": "N.A."}, "title": "Tilly", "genre": "verse", "period": "N.A.", "pub_year": 1862, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wer ist ", "tokens": ["Wer", "ist"], "token_info": ["word", "word"], "pos": ["PWS", "VAFIN"], "meter": "-+", "measure": "iambic.single"}, "line.2": {"text": "Jenes steinerne Gesicht,", "tokens": ["Je\u00b7nes", "stei\u00b7ner\u00b7ne", "Ge\u00b7sicht", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PDAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Jener Reiter, hoch und hager? \u2013", "tokens": ["Je\u00b7ner", "Rei\u00b7ter", ",", "hoch", "und", "ha\u00b7ger", "?", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["PDAT", "NN", "$,", "ADJD", "KON", "ADJD", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Was? Du kennst den Tilly nicht?", "tokens": ["Was", "?", "Du", "kennst", "den", "Til\u00b7ly", "nicht", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "$.", "PPER", "VVFIN", "ART", "NE", "PTKNEG", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Auf dem Hut die rote Feder", "tokens": ["Auf", "dem", "Hut", "die", "ro\u00b7te", "Fe\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Gibt ihm rechten Teufelsschein,", "tokens": ["Gibt", "ihm", "rech\u00b7ten", "Teu\u00b7fels\u00b7schein", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Durch sein Wams von Elenleder", "tokens": ["Durch", "sein", "Wams", "von", "E\u00b7len\u00b7le\u00b7der"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Drang noch keine Kugel ein.", "tokens": ["Drang", "noch", "kei\u00b7ne", "Ku\u00b7gel", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "PIAT", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Gleicht er nicht den letzten Boten,", "tokens": ["Gleicht", "er", "nicht", "den", "letz\u00b7ten", "Bo\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKNEG", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Einem jener Reiter nicht,", "tokens": ["Ei\u00b7nem", "je\u00b7ner", "Rei\u00b7ter", "nicht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "PDAT", "NN", "PTKNEG", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Die dereinst durchs Feld der Toten", "tokens": ["Die", "de\u00b7reinst", "durchs", "Feld", "der", "To\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "APPRART", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Laden zu dem Weltgericht?", "tokens": ["La\u00b7den", "zu", "dem", "Welt\u00b7ge\u00b7richt", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Auf ein Haus im d\u00fcrren Rasen", "tokens": ["Auf", "ein", "Haus", "im", "d\u00fcr\u00b7ren", "Ra\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "APPRART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Trabt er zu, rasch steigt er ab,", "tokens": ["Trabt", "er", "zu", ",", "rasch", "steigt", "er", "ab", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKVZ", "$,", "ADJD", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und die Heertrompeter blasen", "tokens": ["Und", "die", "Heer\u00b7trom\u00b7pe\u00b7ter", "bla\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Zur Beratung seinen Stab.", "tokens": ["Zur", "Be\u00b7ra\u00b7tung", "sei\u00b7nen", "Stab", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Denn vor Leipzig gibt es morgen", "tokens": ["Denn", "vor", "Leip\u00b7zig", "gibt", "es", "mor\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "NE", "VVFIN", "PPER", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Eine schwere, hei\u00dfe Schlacht,", "tokens": ["Ei\u00b7ne", "schwe\u00b7re", ",", "hei\u00b7\u00dfe", "Schlacht", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und er hat darob in Sorgen", "tokens": ["Und", "er", "hat", "da\u00b7rob", "in", "Sor\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VAFIN", "PAV", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Manche Stunde zugebracht.", "tokens": ["Man\u00b7che", "Stun\u00b7de", "zu\u00b7ge\u00b7bracht", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Soll er freventlich es wagen", "tokens": ["Soll", "er", "fre\u00b7vent\u00b7lich", "es", "wa\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VMFIN", "PPER", "ADJD", "PPER", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und versuchen sein Geschick?", "tokens": ["Und", "ver\u00b7su\u00b7chen", "sein", "Ge\u00b7schick", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und als wollt' er Geister fragen,", "tokens": ["Und", "als", "wollt'", "er", "Geis\u00b7ter", "fra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "VMFIN", "PPER", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Sp\u00e4ht durchs Fenster starr sein Blick.", "tokens": ["Sp\u00e4ht", "durchs", "Fens\u00b7ter", "starr", "sein", "Blick", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPRART", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Sieh, da tritt ein Alter eben", "tokens": ["Sieh", ",", "da", "tritt", "ein", "Al\u00b7ter", "e\u00b7ben"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NE", "$,", "ADV", "VVFIN", "ART", "NN", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Durch die T\u00fcr und fl\u00fcstert klug:", "tokens": ["Durch", "die", "T\u00fcr", "und", "fl\u00fcs\u00b7tert", "klug", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "KON", "VVFIN", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "\u00bbmorgen wird es Arbeit geben,", "tokens": ["\u00bb", "mor\u00b7gen", "wird", "es", "Ar\u00b7beit", "ge\u00b7ben", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VAFIN", "PPER", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Mir und Euch, o Herr, genug!\u00ab", "tokens": ["Mir", "und", "Euch", ",", "o", "Herr", ",", "ge\u00b7nug", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct", "punct"], "pos": ["NE", "KON", "PPER", "$,", "FM", "NN", "$,", "ADV", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Auff\u00e4hrt Tilly: \u00bbMir, wie Keinem!", "tokens": ["Auf\u00b7f\u00e4hrt", "Til\u00b7ly", ":", "\u00bb", "Mir", ",", "wie", "Kei\u00b7nem", "!"], "token_info": ["word", "word", "punct", "punct", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "NE", "$.", "$(", "NE", "$,", "PWAV", "PIS", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Frecher, fort!\u00ab Und Meister Klaus", "tokens": ["Fre\u00b7cher", ",", "fort", "!", "\u00ab", "Und", "Meis\u00b7ter", "Klaus"], "token_info": ["word", "punct", "word", "punct", "punct", "word", "word", "word"], "pos": ["NN", "$,", "PTKVZ", "$.", "$(", "KON", "NE", "NE"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "B\u00fcckt sich: \u00bbHerr, Ihr seid in meinem,", "tokens": ["B\u00fcckt", "sich", ":", "\u00bb", "Herr", ",", "Ihr", "seid", "in", "mei\u00b7nem", ","], "token_info": ["word", "word", "punct", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "$.", "$(", "NN", "$,", "PPER", "VAFIN", "APPR", "PPOSAT", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "In des Totengr\u00e4bers Haus.\u00ab", "tokens": ["In", "des", "To\u00b7ten\u00b7gr\u00e4\u00b7bers", "Haus", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "ART", "NN", "NN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Wer ist ", "tokens": ["Wer", "ist"], "token_info": ["word", "word"], "pos": ["PWS", "VAFIN"], "meter": "-+", "measure": "iambic.single"}, "line.2": {"text": "Jenes steinerne Gesicht,", "tokens": ["Je\u00b7nes", "stei\u00b7ner\u00b7ne", "Ge\u00b7sicht", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PDAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Jener Reiter, hoch und hager? \u2013", "tokens": ["Je\u00b7ner", "Rei\u00b7ter", ",", "hoch", "und", "ha\u00b7ger", "?", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["PDAT", "NN", "$,", "ADJD", "KON", "ADJD", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Was? Du kennst den Tilly nicht?", "tokens": ["Was", "?", "Du", "kennst", "den", "Til\u00b7ly", "nicht", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "$.", "PPER", "VVFIN", "ART", "NE", "PTKNEG", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Auf dem Hut die rote Feder", "tokens": ["Auf", "dem", "Hut", "die", "ro\u00b7te", "Fe\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Gibt ihm rechten Teufelsschein,", "tokens": ["Gibt", "ihm", "rech\u00b7ten", "Teu\u00b7fels\u00b7schein", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Durch sein Wams von Elenleder", "tokens": ["Durch", "sein", "Wams", "von", "E\u00b7len\u00b7le\u00b7der"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Drang noch keine Kugel ein.", "tokens": ["Drang", "noch", "kei\u00b7ne", "Ku\u00b7gel", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "PIAT", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Gleicht er nicht den letzten Boten,", "tokens": ["Gleicht", "er", "nicht", "den", "letz\u00b7ten", "Bo\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKNEG", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Einem jener Reiter nicht,", "tokens": ["Ei\u00b7nem", "je\u00b7ner", "Rei\u00b7ter", "nicht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "PDAT", "NN", "PTKNEG", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Die dereinst durchs Feld der Toten", "tokens": ["Die", "de\u00b7reinst", "durchs", "Feld", "der", "To\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "APPRART", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Laden zu dem Weltgericht?", "tokens": ["La\u00b7den", "zu", "dem", "Welt\u00b7ge\u00b7richt", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Auf ein Haus im d\u00fcrren Rasen", "tokens": ["Auf", "ein", "Haus", "im", "d\u00fcr\u00b7ren", "Ra\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "APPRART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Trabt er zu, rasch steigt er ab,", "tokens": ["Trabt", "er", "zu", ",", "rasch", "steigt", "er", "ab", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKVZ", "$,", "ADJD", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und die Heertrompeter blasen", "tokens": ["Und", "die", "Heer\u00b7trom\u00b7pe\u00b7ter", "bla\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Zur Beratung seinen Stab.", "tokens": ["Zur", "Be\u00b7ra\u00b7tung", "sei\u00b7nen", "Stab", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Denn vor Leipzig gibt es morgen", "tokens": ["Denn", "vor", "Leip\u00b7zig", "gibt", "es", "mor\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "NE", "VVFIN", "PPER", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Eine schwere, hei\u00dfe Schlacht,", "tokens": ["Ei\u00b7ne", "schwe\u00b7re", ",", "hei\u00b7\u00dfe", "Schlacht", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und er hat darob in Sorgen", "tokens": ["Und", "er", "hat", "da\u00b7rob", "in", "Sor\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VAFIN", "PAV", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Manche Stunde zugebracht.", "tokens": ["Man\u00b7che", "Stun\u00b7de", "zu\u00b7ge\u00b7bracht", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "Soll er freventlich es wagen", "tokens": ["Soll", "er", "fre\u00b7vent\u00b7lich", "es", "wa\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VMFIN", "PPER", "ADJD", "PPER", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und versuchen sein Geschick?", "tokens": ["Und", "ver\u00b7su\u00b7chen", "sein", "Ge\u00b7schick", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und als wollt' er Geister fragen,", "tokens": ["Und", "als", "wollt'", "er", "Geis\u00b7ter", "fra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "VMFIN", "PPER", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Sp\u00e4ht durchs Fenster starr sein Blick.", "tokens": ["Sp\u00e4ht", "durchs", "Fens\u00b7ter", "starr", "sein", "Blick", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPRART", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.15": {"line.1": {"text": "Sieh, da tritt ein Alter eben", "tokens": ["Sieh", ",", "da", "tritt", "ein", "Al\u00b7ter", "e\u00b7ben"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NE", "$,", "ADV", "VVFIN", "ART", "NN", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Durch die T\u00fcr und fl\u00fcstert klug:", "tokens": ["Durch", "die", "T\u00fcr", "und", "fl\u00fcs\u00b7tert", "klug", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "KON", "VVFIN", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "\u00bbmorgen wird es Arbeit geben,", "tokens": ["\u00bb", "mor\u00b7gen", "wird", "es", "Ar\u00b7beit", "ge\u00b7ben", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VAFIN", "PPER", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Mir und Euch, o Herr, genug!\u00ab", "tokens": ["Mir", "und", "Euch", ",", "o", "Herr", ",", "ge\u00b7nug", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct", "punct"], "pos": ["NE", "KON", "PPER", "$,", "FM", "NN", "$,", "ADV", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.16": {"line.1": {"text": "Auff\u00e4hrt Tilly: \u00bbMir, wie Keinem!", "tokens": ["Auf\u00b7f\u00e4hrt", "Til\u00b7ly", ":", "\u00bb", "Mir", ",", "wie", "Kei\u00b7nem", "!"], "token_info": ["word", "word", "punct", "punct", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "NE", "$.", "$(", "NE", "$,", "PWAV", "PIS", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Frecher, fort!\u00ab Und Meister Klaus", "tokens": ["Fre\u00b7cher", ",", "fort", "!", "\u00ab", "Und", "Meis\u00b7ter", "Klaus"], "token_info": ["word", "punct", "word", "punct", "punct", "word", "word", "word"], "pos": ["NN", "$,", "PTKVZ", "$.", "$(", "KON", "NE", "NE"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "B\u00fcckt sich: \u00bbHerr, Ihr seid in meinem,", "tokens": ["B\u00fcckt", "sich", ":", "\u00bb", "Herr", ",", "Ihr", "seid", "in", "mei\u00b7nem", ","], "token_info": ["word", "word", "punct", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "$.", "$(", "NN", "$,", "PPER", "VAFIN", "APPR", "PPOSAT", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "In des Totengr\u00e4bers Haus.\u00ab", "tokens": ["In", "des", "To\u00b7ten\u00b7gr\u00e4\u00b7bers", "Haus", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "ART", "NN", "NN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}