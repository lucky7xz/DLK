{"textgrid.poem.57466": {"metadata": {"author": {"name": "Gottsched, Johann Christoph", "birth": "N.A.", "death": "N.A."}, "title": "1L: Die Nacht ist hin, der Tag bricht an!", "genre": "verse", "period": "N.A.", "pub_year": 1733, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Die Nacht ist hin, der Tag bricht an!", "tokens": ["Die", "Nacht", "ist", "hin", ",", "der", "Tag", "bricht", "an", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "$,", "ART", "NN", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "O Sachsen, auf aus deinem Schlummer!", "tokens": ["O", "Sach\u00b7sen", ",", "auf", "aus", "dei\u00b7nem", "Schlum\u00b7mer", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "APPR", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Vergi\u00df, was dich betr\u00fcben kann,", "tokens": ["Ver\u00b7gi\u00df", ",", "was", "dich", "be\u00b7tr\u00fc\u00b7ben", "kann", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "$,", "PWS", "PPER", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und fasse dich nunmehr nach herbem Gram und Kummer.", "tokens": ["Und", "fas\u00b7se", "dich", "nun\u00b7mehr", "nach", "her\u00b7bem", "Gram", "und", "Kum\u00b7mer", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "APPR", "ADJA", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Was weinst du doch um deinen Held,", "tokens": ["Was", "weinst", "du", "doch", "um", "dei\u00b7nen", "Held", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Den du, so wie es schien, vor kurzer Zeit verlohren?", "tokens": ["Den", "du", ",", "so", "wie", "es", "schien", ",", "vor", "kur\u00b7zer", "Zeit", "ver\u00b7loh\u00b7ren", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "$,", "ADV", "KOKOM", "PPER", "VVFIN", "$,", "APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Getrost! du irrst. Er lebet noch!", "tokens": ["Ge\u00b7trost", "!", "du", "irrst", ".", "Er", "le\u00b7bet", "noch", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$.", "PPER", "ADV", "$.", "PPER", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Er lebt! ach jauchze, jauchze doch!", "tokens": ["Er", "lebt", "!", "ach", "jauch\u00b7ze", ",", "jauch\u00b7ze", "doch", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "XY", "XY", "$,", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Und zeigt sich nur verj\u00fcngt und gleichsam neu gebohren.", "tokens": ["Und", "zeigt", "sich", "nur", "ver\u00b7j\u00fcngt", "und", "gleich\u00b7sam", "neu", "ge\u00b7boh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "ADV", "VVPP", "KON", "ADJD", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Wie eine zarte Braut erwacht,", "tokens": ["Wie", "ei\u00b7ne", "zar\u00b7te", "Braut", "er\u00b7wacht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wenn sie des Liebsten Stimme h\u00f6ret,", "tokens": ["Wenn", "sie", "des", "Liebs\u00b7ten", "Stim\u00b7me", "h\u00f6\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Nachdem der Hochzeitkerzen Pracht", "tokens": ["Nach\u00b7dem", "der", "Hoch\u00b7zeit\u00b7ker\u00b7zen", "Pracht"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "NN"], "meter": "+--++--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Ein trauriges Ger\u00fccht von seiner Gruft gest\u00f6ret;", "tokens": ["Ein", "trau\u00b7ri\u00b7ges", "Ge\u00b7r\u00fccht", "von", "sei\u00b7ner", "Gruft", "ge\u00b7st\u00f6\u00b7ret", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Sie rafft sich auf, und sieht umher,", "tokens": ["Sie", "rafft", "sich", "auf", ",", "und", "sieht", "um\u00b7her", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "PTKVZ", "$,", "KON", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und horcht best\u00fcrzt, und zweifelt sehr,", "tokens": ["Und", "horcht", "be\u00b7st\u00fcrzt", ",", "und", "zwei\u00b7felt", "sehr", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "$,", "KON", "VVFIN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Ob irgend sie dabey ein s\u00fc\u00dfer Traum betrogen;", "tokens": ["Ob", "ir\u00b7gend", "sie", "da\u00b7bey", "ein", "s\u00fc\u00b7\u00dfer", "Traum", "be\u00b7tro\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PPER", "PAV", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Doch endlich glaubt sie, was sie sieht,", "tokens": ["Doch", "end\u00b7lich", "glaubt", "sie", ",", "was", "sie", "sieht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Und weil ihr Gl\u00fcck nun wieder bl\u00fcht,", "tokens": ["Und", "weil", "ihr", "Gl\u00fcck", "nun", "wie\u00b7der", "bl\u00fcht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPOSAT", "NN", "ADV", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "So wird im Augenblick der Brautschmuck angezogen:", "tokens": ["So", "wird", "im", "Au\u00b7gen\u00b7blick", "der", "Brautsc\u00b7hmuck", "an\u00b7ge\u00b7zo\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "APPRART", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "So seh ich Sachsens matten Blick", "tokens": ["So", "seh", "ich", "Sach\u00b7sens", "mat\u00b7ten", "Blick"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "NN", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Auf einmal hell und munter werden.", "tokens": ["Auf", "ein\u00b7mal", "hell", "und", "mun\u00b7ter", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "ADJD", "KON", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Der blo\u00dfe Ruf von solchem Gl\u00fcck,", "tokens": ["Der", "blo\u00b7\u00dfe", "Ruf", "von", "sol\u00b7chem", "Gl\u00fcck", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Gesetzt, er w\u00e4re falsch, erweckt es aus der Erden.", "tokens": ["Ge\u00b7setzt", ",", "er", "w\u00e4\u00b7re", "falsch", ",", "er\u00b7weckt", "es", "aus", "der", "Er\u00b7den", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "PPER", "VAFIN", "ADJD", "$,", "VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wie? hei\u00dft sein Wort: Was? lebt ", "tokens": ["Wie", "?", "hei\u00dft", "sein", "Wort", ":", "Was", "?", "lebt"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct", "word"], "pos": ["PWAV", "$.", "VVFIN", "PPOSAT", "NN", "$.", "PWS", "$.", "VVFIN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Lebt ", "tokens": ["Lebt"], "token_info": ["word"], "pos": ["VVFIN"], "meter": "+", "measure": "single.up"}, "line.7": {"text": "Wer spottet meines Grams, und tr\u00f6stet mich zum Hohne?", "tokens": ["Wer", "spot\u00b7tet", "mei\u00b7nes", "Grams", ",", "und", "tr\u00f6s\u00b7tet", "mich", "zum", "Hoh\u00b7ne", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPOSAT", "NN", "$,", "KON", "VVFIN", "PPER", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Es ist unm\u00f6glich! \u2013 \u2013 Sachsen, nein!", "tokens": ["Es", "ist", "un\u00b7m\u00f6g\u00b7lich", "!", "\u2013", "\u2013", "Sach\u00b7sen", ",", "nein", "!"], "token_info": ["word", "word", "word", "punct", "punct", "punct", "word", "punct", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "$.", "$(", "$(", "NE", "$,", "PTKANT", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Man t\u00e4uscht dich nicht; dein Wunsch trifft ein:", "tokens": ["Man", "t\u00e4uscht", "dich", "nicht", ";", "dein", "Wunsch", "trifft", "ein", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "PTKNEG", "$.", "PPOSAT", "NN", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Denn ", "tokens": ["Denn"], "token_info": ["word"], "pos": ["KON"], "meter": "+", "measure": "single.up"}}, "stanza.4": {"line.1": {"text": "Dort k\u00f6mmt ja dein erw\u00fcnschtes Haupt,", "tokens": ["Dort", "k\u00f6mmt", "ja", "dein", "er\u00b7w\u00fcnschtes", "Haupt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Dein ", "tokens": ["Dein"], "token_info": ["word"], "pos": ["PPOSAT"], "meter": "+", "measure": "single.up"}, "line.3": {"text": "Was hat dir nun der Tod geraubt?", "tokens": ["Was", "hat", "dir", "nun", "der", "Tod", "ge\u00b7raubt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "ADV", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und warum gehst du noch, so wie bisher, im Leide?", "tokens": ["Und", "wa\u00b7rum", "gehst", "du", "noch", ",", "so", "wie", "bis\u00b7her", ",", "im", "Lei\u00b7de", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PWAV", "VVFIN", "PPER", "ADV", "$,", "ADV", "KOKOM", "ADV", "$,", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Sieh doch sein holdes Angesicht!", "tokens": ["Sieh", "doch", "sein", "hol\u00b7des", "An\u00b7ge\u00b7sicht", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Sieh, seiner Augen heitres Licht", "tokens": ["Sieh", ",", "sei\u00b7ner", "Au\u00b7gen", "heit\u00b7res", "Licht"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NE", "$,", "PPOSAT", "NN", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Erweckt ja jeder Brust ein wallendes Vergn\u00fcgen.", "tokens": ["Er\u00b7weckt", "ja", "je\u00b7der", "Brust", "ein", "wal\u00b7len\u00b7des", "Ver\u00b7gn\u00fc\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PIAT", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Ein jeder dringt vor seinen Thron,", "tokens": ["Ein", "je\u00b7der", "dringt", "vor", "sei\u00b7nen", "Thron", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Und will dem gro\u00dfen K\u00f6nigssohn,", "tokens": ["Und", "will", "dem", "gro\u00b7\u00dfen", "K\u00f6\u00b7nigs\u00b7sohn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Wie seinem Vater sonst, entz\u00fcckt zu F\u00fc\u00dfen liegen.", "tokens": ["Wie", "sei\u00b7nem", "Va\u00b7ter", "sonst", ",", "ent\u00b7z\u00fcckt", "zu", "F\u00fc\u00b7\u00dfen", "lie\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "NN", "ADV", "$,", "VVFIN", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Doch nein! das lie\u00df ", "tokens": ["Doch", "nein", "!", "das", "lie\u00df"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["KON", "PTKANT", "$.", "PDS", "VVFIN"], "meter": "-+-+", "measure": "iambic.di"}, "line.2": {"text": "Der wollte nichts von Sklaven wissen:", "tokens": ["Der", "woll\u00b7te", "nichts", "von", "Skla\u00b7ven", "wis\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PIS", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Ein gleiches, ", "tokens": ["Ein", "glei\u00b7ches", ","], "token_info": ["word", "word", "punct"], "pos": ["ART", "ADJA", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.4": {"text": "Du reichest blo\u00df die Hand, nur diese darf man k\u00fcssen.", "tokens": ["Du", "rei\u00b7chest", "blo\u00df", "die", "Hand", ",", "nur", "die\u00b7se", "darf", "man", "k\u00fcs\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN", "$,", "ADV", "PDS", "VMFIN", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "So sieht mans, wem du \u00e4hnlich bist;", "tokens": ["So", "sieht", "mans", ",", "wem", "du", "\u00e4hn\u00b7lich", "bist", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "$,", "PWS", "PPER", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "So braucht es weder Kunst noch List,", "tokens": ["So", "braucht", "es", "we\u00b7der", "Kunst", "noch", "List", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "KON", "NN", "ADV", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Des gro\u00dfen Vaters Art in deinem Thun zu finden.", "tokens": ["Des", "gro\u00b7\u00dfen", "Va\u00b7ters", "Art", "in", "dei\u00b7nem", "Thun", "zu", "fin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "APPR", "PPOSAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Du bist ihm fast in allem gleich;", "tokens": ["Du", "bist", "ihm", "fast", "in", "al\u00b7lem", "gleich", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "APPR", "PIS", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "War er an Gnad und Weisheit reich,", "tokens": ["War", "er", "an", "Gnad", "und", "Weis\u00b7heit", "reich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPR", "NN", "KON", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "So weist du beydes auch vollkommen zu verbinden.", "tokens": ["So", "weist", "du", "bey\u00b7des", "auch", "voll\u00b7kom\u00b7men", "zu", "ver\u00b7bin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PIS", "ADV", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Kaum legtest du die Kindheit hin,", "tokens": ["Kaum", "leg\u00b7test", "du", "die", "Kind\u00b7heit", "hin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So stund dein Herz nach edlen Sachen:", "tokens": ["So", "stund", "dein", "Herz", "nach", "ed\u00b7len", "Sa\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Denn Frankfurt lockte deinen Sinn,", "tokens": ["Denn", "Frank\u00b7furt", "lock\u00b7te", "dei\u00b7nen", "Sinn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der deutschen Kaiser Wahl dir recht bekannt zu machen.", "tokens": ["Der", "deut\u00b7schen", "Kai\u00b7ser", "Wahl", "dir", "recht", "be\u00b7kannt", "zu", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "PPER", "ADV", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Du sahst sie an; doch da Paris", "tokens": ["Du", "sahst", "sie", "an", ";", "doch", "da", "Pa\u00b7ris"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "PTKVZ", "$.", "ADV", "ADV", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "In seinem ", "tokens": ["In", "sei\u00b7nem"], "token_info": ["word", "word"], "pos": ["APPR", "PPOSAT"], "meter": "-+-", "measure": "amphibrach.single"}, "line.7": {"text": "Was F\u00fcrsten vor der Welt zum h\u00f6chsten Ruhm erhebet:", "tokens": ["Was", "F\u00fcrs\u00b7ten", "vor", "der", "Welt", "zum", "h\u00f6chs\u00b7ten", "Ruhm", "er\u00b7he\u00b7bet", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "APPR", "ART", "NN", "APPRART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "So war der Weg dir nicht zu weit,", "tokens": ["So", "war", "der", "Weg", "dir", "nicht", "zu", "weit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "PPER", "PTKNEG", "PTKA", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Vielmehr hat deine Munterkeit", "tokens": ["Viel\u00b7mehr", "hat", "dei\u00b7ne", "Mun\u00b7ter\u00b7keit"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Dem Gipfel wahrer H\u00f6h begierig nachgestrebet.", "tokens": ["Dem", "Gip\u00b7fel", "wah\u00b7rer", "H\u00f6h", "be\u00b7gie\u00b7rig", "nach\u00b7ge\u00b7stre\u00b7bet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Du sahst auch ferner Rom und Wien,", "tokens": ["Du", "sahst", "auch", "fer\u00b7ner", "Rom", "und", "Wi\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "NE", "KON", "NE", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Das alt und neue Haupt der Erden:", "tokens": ["Das", "alt", "und", "neu\u00b7e", "Haupt", "der", "Er\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADJD", "KON", "ADJA", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und alles das, mit dem Bem\u00fchn,", "tokens": ["Und", "al\u00b7les", "das", ",", "mit", "dem", "Be\u00b7m\u00fchn", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "PDS", "$,", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Durch das, was du gesehn, ein weiser F\u00fcrst zu werden.", "tokens": ["Durch", "das", ",", "was", "du", "ge\u00b7sehn", ",", "ein", "wei\u00b7ser", "F\u00fcrst", "zu", "wer\u00b7den", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDS", "$,", "PWS", "PPER", "VVPP", "$,", "ART", "ADJA", "NN", "PTKZU", "VAINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Nicht fremder V\u00f6lker Eitelkeit,", "tokens": ["Nicht", "frem\u00b7der", "V\u00f6l\u00b7ker", "Ei\u00b7tel\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Nein, Staatskunst und Erfahrenheit", "tokens": ["Nein", ",", "Staats\u00b7kunst", "und", "Er\u00b7fah\u00b7ren\u00b7heit"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["PTKANT", "$,", "NN", "KON", "NN"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.7": {"text": "War, andrer ", "tokens": ["War", ",", "an\u00b7drer"], "token_info": ["word", "punct", "word"], "pos": ["VAFIN", "$,", "ADJA"], "meter": "-+-", "measure": "amphibrach.single"}, "line.8": {"text": "Drum sp\u00fcrten auch die L\u00e4nder schon,", "tokens": ["Drum", "sp\u00fcr\u00b7ten", "auch", "die", "L\u00e4n\u00b7der", "schon", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "ADV", "ART", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Es w\u00fcrde dieser K\u00f6nigssohn", "tokens": ["Es", "w\u00fcr\u00b7de", "die\u00b7ser", "K\u00f6\u00b7nigs\u00b7sohn"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PDAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Der Welt einmal ein Bild vollkommner F\u00fcrsten weisen.", "tokens": ["Der", "Welt", "ein\u00b7mal", "ein", "Bild", "voll\u00b7komm\u00b7ner", "F\u00fcrs\u00b7ten", "wei\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ART", "NN", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "Das Schrecken ", "tokens": ["Das", "Schre\u00b7cken"], "token_info": ["word", "word"], "pos": ["ART", "NN"], "meter": "-+-", "measure": "amphibrach.single"}, "line.2": {"text": "Karl, welcher Temeswar bezwungen,", "tokens": ["Karl", ",", "wel\u00b7cher", "Te\u00b7mes\u00b7war", "be\u00b7zwun\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PWAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und gar, dem Muselmann zu Trutz,", "tokens": ["Und", "gar", ",", "dem", "Mu\u00b7sel\u00b7mann", "zu", "Trutz", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$,", "ART", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Bis in des Reiches Herz nach Belgrad eingedrungen;", "tokens": ["Bis", "in", "des", "Rei\u00b7ches", "Herz", "nach", "Bel\u00b7grad", "ein\u00b7ge\u00b7drun\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "APPR", "ART", "ADJA", "NN", "APPR", "NE", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die\u00df gro\u00dfe Haupt der Christenheit", "tokens": ["Die\u00df", "gro\u00b7\u00dfe", "Haupt", "der", "Chris\u00b7ten\u00b7heit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "ADJA", "NN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Erblickte bald die Trefflichkeit,", "tokens": ["Er\u00b7blick\u00b7te", "bald", "die", "Treff\u00b7lich\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Die ", "tokens": ["Die"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}, "line.8": {"text": "Er fand, und hat es oft erkl\u00e4rt:", "tokens": ["Er", "fand", ",", "und", "hat", "es", "oft", "er\u00b7kl\u00e4rt", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KON", "VAFIN", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Ein solcher Prinz sey Kronen werth,", "tokens": ["Ein", "sol\u00b7cher", "Prinz", "sey", "Kro\u00b7nen", "werth", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VAFIN", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Der jedes Herz gewann, und alles zu sich neigte.", "tokens": ["Der", "je\u00b7des", "Herz", "ge\u00b7wann", ",", "und", "al\u00b7les", "zu", "sich", "neig\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VVFIN", "$,", "KON", "PIS", "APPR", "PRF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Doch dir ward auch dein Hers entf\u00fchrt,", "tokens": ["Doch", "dir", "ward", "auch", "dein", "Hers", "ent\u00b7f\u00fchrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "ADV", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "O ", "tokens": ["O"], "token_info": ["word"], "pos": ["NE"], "meter": "+", "measure": "single.up"}, "line.3": {"text": "Des Kaiserstammes Schmuck, dein einziges Verlangen.", "tokens": ["Des", "Kai\u00b7ser\u00b7stam\u00b7mes", "Schmuck", ",", "dein", "ein\u00b7zi\u00b7ges", "Ver\u00b7lan\u00b7gen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Du zogst nach Sachsen zwar zur\u00fcck;", "tokens": ["Du", "zogst", "nach", "Sach\u00b7sen", "zwar", "zu\u00b7r\u00fcck", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NE", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Doch drehte sich dein kluger Blick", "tokens": ["Doch", "dreh\u00b7te", "sich", "dein", "klu\u00b7ger", "Blick"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PRF", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Noch stets nach Oesterreichs und Wiens verla\u00dfnen Gr\u00e4nzen.", "tokens": ["Noch", "stets", "nach", "O\u00b7es\u00b7ter\u00b7reichs", "und", "Wiens", "ver\u00b7la\u00df\u00b7nen", "Gr\u00e4n\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "NE", "KON", "NN", "ADJA", "NN", "$."], "meter": "-+-+--+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.7": {"text": "So kehrt sich jener Wunderstein", "tokens": ["So", "kehrt", "sich", "je\u00b7ner", "Wun\u00b7der\u00b7stein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PRF", "PDAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Nach des entfernten Nordsterns Schein;", "tokens": ["Nach", "des", "ent\u00b7fern\u00b7ten", "Nords\u00b7terns", "Schein", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Gesetzt, er sieht ihn nicht bey hellem Tage gl\u00e4nzen.", "tokens": ["Ge\u00b7setzt", ",", "er", "sieht", "ihn", "nicht", "bey", "hel\u00b7lem", "Ta\u00b7ge", "gl\u00e4n\u00b7zen", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "PPER", "VVFIN", "PPER", "PTKNEG", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.10": {"line.1": {"text": "Ihr Musen, denen nichts entf\u00e4llt,", "tokens": ["Ihr", "Mu\u00b7sen", ",", "de\u00b7nen", "nichts", "ent\u00b7f\u00e4llt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PRELS", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Was auch vor grauer Zeit geschehen:", "tokens": ["Was", "auch", "vor", "grau\u00b7er", "Zeit", "ge\u00b7sche\u00b7hen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "O sagt, wie froh war unser Held,", "tokens": ["O", "sagt", ",", "wie", "froh", "war", "un\u00b7ser", "Held", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "$,", "PWAV", "ADJD", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Als seine Liebe drauf den Wunsch erf\u00fcllt gesehen?", "tokens": ["Als", "sei\u00b7ne", "Lie\u00b7be", "drauf", "den", "Wunsch", "er\u00b7f\u00fcllt", "ge\u00b7se\u00b7hen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "PAV", "ART", "NN", "VVPP", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Beschreibt mir doch ", "tokens": ["Be\u00b7schreibt", "mir", "doch"], "token_info": ["word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV"], "meter": "-+-+", "measure": "iambic.di"}, "line.6": {"text": "Und lehrt mich, was ihr Herz gedacht,", "tokens": ["Und", "lehrt", "mich", ",", "was", "ihr", "Herz", "ge\u00b7dacht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "$,", "PRELS", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Als ", "tokens": ["Als"], "token_info": ["word"], "pos": ["KOUS"], "meter": "+", "measure": "single.up"}, "line.8": {"text": "Als sie aus Gassen, Volk und Stadt,", "tokens": ["Als", "sie", "aus", "Gas\u00b7sen", ",", "Volk", "und", "Stadt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Aus Burg und Hof geschlossen hat,", "tokens": ["Aus", "Burg", "und", "Hof", "ge\u00b7schlos\u00b7sen", "hat", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Sie sey in Dresden fast zum Kaiserthron gekommen.", "tokens": ["Sie", "sey", "in", "Dres\u00b7den", "fast", "zum", "Kai\u00b7ser\u00b7thron", "ge\u00b7kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "NE", "ADV", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.11": {"line.1": {"text": "So war das gro\u00dfe Band nun fest,", "tokens": ["So", "war", "das", "gro\u00b7\u00dfe", "Band", "nun", "fest", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "ADJA", "NN", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das Sachsenland und Wien verbunden;", "tokens": ["Das", "Sach\u00b7sen\u00b7land", "und", "Wi\u00b7en", "ver\u00b7bun\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NE", "VVPP", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Das keine Zeit veralten l\u00e4\u00dft,", "tokens": ["Das", "kei\u00b7ne", "Zeit", "ver\u00b7al\u00b7ten", "l\u00e4\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und das noch unverr\u00fcckt des Himmels Huld empfunden.", "tokens": ["Und", "das", "noch", "un\u00b7ver\u00b7r\u00fcckt", "des", "Him\u00b7mels", "Huld", "emp\u00b7fun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "ADV", "ADJD", "ART", "NN", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wie manchen Segen keuscher Brunst", "tokens": ["Wie", "man\u00b7chen", "Se\u00b7gen", "keu\u00b7scher", "Brunst"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "PIAT", "NN", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Hat dir des Schicksals h\u00f6chste Gunst,", "tokens": ["Hat", "dir", "des", "Schick\u00b7sals", "h\u00f6chs\u00b7te", "Gunst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "In deinem Ehbett, ", "tokens": ["In", "dei\u00b7nem", "Eh\u00b7bett", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.8": {"text": "Noch itzo gr\u00fcnt die Hoffnung sch\u00f6n:", "tokens": ["Noch", "it\u00b7zo", "gr\u00fcnt", "die", "Hoff\u00b7nung", "sch\u00f6n", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Wie kann dein Stamm denn untergehn,", "tokens": ["Wie", "kann", "dein", "Stamm", "denn", "un\u00b7ter\u00b7gehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "PPOSAT", "NN", "KON", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Da so viel Zweige schon vor deinen Augen bl\u00fchen!", "tokens": ["Da", "so", "viel", "Zwei\u00b7ge", "schon", "vor", "dei\u00b7nen", "Au\u00b7gen", "bl\u00fc\u00b7hen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PIAT", "NN", "ADV", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.12": {"line.1": {"text": "Was zeigt sich f\u00fcr ein Wunderbau?", "tokens": ["Was", "zeigt", "sich", "f\u00fcr", "ein", "Wun\u00b7der\u00b7bau", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PRF", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Hat mich denn Ph\u00f6bus gar entz\u00fccket?", "tokens": ["Hat", "mich", "denn", "Ph\u00f6\u00b7bus", "gar", "ent\u00b7z\u00fc\u00b7cket", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "NE", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Was stellt sich f\u00fcr ein Schlo\u00df zur Schau,", "tokens": ["Was", "stellt", "sich", "f\u00fcr", "ein", "Schlo\u00df", "zur", "Schau", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PRF", "APPR", "ART", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Dergleichen wahrlich Rom und W\u00e4lschland kaum erblicket?", "tokens": ["Derg\u00b7lei\u00b7chen", "wahr\u00b7lich", "Rom", "und", "W\u00e4l\u00b7schland", "kaum", "er\u00b7bli\u00b7cket", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "ADV", "NE", "KON", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wer z\u00e4hlt der Fenster Menge hier?", "tokens": ["Wer", "z\u00e4hlt", "der", "Fens\u00b7ter", "Men\u00b7ge", "hier", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ART", "NN", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wer sch\u00e4tzt der stolzen Thore Zier?", "tokens": ["Wer", "sch\u00e4tzt", "der", "stol\u00b7zen", "Tho\u00b7re", "Zier", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ART", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Wer kann der D\u00e4cher Pracht, der Fl\u00fcgel Gr\u00f6\u00dfe nennen?", "tokens": ["Wer", "kann", "der", "D\u00e4\u00b7cher", "Pracht", ",", "der", "Fl\u00fc\u00b7gel", "Gr\u00f6\u00b7\u00dfe", "nen\u00b7nen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "ART", "NN", "NN", "$,", "ART", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Wer lehrt mich alle Symmetrie,", "tokens": ["Wer", "lehrt", "mich", "al\u00b7le", "Sym\u00b7me\u00b7trie", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Und was wir nach der Eurythmie,", "tokens": ["Und", "was", "wir", "nach", "der", "Eu\u00b7ryth\u00b7mie", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Im Bauen, f\u00fcr ein Werk der gr\u00f6\u00dften Kunst erkennen?", "tokens": ["Im", "Bau\u00b7en", ",", "f\u00fcr", "ein", "Werk", "der", "gr\u00f6\u00df\u00b7ten", "Kunst", "er\u00b7ken\u00b7nen", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "APPR", "ART", "NN", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.13": {"line.1": {"text": "O Hubertsburg! bist du es nicht", "tokens": ["O", "Hu\u00b7berts\u00b7burg", "!", "bist", "du", "es", "nicht"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "NE", "$.", "VAFIN", "PPER", "PPER", "PTKNEG"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "In deinen schattigten Geb\u00fcschen?", "tokens": ["In", "dei\u00b7nen", "schat\u00b7tig\u00b7ten", "Ge\u00b7b\u00fc\u00b7schen", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Ja ja, du bists, und mein Gesicht", "tokens": ["Ja", "ja", ",", "du", "bists", ",", "und", "mein", "Ge\u00b7sicht"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["PTKANT", "PTKANT", "$,", "PPER", "ADV", "$,", "KON", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Kann leichtlich deinen Bau mit W\u00e4lschlands Pracht vermischen.", "tokens": ["Kann", "leicht\u00b7lich", "dei\u00b7nen", "Bau", "mit", "W\u00e4l\u00b7schlands", "Pracht", "ver\u00b7mi\u00b7schen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADJD", "PPOSAT", "NN", "APPR", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ich seh dich zwischen Berg und Thal,", "tokens": ["Ich", "seh", "dich", "zwi\u00b7schen", "Berg", "und", "Thal", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Mit stolzen Tannen ohne Zahl,", "tokens": ["Mit", "stol\u00b7zen", "Tan\u00b7nen", "oh\u00b7ne", "Zahl", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Mit Eichen edler Art und anderm Holz umringet.", "tokens": ["Mit", "Ei\u00b7chen", "ed\u00b7ler", "Art", "und", "an\u00b7derm", "Holz", "um\u00b7rin\u00b7get", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADJA", "NN", "KON", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Hier ist Dianens Reich und Sitz!", "tokens": ["Hier", "ist", "Di\u00b7a\u00b7nens", "Reich", "und", "Sitz", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "NE", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Allhier wohnt Echo, deren Witz", "tokens": ["All\u00b7hier", "wohnt", "E\u00b7cho", ",", "de\u00b7ren", "Witz"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "VVFIN", "NN", "$,", "PRELAT", "NN"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.10": {"text": "Dem J\u00e4ger, wenn er bl\u00e4st, die Antwort zehnfach bringet.", "tokens": ["Dem", "J\u00e4\u00b7ger", ",", "wenn", "er", "bl\u00e4st", ",", "die", "Ant\u00b7wort", "zehn\u00b7fach", "brin\u00b7get", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "KOUS", "PPER", "VVFIN", "$,", "ART", "NN", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.14": {"line.1": {"text": "Verliert sich doch das Auge ganz", "tokens": ["Ver\u00b7liert", "sich", "doch", "das", "Au\u00b7ge", "ganz"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PRF", "ADV", "ART", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "In meilenlang durchschnittnen W\u00e4ldern!", "tokens": ["In", "mei\u00b7len\u00b7lang", "durch\u00b7schnitt\u00b7nen", "W\u00e4l\u00b7dern", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Da sieht man deiner Fenster Glanz,", "tokens": ["Da", "sieht", "man", "dei\u00b7ner", "Fens\u00b7ter", "Glanz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wenn Ph\u00f6bus sie bestralt, in weitentlegnen Feldern.", "tokens": ["Wenn", "Ph\u00f6\u00b7bus", "sie", "be\u00b7stralt", ",", "in", "wei\u00b7tent\u00b7leg\u00b7nen", "Fel\u00b7dern", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "PPER", "ADJD", "$,", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Man r\u00fcckt hinzu, man n\u00e4hert sich,", "tokens": ["Man", "r\u00fcckt", "hin\u00b7zu", ",", "man", "n\u00e4\u00b7hert", "sich", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PTKVZ", "$,", "PIS", "VVFIN", "PRF", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Und jeder Schritt vergr\u00f6\u00dfert dich,", "tokens": ["Und", "je\u00b7der", "Schritt", "ver\u00b7gr\u00f6\u00b7\u00dfert", "dich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "VVFIN", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Bis dich die Gegenwart in voller Sch\u00f6nheit weiset;", "tokens": ["Bis", "dich", "die", "Ge\u00b7gen\u00b7wart", "in", "vol\u00b7ler", "Sch\u00f6n\u00b7heit", "wei\u00b7set", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ART", "NN", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Bis dich durch den gespaltnen Wald,", "tokens": ["Bis", "dich", "durch", "den", "ge\u00b7spalt\u00b7nen", "Wald", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRF", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Des Wildes gr\u00fcnen Aufenthalt,", "tokens": ["Des", "Wil\u00b7des", "gr\u00fc\u00b7nen", "Auf\u00b7ent\u00b7halt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Ein ferner Blick zuletzt auf langen Wegen preiset.", "tokens": ["Ein", "fer\u00b7ner", "Blick", "zu\u00b7letzt", "auf", "lan\u00b7gen", "We\u00b7gen", "prei\u00b7set", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.15": {"line.1": {"text": "Mein Churf\u00fcrst, die\u00df hat dein Verstand,", "tokens": ["Mein", "Chur\u00b7f\u00fcrst", ",", "die\u00df", "hat", "dein", "Ver\u00b7stand", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PDS", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "-+---+-+", "measure": "dactylic.init"}, "line.2": {"text": "Dein gro\u00dfer Geist allein erfunden:", "tokens": ["Dein", "gro\u00b7\u00dfer", "Geist", "al\u00b7lein", "er\u00b7fun\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Allhier hat deine Meisterhand", "tokens": ["All\u00b7hier", "hat", "dei\u00b7ne", "Meis\u00b7ter\u00b7hand"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Sch\u00f6nheit der Natur und jeder Kunst verbunden.", "tokens": ["Die", "Sch\u00f6n\u00b7heit", "der", "Na\u00b7tur", "und", "je\u00b7der", "Kunst", "ver\u00b7bun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "KON", "PIAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Dein Lustschlo\u00df ist der Jagd geweiht;", "tokens": ["Dein", "Lust\u00b7schlo\u00df", "ist", "der", "Jagd", "ge\u00b7weiht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Doch deines Volkes Aemsigkeit", "tokens": ["Doch", "dei\u00b7nes", "Vol\u00b7kes", "A\u00b7em\u00b7sig\u00b7keit"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.7": {"text": "Hat seinen Flei\u00df und Witz hier \u00fcberall gewiesen:", "tokens": ["Hat", "sei\u00b7nen", "Flei\u00df", "und", "Witz", "hier", "\u00fc\u00b7be\u00b7rall", "ge\u00b7wie\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "KON", "NN", "ADV", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Hier hat kein K\u00fcnstler was versehn,", "tokens": ["Hier", "hat", "kein", "K\u00fcnst\u00b7ler", "was", "ver\u00b7sehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIAT", "NN", "PIS", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Und dadurch ist es l\u00e4ngst geschehn,", "tokens": ["Und", "da\u00b7durch", "ist", "es", "l\u00e4ngst", "ge\u00b7schehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PAV", "VAFIN", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Da\u00df alle den Geschmack, womit du baust, gepriesen.", "tokens": ["Da\u00df", "al\u00b7le", "den", "Ge\u00b7schmack", ",", "wo\u00b7mit", "du", "baust", ",", "ge\u00b7prie\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "PIS", "ART", "NN", "$,", "PWAV", "PPER", "VVFIN", "$,", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.16": {"line.1": {"text": "So bist du denn dem Vater gleich,", "tokens": ["So", "bist", "du", "denn", "dem", "Va\u00b7ter", "gleich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ART", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der dir auch darinn vorgegangen:", "tokens": ["Der", "dir", "auch", "da\u00b7rinn", "vor\u00b7ge\u00b7gan\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "PAV", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Denn Bauen macht den B\u00fcrger reich,", "tokens": ["Denn", "Bau\u00b7en", "macht", "den", "B\u00fcr\u00b7ger", "reich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und lockt die Fremden hin, wo solche Schl\u00f6sser prangen:", "tokens": ["Und", "lockt", "die", "Frem\u00b7den", "hin", ",", "wo", "sol\u00b7che", "Schl\u00f6s\u00b7ser", "pran\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "PTKVZ", "$,", "PWAV", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "O ", "tokens": ["O"], "token_info": ["word"], "pos": ["NE"], "meter": "+", "measure": "single.up"}, "line.6": {"text": "Es kostet dich ein einzig Wort,", "tokens": ["Es", "kos\u00b7tet", "dich", "ein", "ein\u00b7zig", "Wort", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "ART", "ADJD", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Dein Sachsen ganz und gar zum Wunderwerk zu machen.", "tokens": ["Dein", "Sach\u00b7sen", "ganz", "und", "gar", "zum", "Wun\u00b7der\u00b7werk", "zu", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADV", "KON", "ADV", "APPRART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Vollf\u00fchre der Geb\u00e4ude Pracht,", "tokens": ["Voll\u00b7f\u00fch\u00b7re", "der", "Ge\u00b7b\u00e4u\u00b7de", "Pracht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Die selbst dein Vater ausgedacht,", "tokens": ["Die", "selbst", "dein", "Va\u00b7ter", "aus\u00b7ge\u00b7dacht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "So wird der Held in dir vor aller Welt erwachen.", "tokens": ["So", "wird", "der", "Held", "in", "dir", "vor", "al\u00b7ler", "Welt", "er\u00b7wa\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "APPR", "PPER", "APPR", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.17": {"line.1": {"text": "Man eilt zur Jagd; dein Ro\u00df ist stolz,", "tokens": ["Man", "eilt", "zur", "Jagd", ";", "dein", "Ro\u00df", "ist", "stolz", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "APPRART", "NN", "$.", "PPOSAT", "NN", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dich, Herr, ins freye Feld zu tragen;", "tokens": ["Dich", ",", "Herr", ",", "ins", "frey\u00b7e", "Feld", "zu", "tra\u00b7gen", ";"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "NN", "$,", "APPRART", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Ein weites Garn umspannt das Holz,", "tokens": ["Ein", "wei\u00b7tes", "Garn", "um\u00b7spannt", "das", "Holz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Da will es Preis und Ruhm durch seinen Lauf erjagen.", "tokens": ["Da", "will", "es", "Preis", "und", "Ruhm", "durch", "sei\u00b7nen", "Lauf", "er\u00b7ja\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "NN", "KON", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Das Waldhorn t\u00f6nt, das Windspiel bellt,", "tokens": ["Das", "Wald\u00b7horn", "t\u00f6nt", ",", "das", "Wind\u00b7spiel", "bellt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Das Rohr geht los, das Wildpret f\u00e4llt,", "tokens": ["Das", "Rohr", "geht", "los", ",", "das", "Wild\u00b7pret", "f\u00e4llt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "$,", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Oft sinkt ein matter Hirsch ganz athemlos zur Erden.", "tokens": ["Oft", "sinkt", "ein", "mat\u00b7ter", "Hirsch", "ganz", "at\u00b7hem\u00b7los", "zur", "Er\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "ADV", "ADJD", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "O ", "tokens": ["O"], "token_info": ["word"], "pos": ["NE"], "meter": "+", "measure": "single.up"}, "line.9": {"text": "Mu\u00df billig deiner F\u00fcrstenbrust", "tokens": ["Mu\u00df", "bil\u00b7lig", "dei\u00b7ner", "F\u00fcrs\u00b7ten\u00b7brust"], "token_info": ["word", "word", "word", "word"], "pos": ["VMFIN", "ADJD", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Der beste Zeitvertreib, nach M\u00fch und Sorgfalt, werden.", "tokens": ["Der", "bes\u00b7te", "Zeit\u00b7ver\u00b7treib", ",", "nach", "M\u00fch", "und", "Sorg\u00b7falt", ",", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "APPR", "NE", "KON", "NN", "$,", "VAINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.18": {"line.1": {"text": "Die\u00df war der alten Helden Brauch,", "tokens": ["Die\u00df", "war", "der", "al\u00b7ten", "Hel\u00b7den", "Brauch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die d\u00e4mpften Hydren und Chim\u00e4ren!", "tokens": ["Die", "d\u00e4mpf\u00b7ten", "Hyd\u00b7ren", "und", "Chi\u00b7m\u00e4\u00b7ren", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "So hetzte sonst Ulysses auch,", "tokens": ["So", "hetz\u00b7te", "sonst", "U\u00b7lys\u00b7ses", "auch", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "NE", "ADV", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.4": {"text": "Im Jagen so ge\u00fcbt, als in der Weisheit Lehren.", "tokens": ["Im", "Ja\u00b7gen", "so", "ge\u00b7\u00fcbt", ",", "als", "in", "der", "Weis\u00b7heit", "Leh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADV", "VVPP", "$,", "KOUS", "APPR", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "So hat dort der ", "tokens": ["So", "hat", "dort", "der"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ADV", "ART"], "meter": "+-+-", "measure": "trochaic.di"}, "line.6": {"text": "Carthago, durch dein flaches Feld,", "tokens": ["Car\u00b7tha\u00b7go", ",", "durch", "dein", "fla\u00b7ches", "Feld", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.7": {"text": "Auf einem schnellen Gaul des Wildes Spur entdecket;", "tokens": ["Auf", "ei\u00b7nem", "schnel\u00b7len", "Gaul", "des", "Wil\u00b7des", "Spur", "ent\u00b7de\u00b7cket", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "ART", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "So ward auch ", "tokens": ["So", "ward", "auch"], "token_info": ["word", "word", "word"], "pos": ["ADV", "VAFIN", "ADV"], "meter": "-+-", "measure": "amphibrach.single"}, "line.9": {"text": "Manch aufgesp\u00fcrtes Wild zu Theil,", "tokens": ["Manch", "auf\u00b7ge\u00b7sp\u00fcr\u00b7tes", "Wild", "zu", "Theil", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Bevor er Troja noch in lichten Brand gestecket.", "tokens": ["Be\u00b7vor", "er", "Tro\u00b7ja", "noch", "in", "lich\u00b7ten", "Brand", "ge\u00b7ste\u00b7cket", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NE", "ADV", "APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.19": {"line.1": {"text": "O! w\u00e4ren diese Helden doch", "tokens": ["O", "!", "w\u00e4\u00b7ren", "die\u00b7se", "Hel\u00b7den", "doch"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NE", "$.", "VAFIN", "PDAT", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Bey solcher F\u00fcrstenlust geblieben:", "tokens": ["Bey", "sol\u00b7cher", "F\u00fcrs\u00b7ten\u00b7lust", "ge\u00b7blie\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "So st\u00fcnden Priams Mauren noch;", "tokens": ["So", "st\u00fcn\u00b7den", "Pri\u00b7ams", "Mau\u00b7ren", "noch", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NE", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So h\u00e4tte Griechenland sich selbst nicht aufgerieben!", "tokens": ["So", "h\u00e4t\u00b7te", "Grie\u00b7chen\u00b7land", "sich", "selbst", "nicht", "auf\u00b7ge\u00b7rie\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "NE", "PRF", "ADV", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Was half sie ein so langer Krieg,", "tokens": ["Was", "half", "sie", "ein", "so", "lan\u00b7ger", "Krieg", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ART", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "In dem der theurerkaufte Sieg,", "tokens": ["In", "dem", "der", "theu\u00b7rer\u00b7kauf\u00b7te", "Sieg", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Durch ganze Str\u00f6me Bluts, ein geiles Weib errungen?", "tokens": ["Durch", "gan\u00b7ze", "Str\u00f6\u00b7me", "Bluts", ",", "ein", "gei\u00b7les", "Weib", "er\u00b7run\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "NN", "$,", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Weit besser ists, ein Thier bek\u00e4mpft,", "tokens": ["Weit", "bes\u00b7ser", "ists", ",", "ein", "Thier", "be\u00b7k\u00e4mpft", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "ADJD", "VAFIN", "$,", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Ein erimantisch Schwein ged\u00e4mpft;", "tokens": ["Ein", "e\u00b7ri\u00b7man\u00b7tisch", "Schwein", "ge\u00b7d\u00e4mpft", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Als voller Mordbegier ein feindlich Heer bezwungen.", "tokens": ["Als", "vol\u00b7ler", "Mord\u00b7be\u00b7gier", "ein", "feind\u00b7lich", "Heer", "be\u00b7zwun\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "NN", "ART", "ADJD", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.20": {"line.1": {"text": "Wenn wird das menschliche Geschlecht", "tokens": ["Wenn", "wird", "das", "menschli\u00b7che", "Ge\u00b7schlecht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "VAFIN", "ART", "ADJA", "NN"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Doch endlich seiner Wuth vergessen,", "tokens": ["Doch", "end\u00b7lich", "sei\u00b7ner", "Wuth", "ver\u00b7ges\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und sich nach Billigkeit und Recht", "tokens": ["Und", "sich", "nach", "Bil\u00b7lig\u00b7keit", "und", "Recht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PRF", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Nicht nach der blinden Macht gest\u00e4hlter F\u00e4uste messen?", "tokens": ["Nicht", "nach", "der", "blin\u00b7den", "Macht", "ge\u00b7st\u00e4hl\u00b7ter", "F\u00e4us\u00b7te", "mes\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "ART", "ADJA", "NN", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Zur\u00fcck, ihr Furien, zur\u00fcck!", "tokens": ["Zu\u00b7r\u00fcck", ",", "ihr", "Fu\u00b7ri\u00b7en", ",", "zu\u00b7r\u00fcck", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["PTKVZ", "$,", "PPOSAT", "NN", "$,", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Verbergt nur euren finstern Blick", "tokens": ["Ver\u00b7bergt", "nur", "eu\u00b7ren", "fins\u00b7tern", "Blick"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "In des Avernus Pfuhl, und r\u00e4umt den Kreis der Erden:", "tokens": ["In", "des", "A\u00b7ver\u00b7nus", "Pfuhl", ",", "und", "r\u00e4umt", "den", "Kreis", "der", "Er\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "$,", "KON", "VVFIN", "ART", "NN", "ART", "NN", "$."], "meter": "--+--+-+-+-+-", "measure": "anapaest.di.plus"}, "line.8": {"text": "Irenens Gottheit zeigt sich schon,", "tokens": ["I\u00b7re\u00b7nens", "Got\u00b7theit", "zeigt", "sich", "schon", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "VVFIN", "PRF", "ADV", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.9": {"text": "Sie pflanzt sich unter uns den Thron,", "tokens": ["Sie", "pflanzt", "sich", "un\u00b7ter", "uns", "den", "Thron", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Und ganz Europa soll ein Friedenstempel werden.", "tokens": ["Und", "ganz", "Eu\u00b7ro\u00b7pa", "soll", "ein", "Frie\u00b7dens\u00b7tem\u00b7pel", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "NE", "VMFIN", "ART", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.21": {"line.1": {"text": "Sie bricht schon an, die g\u00fcldne Zeit,", "tokens": ["Sie", "bricht", "schon", "an", ",", "die", "g\u00fcld\u00b7ne", "Zeit", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PTKVZ", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da wir aus Schwertern Sicheln schmieden;", "tokens": ["Da", "wir", "aus", "Schwer\u00b7tern", "Si\u00b7cheln", "schmie\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Wo keine Macht der andern dr\u00e4ut,", "tokens": ["Wo", "kei\u00b7ne", "Macht", "der", "an\u00b7dern", "dr\u00e4ut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIAT", "NN", "ART", "ADJA", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Seit dem die Feder mehr, als sonst der Stahl entschieden.", "tokens": ["Seit", "dem", "die", "Fe\u00b7der", "mehr", ",", "als", "sonst", "der", "Stahl", "ent\u00b7schie\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "ART", "NN", "ADV", "$,", "KOUS", "ADV", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Es weicht der V\u00f6lker Barbarey;", "tokens": ["Es", "weicht", "der", "V\u00f6l\u00b7ker", "Bar\u00b7ba\u00b7rey", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Man liebt kein rohes Feldgeschrey,", "tokens": ["Man", "liebt", "kein", "ro\u00b7hes", "Feld\u00b7ge\u00b7schrey", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Seit die Vernunft den Platz der Dummheit eingenommen.", "tokens": ["Seit", "die", "Ver\u00b7nunft", "den", "Platz", "der", "Dumm\u00b7heit", "ein\u00b7ge\u00b7nom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "So scheint es, da\u00df dem Occident,", "tokens": ["So", "scheint", "es", ",", "da\u00df", "dem", "Oc\u00b7ci\u00b7dent", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "KOUS", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Der Gott den Gott des Friedens nennt,", "tokens": ["Der", "Gott", "den", "Gott", "des", "Frie\u00b7dens", "nennt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Vor allem Blutdurst schon ein Ekel angekommen.", "tokens": ["Vor", "al\u00b7lem", "Blut\u00b7durst", "schon", "ein", "E\u00b7kel", "an\u00b7ge\u00b7kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "NN", "ADV", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.22": {"line.1": {"text": "Zwar Waffen blinken \u00fcberall,", "tokens": ["Zwar", "Waf\u00b7fen", "blin\u00b7ken", "\u00fc\u00b7be\u00b7rall", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "VVFIN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Doch nur zur Lust der Potentaten:", "tokens": ["Doch", "nur", "zur", "Lust", "der", "Po\u00b7ten\u00b7ta\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPRART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Man h\u00f6rt der Stucke Donnerknall,", "tokens": ["Man", "h\u00f6rt", "der", "Stu\u00b7cke", "Don\u00b7ner\u00b7knall", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Doch nur aus Fr\u00f6hlichkeit im Gl\u00fcck vergn\u00fcgter Staaten.", "tokens": ["Doch", "nur", "aus", "Fr\u00f6h\u00b7lich\u00b7keit", "im", "Gl\u00fcck", "ver\u00b7gn\u00fcg\u00b7ter", "Staa\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "NN", "APPRART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "So wurdest du, o ", "tokens": ["So", "wur\u00b7dest", "du", ",", "o"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["ADV", "VAFIN", "PPER", "$,", "FM"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.6": {"text": "Als Leipzig, dessen Lust du bist,", "tokens": ["Als", "Leip\u00b7zig", ",", "des\u00b7sen", "Lust", "du", "bist", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "$,", "PRELAT", "NN", "PPER", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Dich, als sein neues Haupt, mit reger Brust empfangen;", "tokens": ["Dich", ",", "als", "sein", "neu\u00b7es", "Haupt", ",", "mit", "re\u00b7ger", "Brust", "emp\u00b7fan\u00b7gen", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "KOUS", "PPOSAT", "ADJA", "NN", "$,", "APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "So hat des B\u00fcrgers Rohr gekracht,", "tokens": ["So", "hat", "des", "B\u00fcr\u00b7gers", "Rohr", "ge\u00b7kracht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Als du ihn gn\u00e4dig angelacht,", "tokens": ["Als", "du", "ihn", "gn\u00e4\u00b7dig", "an\u00b7ge\u00b7lacht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Und ihm vor Z\u00e4rtlichkeit die Augen \u00fcbergangen.", "tokens": ["Und", "ihm", "vor", "Z\u00e4rt\u00b7lich\u00b7keit", "die", "Au\u00b7gen", "\u00fc\u00b7ber\u00b7gan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "APPR", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.23": {"line.1": {"text": "Sey, ", "tokens": ["Sey", ","], "token_info": ["word", "punct"], "pos": ["VAFIN", "$,"], "meter": "+", "measure": "single.up"}, "line.2": {"text": "So wie dein Wesen l\u00e4ngst geschienen;", "tokens": ["So", "wie", "dein", "We\u00b7sen", "l\u00e4ngst", "ge\u00b7schie\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "PPOSAT", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Denn Sachsens Gl\u00fcck entspringt davon,", "tokens": ["Denn", "Sach\u00b7sens", "Gl\u00fcck", "ent\u00b7springt", "da\u00b7von", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "NN", "VVFIN", "PAV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wenn seine Kinder dir in Ruh und Friede dienen.", "tokens": ["Wenn", "sei\u00b7ne", "Kin\u00b7der", "dir", "in", "Ruh", "und", "Frie\u00b7de", "die\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "PPER", "APPR", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Irene macht die V\u00f6lker gro\u00df,", "tokens": ["I\u00b7re\u00b7ne", "macht", "die", "V\u00f6l\u00b7ker", "gro\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ART", "NN", "ADJD", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.6": {"text": "Wenn Stadt und Land, dem Gl\u00fcck im Schoo\u00df,", "tokens": ["Wenn", "Stadt", "und", "Land", ",", "dem", "Gl\u00fcck", "im", "Schoo\u00df", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "NN", "$,", "ART", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Den fetten Acker baut, den Handel eifrig treibet:", "tokens": ["Den", "fet\u00b7ten", "A\u00b7cker", "baut", ",", "den", "Han\u00b7del", "eif\u00b7rig", "trei\u00b7bet", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,", "ART", "NN", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Indessen da\u00df ein r\u00fcstig Heer,", "tokens": ["In\u00b7des\u00b7sen", "da\u00df", "ein", "r\u00fcs\u00b7tig", "Heer", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "ART", "ADJD", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Bereit zu tapfrer Gegenwehr,", "tokens": ["Be\u00b7reit", "zu", "tapf\u00b7rer", "Ge\u00b7gen\u00b7wehr", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Zu voller Sicherheit in steter Uebung bleibet.", "tokens": ["Zu", "vol\u00b7ler", "Si\u00b7cher\u00b7heit", "in", "ste\u00b7ter", "Ue\u00b7bung", "blei\u00b7bet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.24": {"line.1": {"text": "Wie ist mir denn? Und welch ein Ton", "tokens": ["Wie", "ist", "mir", "denn", "?", "Und", "welch", "ein", "Ton"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWAV", "VAFIN", "PPER", "ADV", "$.", "KON", "PWAT", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Entz\u00fcckt mich hier von ganzen Ch\u00f6ren!", "tokens": ["Ent\u00b7z\u00fcckt", "mich", "hier", "von", "gan\u00b7zen", "Ch\u00f6\u00b7ren", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "L\u00e4\u00dft irgend sich ", "tokens": ["L\u00e4\u00dft", "ir\u00b7gend", "sich"], "token_info": ["word", "word", "word"], "pos": ["VVFIN", "ADV", "PRF"], "meter": "-+-+", "measure": "iambic.di"}, "line.4": {"text": "Mit den gelehrten Schwestern h\u00f6ren?", "tokens": ["Mit", "den", "ge\u00b7lehr\u00b7ten", "Schwes\u00b7tern", "h\u00f6\u00b7ren", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Ist ", "tokens": ["Ist"], "token_info": ["word"], "pos": ["VAFIN"], "meter": "+", "measure": "single.up"}, "line.6": {"text": "Ich irre nicht; sie sind es, ja!", "tokens": ["Ich", "ir\u00b7re", "nicht", ";", "sie", "sind", "es", ",", "ja", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "$.", "PPER", "VAFIN", "PPER", "$,", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Mann nennt sie nur nicht mehr mit den verj\u00e4hrten Namen.", "tokens": ["Mann", "nennt", "sie", "nur", "nicht", "mehr", "mit", "den", "ver\u00b7j\u00e4hr\u00b7ten", "Na\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "ADV", "PTKNEG", "ADV", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.8": {"text": "O s\u00fcsse Zauberharmonie!", "tokens": ["O", "s\u00fcs\u00b7se", "Zau\u00b7ber\u00b7har\u00b7mo\u00b7nie", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Ach w\u00fc\u00dfte dich die Poesie,", "tokens": ["Ach", "w\u00fc\u00df\u00b7te", "dich", "die", "Poe\u00b7sie", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.10": {"text": "Ach w\u00fc\u00dfte dich mein Mund in etwas nachzuahmen!", "tokens": ["Ach", "w\u00fc\u00df\u00b7te", "dich", "mein", "Mund", "in", "et\u00b7was", "nach\u00b7zu\u00b7ah\u00b7men", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "VVFIN", "PPER", "PPOSAT", "NN", "APPR", "PIS", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.25": {"line.1": {"text": "Ich bin in Dresden, ist mir recht,", "tokens": ["Ich", "bin", "in", "Dres\u00b7den", ",", "ist", "mir", "recht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "NE", "$,", "VAFIN", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "In ", "tokens": ["In"], "token_info": ["word"], "pos": ["APPR"], "meter": "-", "measure": "single.down"}, "line.3": {"text": "Hier kl\u00e4ng ", "tokens": ["Hier", "kl\u00e4ng"], "token_info": ["word", "word"], "pos": ["ADV", "VVFIN"], "meter": "+-", "measure": "trochaic.single"}, "line.4": {"text": "Hier f\u00e4nd auch ", "tokens": ["Hier", "f\u00e4nd", "auch"], "token_info": ["word", "word", "word"], "pos": ["ADV", "VVFIN", "ADV"], "meter": "-+-", "measure": "amphibrach.single"}, "line.5": {"text": "Was sag ich viel? Man f\u00fchle nur,", "tokens": ["Was", "sag", "ich", "viel", "?", "Man", "f\u00fch\u00b7le", "nur", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "$.", "PIS", "VVFIN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wie mir der Ton ins Herze fuhr;", "tokens": ["Wie", "mir", "der", "Ton", "ins", "Her\u00b7ze", "fuhr", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "NN", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Wie der mich bald erquickt, bald wieder halb entgeistert;", "tokens": ["Wie", "der", "mich", "bald", "er\u00b7quickt", ",", "bald", "wie\u00b7der", "halb", "ent\u00b7geis\u00b7tert", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "PPER", "ADV", "VVPP", "$,", "ADV", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Wie der bald froh, bald traurig macht,", "tokens": ["Wie", "der", "bald", "froh", ",", "bald", "trau\u00b7rig", "macht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADV", "ADJD", "$,", "ADV", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Den einen rasend aufgebracht,", "tokens": ["Den", "ei\u00b7nen", "ra\u00b7send", "auf\u00b7ge\u00b7bracht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Des andern reger Wuth sich durch den Schlaf bemeistert.", "tokens": ["Des", "an\u00b7dern", "re\u00b7ger", "Wuth", "sich", "durch", "den", "Schlaf", "be\u00b7meis\u00b7tert", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "PRF", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.26": {"line.1": {"text": "Hier, ", "tokens": ["Hier", ","], "token_info": ["word", "punct"], "pos": ["ADV", "$,"], "meter": "+", "measure": "single.up"}, "line.2": {"text": "Des reifen Urtheils St\u00e4rke sp\u00fcren:", "tokens": ["Des", "rei\u00b7fen", "Ur\u00b7theils", "St\u00e4r\u00b7ke", "sp\u00fc\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Nur solch ein auserlesnes Chor", "tokens": ["Nur", "solch", "ein", "au\u00b7ser\u00b7les\u00b7nes", "Chor"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "PIAT", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Kann deinen edlen Geist durch Kunst und Anmuth r\u00fchren.", "tokens": ["Kann", "dei\u00b7nen", "ed\u00b7len", "Geist", "durch", "Kunst", "und", "An\u00b7muth", "r\u00fch\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPOSAT", "ADJA", "NN", "APPR", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "So wie dort ein ", "tokens": ["So", "wie", "dort", "ein"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "KOKOM", "ADV", "ART"], "meter": "-+-+", "measure": "iambic.di"}, "line.6": {"text": "Fr\u00fch morgens auf den Bergen sa\u00df.", "tokens": ["Fr\u00fch", "mor\u00b7gens", "auf", "den", "Ber\u00b7gen", "sa\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADV", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.7": {"text": "Entz\u00fccket durch den Ton bewegter Himmelssph\u00e4ren:", "tokens": ["Ent\u00b7z\u00fc\u00b7cket", "durch", "den", "Ton", "be\u00b7weg\u00b7ter", "Him\u00b7mels\u00b7sph\u00e4\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "So mag auch deine weise Brust,", "tokens": ["So", "mag", "auch", "dei\u00b7ne", "wei\u00b7se", "Brust", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ADV", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Im Gottesdienst und bey der Lust,", "tokens": ["Im", "Got\u00b7tes\u00b7dienst", "und", "bey", "der", "Lust", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "KON", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Nur das vollkommenste, des Himmels Vorschmack h\u00f6ren.", "tokens": ["Nur", "das", "voll\u00b7kom\u00b7mens\u00b7te", ",", "des", "Him\u00b7mels", "Vor\u00b7schmack", "h\u00f6\u00b7ren", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "$,", "ART", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.27": {"line.1": {"text": "Ein gleiches liebt auch dein Gemahl,", "tokens": ["Ein", "glei\u00b7ches", "liebt", "auch", "dein", "Ge\u00b7mahl", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VVFIN", "ADV", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Krone deutscher Prinze\u00dfinnen;", "tokens": ["Die", "Kro\u00b7ne", "deut\u00b7scher", "Prin\u00b7ze\u00b7\u00dfin\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Vor ihres Urtheils kluger Wahl", "tokens": ["Vor", "ih\u00b7res", "Ur\u00b7theils", "klu\u00b7ger", "Wahl"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Weis nichts verwerfliches den Beyfall zu gewinnen.", "tokens": ["Weis", "nichts", "ver\u00b7werf\u00b7li\u00b7ches", "den", "Bey\u00b7fall", "zu", "ge\u00b7win\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ADJA", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "O ", "tokens": ["O"], "token_info": ["word"], "pos": ["NE"], "meter": "+", "measure": "single.up"}, "line.6": {"text": "Ist dieses, da\u00df ", "tokens": ["Ist", "die\u00b7ses", ",", "da\u00df"], "token_info": ["word", "word", "punct", "word"], "pos": ["VAFIN", "PDS", "$,", "KOUS"], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "Durch ihre Gegenwart, dein Leipzig auch begl\u00fccket:", "tokens": ["Durch", "ih\u00b7re", "Ge\u00b7gen\u00b7wart", ",", "dein", "Leip\u00b7zig", "auch", "be\u00b7gl\u00fc\u00b7cket", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "PPOSAT", "NE", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Da\u00df dieser Kaiserstochter Pracht,", "tokens": ["Da\u00df", "die\u00b7ser", "Kai\u00b7ser\u00b7stoch\u00b7ter", "Pracht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDAT", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Uns nicht in unsers Traurens Nacht,", "tokens": ["Uns", "nicht", "in", "un\u00b7sers", "Trau\u00b7rens", "Nacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKNEG", "APPR", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Durch einen Gnadenblick vollkommner Huld erquicket.", "tokens": ["Durch", "ei\u00b7nen", "Gna\u00b7den\u00b7blick", "voll\u00b7komm\u00b7ner", "Huld", "er\u00b7quic\u00b7ket", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.28": {"line.1": {"text": "La\u00df uns, o Vater! n\u00e4chstens hier", "tokens": ["La\u00df", "uns", ",", "o", "Va\u00b7ter", "!", "n\u00e4chs\u00b7tens", "hier"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["VVIMP", "PPER", "$,", "FM", "NN", "$.", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Des Landes theure Mutter sehen!", "tokens": ["Des", "Lan\u00b7des", "theu\u00b7re", "Mut\u00b7ter", "se\u00b7hen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Wir alle wollen mit Begier,", "tokens": ["Wir", "al\u00b7le", "wol\u00b7len", "mit", "Be\u00b7gier", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PIS", "VMFIN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "F\u00fcr sie und ihre Frucht des Himmels Huld erflehen.", "tokens": ["F\u00fcr", "sie", "und", "ih\u00b7re", "Frucht", "des", "Him\u00b7mels", "Huld", "er\u00b7fle\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "KON", "PPOSAT", "NN", "ART", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Sie schm\u00fccket Sachsens Heldenhaus", "tokens": ["Sie", "schm\u00fc\u00b7cket", "Sach\u00b7sens", "Hel\u00b7den\u00b7haus"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "NE", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Durch sch\u00f6ne Prinze\u00dfinnen aus,", "tokens": ["Durch", "sch\u00f6\u00b7ne", "Prin\u00b7ze\u00b7\u00dfin\u00b7nen", "aus", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Durch ein erw\u00fcnschtes Paar von Gott erbethner Prinzen.", "tokens": ["Durch", "ein", "er\u00b7w\u00fcnschtes", "Paar", "von", "Gott", "er\u00b7be\u00b7th\u00b7ner", "Prin\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "APPR", "NN", "ADJA", "NN", "$."], "meter": "-+-++-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.8": {"text": "Sie fahre fort! so w\u00fcnscht das Land,", "tokens": ["Sie", "fah\u00b7re", "fort", "!", "so", "w\u00fcnscht", "das", "Land", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKVZ", "$.", "ADV", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Und nennt dich, ", "tokens": ["Und", "nennt", "dich", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.10": {"text": "Des allgemeinen Heils der s\u00e4chsischen Provinzen.", "tokens": ["Des", "all\u00b7ge\u00b7mei\u00b7nen", "Heils", "der", "s\u00e4ch\u00b7si\u00b7schen", "Pro\u00b7vin\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.29": {"line.1": {"text": "Die Nacht ist hin, der Tag bricht an!", "tokens": ["Die", "Nacht", "ist", "hin", ",", "der", "Tag", "bricht", "an", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "$,", "ART", "NN", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "O Sachsen, auf aus deinem Schlummer!", "tokens": ["O", "Sach\u00b7sen", ",", "auf", "aus", "dei\u00b7nem", "Schlum\u00b7mer", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "APPR", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Vergi\u00df, was dich betr\u00fcben kann,", "tokens": ["Ver\u00b7gi\u00df", ",", "was", "dich", "be\u00b7tr\u00fc\u00b7ben", "kann", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "$,", "PWS", "PPER", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und fasse dich nunmehr nach herbem Gram und Kummer.", "tokens": ["Und", "fas\u00b7se", "dich", "nun\u00b7mehr", "nach", "her\u00b7bem", "Gram", "und", "Kum\u00b7mer", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "APPR", "ADJA", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Was weinst du doch um deinen Held,", "tokens": ["Was", "weinst", "du", "doch", "um", "dei\u00b7nen", "Held", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Den du, so wie es schien, vor kurzer Zeit verlohren?", "tokens": ["Den", "du", ",", "so", "wie", "es", "schien", ",", "vor", "kur\u00b7zer", "Zeit", "ver\u00b7loh\u00b7ren", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "$,", "ADV", "KOKOM", "PPER", "VVFIN", "$,", "APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Getrost! du irrst. Er lebet noch!", "tokens": ["Ge\u00b7trost", "!", "du", "irrst", ".", "Er", "le\u00b7bet", "noch", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$.", "PPER", "ADV", "$.", "PPER", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Er lebt! ach jauchze, jauchze doch!", "tokens": ["Er", "lebt", "!", "ach", "jauch\u00b7ze", ",", "jauch\u00b7ze", "doch", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "XY", "XY", "$,", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Und zeigt sich nur verj\u00fcngt und gleichsam neu gebohren.", "tokens": ["Und", "zeigt", "sich", "nur", "ver\u00b7j\u00fcngt", "und", "gleich\u00b7sam", "neu", "ge\u00b7boh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "ADV", "VVPP", "KON", "ADJD", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.30": {"line.1": {"text": "Wie eine zarte Braut erwacht,", "tokens": ["Wie", "ei\u00b7ne", "zar\u00b7te", "Braut", "er\u00b7wacht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wenn sie des Liebsten Stimme h\u00f6ret,", "tokens": ["Wenn", "sie", "des", "Liebs\u00b7ten", "Stim\u00b7me", "h\u00f6\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Nachdem der Hochzeitkerzen Pracht", "tokens": ["Nach\u00b7dem", "der", "Hoch\u00b7zeit\u00b7ker\u00b7zen", "Pracht"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "NN"], "meter": "+--++--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Ein trauriges Ger\u00fccht von seiner Gruft gest\u00f6ret;", "tokens": ["Ein", "trau\u00b7ri\u00b7ges", "Ge\u00b7r\u00fccht", "von", "sei\u00b7ner", "Gruft", "ge\u00b7st\u00f6\u00b7ret", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Sie rafft sich auf, und sieht umher,", "tokens": ["Sie", "rafft", "sich", "auf", ",", "und", "sieht", "um\u00b7her", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "PTKVZ", "$,", "KON", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und horcht best\u00fcrzt, und zweifelt sehr,", "tokens": ["Und", "horcht", "be\u00b7st\u00fcrzt", ",", "und", "zwei\u00b7felt", "sehr", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "$,", "KON", "VVFIN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Ob irgend sie dabey ein s\u00fc\u00dfer Traum betrogen;", "tokens": ["Ob", "ir\u00b7gend", "sie", "da\u00b7bey", "ein", "s\u00fc\u00b7\u00dfer", "Traum", "be\u00b7tro\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PPER", "PAV", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Doch endlich glaubt sie, was sie sieht,", "tokens": ["Doch", "end\u00b7lich", "glaubt", "sie", ",", "was", "sie", "sieht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Und weil ihr Gl\u00fcck nun wieder bl\u00fcht,", "tokens": ["Und", "weil", "ihr", "Gl\u00fcck", "nun", "wie\u00b7der", "bl\u00fcht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPOSAT", "NN", "ADV", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "So wird im Augenblick der Brautschmuck angezogen:", "tokens": ["So", "wird", "im", "Au\u00b7gen\u00b7blick", "der", "Brautsc\u00b7hmuck", "an\u00b7ge\u00b7zo\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "APPRART", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.31": {"line.1": {"text": "So seh ich Sachsens matten Blick", "tokens": ["So", "seh", "ich", "Sach\u00b7sens", "mat\u00b7ten", "Blick"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "NN", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Auf einmal hell und munter werden.", "tokens": ["Auf", "ein\u00b7mal", "hell", "und", "mun\u00b7ter", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "ADJD", "KON", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Der blo\u00dfe Ruf von solchem Gl\u00fcck,", "tokens": ["Der", "blo\u00b7\u00dfe", "Ruf", "von", "sol\u00b7chem", "Gl\u00fcck", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Gesetzt, er w\u00e4re falsch, erweckt es aus der Erden.", "tokens": ["Ge\u00b7setzt", ",", "er", "w\u00e4\u00b7re", "falsch", ",", "er\u00b7weckt", "es", "aus", "der", "Er\u00b7den", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "PPER", "VAFIN", "ADJD", "$,", "VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wie? hei\u00dft sein Wort: Was? lebt ", "tokens": ["Wie", "?", "hei\u00dft", "sein", "Wort", ":", "Was", "?", "lebt"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct", "word"], "pos": ["PWAV", "$.", "VVFIN", "PPOSAT", "NN", "$.", "PWS", "$.", "VVFIN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Lebt ", "tokens": ["Lebt"], "token_info": ["word"], "pos": ["VVFIN"], "meter": "+", "measure": "single.up"}, "line.7": {"text": "Wer spottet meines Grams, und tr\u00f6stet mich zum Hohne?", "tokens": ["Wer", "spot\u00b7tet", "mei\u00b7nes", "Grams", ",", "und", "tr\u00f6s\u00b7tet", "mich", "zum", "Hoh\u00b7ne", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPOSAT", "NN", "$,", "KON", "VVFIN", "PPER", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Es ist unm\u00f6glich! \u2013 \u2013 Sachsen, nein!", "tokens": ["Es", "ist", "un\u00b7m\u00f6g\u00b7lich", "!", "\u2013", "\u2013", "Sach\u00b7sen", ",", "nein", "!"], "token_info": ["word", "word", "word", "punct", "punct", "punct", "word", "punct", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "$.", "$(", "$(", "NE", "$,", "PTKANT", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Man t\u00e4uscht dich nicht; dein Wunsch trifft ein:", "tokens": ["Man", "t\u00e4uscht", "dich", "nicht", ";", "dein", "Wunsch", "trifft", "ein", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "PTKNEG", "$.", "PPOSAT", "NN", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Denn ", "tokens": ["Denn"], "token_info": ["word"], "pos": ["KON"], "meter": "+", "measure": "single.up"}}, "stanza.32": {"line.1": {"text": "Dort k\u00f6mmt ja dein erw\u00fcnschtes Haupt,", "tokens": ["Dort", "k\u00f6mmt", "ja", "dein", "er\u00b7w\u00fcnschtes", "Haupt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Dein ", "tokens": ["Dein"], "token_info": ["word"], "pos": ["PPOSAT"], "meter": "+", "measure": "single.up"}, "line.3": {"text": "Was hat dir nun der Tod geraubt?", "tokens": ["Was", "hat", "dir", "nun", "der", "Tod", "ge\u00b7raubt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "ADV", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und warum gehst du noch, so wie bisher, im Leide?", "tokens": ["Und", "wa\u00b7rum", "gehst", "du", "noch", ",", "so", "wie", "bis\u00b7her", ",", "im", "Lei\u00b7de", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PWAV", "VVFIN", "PPER", "ADV", "$,", "ADV", "KOKOM", "ADV", "$,", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Sieh doch sein holdes Angesicht!", "tokens": ["Sieh", "doch", "sein", "hol\u00b7des", "An\u00b7ge\u00b7sicht", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Sieh, seiner Augen heitres Licht", "tokens": ["Sieh", ",", "sei\u00b7ner", "Au\u00b7gen", "heit\u00b7res", "Licht"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NE", "$,", "PPOSAT", "NN", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Erweckt ja jeder Brust ein wallendes Vergn\u00fcgen.", "tokens": ["Er\u00b7weckt", "ja", "je\u00b7der", "Brust", "ein", "wal\u00b7len\u00b7des", "Ver\u00b7gn\u00fc\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PIAT", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Ein jeder dringt vor seinen Thron,", "tokens": ["Ein", "je\u00b7der", "dringt", "vor", "sei\u00b7nen", "Thron", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Und will dem gro\u00dfen K\u00f6nigssohn,", "tokens": ["Und", "will", "dem", "gro\u00b7\u00dfen", "K\u00f6\u00b7nigs\u00b7sohn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Wie seinem Vater sonst, entz\u00fcckt zu F\u00fc\u00dfen liegen.", "tokens": ["Wie", "sei\u00b7nem", "Va\u00b7ter", "sonst", ",", "ent\u00b7z\u00fcckt", "zu", "F\u00fc\u00b7\u00dfen", "lie\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "NN", "ADV", "$,", "VVFIN", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.33": {"line.1": {"text": "Doch nein! das lie\u00df ", "tokens": ["Doch", "nein", "!", "das", "lie\u00df"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["KON", "PTKANT", "$.", "PDS", "VVFIN"], "meter": "-+-+", "measure": "iambic.di"}, "line.2": {"text": "Der wollte nichts von Sklaven wissen:", "tokens": ["Der", "woll\u00b7te", "nichts", "von", "Skla\u00b7ven", "wis\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PIS", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Ein gleiches, ", "tokens": ["Ein", "glei\u00b7ches", ","], "token_info": ["word", "word", "punct"], "pos": ["ART", "ADJA", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.4": {"text": "Du reichest blo\u00df die Hand, nur diese darf man k\u00fcssen.", "tokens": ["Du", "rei\u00b7chest", "blo\u00df", "die", "Hand", ",", "nur", "die\u00b7se", "darf", "man", "k\u00fcs\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN", "$,", "ADV", "PDS", "VMFIN", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "So sieht mans, wem du \u00e4hnlich bist;", "tokens": ["So", "sieht", "mans", ",", "wem", "du", "\u00e4hn\u00b7lich", "bist", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "$,", "PWS", "PPER", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "So braucht es weder Kunst noch List,", "tokens": ["So", "braucht", "es", "we\u00b7der", "Kunst", "noch", "List", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "KON", "NN", "ADV", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Des gro\u00dfen Vaters Art in deinem Thun zu finden.", "tokens": ["Des", "gro\u00b7\u00dfen", "Va\u00b7ters", "Art", "in", "dei\u00b7nem", "Thun", "zu", "fin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "APPR", "PPOSAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Du bist ihm fast in allem gleich;", "tokens": ["Du", "bist", "ihm", "fast", "in", "al\u00b7lem", "gleich", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "APPR", "PIS", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "War er an Gnad und Weisheit reich,", "tokens": ["War", "er", "an", "Gnad", "und", "Weis\u00b7heit", "reich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPR", "NN", "KON", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "So weist du beydes auch vollkommen zu verbinden.", "tokens": ["So", "weist", "du", "bey\u00b7des", "auch", "voll\u00b7kom\u00b7men", "zu", "ver\u00b7bin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PIS", "ADV", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.34": {"line.1": {"text": "Kaum legtest du die Kindheit hin,", "tokens": ["Kaum", "leg\u00b7test", "du", "die", "Kind\u00b7heit", "hin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So stund dein Herz nach edlen Sachen:", "tokens": ["So", "stund", "dein", "Herz", "nach", "ed\u00b7len", "Sa\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Denn Frankfurt lockte deinen Sinn,", "tokens": ["Denn", "Frank\u00b7furt", "lock\u00b7te", "dei\u00b7nen", "Sinn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der deutschen Kaiser Wahl dir recht bekannt zu machen.", "tokens": ["Der", "deut\u00b7schen", "Kai\u00b7ser", "Wahl", "dir", "recht", "be\u00b7kannt", "zu", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "PPER", "ADV", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Du sahst sie an; doch da Paris", "tokens": ["Du", "sahst", "sie", "an", ";", "doch", "da", "Pa\u00b7ris"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "PTKVZ", "$.", "ADV", "ADV", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "In seinem ", "tokens": ["In", "sei\u00b7nem"], "token_info": ["word", "word"], "pos": ["APPR", "PPOSAT"], "meter": "-+-", "measure": "amphibrach.single"}, "line.7": {"text": "Was F\u00fcrsten vor der Welt zum h\u00f6chsten Ruhm erhebet:", "tokens": ["Was", "F\u00fcrs\u00b7ten", "vor", "der", "Welt", "zum", "h\u00f6chs\u00b7ten", "Ruhm", "er\u00b7he\u00b7bet", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "APPR", "ART", "NN", "APPRART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "So war der Weg dir nicht zu weit,", "tokens": ["So", "war", "der", "Weg", "dir", "nicht", "zu", "weit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "PPER", "PTKNEG", "PTKA", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Vielmehr hat deine Munterkeit", "tokens": ["Viel\u00b7mehr", "hat", "dei\u00b7ne", "Mun\u00b7ter\u00b7keit"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Dem Gipfel wahrer H\u00f6h begierig nachgestrebet.", "tokens": ["Dem", "Gip\u00b7fel", "wah\u00b7rer", "H\u00f6h", "be\u00b7gie\u00b7rig", "nach\u00b7ge\u00b7stre\u00b7bet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.35": {"line.1": {"text": "Du sahst auch ferner Rom und Wien,", "tokens": ["Du", "sahst", "auch", "fer\u00b7ner", "Rom", "und", "Wi\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "NE", "KON", "NE", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Das alt und neue Haupt der Erden:", "tokens": ["Das", "alt", "und", "neu\u00b7e", "Haupt", "der", "Er\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADJD", "KON", "ADJA", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und alles das, mit dem Bem\u00fchn,", "tokens": ["Und", "al\u00b7les", "das", ",", "mit", "dem", "Be\u00b7m\u00fchn", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "PDS", "$,", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Durch das, was du gesehn, ein weiser F\u00fcrst zu werden.", "tokens": ["Durch", "das", ",", "was", "du", "ge\u00b7sehn", ",", "ein", "wei\u00b7ser", "F\u00fcrst", "zu", "wer\u00b7den", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDS", "$,", "PWS", "PPER", "VVPP", "$,", "ART", "ADJA", "NN", "PTKZU", "VAINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Nicht fremder V\u00f6lker Eitelkeit,", "tokens": ["Nicht", "frem\u00b7der", "V\u00f6l\u00b7ker", "Ei\u00b7tel\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Nein, Staatskunst und Erfahrenheit", "tokens": ["Nein", ",", "Staats\u00b7kunst", "und", "Er\u00b7fah\u00b7ren\u00b7heit"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["PTKANT", "$,", "NN", "KON", "NN"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.7": {"text": "War, andrer ", "tokens": ["War", ",", "an\u00b7drer"], "token_info": ["word", "punct", "word"], "pos": ["VAFIN", "$,", "ADJA"], "meter": "-+-", "measure": "amphibrach.single"}, "line.8": {"text": "Drum sp\u00fcrten auch die L\u00e4nder schon,", "tokens": ["Drum", "sp\u00fcr\u00b7ten", "auch", "die", "L\u00e4n\u00b7der", "schon", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "ADV", "ART", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Es w\u00fcrde dieser K\u00f6nigssohn", "tokens": ["Es", "w\u00fcr\u00b7de", "die\u00b7ser", "K\u00f6\u00b7nigs\u00b7sohn"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PDAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Der Welt einmal ein Bild vollkommner F\u00fcrsten weisen.", "tokens": ["Der", "Welt", "ein\u00b7mal", "ein", "Bild", "voll\u00b7komm\u00b7ner", "F\u00fcrs\u00b7ten", "wei\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ART", "NN", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.36": {"line.1": {"text": "Das Schrecken ", "tokens": ["Das", "Schre\u00b7cken"], "token_info": ["word", "word"], "pos": ["ART", "NN"], "meter": "-+-", "measure": "amphibrach.single"}, "line.2": {"text": "Karl, welcher Temeswar bezwungen,", "tokens": ["Karl", ",", "wel\u00b7cher", "Te\u00b7mes\u00b7war", "be\u00b7zwun\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PWAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und gar, dem Muselmann zu Trutz,", "tokens": ["Und", "gar", ",", "dem", "Mu\u00b7sel\u00b7mann", "zu", "Trutz", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$,", "ART", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Bis in des Reiches Herz nach Belgrad eingedrungen;", "tokens": ["Bis", "in", "des", "Rei\u00b7ches", "Herz", "nach", "Bel\u00b7grad", "ein\u00b7ge\u00b7drun\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "APPR", "ART", "ADJA", "NN", "APPR", "NE", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die\u00df gro\u00dfe Haupt der Christenheit", "tokens": ["Die\u00df", "gro\u00b7\u00dfe", "Haupt", "der", "Chris\u00b7ten\u00b7heit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "ADJA", "NN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Erblickte bald die Trefflichkeit,", "tokens": ["Er\u00b7blick\u00b7te", "bald", "die", "Treff\u00b7lich\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Die ", "tokens": ["Die"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}, "line.8": {"text": "Er fand, und hat es oft erkl\u00e4rt:", "tokens": ["Er", "fand", ",", "und", "hat", "es", "oft", "er\u00b7kl\u00e4rt", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KON", "VAFIN", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Ein solcher Prinz sey Kronen werth,", "tokens": ["Ein", "sol\u00b7cher", "Prinz", "sey", "Kro\u00b7nen", "werth", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VAFIN", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Der jedes Herz gewann, und alles zu sich neigte.", "tokens": ["Der", "je\u00b7des", "Herz", "ge\u00b7wann", ",", "und", "al\u00b7les", "zu", "sich", "neig\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VVFIN", "$,", "KON", "PIS", "APPR", "PRF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.37": {"line.1": {"text": "Doch dir ward auch dein Hers entf\u00fchrt,", "tokens": ["Doch", "dir", "ward", "auch", "dein", "Hers", "ent\u00b7f\u00fchrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "ADV", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "O ", "tokens": ["O"], "token_info": ["word"], "pos": ["NE"], "meter": "+", "measure": "single.up"}, "line.3": {"text": "Des Kaiserstammes Schmuck, dein einziges Verlangen.", "tokens": ["Des", "Kai\u00b7ser\u00b7stam\u00b7mes", "Schmuck", ",", "dein", "ein\u00b7zi\u00b7ges", "Ver\u00b7lan\u00b7gen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Du zogst nach Sachsen zwar zur\u00fcck;", "tokens": ["Du", "zogst", "nach", "Sach\u00b7sen", "zwar", "zu\u00b7r\u00fcck", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NE", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Doch drehte sich dein kluger Blick", "tokens": ["Doch", "dreh\u00b7te", "sich", "dein", "klu\u00b7ger", "Blick"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PRF", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Noch stets nach Oesterreichs und Wiens verla\u00dfnen Gr\u00e4nzen.", "tokens": ["Noch", "stets", "nach", "O\u00b7es\u00b7ter\u00b7reichs", "und", "Wiens", "ver\u00b7la\u00df\u00b7nen", "Gr\u00e4n\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "NE", "KON", "NN", "ADJA", "NN", "$."], "meter": "-+-+--+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.7": {"text": "So kehrt sich jener Wunderstein", "tokens": ["So", "kehrt", "sich", "je\u00b7ner", "Wun\u00b7der\u00b7stein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PRF", "PDAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Nach des entfernten Nordsterns Schein;", "tokens": ["Nach", "des", "ent\u00b7fern\u00b7ten", "Nords\u00b7terns", "Schein", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Gesetzt, er sieht ihn nicht bey hellem Tage gl\u00e4nzen.", "tokens": ["Ge\u00b7setzt", ",", "er", "sieht", "ihn", "nicht", "bey", "hel\u00b7lem", "Ta\u00b7ge", "gl\u00e4n\u00b7zen", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "PPER", "VVFIN", "PPER", "PTKNEG", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.38": {"line.1": {"text": "Ihr Musen, denen nichts entf\u00e4llt,", "tokens": ["Ihr", "Mu\u00b7sen", ",", "de\u00b7nen", "nichts", "ent\u00b7f\u00e4llt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PRELS", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Was auch vor grauer Zeit geschehen:", "tokens": ["Was", "auch", "vor", "grau\u00b7er", "Zeit", "ge\u00b7sche\u00b7hen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "O sagt, wie froh war unser Held,", "tokens": ["O", "sagt", ",", "wie", "froh", "war", "un\u00b7ser", "Held", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "$,", "PWAV", "ADJD", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Als seine Liebe drauf den Wunsch erf\u00fcllt gesehen?", "tokens": ["Als", "sei\u00b7ne", "Lie\u00b7be", "drauf", "den", "Wunsch", "er\u00b7f\u00fcllt", "ge\u00b7se\u00b7hen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "PAV", "ART", "NN", "VVPP", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Beschreibt mir doch ", "tokens": ["Be\u00b7schreibt", "mir", "doch"], "token_info": ["word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV"], "meter": "-+-+", "measure": "iambic.di"}, "line.6": {"text": "Und lehrt mich, was ihr Herz gedacht,", "tokens": ["Und", "lehrt", "mich", ",", "was", "ihr", "Herz", "ge\u00b7dacht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "$,", "PRELS", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Als ", "tokens": ["Als"], "token_info": ["word"], "pos": ["KOUS"], "meter": "+", "measure": "single.up"}, "line.8": {"text": "Als sie aus Gassen, Volk und Stadt,", "tokens": ["Als", "sie", "aus", "Gas\u00b7sen", ",", "Volk", "und", "Stadt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Aus Burg und Hof geschlossen hat,", "tokens": ["Aus", "Burg", "und", "Hof", "ge\u00b7schlos\u00b7sen", "hat", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Sie sey in Dresden fast zum Kaiserthron gekommen.", "tokens": ["Sie", "sey", "in", "Dres\u00b7den", "fast", "zum", "Kai\u00b7ser\u00b7thron", "ge\u00b7kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "NE", "ADV", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.39": {"line.1": {"text": "So war das gro\u00dfe Band nun fest,", "tokens": ["So", "war", "das", "gro\u00b7\u00dfe", "Band", "nun", "fest", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "ADJA", "NN", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das Sachsenland und Wien verbunden;", "tokens": ["Das", "Sach\u00b7sen\u00b7land", "und", "Wi\u00b7en", "ver\u00b7bun\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NE", "VVPP", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Das keine Zeit veralten l\u00e4\u00dft,", "tokens": ["Das", "kei\u00b7ne", "Zeit", "ver\u00b7al\u00b7ten", "l\u00e4\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und das noch unverr\u00fcckt des Himmels Huld empfunden.", "tokens": ["Und", "das", "noch", "un\u00b7ver\u00b7r\u00fcckt", "des", "Him\u00b7mels", "Huld", "emp\u00b7fun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "ADV", "ADJD", "ART", "NN", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wie manchen Segen keuscher Brunst", "tokens": ["Wie", "man\u00b7chen", "Se\u00b7gen", "keu\u00b7scher", "Brunst"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "PIAT", "NN", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Hat dir des Schicksals h\u00f6chste Gunst,", "tokens": ["Hat", "dir", "des", "Schick\u00b7sals", "h\u00f6chs\u00b7te", "Gunst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "In deinem Ehbett, ", "tokens": ["In", "dei\u00b7nem", "Eh\u00b7bett", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.8": {"text": "Noch itzo gr\u00fcnt die Hoffnung sch\u00f6n:", "tokens": ["Noch", "it\u00b7zo", "gr\u00fcnt", "die", "Hoff\u00b7nung", "sch\u00f6n", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Wie kann dein Stamm denn untergehn,", "tokens": ["Wie", "kann", "dein", "Stamm", "denn", "un\u00b7ter\u00b7gehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "PPOSAT", "NN", "KON", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Da so viel Zweige schon vor deinen Augen bl\u00fchen!", "tokens": ["Da", "so", "viel", "Zwei\u00b7ge", "schon", "vor", "dei\u00b7nen", "Au\u00b7gen", "bl\u00fc\u00b7hen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PIAT", "NN", "ADV", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.40": {"line.1": {"text": "Was zeigt sich f\u00fcr ein Wunderbau?", "tokens": ["Was", "zeigt", "sich", "f\u00fcr", "ein", "Wun\u00b7der\u00b7bau", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PRF", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Hat mich denn Ph\u00f6bus gar entz\u00fccket?", "tokens": ["Hat", "mich", "denn", "Ph\u00f6\u00b7bus", "gar", "ent\u00b7z\u00fc\u00b7cket", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "NE", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Was stellt sich f\u00fcr ein Schlo\u00df zur Schau,", "tokens": ["Was", "stellt", "sich", "f\u00fcr", "ein", "Schlo\u00df", "zur", "Schau", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PRF", "APPR", "ART", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Dergleichen wahrlich Rom und W\u00e4lschland kaum erblicket?", "tokens": ["Derg\u00b7lei\u00b7chen", "wahr\u00b7lich", "Rom", "und", "W\u00e4l\u00b7schland", "kaum", "er\u00b7bli\u00b7cket", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "ADV", "NE", "KON", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wer z\u00e4hlt der Fenster Menge hier?", "tokens": ["Wer", "z\u00e4hlt", "der", "Fens\u00b7ter", "Men\u00b7ge", "hier", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ART", "NN", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wer sch\u00e4tzt der stolzen Thore Zier?", "tokens": ["Wer", "sch\u00e4tzt", "der", "stol\u00b7zen", "Tho\u00b7re", "Zier", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ART", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Wer kann der D\u00e4cher Pracht, der Fl\u00fcgel Gr\u00f6\u00dfe nennen?", "tokens": ["Wer", "kann", "der", "D\u00e4\u00b7cher", "Pracht", ",", "der", "Fl\u00fc\u00b7gel", "Gr\u00f6\u00b7\u00dfe", "nen\u00b7nen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "ART", "NN", "NN", "$,", "ART", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Wer lehrt mich alle Symmetrie,", "tokens": ["Wer", "lehrt", "mich", "al\u00b7le", "Sym\u00b7me\u00b7trie", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Und was wir nach der Eurythmie,", "tokens": ["Und", "was", "wir", "nach", "der", "Eu\u00b7ryth\u00b7mie", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Im Bauen, f\u00fcr ein Werk der gr\u00f6\u00dften Kunst erkennen?", "tokens": ["Im", "Bau\u00b7en", ",", "f\u00fcr", "ein", "Werk", "der", "gr\u00f6\u00df\u00b7ten", "Kunst", "er\u00b7ken\u00b7nen", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "APPR", "ART", "NN", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.41": {"line.1": {"text": "O Hubertsburg! bist du es nicht", "tokens": ["O", "Hu\u00b7berts\u00b7burg", "!", "bist", "du", "es", "nicht"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "NE", "$.", "VAFIN", "PPER", "PPER", "PTKNEG"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "In deinen schattigten Geb\u00fcschen?", "tokens": ["In", "dei\u00b7nen", "schat\u00b7tig\u00b7ten", "Ge\u00b7b\u00fc\u00b7schen", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Ja ja, du bists, und mein Gesicht", "tokens": ["Ja", "ja", ",", "du", "bists", ",", "und", "mein", "Ge\u00b7sicht"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["PTKANT", "PTKANT", "$,", "PPER", "ADV", "$,", "KON", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Kann leichtlich deinen Bau mit W\u00e4lschlands Pracht vermischen.", "tokens": ["Kann", "leicht\u00b7lich", "dei\u00b7nen", "Bau", "mit", "W\u00e4l\u00b7schlands", "Pracht", "ver\u00b7mi\u00b7schen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADJD", "PPOSAT", "NN", "APPR", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ich seh dich zwischen Berg und Thal,", "tokens": ["Ich", "seh", "dich", "zwi\u00b7schen", "Berg", "und", "Thal", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Mit stolzen Tannen ohne Zahl,", "tokens": ["Mit", "stol\u00b7zen", "Tan\u00b7nen", "oh\u00b7ne", "Zahl", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Mit Eichen edler Art und anderm Holz umringet.", "tokens": ["Mit", "Ei\u00b7chen", "ed\u00b7ler", "Art", "und", "an\u00b7derm", "Holz", "um\u00b7rin\u00b7get", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADJA", "NN", "KON", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Hier ist Dianens Reich und Sitz!", "tokens": ["Hier", "ist", "Di\u00b7a\u00b7nens", "Reich", "und", "Sitz", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "NE", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Allhier wohnt Echo, deren Witz", "tokens": ["All\u00b7hier", "wohnt", "E\u00b7cho", ",", "de\u00b7ren", "Witz"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "VVFIN", "NN", "$,", "PRELAT", "NN"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.10": {"text": "Dem J\u00e4ger, wenn er bl\u00e4st, die Antwort zehnfach bringet.", "tokens": ["Dem", "J\u00e4\u00b7ger", ",", "wenn", "er", "bl\u00e4st", ",", "die", "Ant\u00b7wort", "zehn\u00b7fach", "brin\u00b7get", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "KOUS", "PPER", "VVFIN", "$,", "ART", "NN", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.42": {"line.1": {"text": "Verliert sich doch das Auge ganz", "tokens": ["Ver\u00b7liert", "sich", "doch", "das", "Au\u00b7ge", "ganz"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PRF", "ADV", "ART", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "In meilenlang durchschnittnen W\u00e4ldern!", "tokens": ["In", "mei\u00b7len\u00b7lang", "durch\u00b7schnitt\u00b7nen", "W\u00e4l\u00b7dern", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Da sieht man deiner Fenster Glanz,", "tokens": ["Da", "sieht", "man", "dei\u00b7ner", "Fens\u00b7ter", "Glanz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wenn Ph\u00f6bus sie bestralt, in weitentlegnen Feldern.", "tokens": ["Wenn", "Ph\u00f6\u00b7bus", "sie", "be\u00b7stralt", ",", "in", "wei\u00b7tent\u00b7leg\u00b7nen", "Fel\u00b7dern", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "PPER", "ADJD", "$,", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Man r\u00fcckt hinzu, man n\u00e4hert sich,", "tokens": ["Man", "r\u00fcckt", "hin\u00b7zu", ",", "man", "n\u00e4\u00b7hert", "sich", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PTKVZ", "$,", "PIS", "VVFIN", "PRF", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Und jeder Schritt vergr\u00f6\u00dfert dich,", "tokens": ["Und", "je\u00b7der", "Schritt", "ver\u00b7gr\u00f6\u00b7\u00dfert", "dich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "VVFIN", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Bis dich die Gegenwart in voller Sch\u00f6nheit weiset;", "tokens": ["Bis", "dich", "die", "Ge\u00b7gen\u00b7wart", "in", "vol\u00b7ler", "Sch\u00f6n\u00b7heit", "wei\u00b7set", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ART", "NN", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Bis dich durch den gespaltnen Wald,", "tokens": ["Bis", "dich", "durch", "den", "ge\u00b7spalt\u00b7nen", "Wald", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRF", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Des Wildes gr\u00fcnen Aufenthalt,", "tokens": ["Des", "Wil\u00b7des", "gr\u00fc\u00b7nen", "Auf\u00b7ent\u00b7halt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Ein ferner Blick zuletzt auf langen Wegen preiset.", "tokens": ["Ein", "fer\u00b7ner", "Blick", "zu\u00b7letzt", "auf", "lan\u00b7gen", "We\u00b7gen", "prei\u00b7set", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.43": {"line.1": {"text": "Mein Churf\u00fcrst, die\u00df hat dein Verstand,", "tokens": ["Mein", "Chur\u00b7f\u00fcrst", ",", "die\u00df", "hat", "dein", "Ver\u00b7stand", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PDS", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "-+---+-+", "measure": "dactylic.init"}, "line.2": {"text": "Dein gro\u00dfer Geist allein erfunden:", "tokens": ["Dein", "gro\u00b7\u00dfer", "Geist", "al\u00b7lein", "er\u00b7fun\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Allhier hat deine Meisterhand", "tokens": ["All\u00b7hier", "hat", "dei\u00b7ne", "Meis\u00b7ter\u00b7hand"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Sch\u00f6nheit der Natur und jeder Kunst verbunden.", "tokens": ["Die", "Sch\u00f6n\u00b7heit", "der", "Na\u00b7tur", "und", "je\u00b7der", "Kunst", "ver\u00b7bun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "KON", "PIAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Dein Lustschlo\u00df ist der Jagd geweiht;", "tokens": ["Dein", "Lust\u00b7schlo\u00df", "ist", "der", "Jagd", "ge\u00b7weiht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Doch deines Volkes Aemsigkeit", "tokens": ["Doch", "dei\u00b7nes", "Vol\u00b7kes", "A\u00b7em\u00b7sig\u00b7keit"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.7": {"text": "Hat seinen Flei\u00df und Witz hier \u00fcberall gewiesen:", "tokens": ["Hat", "sei\u00b7nen", "Flei\u00df", "und", "Witz", "hier", "\u00fc\u00b7be\u00b7rall", "ge\u00b7wie\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "KON", "NN", "ADV", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Hier hat kein K\u00fcnstler was versehn,", "tokens": ["Hier", "hat", "kein", "K\u00fcnst\u00b7ler", "was", "ver\u00b7sehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIAT", "NN", "PIS", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Und dadurch ist es l\u00e4ngst geschehn,", "tokens": ["Und", "da\u00b7durch", "ist", "es", "l\u00e4ngst", "ge\u00b7schehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PAV", "VAFIN", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Da\u00df alle den Geschmack, womit du baust, gepriesen.", "tokens": ["Da\u00df", "al\u00b7le", "den", "Ge\u00b7schmack", ",", "wo\u00b7mit", "du", "baust", ",", "ge\u00b7prie\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "PIS", "ART", "NN", "$,", "PWAV", "PPER", "VVFIN", "$,", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.44": {"line.1": {"text": "So bist du denn dem Vater gleich,", "tokens": ["So", "bist", "du", "denn", "dem", "Va\u00b7ter", "gleich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ART", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der dir auch darinn vorgegangen:", "tokens": ["Der", "dir", "auch", "da\u00b7rinn", "vor\u00b7ge\u00b7gan\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "PAV", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Denn Bauen macht den B\u00fcrger reich,", "tokens": ["Denn", "Bau\u00b7en", "macht", "den", "B\u00fcr\u00b7ger", "reich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und lockt die Fremden hin, wo solche Schl\u00f6sser prangen:", "tokens": ["Und", "lockt", "die", "Frem\u00b7den", "hin", ",", "wo", "sol\u00b7che", "Schl\u00f6s\u00b7ser", "pran\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "PTKVZ", "$,", "PWAV", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "O ", "tokens": ["O"], "token_info": ["word"], "pos": ["NE"], "meter": "+", "measure": "single.up"}, "line.6": {"text": "Es kostet dich ein einzig Wort,", "tokens": ["Es", "kos\u00b7tet", "dich", "ein", "ein\u00b7zig", "Wort", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "ART", "ADJD", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Dein Sachsen ganz und gar zum Wunderwerk zu machen.", "tokens": ["Dein", "Sach\u00b7sen", "ganz", "und", "gar", "zum", "Wun\u00b7der\u00b7werk", "zu", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADV", "KON", "ADV", "APPRART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Vollf\u00fchre der Geb\u00e4ude Pracht,", "tokens": ["Voll\u00b7f\u00fch\u00b7re", "der", "Ge\u00b7b\u00e4u\u00b7de", "Pracht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Die selbst dein Vater ausgedacht,", "tokens": ["Die", "selbst", "dein", "Va\u00b7ter", "aus\u00b7ge\u00b7dacht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "So wird der Held in dir vor aller Welt erwachen.", "tokens": ["So", "wird", "der", "Held", "in", "dir", "vor", "al\u00b7ler", "Welt", "er\u00b7wa\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "APPR", "PPER", "APPR", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.45": {"line.1": {"text": "Man eilt zur Jagd; dein Ro\u00df ist stolz,", "tokens": ["Man", "eilt", "zur", "Jagd", ";", "dein", "Ro\u00df", "ist", "stolz", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "APPRART", "NN", "$.", "PPOSAT", "NN", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dich, Herr, ins freye Feld zu tragen;", "tokens": ["Dich", ",", "Herr", ",", "ins", "frey\u00b7e", "Feld", "zu", "tra\u00b7gen", ";"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "NN", "$,", "APPRART", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Ein weites Garn umspannt das Holz,", "tokens": ["Ein", "wei\u00b7tes", "Garn", "um\u00b7spannt", "das", "Holz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Da will es Preis und Ruhm durch seinen Lauf erjagen.", "tokens": ["Da", "will", "es", "Preis", "und", "Ruhm", "durch", "sei\u00b7nen", "Lauf", "er\u00b7ja\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "NN", "KON", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Das Waldhorn t\u00f6nt, das Windspiel bellt,", "tokens": ["Das", "Wald\u00b7horn", "t\u00f6nt", ",", "das", "Wind\u00b7spiel", "bellt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Das Rohr geht los, das Wildpret f\u00e4llt,", "tokens": ["Das", "Rohr", "geht", "los", ",", "das", "Wild\u00b7pret", "f\u00e4llt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "$,", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Oft sinkt ein matter Hirsch ganz athemlos zur Erden.", "tokens": ["Oft", "sinkt", "ein", "mat\u00b7ter", "Hirsch", "ganz", "at\u00b7hem\u00b7los", "zur", "Er\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "ADV", "ADJD", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "O ", "tokens": ["O"], "token_info": ["word"], "pos": ["NE"], "meter": "+", "measure": "single.up"}, "line.9": {"text": "Mu\u00df billig deiner F\u00fcrstenbrust", "tokens": ["Mu\u00df", "bil\u00b7lig", "dei\u00b7ner", "F\u00fcrs\u00b7ten\u00b7brust"], "token_info": ["word", "word", "word", "word"], "pos": ["VMFIN", "ADJD", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Der beste Zeitvertreib, nach M\u00fch und Sorgfalt, werden.", "tokens": ["Der", "bes\u00b7te", "Zeit\u00b7ver\u00b7treib", ",", "nach", "M\u00fch", "und", "Sorg\u00b7falt", ",", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "APPR", "NE", "KON", "NN", "$,", "VAINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.46": {"line.1": {"text": "Die\u00df war der alten Helden Brauch,", "tokens": ["Die\u00df", "war", "der", "al\u00b7ten", "Hel\u00b7den", "Brauch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die d\u00e4mpften Hydren und Chim\u00e4ren!", "tokens": ["Die", "d\u00e4mpf\u00b7ten", "Hyd\u00b7ren", "und", "Chi\u00b7m\u00e4\u00b7ren", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "So hetzte sonst Ulysses auch,", "tokens": ["So", "hetz\u00b7te", "sonst", "U\u00b7lys\u00b7ses", "auch", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "NE", "ADV", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.4": {"text": "Im Jagen so ge\u00fcbt, als in der Weisheit Lehren.", "tokens": ["Im", "Ja\u00b7gen", "so", "ge\u00b7\u00fcbt", ",", "als", "in", "der", "Weis\u00b7heit", "Leh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADV", "VVPP", "$,", "KOUS", "APPR", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "So hat dort der ", "tokens": ["So", "hat", "dort", "der"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ADV", "ART"], "meter": "+-+-", "measure": "trochaic.di"}, "line.6": {"text": "Carthago, durch dein flaches Feld,", "tokens": ["Car\u00b7tha\u00b7go", ",", "durch", "dein", "fla\u00b7ches", "Feld", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.7": {"text": "Auf einem schnellen Gaul des Wildes Spur entdecket;", "tokens": ["Auf", "ei\u00b7nem", "schnel\u00b7len", "Gaul", "des", "Wil\u00b7des", "Spur", "ent\u00b7de\u00b7cket", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "ART", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "So ward auch ", "tokens": ["So", "ward", "auch"], "token_info": ["word", "word", "word"], "pos": ["ADV", "VAFIN", "ADV"], "meter": "-+-", "measure": "amphibrach.single"}, "line.9": {"text": "Manch aufgesp\u00fcrtes Wild zu Theil,", "tokens": ["Manch", "auf\u00b7ge\u00b7sp\u00fcr\u00b7tes", "Wild", "zu", "Theil", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Bevor er Troja noch in lichten Brand gestecket.", "tokens": ["Be\u00b7vor", "er", "Tro\u00b7ja", "noch", "in", "lich\u00b7ten", "Brand", "ge\u00b7ste\u00b7cket", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NE", "ADV", "APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.47": {"line.1": {"text": "O! w\u00e4ren diese Helden doch", "tokens": ["O", "!", "w\u00e4\u00b7ren", "die\u00b7se", "Hel\u00b7den", "doch"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NE", "$.", "VAFIN", "PDAT", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Bey solcher F\u00fcrstenlust geblieben:", "tokens": ["Bey", "sol\u00b7cher", "F\u00fcrs\u00b7ten\u00b7lust", "ge\u00b7blie\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "So st\u00fcnden Priams Mauren noch;", "tokens": ["So", "st\u00fcn\u00b7den", "Pri\u00b7ams", "Mau\u00b7ren", "noch", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NE", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So h\u00e4tte Griechenland sich selbst nicht aufgerieben!", "tokens": ["So", "h\u00e4t\u00b7te", "Grie\u00b7chen\u00b7land", "sich", "selbst", "nicht", "auf\u00b7ge\u00b7rie\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "NE", "PRF", "ADV", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Was half sie ein so langer Krieg,", "tokens": ["Was", "half", "sie", "ein", "so", "lan\u00b7ger", "Krieg", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ART", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "In dem der theurerkaufte Sieg,", "tokens": ["In", "dem", "der", "theu\u00b7rer\u00b7kauf\u00b7te", "Sieg", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Durch ganze Str\u00f6me Bluts, ein geiles Weib errungen?", "tokens": ["Durch", "gan\u00b7ze", "Str\u00f6\u00b7me", "Bluts", ",", "ein", "gei\u00b7les", "Weib", "er\u00b7run\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "NN", "$,", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Weit besser ists, ein Thier bek\u00e4mpft,", "tokens": ["Weit", "bes\u00b7ser", "ists", ",", "ein", "Thier", "be\u00b7k\u00e4mpft", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "ADJD", "VAFIN", "$,", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Ein erimantisch Schwein ged\u00e4mpft;", "tokens": ["Ein", "e\u00b7ri\u00b7man\u00b7tisch", "Schwein", "ge\u00b7d\u00e4mpft", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Als voller Mordbegier ein feindlich Heer bezwungen.", "tokens": ["Als", "vol\u00b7ler", "Mord\u00b7be\u00b7gier", "ein", "feind\u00b7lich", "Heer", "be\u00b7zwun\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "NN", "ART", "ADJD", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.48": {"line.1": {"text": "Wenn wird das menschliche Geschlecht", "tokens": ["Wenn", "wird", "das", "menschli\u00b7che", "Ge\u00b7schlecht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "VAFIN", "ART", "ADJA", "NN"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Doch endlich seiner Wuth vergessen,", "tokens": ["Doch", "end\u00b7lich", "sei\u00b7ner", "Wuth", "ver\u00b7ges\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und sich nach Billigkeit und Recht", "tokens": ["Und", "sich", "nach", "Bil\u00b7lig\u00b7keit", "und", "Recht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PRF", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Nicht nach der blinden Macht gest\u00e4hlter F\u00e4uste messen?", "tokens": ["Nicht", "nach", "der", "blin\u00b7den", "Macht", "ge\u00b7st\u00e4hl\u00b7ter", "F\u00e4us\u00b7te", "mes\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "ART", "ADJA", "NN", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Zur\u00fcck, ihr Furien, zur\u00fcck!", "tokens": ["Zu\u00b7r\u00fcck", ",", "ihr", "Fu\u00b7ri\u00b7en", ",", "zu\u00b7r\u00fcck", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["PTKVZ", "$,", "PPOSAT", "NN", "$,", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Verbergt nur euren finstern Blick", "tokens": ["Ver\u00b7bergt", "nur", "eu\u00b7ren", "fins\u00b7tern", "Blick"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "In des Avernus Pfuhl, und r\u00e4umt den Kreis der Erden:", "tokens": ["In", "des", "A\u00b7ver\u00b7nus", "Pfuhl", ",", "und", "r\u00e4umt", "den", "Kreis", "der", "Er\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "$,", "KON", "VVFIN", "ART", "NN", "ART", "NN", "$."], "meter": "--+--+-+-+-+-", "measure": "anapaest.di.plus"}, "line.8": {"text": "Irenens Gottheit zeigt sich schon,", "tokens": ["I\u00b7re\u00b7nens", "Got\u00b7theit", "zeigt", "sich", "schon", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "VVFIN", "PRF", "ADV", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.9": {"text": "Sie pflanzt sich unter uns den Thron,", "tokens": ["Sie", "pflanzt", "sich", "un\u00b7ter", "uns", "den", "Thron", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Und ganz Europa soll ein Friedenstempel werden.", "tokens": ["Und", "ganz", "Eu\u00b7ro\u00b7pa", "soll", "ein", "Frie\u00b7dens\u00b7tem\u00b7pel", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "NE", "VMFIN", "ART", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.49": {"line.1": {"text": "Sie bricht schon an, die g\u00fcldne Zeit,", "tokens": ["Sie", "bricht", "schon", "an", ",", "die", "g\u00fcld\u00b7ne", "Zeit", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PTKVZ", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da wir aus Schwertern Sicheln schmieden;", "tokens": ["Da", "wir", "aus", "Schwer\u00b7tern", "Si\u00b7cheln", "schmie\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Wo keine Macht der andern dr\u00e4ut,", "tokens": ["Wo", "kei\u00b7ne", "Macht", "der", "an\u00b7dern", "dr\u00e4ut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIAT", "NN", "ART", "ADJA", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Seit dem die Feder mehr, als sonst der Stahl entschieden.", "tokens": ["Seit", "dem", "die", "Fe\u00b7der", "mehr", ",", "als", "sonst", "der", "Stahl", "ent\u00b7schie\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "ART", "NN", "ADV", "$,", "KOUS", "ADV", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Es weicht der V\u00f6lker Barbarey;", "tokens": ["Es", "weicht", "der", "V\u00f6l\u00b7ker", "Bar\u00b7ba\u00b7rey", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Man liebt kein rohes Feldgeschrey,", "tokens": ["Man", "liebt", "kein", "ro\u00b7hes", "Feld\u00b7ge\u00b7schrey", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Seit die Vernunft den Platz der Dummheit eingenommen.", "tokens": ["Seit", "die", "Ver\u00b7nunft", "den", "Platz", "der", "Dumm\u00b7heit", "ein\u00b7ge\u00b7nom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "So scheint es, da\u00df dem Occident,", "tokens": ["So", "scheint", "es", ",", "da\u00df", "dem", "Oc\u00b7ci\u00b7dent", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "KOUS", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Der Gott den Gott des Friedens nennt,", "tokens": ["Der", "Gott", "den", "Gott", "des", "Frie\u00b7dens", "nennt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Vor allem Blutdurst schon ein Ekel angekommen.", "tokens": ["Vor", "al\u00b7lem", "Blut\u00b7durst", "schon", "ein", "E\u00b7kel", "an\u00b7ge\u00b7kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "NN", "ADV", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.50": {"line.1": {"text": "Zwar Waffen blinken \u00fcberall,", "tokens": ["Zwar", "Waf\u00b7fen", "blin\u00b7ken", "\u00fc\u00b7be\u00b7rall", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "VVFIN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Doch nur zur Lust der Potentaten:", "tokens": ["Doch", "nur", "zur", "Lust", "der", "Po\u00b7ten\u00b7ta\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPRART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Man h\u00f6rt der Stucke Donnerknall,", "tokens": ["Man", "h\u00f6rt", "der", "Stu\u00b7cke", "Don\u00b7ner\u00b7knall", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Doch nur aus Fr\u00f6hlichkeit im Gl\u00fcck vergn\u00fcgter Staaten.", "tokens": ["Doch", "nur", "aus", "Fr\u00f6h\u00b7lich\u00b7keit", "im", "Gl\u00fcck", "ver\u00b7gn\u00fcg\u00b7ter", "Staa\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "NN", "APPRART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "So wurdest du, o ", "tokens": ["So", "wur\u00b7dest", "du", ",", "o"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["ADV", "VAFIN", "PPER", "$,", "FM"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.6": {"text": "Als Leipzig, dessen Lust du bist,", "tokens": ["Als", "Leip\u00b7zig", ",", "des\u00b7sen", "Lust", "du", "bist", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "$,", "PRELAT", "NN", "PPER", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Dich, als sein neues Haupt, mit reger Brust empfangen;", "tokens": ["Dich", ",", "als", "sein", "neu\u00b7es", "Haupt", ",", "mit", "re\u00b7ger", "Brust", "emp\u00b7fan\u00b7gen", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "KOUS", "PPOSAT", "ADJA", "NN", "$,", "APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "So hat des B\u00fcrgers Rohr gekracht,", "tokens": ["So", "hat", "des", "B\u00fcr\u00b7gers", "Rohr", "ge\u00b7kracht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Als du ihn gn\u00e4dig angelacht,", "tokens": ["Als", "du", "ihn", "gn\u00e4\u00b7dig", "an\u00b7ge\u00b7lacht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Und ihm vor Z\u00e4rtlichkeit die Augen \u00fcbergangen.", "tokens": ["Und", "ihm", "vor", "Z\u00e4rt\u00b7lich\u00b7keit", "die", "Au\u00b7gen", "\u00fc\u00b7ber\u00b7gan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "APPR", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.51": {"line.1": {"text": "Sey, ", "tokens": ["Sey", ","], "token_info": ["word", "punct"], "pos": ["VAFIN", "$,"], "meter": "+", "measure": "single.up"}, "line.2": {"text": "So wie dein Wesen l\u00e4ngst geschienen;", "tokens": ["So", "wie", "dein", "We\u00b7sen", "l\u00e4ngst", "ge\u00b7schie\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "PPOSAT", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Denn Sachsens Gl\u00fcck entspringt davon,", "tokens": ["Denn", "Sach\u00b7sens", "Gl\u00fcck", "ent\u00b7springt", "da\u00b7von", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "NN", "VVFIN", "PAV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wenn seine Kinder dir in Ruh und Friede dienen.", "tokens": ["Wenn", "sei\u00b7ne", "Kin\u00b7der", "dir", "in", "Ruh", "und", "Frie\u00b7de", "die\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "PPER", "APPR", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Irene macht die V\u00f6lker gro\u00df,", "tokens": ["I\u00b7re\u00b7ne", "macht", "die", "V\u00f6l\u00b7ker", "gro\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ART", "NN", "ADJD", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.6": {"text": "Wenn Stadt und Land, dem Gl\u00fcck im Schoo\u00df,", "tokens": ["Wenn", "Stadt", "und", "Land", ",", "dem", "Gl\u00fcck", "im", "Schoo\u00df", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "NN", "$,", "ART", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Den fetten Acker baut, den Handel eifrig treibet:", "tokens": ["Den", "fet\u00b7ten", "A\u00b7cker", "baut", ",", "den", "Han\u00b7del", "eif\u00b7rig", "trei\u00b7bet", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,", "ART", "NN", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Indessen da\u00df ein r\u00fcstig Heer,", "tokens": ["In\u00b7des\u00b7sen", "da\u00df", "ein", "r\u00fcs\u00b7tig", "Heer", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "ART", "ADJD", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Bereit zu tapfrer Gegenwehr,", "tokens": ["Be\u00b7reit", "zu", "tapf\u00b7rer", "Ge\u00b7gen\u00b7wehr", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Zu voller Sicherheit in steter Uebung bleibet.", "tokens": ["Zu", "vol\u00b7ler", "Si\u00b7cher\u00b7heit", "in", "ste\u00b7ter", "Ue\u00b7bung", "blei\u00b7bet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.52": {"line.1": {"text": "Wie ist mir denn? Und welch ein Ton", "tokens": ["Wie", "ist", "mir", "denn", "?", "Und", "welch", "ein", "Ton"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWAV", "VAFIN", "PPER", "ADV", "$.", "KON", "PWAT", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Entz\u00fcckt mich hier von ganzen Ch\u00f6ren!", "tokens": ["Ent\u00b7z\u00fcckt", "mich", "hier", "von", "gan\u00b7zen", "Ch\u00f6\u00b7ren", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "L\u00e4\u00dft irgend sich ", "tokens": ["L\u00e4\u00dft", "ir\u00b7gend", "sich"], "token_info": ["word", "word", "word"], "pos": ["VVFIN", "ADV", "PRF"], "meter": "-+-+", "measure": "iambic.di"}, "line.4": {"text": "Mit den gelehrten Schwestern h\u00f6ren?", "tokens": ["Mit", "den", "ge\u00b7lehr\u00b7ten", "Schwes\u00b7tern", "h\u00f6\u00b7ren", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Ist ", "tokens": ["Ist"], "token_info": ["word"], "pos": ["VAFIN"], "meter": "+", "measure": "single.up"}, "line.6": {"text": "Ich irre nicht; sie sind es, ja!", "tokens": ["Ich", "ir\u00b7re", "nicht", ";", "sie", "sind", "es", ",", "ja", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "$.", "PPER", "VAFIN", "PPER", "$,", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Mann nennt sie nur nicht mehr mit den verj\u00e4hrten Namen.", "tokens": ["Mann", "nennt", "sie", "nur", "nicht", "mehr", "mit", "den", "ver\u00b7j\u00e4hr\u00b7ten", "Na\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "ADV", "PTKNEG", "ADV", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.8": {"text": "O s\u00fcsse Zauberharmonie!", "tokens": ["O", "s\u00fcs\u00b7se", "Zau\u00b7ber\u00b7har\u00b7mo\u00b7nie", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Ach w\u00fc\u00dfte dich die Poesie,", "tokens": ["Ach", "w\u00fc\u00df\u00b7te", "dich", "die", "Poe\u00b7sie", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.10": {"text": "Ach w\u00fc\u00dfte dich mein Mund in etwas nachzuahmen!", "tokens": ["Ach", "w\u00fc\u00df\u00b7te", "dich", "mein", "Mund", "in", "et\u00b7was", "nach\u00b7zu\u00b7ah\u00b7men", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "VVFIN", "PPER", "PPOSAT", "NN", "APPR", "PIS", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.53": {"line.1": {"text": "Ich bin in Dresden, ist mir recht,", "tokens": ["Ich", "bin", "in", "Dres\u00b7den", ",", "ist", "mir", "recht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "NE", "$,", "VAFIN", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "In ", "tokens": ["In"], "token_info": ["word"], "pos": ["APPR"], "meter": "-", "measure": "single.down"}, "line.3": {"text": "Hier kl\u00e4ng ", "tokens": ["Hier", "kl\u00e4ng"], "token_info": ["word", "word"], "pos": ["ADV", "VVFIN"], "meter": "+-", "measure": "trochaic.single"}, "line.4": {"text": "Hier f\u00e4nd auch ", "tokens": ["Hier", "f\u00e4nd", "auch"], "token_info": ["word", "word", "word"], "pos": ["ADV", "VVFIN", "ADV"], "meter": "-+-", "measure": "amphibrach.single"}, "line.5": {"text": "Was sag ich viel? Man f\u00fchle nur,", "tokens": ["Was", "sag", "ich", "viel", "?", "Man", "f\u00fch\u00b7le", "nur", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "$.", "PIS", "VVFIN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wie mir der Ton ins Herze fuhr;", "tokens": ["Wie", "mir", "der", "Ton", "ins", "Her\u00b7ze", "fuhr", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "NN", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Wie der mich bald erquickt, bald wieder halb entgeistert;", "tokens": ["Wie", "der", "mich", "bald", "er\u00b7quickt", ",", "bald", "wie\u00b7der", "halb", "ent\u00b7geis\u00b7tert", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "PPER", "ADV", "VVPP", "$,", "ADV", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Wie der bald froh, bald traurig macht,", "tokens": ["Wie", "der", "bald", "froh", ",", "bald", "trau\u00b7rig", "macht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADV", "ADJD", "$,", "ADV", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Den einen rasend aufgebracht,", "tokens": ["Den", "ei\u00b7nen", "ra\u00b7send", "auf\u00b7ge\u00b7bracht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Des andern reger Wuth sich durch den Schlaf bemeistert.", "tokens": ["Des", "an\u00b7dern", "re\u00b7ger", "Wuth", "sich", "durch", "den", "Schlaf", "be\u00b7meis\u00b7tert", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "PRF", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.54": {"line.1": {"text": "Hier, ", "tokens": ["Hier", ","], "token_info": ["word", "punct"], "pos": ["ADV", "$,"], "meter": "+", "measure": "single.up"}, "line.2": {"text": "Des reifen Urtheils St\u00e4rke sp\u00fcren:", "tokens": ["Des", "rei\u00b7fen", "Ur\u00b7theils", "St\u00e4r\u00b7ke", "sp\u00fc\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Nur solch ein auserlesnes Chor", "tokens": ["Nur", "solch", "ein", "au\u00b7ser\u00b7les\u00b7nes", "Chor"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "PIAT", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Kann deinen edlen Geist durch Kunst und Anmuth r\u00fchren.", "tokens": ["Kann", "dei\u00b7nen", "ed\u00b7len", "Geist", "durch", "Kunst", "und", "An\u00b7muth", "r\u00fch\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPOSAT", "ADJA", "NN", "APPR", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "So wie dort ein ", "tokens": ["So", "wie", "dort", "ein"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "KOKOM", "ADV", "ART"], "meter": "-+-+", "measure": "iambic.di"}, "line.6": {"text": "Fr\u00fch morgens auf den Bergen sa\u00df.", "tokens": ["Fr\u00fch", "mor\u00b7gens", "auf", "den", "Ber\u00b7gen", "sa\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADV", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.7": {"text": "Entz\u00fccket durch den Ton bewegter Himmelssph\u00e4ren:", "tokens": ["Ent\u00b7z\u00fc\u00b7cket", "durch", "den", "Ton", "be\u00b7weg\u00b7ter", "Him\u00b7mels\u00b7sph\u00e4\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "So mag auch deine weise Brust,", "tokens": ["So", "mag", "auch", "dei\u00b7ne", "wei\u00b7se", "Brust", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ADV", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Im Gottesdienst und bey der Lust,", "tokens": ["Im", "Got\u00b7tes\u00b7dienst", "und", "bey", "der", "Lust", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "KON", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Nur das vollkommenste, des Himmels Vorschmack h\u00f6ren.", "tokens": ["Nur", "das", "voll\u00b7kom\u00b7mens\u00b7te", ",", "des", "Him\u00b7mels", "Vor\u00b7schmack", "h\u00f6\u00b7ren", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "$,", "ART", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.55": {"line.1": {"text": "Ein gleiches liebt auch dein Gemahl,", "tokens": ["Ein", "glei\u00b7ches", "liebt", "auch", "dein", "Ge\u00b7mahl", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VVFIN", "ADV", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Krone deutscher Prinze\u00dfinnen;", "tokens": ["Die", "Kro\u00b7ne", "deut\u00b7scher", "Prin\u00b7ze\u00b7\u00dfin\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Vor ihres Urtheils kluger Wahl", "tokens": ["Vor", "ih\u00b7res", "Ur\u00b7theils", "klu\u00b7ger", "Wahl"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Weis nichts verwerfliches den Beyfall zu gewinnen.", "tokens": ["Weis", "nichts", "ver\u00b7werf\u00b7li\u00b7ches", "den", "Bey\u00b7fall", "zu", "ge\u00b7win\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ADJA", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "O ", "tokens": ["O"], "token_info": ["word"], "pos": ["NE"], "meter": "+", "measure": "single.up"}, "line.6": {"text": "Ist dieses, da\u00df ", "tokens": ["Ist", "die\u00b7ses", ",", "da\u00df"], "token_info": ["word", "word", "punct", "word"], "pos": ["VAFIN", "PDS", "$,", "KOUS"], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "Durch ihre Gegenwart, dein Leipzig auch begl\u00fccket:", "tokens": ["Durch", "ih\u00b7re", "Ge\u00b7gen\u00b7wart", ",", "dein", "Leip\u00b7zig", "auch", "be\u00b7gl\u00fc\u00b7cket", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "PPOSAT", "NE", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Da\u00df dieser Kaiserstochter Pracht,", "tokens": ["Da\u00df", "die\u00b7ser", "Kai\u00b7ser\u00b7stoch\u00b7ter", "Pracht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDAT", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Uns nicht in unsers Traurens Nacht,", "tokens": ["Uns", "nicht", "in", "un\u00b7sers", "Trau\u00b7rens", "Nacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKNEG", "APPR", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Durch einen Gnadenblick vollkommner Huld erquicket.", "tokens": ["Durch", "ei\u00b7nen", "Gna\u00b7den\u00b7blick", "voll\u00b7komm\u00b7ner", "Huld", "er\u00b7quic\u00b7ket", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.56": {"line.1": {"text": "La\u00df uns, o Vater! n\u00e4chstens hier", "tokens": ["La\u00df", "uns", ",", "o", "Va\u00b7ter", "!", "n\u00e4chs\u00b7tens", "hier"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["VVIMP", "PPER", "$,", "FM", "NN", "$.", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Des Landes theure Mutter sehen!", "tokens": ["Des", "Lan\u00b7des", "theu\u00b7re", "Mut\u00b7ter", "se\u00b7hen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Wir alle wollen mit Begier,", "tokens": ["Wir", "al\u00b7le", "wol\u00b7len", "mit", "Be\u00b7gier", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PIS", "VMFIN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "F\u00fcr sie und ihre Frucht des Himmels Huld erflehen.", "tokens": ["F\u00fcr", "sie", "und", "ih\u00b7re", "Frucht", "des", "Him\u00b7mels", "Huld", "er\u00b7fle\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "KON", "PPOSAT", "NN", "ART", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Sie schm\u00fccket Sachsens Heldenhaus", "tokens": ["Sie", "schm\u00fc\u00b7cket", "Sach\u00b7sens", "Hel\u00b7den\u00b7haus"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "NE", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Durch sch\u00f6ne Prinze\u00dfinnen aus,", "tokens": ["Durch", "sch\u00f6\u00b7ne", "Prin\u00b7ze\u00b7\u00dfin\u00b7nen", "aus", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Durch ein erw\u00fcnschtes Paar von Gott erbethner Prinzen.", "tokens": ["Durch", "ein", "er\u00b7w\u00fcnschtes", "Paar", "von", "Gott", "er\u00b7be\u00b7th\u00b7ner", "Prin\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "APPR", "NN", "ADJA", "NN", "$."], "meter": "-+-++-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.8": {"text": "Sie fahre fort! so w\u00fcnscht das Land,", "tokens": ["Sie", "fah\u00b7re", "fort", "!", "so", "w\u00fcnscht", "das", "Land", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKVZ", "$.", "ADV", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Und nennt dich, ", "tokens": ["Und", "nennt", "dich", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.10": {"text": "Des allgemeinen Heils der s\u00e4chsischen Provinzen.", "tokens": ["Des", "all\u00b7ge\u00b7mei\u00b7nen", "Heils", "der", "s\u00e4ch\u00b7si\u00b7schen", "Pro\u00b7vin\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}