{"textgrid.poem.50142": {"metadata": {"author": {"name": "Wernicke, Christian", "birth": "N.A.", "death": "N.A."}, "title": "30. Auff Policrates", "genre": "verse", "period": "N.A.", "pub_year": 1693, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Es bildte sich das ", "tokens": ["Es", "bild\u00b7te", "sich", "das"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PRF", "ART"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.2": {"text": "Man k\u00f6nne leicht ungl\u00fccklich sein,", "tokens": ["Man", "k\u00f6n\u00b7ne", "leicht", "un\u00b7gl\u00fcck\u00b7lich", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "ADJD", "ADJD", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und dass, sein ", "tokens": ["Und", "dass", ",", "sein"], "token_info": ["word", "word", "punct", "word"], "pos": ["KON", "PDS", "$,", "PPOSAT"], "meter": "+-+", "measure": "trochaic.di"}, "line.4": {"text": "Versenckt, hiezu ein Mittel w\u00e4r:", "tokens": ["Ver\u00b7senckt", ",", "hie\u00b7zu", "ein", "Mit\u00b7tel", "w\u00e4r", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "PAV", "ART", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Er hatte niemahls noch ergr\u00fcndt,", "tokens": ["Er", "hat\u00b7te", "nie\u00b7mahls", "noch", "er\u00b7gr\u00fcndt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Es sey der Mensch offt so verflucht,", "tokens": ["Es", "sey", "der", "Mensch", "offt", "so", "ver\u00b7flucht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "ADV", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Dass, wenn er selbst ", "tokens": ["Dass", ",", "wenn", "er", "selbst"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["PDS", "$,", "KOUS", "PPER", "ADV"], "meter": "+--+", "measure": "iambic.di.chol"}}, "stanza.2": {"line.1": {"text": "Es bildte sich das ", "tokens": ["Es", "bild\u00b7te", "sich", "das"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PRF", "ART"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.2": {"text": "Man k\u00f6nne leicht ungl\u00fccklich sein,", "tokens": ["Man", "k\u00f6n\u00b7ne", "leicht", "un\u00b7gl\u00fcck\u00b7lich", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "ADJD", "ADJD", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und dass, sein ", "tokens": ["Und", "dass", ",", "sein"], "token_info": ["word", "word", "punct", "word"], "pos": ["KON", "PDS", "$,", "PPOSAT"], "meter": "+-+", "measure": "trochaic.di"}, "line.4": {"text": "Versenckt, hiezu ein Mittel w\u00e4r:", "tokens": ["Ver\u00b7senckt", ",", "hie\u00b7zu", "ein", "Mit\u00b7tel", "w\u00e4r", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "PAV", "ART", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Er hatte niemahls noch ergr\u00fcndt,", "tokens": ["Er", "hat\u00b7te", "nie\u00b7mahls", "noch", "er\u00b7gr\u00fcndt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Es sey der Mensch offt so verflucht,", "tokens": ["Es", "sey", "der", "Mensch", "offt", "so", "ver\u00b7flucht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "ADV", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Dass, wenn er selbst ", "tokens": ["Dass", ",", "wenn", "er", "selbst"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["PDS", "$,", "KOUS", "PPER", "ADV"], "meter": "+--+", "measure": "iambic.di.chol"}}}}}