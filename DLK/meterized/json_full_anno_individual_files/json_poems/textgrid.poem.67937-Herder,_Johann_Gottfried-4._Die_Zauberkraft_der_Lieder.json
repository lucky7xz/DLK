{"textgrid.poem.67937": {"metadata": {"author": {"name": "Herder, Johann Gottfried", "birth": "N.A.", "death": "N.A."}, "title": "4. Die Zauberkraft der Lieder", "genre": "verse", "period": "N.A.", "pub_year": 1773, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ich wei\u00df, ich hing neun N\u00e4chte lang,", "tokens": ["Ich", "wei\u00df", ",", "ich", "hing", "neun", "N\u00e4ch\u00b7te", "lang", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VVFIN", "CARD", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Geschenkt dem Odin (und ihn mir,)", "tokens": ["Ge\u00b7schenkt", "dem", "O\u00b7din", "(", "und", "ihn", "mir", ",", ")"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "ART", "NE", "$(", "KON", "PPER", "PPER", "$,", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Den Winden entgegen, durchstochen mit dem Schwert,", "tokens": ["Den", "Win\u00b7den", "ent\u00b7ge\u00b7gen", ",", "durch\u00b7sto\u00b7chen", "mit", "dem", "Schwert", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "$,", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Am Baum, de\u00df Wurzel niemand kennt.", "tokens": ["Am", "Baum", ",", "de\u00df", "Wur\u00b7zel", "nie\u00b7mand", "kennt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "ART", "NN", "PIS", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Da n\u00e4hrte mich nicht Brod noch Trank;", "tokens": ["Da", "n\u00e4hr\u00b7te", "mich", "nicht", "Brod", "noch", "Trank", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PTKNEG", "NN", "ADV", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mit Schmerzen fiel ich herab und fand", "tokens": ["Mit", "Schmer\u00b7zen", "fiel", "ich", "her\u00b7ab", "und", "fand"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "VVFIN", "PPER", "ADV", "KON", "VVFIN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Die Runen: schmerzend fiel mein Leib", "tokens": ["Die", "Ru\u00b7nen", ":", "schmer\u00b7zend", "fiel", "mein", "Leib"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$.", "ADJD", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Aufs neu herab.", "tokens": ["Aufs", "neu", "her\u00b7ab", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "ADJD", "ADV", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.3": {"line.1": {"text": "Neun grosse Lieder hab ich gelernt,", "tokens": ["Neun", "gros\u00b7se", "Lie\u00b7der", "hab", "ich", "ge\u00b7lernt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "ADJA", "NN", "VAFIN", "PPER", "VVPP", "$,"], "meter": "---+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Von Bolthar, Freya's ber\u00fchmtem Sohn,", "tokens": ["Von", "Bolt\u00b7har", ",", "Freya's", "be\u00b7r\u00fchm\u00b7tem", "Sohn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "$,", "NE", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und trank den edlen Honigtrank", "tokens": ["Und", "trank", "den", "ed\u00b7len", "Ho\u00b7nig\u00b7trank"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Voll Sangeskunst.", "tokens": ["Voll", "San\u00b7ges\u00b7kunst", "."], "token_info": ["word", "word", "punct"], "pos": ["ADJD", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.4": {"line.1": {"text": "Da ward ich weise, da ward ich gro\u00df,", "tokens": ["Da", "ward", "ich", "wei\u00b7se", ",", "da", "ward", "ich", "gro\u00df", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "VVFIN", "$,", "ADV", "VAFIN", "PPER", "ADJD", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Da ward ich gl\u00fccklich, Wort gab Wort,", "tokens": ["Da", "ward", "ich", "gl\u00fcck\u00b7lich", ",", "Wort", "gab", "Wort", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "$,", "NN", "VVFIN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und That gab That.", "tokens": ["Und", "That", "gab", "That", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.5": {"line.1": {"text": "Auch du wirst Runen finden und Zeichen,", "tokens": ["Auch", "du", "wirst", "Ru\u00b7nen", "fin\u00b7den", "und", "Zei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VAFIN", "NN", "VVINF", "KON", "NN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "M\u00e4chtige Zeichen, grosse Zeichen!", "tokens": ["M\u00e4ch\u00b7ti\u00b7ge", "Zei\u00b7chen", ",", "gros\u00b7se", "Zei\u00b7chen", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "ADJA", "NN", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Die der Alte der G\u00f6tter erfand!", "tokens": ["Die", "der", "Al\u00b7te", "der", "G\u00f6t\u00b7ter", "er\u00b7fand", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "ART", "NN", "VVFIN", "$."], "meter": "--+--+--+", "measure": "anapaest.tri.plus"}, "line.4": {"text": "Und die G\u00f6tter machten und Odin grub.", "tokens": ["Und", "die", "G\u00f6t\u00b7ter", "mach\u00b7ten", "und", "O\u00b7din", "grub", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "KON", "NE", "VVFIN", "$."], "meter": "--+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.6": {"line.1": {"text": "Odin der Asen, der Alfen Dwalinn,", "tokens": ["O\u00b7din", "der", "A\u00b7sen", ",", "der", "Al\u00b7fen", "Dwa\u00b7linn", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "ART", "NN", "$,", "ART", "NN", "NN", "$,"], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}, "line.2": {"text": "Dain der Zwerge, Asvid der Riesen,", "tokens": ["Dain", "der", "Zwer\u00b7ge", ",", "As\u00b7vid", "der", "Rie\u00b7sen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "NN", "$,", "NE", "ART", "NN", "$,"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "Auch ich grub etliche ein.", "tokens": ["Auch", "ich", "grub", "et\u00b7li\u00b7che", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VVFIN", "PIS", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Weistu, wie sie einzugraben? weistu, wie sie aufzul\u00f6sen?", "tokens": ["Weis\u00b7tu", ",", "wie", "sie", "ein\u00b7zu\u00b7gra\u00b7ben", "?", "weis\u00b7tu", ",", "wie", "sie", "auf\u00b7zu\u00b7l\u00f6\u00b7sen", "?"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PWAV", "PPER", "VVIZU", "$.", "VVFIN", "$,", "PWAV", "PPER", "VVPP", "$."], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.2": {"text": "Weistu, wie sie sind zu versuchen? weistu wie sie sind zu erfragen?", "tokens": ["Weis\u00b7tu", ",", "wie", "sie", "sind", "zu", "ver\u00b7su\u00b7chen", "?", "weis\u00b7tu", "wie", "sie", "sind", "zu", "er\u00b7fra\u00b7gen", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PWAV", "PPER", "VAFIN", "PTKZU", "VVINF", "$.", "VVFIN", "KOKOM", "PPER", "VAFIN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+--+-+-+-", "measure": "iambic.octa.plus.relaxed"}, "line.3": {"text": "Weistu, wie sie wegzusenden? weistu, wie zur\u00fcckzurufen?", "tokens": ["Weis\u00b7tu", ",", "wie", "sie", "weg\u00b7zu\u00b7sen\u00b7den", "?", "weis\u00b7tu", ",", "wie", "zu\u00b7r\u00fcck\u00b7zu\u00b7ru\u00b7fen", "?"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "PWAV", "PPER", "VVPP", "$.", "VVFIN", "$,", "PWAV", "VVPP", "$."], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.4": {"text": "Denn besser nicht zu senden, als zur\u00fcckzurufen zu oft.", "tokens": ["Denn", "bes\u00b7ser", "nicht", "zu", "sen\u00b7den", ",", "als", "zu\u00b7r\u00fcck\u00b7zu\u00b7ru\u00b7fen", "zu", "oft", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "PTKNEG", "PTKZU", "VVINF", "$,", "KOUS", "VVINF", "PTKZU", "ADV", "$."], "meter": "-+-+-+-+-+-+--+", "measure": "iambic.septa.chol"}}, "stanza.8": {"line.1": {"text": "Lieder kann ich; es kann sie keiner,", "tokens": ["Lie\u00b7der", "kann", "ich", ";", "es", "kann", "sie", "kei\u00b7ner", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "PPER", "$.", "PPER", "VMFIN", "PPER", "PIS", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Nicht K\u00f6nigs Tochter, nicht Mannes Sohn.", "tokens": ["Nicht", "K\u00f6\u00b7nigs", "Toch\u00b7ter", ",", "nicht", "Man\u00b7nes", "Sohn", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "NN", "NN", "$,", "PTKNEG", "NN", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Eins hei\u00dft H\u00fclfe; es wird dir helfen", "tokens": ["Eins", "hei\u00dft", "H\u00fcl\u00b7fe", ";", "es", "wird", "dir", "hel\u00b7fen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "NN", "$.", "PPER", "VAFIN", "PPER", "VVINF"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "In Schmerz, in Trauer, in aller Noth.", "tokens": ["In", "Schmerz", ",", "in", "Trau\u00b7er", ",", "in", "al\u00b7ler", "Noth", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "APPR", "NN", "$,", "APPR", "PIAT", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.9": {"line.1": {"text": "Ich kann ein Zweites; sein bed\u00f6rfen", "tokens": ["Ich", "kann", "ein", "Zwei\u00b7tes", ";", "sein", "be\u00b7d\u00f6r\u00b7fen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VMFIN", "ART", "NN", "$.", "PPOSAT", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die Menschens\u00f6hne zur Arzenei.", "tokens": ["Die", "Men\u00b7schen\u00b7s\u00f6h\u00b7ne", "zur", "Ar\u00b7ze\u00b7nei", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.10": {"line.1": {"text": "Ich kann ein Drittes, den Feind zu zwingen,", "tokens": ["Ich", "kann", "ein", "Drit\u00b7tes", ",", "den", "Feind", "zu", "zwin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "ADJA", "$,", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Wenn Noth mir ist:", "tokens": ["Wenn", "Noth", "mir", "ist", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "PPER", "VAFIN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "Sein Schwert zu stumpfen und seine List,", "tokens": ["Sein", "Schwert", "zu", "stump\u00b7fen", "und", "sei\u00b7ne", "List", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PTKZU", "VVINF", "KON", "PPOSAT", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Das[s] sie nichts vermag.", "tokens": ["Das", "s", "sie", "nichts", "ver\u00b7mag", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "$(", "FM.la", "$(", "PPER", "PIS", "VVFIN", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.11": {"line.1": {"text": "Ich kann ein Viertes: werfen die M\u00e4nner", "tokens": ["Ich", "kann", "ein", "Vier\u00b7tes", ":", "wer\u00b7fen", "die", "M\u00e4n\u00b7ner"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ART", "NN", "$.", "VVFIN", "ART", "NN"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Bande mir an.", "tokens": ["Ban\u00b7de", "mir", "an", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PPER", "PTKVZ", "$."], "meter": "+--+", "measure": "iambic.di.chol"}, "line.3": {"text": "Ich singe das Lied und wandle frei;", "tokens": ["Ich", "sin\u00b7ge", "das", "Lied", "und", "wand\u00b7le", "frei", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "KON", "VVFIN", "ADJD", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Die Ketten brechen mir an den F\u00fcssen;", "tokens": ["Die", "Ket\u00b7ten", "bre\u00b7chen", "mir", "an", "den", "F\u00fcs\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Die Fesseln fallen von den H\u00e4nden mir.", "tokens": ["Die", "Fes\u00b7seln", "fal\u00b7len", "von", "den", "H\u00e4n\u00b7den", "mir", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ART", "NN", "PPER", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.12": {"line.1": {"text": "Ich kann ein F\u00fcnftes: seh ich geschossen", "tokens": ["Ich", "kann", "ein", "F\u00fcnf\u00b7tes", ":", "seh", "ich", "ge\u00b7schos\u00b7sen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ART", "NN", "$.", "VVFIN", "PPER", "VVPP"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Mit Feindesmuthe den fliegenden Pfeil,", "tokens": ["Mit", "Fein\u00b7des\u00b7mu\u00b7the", "den", "flie\u00b7gen\u00b7den", "Pfeil", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "In seinem Fluge halt ich ihn auf", "tokens": ["In", "sei\u00b7nem", "Flu\u00b7ge", "halt", "ich", "ihn", "auf"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "PPER", "PPER", "APPR"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Durch meinen Blick.", "tokens": ["Durch", "mei\u00b7nen", "Blick", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.13": {"line.1": {"text": "Ich kann ein Sechstes: wenn mich verwundet", "tokens": ["Ich", "kann", "ein", "Sechs\u00b7tes", ":", "wenn", "mich", "ver\u00b7wun\u00b7det"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ART", "NN", "$.", "KOUS", "PPER", "VVPP"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Ein Mann mit Zauber und reitzt mit Zorn;", "tokens": ["Ein", "Mann", "mit", "Zau\u00b7ber", "und", "reitzt", "mit", "Zorn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "KON", "VVFIN", "APPR", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Ich singe das Lied, da\u00df ihn, nicht mich", "tokens": ["Ich", "sin\u00b7ge", "das", "Lied", ",", "da\u00df", "ihn", ",", "nicht", "mich"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "KOUS", "PPER", "$,", "PTKNEG", "PPER"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Das Uebel trift.", "tokens": ["Das", "Ue\u00b7bel", "trift", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.14": {"line.1": {"text": "Ich kann ein Siebendes: seh ich brennen", "tokens": ["Ich", "kann", "ein", "Sie\u00b7ben\u00b7des", ":", "seh", "ich", "bren\u00b7nen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ART", "NN", "$.", "VVFIN", "PPER", "VVINF"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Ein Haus und die Flamme breitet sich umher.", "tokens": ["Ein", "Haus", "und", "die", "Flam\u00b7me", "brei\u00b7tet", "sich", "um\u00b7her", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "VVFIN", "PRF", "PTKVZ", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Ich singe den Zauber und b\u00e4ndige sie.", "tokens": ["Ich", "sin\u00b7ge", "den", "Zau\u00b7ber", "und", "b\u00e4n\u00b7di\u00b7ge", "sie", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "KON", "VVFIN", "PPER", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}}, "stanza.15": {"line.1": {"text": "Ich kann ein Achtes: das Noth ist Allen,", "tokens": ["Ich", "kann", "ein", "Ach\u00b7tes", ":", "das", "Noth", "ist", "Al\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "NN", "$.", "ART", "NN", "VAFIN", "NE", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Wenn unter den Menschen Ha\u00df beginnt;", "tokens": ["Wenn", "un\u00b7ter", "den", "Men\u00b7schen", "Ha\u00df", "be\u00b7ginnt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "ART", "NN", "NN", "VVFIN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Ich sing' es und ersticke das Uebel schnell.", "tokens": ["Ich", "sing'", "es", "und", "er\u00b7sti\u00b7cke", "das", "Ue\u00b7bel", "schnell", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "KON", "VVFIN", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}}, "stanza.16": {"line.1": {"text": "Ich kann ein Neuntes: wenn Noth mir ist,", "tokens": ["Ich", "kann", "ein", "Neun\u00b7tes", ":", "wenn", "Noth", "mir", "ist", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "NN", "$.", "KOUS", "NN", "PPER", "VAFIN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Mein Schiff zu retten auf st\u00fcrmiger See;", "tokens": ["Mein", "Schiff", "zu", "ret\u00b7ten", "auf", "st\u00fcr\u00b7mi\u00b7ger", "See", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PTKZU", "VVINF", "APPR", "ADJA", "NN", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Ich stille den Wind und stille die See.", "tokens": ["Ich", "stil\u00b7le", "den", "Wind", "und", "stil\u00b7le", "die", "See", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "KON", "VVFIN", "ART", "NN", "$."], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}}, "stanza.17": {"line.1": {"text": "Ich kann ein Zehntes: wenn Zauberinnen", "tokens": ["Ich", "kann", "ein", "Zehn\u00b7tes", ":", "wenn", "Zau\u00b7be\u00b7rin\u00b7nen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VMFIN", "ART", "NN", "$.", "KOUS", "NN"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Die Luft durchreiten; ich blicke sie ab", "tokens": ["Die", "Luft", "durch\u00b7rei\u00b7ten", ";", "ich", "bli\u00b7cke", "sie", "ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "$.", "PPER", "VVFIN", "PPER", "PTKVZ"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Von ihrem Wege, von ihrer Bahn.", "tokens": ["Von", "ih\u00b7rem", "We\u00b7ge", ",", "von", "ih\u00b7rer", "Bahn", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.18": {"line.1": {"text": "Ich kann ein Eilftes; f\u00fchr' ich ins Treffen,", "tokens": ["Ich", "kann", "ein", "Eilf\u00b7tes", ";", "f\u00fchr'", "ich", "ins", "Tref\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "NN", "$.", "VVFIN", "PPER", "APPRART", "NN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Alte Freunde, so bezaubr' ich die Waffen;", "tokens": ["Al\u00b7te", "Freun\u00b7de", ",", "so", "be\u00b7zau\u00b7br'", "ich", "die", "Waf\u00b7fen", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "ADV", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.3": {"text": "Da gehn sie m\u00e4chtig und heil zur Schlacht,", "tokens": ["Da", "gehn", "sie", "m\u00e4ch\u00b7tig", "und", "heil", "zur", "Schlacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "KON", "ADJD", "APPRART", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Und heil hinaus und \u00fcberall heil.", "tokens": ["Und", "heil", "hin\u00b7aus", "und", "\u00fc\u00b7be\u00b7rall", "heil", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "PTKVZ", "KON", "ADV", "ADJD", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.19": {"line.1": {"text": "Ich kann ein Zw\u00f6lftes, seh ich am Baume", "tokens": ["Ich", "kann", "ein", "Zw\u00f6lf\u00b7tes", ",", "seh", "ich", "am", "Bau\u00b7me"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ART", "NN", "$,", "VVFIN", "PPER", "APPRART", "NN"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Den Todten hangen; ich zeichne Runen;", "tokens": ["Den", "Tod\u00b7ten", "han\u00b7gen", ";", "ich", "zeich\u00b7ne", "Ru\u00b7nen", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "$.", "PPER", "VVFIN", "NN", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "So kommt der Mann und spricht mit mir.", "tokens": ["So", "kommt", "der", "Mann", "und", "spricht", "mit", "mir", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "KON", "VVFIN", "APPR", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.20": {"line.1": {"text": "Ich kann ein Andres: bespreng ich mit Wasser", "tokens": ["Ich", "kann", "ein", "And\u00b7res", ":", "be\u00b7spreng", "ich", "mit", "Was\u00b7ser"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ART", "PIS", "$.", "VVFIN", "PPER", "APPR", "NN"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Den zarten Knaben, so wird er von Waffen", "tokens": ["Den", "zar\u00b7ten", "Kna\u00b7ben", ",", "so", "wird", "er", "von", "Waf\u00b7fen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "ADV", "VAFIN", "PPER", "APPR", "NN"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Und Schwert nicht fallen in keiner Schlacht.", "tokens": ["Und", "Schwert", "nicht", "fal\u00b7len", "in", "kei\u00b7ner", "Schlacht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "PTKNEG", "VVINF", "APPR", "PIAT", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.21": {"line.1": {"text": "Ich kann ein Anders; der V\u00f6lker Namen,", "tokens": ["Ich", "kann", "ein", "An\u00b7ders", ";", "der", "V\u00f6l\u00b7ker", "Na\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "NN", "$.", "ART", "NN", "NN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Der Asen und Alfen Unterschied", "tokens": ["Der", "A\u00b7sen", "und", "Al\u00b7fen", "Un\u00b7ter\u00b7schied"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "KON", "NN", "NN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Kann ich euch nennen, wenige k\u00f6nnens.", "tokens": ["Kann", "ich", "euch", "nen\u00b7nen", ",", "we\u00b7ni\u00b7ge", "k\u00f6n\u00b7nens", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PPER", "VVINF", "$,", "PIAT", "NN", "$."], "meter": "+-+--+--+-", "measure": "trochaic.tetra.relaxed"}}, "stanza.22": {"line.1": {"text": "Ich kann ein Anders, das sang Thiodrey", "tokens": ["Ich", "kann", "ein", "An\u00b7ders", ",", "das", "sang", "Thiod\u00b7rey"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ART", "NN", "$,", "PRELS", "ADJD", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Vor Dellings Pforte: Muth den Asen", "tokens": ["Vor", "Del\u00b7lings", "Pfor\u00b7te", ":", "Muth", "den", "A\u00b7sen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "NE", "NN", "$.", "NN", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Den Alfen Kraft, Weisheit den Odi[n].", "tokens": ["Den", "Al\u00b7fen", "Kraft", ",", "Weis\u00b7heit", "den", "O\u00b7di", "n", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct", "punct"], "pos": ["ART", "NN", "NN", "$,", "NN", "ART", "NE", "$(", "XY", "$(", "$."], "meter": "-+-+++-+-+", "measure": "zehnsilber"}}, "stanza.23": {"line.1": {"text": "Ich kann ein Anders, will ich geniessen", "tokens": ["Ich", "kann", "ein", "An\u00b7ders", ",", "will", "ich", "ge\u00b7nies\u00b7sen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ART", "NN", "$,", "VMFIN", "PPER", "VVINF"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Des edelsten M\u00e4dchen Lieb und Gunst:", "tokens": ["Des", "e\u00b7dels\u00b7ten", "M\u00e4d\u00b7chen", "Lieb", "und", "Gunst", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "KON", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Ich sing es und wandle den Sinn des M\u00e4dchen", "tokens": ["Ich", "sing", "es", "und", "wand\u00b7le", "den", "Sinn", "des", "M\u00e4d\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "KON", "VVFIN", "ART", "NN", "ART", "NN"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Von weissen Armen, und lenk' ihr Herz.", "tokens": ["Von", "weis\u00b7sen", "Ar\u00b7men", ",", "und", "lenk'", "ihr", "Herz", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "KON", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.24": {"line.1": {"text": "Ich kann ein Anders, das[s] mich das M\u00e4dchen", "tokens": ["Ich", "kann", "ein", "An\u00b7ders", ",", "das", "s", "mich", "das", "M\u00e4d\u00b7chen"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ART", "NN", "$,", "PRELS", "$(", "FM.la", "$(", "PPER", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Nie verlasse; \u2013 Lotfafner du,", "tokens": ["Nie", "ver\u00b7las\u00b7se", ";", "\u2013", "Lot\u00b7faf\u00b7ner", "du", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$.", "$(", "NE", "NE", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.3": {"text": "Weist du die Lieder? sie sind dir gut:", "tokens": ["Weist", "du", "die", "Lie\u00b7der", "?", "sie", "sind", "dir", "gut", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "NN", "$.", "PPER", "VAFIN", "PPER", "ADJD", "$."], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.4": {"text": "N\u00fctz zu lernen, zu wissen noth.", "tokens": ["N\u00fctz", "zu", "ler\u00b7nen", ",", "zu", "wis\u00b7sen", "noth", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "PTKZU", "VVINF", "$,", "PTKZU", "VVINF", "NN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.25": {"line.1": {"text": "Ich kann ein Anders, das lehr' ich keinem", "tokens": ["Ich", "kann", "ein", "An\u00b7ders", ",", "das", "lehr'", "ich", "kei\u00b7nem"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ART", "NN", "$,", "PDS", "VVFIN", "PPER", "PIAT"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "M\u00e4dchen noch Weibe; nur Einer wei\u00df es:", "tokens": ["M\u00e4d\u00b7chen", "noch", "Wei\u00b7be", ";", "nur", "Ei\u00b7ner", "wei\u00df", "es", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "NN", "$.", "ADV", "PIS", "VVFIN", "PPER", "$."], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}, "line.3": {"text": "Das beste der Lieder; ich lehr' es etwa", "tokens": ["Das", "bes\u00b7te", "der", "Lie\u00b7der", ";", "ich", "lehr'", "es", "et\u00b7wa"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "ART", "NN", "$.", "PPER", "VVFIN", "PPER", "ADV"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "Nur meiner Schwester und die mich in ihre", "tokens": ["Nur", "mei\u00b7ner", "Schwes\u00b7ter", "und", "die", "mich", "in", "ih\u00b7re"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "PPOSAT", "NN", "KON", "PRELS", "PRF", "APPR", "PPOSAT"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Arme schlie\u00dft.", "tokens": ["Ar\u00b7me", "schlie\u00dft", "."], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVFIN", "$."], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.26": {"line.1": {"text": "Nun sind gesungen die hohen Spr\u00fcche", "tokens": ["Nun", "sind", "ge\u00b7sun\u00b7gen", "die", "ho\u00b7hen", "Spr\u00fc\u00b7che"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "VVPP", "ART", "ADJA", "NN"], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}, "line.2": {"text": "Im hohen Pallast:", "tokens": ["Im", "ho\u00b7hen", "Pal\u00b7last", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.3": {"text": "Sie sind sehr noth den Menschens\u00f6hnen,", "tokens": ["Sie", "sind", "sehr", "noth", "den", "Men\u00b7schen\u00b7s\u00f6h\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "(und sind nicht noth den Menschens\u00f6hnen.)", "tokens": ["(", "und", "sind", "nicht", "noth", "den", "Men\u00b7schen\u00b7s\u00f6h\u00b7nen", ".", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "KON", "VAFIN", "PTKNEG", "NN", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Heil der sie sang! Heil der sie kann!", "tokens": ["Heil", "der", "sie", "sang", "!", "Heil", "der", "sie", "kann", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "PPER", "VVFIN", "$.", "NN", "ART", "PPER", "VMFIN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.6": {"text": "Wohl der sie lernt! heil, der sie h\u00f6rt! \u2013", "tokens": ["Wohl", "der", "sie", "lernt", "!", "heil", ",", "der", "sie", "h\u00f6rt", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "ART", "PPER", "VVFIN", "$.", "ADJD", "$,", "PRELS", "PPER", "VVFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.27": {"line.1": {"text": "Ich wei\u00df, ich hing neun N\u00e4chte lang,", "tokens": ["Ich", "wei\u00df", ",", "ich", "hing", "neun", "N\u00e4ch\u00b7te", "lang", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VVFIN", "CARD", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Geschenkt dem Odin (und ihn mir,)", "tokens": ["Ge\u00b7schenkt", "dem", "O\u00b7din", "(", "und", "ihn", "mir", ",", ")"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "ART", "NE", "$(", "KON", "PPER", "PPER", "$,", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Den Winden entgegen, durchstochen mit dem Schwert,", "tokens": ["Den", "Win\u00b7den", "ent\u00b7ge\u00b7gen", ",", "durch\u00b7sto\u00b7chen", "mit", "dem", "Schwert", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "$,", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Am Baum, de\u00df Wurzel niemand kennt.", "tokens": ["Am", "Baum", ",", "de\u00df", "Wur\u00b7zel", "nie\u00b7mand", "kennt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "ART", "NN", "PIS", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.28": {"line.1": {"text": "Da n\u00e4hrte mich nicht Brod noch Trank;", "tokens": ["Da", "n\u00e4hr\u00b7te", "mich", "nicht", "Brod", "noch", "Trank", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PTKNEG", "NN", "ADV", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mit Schmerzen fiel ich herab und fand", "tokens": ["Mit", "Schmer\u00b7zen", "fiel", "ich", "her\u00b7ab", "und", "fand"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "VVFIN", "PPER", "ADV", "KON", "VVFIN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Die Runen: schmerzend fiel mein Leib", "tokens": ["Die", "Ru\u00b7nen", ":", "schmer\u00b7zend", "fiel", "mein", "Leib"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$.", "ADJD", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Aufs neu herab.", "tokens": ["Aufs", "neu", "her\u00b7ab", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "ADJD", "ADV", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.29": {"line.1": {"text": "Neun grosse Lieder hab ich gelernt,", "tokens": ["Neun", "gros\u00b7se", "Lie\u00b7der", "hab", "ich", "ge\u00b7lernt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "ADJA", "NN", "VAFIN", "PPER", "VVPP", "$,"], "meter": "---+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Von Bolthar, Freya's ber\u00fchmtem Sohn,", "tokens": ["Von", "Bolt\u00b7har", ",", "Freya's", "be\u00b7r\u00fchm\u00b7tem", "Sohn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "$,", "NE", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und trank den edlen Honigtrank", "tokens": ["Und", "trank", "den", "ed\u00b7len", "Ho\u00b7nig\u00b7trank"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Voll Sangeskunst.", "tokens": ["Voll", "San\u00b7ges\u00b7kunst", "."], "token_info": ["word", "word", "punct"], "pos": ["ADJD", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.30": {"line.1": {"text": "Da ward ich weise, da ward ich gro\u00df,", "tokens": ["Da", "ward", "ich", "wei\u00b7se", ",", "da", "ward", "ich", "gro\u00df", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "VVFIN", "$,", "ADV", "VAFIN", "PPER", "ADJD", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Da ward ich gl\u00fccklich, Wort gab Wort,", "tokens": ["Da", "ward", "ich", "gl\u00fcck\u00b7lich", ",", "Wort", "gab", "Wort", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "$,", "NN", "VVFIN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und That gab That.", "tokens": ["Und", "That", "gab", "That", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.31": {"line.1": {"text": "Auch du wirst Runen finden und Zeichen,", "tokens": ["Auch", "du", "wirst", "Ru\u00b7nen", "fin\u00b7den", "und", "Zei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VAFIN", "NN", "VVINF", "KON", "NN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "M\u00e4chtige Zeichen, grosse Zeichen!", "tokens": ["M\u00e4ch\u00b7ti\u00b7ge", "Zei\u00b7chen", ",", "gros\u00b7se", "Zei\u00b7chen", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "ADJA", "NN", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Die der Alte der G\u00f6tter erfand!", "tokens": ["Die", "der", "Al\u00b7te", "der", "G\u00f6t\u00b7ter", "er\u00b7fand", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "ART", "NN", "VVFIN", "$."], "meter": "--+--+--+", "measure": "anapaest.tri.plus"}, "line.4": {"text": "Und die G\u00f6tter machten und Odin grub.", "tokens": ["Und", "die", "G\u00f6t\u00b7ter", "mach\u00b7ten", "und", "O\u00b7din", "grub", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "KON", "NE", "VVFIN", "$."], "meter": "--+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.32": {"line.1": {"text": "Odin der Asen, der Alfen Dwalinn,", "tokens": ["O\u00b7din", "der", "A\u00b7sen", ",", "der", "Al\u00b7fen", "Dwa\u00b7linn", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "ART", "NN", "$,", "ART", "NN", "NN", "$,"], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}, "line.2": {"text": "Dain der Zwerge, Asvid der Riesen,", "tokens": ["Dain", "der", "Zwer\u00b7ge", ",", "As\u00b7vid", "der", "Rie\u00b7sen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "NN", "$,", "NE", "ART", "NN", "$,"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "Auch ich grub etliche ein.", "tokens": ["Auch", "ich", "grub", "et\u00b7li\u00b7che", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VVFIN", "PIS", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.33": {"line.1": {"text": "Weistu, wie sie einzugraben? weistu, wie sie aufzul\u00f6sen?", "tokens": ["Weis\u00b7tu", ",", "wie", "sie", "ein\u00b7zu\u00b7gra\u00b7ben", "?", "weis\u00b7tu", ",", "wie", "sie", "auf\u00b7zu\u00b7l\u00f6\u00b7sen", "?"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PWAV", "PPER", "VVIZU", "$.", "VVFIN", "$,", "PWAV", "PPER", "VVPP", "$."], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.2": {"text": "Weistu, wie sie sind zu versuchen? weistu wie sie sind zu erfragen?", "tokens": ["Weis\u00b7tu", ",", "wie", "sie", "sind", "zu", "ver\u00b7su\u00b7chen", "?", "weis\u00b7tu", "wie", "sie", "sind", "zu", "er\u00b7fra\u00b7gen", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PWAV", "PPER", "VAFIN", "PTKZU", "VVINF", "$.", "VVFIN", "KOKOM", "PPER", "VAFIN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+--+-+-+-", "measure": "iambic.octa.plus.relaxed"}, "line.3": {"text": "Weistu, wie sie wegzusenden? weistu, wie zur\u00fcckzurufen?", "tokens": ["Weis\u00b7tu", ",", "wie", "sie", "weg\u00b7zu\u00b7sen\u00b7den", "?", "weis\u00b7tu", ",", "wie", "zu\u00b7r\u00fcck\u00b7zu\u00b7ru\u00b7fen", "?"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "PWAV", "PPER", "VVPP", "$.", "VVFIN", "$,", "PWAV", "VVPP", "$."], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.4": {"text": "Denn besser nicht zu senden, als zur\u00fcckzurufen zu oft.", "tokens": ["Denn", "bes\u00b7ser", "nicht", "zu", "sen\u00b7den", ",", "als", "zu\u00b7r\u00fcck\u00b7zu\u00b7ru\u00b7fen", "zu", "oft", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "PTKNEG", "PTKZU", "VVINF", "$,", "KOUS", "VVINF", "PTKZU", "ADV", "$."], "meter": "-+-+-+-+-+-+--+", "measure": "iambic.septa.chol"}}, "stanza.34": {"line.1": {"text": "Lieder kann ich; es kann sie keiner,", "tokens": ["Lie\u00b7der", "kann", "ich", ";", "es", "kann", "sie", "kei\u00b7ner", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "PPER", "$.", "PPER", "VMFIN", "PPER", "PIS", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Nicht K\u00f6nigs Tochter, nicht Mannes Sohn.", "tokens": ["Nicht", "K\u00f6\u00b7nigs", "Toch\u00b7ter", ",", "nicht", "Man\u00b7nes", "Sohn", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "NN", "NN", "$,", "PTKNEG", "NN", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Eins hei\u00dft H\u00fclfe; es wird dir helfen", "tokens": ["Eins", "hei\u00dft", "H\u00fcl\u00b7fe", ";", "es", "wird", "dir", "hel\u00b7fen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "NN", "$.", "PPER", "VAFIN", "PPER", "VVINF"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "In Schmerz, in Trauer, in aller Noth.", "tokens": ["In", "Schmerz", ",", "in", "Trau\u00b7er", ",", "in", "al\u00b7ler", "Noth", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "APPR", "NN", "$,", "APPR", "PIAT", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.35": {"line.1": {"text": "Ich kann ein Zweites; sein bed\u00f6rfen", "tokens": ["Ich", "kann", "ein", "Zwei\u00b7tes", ";", "sein", "be\u00b7d\u00f6r\u00b7fen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VMFIN", "ART", "NN", "$.", "PPOSAT", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die Menschens\u00f6hne zur Arzenei.", "tokens": ["Die", "Men\u00b7schen\u00b7s\u00f6h\u00b7ne", "zur", "Ar\u00b7ze\u00b7nei", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.36": {"line.1": {"text": "Ich kann ein Drittes, den Feind zu zwingen,", "tokens": ["Ich", "kann", "ein", "Drit\u00b7tes", ",", "den", "Feind", "zu", "zwin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "ADJA", "$,", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Wenn Noth mir ist:", "tokens": ["Wenn", "Noth", "mir", "ist", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "PPER", "VAFIN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "Sein Schwert zu stumpfen und seine List,", "tokens": ["Sein", "Schwert", "zu", "stump\u00b7fen", "und", "sei\u00b7ne", "List", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PTKZU", "VVINF", "KON", "PPOSAT", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Das[s] sie nichts vermag.", "tokens": ["Das", "s", "sie", "nichts", "ver\u00b7mag", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "$(", "FM.la", "$(", "PPER", "PIS", "VVFIN", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.37": {"line.1": {"text": "Ich kann ein Viertes: werfen die M\u00e4nner", "tokens": ["Ich", "kann", "ein", "Vier\u00b7tes", ":", "wer\u00b7fen", "die", "M\u00e4n\u00b7ner"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ART", "NN", "$.", "VVFIN", "ART", "NN"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Bande mir an.", "tokens": ["Ban\u00b7de", "mir", "an", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PPER", "PTKVZ", "$."], "meter": "+--+", "measure": "iambic.di.chol"}, "line.3": {"text": "Ich singe das Lied und wandle frei;", "tokens": ["Ich", "sin\u00b7ge", "das", "Lied", "und", "wand\u00b7le", "frei", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "KON", "VVFIN", "ADJD", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Die Ketten brechen mir an den F\u00fcssen;", "tokens": ["Die", "Ket\u00b7ten", "bre\u00b7chen", "mir", "an", "den", "F\u00fcs\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Die Fesseln fallen von den H\u00e4nden mir.", "tokens": ["Die", "Fes\u00b7seln", "fal\u00b7len", "von", "den", "H\u00e4n\u00b7den", "mir", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ART", "NN", "PPER", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.38": {"line.1": {"text": "Ich kann ein F\u00fcnftes: seh ich geschossen", "tokens": ["Ich", "kann", "ein", "F\u00fcnf\u00b7tes", ":", "seh", "ich", "ge\u00b7schos\u00b7sen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ART", "NN", "$.", "VVFIN", "PPER", "VVPP"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Mit Feindesmuthe den fliegenden Pfeil,", "tokens": ["Mit", "Fein\u00b7des\u00b7mu\u00b7the", "den", "flie\u00b7gen\u00b7den", "Pfeil", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "In seinem Fluge halt ich ihn auf", "tokens": ["In", "sei\u00b7nem", "Flu\u00b7ge", "halt", "ich", "ihn", "auf"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "PPER", "PPER", "APPR"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Durch meinen Blick.", "tokens": ["Durch", "mei\u00b7nen", "Blick", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.39": {"line.1": {"text": "Ich kann ein Sechstes: wenn mich verwundet", "tokens": ["Ich", "kann", "ein", "Sechs\u00b7tes", ":", "wenn", "mich", "ver\u00b7wun\u00b7det"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ART", "NN", "$.", "KOUS", "PPER", "VVPP"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Ein Mann mit Zauber und reitzt mit Zorn;", "tokens": ["Ein", "Mann", "mit", "Zau\u00b7ber", "und", "reitzt", "mit", "Zorn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "KON", "VVFIN", "APPR", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Ich singe das Lied, da\u00df ihn, nicht mich", "tokens": ["Ich", "sin\u00b7ge", "das", "Lied", ",", "da\u00df", "ihn", ",", "nicht", "mich"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "KOUS", "PPER", "$,", "PTKNEG", "PPER"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Das Uebel trift.", "tokens": ["Das", "Ue\u00b7bel", "trift", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.40": {"line.1": {"text": "Ich kann ein Siebendes: seh ich brennen", "tokens": ["Ich", "kann", "ein", "Sie\u00b7ben\u00b7des", ":", "seh", "ich", "bren\u00b7nen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ART", "NN", "$.", "VVFIN", "PPER", "VVINF"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Ein Haus und die Flamme breitet sich umher.", "tokens": ["Ein", "Haus", "und", "die", "Flam\u00b7me", "brei\u00b7tet", "sich", "um\u00b7her", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "VVFIN", "PRF", "PTKVZ", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Ich singe den Zauber und b\u00e4ndige sie.", "tokens": ["Ich", "sin\u00b7ge", "den", "Zau\u00b7ber", "und", "b\u00e4n\u00b7di\u00b7ge", "sie", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "KON", "VVFIN", "PPER", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}}, "stanza.41": {"line.1": {"text": "Ich kann ein Achtes: das Noth ist Allen,", "tokens": ["Ich", "kann", "ein", "Ach\u00b7tes", ":", "das", "Noth", "ist", "Al\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "NN", "$.", "ART", "NN", "VAFIN", "NE", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Wenn unter den Menschen Ha\u00df beginnt;", "tokens": ["Wenn", "un\u00b7ter", "den", "Men\u00b7schen", "Ha\u00df", "be\u00b7ginnt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "ART", "NN", "NN", "VVFIN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Ich sing' es und ersticke das Uebel schnell.", "tokens": ["Ich", "sing'", "es", "und", "er\u00b7sti\u00b7cke", "das", "Ue\u00b7bel", "schnell", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "KON", "VVFIN", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}}, "stanza.42": {"line.1": {"text": "Ich kann ein Neuntes: wenn Noth mir ist,", "tokens": ["Ich", "kann", "ein", "Neun\u00b7tes", ":", "wenn", "Noth", "mir", "ist", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "NN", "$.", "KOUS", "NN", "PPER", "VAFIN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Mein Schiff zu retten auf st\u00fcrmiger See;", "tokens": ["Mein", "Schiff", "zu", "ret\u00b7ten", "auf", "st\u00fcr\u00b7mi\u00b7ger", "See", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PTKZU", "VVINF", "APPR", "ADJA", "NN", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Ich stille den Wind und stille die See.", "tokens": ["Ich", "stil\u00b7le", "den", "Wind", "und", "stil\u00b7le", "die", "See", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "KON", "VVFIN", "ART", "NN", "$."], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}}, "stanza.43": {"line.1": {"text": "Ich kann ein Zehntes: wenn Zauberinnen", "tokens": ["Ich", "kann", "ein", "Zehn\u00b7tes", ":", "wenn", "Zau\u00b7be\u00b7rin\u00b7nen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VMFIN", "ART", "NN", "$.", "KOUS", "NN"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Die Luft durchreiten; ich blicke sie ab", "tokens": ["Die", "Luft", "durch\u00b7rei\u00b7ten", ";", "ich", "bli\u00b7cke", "sie", "ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "$.", "PPER", "VVFIN", "PPER", "PTKVZ"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Von ihrem Wege, von ihrer Bahn.", "tokens": ["Von", "ih\u00b7rem", "We\u00b7ge", ",", "von", "ih\u00b7rer", "Bahn", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.44": {"line.1": {"text": "Ich kann ein Eilftes; f\u00fchr' ich ins Treffen,", "tokens": ["Ich", "kann", "ein", "Eilf\u00b7tes", ";", "f\u00fchr'", "ich", "ins", "Tref\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "NN", "$.", "VVFIN", "PPER", "APPRART", "NN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Alte Freunde, so bezaubr' ich die Waffen;", "tokens": ["Al\u00b7te", "Freun\u00b7de", ",", "so", "be\u00b7zau\u00b7br'", "ich", "die", "Waf\u00b7fen", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "ADV", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.3": {"text": "Da gehn sie m\u00e4chtig und heil zur Schlacht,", "tokens": ["Da", "gehn", "sie", "m\u00e4ch\u00b7tig", "und", "heil", "zur", "Schlacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "KON", "ADJD", "APPRART", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Und heil hinaus und \u00fcberall heil.", "tokens": ["Und", "heil", "hin\u00b7aus", "und", "\u00fc\u00b7be\u00b7rall", "heil", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "PTKVZ", "KON", "ADV", "ADJD", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.45": {"line.1": {"text": "Ich kann ein Zw\u00f6lftes, seh ich am Baume", "tokens": ["Ich", "kann", "ein", "Zw\u00f6lf\u00b7tes", ",", "seh", "ich", "am", "Bau\u00b7me"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ART", "NN", "$,", "VVFIN", "PPER", "APPRART", "NN"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Den Todten hangen; ich zeichne Runen;", "tokens": ["Den", "Tod\u00b7ten", "han\u00b7gen", ";", "ich", "zeich\u00b7ne", "Ru\u00b7nen", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "$.", "PPER", "VVFIN", "NN", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "So kommt der Mann und spricht mit mir.", "tokens": ["So", "kommt", "der", "Mann", "und", "spricht", "mit", "mir", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "KON", "VVFIN", "APPR", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.46": {"line.1": {"text": "Ich kann ein Andres: bespreng ich mit Wasser", "tokens": ["Ich", "kann", "ein", "And\u00b7res", ":", "be\u00b7spreng", "ich", "mit", "Was\u00b7ser"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ART", "PIS", "$.", "VVFIN", "PPER", "APPR", "NN"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Den zarten Knaben, so wird er von Waffen", "tokens": ["Den", "zar\u00b7ten", "Kna\u00b7ben", ",", "so", "wird", "er", "von", "Waf\u00b7fen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "ADV", "VAFIN", "PPER", "APPR", "NN"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Und Schwert nicht fallen in keiner Schlacht.", "tokens": ["Und", "Schwert", "nicht", "fal\u00b7len", "in", "kei\u00b7ner", "Schlacht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "PTKNEG", "VVINF", "APPR", "PIAT", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.47": {"line.1": {"text": "Ich kann ein Anders; der V\u00f6lker Namen,", "tokens": ["Ich", "kann", "ein", "An\u00b7ders", ";", "der", "V\u00f6l\u00b7ker", "Na\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "NN", "$.", "ART", "NN", "NN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Der Asen und Alfen Unterschied", "tokens": ["Der", "A\u00b7sen", "und", "Al\u00b7fen", "Un\u00b7ter\u00b7schied"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "KON", "NN", "NN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Kann ich euch nennen, wenige k\u00f6nnens.", "tokens": ["Kann", "ich", "euch", "nen\u00b7nen", ",", "we\u00b7ni\u00b7ge", "k\u00f6n\u00b7nens", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PPER", "VVINF", "$,", "PIAT", "NN", "$."], "meter": "+-+--+--+-", "measure": "trochaic.tetra.relaxed"}}, "stanza.48": {"line.1": {"text": "Ich kann ein Anders, das sang Thiodrey", "tokens": ["Ich", "kann", "ein", "An\u00b7ders", ",", "das", "sang", "Thiod\u00b7rey"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ART", "NN", "$,", "PRELS", "ADJD", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Vor Dellings Pforte: Muth den Asen", "tokens": ["Vor", "Del\u00b7lings", "Pfor\u00b7te", ":", "Muth", "den", "A\u00b7sen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "NE", "NN", "$.", "NN", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Den Alfen Kraft, Weisheit den Odi[n].", "tokens": ["Den", "Al\u00b7fen", "Kraft", ",", "Weis\u00b7heit", "den", "O\u00b7di", "n", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct", "punct"], "pos": ["ART", "NN", "NN", "$,", "NN", "ART", "NE", "$(", "XY", "$(", "$."], "meter": "-+-+++-+-+", "measure": "zehnsilber"}}, "stanza.49": {"line.1": {"text": "Ich kann ein Anders, will ich geniessen", "tokens": ["Ich", "kann", "ein", "An\u00b7ders", ",", "will", "ich", "ge\u00b7nies\u00b7sen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ART", "NN", "$,", "VMFIN", "PPER", "VVINF"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Des edelsten M\u00e4dchen Lieb und Gunst:", "tokens": ["Des", "e\u00b7dels\u00b7ten", "M\u00e4d\u00b7chen", "Lieb", "und", "Gunst", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "KON", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Ich sing es und wandle den Sinn des M\u00e4dchen", "tokens": ["Ich", "sing", "es", "und", "wand\u00b7le", "den", "Sinn", "des", "M\u00e4d\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "KON", "VVFIN", "ART", "NN", "ART", "NN"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Von weissen Armen, und lenk' ihr Herz.", "tokens": ["Von", "weis\u00b7sen", "Ar\u00b7men", ",", "und", "lenk'", "ihr", "Herz", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "KON", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.50": {"line.1": {"text": "Ich kann ein Anders, das[s] mich das M\u00e4dchen", "tokens": ["Ich", "kann", "ein", "An\u00b7ders", ",", "das", "s", "mich", "das", "M\u00e4d\u00b7chen"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ART", "NN", "$,", "PRELS", "$(", "FM.la", "$(", "PPER", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Nie verlasse; \u2013 Lotfafner du,", "tokens": ["Nie", "ver\u00b7las\u00b7se", ";", "\u2013", "Lot\u00b7faf\u00b7ner", "du", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$.", "$(", "NE", "NE", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.3": {"text": "Weist du die Lieder? sie sind dir gut:", "tokens": ["Weist", "du", "die", "Lie\u00b7der", "?", "sie", "sind", "dir", "gut", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "NN", "$.", "PPER", "VAFIN", "PPER", "ADJD", "$."], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.4": {"text": "N\u00fctz zu lernen, zu wissen noth.", "tokens": ["N\u00fctz", "zu", "ler\u00b7nen", ",", "zu", "wis\u00b7sen", "noth", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "PTKZU", "VVINF", "$,", "PTKZU", "VVINF", "NN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.51": {"line.1": {"text": "Ich kann ein Anders, das lehr' ich keinem", "tokens": ["Ich", "kann", "ein", "An\u00b7ders", ",", "das", "lehr'", "ich", "kei\u00b7nem"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ART", "NN", "$,", "PDS", "VVFIN", "PPER", "PIAT"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "M\u00e4dchen noch Weibe; nur Einer wei\u00df es:", "tokens": ["M\u00e4d\u00b7chen", "noch", "Wei\u00b7be", ";", "nur", "Ei\u00b7ner", "wei\u00df", "es", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "NN", "$.", "ADV", "PIS", "VVFIN", "PPER", "$."], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}, "line.3": {"text": "Das beste der Lieder; ich lehr' es etwa", "tokens": ["Das", "bes\u00b7te", "der", "Lie\u00b7der", ";", "ich", "lehr'", "es", "et\u00b7wa"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "ART", "NN", "$.", "PPER", "VVFIN", "PPER", "ADV"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "Nur meiner Schwester und die mich in ihre", "tokens": ["Nur", "mei\u00b7ner", "Schwes\u00b7ter", "und", "die", "mich", "in", "ih\u00b7re"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "PPOSAT", "NN", "KON", "PRELS", "PRF", "APPR", "PPOSAT"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Arme schlie\u00dft.", "tokens": ["Ar\u00b7me", "schlie\u00dft", "."], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVFIN", "$."], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.52": {"line.1": {"text": "Nun sind gesungen die hohen Spr\u00fcche", "tokens": ["Nun", "sind", "ge\u00b7sun\u00b7gen", "die", "ho\u00b7hen", "Spr\u00fc\u00b7che"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "VVPP", "ART", "ADJA", "NN"], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}, "line.2": {"text": "Im hohen Pallast:", "tokens": ["Im", "ho\u00b7hen", "Pal\u00b7last", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.3": {"text": "Sie sind sehr noth den Menschens\u00f6hnen,", "tokens": ["Sie", "sind", "sehr", "noth", "den", "Men\u00b7schen\u00b7s\u00f6h\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "(und sind nicht noth den Menschens\u00f6hnen.)", "tokens": ["(", "und", "sind", "nicht", "noth", "den", "Men\u00b7schen\u00b7s\u00f6h\u00b7nen", ".", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "KON", "VAFIN", "PTKNEG", "NN", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Heil der sie sang! Heil der sie kann!", "tokens": ["Heil", "der", "sie", "sang", "!", "Heil", "der", "sie", "kann", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "PPER", "VVFIN", "$.", "NN", "ART", "PPER", "VMFIN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.6": {"text": "Wohl der sie lernt! heil, der sie h\u00f6rt! \u2013", "tokens": ["Wohl", "der", "sie", "lernt", "!", "heil", ",", "der", "sie", "h\u00f6rt", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "ART", "PPER", "VVFIN", "$.", "ADJD", "$,", "PRELS", "PPER", "VVFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}