{"textgrid.poem.42948": {"metadata": {"author": {"name": "Ringelnatz, Joachim", "birth": "N.A.", "death": "N.A."}, "title": "Offener Antrag auf der Stra\u00dfe", "genre": "verse", "period": "N.A.", "pub_year": 1908, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ich habe einen Frisiersalon.", "tokens": ["Ich", "ha\u00b7be", "ei\u00b7nen", "Fri\u00b7sier\u00b7sa\u00b7lon", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Komm mit. Dort wollen wir knutschen.", "tokens": ["Komm", "mit", ".", "Dort", "wol\u00b7len", "wir", "knut\u00b7schen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "$.", "ADV", "VMFIN", "PPER", "VVFIN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Ich wollte, ich w\u00e4re ein Malzbonbon", "tokens": ["Ich", "woll\u00b7te", ",", "ich", "w\u00e4\u00b7re", "ein", "Malz\u00b7bon\u00b7bon"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "$,", "PPER", "VAFIN", "ART", "NN"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Und du, du w\u00fcrdest mich lutschen.", "tokens": ["Und", "du", ",", "du", "w\u00fcr\u00b7dest", "mich", "lut\u00b7schen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "$,", "PPER", "VAFIN", "PPER", "VVINF", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.2": {"line.1": {"text": "Wir geben dem Lehrbub den Nachmittag frei", "tokens": ["Wir", "ge\u00b7ben", "dem", "Lehr\u00b7bub", "den", "Nach\u00b7mit\u00b7tag", "frei"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "ART", "NN", "ADJD"], "meter": "-+--++-+--+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Und schreiben \u00bbGeschlossen bis sieben\u00ab.", "tokens": ["Und", "schrei\u00b7ben", "\u00bb", "Ge\u00b7schlos\u00b7sen", "bis", "sie\u00b7ben", "\u00ab", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "$(", "NN", "APPR", "CARD", "$(", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "Ich habe Rotwein im Laden und drei", "tokens": ["Ich", "ha\u00b7be", "Rot\u00b7wein", "im", "La\u00b7den", "und", "drei"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "NN", "APPRART", "NN", "KON", "CARD"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Dicke Ro\u00dfhaars\u00e4cke zum Lieben.", "tokens": ["Di\u00b7cke", "Ro\u00df\u00b7haar\u00b7s\u00e4\u00b7cke", "zum", "Lie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "APPRART", "ADJA", "$."], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}}, "stanza.3": {"line.1": {"text": "Ich werde dich unentgeltlich frisiern", "tokens": ["Ich", "wer\u00b7de", "dich", "un\u00b7ent\u00b7gelt\u00b7lich", "fri\u00b7si\u00b7ern"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PPER", "ADJD", "VVINF"], "meter": "-+--+-+-+--", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Und dir die N\u00e4gel beschneiden.", "tokens": ["Und", "dir", "die", "N\u00e4\u00b7gel", "be\u00b7schnei\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ART", "NN", "VVPP", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Du brauchst dich gar nicht vor mir geniern,", "tokens": ["Du", "brauchst", "dich", "gar", "nicht", "vor", "mir", "ge\u00b7ni\u00b7ern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "PTKNEG", "APPR", "PPER", "VVINF", "$,"], "meter": "+---++--+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Denn ich mag dicke Fraun leiden.", "tokens": ["Denn", "ich", "mag", "di\u00b7cke", "Fraun", "lei\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VMFIN", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.4": {"line.1": {"text": "Ich habe auch Schwarzbrot und Butter und Quark", "tokens": ["Ich", "ha\u00b7be", "auch", "Schwarz\u00b7brot", "und", "But\u00b7ter", "und", "Quark"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "NN", "KON", "NN", "KON", "NN"], "meter": "-+--++-+--+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Und au\u00dferdem einen gro\u00dfen \u2013 \u2013", "tokens": ["Und", "au\u00b7\u00dfer\u00b7dem", "ei\u00b7nen", "gro\u00b7\u00dfen", "\u2013", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "PAV", "ART", "ADJA", "$(", "$("], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Donnerwetter, sind deine Muskeln stark!", "tokens": ["Don\u00b7ner\u00b7wet\u00b7ter", ",", "sind", "dei\u00b7ne", "Mus\u00b7keln", "stark", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VAFIN", "PPOSAT", "NN", "ADJD", "$."], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Du, zeig mal: Was hast du f\u00fcr Hosen?", "tokens": ["Du", ",", "zeig", "mal", ":", "Was", "hast", "du", "f\u00fcr", "Ho\u00b7sen", "?"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "VVFIN", "ADV", "$.", "PWS", "VAFIN", "PPER", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Wenn du dann fortgehst, bedanke dich nicht,", "tokens": ["Wenn", "du", "dann", "fort\u00b7gehst", ",", "be\u00b7dan\u00b7ke", "dich", "nicht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VVFIN", "$,", "VVFIN", "PPER", "PTKNEG", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Sondern halt es mit meinem Freund Franke.", "tokens": ["Son\u00b7dern", "halt", "es", "mit", "mei\u00b7nem", "Freund", "Fran\u00b7ke", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "NE", "$."], "meter": "+-+--+--+-", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "Der sagt immer, wenn man vom lieben Gott spricht:", "tokens": ["Der", "sagt", "im\u00b7mer", ",", "wenn", "man", "vom", "lie\u00b7ben", "Gott", "spricht", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "$,", "KOUS", "PIS", "APPRART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-----+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "\u00bbwem's gut geht, der sagt nicht danke.\u00ab", "tokens": ["\u00bb", "wem's", "gut", "geht", ",", "der", "sagt", "nicht", "dan\u00b7ke", ".", "\u00ab"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PWS", "ADJD", "VVFIN", "$,", "PRELS", "VVFIN", "PTKNEG", "VVFIN", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Ich habe einen Frisiersalon.", "tokens": ["Ich", "ha\u00b7be", "ei\u00b7nen", "Fri\u00b7sier\u00b7sa\u00b7lon", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Komm mit. Dort wollen wir knutschen.", "tokens": ["Komm", "mit", ".", "Dort", "wol\u00b7len", "wir", "knut\u00b7schen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "$.", "ADV", "VMFIN", "PPER", "VVFIN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Ich wollte, ich w\u00e4re ein Malzbonbon", "tokens": ["Ich", "woll\u00b7te", ",", "ich", "w\u00e4\u00b7re", "ein", "Malz\u00b7bon\u00b7bon"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "$,", "PPER", "VAFIN", "ART", "NN"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Und du, du w\u00fcrdest mich lutschen.", "tokens": ["Und", "du", ",", "du", "w\u00fcr\u00b7dest", "mich", "lut\u00b7schen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "$,", "PPER", "VAFIN", "PPER", "VVINF", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.7": {"line.1": {"text": "Wir geben dem Lehrbub den Nachmittag frei", "tokens": ["Wir", "ge\u00b7ben", "dem", "Lehr\u00b7bub", "den", "Nach\u00b7mit\u00b7tag", "frei"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "ART", "NN", "ADJD"], "meter": "-+--++-+--+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Und schreiben \u00bbGeschlossen bis sieben\u00ab.", "tokens": ["Und", "schrei\u00b7ben", "\u00bb", "Ge\u00b7schlos\u00b7sen", "bis", "sie\u00b7ben", "\u00ab", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "$(", "NN", "APPR", "CARD", "$(", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "Ich habe Rotwein im Laden und drei", "tokens": ["Ich", "ha\u00b7be", "Rot\u00b7wein", "im", "La\u00b7den", "und", "drei"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "NN", "APPRART", "NN", "KON", "CARD"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Dicke Ro\u00dfhaars\u00e4cke zum Lieben.", "tokens": ["Di\u00b7cke", "Ro\u00df\u00b7haar\u00b7s\u00e4\u00b7cke", "zum", "Lie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "APPRART", "ADJA", "$."], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}}, "stanza.8": {"line.1": {"text": "Ich werde dich unentgeltlich frisiern", "tokens": ["Ich", "wer\u00b7de", "dich", "un\u00b7ent\u00b7gelt\u00b7lich", "fri\u00b7si\u00b7ern"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PPER", "ADJD", "VVINF"], "meter": "-+--+-+-+--", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Und dir die N\u00e4gel beschneiden.", "tokens": ["Und", "dir", "die", "N\u00e4\u00b7gel", "be\u00b7schnei\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ART", "NN", "VVPP", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Du brauchst dich gar nicht vor mir geniern,", "tokens": ["Du", "brauchst", "dich", "gar", "nicht", "vor", "mir", "ge\u00b7ni\u00b7ern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "PTKNEG", "APPR", "PPER", "VVINF", "$,"], "meter": "+---++--+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Denn ich mag dicke Fraun leiden.", "tokens": ["Denn", "ich", "mag", "di\u00b7cke", "Fraun", "lei\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VMFIN", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.9": {"line.1": {"text": "Ich habe auch Schwarzbrot und Butter und Quark", "tokens": ["Ich", "ha\u00b7be", "auch", "Schwarz\u00b7brot", "und", "But\u00b7ter", "und", "Quark"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "NN", "KON", "NN", "KON", "NN"], "meter": "-+--++-+--+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Und au\u00dferdem einen gro\u00dfen \u2013 \u2013", "tokens": ["Und", "au\u00b7\u00dfer\u00b7dem", "ei\u00b7nen", "gro\u00b7\u00dfen", "\u2013", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "PAV", "ART", "ADJA", "$(", "$("], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Donnerwetter, sind deine Muskeln stark!", "tokens": ["Don\u00b7ner\u00b7wet\u00b7ter", ",", "sind", "dei\u00b7ne", "Mus\u00b7keln", "stark", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VAFIN", "PPOSAT", "NN", "ADJD", "$."], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Du, zeig mal: Was hast du f\u00fcr Hosen?", "tokens": ["Du", ",", "zeig", "mal", ":", "Was", "hast", "du", "f\u00fcr", "Ho\u00b7sen", "?"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "VVFIN", "ADV", "$.", "PWS", "VAFIN", "PPER", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Wenn du dann fortgehst, bedanke dich nicht,", "tokens": ["Wenn", "du", "dann", "fort\u00b7gehst", ",", "be\u00b7dan\u00b7ke", "dich", "nicht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VVFIN", "$,", "VVFIN", "PPER", "PTKNEG", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Sondern halt es mit meinem Freund Franke.", "tokens": ["Son\u00b7dern", "halt", "es", "mit", "mei\u00b7nem", "Freund", "Fran\u00b7ke", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "NE", "$."], "meter": "+-+--+--+-", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "Der sagt immer, wenn man vom lieben Gott spricht:", "tokens": ["Der", "sagt", "im\u00b7mer", ",", "wenn", "man", "vom", "lie\u00b7ben", "Gott", "spricht", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "$,", "KOUS", "PIS", "APPRART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-----+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "\u00bbwem's gut geht, der sagt nicht danke.\u00ab", "tokens": ["\u00bb", "wem's", "gut", "geht", ",", "der", "sagt", "nicht", "dan\u00b7ke", ".", "\u00ab"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PWS", "ADJD", "VVFIN", "$,", "PRELS", "VVFIN", "PTKNEG", "VVFIN", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}}}}