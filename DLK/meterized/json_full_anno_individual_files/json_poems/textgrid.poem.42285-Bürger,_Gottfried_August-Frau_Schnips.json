{"textgrid.poem.42285": {"metadata": {"author": {"name": "B\u00fcrger, Gottfried August", "birth": "N.A.", "death": "N.A."}, "title": "Frau Schnips", "genre": "verse", "period": "N.A.", "pub_year": 1777, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Frau Schnipsen hatte Korn im Stroh,", "tokens": ["Frau", "Schnip\u00b7sen", "hat\u00b7te", "Korn", "im", "Stroh", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "VAFIN", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und hielt sich weidlich lecker;", "tokens": ["Und", "hielt", "sich", "weid\u00b7lich", "le\u00b7cker", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "ADV", "ADJD", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Sie lebt' in dulci Jubilo,", "tokens": ["Sie", "lebt'", "in", "dul\u00b7ci", "Ju\u00b7bi\u00b7lo", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NE", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und Keine war euch kecker.", "tokens": ["Und", "Kei\u00b7ne", "war", "euch", "ke\u00b7cker", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VAFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Das M\u00e4ulchen, sammt dem Z\u00fcnglein flink,", "tokens": ["Das", "M\u00e4ul\u00b7chen", ",", "sammt", "dem", "Z\u00fcn\u00b7glein", "flink", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "APPR", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sa\u00df ihr am rechten Flecken.", "tokens": ["Sa\u00df", "ihr", "am", "rech\u00b7ten", "Fle\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Sie schimpfte wie ein Rohrsperling,", "tokens": ["Sie", "schimpf\u00b7te", "wie", "ein", "Rohr\u00b7sper\u00b7ling", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KOKOM", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wenn man sie wollte necken.", "tokens": ["Wenn", "man", "sie", "woll\u00b7te", "ne\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPER", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Da kam Hans Mors, und zog den Strich", "tokens": ["Da", "kam", "Hans", "Mors", ",", "und", "zog", "den", "Strich"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "NE", "NE", "$,", "KON", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Durch ihr Schlaraffenleben.", "tokens": ["Durch", "ihr", "Schla\u00b7raf\u00b7fen\u00b7le\u00b7ben", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.3": {"text": "Zwar belferte sie j\u00e4mmerlich;", "tokens": ["Zwar", "bel\u00b7fer\u00b7te", "sie", "j\u00e4m\u00b7mer\u00b7lich", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Doch mu\u00dfte sie sich geben.", "tokens": ["Doch", "mu\u00df\u00b7te", "sie", "sich", "ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "PRF", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Sie klaffte fort, den Weg hinan,", "tokens": ["Sie", "klaff\u00b7te", "fort", ",", "den", "Weg", "hi\u00b7nan", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKVZ", "$,", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Bis vor die Himmelspforte,", "tokens": ["Bis", "vor", "die", "Him\u00b7mel\u00b7spfor\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Gekr\u00e4nkt, da\u00df sie nicht Zeit gewann,", "tokens": ["Ge\u00b7kr\u00e4nkt", ",", "da\u00df", "sie", "nicht", "Zeit", "ge\u00b7wann", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "KOUS", "PPER", "PTKNEG", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Zur letzten Mandeltorte.", "tokens": ["Zur", "letz\u00b7ten", "Man\u00b7del\u00b7tor\u00b7te", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Weil nun der letzte \u00c4rger ihr", "tokens": ["Weil", "nun", "der", "letz\u00b7te", "\u00c4r\u00b7ger", "ihr"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "ART", "ADJA", "NN", "PPOSAT"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Noch spukt' im Tabernakel,", "tokens": ["Noch", "spukt'", "im", "Ta\u00b7ber\u00b7na\u00b7kel", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "So trieb sie vor der Himmelsth\u00fcr", "tokens": ["So", "trieb", "sie", "vor", "der", "Him\u00b7mel\u00b7sth\u00fcr"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Viel Unfug und Spektakel.", "tokens": ["Viel", "Un\u00b7fug", "und", "Spek\u00b7ta\u00b7kel", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "KON", "NN", "$."], "meter": "-+--++-", "measure": "iambic.tri.relaxed"}}, "stanza.6": {"line.1": {"text": "\u00bbwer da, rief Adam unmutsvoll,", "tokens": ["\u00bb", "wer", "da", ",", "rief", "A\u00b7dam", "un\u00b7muts\u00b7voll", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "ADV", "$,", "VVFIN", "NE", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "St\u00f6rt so die Ruh der Frommen?\u00ab \u2013", "tokens": ["St\u00f6rt", "so", "die", "Ruh", "der", "From\u00b7men", "?", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "ART", "NN", "$.", "$(", "$("], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.3": {"text": "\u00bbich bins! Frau Schnips! Ich w\u00fcnschte wohl", "tokens": ["\u00bb", "ich", "bins", "!", "Frau", "Schnips", "!", "Ich", "w\u00fcnschte", "wohl"], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["$(", "PPER", "VAFIN", "$.", "NN", "NE", "$.", "PPER", "VVFIN", "ADV"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.4": {"text": "Bei Euch mit anzukommen.\u00ab \u2013", "tokens": ["Bei", "Euch", "mit", "an\u00b7zu\u00b7kom\u00b7men", ".", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["APPR", "PPER", "APPR", "VVIZU", "$.", "$(", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "\u00bbdu? \u2013 Nicht also, Frau S\u00fcnderin!", "tokens": ["\u00bb", "du", "?", "\u2013", "Nicht", "al\u00b7so", ",", "Frau", "S\u00fcn\u00b7de\u00b7rin", "!"], "token_info": ["punct", "word", "punct", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "PPER", "$.", "$(", "PTKNEG", "ADV", "$,", "NN", "NN", "$."], "meter": "+-+-++-+", "measure": "unknown.measure.penta"}, "line.2": {"text": "Frau Liederlich! Frau Lecker!\u00ab \u2013", "tokens": ["Frau", "Lie\u00b7der\u00b7lich", "!", "Frau", "Le\u00b7cker", "!", "\u00ab", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "punct", "punct", "punct"], "pos": ["NN", "ADJD", "$.", "NN", "NE", "$.", "$(", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "\u00bbich wei\u00df wohl selber, was ich bin,", "tokens": ["\u00bb", "ich", "wei\u00df", "wohl", "sel\u00b7ber", ",", "was", "ich", "bin", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "ADV", "ADV", "$,", "PWS", "PPER", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Du alter S\u00fcndenhecker!", "tokens": ["Du", "al\u00b7ter", "S\u00fcn\u00b7den\u00b7he\u00b7cker", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Ei, zupfte sich Herr Erdenklo\u00df", "tokens": ["Ei", ",", "zupf\u00b7te", "sich", "Herr", "Er\u00b7den\u00b7klo\u00df"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$,", "VVFIN", "PRF", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Doch nur an eigner Nase!", "tokens": ["Doch", "nur", "an", "eig\u00b7ner", "Na\u00b7se", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Denn was man ist, das ist man blo\u00df", "tokens": ["Denn", "was", "man", "ist", ",", "das", "ist", "man", "blo\u00df"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "PWS", "PIS", "VAFIN", "$,", "PDS", "VAFIN", "PIS", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Von seinem Apfelfra\u00dfe.", "tokens": ["Von", "sei\u00b7nem", "Ap\u00b7fel\u00b7fra\u00b7\u00dfe", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "So gut wie Er, denk' ich zur Ruh", "tokens": ["So", "gut", "wie", "Er", ",", "denk'", "ich", "zur", "Ruh"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "KOKOM", "PPER", "$,", "VVFIN", "PPER", "APPRART", "NN"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.2": {"text": "Noch Platz hier zu gewinnen.\u00ab \u2013", "tokens": ["Noch", "Platz", "hier", "zu", "ge\u00b7win\u00b7nen", ".", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["ADV", "NN", "ADV", "PTKZU", "VVINF", "$.", "$(", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Der Vater hielt die Ohren zu", "tokens": ["Der", "Va\u00b7ter", "hielt", "die", "Oh\u00b7ren", "zu"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "PTKZU"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und trollte sich von hinnen.", "tokens": ["Und", "troll\u00b7te", "sich", "von", "hin\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "APPR", "ADV", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "D'rauf machte Jakob sich ans Thor:", "tokens": ["D'\u00b7rauf", "mach\u00b7te", "Ja\u00b7kob", "sich", "ans", "Thor", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "NE", "PRF", "APPRART", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "\u00bbmarsch! Packe dich zum Teufel!\u00ab \u2013", "tokens": ["\u00bb", "marsch", "!", "Pa\u00b7cke", "dich", "zum", "Teu\u00b7fel", "!", "\u00ab", "\u2013"], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["$(", "ADJD", "$.", "VVFIN", "PPER", "APPRART", "NN", "$.", "$(", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "\u00bbwas? schrie Frau Schnips ihm laut ins Ohr,", "tokens": ["\u00bb", "was", "?", "schrie", "Frau", "Schnips", "ihm", "laut", "ins", "Ohr", ","], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "$.", "VVFIN", "NN", "NE", "PPER", "ADJD", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Fickfacker! Ich zum Teufel?", "tokens": ["Fick\u00b7fa\u00b7cker", "!", "Ich", "zum", "Teu\u00b7fel", "?"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$.", "PPER", "APPRART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "Du bist mir wohl der rechte Held,", "tokens": ["Du", "bist", "mir", "wohl", "der", "rech\u00b7te", "Held", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und bist wohl hier f\u00fcr's Prellen?", "tokens": ["Und", "bist", "wohl", "hier", "f\u00fcr's", "Prel\u00b7len", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Hast Bruder und Papa geprellt,", "tokens": ["Hast", "Bru\u00b7der", "und", "Pa\u00b7pa", "ge\u00b7prellt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "KON", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mit deinen Ziegenfellen.\u00ab \u2013", "tokens": ["Mit", "dei\u00b7nen", "Zie\u00b7gen\u00b7fel\u00b7len", ".", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "punct", "punct", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$.", "$(", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "Stockm\u00e4uschenstill trieb ihr Geschrei", "tokens": ["Stock\u00b7m\u00e4u\u00b7schen\u00b7still", "trieb", "ihr", "Ge\u00b7schrei"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Hinweg den Patriarchen.", "tokens": ["Hin\u00b7weg", "den", "Pat\u00b7ri\u00b7ar\u00b7chen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Hierauf sprang Ehren-Loth herbei,", "tokens": ["Hier\u00b7auf", "sprang", "Eh\u00b7ren\u00b7Loth", "her\u00b7bei", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mit Brausen und mit Schnarchen.", "tokens": ["Mit", "Brau\u00b7sen", "und", "mit", "Schnar\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "APPR", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.13": {"line.1": {"text": "\u00bbdu auch, du alter Saufaus hast,", "tokens": ["\u00bb", "du", "auch", ",", "du", "al\u00b7ter", "Sauf\u00b7aus", "hast", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "ADV", "$,", "PPER", "ADJA", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Gro\u00df Recht hier zum Geprahle!", "tokens": ["Gro\u00df", "Recht", "hier", "zum", "Ge\u00b7prah\u00b7le", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "NN", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Bist wahrlich nicht der feinste Gast", "tokens": ["Bist", "wahr\u00b7lich", "nicht", "der", "feins\u00b7te", "Gast"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "PTKNEG", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "In diesem Himmelssaale!", "tokens": ["In", "die\u00b7sem", "Him\u00b7mels\u00b7saa\u00b7le", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.14": {"line.1": {"text": "Bezecht sich erst beim Abendbrot,", "tokens": ["Be\u00b7zecht", "sich", "erst", "beim", "A\u00b7bend\u00b7brot", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ADV", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Den Kindern zum Gel\u00e4chter,", "tokens": ["Den", "Kin\u00b7dern", "zum", "Ge\u00b7l\u00e4ch\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und dann beschl\u00e4ft Er \u2013 pfui, Herr Loth! \u2013", "tokens": ["Und", "dann", "be\u00b7schl\u00e4ft", "Er", "\u2013", "pfui", ",", "Herr", "Loth", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "$(", "ITJ", "$,", "NN", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Gar seine eignen T\u00f6chter!\u00ab", "tokens": ["Gar", "sei\u00b7ne", "eig\u00b7nen", "T\u00f6ch\u00b7ter", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "PPOSAT", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.15": {"line.1": {"text": "Ha puh! Wie stank der alte Mist! \u2013", "tokens": ["Ha", "puh", "!", "Wie", "stank", "der", "al\u00b7te", "Mist", "!", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ITJ", "ITJ", "$.", "PWAV", "VVFIN", "ART", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Loth mu\u00dfte sich bequemen,", "tokens": ["Loth", "mu\u00df\u00b7te", "sich", "be\u00b7que\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "PRF", "ADJA", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Als h\u00e4tt' er in das Bett' gepi\u00dft,", "tokens": ["Als", "h\u00e4tt'", "er", "in", "das", "Bett'", "ge\u00b7pi\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VAFIN", "PPER", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Voll Scham Rei\u00dfaus zu nehmen.", "tokens": ["Voll", "Scham", "Rei\u00df\u00b7aus", "zu", "neh\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "NN", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.16": {"line.1": {"text": "\u00bbna! \u2013 lief Relikte Judith hin,", "tokens": ["\u00bb", "na", "!", "\u2013", "lief", "Re\u00b7lik\u00b7te", "Ju\u00b7dith", "hin", ","], "token_info": ["punct", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ITJ", "$.", "$(", "VVFIN", "NN", "NE", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Welch L\u00e4rm hier und Gebrause!\u00ab \u2013", "tokens": ["Welch", "L\u00e4rm", "hier", "und", "Ge\u00b7brau\u00b7se", "!", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PIAT", "NN", "ADV", "KON", "NN", "$.", "$(", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "\u00bbbonsdies! Frau Gurgelschneiderin!", "tokens": ["\u00bb", "bons\u00b7dies", "!", "Frau", "Gur\u00b7gel\u00b7schnei\u00b7de\u00b7rin", "!"], "token_info": ["punct", "word", "punct", "word", "word", "punct"], "pos": ["$(", "VVFIN", "$.", "NN", "NE", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Sie ist hier auch zu Hause?\u00ab \u2013", "tokens": ["Sie", "ist", "hier", "auch", "zu", "Hau\u00b7se", "?", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "APPR", "NN", "$.", "$(", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.17": {"line.1": {"text": "Vor gro\u00dfer Scham bald bleich bald rot,", "tokens": ["Vor", "gro\u00b7\u00dfer", "Scham", "bald", "bleich", "bald", "rot", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ADV", "ADJD", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Stand Judith bei dem Gru\u00dfe.", "tokens": ["Stand", "Ju\u00b7dith", "bei", "dem", "Gru\u00b7\u00dfe", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Der K\u00f6nig David sah die Not,", "tokens": ["Der", "K\u00f6\u00b7nig", "Da\u00b7vid", "sah", "die", "Not", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NE", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und folgt' ihr auf dem Fu\u00dfe.", "tokens": ["Und", "folgt'", "ihr", "auf", "dem", "Fu\u00b7\u00dfe", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.18": {"line.1": {"text": "\u00bbwas f\u00fcr Hallo, du Teufelsweib?", "tokens": ["\u00bb", "was", "f\u00fcr", "Hal\u00b7lo", ",", "du", "Teu\u00b7fels\u00b7weib", "?"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "PWS", "APPR", "NE", "$,", "PPER", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Potz hunderttausend Velten!\u00ab \u2013", "tokens": ["Potz", "hun\u00b7dert\u00b7tau\u00b7send", "Vel\u00b7ten", "!", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "punct", "punct", "punct"], "pos": ["NN", "CARD", "NN", "$.", "$(", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "\u00bbei, Herr, w\u00e4r' ich Uria's Weib,", "tokens": ["\u00bb", "ei", ",", "Herr", ",", "w\u00e4r'", "ich", "U\u00b7ria's", "Weib", ","], "token_info": ["punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ITJ", "$,", "NN", "$,", "VAFIN", "PPER", "NE", "NE", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Ihr w\u00fcrdet so nicht schelten.", "tokens": ["Ihr", "w\u00fcr\u00b7det", "so", "nicht", "schel\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.19": {"line.1": {"text": "Es war, mein Seel! wohl mehr Hallo,", "tokens": ["Es", "war", ",", "mein", "Seel", "!", "wohl", "mehr", "Hal\u00b7lo", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "PPOSAT", "NN", "$.", "ADV", "ADV", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mit Bathseba zu liebeln,", "tokens": ["Mit", "Bath\u00b7se\u00b7ba", "zu", "lie\u00b7beln", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und ihren armen Hahnrei so", "tokens": ["Und", "ih\u00b7ren", "ar\u00b7men", "Hahn\u00b7rei", "so"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Zur Welt hinaus zu b\u00fcbeln.\u00ab \u2013", "tokens": ["Zur", "Welt", "hin\u00b7aus", "zu", "b\u00fc\u00b7beln", ".", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["APPRART", "NN", "APZR", "PTKZU", "VVINF", "$.", "$(", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.20": {"line.1": {"text": "\u00bbdas Weib ist toll, rief Salomo,", "tokens": ["\u00bb", "das", "Weib", "ist", "toll", ",", "rief", "Sa\u00b7lo\u00b7mo", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "VAFIN", "ADJD", "$,", "VVFIN", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Hat zu viel Schnaps genommen!", "tokens": ["Hat", "zu", "viel", "Schnaps", "ge\u00b7nom\u00b7men", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "PIAT", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Was? Seiner Majest\u00e4t also \u2013 \u2013 \u2013", "tokens": ["Was", "?", "Sei\u00b7ner", "Ma\u00b7jes\u00b7t\u00e4t", "al\u00b7so", "\u2013", "\u2013", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PWS", "$.", "PPOSAT", "NN", "ADV", "$(", "$(", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So \u2013 \u2013 hundsf\u00f6ttsch anzukommen?\u00ab \u2013", "tokens": ["So", "\u2013", "\u2013", "hunds\u00b7f\u00f6ttsch", "an\u00b7zu\u00b7kom\u00b7men", "?", "\u00ab", "\u2013"], "token_info": ["word", "punct", "punct", "word", "word", "punct", "punct", "punct"], "pos": ["ADV", "$(", "$(", "ADJD", "VVIZU", "$.", "$(", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.21": {"line.1": {"text": "\u00bbo Herr, nicht halb so toll, als Er!", "tokens": ["\u00bb", "o", "Herr", ",", "nicht", "halb", "so", "toll", ",", "als", "Er", "!"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "FM", "NN", "$,", "PTKNEG", "ADJD", "ADV", "ADJD", "$,", "KOUS", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "H\u00e4tt' er sein Maul gehalten!", "tokens": ["H\u00e4tt'", "er", "sein", "Maul", "ge\u00b7hal\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Wir wissen's noch recht gut, wie Er", "tokens": ["Wir", "wis\u00b7sen's", "noch", "recht", "gut", ",", "wie", "Er"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "ADJD", "$,", "PWAV", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Auf Erden Haus gehalten.", "tokens": ["Auf", "Er\u00b7den", "Haus", "ge\u00b7hal\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.22": {"line.1": {"text": "Sieb'n hundert Weiber auf der Streu,", "tokens": ["Sie\u00b7b'n", "hun\u00b7dert", "Wei\u00b7ber", "auf", "der", "Streu", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["XY", "CARD", "NN", "APPR", "ART", "NN", "$,"], "meter": "+++-+-+-+", "measure": "unknown.measure.hexa"}, "line.2": {"text": "Und extra doch darneben", "tokens": ["Und", "ex\u00b7tra", "doch", "dar\u00b7ne\u00b7ben"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ADV", "ADV", "PAV"], "meter": "-+--+--", "measure": "iambic.di.relaxed"}, "line.3": {"text": "Drei hundert \u2013 \u2013 Andre! Meiner Treu!", "tokens": ["Drei", "hun\u00b7dert", "\u2013", "\u2013", "And\u00b7re", "!", "Mei\u00b7ner", "Treu", "!"], "token_info": ["word", "word", "punct", "punct", "word", "punct", "word", "word", "punct"], "pos": ["CARD", "CARD", "$(", "$(", "PIS", "$.", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Das war ein z\u00fcchtig Leben!", "tokens": ["Das", "war", "ein", "z\u00fcch\u00b7tig", "Le\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "ADJD", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.23": {"line.1": {"text": "Und Sein Verstand war klimperklein,", "tokens": ["Und", "Sein", "Ver\u00b7stand", "war", "klim\u00b7per\u00b7klein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Als Er von Gott sich wandte,", "tokens": ["Als", "Er", "von", "Gott", "sich", "wand\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NN", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und G\u00f6tzen pur von Holz und Stein,", "tokens": ["Und", "G\u00f6t\u00b7zen", "pur", "von", "Holz", "und", "Stein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ADJD", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sein th\u00f6richt Opfer brannte.\u00ab \u2013", "tokens": ["Sein", "th\u00f6\u00b7richt", "Op\u00b7fer", "brann\u00b7te", ".", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PPOSAT", "NN", "NN", "VVFIN", "$.", "$(", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.24": {"line.1": {"text": "\u00bbf\u00fcrwahr, emp\u00f6rte Jonas sich,", "tokens": ["\u00bb", "f\u00fcr\u00b7wahr", ",", "em\u00b7p\u00f6r\u00b7te", "Jo\u00b7nas", "sich", ","], "token_info": ["punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "$,", "VVFIN", "NE", "PRF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das Weib speit, wie ein Drache!\u00ab \u2013", "tokens": ["Das", "Weib", "speit", ",", "wie", "ein", "Dra\u00b7che", "!", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "punct", "punct"], "pos": ["ART", "NN", "ADJD", "$,", "PWAV", "ART", "NN", "$.", "$(", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "\u00bbhalt's Maul, Ausrei\u00dfer! K\u00fcmmre dich", "tokens": ["\u00bb", "halt's", "Maul", ",", "Aus\u00b7rei\u00b7\u00dfer", "!", "K\u00fcmm\u00b7re", "dich"], "token_info": ["punct", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["$(", "ADJA", "NN", "$,", "NN", "$.", "NN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Um Deine faule Sache!\u00ab \u2013", "tokens": ["Um", "Dei\u00b7ne", "fau\u00b7le", "Sa\u00b7che", "!", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["KOUI", "PPOSAT", "ADJA", "NN", "$.", "$(", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.25": {"line.1": {"text": "Auch Thom's gab seinen Senf dazu:", "tokens": ["Auch", "Thom's", "gab", "sei\u00b7nen", "Senf", "da\u00b7zu", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NE", "VVFIN", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u00bbein Sprichwort, das ich glaube,", "tokens": ["\u00bb", "ein", "Sprich\u00b7wort", ",", "das", "ich", "glau\u00b7be", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Sagt: Weiberzung' hat nimmer Ruh;", "tokens": ["Sagt", ":", "Wei\u00b7ber\u00b7zung'", "hat", "nim\u00b7mer", "Ruh", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$.", "NE", "VAFIN", "ADV", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sie ist von Espenlaube.\u00ab \u2013", "tokens": ["Sie", "ist", "von", "E\u00b7spen\u00b7lau\u00b7be", ".", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PPER", "VAFIN", "APPR", "NN", "$.", "$(", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.26": {"line.1": {"text": "\u00bbglaub' immer was ein Narr erdacht,", "tokens": ["\u00bb", "glaub'", "im\u00b7mer", "was", "ein", "Narr", "er\u00b7dacht", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "ADV", "PWS", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mit allen dummen Teufeln!", "tokens": ["Mit", "al\u00b7len", "dum\u00b7men", "Teu\u00b7feln", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Doch konnt' an seines Heilands Macht", "tokens": ["Doch", "konnt'", "an", "sei\u00b7nes", "Hei\u00b7lands", "Macht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VMFIN", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der schwache Pinsel zweifeln.\u00ab \u2013", "tokens": ["Der", "schwa\u00b7che", "Pin\u00b7sel", "zwei\u00b7feln", ".", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "$.", "$(", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.27": {"line.1": {"text": "Maria Magdalena kam. \u2013", "tokens": ["Ma\u00b7ria", "Mag\u00b7da\u00b7le\u00b7na", "kam", ".", "\u2013"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["NE", "NE", "VVFIN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Nu ja! Die wird's erst kriegen! \u2013", "tokens": ["Nu", "ja", "!", "Die", "wird's", "erst", "krie\u00b7gen", "!", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "ADV", "$.", "PDS", "VAFIN", "ADV", "VVINF", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "\u00bbstill, gute Frau, fein still und zahm!", "tokens": ["\u00bb", "still", ",", "gu\u00b7te", "Frau", ",", "fein", "still", "und", "zahm", "!"], "token_info": ["punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PTKVZ", "$,", "ADJA", "NN", "$,", "ADJD", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ihr m\u00fc\u00dft Euch anders f\u00fcgen.", "tokens": ["Ihr", "m\u00fc\u00dft", "Euch", "an\u00b7ders", "f\u00fc\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.28": {"line.1": {"text": "Denn, gute Frau, erinnert Euch", "tokens": ["Denn", ",", "gu\u00b7te", "Frau", ",", "e\u00b7rin\u00b7nert", "Euch"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word"], "pos": ["KON", "$,", "ADJA", "NN", "$,", "VVFIN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "An Eu'r verruchtes Leben!", "tokens": ["An", "Eu'r", "ver\u00b7ruch\u00b7tes", "Le\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "So ", "tokens": ["So"], "token_info": ["word"], "pos": ["ADV"], "meter": "-", "measure": "single.down"}, "line.4": {"text": "Kein Pl\u00e4tzchen eingegeben.\u00ab \u2013", "tokens": ["Kein", "Pl\u00e4tz\u00b7chen", "ein\u00b7ge\u00b7ge\u00b7ben", ".", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "punct", "punct", "punct"], "pos": ["PIAT", "NN", "VVPP", "$.", "$(", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.29": {"line.1": {"text": "\u00bbso ", "tokens": ["\u00bb", "so"], "token_info": ["punct", "word"], "pos": ["$(", "ADV"], "meter": "-", "measure": "single.down"}, "line.2": {"text": "Was bin ich denn f\u00fcr ", "tokens": ["Was", "bin", "ich", "denn", "f\u00fcr"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "VAFIN", "PPER", "ADV", "APPR"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "Sie war mir auch das rechte Kraut!", "tokens": ["Sie", "war", "mir", "auch", "das", "rech\u00b7te", "Kraut", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Nun brennt Sie gar sich reine?", "tokens": ["Nun", "brennt", "Sie", "gar", "sich", "rei\u00b7ne", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "PRF", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.30": {"line.1": {"text": "Ach! Um die Tugend Ihrer Zeit", "tokens": ["Ach", "!", "Um", "die", "Tu\u00b7gend", "Ih\u00b7rer", "Zeit"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["ITJ", "$.", "KOUI", "ART", "NN", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ist Sie nicht hergekommen.", "tokens": ["Ist", "Sie", "nicht", "her\u00b7ge\u00b7kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Des Heilands Allbarmherzigkeit", "tokens": ["Des", "Hei\u00b7lands", "All\u00b7barm\u00b7her\u00b7zig\u00b7keit"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Hat Sie hier aufgenommen.", "tokens": ["Hat", "Sie", "hier", "auf\u00b7ge\u00b7nom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.31": {"line.1": {"text": "Durch diese Allbarmherzigkeit,", "tokens": ["Durch", "die\u00b7se", "All\u00b7barm\u00b7her\u00b7zig\u00b7keit", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sie wird's nicht \u00fcbel deuten,", "tokens": ["Sie", "wird's", "nicht", "\u00fc\u00b7bel", "deu\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKNEG", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Hoff' ich, trotz meiner S\u00fcndlichkeit,", "tokens": ["Hoff'", "ich", ",", "trotz", "mei\u00b7ner", "S\u00fcnd\u00b7lich\u00b7keit", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Auch noch hineinzuschreiten.\u00ab \u2013", "tokens": ["Auch", "noch", "hin\u00b7ein\u00b7zu\u00b7schrei\u00b7ten", ".", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "punct", "punct", "punct"], "pos": ["ADV", "ADV", "VVINF", "$.", "$(", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.32": {"line.1": {"text": "Jetzt sprang Apostel Paul empor:", "tokens": ["Jetzt", "sprang", "A\u00b7pos\u00b7tel", "Paul", "em\u00b7por", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NE", "NE", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u00bbmit deinen alten S\u00fcnden,", "tokens": ["\u00bb", "mit", "dei\u00b7nen", "al\u00b7ten", "S\u00fcn\u00b7den", ","], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Weib, wirst du durch das Himmelsthor", "tokens": ["Weib", ",", "wirst", "du", "durch", "das", "Him\u00b7mel\u00b7sthor"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "VAFIN", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Den Eingang nimmer finden!\u00ab \u2013", "tokens": ["Den", "Ein\u00b7gang", "nim\u00b7mer", "fin\u00b7den", "!", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["ART", "NN", "ADV", "VVINF", "$.", "$(", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.33": {"line.1": {"text": "\u00bbdie lass' ich drau\u00dfen! \u2013 Denke, Paul,", "tokens": ["\u00bb", "die", "lass'", "ich", "drau\u00b7\u00dfen", "!", "\u2013", "Den\u00b7ke", ",", "Paul", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct", "word", "punct", "word", "punct"], "pos": ["$(", "ART", "VVFIN", "PPER", "ADV", "$.", "$(", "VVIMP", "$,", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wie dir's vor Zeiten gl\u00fcckte;", "tokens": ["Wie", "dir's", "vor", "Zei\u00b7ten", "gl\u00fcck\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Dir, der doch so mit Mord, als Saul,", "tokens": ["Dir", ",", "der", "doch", "so", "mit", "Mord", ",", "als", "Saul", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "$,", "PRELS", "ADV", "ADV", "APPR", "NN", "$,", "KOUS", "NE", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.4": {"text": "Die Kirche Gottes dr\u00fcckte!\u00ab \u2013", "tokens": ["Die", "Kir\u00b7che", "Got\u00b7tes", "dr\u00fcck\u00b7te", "!", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "$.", "$(", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.34": {"line.1": {"text": "Sanct Peter kam nun auch zum Spiel:", "tokens": ["Sanct", "Pe\u00b7ter", "kam", "nun", "auch", "zum", "Spiel", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "VVFIN", "ADV", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u00bbdie Th\u00fcr nicht eingeschlagen!", "tokens": ["\u00bb", "die", "Th\u00fcr", "nicht", "ein\u00b7ge\u00b7schla\u00b7gen", "!"], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Madam, Sie l\u00e4rmt auch allzuviel;", "tokens": ["Ma\u00b7dam", ",", "Sie", "l\u00e4rmt", "auch", "all\u00b7zu\u00b7viel", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PPER", "VVFIN", "ADV", "PIS", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wer kann das hier vertragen?\u00ab \u2013", "tokens": ["Wer", "kann", "das", "hier", "ver\u00b7tra\u00b7gen", "?", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PWS", "VMFIN", "PDS", "ADV", "VVFIN", "$.", "$(", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.35": {"line.1": {"text": "\u00bbgeduld, Herr Pf\u00f6rtner! sagte sie;", "tokens": ["\u00bb", "ge\u00b7duld", ",", "Herr", "Pf\u00f6rt\u00b7ner", "!", "sag\u00b7te", "sie", ";"], "token_info": ["punct", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "ADJD", "$,", "NN", "NE", "$.", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Noch bin ich unverloren!", "tokens": ["Noch", "bin", "ich", "un\u00b7ver\u00b7lo\u00b7ren", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Hab' ich doch meinen Heiland nie,", "tokens": ["Hab'", "ich", "doch", "mei\u00b7nen", "Hei\u00b7land", "nie", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "PPOSAT", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wie Du einst, abgeschworen.\u00ab \u2013 \u2013", "tokens": ["Wie", "Du", "einst", ",", "ab\u00b7ge\u00b7schwo\u00b7ren", ".", "\u00ab", "\u2013", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "punct", "punct", "punct", "punct"], "pos": ["PWAV", "PPER", "ADV", "$,", "VVPP", "$.", "$(", "$(", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.36": {"line.1": {"text": "Und unser lieber Herr vernahm", "tokens": ["Und", "un\u00b7ser", "lie\u00b7ber", "Herr", "ver\u00b7nahm"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Seele letzte Worte.", "tokens": ["Der", "See\u00b7le", "letz\u00b7te", "Wor\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Umringt von tausend Engeln kam", "tokens": ["Um\u00b7ringt", "von", "tau\u00b7send", "En\u00b7geln", "kam"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "CARD", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Er herrlich an die Pforte.", "tokens": ["Er", "herr\u00b7lich", "an", "die", "Pfor\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.37": {"line.1": {"text": "\u00bberbarmen! Ach, Erbarmen!\u00ab schrie", "tokens": ["\u00bb", "er\u00b7bar\u00b7men", "!", "Ach", ",", "Er\u00b7bar\u00b7men", "!", "\u00ab", "schrie"], "token_info": ["punct", "word", "punct", "word", "punct", "word", "punct", "punct", "word"], "pos": ["$(", "VVINF", "$.", "ITJ", "$,", "NN", "$.", "$(", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die arme bange Seele. \u2013", "tokens": ["Die", "ar\u00b7me", "ban\u00b7ge", "See\u00b7le", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "\u00bbo Seele, du gehorchtest nie", "tokens": ["\u00bb", "o", "See\u00b7le", ",", "du", "ge\u00b7horch\u00b7test", "nie"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word"], "pos": ["$(", "FM", "NN", "$,", "PPER", "VVFIN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Dem g\u00f6ttlichen Befehle.", "tokens": ["Dem", "g\u00f6tt\u00b7li\u00b7chen", "Be\u00b7feh\u00b7le", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.38": {"line.1": {"text": "Ich lockte dich an meine Brust:", "tokens": ["Ich", "lock\u00b7te", "dich", "an", "mei\u00b7ne", "Brust", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Zur S\u00fcnde gingst du \u00fcber.", "tokens": ["Zur", "S\u00fcn\u00b7de", "gingst", "du", "\u00fc\u00b7ber", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PPER", "APPR", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Die Welt mit ihrer eiteln Lust", "tokens": ["Die", "Welt", "mit", "ih\u00b7rer", "ei\u00b7teln", "Lust"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "War, Th\u00f6rin, dir viel lieber.\u00ab \u2013", "tokens": ["War", ",", "Th\u00f6\u00b7rin", ",", "dir", "viel", "lie\u00b7ber", ".", "\u00ab", "\u2013"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct", "punct", "punct"], "pos": ["VAFIN", "$,", "NN", "$,", "PPER", "ADV", "ADV", "$.", "$(", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.39": {"line.1": {"text": "\u00bbo! Ich bekenn' es, Herr, ich schwamm", "tokens": ["\u00bb", "o", "!", "Ich", "be\u00b7kenn'", "es", ",", "Herr", ",", "ich", "schwamm"], "token_info": ["punct", "word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["$(", "FM", "$.", "PPER", "VVFIN", "PPER", "$,", "NN", "$,", "PPER", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Im Lustpfuhl dieser Erde;", "tokens": ["Im", "Lust\u00b7pfuhl", "die\u00b7ser", "Er\u00b7de", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PDAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Doch bringe du dein irrend Lamm", "tokens": ["Doch", "brin\u00b7ge", "du", "dein", "ir\u00b7rend", "Lamm"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "PPOSAT", "ADJD", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Zur\u00fcck zu deiner Herde!", "tokens": ["Zu\u00b7r\u00fcck", "zu", "dei\u00b7ner", "Her\u00b7de", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.40": {"line.1": {"text": "Ich will, o lieber Hirt, hinfort", "tokens": ["Ich", "will", ",", "o", "lie\u00b7ber", "Hirt", ",", "hin\u00b7fort"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["PPER", "VMFIN", "$,", "FM", "ADV", "NN", "$,", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mein Irrsal stets bereuen.", "tokens": ["Mein", "Irr\u00b7sal", "stets", "be\u00b7reu\u00b7en", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Half doch sein letztes armes Wort", "tokens": ["Half", "doch", "sein", "letz\u00b7tes", "ar\u00b7mes", "Wort"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVIMP", "ADV", "PPOSAT", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Dem Sch\u00e4cher zum Gedeihen.\u00ab \u2013", "tokens": ["Dem", "Sch\u00e4\u00b7cher", "zum", "Ge\u00b7dei\u00b7hen", ".", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "$.", "$(", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.41": {"line.1": {"text": "\u00bbdu wu\u00dftest, Weib, was ich gethan;", "tokens": ["\u00bb", "du", "wu\u00df\u00b7test", ",", "Weib", ",", "was", "ich", "ge\u00b7than", ";"], "token_info": ["punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "$,", "NN", "$,", "PWS", "PPER", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Du kanntest meinen Willen:", "tokens": ["Du", "kann\u00b7test", "mei\u00b7nen", "Wil\u00b7len", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Allein, was hast du je gethan,", "tokens": ["Al\u00b7lein", ",", "was", "hast", "du", "je", "ge\u00b7than", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PWS", "VAFIN", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ihn dankbar zu erf\u00fcllen?\u00ab \u2013", "tokens": ["Ihn", "dank\u00b7bar", "zu", "er\u00b7f\u00fcl\u00b7len", "?", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PPER", "ADJD", "PTKZU", "VVINF", "$.", "$(", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.42": {"line.1": {"text": "\u00bbach nichts! Doch, lieber Menschensohn,", "tokens": ["\u00bb", "ach", "nichts", "!", "Doch", ",", "lie\u00b7ber", "Men\u00b7schen\u00b7sohn", ","], "token_info": ["punct", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["$(", "ADV", "PIS", "$.", "KON", "$,", "ADV", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Hei\u00df mich darum nicht fliehen!", "tokens": ["Hei\u00df", "mich", "da\u00b7rum", "nicht", "flie\u00b7hen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PRF", "PAV", "PTKNEG", "VVINF", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.3": {"text": "Es hat ja dem verlornen Sohn", "tokens": ["Es", "hat", "ja", "dem", "ver\u00b7lor\u00b7nen", "Sohn"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sein Vater auch verziehen.\u00ab \u2013", "tokens": ["Sein", "Va\u00b7ter", "auch", "ver\u00b7zie\u00b7hen", ".", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PPOSAT", "NN", "ADV", "VVPP", "$.", "$(", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.43": {"line.1": {"text": "\u00bbnun wohl, Verirrte, tritt herzu!", "tokens": ["\u00bb", "nun", "wohl", ",", "Ver\u00b7irr\u00b7te", ",", "tritt", "her\u00b7zu", "!"], "token_info": ["punct", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["$(", "ADV", "ADV", "$,", "VVFIN", "$,", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Will dich mit Gnade zeichnen.", "tokens": ["Will", "dich", "mit", "Gna\u00b7de", "zeich\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PRF", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Auch du bist mein! Geh ein zur Ruh!", "tokens": ["Auch", "du", "bist", "mein", "!", "Geh", "ein", "zur", "Ruh", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VAFIN", "PPOSAT", "$.", "NE", "ART", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ich will dich nicht verleugnen.\u00ab", "tokens": ["Ich", "will", "dich", "nicht", "ver\u00b7leug\u00b7nen", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VMFIN", "PPER", "PTKNEG", "VVINF", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.44": {"line.1": {"text": "Frau Schnipsen hatte Korn im Stroh,", "tokens": ["Frau", "Schnip\u00b7sen", "hat\u00b7te", "Korn", "im", "Stroh", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "VAFIN", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und hielt sich weidlich lecker;", "tokens": ["Und", "hielt", "sich", "weid\u00b7lich", "le\u00b7cker", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "ADV", "ADJD", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Sie lebt' in dulci Jubilo,", "tokens": ["Sie", "lebt'", "in", "dul\u00b7ci", "Ju\u00b7bi\u00b7lo", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NE", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und Keine war euch kecker.", "tokens": ["Und", "Kei\u00b7ne", "war", "euch", "ke\u00b7cker", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VAFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.45": {"line.1": {"text": "Das M\u00e4ulchen, sammt dem Z\u00fcnglein flink,", "tokens": ["Das", "M\u00e4ul\u00b7chen", ",", "sammt", "dem", "Z\u00fcn\u00b7glein", "flink", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "APPR", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sa\u00df ihr am rechten Flecken.", "tokens": ["Sa\u00df", "ihr", "am", "rech\u00b7ten", "Fle\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Sie schimpfte wie ein Rohrsperling,", "tokens": ["Sie", "schimpf\u00b7te", "wie", "ein", "Rohr\u00b7sper\u00b7ling", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KOKOM", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wenn man sie wollte necken.", "tokens": ["Wenn", "man", "sie", "woll\u00b7te", "ne\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPER", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.46": {"line.1": {"text": "Da kam Hans Mors, und zog den Strich", "tokens": ["Da", "kam", "Hans", "Mors", ",", "und", "zog", "den", "Strich"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "NE", "NE", "$,", "KON", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Durch ihr Schlaraffenleben.", "tokens": ["Durch", "ihr", "Schla\u00b7raf\u00b7fen\u00b7le\u00b7ben", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.3": {"text": "Zwar belferte sie j\u00e4mmerlich;", "tokens": ["Zwar", "bel\u00b7fer\u00b7te", "sie", "j\u00e4m\u00b7mer\u00b7lich", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Doch mu\u00dfte sie sich geben.", "tokens": ["Doch", "mu\u00df\u00b7te", "sie", "sich", "ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "PRF", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.47": {"line.1": {"text": "Sie klaffte fort, den Weg hinan,", "tokens": ["Sie", "klaff\u00b7te", "fort", ",", "den", "Weg", "hi\u00b7nan", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKVZ", "$,", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Bis vor die Himmelspforte,", "tokens": ["Bis", "vor", "die", "Him\u00b7mel\u00b7spfor\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Gekr\u00e4nkt, da\u00df sie nicht Zeit gewann,", "tokens": ["Ge\u00b7kr\u00e4nkt", ",", "da\u00df", "sie", "nicht", "Zeit", "ge\u00b7wann", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "KOUS", "PPER", "PTKNEG", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Zur letzten Mandeltorte.", "tokens": ["Zur", "letz\u00b7ten", "Man\u00b7del\u00b7tor\u00b7te", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.48": {"line.1": {"text": "Weil nun der letzte \u00c4rger ihr", "tokens": ["Weil", "nun", "der", "letz\u00b7te", "\u00c4r\u00b7ger", "ihr"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "ART", "ADJA", "NN", "PPOSAT"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Noch spukt' im Tabernakel,", "tokens": ["Noch", "spukt'", "im", "Ta\u00b7ber\u00b7na\u00b7kel", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "So trieb sie vor der Himmelsth\u00fcr", "tokens": ["So", "trieb", "sie", "vor", "der", "Him\u00b7mel\u00b7sth\u00fcr"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Viel Unfug und Spektakel.", "tokens": ["Viel", "Un\u00b7fug", "und", "Spek\u00b7ta\u00b7kel", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "KON", "NN", "$."], "meter": "-+--++-", "measure": "iambic.tri.relaxed"}}, "stanza.49": {"line.1": {"text": "\u00bbwer da, rief Adam unmutsvoll,", "tokens": ["\u00bb", "wer", "da", ",", "rief", "A\u00b7dam", "un\u00b7muts\u00b7voll", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "ADV", "$,", "VVFIN", "NE", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "St\u00f6rt so die Ruh der Frommen?\u00ab \u2013", "tokens": ["St\u00f6rt", "so", "die", "Ruh", "der", "From\u00b7men", "?", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "ART", "NN", "$.", "$(", "$("], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.3": {"text": "\u00bbich bins! Frau Schnips! Ich w\u00fcnschte wohl", "tokens": ["\u00bb", "ich", "bins", "!", "Frau", "Schnips", "!", "Ich", "w\u00fcnschte", "wohl"], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["$(", "PPER", "VAFIN", "$.", "NN", "NE", "$.", "PPER", "VVFIN", "ADV"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.4": {"text": "Bei Euch mit anzukommen.\u00ab \u2013", "tokens": ["Bei", "Euch", "mit", "an\u00b7zu\u00b7kom\u00b7men", ".", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["APPR", "PPER", "APPR", "VVIZU", "$.", "$(", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.50": {"line.1": {"text": "\u00bbdu? \u2013 Nicht also, Frau S\u00fcnderin!", "tokens": ["\u00bb", "du", "?", "\u2013", "Nicht", "al\u00b7so", ",", "Frau", "S\u00fcn\u00b7de\u00b7rin", "!"], "token_info": ["punct", "word", "punct", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "PPER", "$.", "$(", "PTKNEG", "ADV", "$,", "NN", "NN", "$."], "meter": "+-+-++-+", "measure": "unknown.measure.penta"}, "line.2": {"text": "Frau Liederlich! Frau Lecker!\u00ab \u2013", "tokens": ["Frau", "Lie\u00b7der\u00b7lich", "!", "Frau", "Le\u00b7cker", "!", "\u00ab", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "punct", "punct", "punct"], "pos": ["NN", "ADJD", "$.", "NN", "NE", "$.", "$(", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "\u00bbich wei\u00df wohl selber, was ich bin,", "tokens": ["\u00bb", "ich", "wei\u00df", "wohl", "sel\u00b7ber", ",", "was", "ich", "bin", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "ADV", "ADV", "$,", "PWS", "PPER", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Du alter S\u00fcndenhecker!", "tokens": ["Du", "al\u00b7ter", "S\u00fcn\u00b7den\u00b7he\u00b7cker", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.51": {"line.1": {"text": "Ei, zupfte sich Herr Erdenklo\u00df", "tokens": ["Ei", ",", "zupf\u00b7te", "sich", "Herr", "Er\u00b7den\u00b7klo\u00df"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$,", "VVFIN", "PRF", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Doch nur an eigner Nase!", "tokens": ["Doch", "nur", "an", "eig\u00b7ner", "Na\u00b7se", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Denn was man ist, das ist man blo\u00df", "tokens": ["Denn", "was", "man", "ist", ",", "das", "ist", "man", "blo\u00df"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "PWS", "PIS", "VAFIN", "$,", "PDS", "VAFIN", "PIS", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Von seinem Apfelfra\u00dfe.", "tokens": ["Von", "sei\u00b7nem", "Ap\u00b7fel\u00b7fra\u00b7\u00dfe", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.52": {"line.1": {"text": "So gut wie Er, denk' ich zur Ruh", "tokens": ["So", "gut", "wie", "Er", ",", "denk'", "ich", "zur", "Ruh"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "KOKOM", "PPER", "$,", "VVFIN", "PPER", "APPRART", "NN"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.2": {"text": "Noch Platz hier zu gewinnen.\u00ab \u2013", "tokens": ["Noch", "Platz", "hier", "zu", "ge\u00b7win\u00b7nen", ".", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["ADV", "NN", "ADV", "PTKZU", "VVINF", "$.", "$(", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Der Vater hielt die Ohren zu", "tokens": ["Der", "Va\u00b7ter", "hielt", "die", "Oh\u00b7ren", "zu"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "PTKZU"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und trollte sich von hinnen.", "tokens": ["Und", "troll\u00b7te", "sich", "von", "hin\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "APPR", "ADV", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.53": {"line.1": {"text": "D'rauf machte Jakob sich ans Thor:", "tokens": ["D'\u00b7rauf", "mach\u00b7te", "Ja\u00b7kob", "sich", "ans", "Thor", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "NE", "PRF", "APPRART", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "\u00bbmarsch! Packe dich zum Teufel!\u00ab \u2013", "tokens": ["\u00bb", "marsch", "!", "Pa\u00b7cke", "dich", "zum", "Teu\u00b7fel", "!", "\u00ab", "\u2013"], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["$(", "ADJD", "$.", "VVFIN", "PPER", "APPRART", "NN", "$.", "$(", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "\u00bbwas? schrie Frau Schnips ihm laut ins Ohr,", "tokens": ["\u00bb", "was", "?", "schrie", "Frau", "Schnips", "ihm", "laut", "ins", "Ohr", ","], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "$.", "VVFIN", "NN", "NE", "PPER", "ADJD", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Fickfacker! Ich zum Teufel?", "tokens": ["Fick\u00b7fa\u00b7cker", "!", "Ich", "zum", "Teu\u00b7fel", "?"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$.", "PPER", "APPRART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.54": {"line.1": {"text": "Du bist mir wohl der rechte Held,", "tokens": ["Du", "bist", "mir", "wohl", "der", "rech\u00b7te", "Held", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und bist wohl hier f\u00fcr's Prellen?", "tokens": ["Und", "bist", "wohl", "hier", "f\u00fcr's", "Prel\u00b7len", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Hast Bruder und Papa geprellt,", "tokens": ["Hast", "Bru\u00b7der", "und", "Pa\u00b7pa", "ge\u00b7prellt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "KON", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mit deinen Ziegenfellen.\u00ab \u2013", "tokens": ["Mit", "dei\u00b7nen", "Zie\u00b7gen\u00b7fel\u00b7len", ".", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "punct", "punct", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$.", "$(", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.55": {"line.1": {"text": "Stockm\u00e4uschenstill trieb ihr Geschrei", "tokens": ["Stock\u00b7m\u00e4u\u00b7schen\u00b7still", "trieb", "ihr", "Ge\u00b7schrei"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Hinweg den Patriarchen.", "tokens": ["Hin\u00b7weg", "den", "Pat\u00b7ri\u00b7ar\u00b7chen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Hierauf sprang Ehren-Loth herbei,", "tokens": ["Hier\u00b7auf", "sprang", "Eh\u00b7ren\u00b7Loth", "her\u00b7bei", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mit Brausen und mit Schnarchen.", "tokens": ["Mit", "Brau\u00b7sen", "und", "mit", "Schnar\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "APPR", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.56": {"line.1": {"text": "\u00bbdu auch, du alter Saufaus hast,", "tokens": ["\u00bb", "du", "auch", ",", "du", "al\u00b7ter", "Sauf\u00b7aus", "hast", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "ADV", "$,", "PPER", "ADJA", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Gro\u00df Recht hier zum Geprahle!", "tokens": ["Gro\u00df", "Recht", "hier", "zum", "Ge\u00b7prah\u00b7le", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "NN", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Bist wahrlich nicht der feinste Gast", "tokens": ["Bist", "wahr\u00b7lich", "nicht", "der", "feins\u00b7te", "Gast"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "PTKNEG", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "In diesem Himmelssaale!", "tokens": ["In", "die\u00b7sem", "Him\u00b7mels\u00b7saa\u00b7le", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.57": {"line.1": {"text": "Bezecht sich erst beim Abendbrot,", "tokens": ["Be\u00b7zecht", "sich", "erst", "beim", "A\u00b7bend\u00b7brot", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ADV", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Den Kindern zum Gel\u00e4chter,", "tokens": ["Den", "Kin\u00b7dern", "zum", "Ge\u00b7l\u00e4ch\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und dann beschl\u00e4ft Er \u2013 pfui, Herr Loth! \u2013", "tokens": ["Und", "dann", "be\u00b7schl\u00e4ft", "Er", "\u2013", "pfui", ",", "Herr", "Loth", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "$(", "ITJ", "$,", "NN", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Gar seine eignen T\u00f6chter!\u00ab", "tokens": ["Gar", "sei\u00b7ne", "eig\u00b7nen", "T\u00f6ch\u00b7ter", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "PPOSAT", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.58": {"line.1": {"text": "Ha puh! Wie stank der alte Mist! \u2013", "tokens": ["Ha", "puh", "!", "Wie", "stank", "der", "al\u00b7te", "Mist", "!", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ITJ", "ITJ", "$.", "PWAV", "VVFIN", "ART", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Loth mu\u00dfte sich bequemen,", "tokens": ["Loth", "mu\u00df\u00b7te", "sich", "be\u00b7que\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "PRF", "ADJA", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Als h\u00e4tt' er in das Bett' gepi\u00dft,", "tokens": ["Als", "h\u00e4tt'", "er", "in", "das", "Bett'", "ge\u00b7pi\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VAFIN", "PPER", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Voll Scham Rei\u00dfaus zu nehmen.", "tokens": ["Voll", "Scham", "Rei\u00df\u00b7aus", "zu", "neh\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "NN", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.59": {"line.1": {"text": "\u00bbna! \u2013 lief Relikte Judith hin,", "tokens": ["\u00bb", "na", "!", "\u2013", "lief", "Re\u00b7lik\u00b7te", "Ju\u00b7dith", "hin", ","], "token_info": ["punct", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ITJ", "$.", "$(", "VVFIN", "NN", "NE", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Welch L\u00e4rm hier und Gebrause!\u00ab \u2013", "tokens": ["Welch", "L\u00e4rm", "hier", "und", "Ge\u00b7brau\u00b7se", "!", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PIAT", "NN", "ADV", "KON", "NN", "$.", "$(", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "\u00bbbonsdies! Frau Gurgelschneiderin!", "tokens": ["\u00bb", "bons\u00b7dies", "!", "Frau", "Gur\u00b7gel\u00b7schnei\u00b7de\u00b7rin", "!"], "token_info": ["punct", "word", "punct", "word", "word", "punct"], "pos": ["$(", "VVFIN", "$.", "NN", "NE", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Sie ist hier auch zu Hause?\u00ab \u2013", "tokens": ["Sie", "ist", "hier", "auch", "zu", "Hau\u00b7se", "?", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "APPR", "NN", "$.", "$(", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.60": {"line.1": {"text": "Vor gro\u00dfer Scham bald bleich bald rot,", "tokens": ["Vor", "gro\u00b7\u00dfer", "Scham", "bald", "bleich", "bald", "rot", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ADV", "ADJD", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Stand Judith bei dem Gru\u00dfe.", "tokens": ["Stand", "Ju\u00b7dith", "bei", "dem", "Gru\u00b7\u00dfe", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Der K\u00f6nig David sah die Not,", "tokens": ["Der", "K\u00f6\u00b7nig", "Da\u00b7vid", "sah", "die", "Not", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NE", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und folgt' ihr auf dem Fu\u00dfe.", "tokens": ["Und", "folgt'", "ihr", "auf", "dem", "Fu\u00b7\u00dfe", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.61": {"line.1": {"text": "\u00bbwas f\u00fcr Hallo, du Teufelsweib?", "tokens": ["\u00bb", "was", "f\u00fcr", "Hal\u00b7lo", ",", "du", "Teu\u00b7fels\u00b7weib", "?"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "PWS", "APPR", "NE", "$,", "PPER", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Potz hunderttausend Velten!\u00ab \u2013", "tokens": ["Potz", "hun\u00b7dert\u00b7tau\u00b7send", "Vel\u00b7ten", "!", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "punct", "punct", "punct"], "pos": ["NN", "CARD", "NN", "$.", "$(", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "\u00bbei, Herr, w\u00e4r' ich Uria's Weib,", "tokens": ["\u00bb", "ei", ",", "Herr", ",", "w\u00e4r'", "ich", "U\u00b7ria's", "Weib", ","], "token_info": ["punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ITJ", "$,", "NN", "$,", "VAFIN", "PPER", "NE", "NE", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Ihr w\u00fcrdet so nicht schelten.", "tokens": ["Ihr", "w\u00fcr\u00b7det", "so", "nicht", "schel\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.62": {"line.1": {"text": "Es war, mein Seel! wohl mehr Hallo,", "tokens": ["Es", "war", ",", "mein", "Seel", "!", "wohl", "mehr", "Hal\u00b7lo", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "PPOSAT", "NN", "$.", "ADV", "ADV", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mit Bathseba zu liebeln,", "tokens": ["Mit", "Bath\u00b7se\u00b7ba", "zu", "lie\u00b7beln", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und ihren armen Hahnrei so", "tokens": ["Und", "ih\u00b7ren", "ar\u00b7men", "Hahn\u00b7rei", "so"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Zur Welt hinaus zu b\u00fcbeln.\u00ab \u2013", "tokens": ["Zur", "Welt", "hin\u00b7aus", "zu", "b\u00fc\u00b7beln", ".", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["APPRART", "NN", "APZR", "PTKZU", "VVINF", "$.", "$(", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.63": {"line.1": {"text": "\u00bbdas Weib ist toll, rief Salomo,", "tokens": ["\u00bb", "das", "Weib", "ist", "toll", ",", "rief", "Sa\u00b7lo\u00b7mo", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "VAFIN", "ADJD", "$,", "VVFIN", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Hat zu viel Schnaps genommen!", "tokens": ["Hat", "zu", "viel", "Schnaps", "ge\u00b7nom\u00b7men", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "PIAT", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Was? Seiner Majest\u00e4t also \u2013 \u2013 \u2013", "tokens": ["Was", "?", "Sei\u00b7ner", "Ma\u00b7jes\u00b7t\u00e4t", "al\u00b7so", "\u2013", "\u2013", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PWS", "$.", "PPOSAT", "NN", "ADV", "$(", "$(", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So \u2013 \u2013 hundsf\u00f6ttsch anzukommen?\u00ab \u2013", "tokens": ["So", "\u2013", "\u2013", "hunds\u00b7f\u00f6ttsch", "an\u00b7zu\u00b7kom\u00b7men", "?", "\u00ab", "\u2013"], "token_info": ["word", "punct", "punct", "word", "word", "punct", "punct", "punct"], "pos": ["ADV", "$(", "$(", "ADJD", "VVIZU", "$.", "$(", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.64": {"line.1": {"text": "\u00bbo Herr, nicht halb so toll, als Er!", "tokens": ["\u00bb", "o", "Herr", ",", "nicht", "halb", "so", "toll", ",", "als", "Er", "!"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "FM", "NN", "$,", "PTKNEG", "ADJD", "ADV", "ADJD", "$,", "KOUS", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "H\u00e4tt' er sein Maul gehalten!", "tokens": ["H\u00e4tt'", "er", "sein", "Maul", "ge\u00b7hal\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Wir wissen's noch recht gut, wie Er", "tokens": ["Wir", "wis\u00b7sen's", "noch", "recht", "gut", ",", "wie", "Er"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "ADJD", "$,", "PWAV", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Auf Erden Haus gehalten.", "tokens": ["Auf", "Er\u00b7den", "Haus", "ge\u00b7hal\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.65": {"line.1": {"text": "Sieb'n hundert Weiber auf der Streu,", "tokens": ["Sie\u00b7b'n", "hun\u00b7dert", "Wei\u00b7ber", "auf", "der", "Streu", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["XY", "CARD", "NN", "APPR", "ART", "NN", "$,"], "meter": "+++-+-+-+", "measure": "unknown.measure.hexa"}, "line.2": {"text": "Und extra doch darneben", "tokens": ["Und", "ex\u00b7tra", "doch", "dar\u00b7ne\u00b7ben"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ADV", "ADV", "PAV"], "meter": "-+--+--", "measure": "iambic.di.relaxed"}, "line.3": {"text": "Drei hundert \u2013 \u2013 Andre! Meiner Treu!", "tokens": ["Drei", "hun\u00b7dert", "\u2013", "\u2013", "And\u00b7re", "!", "Mei\u00b7ner", "Treu", "!"], "token_info": ["word", "word", "punct", "punct", "word", "punct", "word", "word", "punct"], "pos": ["CARD", "CARD", "$(", "$(", "PIS", "$.", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Das war ein z\u00fcchtig Leben!", "tokens": ["Das", "war", "ein", "z\u00fcch\u00b7tig", "Le\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "ADJD", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.66": {"line.1": {"text": "Und Sein Verstand war klimperklein,", "tokens": ["Und", "Sein", "Ver\u00b7stand", "war", "klim\u00b7per\u00b7klein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Als Er von Gott sich wandte,", "tokens": ["Als", "Er", "von", "Gott", "sich", "wand\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NN", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und G\u00f6tzen pur von Holz und Stein,", "tokens": ["Und", "G\u00f6t\u00b7zen", "pur", "von", "Holz", "und", "Stein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ADJD", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sein th\u00f6richt Opfer brannte.\u00ab \u2013", "tokens": ["Sein", "th\u00f6\u00b7richt", "Op\u00b7fer", "brann\u00b7te", ".", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PPOSAT", "NN", "NN", "VVFIN", "$.", "$(", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.67": {"line.1": {"text": "\u00bbf\u00fcrwahr, emp\u00f6rte Jonas sich,", "tokens": ["\u00bb", "f\u00fcr\u00b7wahr", ",", "em\u00b7p\u00f6r\u00b7te", "Jo\u00b7nas", "sich", ","], "token_info": ["punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "$,", "VVFIN", "NE", "PRF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das Weib speit, wie ein Drache!\u00ab \u2013", "tokens": ["Das", "Weib", "speit", ",", "wie", "ein", "Dra\u00b7che", "!", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "punct", "punct"], "pos": ["ART", "NN", "ADJD", "$,", "PWAV", "ART", "NN", "$.", "$(", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "\u00bbhalt's Maul, Ausrei\u00dfer! K\u00fcmmre dich", "tokens": ["\u00bb", "halt's", "Maul", ",", "Aus\u00b7rei\u00b7\u00dfer", "!", "K\u00fcmm\u00b7re", "dich"], "token_info": ["punct", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["$(", "ADJA", "NN", "$,", "NN", "$.", "NN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Um Deine faule Sache!\u00ab \u2013", "tokens": ["Um", "Dei\u00b7ne", "fau\u00b7le", "Sa\u00b7che", "!", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["KOUI", "PPOSAT", "ADJA", "NN", "$.", "$(", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.68": {"line.1": {"text": "Auch Thom's gab seinen Senf dazu:", "tokens": ["Auch", "Thom's", "gab", "sei\u00b7nen", "Senf", "da\u00b7zu", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NE", "VVFIN", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u00bbein Sprichwort, das ich glaube,", "tokens": ["\u00bb", "ein", "Sprich\u00b7wort", ",", "das", "ich", "glau\u00b7be", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Sagt: Weiberzung' hat nimmer Ruh;", "tokens": ["Sagt", ":", "Wei\u00b7ber\u00b7zung'", "hat", "nim\u00b7mer", "Ruh", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$.", "NE", "VAFIN", "ADV", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sie ist von Espenlaube.\u00ab \u2013", "tokens": ["Sie", "ist", "von", "E\u00b7spen\u00b7lau\u00b7be", ".", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PPER", "VAFIN", "APPR", "NN", "$.", "$(", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.69": {"line.1": {"text": "\u00bbglaub' immer was ein Narr erdacht,", "tokens": ["\u00bb", "glaub'", "im\u00b7mer", "was", "ein", "Narr", "er\u00b7dacht", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "ADV", "PWS", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mit allen dummen Teufeln!", "tokens": ["Mit", "al\u00b7len", "dum\u00b7men", "Teu\u00b7feln", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Doch konnt' an seines Heilands Macht", "tokens": ["Doch", "konnt'", "an", "sei\u00b7nes", "Hei\u00b7lands", "Macht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VMFIN", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der schwache Pinsel zweifeln.\u00ab \u2013", "tokens": ["Der", "schwa\u00b7che", "Pin\u00b7sel", "zwei\u00b7feln", ".", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "$.", "$(", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.70": {"line.1": {"text": "Maria Magdalena kam. \u2013", "tokens": ["Ma\u00b7ria", "Mag\u00b7da\u00b7le\u00b7na", "kam", ".", "\u2013"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["NE", "NE", "VVFIN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Nu ja! Die wird's erst kriegen! \u2013", "tokens": ["Nu", "ja", "!", "Die", "wird's", "erst", "krie\u00b7gen", "!", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "ADV", "$.", "PDS", "VAFIN", "ADV", "VVINF", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "\u00bbstill, gute Frau, fein still und zahm!", "tokens": ["\u00bb", "still", ",", "gu\u00b7te", "Frau", ",", "fein", "still", "und", "zahm", "!"], "token_info": ["punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PTKVZ", "$,", "ADJA", "NN", "$,", "ADJD", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ihr m\u00fc\u00dft Euch anders f\u00fcgen.", "tokens": ["Ihr", "m\u00fc\u00dft", "Euch", "an\u00b7ders", "f\u00fc\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.71": {"line.1": {"text": "Denn, gute Frau, erinnert Euch", "tokens": ["Denn", ",", "gu\u00b7te", "Frau", ",", "e\u00b7rin\u00b7nert", "Euch"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word"], "pos": ["KON", "$,", "ADJA", "NN", "$,", "VVFIN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "An Eu'r verruchtes Leben!", "tokens": ["An", "Eu'r", "ver\u00b7ruch\u00b7tes", "Le\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "So ", "tokens": ["So"], "token_info": ["word"], "pos": ["ADV"], "meter": "-", "measure": "single.down"}, "line.4": {"text": "Kein Pl\u00e4tzchen eingegeben.\u00ab \u2013", "tokens": ["Kein", "Pl\u00e4tz\u00b7chen", "ein\u00b7ge\u00b7ge\u00b7ben", ".", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "punct", "punct", "punct"], "pos": ["PIAT", "NN", "VVPP", "$.", "$(", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.72": {"line.1": {"text": "\u00bbso ", "tokens": ["\u00bb", "so"], "token_info": ["punct", "word"], "pos": ["$(", "ADV"], "meter": "-", "measure": "single.down"}, "line.2": {"text": "Was bin ich denn f\u00fcr ", "tokens": ["Was", "bin", "ich", "denn", "f\u00fcr"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "VAFIN", "PPER", "ADV", "APPR"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "Sie war mir auch das rechte Kraut!", "tokens": ["Sie", "war", "mir", "auch", "das", "rech\u00b7te", "Kraut", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Nun brennt Sie gar sich reine?", "tokens": ["Nun", "brennt", "Sie", "gar", "sich", "rei\u00b7ne", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "PRF", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.73": {"line.1": {"text": "Ach! Um die Tugend Ihrer Zeit", "tokens": ["Ach", "!", "Um", "die", "Tu\u00b7gend", "Ih\u00b7rer", "Zeit"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["ITJ", "$.", "KOUI", "ART", "NN", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ist Sie nicht hergekommen.", "tokens": ["Ist", "Sie", "nicht", "her\u00b7ge\u00b7kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Des Heilands Allbarmherzigkeit", "tokens": ["Des", "Hei\u00b7lands", "All\u00b7barm\u00b7her\u00b7zig\u00b7keit"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Hat Sie hier aufgenommen.", "tokens": ["Hat", "Sie", "hier", "auf\u00b7ge\u00b7nom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.74": {"line.1": {"text": "Durch diese Allbarmherzigkeit,", "tokens": ["Durch", "die\u00b7se", "All\u00b7barm\u00b7her\u00b7zig\u00b7keit", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sie wird's nicht \u00fcbel deuten,", "tokens": ["Sie", "wird's", "nicht", "\u00fc\u00b7bel", "deu\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKNEG", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Hoff' ich, trotz meiner S\u00fcndlichkeit,", "tokens": ["Hoff'", "ich", ",", "trotz", "mei\u00b7ner", "S\u00fcnd\u00b7lich\u00b7keit", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Auch noch hineinzuschreiten.\u00ab \u2013", "tokens": ["Auch", "noch", "hin\u00b7ein\u00b7zu\u00b7schrei\u00b7ten", ".", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "punct", "punct", "punct"], "pos": ["ADV", "ADV", "VVINF", "$.", "$(", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.75": {"line.1": {"text": "Jetzt sprang Apostel Paul empor:", "tokens": ["Jetzt", "sprang", "A\u00b7pos\u00b7tel", "Paul", "em\u00b7por", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NE", "NE", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u00bbmit deinen alten S\u00fcnden,", "tokens": ["\u00bb", "mit", "dei\u00b7nen", "al\u00b7ten", "S\u00fcn\u00b7den", ","], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Weib, wirst du durch das Himmelsthor", "tokens": ["Weib", ",", "wirst", "du", "durch", "das", "Him\u00b7mel\u00b7sthor"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "VAFIN", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Den Eingang nimmer finden!\u00ab \u2013", "tokens": ["Den", "Ein\u00b7gang", "nim\u00b7mer", "fin\u00b7den", "!", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["ART", "NN", "ADV", "VVINF", "$.", "$(", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.76": {"line.1": {"text": "\u00bbdie lass' ich drau\u00dfen! \u2013 Denke, Paul,", "tokens": ["\u00bb", "die", "lass'", "ich", "drau\u00b7\u00dfen", "!", "\u2013", "Den\u00b7ke", ",", "Paul", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct", "word", "punct", "word", "punct"], "pos": ["$(", "ART", "VVFIN", "PPER", "ADV", "$.", "$(", "VVIMP", "$,", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wie dir's vor Zeiten gl\u00fcckte;", "tokens": ["Wie", "dir's", "vor", "Zei\u00b7ten", "gl\u00fcck\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Dir, der doch so mit Mord, als Saul,", "tokens": ["Dir", ",", "der", "doch", "so", "mit", "Mord", ",", "als", "Saul", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "$,", "PRELS", "ADV", "ADV", "APPR", "NN", "$,", "KOUS", "NE", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.4": {"text": "Die Kirche Gottes dr\u00fcckte!\u00ab \u2013", "tokens": ["Die", "Kir\u00b7che", "Got\u00b7tes", "dr\u00fcck\u00b7te", "!", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "$.", "$(", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.77": {"line.1": {"text": "Sanct Peter kam nun auch zum Spiel:", "tokens": ["Sanct", "Pe\u00b7ter", "kam", "nun", "auch", "zum", "Spiel", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "VVFIN", "ADV", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u00bbdie Th\u00fcr nicht eingeschlagen!", "tokens": ["\u00bb", "die", "Th\u00fcr", "nicht", "ein\u00b7ge\u00b7schla\u00b7gen", "!"], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Madam, Sie l\u00e4rmt auch allzuviel;", "tokens": ["Ma\u00b7dam", ",", "Sie", "l\u00e4rmt", "auch", "all\u00b7zu\u00b7viel", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PPER", "VVFIN", "ADV", "PIS", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wer kann das hier vertragen?\u00ab \u2013", "tokens": ["Wer", "kann", "das", "hier", "ver\u00b7tra\u00b7gen", "?", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PWS", "VMFIN", "PDS", "ADV", "VVFIN", "$.", "$(", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.78": {"line.1": {"text": "\u00bbgeduld, Herr Pf\u00f6rtner! sagte sie;", "tokens": ["\u00bb", "ge\u00b7duld", ",", "Herr", "Pf\u00f6rt\u00b7ner", "!", "sag\u00b7te", "sie", ";"], "token_info": ["punct", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "ADJD", "$,", "NN", "NE", "$.", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Noch bin ich unverloren!", "tokens": ["Noch", "bin", "ich", "un\u00b7ver\u00b7lo\u00b7ren", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Hab' ich doch meinen Heiland nie,", "tokens": ["Hab'", "ich", "doch", "mei\u00b7nen", "Hei\u00b7land", "nie", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "PPOSAT", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wie Du einst, abgeschworen.\u00ab \u2013 \u2013", "tokens": ["Wie", "Du", "einst", ",", "ab\u00b7ge\u00b7schwo\u00b7ren", ".", "\u00ab", "\u2013", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "punct", "punct", "punct", "punct"], "pos": ["PWAV", "PPER", "ADV", "$,", "VVPP", "$.", "$(", "$(", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.79": {"line.1": {"text": "Und unser lieber Herr vernahm", "tokens": ["Und", "un\u00b7ser", "lie\u00b7ber", "Herr", "ver\u00b7nahm"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Seele letzte Worte.", "tokens": ["Der", "See\u00b7le", "letz\u00b7te", "Wor\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Umringt von tausend Engeln kam", "tokens": ["Um\u00b7ringt", "von", "tau\u00b7send", "En\u00b7geln", "kam"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "CARD", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Er herrlich an die Pforte.", "tokens": ["Er", "herr\u00b7lich", "an", "die", "Pfor\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.80": {"line.1": {"text": "\u00bberbarmen! Ach, Erbarmen!\u00ab schrie", "tokens": ["\u00bb", "er\u00b7bar\u00b7men", "!", "Ach", ",", "Er\u00b7bar\u00b7men", "!", "\u00ab", "schrie"], "token_info": ["punct", "word", "punct", "word", "punct", "word", "punct", "punct", "word"], "pos": ["$(", "VVINF", "$.", "ITJ", "$,", "NN", "$.", "$(", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die arme bange Seele. \u2013", "tokens": ["Die", "ar\u00b7me", "ban\u00b7ge", "See\u00b7le", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "\u00bbo Seele, du gehorchtest nie", "tokens": ["\u00bb", "o", "See\u00b7le", ",", "du", "ge\u00b7horch\u00b7test", "nie"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word"], "pos": ["$(", "FM", "NN", "$,", "PPER", "VVFIN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Dem g\u00f6ttlichen Befehle.", "tokens": ["Dem", "g\u00f6tt\u00b7li\u00b7chen", "Be\u00b7feh\u00b7le", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.81": {"line.1": {"text": "Ich lockte dich an meine Brust:", "tokens": ["Ich", "lock\u00b7te", "dich", "an", "mei\u00b7ne", "Brust", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Zur S\u00fcnde gingst du \u00fcber.", "tokens": ["Zur", "S\u00fcn\u00b7de", "gingst", "du", "\u00fc\u00b7ber", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PPER", "APPR", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Die Welt mit ihrer eiteln Lust", "tokens": ["Die", "Welt", "mit", "ih\u00b7rer", "ei\u00b7teln", "Lust"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "War, Th\u00f6rin, dir viel lieber.\u00ab \u2013", "tokens": ["War", ",", "Th\u00f6\u00b7rin", ",", "dir", "viel", "lie\u00b7ber", ".", "\u00ab", "\u2013"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct", "punct", "punct"], "pos": ["VAFIN", "$,", "NN", "$,", "PPER", "ADV", "ADV", "$.", "$(", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.82": {"line.1": {"text": "\u00bbo! Ich bekenn' es, Herr, ich schwamm", "tokens": ["\u00bb", "o", "!", "Ich", "be\u00b7kenn'", "es", ",", "Herr", ",", "ich", "schwamm"], "token_info": ["punct", "word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["$(", "FM", "$.", "PPER", "VVFIN", "PPER", "$,", "NN", "$,", "PPER", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Im Lustpfuhl dieser Erde;", "tokens": ["Im", "Lust\u00b7pfuhl", "die\u00b7ser", "Er\u00b7de", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PDAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Doch bringe du dein irrend Lamm", "tokens": ["Doch", "brin\u00b7ge", "du", "dein", "ir\u00b7rend", "Lamm"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "PPOSAT", "ADJD", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Zur\u00fcck zu deiner Herde!", "tokens": ["Zu\u00b7r\u00fcck", "zu", "dei\u00b7ner", "Her\u00b7de", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.83": {"line.1": {"text": "Ich will, o lieber Hirt, hinfort", "tokens": ["Ich", "will", ",", "o", "lie\u00b7ber", "Hirt", ",", "hin\u00b7fort"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["PPER", "VMFIN", "$,", "FM", "ADV", "NN", "$,", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mein Irrsal stets bereuen.", "tokens": ["Mein", "Irr\u00b7sal", "stets", "be\u00b7reu\u00b7en", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Half doch sein letztes armes Wort", "tokens": ["Half", "doch", "sein", "letz\u00b7tes", "ar\u00b7mes", "Wort"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVIMP", "ADV", "PPOSAT", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Dem Sch\u00e4cher zum Gedeihen.\u00ab \u2013", "tokens": ["Dem", "Sch\u00e4\u00b7cher", "zum", "Ge\u00b7dei\u00b7hen", ".", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "$.", "$(", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.84": {"line.1": {"text": "\u00bbdu wu\u00dftest, Weib, was ich gethan;", "tokens": ["\u00bb", "du", "wu\u00df\u00b7test", ",", "Weib", ",", "was", "ich", "ge\u00b7than", ";"], "token_info": ["punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "$,", "NN", "$,", "PWS", "PPER", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Du kanntest meinen Willen:", "tokens": ["Du", "kann\u00b7test", "mei\u00b7nen", "Wil\u00b7len", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Allein, was hast du je gethan,", "tokens": ["Al\u00b7lein", ",", "was", "hast", "du", "je", "ge\u00b7than", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PWS", "VAFIN", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ihn dankbar zu erf\u00fcllen?\u00ab \u2013", "tokens": ["Ihn", "dank\u00b7bar", "zu", "er\u00b7f\u00fcl\u00b7len", "?", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PPER", "ADJD", "PTKZU", "VVINF", "$.", "$(", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.85": {"line.1": {"text": "\u00bbach nichts! Doch, lieber Menschensohn,", "tokens": ["\u00bb", "ach", "nichts", "!", "Doch", ",", "lie\u00b7ber", "Men\u00b7schen\u00b7sohn", ","], "token_info": ["punct", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["$(", "ADV", "PIS", "$.", "KON", "$,", "ADV", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Hei\u00df mich darum nicht fliehen!", "tokens": ["Hei\u00df", "mich", "da\u00b7rum", "nicht", "flie\u00b7hen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PRF", "PAV", "PTKNEG", "VVINF", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.3": {"text": "Es hat ja dem verlornen Sohn", "tokens": ["Es", "hat", "ja", "dem", "ver\u00b7lor\u00b7nen", "Sohn"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sein Vater auch verziehen.\u00ab \u2013", "tokens": ["Sein", "Va\u00b7ter", "auch", "ver\u00b7zie\u00b7hen", ".", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PPOSAT", "NN", "ADV", "VVPP", "$.", "$(", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.86": {"line.1": {"text": "\u00bbnun wohl, Verirrte, tritt herzu!", "tokens": ["\u00bb", "nun", "wohl", ",", "Ver\u00b7irr\u00b7te", ",", "tritt", "her\u00b7zu", "!"], "token_info": ["punct", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["$(", "ADV", "ADV", "$,", "VVFIN", "$,", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Will dich mit Gnade zeichnen.", "tokens": ["Will", "dich", "mit", "Gna\u00b7de", "zeich\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PRF", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Auch du bist mein! Geh ein zur Ruh!", "tokens": ["Auch", "du", "bist", "mein", "!", "Geh", "ein", "zur", "Ruh", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VAFIN", "PPOSAT", "$.", "NE", "ART", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ich will dich nicht verleugnen.\u00ab", "tokens": ["Ich", "will", "dich", "nicht", "ver\u00b7leug\u00b7nen", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VMFIN", "PPER", "PTKNEG", "VVINF", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}}}}