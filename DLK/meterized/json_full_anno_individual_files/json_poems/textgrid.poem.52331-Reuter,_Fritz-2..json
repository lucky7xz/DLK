{"textgrid.poem.52331": {"metadata": {"author": {"name": "Reuter, Fritz", "birth": "N.A.", "death": "N.A."}, "title": "2.", "genre": "verse", "period": "N.A.", "pub_year": 1842, "urn": "N.A.", "language": ["de:0.85", "sv:0.14"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Junker Korl, de w\u00fcrd nu gr\u00f6ter,", "tokens": ["Jun\u00b7ker", "Korl", ",", "de", "w\u00fcrd", "nu", "gr\u00f6\u00b7ter", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "NE", "VAFIN", "ADV", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "As en groten Kirl all let'e,", "tokens": ["As", "en", "gro\u00b7ten", "Kirl", "all", "let'e", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "ADJA", "NN", "PIAT", "ADJA", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "\u00c4werst dumm was hei man blewen,", "tokens": ["\u00c4\u00b7werst", "dumm", "was", "hei", "man", "ble\u00b7wen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PWS", "VAFIN", "PIS", "VVINF", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "D\u00e4mlich was hei \u00e4werdrewen;", "tokens": ["D\u00e4m\u00b7lich", "was", "hei", "\u00e4\u00b7wer\u00b7dre\u00b7wen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "FM", "FM", "FM", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.5": {"text": "Den Papa taum Schawernack", "tokens": ["Den", "Pa\u00b7pa", "taum", "Scha\u00b7wer\u00b7nack"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ADV", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Ded hei m\u00e4nn'gen dummen Snack.", "tokens": ["Ded", "hei", "m\u00e4nn'\u00b7gen", "dum\u00b7men", "Snack", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "ADJA", "ADJA", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.2": {"line.1": {"text": "Un de gned'ge Herr von Degen", "tokens": ["Un", "de", "gne\u00b7d'\u00b7ge", "Herr", "von", "De\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "NE", "ADJA", "NN", "APPR", "NN"], "meter": "+-++-+-+-", "measure": "unknown.measure.penta"}, "line.2": {"text": "M\u00fc\u00dft sick \u00fcmmer sihr von wegen", "tokens": ["M\u00fc\u00dft", "sick", "\u00fcm\u00b7mer", "sihr", "von", "we\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["FM.fr", "FM.fr", "FM.fr", "FM.fr", "APPR", "APPR"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Sine D\u00e4mlichkeit schanieren,", "tokens": ["Si\u00b7ne", "D\u00e4m\u00b7lich\u00b7keit", "scha\u00b7nie\u00b7ren", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Let em nich mihr mit sick f\u00fchren,", "tokens": ["Let", "em", "nich", "mihr", "mit", "sick", "f\u00fch\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["XY", "XY", "PTKNEG", "ADV", "APPR", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Wenn hei utwarts beden wir.", "tokens": ["Wenn", "hei", "ut\u00b7warts", "be\u00b7den", "wir", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "ADV", "VVFIN", "PPER", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.6": {"text": "\u00bbkarl, mein Sohn, du bleibst heut hier.\u00ab", "tokens": ["\u00bb", "karl", ",", "mein", "Sohn", ",", "du", "bleibst", "heut", "hier", ".", "\u00ab"], "token_info": ["punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "NE", "$,", "PPOSAT", "NN", "$,", "PPER", "VVFIN", "ADV", "ADV", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Bi de gned'ge Fru von Degen", "tokens": ["Bi", "de", "gne\u00b7d'\u00b7ge", "Fru", "von", "De\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "NE", "ADJA", "NN", "APPR", "NN"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "W\u00fcrd de Mutterschaft sick r\u00f6gen;", "tokens": ["W\u00fcrd", "de", "Mut\u00b7ter\u00b7schaft", "sick", "r\u00f6\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NE", "NN", "ADJD", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Sei m\u00fc\u00dft \u00e4wer ehren armen,", "tokens": ["Sei", "m\u00fc\u00dft", "\u00e4\u00b7wer", "eh\u00b7ren", "ar\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAIMP", "VMFIN", "ADJD", "VVINF", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "S\u00e4uten K\u00f6rling sick erbarmen.", "tokens": ["S\u00e4u\u00b7ten", "K\u00f6r\u00b7ling", "sick", "er\u00b7bar\u00b7men", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ADJD", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "\u00bbwie die V\u00e4ter hart doch sind!", "tokens": ["\u00bb", "wie", "die", "V\u00e4\u00b7ter", "hart", "doch", "sind", "!"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOKOM", "ART", "NN", "ADJD", "ADV", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Oh, mon cher, nimm mit das Kind!\u00ab", "tokens": ["Oh", ",", "mon", "cher", ",", "nimm", "mit", "das", "Kind", "!", "\u00ab"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["ITJ", "$,", "NE", "NE", "$,", "VVIMP", "APPR", "ART", "NN", "$.", "$("], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.4": {"line.1": {"text": "Korl, de kreg nu \u00c4werwater,", "tokens": ["Korl", ",", "de", "kreg", "nu", "\u00c4\u00b7wer\u00b7wa\u00b7ter", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "FM.la", "FM.la", "FM.la", "FM.la", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Rohrte as en Br\u00f6llenkater,", "tokens": ["Rohr\u00b7te", "as", "en", "Br\u00f6l\u00b7len\u00b7ka\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["FM", "FM", "FM", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "As wenn hei up't Spitt ded steken,", "tokens": ["As", "wenn", "hei", "up't", "Spitt", "ded", "ste\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KOUS", "FM", "FM", "FM", "FM", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ded ok allens Gauds verspreken:", "tokens": ["Ded", "ok", "al\u00b7lens", "Gauds", "ver\u00b7spre\u00b7ken", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "\u00bbwill mi duken as en Hauhn,", "tokens": ["\u00bb", "will", "mi", "du\u00b7ken", "as", "en", "Hauhn", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VMFIN", "FM", "FM", "FM", "FM", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Will ok nich dat Mul updauhn.\u00ab", "tokens": ["Will", "ok", "nich", "dat", "Mul", "up\u00b7dauhn", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VMFIN", "ADV", "PTKNEG", "ART", "NN", "VVINF", "$.", "$("], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.5": {"line.1": {"text": "Na, genaug, de Herr von Degen", "tokens": ["Na", ",", "ge\u00b7naug", ",", "de", "Herr", "von", "De\u00b7gen"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["ITJ", "$,", "VVFIN", "$,", "NE", "NN", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Hett nich sinen Willen kregen,", "tokens": ["Hett", "nich", "si\u00b7nen", "Wil\u00b7len", "kre\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKNEG", "ADJA", "NN", "VVINF", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Korlen w\u00fcrd en reinen Kragen", "tokens": ["Kor\u00b7len", "w\u00fcrd", "en", "rei\u00b7nen", "Kra\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "VAFIN", "FM", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Un 'ne reine B\u00fcx antagen", "tokens": ["Un", "'ne", "rei\u00b7ne", "B\u00fcx", "an\u00b7ta\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "ART", "ADJA", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Un dat Hor em rutemutzt", "tokens": ["Un", "dat", "Hor", "em", "ru\u00b7te\u00b7mutzt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Un de N\u00e4s' em sauber putzt.", "tokens": ["Un", "de", "N\u00e4s'", "em", "sau\u00b7ber", "putzt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "As nu allens in Ordnung sch\u00f6n,", "tokens": ["As", "nu", "al\u00b7lens", "in", "Ord\u00b7nung", "sch\u00f6n", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "ADV", "APPR", "NN", "ADJD", "$,"], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.2": {"text": "Reis't de Vader mit den S\u00e4hn,", "tokens": ["Reis't", "de", "Va\u00b7der", "mit", "den", "S\u00e4hn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "NE", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Un Papa, de s\u00e4d: \u00bbMein S\u00f6hnchen,", "tokens": ["Un", "Pa\u00b7pa", ",", "de", "s\u00e4d", ":", "\u00bb", "Mein", "S\u00f6hn\u00b7chen", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "FM.la", "FM.la", "$.", "$(", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Nun schweig heut auch still recht sch\u00f6nchen,", "tokens": ["Nun", "schweig", "heut", "auch", "still", "recht", "sch\u00f6n\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "ADV", "ADJD", "ADJD", "VVINF", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Gar kein Sterbensw\u00f6rtchen sprich!", "tokens": ["Gar", "kein", "Ster\u00b7bens\u00b7w\u00f6rt\u00b7chen", "sprich", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Schweigen, das verr\u00e4t dich nich.\u00ab", "tokens": ["Schwei\u00b7gen", ",", "das", "ver\u00b7r\u00e4t", "dich", "nich", ".", "\u00ab"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "$,", "PDS", "VVFIN", "PPER", "PTKNEG", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Bald s\u00fcnd sei nu bi dat Eten.", "tokens": ["Bald", "s\u00fcnd", "sei", "nu", "bi", "dat", "E\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VAFIN", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Korl hett mang twei Damen seten,", "tokens": ["Korl", "hett", "mang", "twei", "Da\u00b7men", "se\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "FM", "FM", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Recht so'n por l\u00fctt drift'ge Dirns,", "tokens": ["Recht", "so'n", "por", "l\u00fctt", "drift'\u00b7ge", "Dirns", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Recht so'n Heweltaschen wiren s',", "tokens": ["Recht", "so'n", "He\u00b7wel\u00b7ta\u00b7schen", "wi\u00b7ren", "s'", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "VAFIN", "NE", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.5": {"text": "Wiren ut 'ne grote Stadt,", "tokens": ["Wi\u00b7ren", "ut", "'ne", "gro\u00b7te", "Stadt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Redten glik von dit un dat;", "tokens": ["Red\u00b7ten", "glik", "von", "dit", "un", "dat", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "APPR", "FM", "FM", "FM", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Von Theater, Ball un Weder,", "tokens": ["Von", "The\u00b7a\u00b7ter", ",", "Ball", "un", "We\u00b7der", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "FM", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Von de Lust in grote St\u00e4der.", "tokens": ["Von", "de", "Lust", "in", "gro\u00b7te", "St\u00e4\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "NN", "APPR", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Fang'n ok an mit Korl tau reden.", "tokens": ["Fang'n", "ok", "an", "mit", "Korl", "tau", "re\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "APPR", "APPR", "NE", "NE", "VVINF", "$."], "meter": "+-+--+--", "measure": "trochaic.tri.relaxed"}, "line.4": {"text": "Korl denkt: Lat't mi man taufreden!", "tokens": ["Korl", "denkt", ":", "Lat't", "mi", "man", "tauf\u00b7re\u00b7den", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "$.", "NE", "NE", "PIS", "VVINF", "$."], "meter": "--+--+--", "measure": "anapaest.di.plus"}, "line.5": {"text": "Antwurt' drup nich Swart noch Witt,", "tokens": ["Ant\u00b7wurt'", "drup", "nich", "Swart", "noch", "Witt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "PTKNEG", "NE", "ADV", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Vader nimmt em s\u00fcs nich mit.", "tokens": ["Va\u00b7der", "nimmt", "em", "s\u00fcs", "nich", "mit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "As de beiden l\u00fctten Damen", "tokens": ["As", "de", "bei\u00b7den", "l\u00fct\u00b7ten", "Da\u00b7men"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "NE", "PIAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Gor kein Wurd von em vernamen,", "tokens": ["Gor", "kein", "Wurd", "von", "em", "ver\u00b7na\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PIAT", "NN", "APPR", "ADJA", "VVINF", "$,"], "meter": "---+--+-", "measure": "iambic.di.relaxed"}, "line.3": {"text": "Deiht de ein sick r\u00fcmmer b\u00fccken", "tokens": ["Deiht", "de", "ein", "sick", "r\u00fcm\u00b7mer", "b\u00fc\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Achter Korlen sinen R\u00fcggen.", "tokens": ["Ach\u00b7ter", "Kor\u00b7len", "si\u00b7nen", "R\u00fcg\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "\u00bbnein, Sophie, der Mensch ist stumm,", "tokens": ["\u00bb", "nein", ",", "So\u00b7phie", ",", "der", "Mensch", "ist", "stumm", ","], "token_info": ["punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PTKANT", "$,", "NE", "$,", "ART", "NN", "VAFIN", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Oder er ist schrecklich dumm.\u00ab", "tokens": ["O\u00b7der", "er", "ist", "schreck\u00b7lich", "dumm", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "PPER", "VAFIN", "ADJD", "ADJD", "$.", "$("], "meter": "+---+-+", "measure": "dactylic.init"}}, "stanza.10": {"line.1": {"text": "Dat's man sch\u00f6n, denkt Korl von Degen,", "tokens": ["Dat's", "man", "sch\u00f6n", ",", "denkt", "Korl", "von", "De\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "PIS", "ADJD", "$,", "VVFIN", "NE", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Dat sei't endlich ruter kregen.", "tokens": ["Dat", "sei't", "end\u00b7lich", "ru\u00b7ter", "kre\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ADV", "ADJD", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "\u00bbne, Papa\u00ab, r\u00f6ppt hei ganz lud,", "tokens": ["\u00bb", "ne", ",", "Pa\u00b7pa", "\u00ab", ",", "r\u00f6ppt", "hei", "ganz", "lud", ","], "token_info": ["punct", "word", "punct", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "NE", "$,", "NN", "$(", "$,", "VVPP", "VAFIN", "ADV", "VVFIN", "$,"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.4": {"text": "\u00bbmit dat Swigen is dat ut;", "tokens": ["\u00bb", "mit", "dat", "Swi\u00b7gen", "is", "dat", "ut", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "ART", "NN", "FM", "FM", "FM", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Denn dat Fr\u00f6len rechtsch hir weit", "tokens": ["Denn", "dat", "Fr\u00f6\u00b7len", "rechtsch", "hir", "weit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "ADJD", "ADV", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Ganz genau von mi Bescheid.\u00ab", "tokens": ["Ganz", "ge\u00b7nau", "von", "mi", "Be\u00b7scheid", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "ADJD", "APPR", "NE", "NN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Junker Korl, de w\u00fcrd nu gr\u00f6ter,", "tokens": ["Jun\u00b7ker", "Korl", ",", "de", "w\u00fcrd", "nu", "gr\u00f6\u00b7ter", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "NE", "VAFIN", "ADV", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "As en groten Kirl all let'e,", "tokens": ["As", "en", "gro\u00b7ten", "Kirl", "all", "let'e", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "ADJA", "NN", "PIAT", "ADJA", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "\u00c4werst dumm was hei man blewen,", "tokens": ["\u00c4\u00b7werst", "dumm", "was", "hei", "man", "ble\u00b7wen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PWS", "VAFIN", "PIS", "VVINF", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "D\u00e4mlich was hei \u00e4werdrewen;", "tokens": ["D\u00e4m\u00b7lich", "was", "hei", "\u00e4\u00b7wer\u00b7dre\u00b7wen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "FM", "FM", "FM", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.5": {"text": "Den Papa taum Schawernack", "tokens": ["Den", "Pa\u00b7pa", "taum", "Scha\u00b7wer\u00b7nack"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ADV", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Ded hei m\u00e4nn'gen dummen Snack.", "tokens": ["Ded", "hei", "m\u00e4nn'\u00b7gen", "dum\u00b7men", "Snack", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "ADJA", "ADJA", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.12": {"line.1": {"text": "Un de gned'ge Herr von Degen", "tokens": ["Un", "de", "gne\u00b7d'\u00b7ge", "Herr", "von", "De\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "NE", "ADJA", "NN", "APPR", "NN"], "meter": "+-++-+-+-", "measure": "unknown.measure.penta"}, "line.2": {"text": "M\u00fc\u00dft sick \u00fcmmer sihr von wegen", "tokens": ["M\u00fc\u00dft", "sick", "\u00fcm\u00b7mer", "sihr", "von", "we\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["FM.fr", "FM.fr", "FM.fr", "FM.fr", "APPR", "APPR"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Sine D\u00e4mlichkeit schanieren,", "tokens": ["Si\u00b7ne", "D\u00e4m\u00b7lich\u00b7keit", "scha\u00b7nie\u00b7ren", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Let em nich mihr mit sick f\u00fchren,", "tokens": ["Let", "em", "nich", "mihr", "mit", "sick", "f\u00fch\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["XY", "XY", "PTKNEG", "ADV", "APPR", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Wenn hei utwarts beden wir.", "tokens": ["Wenn", "hei", "ut\u00b7warts", "be\u00b7den", "wir", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "ADV", "VVFIN", "PPER", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.6": {"text": "\u00bbkarl, mein Sohn, du bleibst heut hier.\u00ab", "tokens": ["\u00bb", "karl", ",", "mein", "Sohn", ",", "du", "bleibst", "heut", "hier", ".", "\u00ab"], "token_info": ["punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "NE", "$,", "PPOSAT", "NN", "$,", "PPER", "VVFIN", "ADV", "ADV", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Bi de gned'ge Fru von Degen", "tokens": ["Bi", "de", "gne\u00b7d'\u00b7ge", "Fru", "von", "De\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "NE", "ADJA", "NN", "APPR", "NN"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "W\u00fcrd de Mutterschaft sick r\u00f6gen;", "tokens": ["W\u00fcrd", "de", "Mut\u00b7ter\u00b7schaft", "sick", "r\u00f6\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NE", "NN", "ADJD", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Sei m\u00fc\u00dft \u00e4wer ehren armen,", "tokens": ["Sei", "m\u00fc\u00dft", "\u00e4\u00b7wer", "eh\u00b7ren", "ar\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAIMP", "VMFIN", "ADJD", "VVINF", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "S\u00e4uten K\u00f6rling sick erbarmen.", "tokens": ["S\u00e4u\u00b7ten", "K\u00f6r\u00b7ling", "sick", "er\u00b7bar\u00b7men", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ADJD", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "\u00bbwie die V\u00e4ter hart doch sind!", "tokens": ["\u00bb", "wie", "die", "V\u00e4\u00b7ter", "hart", "doch", "sind", "!"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOKOM", "ART", "NN", "ADJD", "ADV", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Oh, mon cher, nimm mit das Kind!\u00ab", "tokens": ["Oh", ",", "mon", "cher", ",", "nimm", "mit", "das", "Kind", "!", "\u00ab"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["ITJ", "$,", "NE", "NE", "$,", "VVIMP", "APPR", "ART", "NN", "$.", "$("], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.14": {"line.1": {"text": "Korl, de kreg nu \u00c4werwater,", "tokens": ["Korl", ",", "de", "kreg", "nu", "\u00c4\u00b7wer\u00b7wa\u00b7ter", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "FM.la", "FM.la", "FM.la", "FM.la", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Rohrte as en Br\u00f6llenkater,", "tokens": ["Rohr\u00b7te", "as", "en", "Br\u00f6l\u00b7len\u00b7ka\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["FM", "FM", "FM", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "As wenn hei up't Spitt ded steken,", "tokens": ["As", "wenn", "hei", "up't", "Spitt", "ded", "ste\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KOUS", "FM", "FM", "FM", "FM", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ded ok allens Gauds verspreken:", "tokens": ["Ded", "ok", "al\u00b7lens", "Gauds", "ver\u00b7spre\u00b7ken", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "\u00bbwill mi duken as en Hauhn,", "tokens": ["\u00bb", "will", "mi", "du\u00b7ken", "as", "en", "Hauhn", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VMFIN", "FM", "FM", "FM", "FM", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Will ok nich dat Mul updauhn.\u00ab", "tokens": ["Will", "ok", "nich", "dat", "Mul", "up\u00b7dauhn", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VMFIN", "ADV", "PTKNEG", "ART", "NN", "VVINF", "$.", "$("], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.15": {"line.1": {"text": "Na, genaug, de Herr von Degen", "tokens": ["Na", ",", "ge\u00b7naug", ",", "de", "Herr", "von", "De\u00b7gen"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["ITJ", "$,", "VVFIN", "$,", "NE", "NN", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Hett nich sinen Willen kregen,", "tokens": ["Hett", "nich", "si\u00b7nen", "Wil\u00b7len", "kre\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKNEG", "ADJA", "NN", "VVINF", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Korlen w\u00fcrd en reinen Kragen", "tokens": ["Kor\u00b7len", "w\u00fcrd", "en", "rei\u00b7nen", "Kra\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "VAFIN", "FM", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Un 'ne reine B\u00fcx antagen", "tokens": ["Un", "'ne", "rei\u00b7ne", "B\u00fcx", "an\u00b7ta\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "ART", "ADJA", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Un dat Hor em rutemutzt", "tokens": ["Un", "dat", "Hor", "em", "ru\u00b7te\u00b7mutzt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Un de N\u00e4s' em sauber putzt.", "tokens": ["Un", "de", "N\u00e4s'", "em", "sau\u00b7ber", "putzt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.16": {"line.1": {"text": "As nu allens in Ordnung sch\u00f6n,", "tokens": ["As", "nu", "al\u00b7lens", "in", "Ord\u00b7nung", "sch\u00f6n", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "ADV", "APPR", "NN", "ADJD", "$,"], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.2": {"text": "Reis't de Vader mit den S\u00e4hn,", "tokens": ["Reis't", "de", "Va\u00b7der", "mit", "den", "S\u00e4hn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "NE", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Un Papa, de s\u00e4d: \u00bbMein S\u00f6hnchen,", "tokens": ["Un", "Pa\u00b7pa", ",", "de", "s\u00e4d", ":", "\u00bb", "Mein", "S\u00f6hn\u00b7chen", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "FM.la", "FM.la", "$.", "$(", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Nun schweig heut auch still recht sch\u00f6nchen,", "tokens": ["Nun", "schweig", "heut", "auch", "still", "recht", "sch\u00f6n\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "ADV", "ADJD", "ADJD", "VVINF", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Gar kein Sterbensw\u00f6rtchen sprich!", "tokens": ["Gar", "kein", "Ster\u00b7bens\u00b7w\u00f6rt\u00b7chen", "sprich", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Schweigen, das verr\u00e4t dich nich.\u00ab", "tokens": ["Schwei\u00b7gen", ",", "das", "ver\u00b7r\u00e4t", "dich", "nich", ".", "\u00ab"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "$,", "PDS", "VVFIN", "PPER", "PTKNEG", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.17": {"line.1": {"text": "Bald s\u00fcnd sei nu bi dat Eten.", "tokens": ["Bald", "s\u00fcnd", "sei", "nu", "bi", "dat", "E\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VAFIN", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Korl hett mang twei Damen seten,", "tokens": ["Korl", "hett", "mang", "twei", "Da\u00b7men", "se\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "FM", "FM", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Recht so'n por l\u00fctt drift'ge Dirns,", "tokens": ["Recht", "so'n", "por", "l\u00fctt", "drift'\u00b7ge", "Dirns", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Recht so'n Heweltaschen wiren s',", "tokens": ["Recht", "so'n", "He\u00b7wel\u00b7ta\u00b7schen", "wi\u00b7ren", "s'", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "VAFIN", "NE", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.5": {"text": "Wiren ut 'ne grote Stadt,", "tokens": ["Wi\u00b7ren", "ut", "'ne", "gro\u00b7te", "Stadt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Redten glik von dit un dat;", "tokens": ["Red\u00b7ten", "glik", "von", "dit", "un", "dat", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "APPR", "FM", "FM", "FM", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.18": {"line.1": {"text": "Von Theater, Ball un Weder,", "tokens": ["Von", "The\u00b7a\u00b7ter", ",", "Ball", "un", "We\u00b7der", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "FM", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Von de Lust in grote St\u00e4der.", "tokens": ["Von", "de", "Lust", "in", "gro\u00b7te", "St\u00e4\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "NN", "APPR", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Fang'n ok an mit Korl tau reden.", "tokens": ["Fang'n", "ok", "an", "mit", "Korl", "tau", "re\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "APPR", "APPR", "NE", "NE", "VVINF", "$."], "meter": "+-+--+--", "measure": "trochaic.tri.relaxed"}, "line.4": {"text": "Korl denkt: Lat't mi man taufreden!", "tokens": ["Korl", "denkt", ":", "Lat't", "mi", "man", "tauf\u00b7re\u00b7den", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "$.", "NE", "NE", "PIS", "VVINF", "$."], "meter": "--+--+--", "measure": "anapaest.di.plus"}, "line.5": {"text": "Antwurt' drup nich Swart noch Witt,", "tokens": ["Ant\u00b7wurt'", "drup", "nich", "Swart", "noch", "Witt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "PTKNEG", "NE", "ADV", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Vader nimmt em s\u00fcs nich mit.", "tokens": ["Va\u00b7der", "nimmt", "em", "s\u00fcs", "nich", "mit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.19": {"line.1": {"text": "As de beiden l\u00fctten Damen", "tokens": ["As", "de", "bei\u00b7den", "l\u00fct\u00b7ten", "Da\u00b7men"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "NE", "PIAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Gor kein Wurd von em vernamen,", "tokens": ["Gor", "kein", "Wurd", "von", "em", "ver\u00b7na\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PIAT", "NN", "APPR", "ADJA", "VVINF", "$,"], "meter": "---+--+-", "measure": "iambic.di.relaxed"}, "line.3": {"text": "Deiht de ein sick r\u00fcmmer b\u00fccken", "tokens": ["Deiht", "de", "ein", "sick", "r\u00fcm\u00b7mer", "b\u00fc\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Achter Korlen sinen R\u00fcggen.", "tokens": ["Ach\u00b7ter", "Kor\u00b7len", "si\u00b7nen", "R\u00fcg\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "\u00bbnein, Sophie, der Mensch ist stumm,", "tokens": ["\u00bb", "nein", ",", "So\u00b7phie", ",", "der", "Mensch", "ist", "stumm", ","], "token_info": ["punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PTKANT", "$,", "NE", "$,", "ART", "NN", "VAFIN", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Oder er ist schrecklich dumm.\u00ab", "tokens": ["O\u00b7der", "er", "ist", "schreck\u00b7lich", "dumm", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "PPER", "VAFIN", "ADJD", "ADJD", "$.", "$("], "meter": "+---+-+", "measure": "dactylic.init"}}, "stanza.20": {"line.1": {"text": "Dat's man sch\u00f6n, denkt Korl von Degen,", "tokens": ["Dat's", "man", "sch\u00f6n", ",", "denkt", "Korl", "von", "De\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "PIS", "ADJD", "$,", "VVFIN", "NE", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Dat sei't endlich ruter kregen.", "tokens": ["Dat", "sei't", "end\u00b7lich", "ru\u00b7ter", "kre\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ADV", "ADJD", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "\u00bbne, Papa\u00ab, r\u00f6ppt hei ganz lud,", "tokens": ["\u00bb", "ne", ",", "Pa\u00b7pa", "\u00ab", ",", "r\u00f6ppt", "hei", "ganz", "lud", ","], "token_info": ["punct", "word", "punct", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "NE", "$,", "NN", "$(", "$,", "VVPP", "VAFIN", "ADV", "VVFIN", "$,"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.4": {"text": "\u00bbmit dat Swigen is dat ut;", "tokens": ["\u00bb", "mit", "dat", "Swi\u00b7gen", "is", "dat", "ut", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "ART", "NN", "FM", "FM", "FM", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Denn dat Fr\u00f6len rechtsch hir weit", "tokens": ["Denn", "dat", "Fr\u00f6\u00b7len", "rechtsch", "hir", "weit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "ADJD", "ADV", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Ganz genau von mi Bescheid.\u00ab", "tokens": ["Ganz", "ge\u00b7nau", "von", "mi", "Be\u00b7scheid", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "ADJD", "APPR", "NE", "NN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}