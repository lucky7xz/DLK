{"dta.poem.11556": {"metadata": {"author": {"name": "M\u00f6rike, Eduard", "birth": "N.A.", "death": "N.A."}, "title": "Des Schlossk\u00fcpers Geister zu T\u00fcbingen.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1838", "urn": "urn:nbn:de:kobv:b4-200905193969", "language": ["de:0.99"], "booktitle": "M\u00f6rike, Eduard: Gedichte. Stuttgart, 1838."}, "poem": {"stanza.1": {"line.1": {"text": "Da klingt schon viele Jahr kein Glas,", "tokens": ["Da", "klingt", "schon", "vie\u00b7le", "Jahr", "kein", "Glas", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "PIAT", "NN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Kein Kegel f\u00e4llt, keine Karten,", "tokens": ["Kein", "Ke\u00b7gel", "f\u00e4llt", ",", "kei\u00b7ne", "Kar\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "$,", "PIAT", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "W\u00e4chst aber sch\u00f6n lang Gras.", "tokens": ["W\u00e4chst", "a\u00b7ber", "sch\u00f6n", "lang", "Gras", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADJD", "ADJD", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Ich mutterseelalleine", "tokens": ["Ich", "mut\u00b7ter\u00b7see\u00b7lal\u00b7lei\u00b7ne"], "token_info": ["word", "word"], "pos": ["PPER", "VVFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Sazt' mich an einen langen Tisch;", "tokens": ["Sazt'", "mich", "an", "ei\u00b7nen", "lan\u00b7gen", "Tisch", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der Schlo\u00dfwirth regt die Beine,", "tokens": ["Der", "Schlo\u00df\u00b7wirth", "regt", "die", "Bei\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Vom Rothen bringt er frisch.", "tokens": ["Vom", "Ro\u00b7then", "bringt", "er", "frisch", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Und l\u00e4\u00dft sich zu mir nieder;", "tokens": ["Und", "l\u00e4\u00dft", "sich", "zu", "mir", "nie\u00b7der", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "APPR", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Von alten Zeiten red't man viel,", "tokens": ["Von", "al\u00b7ten", "Zei\u00b7ten", "red't", "man", "viel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "PIS", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Man seufzet hin und wieder;", "tokens": ["Man", "seuf\u00b7zet", "hin", "und", "wie\u00b7der", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PTKVZ", "KON", "ADV", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Der Sch\u00f6pplein wird kein Ziel.", "tokens": ["Der", "Sch\u00f6p\u00b7plein", "wird", "kein", "Ziel", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PIAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Da nun der Tag gegangen,", "tokens": ["Da", "nun", "der", "Tag", "ge\u00b7gan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Der Schlo\u00dfwirth sagt kein W\u00f6rtlein mehr;", "tokens": ["Der", "Schlo\u00df\u00b7wirth", "sagt", "kein", "W\u00f6rt\u00b7lein", "mehr", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PIAT", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Neun Lichter th\u00e4t er langen,", "tokens": ["Neun", "Lich\u00b7ter", "th\u00e4t", "er", "lan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "VVFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Neun St\u00fchle sezt er her.", "tokens": ["Neun", "St\u00fch\u00b7le", "sezt", "er", "her", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Als wie zum gr\u00f6\u00dften Feste", "tokens": ["Als", "wie", "zum", "gr\u00f6\u00df\u00b7ten", "Fes\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "KOKOM", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Auftischt er, da\u00df die Tafel kracht:", "tokens": ["Auf\u00b7tischt", "er", ",", "da\u00df", "die", "Ta\u00b7fel", "kracht", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "KOUS", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Was k\u00e4men noch f\u00fcr G\u00e4ste?", "tokens": ["Was", "k\u00e4\u00b7men", "noch", "f\u00fcr", "G\u00e4s\u00b7te", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ADV", "APPR", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Ist doch schier Mitternacht!", "tokens": ["Ist", "doch", "schier", "Mit\u00b7ter\u00b7nacht", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Der Narr, was kann er wollen?", "tokens": ["Der", "Narr", ",", "was", "kann", "er", "wol\u00b7len", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PWS", "VMFIN", "PPER", "VMFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Er macht sich an die Kugelbahn,", "tokens": ["Er", "macht", "sich", "an", "die", "Ku\u00b7gel\u00b7bahn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "L\u00e4\u00dft eine Kugel rollen,", "tokens": ["L\u00e4\u00dft", "ei\u00b7ne", "Ku\u00b7gel", "rol\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Ein H\u00f6llenl\u00e4rm geht an.", "tokens": ["Ein", "H\u00f6l\u00b7len\u00b7l\u00e4rm", "geht", "an", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Es fahren gar behende", "tokens": ["Es", "fah\u00b7ren", "gar", "be\u00b7hen\u00b7de"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "ADJA"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Acht Kegel hinter'm Brett herauf,", "tokens": ["Acht", "Ke\u00b7gel", "hin\u00b7ter'm", "Brett", "her\u00b7auf", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "APPRART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Schrei'n: Hagel und kein Ende!", "tokens": ["Schrei'n", ":", "Ha\u00b7gel", "und", "kein", "En\u00b7de", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "NN", "KON", "PIAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Wer Teufel weckt uns auf?", "tokens": ["Wer", "Teu\u00b7fel", "weckt", "uns", "auf", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Und waren acht Studiosen,", "tokens": ["Und", "wa\u00b7ren", "acht", "Stu\u00b7di\u00b7o\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "CARD", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Wohl aus der Zopf- und Puderzeit:", "tokens": ["Wohl", "aus", "der", "Zopf", "und", "Pu\u00b7der\u00b7zeit", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "TRUNC", "KON", "NN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Rothe R\u00f6cklein, kurze Hosen,", "tokens": ["Ro\u00b7the", "R\u00f6ck\u00b7lein", ",", "kur\u00b7ze", "Ho\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und ganz charmante Leut'.", "tokens": ["Und", "ganz", "char\u00b7man\u00b7te", "Leut'", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJA", "NN", "$."], "meter": "--+--+", "measure": "anapaest.di.plus"}}, "stanza.9": {"line.1": {"text": "Die sehen mit Ergetzen", "tokens": ["Die", "se\u00b7hen", "mit", "Er\u00b7get\u00b7zen"], "token_info": ["word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "APPR", "NN"], "meter": "-+--+--", "measure": "iambic.di.relaxed"}, "line.2": {"text": "Den edelen Karfunkelwein,", "tokens": ["Den", "e\u00b7de\u00b7len", "Kar\u00b7fun\u00b7kel\u00b7wein", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Gleich th\u00e4ten sie sich letzen", "tokens": ["Gleich", "th\u00e4\u00b7ten", "sie", "sich", "let\u00b7zen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und zechen und juchhein.", "tokens": ["Und", "ze\u00b7chen", "und", "juch\u00b7hein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "KON", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "Den Wirth erbaut das wenig;", "tokens": ["Den", "Wirth", "er\u00b7baut", "das", "we\u00b7nig", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "PIS", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Er sprach: Ihr Herren, wollt verzeihn:", "tokens": ["Er", "sprach", ":", "Ihr", "Her\u00b7ren", ",", "wollt", "ver\u00b7zeihn", ":"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "PPOSAT", "NN", "$,", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wo ist der Schoppenk\u00f6nig?", "tokens": ["Wo", "ist", "der", "Schop\u00b7pen\u00b7k\u00f6\u00b7nig", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Wann seyd Ihr denn zu Neun?", "tokens": ["Wann", "seyd", "Ihr", "denn", "zu", "Neun", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PPER", "ADV", "APPR", "CARD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "Ach K\u00fcper, lieber K\u00fcper!", "tokens": ["Ach", "K\u00fc\u00b7per", ",", "lie\u00b7ber", "K\u00fc\u00b7per", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ITJ", "NN", "$,", "ADV", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Wie machest uns das Herze schwer!", "tokens": ["Wie", "ma\u00b7chest", "uns", "das", "Her\u00b7ze", "schwer", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "PDS", "VVFIN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wohl funfzig Jahr und dr\u00fcber", "tokens": ["Wohl", "funf\u00b7zig", "Jahr", "und", "dr\u00fc\u00b7ber"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "CARD", "NN", "KON", "PAV"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Begraben lieget er.", "tokens": ["Be\u00b7gra\u00b7ben", "lie\u00b7get", "er", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "Gott hab' den Herren selig,", "tokens": ["Gott", "hab'", "den", "Her\u00b7ren", "se\u00b7lig", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ART", "NN", "ADJD", "$,"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.2": {"text": "Mit seiner rothen Habichtsnas'!", "tokens": ["Mit", "sei\u00b7ner", "ro\u00b7then", "Ha\u00b7bichts\u00b7nas'", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Regierete so fr\u00f6hlich,", "tokens": ["Re\u00b7gie\u00b7re\u00b7te", "so", "fr\u00f6h\u00b7lich", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADJD", "$,"], "meter": "-+---+-", "measure": "dactylic.init"}, "line.4": {"text": "Kam Tags auf sieben Ma\u00df.", "tokens": ["Kam", "Tags", "auf", "sie\u00b7ben", "Ma\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "APPR", "CARD", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.13": {"line.1": {"text": "Einst th\u00e4t er uns bescheiden,", "tokens": ["Einst", "th\u00e4t", "er", "uns", "be\u00b7schei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "ADJD", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Sprach: M\u00e4nniglich kennt mein Gebot:", "tokens": ["Sprach", ":", "M\u00e4n\u00b7nig\u00b7lich", "kennt", "mein", "Ge\u00b7bot", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "NN", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "Den Gerstensaft zu meiden;", "tokens": ["Den", "Gers\u00b7ten\u00b7saft", "zu", "mei\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Man b\u00fc\u00dfet's mit dem Tod.", "tokens": ["Man", "b\u00fc\u00b7\u00dfet's", "mit", "dem", "Tod", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+---+", "measure": "dactylic.init"}}, "stanza.14": {"line.1": {"text": "Mit ein paar lausigen Dichtern", "tokens": ["Mit", "ein", "paar", "lau\u00b7si\u00b7gen", "Dich\u00b7tern"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "PIAT", "ADJA", "NN"], "meter": "--++--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Traf man beim sauren Bier euch an,", "tokens": ["Traf", "man", "beim", "sau\u00b7ren", "Bier", "euch", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "APPRART", "ADJA", "NN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Versteht sich, nudeln\u00fcchtern,", "tokens": ["Ver\u00b7steht", "sich", ",", "nu\u00b7del\u00b7n\u00fcch\u00b7tern", ","], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["VVFIN", "PRF", "$,", "ADV", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Wohl auf der Kugelbahn.", "tokens": ["Wohl", "auf", "der", "Ku\u00b7gel\u00b7bahn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.15": {"line.1": {"text": "Kommt also her, ihr L\u00fcmmel!", "tokens": ["Kommt", "al\u00b7so", "her", ",", "ihr", "L\u00fcm\u00b7mel", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVIMP", "ADV", "PTKVZ", "$,", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "\u2014 Er zog sein' Zauberstab herf\u00fcr \u2014", "tokens": ["Er", "zog", "sein'", "Zau\u00b7ber\u00b7stab", "her\u00b7f\u00fcr"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "PPOSAT", "NN", "ADV", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wir st\u00fcrzten wie vom Himmel \u2014", "tokens": ["Wir", "st\u00fcrz\u00b7ten", "wie", "vom", "Him\u00b7mel"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KOKOM", "APPRART", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Acht Kegel waren wir!", "tokens": ["Acht", "Ke\u00b7gel", "wa\u00b7ren", "wir", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "VAFIN", "PPER", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.16": {"line.1": {"text": "Jezt ging es an ein Hudeln,", "tokens": ["Jezt", "ging", "es", "an", "ein", "Hu\u00b7deln", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Einen h\u00f6lzern K\u00f6nig man uns gab,", "tokens": ["Ei\u00b7nen", "h\u00f6l\u00b7zern", "K\u00f6\u00b7nig", "man", "uns", "gab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PIS", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Doch scho\u00df man nichts wie Pudel,", "tokens": ["Doch", "scho\u00df", "man", "nichts", "wie", "Pu\u00b7del", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIS", "PIS", "KOKOM", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Da schafften sie uns ab. \u2014", "tokens": ["Da", "schaff\u00b7ten", "sie", "uns", "ab", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "PTKVZ", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.17": {"line.1": {"text": "Nun dauert es nicht lange,", "tokens": ["Nun", "dau\u00b7ert", "es", "nicht", "lan\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PTKNEG", "ADV", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "So zieht das Burschenvolk einmal", "tokens": ["So", "zieht", "das", "Bur\u00b7schen\u00b7volk", "ein\u00b7mal"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Auf's Schlo\u00df mit wildem Sange,", "tokens": ["Auf's", "Schlo\u00df", "mit", "wil\u00b7dem", "San\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Zum K\u00f6nig in den Saal:", "tokens": ["Zum", "K\u00f6\u00b7nig", "in", "den", "Saal", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.18": {"line.1": {"text": "Wir woll'n dich Lands verweisen,", "tokens": ["Wir", "woll'n", "dich", "Lands", "ver\u00b7wei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "NN", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "So du nicht schw\u00f6rest ab den Wein;", "tokens": ["So", "du", "nicht", "schw\u00f6\u00b7rest", "ab", "den", "Wein", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "PTKNEG", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Bierk\u00f6nig sollt du hei\u00dfen!", "tokens": ["Bier\u00b7k\u00f6\u00b7nig", "sollt", "du", "hei\u00b7\u00dfen", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VMFIN", "PPER", "VVINF", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.4": {"text": "\u2014 Er aber saget: Nein;", "tokens": ["Er", "a\u00b7ber", "sa\u00b7get", ":", "Nein", ";"], "token_info": ["punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["$(", "PPER", "ADV", "VVFIN", "$.", "PTKANT", "$."], "meter": "+-+---", "measure": "unknown.measure.di"}}, "stanza.19": {"line.1": {"text": "Da habt ihr meine Krone!", "tokens": ["Da", "habt", "ihr", "mei\u00b7ne", "Kro\u00b7ne", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "An mir ist Hopfen und Malz verlor'n. \u2014", "tokens": ["An", "mir", "ist", "Hop\u00b7fen", "und", "Malz", "ver\u00b7lor'", "n."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "abbreviation", "punct"], "pos": ["APPR", "PPER", "VAFIN", "NN", "KON", "NE", "NE", "NE", "$("], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.3": {"text": "So stieg er von dem Throne", "tokens": ["So", "stieg", "er", "von", "dem", "Thro\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "In seinem edlen Zorn.", "tokens": ["In", "sei\u00b7nem", "ed\u00b7len", "Zorn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.20": {"line.1": {"text": "F\u00fcr Kummer und f\u00fcr Gr\u00e4men", "tokens": ["F\u00fcr", "Kum\u00b7mer", "und", "f\u00fcr", "Gr\u00e4\u00b7men"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "APPR", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Der Herre wurde krank und alt,", "tokens": ["Der", "Her\u00b7re", "wur\u00b7de", "krank", "und", "alt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Zerfiele wie ein Schemen", "tokens": ["Zer\u00b7fie\u00b7le", "wie", "ein", "Sche\u00b7men"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "KOKOM", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und holt der Tod ihn bald.", "tokens": ["Und", "holt", "der", "Tod", "ihn", "bald", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "PPER", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.21": {"line.1": {"text": "Mit Purpur ward gezieret", "tokens": ["Mit", "Pur\u00b7pur", "ward", "ge\u00b7zie\u00b7ret"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NN", "VAFIN", "VVPP"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Sein Leichnam als ein K\u00f6nig gro\u00df;", "tokens": ["Sein", "Leich\u00b7nam", "als", "ein", "K\u00f6\u00b7nig", "gro\u00df", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KOKOM", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ein tief Gew\u00f6lb man f\u00fchret", "tokens": ["Ein", "tief", "Ge\u00b7w\u00f6lb", "man", "f\u00fch\u00b7ret"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJD", "NN", "PIS", "VVFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Zu T\u00fcwingen im Schlo\u00df.", "tokens": ["Zu", "T\u00fc\u00b7win\u00b7gen", "im", "Schlo\u00df", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPRART", "NN", "$."], "meter": "--+--+", "measure": "anapaest.di.plus"}}, "stanza.22": {"line.1": {"text": "Vier schwarze Edelknaben", "tokens": ["Vier", "schwar\u00b7ze", "E\u00b7del\u00b7kna\u00b7ben"], "token_info": ["word", "word", "word"], "pos": ["CARD", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Sein' Becher trugen vor der Bahr';", "tokens": ["Sein'", "Be\u00b7cher", "tru\u00b7gen", "vor", "der", "Bahr'", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der ist mit ihm begraben,", "tokens": ["Der", "ist", "mit", "ihm", "be\u00b7gra\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "APPR", "PPER", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "War doch von Golde gar.", "tokens": ["War", "doch", "von", "Gol\u00b7de", "gar", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "APPR", "NE", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.23": {"line.1": {"text": "Damal ward prophezeihet:", "tokens": ["Da\u00b7mal", "ward", "pro\u00b7phe\u00b7zei\u00b7het", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Wenn nur erst hundert Jahr herum,", "tokens": ["Wenn", "nur", "erst", "hun\u00b7dert", "Jahr", "he\u00b7rum", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ADV", "CARD", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da w\u00fcrd' der Thron erneuet", "tokens": ["Da", "w\u00fcrd'", "der", "Thron", "er\u00b7neu\u00b7et"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ART", "NN", "VVFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Vom alten K\u00f6nigthum.", "tokens": ["Vom", "al\u00b7ten", "K\u00f6\u00b7nig\u00b7thum", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.24": {"line.1": {"text": "So m\u00fcssen wir halt warten,", "tokens": ["So", "m\u00fcs\u00b7sen", "wir", "halt", "war\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "VVFIN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Bis da\u00df die Zeit erf\u00fcllet was;", "tokens": ["Bis", "da\u00df", "die", "Zeit", "er\u00b7f\u00fcl\u00b7let", "was", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "KOUS", "ART", "NN", "VVFIN", "PIS", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und in des Schlo\u00dfwirths Garten", "tokens": ["Und", "in", "des", "Schlo\u00df\u00b7wirths", "Gar\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Derweil w\u00e4chst langes Gras.", "tokens": ["Der\u00b7weil", "w\u00e4chst", "lan\u00b7ges", "Gras", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.25": {"line.1": {"text": "Ach K\u00fcper, lieber K\u00fcper!", "tokens": ["Ach", "K\u00fc\u00b7per", ",", "lie\u00b7ber", "K\u00fc\u00b7per", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ITJ", "NN", "$,", "ADV", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Jezt geige du uns wieder heim!", "tokens": ["Jezt", "gei\u00b7ge", "du", "uns", "wie\u00b7der", "heim", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die Nacht ist schier vor\u00fcber:", "tokens": ["Die", "Nacht", "ist", "schier", "vor\u00b7\u00fc\u00b7ber", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Acht Kegel m\u00fcssen wir seyn.", "tokens": ["Acht", "Ke\u00b7gel", "m\u00fcs\u00b7sen", "wir", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "VMFIN", "PPER", "VAINF", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.26": {"line.1": {"text": "Der Schlo\u00dfwirth nimmt die Geigen", "tokens": ["Der", "Schlo\u00df\u00b7wirth", "nimmt", "die", "Gei\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Und streicht ein ", "tokens": ["Und", "streicht", "ein"], "token_info": ["word", "word", "word"], "pos": ["KON", "VVFIN", "ART"], "meter": "-+-", "measure": "amphibrach.single"}, "line.3": {"text": "Sie tanzen einen Reigen", "tokens": ["Sie", "tan\u00b7zen", "ei\u00b7nen", "Rei\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und Keiner ist mehr da.", "tokens": ["Und", "Kei\u00b7ner", "ist", "mehr", "da", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VAFIN", "ADV", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}}}}