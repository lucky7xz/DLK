{"textgrid.poem.52844": {"metadata": {"author": {"name": "Eichrodt, Ludwig", "birth": "N.A.", "death": "N.A."}, "title": "Berlin", "genre": "verse", "period": "N.A.", "pub_year": 1859, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Berlin ist eine gute Stadt", "tokens": ["Ber\u00b7lin", "ist", "ei\u00b7ne", "gu\u00b7te", "Stadt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "VAFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Im k\u00f6niglichen Preu\u00dfen,", "tokens": ["Im", "k\u00f6\u00b7nig\u00b7li\u00b7chen", "Preu\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Die Polizei, die sich dort hat,", "tokens": ["Die", "Po\u00b7li\u00b7zei", ",", "die", "sich", "dort", "hat", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PRF", "ADV", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wei\u00df Alles zu beweisen.", "tokens": ["Wei\u00df", "Al\u00b7les", "zu", "be\u00b7wei\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Das Bier daselbst ist nabelblond,", "tokens": ["Das", "Bier", "da\u00b7selbst", "ist", "na\u00b7bel\u00b7blond", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PAV", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Schnaps wird \u00fcbertrieben,", "tokens": ["Der", "Schnaps", "wird", "\u00fc\u00b7bert\u00b7rie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Doch diesen bin ich nicht gewohnt,", "tokens": ["Doch", "die\u00b7sen", "bin", "ich", "nicht", "ge\u00b7wohnt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VAFIN", "PPER", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Obschon ich ihn thu lieben.", "tokens": ["Ob\u00b7schon", "ich", "ihn", "thu", "lie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "VVFIN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Dort wei\u00df der Mensch nicht, wie ein Fluch", "tokens": ["Dort", "wei\u00df", "der", "Mensch", "nicht", ",", "wie", "ein", "Fluch"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "PTKNEG", "$,", "PWAV", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dem Menschen 's Herz erleichtert;", "tokens": ["Dem", "Men\u00b7schen", "'s", "Herz", "er\u00b7leich\u00b7tert", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPER", "NN", "VVPP", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Ich kann nicht reden wie ein Buch,", "tokens": ["Ich", "kann", "nicht", "re\u00b7den", "wie", "ein", "Buch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PTKNEG", "VVINF", "KOKOM", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Bin ich 'mal anjefeuchtet.", "tokens": ["Bin", "ich", "'mal", "an\u00b7je\u00b7feuch\u00b7tet", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Wen sein Gesandter dort nicht kennt,", "tokens": ["Wen", "sein", "Ge\u00b7sand\u00b7ter", "dort", "nicht", "kennt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPOSAT", "NN", "ADV", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Den kennt nicht der Berliner,", "tokens": ["Den", "kennt", "nicht", "der", "Ber\u00b7li\u00b7ner", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PTKNEG", "ART", "ADJA", "$,"], "meter": "-+--+--", "measure": "iambic.di.relaxed"}, "line.3": {"text": "Drum mach' ihm gleich dein Kompliment", "tokens": ["Drum", "mach'", "ihm", "gleich", "dein", "Kom\u00b7pli\u00b7ment"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "PPER", "ADV", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und sprich g'horsamer Diener!", "tokens": ["Und", "sprich", "g'\u00b7hor\u00b7sa\u00b7mer", "Die\u00b7ner", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "ADJA", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.5": {"line.1": {"text": "Das Milit\u00e4r und die Kavallerie", "tokens": ["Das", "Mi\u00b7li\u00b7t\u00e4r", "und", "die", "Ka\u00b7val\u00b7le\u00b7rie"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "KON", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Ist dort die einzig Hauptsach,", "tokens": ["Ist", "dort", "die", "ein\u00b7zig", "Haupt\u00b7sach", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "ADJD", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und Philosophie und Menagerie,", "tokens": ["Und", "Phi\u00b7lo\u00b7so\u00b7phie", "und", "Me\u00b7na\u00b7ge\u00b7rie", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "KON", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "O du allm\u00e4chtiger Strohsack!", "tokens": ["O", "du", "all\u00b7m\u00e4ch\u00b7ti\u00b7ger", "Stroh\u00b7sack", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "ADJA", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.6": {"line.1": {"text": "Berlin ist eine gute Stadt", "tokens": ["Ber\u00b7lin", "ist", "ei\u00b7ne", "gu\u00b7te", "Stadt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "VAFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Im k\u00f6niglichen Preu\u00dfen,", "tokens": ["Im", "k\u00f6\u00b7nig\u00b7li\u00b7chen", "Preu\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Die Polizei, die sich dort hat,", "tokens": ["Die", "Po\u00b7li\u00b7zei", ",", "die", "sich", "dort", "hat", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PRF", "ADV", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wei\u00df Alles zu beweisen.", "tokens": ["Wei\u00df", "Al\u00b7les", "zu", "be\u00b7wei\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Das Bier daselbst ist nabelblond,", "tokens": ["Das", "Bier", "da\u00b7selbst", "ist", "na\u00b7bel\u00b7blond", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PAV", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Schnaps wird \u00fcbertrieben,", "tokens": ["Der", "Schnaps", "wird", "\u00fc\u00b7bert\u00b7rie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Doch diesen bin ich nicht gewohnt,", "tokens": ["Doch", "die\u00b7sen", "bin", "ich", "nicht", "ge\u00b7wohnt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VAFIN", "PPER", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Obschon ich ihn thu lieben.", "tokens": ["Ob\u00b7schon", "ich", "ihn", "thu", "lie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "VVFIN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Dort wei\u00df der Mensch nicht, wie ein Fluch", "tokens": ["Dort", "wei\u00df", "der", "Mensch", "nicht", ",", "wie", "ein", "Fluch"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "PTKNEG", "$,", "PWAV", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dem Menschen 's Herz erleichtert;", "tokens": ["Dem", "Men\u00b7schen", "'s", "Herz", "er\u00b7leich\u00b7tert", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPER", "NN", "VVPP", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Ich kann nicht reden wie ein Buch,", "tokens": ["Ich", "kann", "nicht", "re\u00b7den", "wie", "ein", "Buch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PTKNEG", "VVINF", "KOKOM", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Bin ich 'mal anjefeuchtet.", "tokens": ["Bin", "ich", "'mal", "an\u00b7je\u00b7feuch\u00b7tet", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Wen sein Gesandter dort nicht kennt,", "tokens": ["Wen", "sein", "Ge\u00b7sand\u00b7ter", "dort", "nicht", "kennt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPOSAT", "NN", "ADV", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Den kennt nicht der Berliner,", "tokens": ["Den", "kennt", "nicht", "der", "Ber\u00b7li\u00b7ner", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PTKNEG", "ART", "ADJA", "$,"], "meter": "-+--+--", "measure": "iambic.di.relaxed"}, "line.3": {"text": "Drum mach' ihm gleich dein Kompliment", "tokens": ["Drum", "mach'", "ihm", "gleich", "dein", "Kom\u00b7pli\u00b7ment"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "PPER", "ADV", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und sprich g'horsamer Diener!", "tokens": ["Und", "sprich", "g'\u00b7hor\u00b7sa\u00b7mer", "Die\u00b7ner", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "ADJA", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.10": {"line.1": {"text": "Das Milit\u00e4r und die Kavallerie", "tokens": ["Das", "Mi\u00b7li\u00b7t\u00e4r", "und", "die", "Ka\u00b7val\u00b7le\u00b7rie"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "KON", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Ist dort die einzig Hauptsach,", "tokens": ["Ist", "dort", "die", "ein\u00b7zig", "Haupt\u00b7sach", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "ADJD", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und Philosophie und Menagerie,", "tokens": ["Und", "Phi\u00b7lo\u00b7so\u00b7phie", "und", "Me\u00b7na\u00b7ge\u00b7rie", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "KON", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "O du allm\u00e4chtiger Strohsack!", "tokens": ["O", "du", "all\u00b7m\u00e4ch\u00b7ti\u00b7ger", "Stroh\u00b7sack", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "ADJA", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}}}}