{"dta.poem.4221": {"metadata": {"author": {"name": "Brockes, Barthold Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "Die Morgen-R\u00f6hte.  \n Nach  \n Anleitung des  Spectacle de la Nature.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1743", "urn": "urn:nbn:de:kobv:b4-20083-6", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Die Morgen-Zeit ist gar zu sch\u00f6n! Unm\u00f6glich kann ich", "tokens": ["Die", "Mor\u00b7gen\u00b7Zeit", "ist", "gar", "zu", "sch\u00f6n", "!", "Un\u00b7m\u00f6g\u00b7lich", "kann", "ich"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ADV", "PTKA", "ADJD", "$.", "ADJD", "VMFIN", "PPER"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "mich entbrechen,", "tokens": ["mich", "ent\u00b7bre\u00b7chen", ","], "token_info": ["word", "word", "punct"], "pos": ["PPER", "VVINF", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "Von unsers Tages fr\u00fchen Wundern noch was betr\u00e4chtliches", "tokens": ["Von", "un\u00b7sers", "Ta\u00b7ges", "fr\u00fc\u00b7hen", "Wun\u00b7dern", "noch", "was", "be\u00b7tr\u00e4cht\u00b7li\u00b7ches"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "ADJA", "NN", "ADV", "PWS", "ADJA"], "meter": "-+-+-+-+-++-+-+", "measure": "unknown.measure.octa.plus"}, "line.4": {"text": "zu sprechen,", "tokens": ["zu", "spre\u00b7chen", ","], "token_info": ["word", "word", "punct"], "pos": ["PTKZU", "VVINF", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.5": {"text": "So wohl zu meines Sch\u00f6pfers Ruhm, und mir zur Lust, als", "tokens": ["So", "wohl", "zu", "mei\u00b7nes", "Sch\u00f6p\u00b7fers", "Ruhm", ",", "und", "mir", "zur", "Lust", ",", "als"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word"], "pos": ["ADV", "ADV", "APPR", "PPOSAT", "NN", "NN", "$,", "KON", "PPER", "APPRART", "NN", "$,", "KOUS"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "andre mehr", "tokens": ["and\u00b7re", "mehr"], "token_info": ["word", "word"], "pos": ["PIS", "ADV"], "meter": "+-+", "measure": "trochaic.di"}, "line.7": {"text": "Von einem Schlafe zu ermuntern, in welchem sie der Gottheit", "tokens": ["Von", "ei\u00b7nem", "Schla\u00b7fe", "zu", "er\u00b7mun\u00b7tern", ",", "in", "wel\u00b7chem", "sie", "der", "Got\u00b7theit"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "PTKZU", "VVINF", "$,", "APPR", "PRELS", "PPER", "ART", "NN"], "meter": "-+-+-+-+--+-+--+", "measure": "iambic.septa.relaxed"}, "line.8": {"text": "Ehr',", "tokens": ["Ehr'", ","], "token_info": ["word", "punct"], "pos": ["NN", "$,"], "meter": "+", "measure": "single.up"}, "line.9": {"text": "Sammt ihrer eignen Lust und Pflicht, zu welchen sie jedoch", "tokens": ["Sammt", "ih\u00b7rer", "eig\u00b7nen", "Lust", "und", "Pflicht", ",", "zu", "wel\u00b7chen", "sie", "je\u00b7doch"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "PPOSAT", "ADJA", "NN", "KON", "NN", "$,", "APPR", "PWAT", "PPER", "ADV"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.10": {"text": "erschaffen,", "tokens": ["er\u00b7schaf\u00b7fen", ","], "token_info": ["word", "punct"], "pos": ["VVPP", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.11": {"text": "In einer ungl\u00fccksel\u2019gen Tr\u00e4gheit, sehr oft verschnarchen und", "tokens": ["In", "ei\u00b7ner", "un\u00b7gl\u00fcck\u00b7sel'\u00b7gen", "Tr\u00e4g\u00b7heit", ",", "sehr", "oft", "ver\u00b7schnar\u00b7chen", "und"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "$,", "ADV", "ADV", "VVINF", "KON"], "meter": "-+-+-+-+--+-+-+", "measure": "iambic.septa.relaxed"}, "line.12": {"text": "verschlafen.", "tokens": ["ver\u00b7schla\u00b7fen", "."], "token_info": ["word", "punct"], "pos": ["VVPP", "$."], "meter": "-+-", "measure": "amphibrach.single"}}, "stanza.2": {"line.1": {"text": "Die Heyden, welche, mehr als wir, der hellen Fackel der", "tokens": ["Die", "Hey\u00b7den", ",", "wel\u00b7che", ",", "mehr", "als", "wir", ",", "der", "hel\u00b7len", "Fa\u00b7ckel", "der"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "$,", "ADV", "KOUS", "PPER", "$,", "ART", "ADJA", "NN", "ART"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.2": {"text": "Natur", "tokens": ["Na\u00b7tur"], "token_info": ["word"], "pos": ["NN"], "meter": "-+", "measure": "iambic.single"}, "line.3": {"text": "Bem\u00fchet waren nachzufolgen, und ihrer angenehmen", "tokens": ["Be\u00b7m\u00fc\u00b7het", "wa\u00b7ren", "nach\u00b7zu\u00b7fol\u00b7gen", ",", "und", "ih\u00b7rer", "an\u00b7ge\u00b7neh\u00b7men"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "VAFIN", "VVIZU", "$,", "KON", "PPOSAT", "ADJA"], "meter": "-+-+-+-+--+-+-+-", "measure": "iambic.septa.relaxed"}, "line.4": {"text": "Spuhr,", "tokens": ["Spuhr", ","], "token_info": ["word", "punct"], "pos": ["NN", "$,"], "meter": "+", "measure": "single.up"}, "line.5": {"text": "Vermogten nie Jdeen gnug, die Wunder-Werke zu ergr\u00fcn-", "tokens": ["Ver\u00b7mog\u00b7ten", "nie", "Jdeen", "gnug", ",", "die", "Wun\u00b7der\u00b7Wer\u00b7ke", "zu", "er\u00b7gr\u00fcn"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "NN", "ADV", "$,", "ART", "NN", "APPR", "TRUNC"], "meter": "-+--+--+-----+", "measure": "amphibrach.tri.plus"}, "line.6": {"text": "den,", "tokens": ["den", ","], "token_info": ["word", "punct"], "pos": ["ART", "$,"], "meter": "-", "measure": "single.down"}, "line.7": {"text": "Und, solche w\u00fcrdig abzuschildern, nicht Wort\u2019 und Bilder", "tokens": ["Und", ",", "sol\u00b7che", "w\u00fcr\u00b7dig", "ab\u00b7zu\u00b7schil\u00b7dern", ",", "nicht", "Wort'", "und", "Bil\u00b7der"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "$,", "PIAT", "ADJD", "VVIZU", "$,", "PTKNEG", "NN", "KON", "NN"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.8": {"text": "gnug zu finden.", "tokens": ["gnug", "zu", "fin\u00b7den", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "PTKZU", "VVINF", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.9": {"text": "Sie nenneten die ", "tokens": ["Sie", "nen\u00b7ne\u00b7ten", "die"], "token_info": ["word", "word", "word"], "pos": ["PPER", "VVFIN", "ART"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.10": {"text": "zarter Luft,", "tokens": ["zar\u00b7ter", "Luft", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.11": {"text": "Umh\u00fcllt mit einem bunten Schleyer von Purpur- farb- und", "tokens": ["Um\u00b7h\u00fcllt", "mit", "ei\u00b7nem", "bun\u00b7ten", "Schle\u00b7yer", "von", "Pur\u00b7pur", "fa\u00b7rb", "und"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "ART", "ADJA", "NN", "APPR", "TRUNC", "TRUNC", "KON"], "meter": "-+-+-+--+-+-+--", "measure": "iambic.hexa.relaxed"}, "line.12": {"text": "g\u00fcldnem Duft,", "tokens": ["g\u00fcld\u00b7nem", "Duft", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$,"], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.3": {"line.1": {"text": "Die das bestrahlte Morgen-Thor mit Rosen- farbner Hand", "tokens": ["Die", "das", "be\u00b7strahl\u00b7te", "Mor\u00b7gen\u00b7Thor", "mit", "Ro\u00b7sen", "farb\u00b7ner", "Hand"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ART", "ADJA", "NN", "APPR", "TRUNC", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.2": {"text": "entschliesset,", "tokens": ["ent\u00b7schlies\u00b7set", ","], "token_info": ["word", "punct"], "pos": ["VVFIN", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.3": {"text": "Die Luft mit linden Winden f\u00fcllt, und Perlen auf die Kr\u00e4uter", "tokens": ["Die", "Luft", "mit", "lin\u00b7den", "Win\u00b7den", "f\u00fcllt", ",", "und", "Per\u00b7len", "auf", "die", "Kr\u00e4u\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "ADJA", "NN", "VVFIN", "$,", "KON", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.4": {"text": "giesset,", "tokens": ["gies\u00b7set", ","], "token_info": ["word", "punct"], "pos": ["VVFIN", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.5": {"text": "Die alle Pflanzen tr\u00e4nkt und s\u00e4uget, aus deren Schritten", "tokens": ["Die", "al\u00b7le", "Pflan\u00b7zen", "tr\u00e4nkt", "und", "s\u00e4u\u00b7get", ",", "aus", "de\u00b7ren", "Schrit\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "PIAT", "NN", "VVFIN", "KON", "VVFIN", "$,", "APPR", "PRELAT", "NN"], "meter": "-+-+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "Bluhmen quillen,", "tokens": ["Bluh\u00b7men", "quil\u00b7len", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVINF", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.7": {"text": "Durch welche Luft und Meer und Land mit Leben, Licht und", "tokens": ["Durch", "wel\u00b7che", "Luft", "und", "Meer", "und", "Land", "mit", "Le\u00b7ben", ",", "Licht", "und"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "PWAT", "NN", "KON", "NN", "KON", "NN", "APPR", "NN", "$,", "NN", "KON"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Lust sich f\u00fcllen.", "tokens": ["Lust", "sich", "f\u00fcl\u00b7len", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PRF", "VVINF", "$."], "meter": "+-+-", "measure": "trochaic.di"}}, "stanza.4": {"line.1": {"text": "Nun sind zwar solche Stellen reizend, sind s\u00fc\u00df und ange-", "tokens": ["Nun", "sind", "zwar", "sol\u00b7che", "Stel\u00b7len", "rei\u00b7zend", ",", "sind", "s\u00fc\u00df", "und", "an\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ADV", "PIAT", "NN", "VVPP", "$,", "VAFIN", "ADJD", "KON", "TRUNC"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "nehm zu lesen;", "tokens": ["nehm", "zu", "le\u00b7sen", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "PTKZU", "VVINF", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "Jedoch gebrauchet die Natur dergleichen schlechten Schminke", "tokens": ["Je\u00b7doch", "ge\u00b7brau\u00b7chet", "die", "Na\u00b7tur", "derg\u00b7lei\u00b7chen", "schlech\u00b7ten", "Schmin\u00b7ke"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "PIS", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.4": {"text": "nicht.", "tokens": ["nicht", "."], "token_info": ["word", "punct"], "pos": ["PTKNEG", "$."], "meter": "-", "measure": "single.down"}, "line.5": {"text": "Es strahlt aus ihrer Wirklichkeit, es bricht aus ihrem eignen", "tokens": ["Es", "strahlt", "aus", "ih\u00b7rer", "Wirk\u00b7lich\u00b7keit", ",", "es", "bricht", "aus", "ih\u00b7rem", "eig\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN", "$,", "PPER", "VVFIN", "APPR", "PPOSAT", "ADJA"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.6": {"text": "Wesen", "tokens": ["We\u00b7sen"], "token_info": ["word"], "pos": ["NN"], "meter": "+-", "measure": "trochaic.single"}, "line.7": {"text": "Ein wesentlicher Wunder-Glanz, ein wahres eigenth\u00fcmlich", "tokens": ["Ein", "we\u00b7sent\u00b7li\u00b7cher", "Wun\u00b7der\u00b7Glanz", ",", "ein", "wah\u00b7res", "ei\u00b7gent\u00b7h\u00fcm\u00b7lich"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "ADJA", "NN"], "meter": "++---+-+-+-+-+-", "measure": "unknown.measure.septa"}, "line.8": {"text": "Licht,", "tokens": ["Licht", ","], "token_info": ["word", "punct"], "pos": ["NN", "$,"], "meter": "+", "measure": "single.up"}, "line.9": {"text": "Sie prangt mit eigner Majest\u00e4t, man siehet sie sich selber", "tokens": ["Sie", "prangt", "mit", "eig\u00b7ner", "Ma\u00b7jes\u00b7t\u00e4t", ",", "man", "sie\u00b7het", "sie", "sich", "sel\u00b7ber"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ADJA", "NN", "$,", "PIS", "VVFIN", "PPER", "PRF", "ADV"], "meter": "-+-+-+-+--+--+-", "measure": "iambic.hexa.relaxed"}, "line.10": {"text": "kr\u00f6nen,", "tokens": ["kr\u00f6\u00b7nen", ","], "token_info": ["word", "punct"], "pos": ["VVFIN", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.11": {"text": "Und darf sie, was sie selbst besitzt, von fremdem Schimmer", "tokens": ["Und", "darf", "sie", ",", "was", "sie", "selbst", "be\u00b7sitzt", ",", "von", "frem\u00b7dem", "Schim\u00b7mer"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "VMFIN", "PPER", "$,", "PRELS", "PPER", "ADV", "VVPP", "$,", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "nicht entlehnen.", "tokens": ["nicht", "ent\u00b7leh\u00b7nen", "."], "token_info": ["word", "word", "punct"], "pos": ["PTKNEG", "VVINF", "$."], "meter": "+-+-", "measure": "trochaic.di"}}, "stanza.5": {"line.1": {"text": "Man wird die sch\u00f6ne Morgen-R\u00f6hte fast eine neue", "tokens": ["Man", "wird", "die", "sch\u00f6\u00b7ne", "Mor\u00b7gen\u00b7R\u00f6h\u00b7te", "fast", "ei\u00b7ne", "neu\u00b7e"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VAFIN", "ART", "ADJA", "NN", "ADV", "ART", "ADJA"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Sch\u00f6pfung nennen,", "tokens": ["Sch\u00f6p\u00b7fung", "nen\u00b7nen", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVINF", "$,"], "meter": "-+--", "measure": "dactylic.init"}, "line.3": {"text": "Und, unter solchem hohen Bilde, dieselbige betrachten", "tokens": ["Und", ",", "un\u00b7ter", "sol\u00b7chem", "ho\u00b7hen", "Bil\u00b7de", ",", "die\u00b7sel\u00b7bi\u00b7ge", "be\u00b7trach\u00b7ten"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "$,", "APPR", "PIAT", "ADJA", "NN", "$,", "PDS", "VVINF"], "meter": "-+-+-+-+-+-+--+-", "measure": "iambic.septa.relaxed"}, "line.4": {"text": "k\u00f6nnen;", "tokens": ["k\u00f6n\u00b7nen", ";"], "token_info": ["word", "punct"], "pos": ["VMINF", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.5": {"text": "Indem durch sie ein neuer Himmel, und gleichsam eine neue", "tokens": ["In\u00b7dem", "durch", "sie", "ein", "neu\u00b7er", "Him\u00b7mel", ",", "und", "gleich\u00b7sam", "ei\u00b7ne", "neu\u00b7e"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "APPR", "PPER", "ART", "ADJA", "NN", "$,", "KON", "ADJD", "ART", "ADJA"], "meter": "--+--+-+--+-+-+-", "measure": "anapaest.di.plus"}, "line.6": {"text": "Welt,", "tokens": ["Welt", ","], "token_info": ["word", "punct"], "pos": ["NN", "$,"], "meter": "+", "measure": "single.up"}, "line.7": {"text": "Aus tiefer Finsterni\u00df gezogen, von neuem uns wird vorge-", "tokens": ["Aus", "tie\u00b7fer", "Fins\u00b7ter\u00b7ni\u00df", "ge\u00b7zo\u00b7gen", ",", "von", "neu\u00b7em", "uns", "wird", "vor\u00b7ge"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "VVPP", "$,", "APPR", "ADJA", "PPER", "VAFIN", "TRUNC"], "meter": "-+-+-+-+--+-+-+-", "measure": "iambic.septa.relaxed"}, "line.8": {"text": "stellt.", "tokens": ["stellt", "."], "token_info": ["word", "punct"], "pos": ["VVFIN", "$."], "meter": "+", "measure": "single.up"}, "line.9": {"text": "Sie zeiget uns beb\u00fcschte Berge, bebl\u00fchmte Th\u00e4ler, gr\u00fcne", "tokens": ["Sie", "zei\u00b7get", "uns", "be\u00b7b\u00fcschte", "Ber\u00b7ge", ",", "be\u00b7bl\u00fchm\u00b7te", "Th\u00e4\u00b7ler", ",", "gr\u00fc\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word"], "pos": ["PPER", "VVFIN", "PPER", "VVFIN", "NN", "$,", "ADJA", "NN", "$,", "ADJA"], "meter": "-+-+--+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.10": {"text": "W\u00e4lder,", "tokens": ["W\u00e4l\u00b7der", ","], "token_info": ["word", "punct"], "pos": ["NN", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.11": {"text": "Begraste Wiesen, klare B\u00e4che, mit Korn bedeckte fette Felder.", "tokens": ["Be\u00b7gras\u00b7te", "Wie\u00b7sen", ",", "kla\u00b7re", "B\u00e4\u00b7che", ",", "mit", "Korn", "be\u00b7deck\u00b7te", "fet\u00b7te", "Fel\u00b7der", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "ADJA", "NN", "$,", "APPR", "NN", "VVFIN", "ADJA", "NN", "$."], "meter": "-+-+-+-+--+-+-+-+-", "measure": "iambic.octa.plus.relaxed"}}, "stanza.6": {"line.1": {"text": "Sie ziehet vor geth\u00fcrmte St\u00e4dte den sie verh\u00fcll\u2019nden Vor-", "tokens": ["Sie", "zie\u00b7het", "vor", "ge\u00b7th\u00fcrm\u00b7te", "St\u00e4d\u00b7te", "den", "sie", "ver\u00b7h\u00fcll'n\u00b7den", "Vor"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ADJA", "NN", "ART", "PPER", "ADJA", "NN"], "meter": "-+-+-+-+--+-+-+", "measure": "iambic.septa.relaxed"}, "line.2": {"text": "hang weg,", "tokens": ["hang", "weg", ","], "token_info": ["word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "$,"], "meter": "-+", "measure": "iambic.single"}, "line.3": {"text": "Sie zeigt des Wildes Spuhr dem J\u00e4ger, dem Wandrer den", "tokens": ["Sie", "zeigt", "des", "Wil\u00b7des", "Spuhr", "dem", "J\u00e4\u00b7ger", ",", "dem", "Wand\u00b7rer", "den"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "NN", "ART", "NN", "$,", "ART", "NN", "ART"], "meter": "-+-+-+-+--+--", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "gesuchten Steg.", "tokens": ["ge\u00b7such\u00b7ten", "Steg", "."], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.5": {"text": "Die Herrlichkeit so reicher Sch\u00e4tze war noch vor kurzem ganz", "tokens": ["Die", "Herr\u00b7lich\u00b7keit", "so", "rei\u00b7cher", "Sch\u00e4t\u00b7ze", "war", "noch", "vor", "kur\u00b7zem", "ganz"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADV", "ADJD", "NN", "VAFIN", "ADV", "APPR", "ADJA", "ADV"], "meter": "-+-+-+-+--+-+-+", "measure": "iambic.septa.relaxed"}, "line.6": {"text": "verlohren,", "tokens": ["ver\u00b7loh\u00b7ren", ","], "token_info": ["word", "punct"], "pos": ["VVPP", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.7": {"text": "Die Schatten hatten sie geraubt. Jtzt sind sie gleichsam neu", "tokens": ["Die", "Schat\u00b7ten", "hat\u00b7ten", "sie", "ge\u00b7raubt", ".", "Jtzt", "sind", "sie", "gleich\u00b7sam", "neu"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "PPER", "VVPP", "$.", "ADV", "VAFIN", "PPER", "ADJD", "ADJD"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.8": {"text": "gebohren,", "tokens": ["ge\u00b7boh\u00b7ren", ","], "token_info": ["word", "punct"], "pos": ["VVPP", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.9": {"text": "Erscheinen aus dem dunklen Nichts.", "tokens": ["Er\u00b7schei\u00b7nen", "aus", "dem", "dunk\u00b7len", "Nichts", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Wie nun der Glanz des Morgen-Lichts,", "tokens": ["Wie", "nun", "der", "Glanz", "des", "Mor\u00b7gen\u00b7Lichts", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Ohn\u2019 unser Zuthun, wiederkehrt;", "tokens": ["Ohn'", "un\u00b7ser", "Zu\u00b7thun", ",", "wie\u00b7der\u00b7kehrt", ";"], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "So scheint uns eine neue Sch\u00f6pfung, in seiner Wiederkunft,", "tokens": ["So", "scheint", "uns", "ei\u00b7ne", "neu\u00b7e", "Sch\u00f6p\u00b7fung", ",", "in", "sei\u00b7ner", "Wie\u00b7der\u00b7kunft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "ADJA", "NN", "$,", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+--+-+-+", "measure": "iambic.septa.relaxed"}, "line.13": {"text": "beschehrt,", "tokens": ["be\u00b7schehrt", ","], "token_info": ["word", "punct"], "pos": ["VVPP", "$,"], "meter": "-+", "measure": "iambic.single"}, "line.14": {"text": "So da\u00df man einen jeden Morgen, und einen jeden neuen Tag,", "tokens": ["So", "da\u00df", "man", "ei\u00b7nen", "je\u00b7den", "Mor\u00b7gen", ",", "und", "ei\u00b7nen", "je\u00b7den", "neu\u00b7en", "Tag", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PIS", "ART", "PIAT", "NN", "$,", "KON", "ART", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+--+-+-+-+", "measure": "iambic.octa.plus.relaxed"}, "line.15": {"text": "So wohl, als wie den allerersten, betrachten und bewundern", "tokens": ["So", "wohl", ",", "als", "wie", "den", "al\u00b7le\u00b7rers\u00b7ten", ",", "be\u00b7trach\u00b7ten", "und", "be\u00b7wun\u00b7dern"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "ADV", "$,", "KOUS", "KOKOM", "ART", "ADJA", "$,", "VVINF", "KON", "VVINF"], "meter": "-+-+-+-+--+-+-+-", "measure": "iambic.septa.relaxed"}, "line.16": {"text": "mag.", "tokens": ["mag."], "token_info": ["abbreviation"], "pos": ["NE"]}, "line.17": {"text": "Es ist, nicht minder als der erste, f\u00fcr uns jedwedes Tages", "tokens": ["Es", "ist", ",", "nicht", "min\u00b7der", "als", "der", "ers\u00b7te", ",", "f\u00fcr", "uns", "jed\u00b7we\u00b7des", "Ta\u00b7ges"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "$,", "PTKNEG", "ADV", "KOUS", "ART", "ADJA", "$,", "APPR", "PPER", "PIAT", "NN"], "meter": "-+-+-+-+--+-+-+-", "measure": "iambic.septa.relaxed"}, "line.18": {"text": "Schein", "tokens": ["Schein"], "token_info": ["word"], "pos": ["NN"], "meter": "+", "measure": "single.up"}, "line.19": {"text": "Ein neues g\u00f6ttliches Geschenke. La\u00dft uns denn t\u00e4glich", "tokens": ["Ein", "neu\u00b7es", "g\u00f6tt\u00b7li\u00b7ches", "Ge\u00b7schen\u00b7ke", ".", "La\u00dft", "uns", "denn", "t\u00e4g\u00b7lich"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "ADJA", "NN", "$.", "VVIMP", "PPER", "ADV", "ADJD"], "meter": "-+-+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.20": {"text": "dankbar seyn!", "tokens": ["dank\u00b7bar", "seyn", "!"], "token_info": ["word", "word", "punct"], "pos": ["ADJD", "VAINF", "$."], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.7": {"line.1": {"text": "Zur t\u00e4glichen Gebuhrt der Erden wird, von dem neuen", "tokens": ["Zur", "t\u00e4g\u00b7li\u00b7chen", "Ge\u00b7buhrt", "der", "Er\u00b7den", "wird", ",", "von", "dem", "neu\u00b7en"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPRART", "ADJA", "NN", "ART", "NN", "VAFIN", "$,", "APPR", "ART", "ADJA"], "meter": "-+-+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Morgen-Licht,", "tokens": ["Mor\u00b7gen\u00b7Licht", ","], "token_info": ["word", "punct"], "pos": ["NN", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.3": {"text": "F\u00fcr uns noch ein Geschenk gef\u00fcgt, das fast f\u00fcr uns geringer", "tokens": ["F\u00fcr", "uns", "noch", "ein", "Ge\u00b7schenk", "ge\u00b7f\u00fcgt", ",", "das", "fast", "f\u00fcr", "uns", "ge\u00b7rin\u00b7ger"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPER", "ADV", "ART", "NN", "VVPP", "$,", "PRELS", "ADV", "APPR", "PPER", "ADJA"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.4": {"text": "nicht,", "tokens": ["nicht", ","], "token_info": ["word", "punct"], "pos": ["PTKNEG", "$,"], "meter": "-", "measure": "single.down"}, "line.5": {"text": "Als wie das erste: Wird uns nicht dadurch fast ein verneutes", "tokens": ["Als", "wie", "das", "ers\u00b7te", ":", "Wird", "uns", "nicht", "da\u00b7durch", "fast", "ein", "ver\u00b7neu\u00b7tes"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "KOKOM", "ART", "ADJA", "$.", "VAFIN", "PPER", "PTKNEG", "PAV", "ADV", "ART", "ADJA"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.6": {"text": "Leben,", "tokens": ["Le\u00b7ben", ","], "token_info": ["word", "punct"], "pos": ["NN", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.7": {"text": "Indem, als einer Art des Todes, es uns dem Schlaf entzieht,", "tokens": ["In\u00b7dem", ",", "als", "ei\u00b7ner", "Art", "des", "To\u00b7des", ",", "es", "uns", "dem", "Schlaf", "ent\u00b7zieht", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$,", "KOUS", "ART", "NN", "ART", "NN", "$,", "PPER", "PRF", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+--+-+-+", "measure": "iambic.septa.relaxed"}, "line.8": {"text": "gegeben?", "tokens": ["ge\u00b7ge\u00b7ben", "?"], "token_info": ["word", "punct"], "pos": ["VVPP", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.9": {"text": "Er giebet gleichsam uns den Geist, die Arme, Bein\u2019 und andre", "tokens": ["Er", "gie\u00b7bet", "gleich\u00b7sam", "uns", "den", "Geist", ",", "die", "Ar\u00b7me", ",", "Bein'", "und", "and\u00b7re"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADJD", "PPER", "ART", "NN", "$,", "ART", "NN", "$,", "NN", "KON", "ADJA"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.10": {"text": "Glieder,", "tokens": ["Glie\u00b7der", ","], "token_info": ["word", "punct"], "pos": ["NN", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.11": {"text": "Die, durch den Schlaf, nicht brauchbar waren, des Morgens", "tokens": ["Die", ",", "durch", "den", "Schlaf", ",", "nicht", "brauch\u00b7bar", "wa\u00b7ren", ",", "des", "Mor\u00b7gens"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "$,", "APPR", "ART", "NN", "$,", "PTKNEG", "ADJD", "VAFIN", "$,", "ART", "NN"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.12": {"text": "uns aufs neue wieder.", "tokens": ["uns", "aufs", "neu\u00b7e", "wie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "APPRART", "ADJA", "ADV", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.8": {"line.1": {"text": "Er ruft zur Arbeit: welche Stimme zwar nicht ergetzlich", "tokens": ["Er", "ruft", "zur", "Ar\u00b7beit", ":", "wel\u00b7che", "Stim\u00b7me", "zwar", "nicht", "er\u00b7getz\u00b7lich"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "$.", "PWAT", "NN", "ADV", "PTKNEG", "ADJD"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "w\u00fcrde seyn,", "tokens": ["w\u00fcr\u00b7de", "seyn", ","], "token_info": ["word", "word", "punct"], "pos": ["VAFIN", "VAINF", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.3": {"text": "Wann ", "tokens": ["Wann"], "token_info": ["word"], "pos": ["PWAV"], "meter": "+", "measure": "single.up"}, "line.4": {"text": "nicht allein", "tokens": ["nicht", "al\u00b7lein"], "token_info": ["word", "word"], "pos": ["PTKNEG", "ADV"], "meter": "+-+", "measure": "trochaic.di"}, "line.5": {"text": "Ein' Uebung der uns n\u00f6ht'gen Tugend; sie ist des", "tokens": ["Ein'", "Ue\u00b7bung", "der", "uns", "n\u00f6ht'\u00b7gen", "Tu\u00b7gend", ";", "sie", "ist", "des"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "ART", "PPER", "ADJA", "NN", "$.", "PPER", "VAFIN", "ART"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "wahren Gl\u00fcckes Quelle.", "tokens": ["wah\u00b7ren", "Gl\u00fc\u00b7ckes", "Quel\u00b7le", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.9": {"line.1": {"text": "Die Morgen-R\u00f6hte machet alles, zu rechter Zeit, in", "tokens": ["Die", "Mor\u00b7gen\u00b7R\u00f6h\u00b7te", "ma\u00b7chet", "al\u00b7les", ",", "zu", "rech\u00b7ter", "Zeit", ",", "in"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["ART", "NN", "VVFIN", "PIS", "$,", "APPR", "ADJA", "NN", "$,", "APPR"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Ordnung, helle,", "tokens": ["Ord\u00b7nung", ",", "hel\u00b7le", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$,", "ADJA", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "Und zwinget uns, uns selbst zu dienen. Des Hahnen richti-", "tokens": ["Und", "zwin\u00b7get", "uns", ",", "uns", "selbst", "zu", "die\u00b7nen", ".", "Des", "Hah\u00b7nen", "rich\u00b7ti"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "$,", "PPER", "ADV", "PTKZU", "VVINF", "$.", "ART", "NN", "TRUNC"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "ger Gesang", "tokens": ["ger", "Ge\u00b7sang"], "token_info": ["word", "word"], "pos": ["ADJA", "NN"], "meter": "--+", "measure": "anapaest.init"}, "line.5": {"text": "Vertritt noch \u00fcberdem die Stelle von eines Uhren-Weckers", "tokens": ["Ver\u00b7tritt", "noch", "\u00fc\u00b7ber\u00b7dem", "die", "Stel\u00b7le", "von", "ei\u00b7nes", "Uh\u00b7ren\u00b7We\u00b7ckers"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "ADV", "ART", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+--+-+-+-", "measure": "iambic.septa.relaxed"}, "line.6": {"text": "Klang,", "tokens": ["Klang", ","], "token_info": ["word", "punct"], "pos": ["NN", "$,"], "meter": "+", "measure": "single.up"}, "line.7": {"text": "Damit man nicht die Zeit verschlafe. Die V\u00f6gel haben auf", "tokens": ["Da\u00b7mit", "man", "nicht", "die", "Zeit", "ver\u00b7schla\u00b7fe", ".", "Die", "V\u00f6\u00b7gel", "ha\u00b7ben", "auf"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "PTKNEG", "ART", "NN", "VVFIN", "$.", "ART", "NN", "VAFIN", "APPR"], "meter": "-+-+-+-+--+-+-+", "measure": "iambic.septa.relaxed"}, "line.8": {"text": "die Felder", "tokens": ["die", "Fel\u00b7der"], "token_info": ["word", "word"], "pos": ["ART", "NN"], "meter": "-+-", "measure": "amphibrach.single"}, "line.9": {"text": "Sich schon, noch eh\u2019 als wir, verf\u00fcgt, erf\u00fcllen Wiesen, Luft", "tokens": ["Sich", "schon", ",", "noch", "eh'", "als", "wir", ",", "ver\u00b7f\u00fcgt", ",", "er\u00b7f\u00fcl\u00b7len", "Wie\u00b7sen", ",", "Luft"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct", "word"], "pos": ["PRF", "ADV", "$,", "ADV", "KOUS", "KOUS", "PPER", "$,", "VVFIN", "$,", "ADJA", "NN", "$,", "NN"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.10": {"text": "und W\u00e4lder", "tokens": ["und", "W\u00e4l\u00b7der"], "token_info": ["word", "word"], "pos": ["KON", "NN"], "meter": "-+-", "measure": "amphibrach.single"}, "line.11": {"text": "Mit ihrem gurgelnden Get\u00f6n, und helfen, mit gelindem", "tokens": ["Mit", "ih\u00b7rem", "gur\u00b7geln\u00b7den", "Ge\u00b7t\u00f6n", ",", "und", "hel\u00b7fen", ",", "mit", "ge\u00b7lin\u00b7dem"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$,", "KON", "VVINF", "$,", "APPR", "ADJA"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.12": {"text": "Schall,", "tokens": ["Schall", ","], "token_info": ["word", "punct"], "pos": ["NN", "$,"], "meter": "+", "measure": "single.up"}, "line.13": {"text": "Den Schlummer g\u00e4nzlich zu vertreiben. Jtzt regt sich alles", "tokens": ["Den", "Schlum\u00b7mer", "g\u00e4nz\u00b7lich", "zu", "ver\u00b7trei\u00b7ben", ".", "Jtzt", "regt", "sich", "al\u00b7les"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADJD", "PTKZU", "VVINF", "$.", "ADV", "VVFIN", "PRF", "PIS"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.14": {"text": "\u00fcberall,", "tokens": ["\u00fc\u00b7be\u00b7rall", ","], "token_info": ["word", "punct"], "pos": ["ADV", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.15": {"text": "Das Vieh zum Acker-Werk ist fertig, die Ochsen, nebst den", "tokens": ["Das", "Vieh", "zum", "A\u00b7cke\u00b7rWerk", "ist", "fer\u00b7tig", ",", "die", "Och\u00b7sen", ",", "nebst", "den"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "APPRART", "NN", "VAFIN", "ADJD", "$,", "ART", "NN", "$,", "APPR", "ART"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.16": {"text": "muntern Pferden,", "tokens": ["mun\u00b7tern", "Pfer\u00b7den", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.17": {"text": "Erwarten unsern Wink allein, zusammt den Wollen-reichen", "tokens": ["Er\u00b7war\u00b7ten", "un\u00b7sern", "Wink", "al\u00b7lein", ",", "zu\u00b7sammt", "den", "Wol\u00b7len\u00b7rei\u00b7chen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "PPOSAT", "NN", "ADV", "$,", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.18": {"text": "Heerden,", "tokens": ["Heer\u00b7den", ","], "token_info": ["word", "punct"], "pos": ["NN", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.19": {"text": "Den Marsch gehorsam anzufangen. So weit mein Auge", "tokens": ["Den", "Marsch", "ge\u00b7hor\u00b7sam", "an\u00b7zu\u00b7fan\u00b7gen", ".", "So", "weit", "mein", "Au\u00b7ge"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADJD", "VVIZU", "$.", "ADV", "ADJD", "PPOSAT", "NN"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.20": {"text": "tragen kann,", "tokens": ["tra\u00b7gen", "kann", ","], "token_info": ["word", "word", "punct"], "pos": ["VVINF", "VMFIN", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.21": {"text": "Treff\u2019 ich, aus nah- und fernen D\u00f6rfern, ein emsiges Bewe-", "tokens": ["Treff'", "ich", ",", "aus", "nah", "und", "fer\u00b7nen", "D\u00f6r\u00b7fern", ",", "ein", "em\u00b7si\u00b7ges", "Be\u00b7we"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVIMP", "PPER", "$,", "APPR", "TRUNC", "KON", "ADJA", "NN", "$,", "ART", "ADJA", "TRUNC"], "meter": "-+-+-+-+-+-+--+", "measure": "iambic.septa.chol"}, "line.22": {"text": "gen an.", "tokens": ["gen", "an", "."], "token_info": ["word", "word", "punct"], "pos": ["APPR", "PTKVZ", "$."], "meter": "-+", "measure": "iambic.single"}, "line.23": {"text": "Hier Acker-Leut\u2019 und Acker-Vieh, dort Reisende zu Fu\u00df und", "tokens": ["Hier", "A\u00b7cke\u00b7rLeut'", "und", "A\u00b7cke\u00b7rVieh", ",", "dort", "Rei\u00b7sen\u00b7de", "zu", "Fu\u00df", "und"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "NN", "KON", "NN", "$,", "ADV", "NN", "APPR", "NN", "KON"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.24": {"text": "Wagen,", "tokens": ["Wa\u00b7gen", ","], "token_info": ["word", "punct"], "pos": ["NN", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.25": {"text": "Dort Hirten vor den Heerden her, hier sieht man Handwerks-", "tokens": ["Dort", "Hir\u00b7ten", "vor", "den", "Heer\u00b7den", "her", ",", "hier", "sieht", "man", "Hand\u00b7werks"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "NN", "APPR", "ART", "NN", "PTKVZ", "$,", "ADV", "VVFIN", "PIS", "TRUNC"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Leute tragen", "tokens": ["Leu\u00b7te", "tra\u00b7gen"], "token_info": ["word", "word"], "pos": ["NN", "VVINF"], "meter": "+-+-", "measure": "trochaic.di"}}, "stanza.10": {"line.1": {"text": "So mancherley Ger\u00e4ht und Werkzeug. So fern sich unser", "tokens": ["So", "man\u00b7cher\u00b7ley", "Ge\u00b7r\u00e4ht", "und", "Werk\u00b7zeug", ".", "So", "fern", "sich", "un\u00b7ser"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "PIAT", "NN", "KON", "NN", "$.", "ADV", "ADJD", "PRF", "PPOSAT"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Blick erstreckt,", "tokens": ["Blick", "er\u00b7streckt", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVPP", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.3": {"text": "Sind Wege, Br\u00fccken, Haven, M\u00e4rkte bereits erf\u00fcllet und", "tokens": ["Sind", "We\u00b7ge", ",", "Br\u00fc\u00b7cken", ",", "Ha\u00b7ven", ",", "M\u00e4rk\u00b7te", "be\u00b7reits", "er\u00b7f\u00fcl\u00b7let", "und"], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["VAFIN", "NN", "$,", "NN", "$,", "NE", "$,", "NN", "ADV", "VVFIN", "KON"], "meter": "-+-+-+-+--+-+-+", "measure": "iambic.septa.relaxed"}, "line.4": {"text": "bedeckt,", "tokens": ["be\u00b7deckt", ","], "token_info": ["word", "punct"], "pos": ["VVPP", "$,"], "meter": "-+", "measure": "iambic.single"}, "line.5": {"text": "Was lebet, ist schon in Bewegung. Der Morgen hat uns", "tokens": ["Was", "le\u00b7bet", ",", "ist", "schon", "in", "Be\u00b7we\u00b7gung", ".", "Der", "Mor\u00b7gen", "hat", "uns"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "$,", "VAFIN", "ADV", "APPR", "NN", "$.", "ART", "NN", "VAFIN", "PPER"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "angezeiget,", "tokens": ["an\u00b7ge\u00b7zei\u00b7get", ","], "token_info": ["word", "punct"], "pos": ["VVPP", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.7": {"text": "Die Zeit zur Arbeit sey erschienen, und alles ist dazu geneiget.", "tokens": ["Die", "Zeit", "zur", "Ar\u00b7beit", "sey", "er\u00b7schie\u00b7nen", ",", "und", "al\u00b7les", "ist", "da\u00b7zu", "ge\u00b7nei\u00b7get", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "VAFIN", "VVPP", "$,", "KON", "PIS", "VAFIN", "PAV", "VVPP", "$."], "meter": "-+-+-+-+--+-+-+-+-", "measure": "iambic.octa.plus.relaxed"}}, "stanza.11": {"line.1": {"text": "Inzwischen nun, da\u00df wir die Menschen, mit ihren Thieren,", "tokens": ["I\u00b7nzwi\u00b7schen", "nun", ",", "da\u00df", "wir", "die", "Men\u00b7schen", ",", "mit", "ih\u00b7ren", "Thie\u00b7ren", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$,", "KOUS", "PPER", "ART", "NN", "$,", "APPR", "PPOSAT", "NN", "$,"], "meter": "---+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "kommen sehn,", "tokens": ["kom\u00b7men", "sehn", ","], "token_info": ["word", "word", "punct"], "pos": ["VVINF", "VVINF", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.3": {"text": "Erblick\u2019 ich, voll Verwunderung, da\u00df ander\u2019 eilig von uns", "tokens": ["Er\u00b7blick'", "ich", ",", "voll", "Ver\u00b7wun\u00b7de\u00b7rung", ",", "da\u00df", "an\u00b7der'", "ei\u00b7lig", "von", "uns"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVIMP", "PPER", "$,", "ADJD", "NN", "$,", "KOUS", "PIS", "ADJD", "APPR", "PPER"], "meter": "-+-+-+-+-+-+--+", "measure": "iambic.septa.chol"}, "line.4": {"text": "gehn,", "tokens": ["gehn", ","], "token_info": ["word", "punct"], "pos": ["VVINF", "$,"], "meter": "+", "measure": "single.up"}, "line.5": {"text": "Und, statt des Lichts sich zu erfreun, vor seinem Schimmer fast", "tokens": ["Und", ",", "statt", "des", "Lichts", "sich", "zu", "er\u00b7freun", ",", "vor", "sei\u00b7nem", "Schim\u00b7mer", "fast"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "$,", "KOUI", "ART", "NN", "PRF", "PTKZU", "VVINF", "$,", "APPR", "PPOSAT", "NN", "ADV"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.6": {"text": "erschrecken,", "tokens": ["er\u00b7schre\u00b7cken", ","], "token_info": ["word", "punct"], "pos": ["VVFIN", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.7": {"text": "Und sich in H\u00f6hlen, Gr\u00fcfte, L\u00f6cher und dunkle W\u00e4lder schnell", "tokens": ["Und", "sich", "in", "H\u00f6h\u00b7len", ",", "Gr\u00fcf\u00b7te", ",", "L\u00f6\u00b7cher", "und", "dunk\u00b7le", "W\u00e4l\u00b7der", "schnell"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "PRF", "APPR", "NN", "$,", "NN", "$,", "NN", "KON", "ADJA", "NN", "ADJD"], "meter": "-+-+-+-+--+-+-+", "measure": "iambic.septa.relaxed"}, "line.8": {"text": "verstecken,", "tokens": ["ver\u00b7ste\u00b7cken", ","], "token_info": ["word", "punct"], "pos": ["VVINF", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.9": {"text": "Ja die auch sonst das Licht nicht scheuen, bem\u00fchen sich, sich zu", "tokens": ["Ja", "die", "auch", "sonst", "das", "Licht", "nicht", "scheu\u00b7en", ",", "be\u00b7m\u00fc\u00b7hen", "sich", ",", "sich", "zu"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["PTKANT", "PRELS", "ADV", "ADV", "ART", "NN", "PTKNEG", "VVINF", "$,", "VVFIN", "PRF", "$,", "PRF", "APPR"], "meter": "-+-+-+-+--+-+-+", "measure": "iambic.septa.relaxed"}, "line.10": {"text": "verdecken.", "tokens": ["ver\u00b7de\u00b7cken", "."], "token_info": ["word", "punct"], "pos": ["VVINF", "$."], "meter": "-+-", "measure": "amphibrach.single"}}, "stanza.12": {"line.1": {"text": "Da, wo ein dichter Wald beginnt, kommt hier ein Fuchs,", "tokens": ["Da", ",", "wo", "ein", "dich\u00b7ter", "Wald", "be\u00b7ginnt", ",", "kommt", "hier", "ein", "Fuchs", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PWAV", "ART", "ADJA", "NN", "VVFIN", "$,", "VVFIN", "ADV", "ART", "NE", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "und dort ein Reh,", "tokens": ["und", "dort", "ein", "Reh", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "Ein Wolf, ein Hirsch, ein wildes Schwein, bald aus dem", "tokens": ["Ein", "Wolf", ",", "ein", "Hirsch", ",", "ein", "wil\u00b7des", "Schwein", ",", "bald", "aus", "dem"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NE", "$,", "ART", "NN", "$,", "ART", "ADJA", "NN", "$,", "ADV", "APPR", "ART"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Thal, bald von der H\u00f6h,", "tokens": ["Thal", ",", "bald", "von", "der", "H\u00f6h", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADV", "APPR", "ART", "NN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.5": {"text": "Bald traben, h\u00fcpfen, laufen, springen,", "tokens": ["Bald", "tra\u00b7ben", ",", "h\u00fcp\u00b7fen", ",", "lau\u00b7fen", ",", "sprin\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ADV", "VVINF", "$,", "VVFIN", "$,", "VVFIN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Um uns das Feld zu \u00fcberlassen, und in den dicken Busch zu", "tokens": ["Um", "uns", "das", "Feld", "zu", "\u00fc\u00b7ber\u00b7las\u00b7sen", ",", "und", "in", "den", "di\u00b7cken", "Busch", "zu"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["KOUI", "PPER", "ART", "NN", "PTKZU", "VVINF", "$,", "KON", "APPR", "ART", "ADJA", "NN", "PTKZU"], "meter": "-+-+-+-+--+-+-+-", "measure": "iambic.septa.relaxed"}, "line.7": {"text": "dringen.", "tokens": ["drin\u00b7gen", "."], "token_info": ["word", "punct"], "pos": ["VVFIN", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.8": {"text": "Was zwinget sie, sich zu entfernen? Die wenigsten das", "tokens": ["Was", "zwin\u00b7get", "sie", ",", "sich", "zu", "ent\u00b7fer\u00b7nen", "?", "Die", "we\u00b7nigs\u00b7ten", "das"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWS", "VVFIN", "PPER", "$,", "PRF", "PTKZU", "VVINF", "$.", "ART", "PIS", "ART"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.9": {"text": "Morgen-Licht,", "tokens": ["Mor\u00b7gen\u00b7Licht", ","], "token_info": ["word", "punct"], "pos": ["NN", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.10": {"text": "Als dessen sie sich auch bedienen. Die Menschen thun es", "tokens": ["Als", "des\u00b7sen", "sie", "sich", "auch", "be\u00b7die\u00b7nen", ".", "Die", "Men\u00b7schen", "thun", "es"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "PDS", "PPER", "PRF", "ADV", "VVINF", "$.", "ART", "NN", "VVFIN", "PPER"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.11": {"text": "gleichfalls nicht,", "tokens": ["gleich\u00b7falls", "nicht", ","], "token_info": ["word", "word", "punct"], "pos": ["ADV", "PTKNEG", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.12": {"text": "Als welche ja nicht in der N\u00e4he; und die sich etwan nahe", "tokens": ["Als", "wel\u00b7che", "ja", "nicht", "in", "der", "N\u00e4\u00b7he", ";", "und", "die", "sich", "et\u00b7wan", "na\u00b7he"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PRELS", "ADV", "PTKNEG", "APPR", "ART", "NN", "$.", "KON", "PRELS", "PRF", "ADV", "ADJD"], "meter": "-+--+--+--+-+-+-", "measure": "amphibrach.tetra.plus"}, "line.13": {"text": "finden,", "tokens": ["fin\u00b7den", ","], "token_info": ["word", "punct"], "pos": ["VVINF", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.14": {"text": "Sind ja mit Waffen nicht versehn. Hier lieget einer in den", "tokens": ["Sind", "ja", "mit", "Waf\u00b7fen", "nicht", "ver\u00b7sehn", ".", "Hier", "lie\u00b7get", "ei\u00b7ner", "in", "den"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "APPR", "NN", "PTKNEG", "VVINF", "$.", "ADV", "VVFIN", "ART", "APPR", "ART"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.15": {"text": "Gr\u00fcnden,", "tokens": ["Gr\u00fcn\u00b7den", ","], "token_info": ["word", "punct"], "pos": ["NN", "$,"], "meter": "+-", "measure": "trochaic.single"}}, "stanza.13": {"line.1": {"text": "Jm Grase ruhig bey den Schafen, der spielt dort auf der", "tokens": ["Jm", "Gra\u00b7se", "ru\u00b7hig", "bey", "den", "Scha\u00b7fen", ",", "der", "spielt", "dort", "auf", "der"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "ADJD", "APPR", "ART", "NN", "$,", "PRELS", "VVFIN", "ADV", "APPR", "ART"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Feld-Schallmey,", "tokens": ["Feld\u00b7Schall\u00b7mey", ","], "token_info": ["word", "punct"], "pos": ["NE", "$,"], "meter": "++-", "measure": "unknown.measure.di"}, "line.3": {"text": "Ein Reisender geht, ohne Sorg\u2019 und b\u00f6sen Willen, schnell", "tokens": ["Ein", "Rei\u00b7sen\u00b7der", "geht", ",", "oh\u00b7ne", "Sor\u00b7g'", "und", "b\u00f6\u00b7sen", "Wil\u00b7len", ",", "schnell"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["ART", "NN", "VVFIN", "$,", "KOUI", "NN", "KON", "ADJA", "NN", "$,", "ADJD"], "meter": "-+---+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "vorbey.", "tokens": ["vor\u00b7bey", "."], "token_info": ["word", "punct"], "pos": ["PTKVZ", "$."], "meter": "++", "measure": "spondeus"}, "line.5": {"text": "So la\u00dft uns auch, in dieser Handlung, des Sch\u00f6pfers Ord-", "tokens": ["So", "la\u00dft", "uns", "auch", ",", "in", "die\u00b7ser", "Hand\u00b7lung", ",", "des", "Sch\u00f6p\u00b7fers", "Ord"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVIMP", "PPER", "ADV", "$,", "APPR", "PDAT", "NN", "$,", "ART", "NN", "TRUNC"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "nungen erkennen.", "tokens": ["nun\u00b7gen", "er\u00b7ken\u00b7nen", "."], "token_info": ["word", "word", "punct"], "pos": ["ADV", "VVINF", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.7": {"text": "Da Er, als wie ein Eigenthum, die Welt dem Menschen", "tokens": ["Da", "Er", ",", "als", "wie", "ein", "Ei\u00b7gen\u00b7thum", ",", "die", "Welt", "dem", "Men\u00b7schen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "$,", "KOUS", "KOKOM", "ART", "NN", "$,", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "wollen g\u00f6nnen;", "tokens": ["wol\u00b7len", "g\u00f6n\u00b7nen", ";"], "token_info": ["word", "word", "punct"], "pos": ["VMFIN", "VVINF", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.9": {"text": "Mu\u00df alles das, was ihm beschwehrlich, so bald als er erschei-", "tokens": ["Mu\u00df", "al\u00b7les", "das", ",", "was", "ihm", "be\u00b7schwehr\u00b7lich", ",", "so", "bald", "als", "er", "er\u00b7schei"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "PIS", "PDS", "$,", "PWS", "PPER", "ADJD", "$,", "ADV", "ADV", "KOUS", "PPER", "TRUNC"], "meter": "-+-+-+-+--+-+-+", "measure": "iambic.septa.relaxed"}, "line.10": {"text": "net, fliehn,", "tokens": ["net", ",", "fliehn", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NE", "$,", "VVINF", "$,"], "meter": "-+", "measure": "iambic.single"}, "line.11": {"text": "Und, was ihm sch\u00e4dlich, wenn er kommt, sich seiner Gegen-", "tokens": ["Und", ",", "was", "ihm", "sch\u00e4d\u00b7lich", ",", "wenn", "er", "kommt", ",", "sich", "sei\u00b7ner", "Ge\u00b7gen"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "$,", "PWS", "PPER", "ADJD", "$,", "KOUS", "PPER", "VVFIN", "$,", "PRF", "PPOSAT", "TRUNC"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "wart entziehn.", "tokens": ["wart", "ent\u00b7ziehn", "."], "token_info": ["word", "word", "punct"], "pos": ["VVFIN", "VVINF", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.13": {"text": "Das Wild, das ihn sonst hindern k\u00f6nnte, mu\u00df seinem Mei-", "tokens": ["Das", "Wild", ",", "das", "ihn", "sonst", "hin\u00b7dern", "k\u00f6nn\u00b7te", ",", "mu\u00df", "sei\u00b7nem", "Mei"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "ADV", "VVINF", "VMFIN", "$,", "VMFIN", "PPOSAT", "TRUNC"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.14": {"text": "ster weichen lernen.", "tokens": ["ster", "wei\u00b7chen", "ler\u00b7nen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "VVINF", "VVINF", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.15": {"text": "Die unsichtbare Wunder-Hand des Sch\u00f6pfers wei\u00df sie zu", "tokens": ["Die", "un\u00b7sicht\u00b7ba\u00b7re", "Wun\u00b7der\u00b7Hand", "des", "Sch\u00f6p\u00b7fers", "wei\u00df", "sie", "zu"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "VVFIN", "PPER", "APPR"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.16": {"text": "entfernen;", "tokens": ["ent\u00b7fer\u00b7nen", ";"], "token_info": ["word", "punct"], "pos": ["VVINF", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.17": {"text": "So da\u00df der Mensch, der Herr der Erden, wenn er sein Eigen-", "tokens": ["So", "da\u00df", "der", "Mensch", ",", "der", "Herr", "der", "Er\u00b7den", ",", "wenn", "er", "sein", "Ei\u00b7gen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "KOUS", "ART", "NN", "$,", "ART", "NN", "ART", "NN", "$,", "KOUS", "PPER", "PPOSAT", "TRUNC"], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.18": {"text": "thum besehn,", "tokens": ["thum", "be\u00b7sehn", ","], "token_info": ["word", "word", "punct"], "pos": ["ADV", "VVINF", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.19": {"text": "Und auf demselben wirken will, in einer sichern Freyheit", "tokens": ["Und", "auf", "dem\u00b7sel\u00b7ben", "wir\u00b7ken", "will", ",", "in", "ei\u00b7ner", "si\u00b7chern", "Frey\u00b7heit"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "APPR", "PDAT", "VVINF", "VMFIN", "$,", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.20": {"text": "gehn,", "tokens": ["gehn", ","], "token_info": ["word", "punct"], "pos": ["VVINF", "$,"], "meter": "+", "measure": "single.up"}, "line.21": {"text": "Sich ungest\u00f6rt besch\u00e4ft\u2019gen kann. Es mu\u00df, was ihn behin-", "tokens": ["Sich", "un\u00b7ge\u00b7st\u00f6rt", "be\u00b7sch\u00e4ft'\u00b7gen", "kann", ".", "Es", "mu\u00df", ",", "was", "ihn", "be\u00b7hin"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["PRF", "ADJD", "VVINF", "VMFIN", "$.", "PPER", "VMFIN", "$,", "PRELS", "PPER", "TRUNC"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.22": {"text": "dern k\u00f6nnen,", "tokens": ["dern", "k\u00f6n\u00b7nen", ","], "token_info": ["word", "word", "punct"], "pos": ["PDS", "VMFIN", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.23": {"text": "Durch ein gewi\u00df, ich wei\u00df nicht was, entweichen und sich von", "tokens": ["Durch", "ein", "ge\u00b7wi\u00df", ",", "ich", "wei\u00df", "nicht", "was", ",", "ent\u00b7wei\u00b7chen", "und", "sich", "von"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADV", "$,", "PPER", "VVFIN", "PTKNEG", "PIS", "$,", "ADJA", "KON", "PRF", "APPR"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.24": {"text": "ihm trennen.", "tokens": ["ihm", "tren\u00b7nen", "."], "token_info": ["word", "word", "punct"], "pos": ["PPER", "VVINF", "$."], "meter": "-+-", "measure": "amphibrach.single"}}, "stanza.14": {"line.1": {"text": "Mit noch viel mehr- und andern Sch\u00e4tzen sieht man den", "tokens": ["Mit", "noch", "viel", "mehr", "und", "an\u00b7dern", "Sch\u00e4t\u00b7zen", "sieht", "man", "den"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADV", "ADV", "TRUNC", "KON", "ADJA", "NN", "VVFIN", "PIS", "ART"], "meter": "-+-+-+-+-+--", "measure": "unknown.measure.penta"}, "line.2": {"text": "All- erfreu'nden Morgen,", "tokens": ["All", "er\u00b7freu'n\u00b7den", "Mor\u00b7gen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["TRUNC", "ADJA", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Noch eh\u2019 die Sonne selbst erscheint, uns, in dem k\u00fchlen Thau,", "tokens": ["Noch", "eh'", "die", "Son\u00b7ne", "selbst", "er\u00b7scheint", ",", "uns", ",", "in", "dem", "k\u00fch\u00b7len", "Thau", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "ART", "NN", "ADV", "VVFIN", "$,", "PPER", "$,", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.4": {"text": "versorgen.", "tokens": ["ver\u00b7sor\u00b7gen", "."], "token_info": ["word", "punct"], "pos": ["VVPP", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.5": {"text": "Ein Heer von Luft- und Wasser-Bl\u00e4schen, so gestern, durch", "tokens": ["Ein", "Heer", "von", "Luft", "und", "Was\u00b7ser\u00b7Bl\u00e4s\u00b7chen", ",", "so", "ge\u00b7stern", ",", "durch"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word"], "pos": ["ART", "NN", "APPR", "TRUNC", "KON", "NN", "$,", "ADV", "ADJD", "$,", "APPR"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "die Sonn', erh\u00f6ht,", "tokens": ["die", "Sonn'", ",", "er\u00b7h\u00f6ht", ","], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "$,", "VVPP", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "Und in die obre Luft gezogen, so bald die kalte Nacht vergeht,", "tokens": ["Und", "in", "die", "ob\u00b7re", "Luft", "ge\u00b7zo\u00b7gen", ",", "so", "bald", "die", "kal\u00b7te", "Nacht", "ver\u00b7geht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "VVPP", "$,", "ADV", "ADV", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+--+-+-+-+", "measure": "iambic.octa.plus.relaxed"}}, "stanza.15": {"line.1": {"text": "Wird fr\u00fch, so bald es angestrahlt, erregt, allm\u00e4hlig ausge-", "tokens": ["Wird", "fr\u00fch", ",", "so", "bald", "es", "an\u00b7ge\u00b7strahlt", ",", "er\u00b7regt", ",", "all\u00b7m\u00e4h\u00b7lig", "aus\u00b7ge"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["VAFIN", "ADJD", "$,", "ADV", "ADV", "PPER", "VVPP", "$,", "VVPP", "$,", "ADJD", "TRUNC"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.2": {"text": "breitet,", "tokens": ["brei\u00b7tet", ","], "token_info": ["word", "punct"], "pos": ["VVFIN", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.3": {"text": "Durch die Bewegung in der Luft wird uns ein k\u00fchler Wind", "tokens": ["Durch", "die", "Be\u00b7we\u00b7gung", "in", "der", "Luft", "wird", "uns", "ein", "k\u00fch\u00b7ler", "Wind"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "APPR", "ART", "NN", "VAFIN", "PPER", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.4": {"text": "bereitet,", "tokens": ["be\u00b7rei\u00b7tet", ","], "token_info": ["word", "punct"], "pos": ["VVFIN", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.5": {"text": "Der, da er andre Bl\u00e4schen trifft, dieselben allgemach bewegt,", "tokens": ["Der", ",", "da", "er", "and\u00b7re", "Bl\u00e4\u00b7schen", "trifft", ",", "die\u00b7sel\u00b7ben", "all\u00b7ge\u00b7mach", "be\u00b7wegt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "$,", "KOUS", "PPER", "ADJA", "NN", "VVFIN", "$,", "PDAT", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-+-+", "measure": "iambic.octa.plus"}, "line.6": {"text": "Da denn der frische Dunst der Luft sich sanft zu uns herunter", "tokens": ["Da", "denn", "der", "fri\u00b7sche", "Dunst", "der", "Luft", "sich", "sanft", "zu", "uns", "her\u00b7un\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "ART", "ADJA", "NN", "ART", "NN", "PRF", "ADJD", "APPR", "PPER", "APZR"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.7": {"text": "schl\u00e4gt,", "tokens": ["schl\u00e4gt", ","], "token_info": ["word", "punct"], "pos": ["VVFIN", "$,"], "meter": "-", "measure": "single.down"}, "line.8": {"text": "Als eine Milch die Pflanzen s\u00e4ugt, die Bluhmen, Gras und", "tokens": ["Als", "ei\u00b7ne", "Milch", "die", "Pflan\u00b7zen", "s\u00e4ugt", ",", "die", "Bluh\u00b7men", ",", "Gras", "und"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["KOUS", "ART", "NN", "ART", "NN", "VVFIN", "$,", "ART", "NN", "$,", "NN", "KON"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Kr\u00e4uter n\u00e4hret,", "tokens": ["Kr\u00e4u\u00b7ter", "n\u00e4h\u00b7ret", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVFIN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.10": {"text": "Die Felder netzt, die Erde tr\u00e4nkt, und ihnen Oel und Salz", "tokens": ["Die", "Fel\u00b7der", "netzt", ",", "die", "Er\u00b7de", "tr\u00e4nkt", ",", "und", "ih\u00b7nen", "O\u00b7el", "und", "Salz"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "$,", "ART", "NN", "VVFIN", "$,", "KON", "PPER", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+--+", "measure": "iambic.septa.chol"}, "line.11": {"text": "gew\u00e4hret.", "tokens": ["ge\u00b7w\u00e4h\u00b7ret", "."], "token_info": ["word", "punct"], "pos": ["VVPP", "$."], "meter": "-+-", "measure": "amphibrach.single"}}}}}