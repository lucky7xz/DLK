{"textgrid.poem.64798": {"metadata": {"author": {"name": "K\u00e4stner, Abraham Gotthelf", "birth": "N.A.", "death": "N.A."}, "title": "4. Der vern\u00fcnftige Rechtsgelehrte", "genre": "verse", "period": "N.A.", "pub_year": 1759, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Sagt, Freunde, denen es durch vielen Flei\u00df gelungen,", "tokens": ["Sagt", ",", "Freun\u00b7de", ",", "de\u00b7nen", "es", "durch", "vie\u00b7len", "Flei\u00df", "ge\u00b7lun\u00b7gen", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "NN", "$,", "PRELS", "PPER", "APPR", "PIAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Da\u00df ihr ins Heiligthum ", "tokens": ["Da\u00df", "ihr", "ins", "Hei\u00b7lig\u00b7thum"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPRART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ist's m\u00f6glich, da\u00df ein Geist, der Witz und Denken liebt,", "tokens": ["Ist's", "m\u00f6g\u00b7lich", ",", "da\u00df", "ein", "Geist", ",", "der", "Witz", "und", "Den\u00b7ken", "liebt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADJD", "$,", "KOUS", "ART", "NN", "$,", "ART", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "In eurer Wissenschaft sich mit Vergn\u00fcgen \u00fcbt?", "tokens": ["In", "eu\u00b7rer", "Wis\u00b7sen\u00b7schaft", "sich", "mit", "Ver\u00b7gn\u00fc\u00b7gen", "\u00fcbt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PRF", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Sagt, womit kann uns wohl das Chaos von Gesetzen,", "tokens": ["Sagt", ",", "wo\u00b7mit", "kann", "uns", "wohl", "das", "Chaos", "von", "Ge\u00b7set\u00b7zen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PWAV", "VMFIN", "PPER", "ADV", "ART", "NN", "APPR", "NN", "$,"], "meter": "---+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Verwirrt, voll Dunkelheit, voll innerm Zwist, erg\u00f6tzen?", "tokens": ["Ver\u00b7wirrt", ",", "voll", "Dun\u00b7kel\u00b7heit", ",", "voll", "in\u00b7nerm", "Zwist", ",", "er\u00b7g\u00f6t\u00b7zen", "?"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["VVPP", "$,", "ADJD", "NN", "$,", "ADJD", "APPRART", "NN", "$,", "VVINF", "$."], "meter": "-+-+-++--+-+-", "measure": "iambic.hexa.relaxed"}, "line.7": {"text": "Durch was f\u00fcr Wollust wird der m\u00fcde Flei\u00df gest\u00e4rkt,", "tokens": ["Durch", "was", "f\u00fcr", "Wol\u00b7lust", "wird", "der", "m\u00fc\u00b7de", "Flei\u00df", "ge\u00b7st\u00e4rkt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "APPR", "NN", "VAFIN", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Wenn das Ged\u00e4chtni\u00df nur zerstreute S\u00e4tze merkt?", "tokens": ["Wenn", "das", "Ge\u00b7d\u00e4cht\u00b7ni\u00df", "nur", "zer\u00b7streu\u00b7te", "S\u00e4t\u00b7ze", "merkt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ADV", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Was wirket der Verstand, wenn wir f\u00fcr Grund und Schl\u00fcssen,", "tokens": ["Was", "wir\u00b7ket", "der", "Ver\u00b7stand", ",", "wenn", "wir", "f\u00fcr", "Grund", "und", "Schl\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ART", "NN", "$,", "KOUS", "PPER", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Nur auf des Lehrers Wort, die Lehren glauben m\u00fcssen?", "tokens": ["Nur", "auf", "des", "Leh\u00b7rers", "Wort", ",", "die", "Leh\u00b7ren", "glau\u00b7ben", "m\u00fcs\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "NN", "$,", "ART", "NN", "VVINF", "VMINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Wenn ein bew\u00e4hrter Mann dem andern widerspricht,", "tokens": ["Wenn", "ein", "be\u00b7w\u00e4hr\u00b7ter", "Mann", "dem", "an\u00b7dern", "wi\u00b7der\u00b7spricht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "ART", "ADJA", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "(der Beyfall des Gebrauchs fehlt keiner Meynung nicht);", "tokens": ["(", "der", "Bey\u00b7fall", "des", "Ge\u00b7brauchs", "fehlt", "kei\u00b7ner", "Mey\u00b7nung", "nicht", ")", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ART", "NN", "ART", "NN", "VVFIN", "PIAT", "NN", "PTKNEG", "$(", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Wenn man hier billig hei\u00dft, was man dort strafbar nennet;", "tokens": ["Wenn", "man", "hier", "bil\u00b7lig", "hei\u00dft", ",", "was", "man", "dort", "straf\u00b7bar", "nen\u00b7net", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ADV", "ADJD", "VVFIN", "$,", "PRELS", "PIS", "ADV", "ADJD", "VVFIN", "$."], "meter": "-+-+-+--+-+--", "measure": "iambic.penta.relaxed"}, "line.14": {"text": "Hier zu gelinde spricht, und dort zu scharf erkennet;", "tokens": ["Hier", "zu", "ge\u00b7lin\u00b7de", "spricht", ",", "und", "dort", "zu", "scharf", "er\u00b7ken\u00b7net", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ADJA", "VVFIN", "$,", "KON", "ADV", "PTKA", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Wenn man der Meynung folgt, die die Vernunft verdammt,", "tokens": ["Wenn", "man", "der", "Mey\u00b7nung", "folgt", ",", "die", "die", "Ver\u00b7nunft", "ver\u00b7dammt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ART", "NN", "VVFIN", "$,", "PRELS", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Nur weil sie auf uns her von unsern V\u00e4tern stammt;", "tokens": ["Nur", "weil", "sie", "auf", "uns", "her", "von", "un\u00b7sern", "V\u00e4\u00b7tern", "stammt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PPER", "APPR", "PPER", "ADV", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Mit der Gerichte Brauch, mit jedes Dorfes Sitten,", "tokens": ["Mit", "der", "Ge\u00b7rich\u00b7te", "Brauch", ",", "mit", "je\u00b7des", "Dor\u00b7fes", "Sit\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "$,", "APPR", "PIAT", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Der Ordnung jeder Stadt sich mu\u00df den Kopf zerr\u00fctten;", "tokens": ["Der", "Ord\u00b7nung", "je\u00b7der", "Stadt", "sich", "mu\u00df", "den", "Kopf", "zer\u00b7r\u00fct\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PIAT", "NN", "PRF", "VMFIN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Und wenn zuletzt die Frucht von so viel Arbeit ist,", "tokens": ["Und", "wenn", "zu\u00b7letzt", "die", "Frucht", "von", "so", "viel", "Ar\u00b7beit", "ist", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ADV", "ART", "NN", "APPR", "ADV", "PIAT", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Da\u00df man im dicken Sto\u00df verworrner Acten liest?", "tokens": ["Da\u00df", "man", "im", "di\u00b7cken", "Sto\u00df", "ver\u00b7worr\u00b7ner", "Ac\u00b7ten", "liest", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "APPRART", "ADJA", "NN", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "So, Freunde, h\u00f6r' ich oft zu k\u00fchne Sp\u00f6tter richten.", "tokens": ["So", ",", "Freun\u00b7de", ",", "h\u00f6r'", "ich", "oft", "zu", "k\u00fch\u00b7ne", "Sp\u00f6t\u00b7ter", "rich\u00b7ten", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "NN", "$,", "VVFIN", "PPER", "ADV", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Beurtheilt, kann dies Blatt wohl ihren Wahn vernichten?", "tokens": ["Beurt\u00b7heilt", ",", "kann", "dies", "Blatt", "wohl", "ih\u00b7ren", "Wahn", "ver\u00b7nich\u00b7ten", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "VMFIN", "PDS", "NN", "ADV", "PPOSAT", "NN", "VVINF", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.3": {"text": "Gesetze m\u00fcssen seyn, sonst kann kein Staat bestehn,", "tokens": ["Ge\u00b7set\u00b7ze", "m\u00fcs\u00b7sen", "seyn", ",", "sonst", "kann", "kein", "Staat", "be\u00b7stehn", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "VAINF", "$,", "ADV", "VMFIN", "PIAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Weswegen will man denn Die, so sie lernen, schm\u00e4hn?", "tokens": ["Wes\u00b7we\u00b7gen", "will", "man", "denn", "Die", ",", "so", "sie", "ler\u00b7nen", ",", "schm\u00e4hn", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["NN", "VMFIN", "PIS", "ADV", "ART", "$,", "ADV", "PPER", "VVINF", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Vielleicht ist das allein ein Flei\u00df f\u00fcr kleine Seelen,", "tokens": ["Viel\u00b7leicht", "ist", "das", "al\u00b7lein", "ein", "Flei\u00df", "f\u00fcr", "klei\u00b7ne", "See\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PDS", "ADV", "ART", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wo Einsicht und Verstand zu gr\u00f6\u00dfern Dingen fehlen?", "tokens": ["Wo", "Ein\u00b7sicht", "und", "Ver\u00b7stand", "zu", "gr\u00f6\u00b7\u00dfern", "Din\u00b7gen", "feh\u00b7len", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "KON", "NN", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Gesetzt, es w\u00e4re so: wird denn wohl Der verlacht,", "tokens": ["Ge\u00b7setzt", ",", "es", "w\u00e4\u00b7re", "so", ":", "wird", "denn", "wohl", "Der", "ver\u00b7lacht", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "PPER", "VAFIN", "ADV", "$.", "VAFIN", "ADV", "ADV", "ART", "VVPP", "$,"], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.8": {"text": "Der auch mit kleiner M\u00fch' f\u00fcr Andrer Gl\u00fccke wacht?", "tokens": ["Der", "auch", "mit", "klei\u00b7ner", "M\u00fch'", "f\u00fcr", "A\u00b7ndrer", "Gl\u00fc\u00b7cke", "wacht", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "ADJA", "NN", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Und lobte man vielleicht an ihm mit besserm Rechte,", "tokens": ["Und", "lob\u00b7te", "man", "viel\u00b7leicht", "an", "ihm", "mit", "bes\u00b7serm", "Rech\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIS", "ADV", "APPR", "PPER", "APPR", "ADJA", "NN", "$,"], "meter": "-+--+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.10": {"text": "Wenn er durch gr\u00f6\u00dfern Flei\u00df geringern Nutzen br\u00e4chte?", "tokens": ["Wenn", "er", "durch", "gr\u00f6\u00b7\u00dfern", "Flei\u00df", "ge\u00b7rin\u00b7gern", "Nut\u00b7zen", "br\u00e4ch\u00b7te", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ADJA", "NN", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Doch, Tadler, glaubet nicht, der Rechte Wissenschaft", "tokens": ["Doch", ",", "Tad\u00b7ler", ",", "glau\u00b7bet", "nicht", ",", "der", "Rech\u00b7te", "Wis\u00b7sen\u00b7schaft"], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "$,", "NN", "$,", "VVFIN", "PTKNEG", "$,", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Erfodre wenig Flei\u00df, und nur geringe Kraft.", "tokens": ["Er\u00b7fod\u00b7re", "we\u00b7nig", "Flei\u00df", ",", "und", "nur", "ge\u00b7rin\u00b7ge", "Kraft", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "NN", "$,", "KON", "ADV", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Nicht Alle lernen sie in ihrem Umfang kennen,", "tokens": ["Nicht", "Al\u00b7le", "ler\u00b7nen", "sie", "in", "ih\u00b7rem", "Um\u00b7fang", "ken\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "PIS", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Die ihre Sch\u00fcler sind, ja die sich Lehrer nennen.", "tokens": ["Die", "ih\u00b7re", "Sch\u00fc\u00b7ler", "sind", ",", "ja", "die", "sich", "Leh\u00b7rer", "nen\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "VAFIN", "$,", "ADV", "ART", "PRF", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Der glaubt, im alten Rom, wo sich ihr Quell versteckt,", "tokens": ["Der", "glaubt", ",", "im", "al\u00b7ten", "Rom", ",", "wo", "sich", "ihr", "Quell", "ver\u00b7steckt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "$,", "APPRART", "ADJA", "NE", "$,", "PWAV", "PRF", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Sey Alles, was man nur zu wissen braucht, entdeckt;", "tokens": ["Sey", "Al\u00b7les", ",", "was", "man", "nur", "zu", "wis\u00b7sen", "braucht", ",", "ent\u00b7deckt", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["VAFIN", "PIS", "$,", "PRELS", "PIS", "ADV", "PTKZU", "VVINF", "VVFIN", "$,", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Ein Andrer, der sich nie vom Nutzen will entfernen,", "tokens": ["Ein", "A\u00b7ndrer", ",", "der", "sich", "nie", "vom", "Nut\u00b7zen", "will", "ent\u00b7fer\u00b7nen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PRF", "ADV", "APPRART", "NN", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Wird nur den Schlendrian der goldnen Praris lernen;", "tokens": ["Wird", "nur", "den", "Schlen\u00b7dri\u00b7an", "der", "gold\u00b7nen", "Pra\u00b7ris", "ler\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Und Beyder dummen Flei\u00df verlacht ein tiefer Geist,", "tokens": ["Und", "Bey\u00b7der", "dum\u00b7men", "Flei\u00df", "ver\u00b7lacht", "ein", "tie\u00b7fer", "Geist", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ADJA", "NN", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Der der Gesetze Grund, wie ein ", "tokens": ["Der", "der", "Ge\u00b7set\u00b7ze", "Grund", ",", "wie", "ein"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "ART", "NN", "NN", "$,", "PWAV", "ART"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.21": {"text": "Doch Alle fehlen hier, und Keiner w\u00fcrde fehlen,", "tokens": ["Doch", "Al\u00b7le", "feh\u00b7len", "hier", ",", "und", "Kei\u00b7ner", "w\u00fcr\u00b7de", "feh\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "ADV", "$,", "KON", "PIS", "VAFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Wollt' er des Andern Flei\u00df sich auch zum Beyspiel w\u00e4hlen.", "tokens": ["Wollt'", "er", "des", "An\u00b7dern", "Flei\u00df", "sich", "auch", "zum", "Bey\u00b7spiel", "w\u00e4h\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ART", "ADJA", "NN", "PRF", "ADV", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Mit Recht wird Griechenland, mit Rechte Rom verehrt;", "tokens": ["Mit", "Recht", "wird", "Grie\u00b7chen\u00b7land", ",", "mit", "Rech\u00b7te", "Rom", "ver\u00b7ehrt", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VAFIN", "NE", "$,", "APPR", "NN", "NE", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Dies hat die Welt regiert, und jenes sie gelehrt.", "tokens": ["Dies", "hat", "die", "Welt", "re\u00b7giert", ",", "und", "je\u00b7nes", "sie", "ge\u00b7lehrt", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "VVFIN", "$,", "KON", "PDS", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Mit Rechte fraget man, zum Nutzen stets besch\u00e4ftigt,", "tokens": ["Mit", "Rech\u00b7te", "fra\u00b7get", "man", ",", "zum", "Nut\u00b7zen", "stets", "be\u00b7sch\u00e4f\u00b7tigt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PIS", "$,", "APPRART", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Ob das, was man erlernt, auch der Gebrauch bekr\u00e4ftigt,", "tokens": ["Ob", "das", ",", "was", "man", "er\u00b7lernt", ",", "auch", "der", "Ge\u00b7brauch", "be\u00b7kr\u00e4f\u00b7tigt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDS", "$,", "PRELS", "PIS", "VVPP", "$,", "ADV", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Mit Recht sucht man von dem, was ein Gesetz gebeut,", "tokens": ["Mit", "Recht", "sucht", "man", "von", "dem", ",", "was", "ein", "Ge\u00b7setz", "ge\u00b7beut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PIS", "APPR", "ART", "$,", "PRELS", "ART", "NN", "VVFIN", "$,"], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.28": {"text": "Den unbewegten Grund in ew'ger Billigkeit.", "tokens": ["Den", "un\u00b7be\u00b7weg\u00b7ten", "Grund", "in", "ew'\u00b7ger", "Bil\u00b7lig\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Doch soll man nirgends nicht den wahren Weg verlieren:", "tokens": ["Doch", "soll", "man", "nir\u00b7gends", "nicht", "den", "wah\u00b7ren", "Weg", "ver\u00b7lie\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PIS", "ADV", "PTKNEG", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "So mu\u00df uns Alterthum, Gebrauch und Schlie\u00dfen f\u00fchren.", "tokens": ["So", "mu\u00df", "uns", "Al\u00b7ter\u00b7thum", ",", "Ge\u00b7brauch", "und", "Schlie\u00b7\u00dfen", "f\u00fch\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "NN", "$,", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "So viel umfa\u00dft ein Geist, der sich ", "tokens": ["So", "viel", "um\u00b7fa\u00dft", "ein", "Geist", ",", "der", "sich"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "ADV", "VVFIN", "ART", "NN", "$,", "PRELS", "PRF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Gest\u00e4rket durch Vernunft wie durch Gelehrsamkeit;", "tokens": ["Ge\u00b7st\u00e4r\u00b7ket", "durch", "Ver\u00b7nunft", "wie", "durch", "Ge\u00b7lehr\u00b7sam\u00b7keit", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "NN", "KOKOM", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die zeiget ihm den Weg, den man vor ihm gew\u00e4hlet,", "tokens": ["Die", "zei\u00b7get", "ihm", "den", "Weg", ",", "den", "man", "vor", "ihm", "ge\u00b7w\u00e4h\u00b7let", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ART", "NN", "$,", "PRELS", "PIS", "APPR", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die f\u00fchret seinen Schritt, wo ihm ein F\u00fchrer fehlet.", "tokens": ["Die", "f\u00fch\u00b7ret", "sei\u00b7nen", "Schritt", ",", "wo", "ihm", "ein", "F\u00fch\u00b7rer", "feh\u00b7let", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPOSAT", "NN", "$,", "PWAV", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Denn damit schmeichle sich kein schl\u00e4friger Verstand,", "tokens": ["Denn", "da\u00b7mit", "schmeich\u00b7le", "sich", "kein", "schl\u00e4f\u00b7ri\u00b7ger", "Ver\u00b7stand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PAV", "VVFIN", "PRF", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Da\u00df er nur Alles wei\u00df, was man vor ihm erkannt.", "tokens": ["Da\u00df", "er", "nur", "Al\u00b7les", "wei\u00df", ",", "was", "man", "vor", "ihm", "er\u00b7kannt", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PIS", "VVFIN", "$,", "PRELS", "PIS", "APPR", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Viel konnte man vor uns in feste Regeln binden:", "tokens": ["Viel", "konn\u00b7te", "man", "vor", "uns", "in", "fes\u00b7te", "Re\u00b7geln", "bin\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PIS", "APPR", "PPER", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Viel m\u00fcssen wir anjetzt selbst denken, selbst erfinden.", "tokens": ["Viel", "m\u00fcs\u00b7sen", "wir", "an\u00b7jetzt", "selbst", "den\u00b7ken", ",", "selbst", "er\u00b7fin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "ADV", "VVINF", "$,", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Hier schr\u00e4nkt man den Verstand zu weiter Vorschrift ein,", "tokens": ["Hier", "schr\u00e4nkt", "man", "den", "Ver\u00b7stand", "zu", "wei\u00b7ter", "Vor\u00b7schrift", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "ART", "NN", "APPR", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Den eingeschr\u00e4nkten Satz macht man dort allgemein,", "tokens": ["Den", "ein\u00b7ge\u00b7schr\u00e4nk\u00b7ten", "Satz", "macht", "man", "dort", "all\u00b7ge\u00b7mein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PIS", "ADV", "ADJD", "$,"], "meter": "-+-+-++--+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Erkl\u00e4rt, was dunkel ist, vers\u00f6hnt, was scheint zu streiten,", "tokens": ["Er\u00b7kl\u00e4rt", ",", "was", "dun\u00b7kel", "ist", ",", "ver\u00b7s\u00f6hnt", ",", "was", "scheint", "zu", "strei\u00b7ten", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "PRELS", "ADJD", "VAFIN", "$,", "VVPP", "$,", "PWS", "VVFIN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "L\u00e4\u00dft, wo kein F\u00fcrst befiehlt, von der Natur sich leiten;", "tokens": ["L\u00e4\u00dft", ",", "wo", "kein", "F\u00fcrst", "be\u00b7fiehlt", ",", "von", "der", "Na\u00b7tur", "sich", "lei\u00b7ten", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PWAV", "PIAT", "NN", "VVFIN", "$,", "APPR", "ART", "NN", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Was dieser Staat verlangt, schickt sich f\u00fcr jenen nicht,", "tokens": ["Was", "die\u00b7ser", "Staat", "ver\u00b7langt", ",", "schickt", "sich", "f\u00fcr", "je\u00b7nen", "nicht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PDAT", "NN", "VVPP", "$,", "VVFIN", "PRF", "APPR", "PDS", "PTKNEG", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Was sonst verboten war, wird jetzund oft zur Pflicht.", "tokens": ["Was", "sonst", "ver\u00b7bo\u00b7ten", "war", ",", "wird", "je\u00b7tzund", "oft", "zur", "Pflicht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "VVPP", "VAFIN", "$,", "VAFIN", "ADV", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Unendlich ist die Zahl von stets verschiednen F\u00e4llen,", "tokens": ["Un\u00b7end\u00b7lich", "ist", "die", "Zahl", "von", "stets", "ver\u00b7schied\u00b7nen", "F\u00e4l\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "ART", "NN", "APPR", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Man sieht sie manchen Band geh\u00e4ufter Spr\u00fcche schwellen.", "tokens": ["Man", "sieht", "sie", "man\u00b7chen", "Band", "ge\u00b7h\u00e4uf\u00b7ter", "Spr\u00fc\u00b7che", "schwel\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "PIAT", "NN", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Vergebens lernt daraus des Ansehns tr\u00e4ger Knecht:", "tokens": ["Ver\u00b7ge\u00b7bens", "lernt", "da\u00b7raus", "des", "An\u00b7sehns", "tr\u00e4\u00b7ger", "Knecht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PAV", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Ein neuer Umstand kommt, und heischt ein neues Recht.", "tokens": ["Ein", "neu\u00b7er", "Um\u00b7stand", "kommt", ",", "und", "heischt", "ein", "neu\u00b7es", "Recht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,", "KON", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Verwegner Bosheit Trotz mu\u00df man beherzt besiegen;", "tokens": ["Ver\u00b7weg\u00b7ner", "Bos\u00b7heit", "Trotz", "mu\u00df", "man", "be\u00b7herzt", "be\u00b7sie\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "APPR", "VMFIN", "PIS", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Mit Klugheit hindert man der schlauen List Betriegen,", "tokens": ["Mit", "Klug\u00b7heit", "hin\u00b7dert", "man", "der", "schlau\u00b7en", "List", "Be\u00b7trie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PIS", "ART", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Bestimmt des Beyfalls Maa\u00df, wenn man den Zeugen h\u00f6rt,", "tokens": ["Be\u00b7stimmt", "des", "Bey\u00b7falls", "Maa\u00df", ",", "wenn", "man", "den", "Zeu\u00b7gen", "h\u00f6rt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "NN", "$,", "KOUS", "PIS", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Ob er voll Dummheit irrt, voll Trug uns falsch belehrt.", "tokens": ["Ob", "er", "voll", "Dumm\u00b7heit", "irrt", ",", "voll", "Trug", "uns", "falsch", "be\u00b7lehrt", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "NN", "VVFIN", "$,", "ADJD", "NN", "PPER", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Lernt, wie die frevle List verborgner Uebelthaten", "tokens": ["Lernt", ",", "wie", "die", "frev\u00b7le", "List", "ver\u00b7borg\u00b7ner", "Ue\u00b7belt\u00b7ha\u00b7ten"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "$,", "PWAV", "ART", "ADJA", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Durch manches Zeichen sich der Rache mu\u00df verrathen.", "tokens": ["Durch", "man\u00b7ches", "Zei\u00b7chen", "sich", "der", "Ra\u00b7che", "mu\u00df", "ver\u00b7ra\u00b7then", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "PRF", "ART", "NN", "VMFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Dies Alles braucht Verstand. Umsonst ist Dessen Flei\u00df,", "tokens": ["Dies", "Al\u00b7les", "braucht", "Ver\u00b7stand", ".", "Um\u00b7sonst", "ist", "Des\u00b7sen", "Flei\u00df", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PIS", "VVFIN", "NN", "$.", "ADV", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Der, was man ihm gesagt, nur nachzusprechen wei\u00df.", "tokens": ["Der", ",", "was", "man", "ihm", "ge\u00b7sagt", ",", "nur", "nach\u00b7zu\u00b7spre\u00b7chen", "wei\u00df", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "$,", "PRELS", "PIS", "PPER", "VVPP", "$,", "ADV", "VVIZU", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Wahr ist es, da\u00df ein Schwarm ", "tokens": ["Wahr", "ist", "es", ",", "da\u00df", "ein", "Schwarm"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADJD", "VAFIN", "PPER", "$,", "KOUS", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "An Zahl den Fliegen gleich, die sich im Sommer mehren,", "tokens": ["An", "Zahl", "den", "Flie\u00b7gen", "gleich", ",", "die", "sich", "im", "Som\u00b7mer", "meh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ART", "NN", "ADV", "$,", "PRELS", "PRF", "APPRART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "F\u00fcr sich gedankenlos, von fremder Meynung voll,", "tokens": ["F\u00fcr", "sich", "ge\u00b7dan\u00b7ken\u00b7los", ",", "von", "frem\u00b7der", "Mey\u00b7nung", "voll", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRF", "ADJD", "$,", "APPR", "ADJA", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "(nur hat er noch Verstand, wenn er betriegen soll,)", "tokens": ["(", "nur", "hat", "er", "noch", "Ver\u00b7stand", ",", "wenn", "er", "be\u00b7trie\u00b7gen", "soll", ",", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADV", "VAFIN", "PPER", "ADV", "NN", "$,", "KOUS", "PPER", "VVINF", "VMFIN", "$,", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Der nie nach Billigkeit, nie nach Vernunft getrachtet,", "tokens": ["Der", "nie", "nach", "Bil\u00b7lig\u00b7keit", ",", "nie", "nach", "Ver\u00b7nunft", "ge\u00b7trach\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "NN", "$,", "ADV", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Vom P\u00f6bel stets geha\u00dft, vom Weisen stets verachtet.", "tokens": ["Vom", "P\u00f6\u00b7bel", "stets", "ge\u00b7ha\u00dft", ",", "vom", "Wei\u00b7sen", "stets", "ver\u00b7ach\u00b7tet", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADV", "VVPP", "$,", "APPRART", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Doch wer ist, der so schlecht den Werth der Dinge kennt,", "tokens": ["Doch", "wer", "ist", ",", "der", "so", "schlecht", "den", "Werth", "der", "Din\u00b7ge", "kennt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VAFIN", "$,", "PRELS", "ADV", "ADJD", "ART", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Da\u00df er ein solches Volk ", "tokens": ["Da\u00df", "er", "ein", "sol\u00b7ches", "Volk"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "PIAT", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "Wo ist die Wissenschaft, da nicht der Thoren Menge", "tokens": ["Wo", "ist", "die", "Wis\u00b7sen\u00b7schaft", ",", "da", "nicht", "der", "Tho\u00b7ren", "Men\u00b7ge"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PWAV", "VAFIN", "ART", "NN", "$,", "KOUS", "PTKNEG", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Sich zu der kleinen Zahl von wahren Weisen dr\u00e4nge?", "tokens": ["Sich", "zu", "der", "klei\u00b7nen", "Zahl", "von", "wah\u00b7ren", "Wei\u00b7sen", "dr\u00e4n\u00b7ge", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "ART", "ADJA", "NN", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Wie aber, flieht nicht Der, der sichre Kenntni\u00df liebt,", "tokens": ["Wie", "a\u00b7ber", ",", "flieht", "nicht", "Der", ",", "der", "sich\u00b7re", "Kennt\u00b7ni\u00df", "liebt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "$,", "VVFIN", "PTKNEG", "ART", "$,", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die Kunst, wo steter Zank die gr\u00f6\u00dften Meister \u00fcbt,", "tokens": ["Die", "Kunst", ",", "wo", "ste\u00b7ter", "Zank", "die", "gr\u00f6\u00df\u00b7ten", "Meis\u00b7ter", "\u00fcbt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PWAV", "ADJA", "NN", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und wider einen Spruch, der auf das Recht sich st\u00fctzet,", "tokens": ["Und", "wi\u00b7der", "ei\u00b7nen", "Spruch", ",", "der", "auf", "das", "Recht", "sich", "st\u00fct\u00b7zet", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "$,", "PRELS", "APPR", "ART", "NN", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ein andrer Spruch erscheint, den auch das Recht besch\u00fctzet?", "tokens": ["Ein", "an\u00b7drer", "Spruch", "er\u00b7scheint", ",", "den", "auch", "das", "Recht", "be\u00b7sch\u00fct\u00b7zet", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,", "PRELS", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Bisweilen wankt das Recht, ich r\u00e4um' es willig ein:", "tokens": ["Bis\u00b7wei\u00b7len", "wankt", "das", "Recht", ",", "ich", "r\u00e4um'", "es", "wil\u00b7lig", "ein", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$,", "PPER", "VVFIN", "PPER", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Doch \u00f6fter wird die Schuld nur an dem Lehrer seyn.", "tokens": ["Doch", "\u00f6f\u00b7ter", "wird", "die", "Schuld", "nur", "an", "dem", "Leh\u00b7rer", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "ART", "NN", "ADV", "APPR", "ART", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Ein Geist von Wahrheit voll, gew\u00f6hnt zu scharfen Schl\u00fcssen,", "tokens": ["Ein", "Geist", "von", "Wahr\u00b7heit", "voll", ",", "ge\u00b7w\u00f6hnt", "zu", "schar\u00b7fen", "Schl\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "ADJD", "$,", "VVPP", "PTKZU", "VVINF", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Entdecket da Beweis, wo Andre glauben m\u00fcssen,", "tokens": ["Ent\u00b7de\u00b7cket", "da", "Be\u00b7weis", ",", "wo", "And\u00b7re", "glau\u00b7ben", "m\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "NN", "$,", "PWAV", "PIS", "VVINF", "VMINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Und wo ihm das Gesetz vielleicht zu dunkel spricht,", "tokens": ["Und", "wo", "ihm", "das", "Ge\u00b7setz", "viel\u00b7leicht", "zu", "dun\u00b7kel", "spricht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPER", "ART", "NN", "ADV", "PTKA", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Versagt die Billigkeit ihm ihren Ausspruch nicht.", "tokens": ["Ver\u00b7sagt", "die", "Bil\u00b7lig\u00b7keit", "ihm", "ih\u00b7ren", "Aus\u00b7spruch", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "PPER", "PPOSAT", "NN", "PTKNEG", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Durch ein verdreht Gesetz, durch ein verwirrt Erz\u00e4hlen", "tokens": ["Durch", "ein", "ver\u00b7dreht", "Ge\u00b7setz", ",", "durch", "ein", "ver\u00b7wirrt", "Er\u00b7z\u00e4h\u00b7len"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "ART", "VVFIN", "NN", "$,", "APPR", "ART", "ADJD", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Gl\u00fcckt es dem Z\u00e4nker nicht, ihm Beyfall abzustehlen.", "tokens": ["Gl\u00fcckt", "es", "dem", "Z\u00e4n\u00b7ker", "nicht", ",", "ihm", "Bey\u00b7fall", "ab\u00b7zu\u00b7steh\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "PTKNEG", "$,", "PPER", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Durch ihn wird selbst das Recht, das so verworren scheint,", "tokens": ["Durch", "ihn", "wird", "selbst", "das", "Recht", ",", "das", "so", "ver\u00b7wor\u00b7ren", "scheint", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VAFIN", "ADV", "ART", "NN", "$,", "PRELS", "ADV", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Ein ordentlicher Bau, wo Alles sich vereint.", "tokens": ["Ein", "or\u00b7dent\u00b7li\u00b7cher", "Bau", ",", "wo", "Al\u00b7les", "sich", "ver\u00b7eint", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PWAV", "PIS", "PRF", "VVPP", "$."], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.15": {"text": "Er sieht, wie ein Gesetz sich stets im andern gr\u00fcndet,", "tokens": ["Er", "sieht", ",", "wie", "ein", "Ge\u00b7setz", "sich", "stets", "im", "an\u00b7dern", "gr\u00fcn\u00b7det", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PWAV", "ART", "NN", "PRF", "ADV", "APPRART", "ADJA", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Den Menschen die Natur, der Staat den B\u00fcrger bindet;", "tokens": ["Den", "Men\u00b7schen", "die", "Na\u00b7tur", ",", "der", "Staat", "den", "B\u00fcr\u00b7ger", "bin\u00b7det", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$,", "ART", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Er kennet, er verehrt die Weisen jener Zeit,", "tokens": ["Er", "ken\u00b7net", ",", "er", "ver\u00b7ehrt", "die", "Wei\u00b7sen", "je\u00b7ner", "Zeit", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VVFIN", "ART", "NN", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Wie sie, an Einsicht stark, und voll Gerechtigkeit.", "tokens": ["Wie", "sie", ",", "an", "Ein\u00b7sicht", "stark", ",", "und", "voll", "Ge\u00b7rech\u00b7tig\u00b7keit", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "$,", "APPR", "NN", "ADJD", "$,", "KON", "ADJD", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Vergleicht man sie mit ihm, nach weit entfernten Jahren,", "tokens": ["Ver\u00b7gleicht", "man", "sie", "mit", "ihm", ",", "nach", "weit", "ent\u00b7fern\u00b7ten", "Jah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PPER", "APPR", "PPER", "$,", "APPR", "ADJD", "ADJA", "NN", "$,"], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.20": {"text": "Wird das ihr Vorzug seyn, da\u00df sie sein Muster waren.", "tokens": ["Wird", "das", "ihr", "Vor\u00b7zug", "seyn", ",", "da\u00df", "sie", "sein", "Mus\u00b7ter", "wa\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "PPOSAT", "NN", "VAINF", "$,", "KOUS", "PPER", "PPOSAT", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Er wirkt der Menschen Gl\u00fcck durch Tugend und Verstand;", "tokens": ["Er", "wirkt", "der", "Men\u00b7schen", "Gl\u00fcck", "durch", "Tu\u00b7gend", "und", "Ver\u00b7stand", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "NN", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Nun urtheilt, wird er wohl verehrungswerth erkannt?", "tokens": ["Nun", "ur\u00b7theilt", ",", "wird", "er", "wohl", "ver\u00b7eh\u00b7rungs\u00b7werth", "er\u00b7kannt", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "VAFIN", "PPER", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "Sagt, Freunde, denen es durch vielen Flei\u00df gelungen,", "tokens": ["Sagt", ",", "Freun\u00b7de", ",", "de\u00b7nen", "es", "durch", "vie\u00b7len", "Flei\u00df", "ge\u00b7lun\u00b7gen", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "NN", "$,", "PRELS", "PPER", "APPR", "PIAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Da\u00df ihr ins Heiligthum ", "tokens": ["Da\u00df", "ihr", "ins", "Hei\u00b7lig\u00b7thum"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPRART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ist's m\u00f6glich, da\u00df ein Geist, der Witz und Denken liebt,", "tokens": ["Ist's", "m\u00f6g\u00b7lich", ",", "da\u00df", "ein", "Geist", ",", "der", "Witz", "und", "Den\u00b7ken", "liebt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADJD", "$,", "KOUS", "ART", "NN", "$,", "ART", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "In eurer Wissenschaft sich mit Vergn\u00fcgen \u00fcbt?", "tokens": ["In", "eu\u00b7rer", "Wis\u00b7sen\u00b7schaft", "sich", "mit", "Ver\u00b7gn\u00fc\u00b7gen", "\u00fcbt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PRF", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Sagt, womit kann uns wohl das Chaos von Gesetzen,", "tokens": ["Sagt", ",", "wo\u00b7mit", "kann", "uns", "wohl", "das", "Chaos", "von", "Ge\u00b7set\u00b7zen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PWAV", "VMFIN", "PPER", "ADV", "ART", "NN", "APPR", "NN", "$,"], "meter": "---+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Verwirrt, voll Dunkelheit, voll innerm Zwist, erg\u00f6tzen?", "tokens": ["Ver\u00b7wirrt", ",", "voll", "Dun\u00b7kel\u00b7heit", ",", "voll", "in\u00b7nerm", "Zwist", ",", "er\u00b7g\u00f6t\u00b7zen", "?"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["VVPP", "$,", "ADJD", "NN", "$,", "ADJD", "APPRART", "NN", "$,", "VVINF", "$."], "meter": "-+-+-++--+-+-", "measure": "iambic.hexa.relaxed"}, "line.7": {"text": "Durch was f\u00fcr Wollust wird der m\u00fcde Flei\u00df gest\u00e4rkt,", "tokens": ["Durch", "was", "f\u00fcr", "Wol\u00b7lust", "wird", "der", "m\u00fc\u00b7de", "Flei\u00df", "ge\u00b7st\u00e4rkt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "APPR", "NN", "VAFIN", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Wenn das Ged\u00e4chtni\u00df nur zerstreute S\u00e4tze merkt?", "tokens": ["Wenn", "das", "Ge\u00b7d\u00e4cht\u00b7ni\u00df", "nur", "zer\u00b7streu\u00b7te", "S\u00e4t\u00b7ze", "merkt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ADV", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Was wirket der Verstand, wenn wir f\u00fcr Grund und Schl\u00fcssen,", "tokens": ["Was", "wir\u00b7ket", "der", "Ver\u00b7stand", ",", "wenn", "wir", "f\u00fcr", "Grund", "und", "Schl\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ART", "NN", "$,", "KOUS", "PPER", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Nur auf des Lehrers Wort, die Lehren glauben m\u00fcssen?", "tokens": ["Nur", "auf", "des", "Leh\u00b7rers", "Wort", ",", "die", "Leh\u00b7ren", "glau\u00b7ben", "m\u00fcs\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "NN", "$,", "ART", "NN", "VVINF", "VMINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Wenn ein bew\u00e4hrter Mann dem andern widerspricht,", "tokens": ["Wenn", "ein", "be\u00b7w\u00e4hr\u00b7ter", "Mann", "dem", "an\u00b7dern", "wi\u00b7der\u00b7spricht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "ART", "ADJA", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "(der Beyfall des Gebrauchs fehlt keiner Meynung nicht);", "tokens": ["(", "der", "Bey\u00b7fall", "des", "Ge\u00b7brauchs", "fehlt", "kei\u00b7ner", "Mey\u00b7nung", "nicht", ")", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ART", "NN", "ART", "NN", "VVFIN", "PIAT", "NN", "PTKNEG", "$(", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Wenn man hier billig hei\u00dft, was man dort strafbar nennet;", "tokens": ["Wenn", "man", "hier", "bil\u00b7lig", "hei\u00dft", ",", "was", "man", "dort", "straf\u00b7bar", "nen\u00b7net", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ADV", "ADJD", "VVFIN", "$,", "PRELS", "PIS", "ADV", "ADJD", "VVFIN", "$."], "meter": "-+-+-+--+-+--", "measure": "iambic.penta.relaxed"}, "line.14": {"text": "Hier zu gelinde spricht, und dort zu scharf erkennet;", "tokens": ["Hier", "zu", "ge\u00b7lin\u00b7de", "spricht", ",", "und", "dort", "zu", "scharf", "er\u00b7ken\u00b7net", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ADJA", "VVFIN", "$,", "KON", "ADV", "PTKA", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Wenn man der Meynung folgt, die die Vernunft verdammt,", "tokens": ["Wenn", "man", "der", "Mey\u00b7nung", "folgt", ",", "die", "die", "Ver\u00b7nunft", "ver\u00b7dammt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ART", "NN", "VVFIN", "$,", "PRELS", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Nur weil sie auf uns her von unsern V\u00e4tern stammt;", "tokens": ["Nur", "weil", "sie", "auf", "uns", "her", "von", "un\u00b7sern", "V\u00e4\u00b7tern", "stammt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PPER", "APPR", "PPER", "ADV", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Mit der Gerichte Brauch, mit jedes Dorfes Sitten,", "tokens": ["Mit", "der", "Ge\u00b7rich\u00b7te", "Brauch", ",", "mit", "je\u00b7des", "Dor\u00b7fes", "Sit\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "$,", "APPR", "PIAT", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Der Ordnung jeder Stadt sich mu\u00df den Kopf zerr\u00fctten;", "tokens": ["Der", "Ord\u00b7nung", "je\u00b7der", "Stadt", "sich", "mu\u00df", "den", "Kopf", "zer\u00b7r\u00fct\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PIAT", "NN", "PRF", "VMFIN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Und wenn zuletzt die Frucht von so viel Arbeit ist,", "tokens": ["Und", "wenn", "zu\u00b7letzt", "die", "Frucht", "von", "so", "viel", "Ar\u00b7beit", "ist", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ADV", "ART", "NN", "APPR", "ADV", "PIAT", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Da\u00df man im dicken Sto\u00df verworrner Acten liest?", "tokens": ["Da\u00df", "man", "im", "di\u00b7cken", "Sto\u00df", "ver\u00b7worr\u00b7ner", "Ac\u00b7ten", "liest", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "APPRART", "ADJA", "NN", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "So, Freunde, h\u00f6r' ich oft zu k\u00fchne Sp\u00f6tter richten.", "tokens": ["So", ",", "Freun\u00b7de", ",", "h\u00f6r'", "ich", "oft", "zu", "k\u00fch\u00b7ne", "Sp\u00f6t\u00b7ter", "rich\u00b7ten", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "NN", "$,", "VVFIN", "PPER", "ADV", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Beurtheilt, kann dies Blatt wohl ihren Wahn vernichten?", "tokens": ["Beurt\u00b7heilt", ",", "kann", "dies", "Blatt", "wohl", "ih\u00b7ren", "Wahn", "ver\u00b7nich\u00b7ten", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "VMFIN", "PDS", "NN", "ADV", "PPOSAT", "NN", "VVINF", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.3": {"text": "Gesetze m\u00fcssen seyn, sonst kann kein Staat bestehn,", "tokens": ["Ge\u00b7set\u00b7ze", "m\u00fcs\u00b7sen", "seyn", ",", "sonst", "kann", "kein", "Staat", "be\u00b7stehn", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "VAINF", "$,", "ADV", "VMFIN", "PIAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Weswegen will man denn Die, so sie lernen, schm\u00e4hn?", "tokens": ["Wes\u00b7we\u00b7gen", "will", "man", "denn", "Die", ",", "so", "sie", "ler\u00b7nen", ",", "schm\u00e4hn", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["NN", "VMFIN", "PIS", "ADV", "ART", "$,", "ADV", "PPER", "VVINF", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Vielleicht ist das allein ein Flei\u00df f\u00fcr kleine Seelen,", "tokens": ["Viel\u00b7leicht", "ist", "das", "al\u00b7lein", "ein", "Flei\u00df", "f\u00fcr", "klei\u00b7ne", "See\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PDS", "ADV", "ART", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wo Einsicht und Verstand zu gr\u00f6\u00dfern Dingen fehlen?", "tokens": ["Wo", "Ein\u00b7sicht", "und", "Ver\u00b7stand", "zu", "gr\u00f6\u00b7\u00dfern", "Din\u00b7gen", "feh\u00b7len", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "KON", "NN", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Gesetzt, es w\u00e4re so: wird denn wohl Der verlacht,", "tokens": ["Ge\u00b7setzt", ",", "es", "w\u00e4\u00b7re", "so", ":", "wird", "denn", "wohl", "Der", "ver\u00b7lacht", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "PPER", "VAFIN", "ADV", "$.", "VAFIN", "ADV", "ADV", "ART", "VVPP", "$,"], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.8": {"text": "Der auch mit kleiner M\u00fch' f\u00fcr Andrer Gl\u00fccke wacht?", "tokens": ["Der", "auch", "mit", "klei\u00b7ner", "M\u00fch'", "f\u00fcr", "A\u00b7ndrer", "Gl\u00fc\u00b7cke", "wacht", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "ADJA", "NN", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Und lobte man vielleicht an ihm mit besserm Rechte,", "tokens": ["Und", "lob\u00b7te", "man", "viel\u00b7leicht", "an", "ihm", "mit", "bes\u00b7serm", "Rech\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIS", "ADV", "APPR", "PPER", "APPR", "ADJA", "NN", "$,"], "meter": "-+--+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.10": {"text": "Wenn er durch gr\u00f6\u00dfern Flei\u00df geringern Nutzen br\u00e4chte?", "tokens": ["Wenn", "er", "durch", "gr\u00f6\u00b7\u00dfern", "Flei\u00df", "ge\u00b7rin\u00b7gern", "Nut\u00b7zen", "br\u00e4ch\u00b7te", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ADJA", "NN", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Doch, Tadler, glaubet nicht, der Rechte Wissenschaft", "tokens": ["Doch", ",", "Tad\u00b7ler", ",", "glau\u00b7bet", "nicht", ",", "der", "Rech\u00b7te", "Wis\u00b7sen\u00b7schaft"], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "$,", "NN", "$,", "VVFIN", "PTKNEG", "$,", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Erfodre wenig Flei\u00df, und nur geringe Kraft.", "tokens": ["Er\u00b7fod\u00b7re", "we\u00b7nig", "Flei\u00df", ",", "und", "nur", "ge\u00b7rin\u00b7ge", "Kraft", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "NN", "$,", "KON", "ADV", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Nicht Alle lernen sie in ihrem Umfang kennen,", "tokens": ["Nicht", "Al\u00b7le", "ler\u00b7nen", "sie", "in", "ih\u00b7rem", "Um\u00b7fang", "ken\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "PIS", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Die ihre Sch\u00fcler sind, ja die sich Lehrer nennen.", "tokens": ["Die", "ih\u00b7re", "Sch\u00fc\u00b7ler", "sind", ",", "ja", "die", "sich", "Leh\u00b7rer", "nen\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "VAFIN", "$,", "ADV", "ART", "PRF", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Der glaubt, im alten Rom, wo sich ihr Quell versteckt,", "tokens": ["Der", "glaubt", ",", "im", "al\u00b7ten", "Rom", ",", "wo", "sich", "ihr", "Quell", "ver\u00b7steckt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "$,", "APPRART", "ADJA", "NE", "$,", "PWAV", "PRF", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Sey Alles, was man nur zu wissen braucht, entdeckt;", "tokens": ["Sey", "Al\u00b7les", ",", "was", "man", "nur", "zu", "wis\u00b7sen", "braucht", ",", "ent\u00b7deckt", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["VAFIN", "PIS", "$,", "PRELS", "PIS", "ADV", "PTKZU", "VVINF", "VVFIN", "$,", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Ein Andrer, der sich nie vom Nutzen will entfernen,", "tokens": ["Ein", "A\u00b7ndrer", ",", "der", "sich", "nie", "vom", "Nut\u00b7zen", "will", "ent\u00b7fer\u00b7nen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PRF", "ADV", "APPRART", "NN", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Wird nur den Schlendrian der goldnen Praris lernen;", "tokens": ["Wird", "nur", "den", "Schlen\u00b7dri\u00b7an", "der", "gold\u00b7nen", "Pra\u00b7ris", "ler\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Und Beyder dummen Flei\u00df verlacht ein tiefer Geist,", "tokens": ["Und", "Bey\u00b7der", "dum\u00b7men", "Flei\u00df", "ver\u00b7lacht", "ein", "tie\u00b7fer", "Geist", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ADJA", "NN", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Der der Gesetze Grund, wie ein ", "tokens": ["Der", "der", "Ge\u00b7set\u00b7ze", "Grund", ",", "wie", "ein"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "ART", "NN", "NN", "$,", "PWAV", "ART"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.21": {"text": "Doch Alle fehlen hier, und Keiner w\u00fcrde fehlen,", "tokens": ["Doch", "Al\u00b7le", "feh\u00b7len", "hier", ",", "und", "Kei\u00b7ner", "w\u00fcr\u00b7de", "feh\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "ADV", "$,", "KON", "PIS", "VAFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Wollt' er des Andern Flei\u00df sich auch zum Beyspiel w\u00e4hlen.", "tokens": ["Wollt'", "er", "des", "An\u00b7dern", "Flei\u00df", "sich", "auch", "zum", "Bey\u00b7spiel", "w\u00e4h\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ART", "ADJA", "NN", "PRF", "ADV", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Mit Recht wird Griechenland, mit Rechte Rom verehrt;", "tokens": ["Mit", "Recht", "wird", "Grie\u00b7chen\u00b7land", ",", "mit", "Rech\u00b7te", "Rom", "ver\u00b7ehrt", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VAFIN", "NE", "$,", "APPR", "NN", "NE", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Dies hat die Welt regiert, und jenes sie gelehrt.", "tokens": ["Dies", "hat", "die", "Welt", "re\u00b7giert", ",", "und", "je\u00b7nes", "sie", "ge\u00b7lehrt", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "VVFIN", "$,", "KON", "PDS", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Mit Rechte fraget man, zum Nutzen stets besch\u00e4ftigt,", "tokens": ["Mit", "Rech\u00b7te", "fra\u00b7get", "man", ",", "zum", "Nut\u00b7zen", "stets", "be\u00b7sch\u00e4f\u00b7tigt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PIS", "$,", "APPRART", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Ob das, was man erlernt, auch der Gebrauch bekr\u00e4ftigt,", "tokens": ["Ob", "das", ",", "was", "man", "er\u00b7lernt", ",", "auch", "der", "Ge\u00b7brauch", "be\u00b7kr\u00e4f\u00b7tigt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDS", "$,", "PRELS", "PIS", "VVPP", "$,", "ADV", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Mit Recht sucht man von dem, was ein Gesetz gebeut,", "tokens": ["Mit", "Recht", "sucht", "man", "von", "dem", ",", "was", "ein", "Ge\u00b7setz", "ge\u00b7beut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PIS", "APPR", "ART", "$,", "PRELS", "ART", "NN", "VVFIN", "$,"], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.28": {"text": "Den unbewegten Grund in ew'ger Billigkeit.", "tokens": ["Den", "un\u00b7be\u00b7weg\u00b7ten", "Grund", "in", "ew'\u00b7ger", "Bil\u00b7lig\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Doch soll man nirgends nicht den wahren Weg verlieren:", "tokens": ["Doch", "soll", "man", "nir\u00b7gends", "nicht", "den", "wah\u00b7ren", "Weg", "ver\u00b7lie\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PIS", "ADV", "PTKNEG", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "So mu\u00df uns Alterthum, Gebrauch und Schlie\u00dfen f\u00fchren.", "tokens": ["So", "mu\u00df", "uns", "Al\u00b7ter\u00b7thum", ",", "Ge\u00b7brauch", "und", "Schlie\u00b7\u00dfen", "f\u00fch\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "NN", "$,", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.10": {"line.1": {"text": "So viel umfa\u00dft ein Geist, der sich ", "tokens": ["So", "viel", "um\u00b7fa\u00dft", "ein", "Geist", ",", "der", "sich"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "ADV", "VVFIN", "ART", "NN", "$,", "PRELS", "PRF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Gest\u00e4rket durch Vernunft wie durch Gelehrsamkeit;", "tokens": ["Ge\u00b7st\u00e4r\u00b7ket", "durch", "Ver\u00b7nunft", "wie", "durch", "Ge\u00b7lehr\u00b7sam\u00b7keit", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "NN", "KOKOM", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die zeiget ihm den Weg, den man vor ihm gew\u00e4hlet,", "tokens": ["Die", "zei\u00b7get", "ihm", "den", "Weg", ",", "den", "man", "vor", "ihm", "ge\u00b7w\u00e4h\u00b7let", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ART", "NN", "$,", "PRELS", "PIS", "APPR", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die f\u00fchret seinen Schritt, wo ihm ein F\u00fchrer fehlet.", "tokens": ["Die", "f\u00fch\u00b7ret", "sei\u00b7nen", "Schritt", ",", "wo", "ihm", "ein", "F\u00fch\u00b7rer", "feh\u00b7let", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPOSAT", "NN", "$,", "PWAV", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.11": {"line.1": {"text": "Denn damit schmeichle sich kein schl\u00e4friger Verstand,", "tokens": ["Denn", "da\u00b7mit", "schmeich\u00b7le", "sich", "kein", "schl\u00e4f\u00b7ri\u00b7ger", "Ver\u00b7stand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PAV", "VVFIN", "PRF", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Da\u00df er nur Alles wei\u00df, was man vor ihm erkannt.", "tokens": ["Da\u00df", "er", "nur", "Al\u00b7les", "wei\u00df", ",", "was", "man", "vor", "ihm", "er\u00b7kannt", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PIS", "VVFIN", "$,", "PRELS", "PIS", "APPR", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Viel konnte man vor uns in feste Regeln binden:", "tokens": ["Viel", "konn\u00b7te", "man", "vor", "uns", "in", "fes\u00b7te", "Re\u00b7geln", "bin\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PIS", "APPR", "PPER", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Viel m\u00fcssen wir anjetzt selbst denken, selbst erfinden.", "tokens": ["Viel", "m\u00fcs\u00b7sen", "wir", "an\u00b7jetzt", "selbst", "den\u00b7ken", ",", "selbst", "er\u00b7fin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "ADV", "VVINF", "$,", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.12": {"line.1": {"text": "Hier schr\u00e4nkt man den Verstand zu weiter Vorschrift ein,", "tokens": ["Hier", "schr\u00e4nkt", "man", "den", "Ver\u00b7stand", "zu", "wei\u00b7ter", "Vor\u00b7schrift", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "ART", "NN", "APPR", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Den eingeschr\u00e4nkten Satz macht man dort allgemein,", "tokens": ["Den", "ein\u00b7ge\u00b7schr\u00e4nk\u00b7ten", "Satz", "macht", "man", "dort", "all\u00b7ge\u00b7mein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PIS", "ADV", "ADJD", "$,"], "meter": "-+-+-++--+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Erkl\u00e4rt, was dunkel ist, vers\u00f6hnt, was scheint zu streiten,", "tokens": ["Er\u00b7kl\u00e4rt", ",", "was", "dun\u00b7kel", "ist", ",", "ver\u00b7s\u00f6hnt", ",", "was", "scheint", "zu", "strei\u00b7ten", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "PRELS", "ADJD", "VAFIN", "$,", "VVPP", "$,", "PWS", "VVFIN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "L\u00e4\u00dft, wo kein F\u00fcrst befiehlt, von der Natur sich leiten;", "tokens": ["L\u00e4\u00dft", ",", "wo", "kein", "F\u00fcrst", "be\u00b7fiehlt", ",", "von", "der", "Na\u00b7tur", "sich", "lei\u00b7ten", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PWAV", "PIAT", "NN", "VVFIN", "$,", "APPR", "ART", "NN", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Was dieser Staat verlangt, schickt sich f\u00fcr jenen nicht,", "tokens": ["Was", "die\u00b7ser", "Staat", "ver\u00b7langt", ",", "schickt", "sich", "f\u00fcr", "je\u00b7nen", "nicht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PDAT", "NN", "VVPP", "$,", "VVFIN", "PRF", "APPR", "PDS", "PTKNEG", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Was sonst verboten war, wird jetzund oft zur Pflicht.", "tokens": ["Was", "sonst", "ver\u00b7bo\u00b7ten", "war", ",", "wird", "je\u00b7tzund", "oft", "zur", "Pflicht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "VVPP", "VAFIN", "$,", "VAFIN", "ADV", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Unendlich ist die Zahl von stets verschiednen F\u00e4llen,", "tokens": ["Un\u00b7end\u00b7lich", "ist", "die", "Zahl", "von", "stets", "ver\u00b7schied\u00b7nen", "F\u00e4l\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "ART", "NN", "APPR", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Man sieht sie manchen Band geh\u00e4ufter Spr\u00fcche schwellen.", "tokens": ["Man", "sieht", "sie", "man\u00b7chen", "Band", "ge\u00b7h\u00e4uf\u00b7ter", "Spr\u00fc\u00b7che", "schwel\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "PIAT", "NN", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Vergebens lernt daraus des Ansehns tr\u00e4ger Knecht:", "tokens": ["Ver\u00b7ge\u00b7bens", "lernt", "da\u00b7raus", "des", "An\u00b7sehns", "tr\u00e4\u00b7ger", "Knecht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PAV", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Ein neuer Umstand kommt, und heischt ein neues Recht.", "tokens": ["Ein", "neu\u00b7er", "Um\u00b7stand", "kommt", ",", "und", "heischt", "ein", "neu\u00b7es", "Recht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,", "KON", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Verwegner Bosheit Trotz mu\u00df man beherzt besiegen;", "tokens": ["Ver\u00b7weg\u00b7ner", "Bos\u00b7heit", "Trotz", "mu\u00df", "man", "be\u00b7herzt", "be\u00b7sie\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "APPR", "VMFIN", "PIS", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Mit Klugheit hindert man der schlauen List Betriegen,", "tokens": ["Mit", "Klug\u00b7heit", "hin\u00b7dert", "man", "der", "schlau\u00b7en", "List", "Be\u00b7trie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PIS", "ART", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Bestimmt des Beyfalls Maa\u00df, wenn man den Zeugen h\u00f6rt,", "tokens": ["Be\u00b7stimmt", "des", "Bey\u00b7falls", "Maa\u00df", ",", "wenn", "man", "den", "Zeu\u00b7gen", "h\u00f6rt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "NN", "$,", "KOUS", "PIS", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Ob er voll Dummheit irrt, voll Trug uns falsch belehrt.", "tokens": ["Ob", "er", "voll", "Dumm\u00b7heit", "irrt", ",", "voll", "Trug", "uns", "falsch", "be\u00b7lehrt", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "NN", "VVFIN", "$,", "ADJD", "NN", "PPER", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Lernt, wie die frevle List verborgner Uebelthaten", "tokens": ["Lernt", ",", "wie", "die", "frev\u00b7le", "List", "ver\u00b7borg\u00b7ner", "Ue\u00b7belt\u00b7ha\u00b7ten"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "$,", "PWAV", "ART", "ADJA", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Durch manches Zeichen sich der Rache mu\u00df verrathen.", "tokens": ["Durch", "man\u00b7ches", "Zei\u00b7chen", "sich", "der", "Ra\u00b7che", "mu\u00df", "ver\u00b7ra\u00b7then", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "PRF", "ART", "NN", "VMFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Dies Alles braucht Verstand. Umsonst ist Dessen Flei\u00df,", "tokens": ["Dies", "Al\u00b7les", "braucht", "Ver\u00b7stand", ".", "Um\u00b7sonst", "ist", "Des\u00b7sen", "Flei\u00df", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PIS", "VVFIN", "NN", "$.", "ADV", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Der, was man ihm gesagt, nur nachzusprechen wei\u00df.", "tokens": ["Der", ",", "was", "man", "ihm", "ge\u00b7sagt", ",", "nur", "nach\u00b7zu\u00b7spre\u00b7chen", "wei\u00df", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "$,", "PRELS", "PIS", "PPER", "VVPP", "$,", "ADV", "VVIZU", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.13": {"line.1": {"text": "Wahr ist es, da\u00df ein Schwarm ", "tokens": ["Wahr", "ist", "es", ",", "da\u00df", "ein", "Schwarm"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADJD", "VAFIN", "PPER", "$,", "KOUS", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "An Zahl den Fliegen gleich, die sich im Sommer mehren,", "tokens": ["An", "Zahl", "den", "Flie\u00b7gen", "gleich", ",", "die", "sich", "im", "Som\u00b7mer", "meh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ART", "NN", "ADV", "$,", "PRELS", "PRF", "APPRART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "F\u00fcr sich gedankenlos, von fremder Meynung voll,", "tokens": ["F\u00fcr", "sich", "ge\u00b7dan\u00b7ken\u00b7los", ",", "von", "frem\u00b7der", "Mey\u00b7nung", "voll", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRF", "ADJD", "$,", "APPR", "ADJA", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "(nur hat er noch Verstand, wenn er betriegen soll,)", "tokens": ["(", "nur", "hat", "er", "noch", "Ver\u00b7stand", ",", "wenn", "er", "be\u00b7trie\u00b7gen", "soll", ",", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADV", "VAFIN", "PPER", "ADV", "NN", "$,", "KOUS", "PPER", "VVINF", "VMFIN", "$,", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Der nie nach Billigkeit, nie nach Vernunft getrachtet,", "tokens": ["Der", "nie", "nach", "Bil\u00b7lig\u00b7keit", ",", "nie", "nach", "Ver\u00b7nunft", "ge\u00b7trach\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "NN", "$,", "ADV", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Vom P\u00f6bel stets geha\u00dft, vom Weisen stets verachtet.", "tokens": ["Vom", "P\u00f6\u00b7bel", "stets", "ge\u00b7ha\u00dft", ",", "vom", "Wei\u00b7sen", "stets", "ver\u00b7ach\u00b7tet", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADV", "VVPP", "$,", "APPRART", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Doch wer ist, der so schlecht den Werth der Dinge kennt,", "tokens": ["Doch", "wer", "ist", ",", "der", "so", "schlecht", "den", "Werth", "der", "Din\u00b7ge", "kennt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VAFIN", "$,", "PRELS", "ADV", "ADJD", "ART", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Da\u00df er ein solches Volk ", "tokens": ["Da\u00df", "er", "ein", "sol\u00b7ches", "Volk"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "PIAT", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "Wo ist die Wissenschaft, da nicht der Thoren Menge", "tokens": ["Wo", "ist", "die", "Wis\u00b7sen\u00b7schaft", ",", "da", "nicht", "der", "Tho\u00b7ren", "Men\u00b7ge"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PWAV", "VAFIN", "ART", "NN", "$,", "KOUS", "PTKNEG", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Sich zu der kleinen Zahl von wahren Weisen dr\u00e4nge?", "tokens": ["Sich", "zu", "der", "klei\u00b7nen", "Zahl", "von", "wah\u00b7ren", "Wei\u00b7sen", "dr\u00e4n\u00b7ge", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "ART", "ADJA", "NN", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.14": {"line.1": {"text": "Wie aber, flieht nicht Der, der sichre Kenntni\u00df liebt,", "tokens": ["Wie", "a\u00b7ber", ",", "flieht", "nicht", "Der", ",", "der", "sich\u00b7re", "Kennt\u00b7ni\u00df", "liebt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "$,", "VVFIN", "PTKNEG", "ART", "$,", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die Kunst, wo steter Zank die gr\u00f6\u00dften Meister \u00fcbt,", "tokens": ["Die", "Kunst", ",", "wo", "ste\u00b7ter", "Zank", "die", "gr\u00f6\u00df\u00b7ten", "Meis\u00b7ter", "\u00fcbt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PWAV", "ADJA", "NN", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und wider einen Spruch, der auf das Recht sich st\u00fctzet,", "tokens": ["Und", "wi\u00b7der", "ei\u00b7nen", "Spruch", ",", "der", "auf", "das", "Recht", "sich", "st\u00fct\u00b7zet", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "$,", "PRELS", "APPR", "ART", "NN", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ein andrer Spruch erscheint, den auch das Recht besch\u00fctzet?", "tokens": ["Ein", "an\u00b7drer", "Spruch", "er\u00b7scheint", ",", "den", "auch", "das", "Recht", "be\u00b7sch\u00fct\u00b7zet", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,", "PRELS", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Bisweilen wankt das Recht, ich r\u00e4um' es willig ein:", "tokens": ["Bis\u00b7wei\u00b7len", "wankt", "das", "Recht", ",", "ich", "r\u00e4um'", "es", "wil\u00b7lig", "ein", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$,", "PPER", "VVFIN", "PPER", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Doch \u00f6fter wird die Schuld nur an dem Lehrer seyn.", "tokens": ["Doch", "\u00f6f\u00b7ter", "wird", "die", "Schuld", "nur", "an", "dem", "Leh\u00b7rer", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "ART", "NN", "ADV", "APPR", "ART", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Ein Geist von Wahrheit voll, gew\u00f6hnt zu scharfen Schl\u00fcssen,", "tokens": ["Ein", "Geist", "von", "Wahr\u00b7heit", "voll", ",", "ge\u00b7w\u00f6hnt", "zu", "schar\u00b7fen", "Schl\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "ADJD", "$,", "VVPP", "PTKZU", "VVINF", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Entdecket da Beweis, wo Andre glauben m\u00fcssen,", "tokens": ["Ent\u00b7de\u00b7cket", "da", "Be\u00b7weis", ",", "wo", "And\u00b7re", "glau\u00b7ben", "m\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "NN", "$,", "PWAV", "PIS", "VVINF", "VMINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Und wo ihm das Gesetz vielleicht zu dunkel spricht,", "tokens": ["Und", "wo", "ihm", "das", "Ge\u00b7setz", "viel\u00b7leicht", "zu", "dun\u00b7kel", "spricht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPER", "ART", "NN", "ADV", "PTKA", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Versagt die Billigkeit ihm ihren Ausspruch nicht.", "tokens": ["Ver\u00b7sagt", "die", "Bil\u00b7lig\u00b7keit", "ihm", "ih\u00b7ren", "Aus\u00b7spruch", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "PPER", "PPOSAT", "NN", "PTKNEG", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Durch ein verdreht Gesetz, durch ein verwirrt Erz\u00e4hlen", "tokens": ["Durch", "ein", "ver\u00b7dreht", "Ge\u00b7setz", ",", "durch", "ein", "ver\u00b7wirrt", "Er\u00b7z\u00e4h\u00b7len"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "ART", "VVFIN", "NN", "$,", "APPR", "ART", "ADJD", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Gl\u00fcckt es dem Z\u00e4nker nicht, ihm Beyfall abzustehlen.", "tokens": ["Gl\u00fcckt", "es", "dem", "Z\u00e4n\u00b7ker", "nicht", ",", "ihm", "Bey\u00b7fall", "ab\u00b7zu\u00b7steh\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "PTKNEG", "$,", "PPER", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Durch ihn wird selbst das Recht, das so verworren scheint,", "tokens": ["Durch", "ihn", "wird", "selbst", "das", "Recht", ",", "das", "so", "ver\u00b7wor\u00b7ren", "scheint", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VAFIN", "ADV", "ART", "NN", "$,", "PRELS", "ADV", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Ein ordentlicher Bau, wo Alles sich vereint.", "tokens": ["Ein", "or\u00b7dent\u00b7li\u00b7cher", "Bau", ",", "wo", "Al\u00b7les", "sich", "ver\u00b7eint", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PWAV", "PIS", "PRF", "VVPP", "$."], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.15": {"text": "Er sieht, wie ein Gesetz sich stets im andern gr\u00fcndet,", "tokens": ["Er", "sieht", ",", "wie", "ein", "Ge\u00b7setz", "sich", "stets", "im", "an\u00b7dern", "gr\u00fcn\u00b7det", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PWAV", "ART", "NN", "PRF", "ADV", "APPRART", "ADJA", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Den Menschen die Natur, der Staat den B\u00fcrger bindet;", "tokens": ["Den", "Men\u00b7schen", "die", "Na\u00b7tur", ",", "der", "Staat", "den", "B\u00fcr\u00b7ger", "bin\u00b7det", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$,", "ART", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Er kennet, er verehrt die Weisen jener Zeit,", "tokens": ["Er", "ken\u00b7net", ",", "er", "ver\u00b7ehrt", "die", "Wei\u00b7sen", "je\u00b7ner", "Zeit", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VVFIN", "ART", "NN", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Wie sie, an Einsicht stark, und voll Gerechtigkeit.", "tokens": ["Wie", "sie", ",", "an", "Ein\u00b7sicht", "stark", ",", "und", "voll", "Ge\u00b7rech\u00b7tig\u00b7keit", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "$,", "APPR", "NN", "ADJD", "$,", "KON", "ADJD", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Vergleicht man sie mit ihm, nach weit entfernten Jahren,", "tokens": ["Ver\u00b7gleicht", "man", "sie", "mit", "ihm", ",", "nach", "weit", "ent\u00b7fern\u00b7ten", "Jah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PPER", "APPR", "PPER", "$,", "APPR", "ADJD", "ADJA", "NN", "$,"], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.20": {"text": "Wird das ihr Vorzug seyn, da\u00df sie sein Muster waren.", "tokens": ["Wird", "das", "ihr", "Vor\u00b7zug", "seyn", ",", "da\u00df", "sie", "sein", "Mus\u00b7ter", "wa\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "PPOSAT", "NN", "VAINF", "$,", "KOUS", "PPER", "PPOSAT", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Er wirkt der Menschen Gl\u00fcck durch Tugend und Verstand;", "tokens": ["Er", "wirkt", "der", "Men\u00b7schen", "Gl\u00fcck", "durch", "Tu\u00b7gend", "und", "Ver\u00b7stand", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "NN", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Nun urtheilt, wird er wohl verehrungswerth erkannt?", "tokens": ["Nun", "ur\u00b7theilt", ",", "wird", "er", "wohl", "ver\u00b7eh\u00b7rungs\u00b7werth", "er\u00b7kannt", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "VAFIN", "PPER", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}