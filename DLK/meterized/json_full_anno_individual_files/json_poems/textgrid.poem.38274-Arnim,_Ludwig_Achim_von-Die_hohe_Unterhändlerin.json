{"textgrid.poem.38274": {"metadata": {"author": {"name": "Arnim, Ludwig Achim von", "birth": "N.A.", "death": "N.A."}, "title": "Die hohe Unterh\u00e4ndlerin", "genre": "verse", "period": "N.A.", "pub_year": 1806, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "\u00bbschwing' dich auf, Frau Nachtigall, geschwinde,", "tokens": ["\u00bb", "schwing'", "dich", "auf", ",", "Frau", "Nach\u00b7ti\u00b7gall", ",", "ge\u00b7schwin\u00b7de", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["$(", "VVFIN", "PPER", "PTKVZ", "$,", "NN", "NN", "$,", "ADJA", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Vor meines Liebsten Fensterlein dich finde;", "tokens": ["Vor", "mei\u00b7nes", "Liebs\u00b7ten", "Fens\u00b7ter\u00b7lein", "dich", "fin\u00b7de", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Sing' ihm das Lied, welches, ohn Beschweren,", "tokens": ["Sing'", "ihm", "das", "Lied", ",", "wel\u00b7ches", ",", "ohn", "Be\u00b7schwe\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NE", "PPER", "ART", "NN", "$,", "PRELS", "$,", "KOUI", "NN", "$,"], "meter": "+--++-+-+-", "measure": "dactylic.init"}, "line.4": {"text": "Mir erdacht, mein'm Schatz zu Ruhm und Ehren.\u00ab", "tokens": ["Mir", "er\u00b7dacht", ",", "mein'm", "Schatz", "zu", "Ruhm", "und", "Eh\u00b7ren", ".", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVPP", "$,", "PPOSAT", "NN", "APPR", "NN", "KON", "NN", "$.", "$("], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.2": {"line.1": {"text": "\u00bbich komm' her von eurer Sch\u00f6nen, Zarten,", "tokens": ["\u00bb", "ich", "komm'", "her", "von", "eu\u00b7rer", "Sch\u00f6\u00b7nen", ",", "Zar\u00b7ten", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "ADV", "APPR", "PPOSAT", "NN", "$,", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Welche mich aus ihrem Rosengarten,", "tokens": ["Wel\u00b7che", "mich", "aus", "ih\u00b7rem", "Ro\u00b7sen\u00b7gar\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Sendet zu euch sammt einem Kranz geringe,", "tokens": ["Sen\u00b7det", "zu", "euch", "sammt", "ei\u00b7nem", "Kranz", "ge\u00b7rin\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PPER", "APPR", "ART", "NN", "ADJA", "$,"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.4": {"text": "Den ich euch von ihrentwegen bringe.\u00ab", "tokens": ["Den", "ich", "euch", "von", "ih\u00b7rent\u00b7we\u00b7gen", "brin\u00b7ge", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "PPER", "PRF", "APPR", "PPOSAT", "VVFIN", "$.", "$("], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.3": {"line.1": {"text": "\u00bbgl\u00fcck und Heil sie w\u00fcnscht von Herzensgrunde", "tokens": ["\u00bb", "gl\u00fcck", "und", "Heil", "sie", "w\u00fcnscht", "von", "Her\u00b7zens\u00b7grun\u00b7de"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "ADJD", "KON", "NN", "PPER", "VVFIN", "APPR", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Ihrem Schatz zu jeder Zeit und Stunde,", "tokens": ["Ih\u00b7rem", "Schatz", "zu", "je\u00b7der", "Zeit", "und", "Stun\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "PIAT", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Ihr zartes Herze ist gar sehr besessen", "tokens": ["Ihr", "zar\u00b7tes", "Her\u00b7ze", "ist", "gar", "sehr", "be\u00b7ses\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN", "VAFIN", "ADV", "ADV", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Sie kann ihres Liebsten nicht vergessen.\u00ab", "tokens": ["Sie", "kann", "ih\u00b7res", "Liebs\u00b7ten", "nicht", "ver\u00b7ges\u00b7sen", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VMFIN", "PPOSAT", "NN", "PTKNEG", "VVPP", "$.", "$("], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.4": {"line.1": {"text": "\u00bbje l\u00e4nger, je lieber hei\u00dft ein Bl\u00fcmelein,", "tokens": ["\u00bb", "je", "l\u00e4n\u00b7ger", ",", "je", "lie\u00b7ber", "hei\u00dft", "ein", "Bl\u00fc\u00b7me\u00b7lein", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "ADJD", "$,", "ADV", "ADV", "VVFIN", "ART", "NN", "$,"], "meter": "+---+-+-+-+", "measure": "dactylic.init"}, "line.2": {"text": "Daraus hat sie gemacht das Ehrenkr\u00e4nzelein,", "tokens": ["Da\u00b7raus", "hat", "sie", "ge\u00b7macht", "das", "Eh\u00b7ren\u00b7kr\u00e4n\u00b7zel\u00b7ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "PPER", "VVPP", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Augentrost ist darunter gemenget,", "tokens": ["Au\u00b7gen\u00b7trost", "ist", "da\u00b7run\u00b7ter", "ge\u00b7men\u00b7get", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PAV", "VVPP", "$,"], "meter": "+-+--+--+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Vergi\u00df mein nicht mit eingesprenget.\u00ab", "tokens": ["Ver\u00b7gi\u00df", "mein", "nicht", "mit", "ein\u00b7ge\u00b7spren\u00b7get", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVIMP", "PPOSAT", "PTKNEG", "APPR", "VVFIN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "\u00bbauch ist so viel Ehrenprei\u00df darinnen,", "tokens": ["\u00bb", "auch", "ist", "so", "viel", "Eh\u00b7ren\u00b7prei\u00df", "da\u00b7rin\u00b7nen", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VAFIN", "ADV", "PIAT", "NN", "ADV", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "So werdet ihr des Wohlgemuthes innen;", "tokens": ["So", "wer\u00b7det", "ihr", "des", "Wohl\u00b7ge\u00b7mu\u00b7thes", "in\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ART", "NN", "ADV", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Der Kranzb\u00fcgel ist mit Ehren gewunden,", "tokens": ["Der", "Kranz\u00b7b\u00fc\u00b7gel", "ist", "mit", "Eh\u00b7ren", "ge\u00b7wun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "APPR", "NN", "VAPP", "$,"], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Ein treues Herzelein hat ihn gebunden.\u00ab", "tokens": ["Ein", "treu\u00b7es", "Her\u00b7ze\u00b7lein", "hat", "ihn", "ge\u00b7bun\u00b7den", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "PPER", "VVPP", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "\u00bbmerkt noch mehr, was sie mir hat befohlen,", "tokens": ["\u00bb", "merkt", "noch", "mehr", ",", "was", "sie", "mir", "hat", "be\u00b7foh\u00b7len", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "ADV", "ADV", "$,", "PRELS", "PPER", "PPER", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Das sag' ich euch ganz frey und unverholen:", "tokens": ["Das", "sag'", "ich", "euch", "ganz", "frey", "und", "un\u00b7ver\u00b7ho\u00b7len", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "PPER", "ADV", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Ohn' Antwort soll ich nicht wieder kommen,", "tokens": ["Ohn'", "Ant\u00b7wort", "soll", "ich", "nicht", "wie\u00b7der", "kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VMFIN", "PPER", "PTKNEG", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "Darum merkt wohl, was ihr von mir vernommen.\u00ab \u2013", "tokens": ["Da\u00b7rum", "merkt", "wohl", ",", "was", "ihr", "von", "mir", "ver\u00b7nom\u00b7men", ".", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PAV", "VVFIN", "ADV", "$,", "PWS", "PPER", "APPR", "PPER", "VVPP", "$.", "$(", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.7": {"line.1": {"text": "\u00bbflei\u00dfig hab' ich dein' Botschaft verstanden,", "tokens": ["\u00bb", "flei\u00b7\u00dfig", "hab'", "ich", "dein'", "Bot\u00b7schaft", "ver\u00b7stan\u00b7den", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "VAFIN", "PPER", "PPOSAT", "NN", "VVPP", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Antwort soll auch seyn bei mir vorhanden;", "tokens": ["Ant\u00b7wort", "soll", "auch", "seyn", "bei", "mir", "vor\u00b7han\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "ADV", "VAINF", "APPR", "PPER", "ADJD", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Schwing' dich auf mit deinem zarten Gefieder", "tokens": ["Schwing'", "dich", "auf", "mit", "dei\u00b7nem", "zar\u00b7ten", "Ge\u00b7fie\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVIMP", "PPER", "APPR", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+--+-", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Und gr\u00fc\u00dfe mir mein tausend Herzelein wieder.\u00ab", "tokens": ["Und", "gr\u00fc\u00b7\u00dfe", "mir", "mein", "tau\u00b7send", "Her\u00b7ze\u00b7lein", "wie\u00b7der", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "PPER", "PPOSAT", "CARD", "NN", "ADV", "$.", "$("], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}}, "stanza.8": {"line.1": {"text": "\u00bbnichts liebers h\u00e4tte sie mir k\u00f6nnen schicken,", "tokens": ["\u00bb", "nichts", "lie\u00b7bers", "h\u00e4t\u00b7te", "sie", "mir", "k\u00f6n\u00b7nen", "schi\u00b7cken", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PIS", "ADV", "VAFIN", "PPER", "PPER", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Dadurch sie th\u00e4t mein junges Herz erquicken;", "tokens": ["Da\u00b7durch", "sie", "th\u00e4t", "mein", "jun\u00b7ges", "Herz", "er\u00b7qui\u00b7cken", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PPER", "VVFIN", "PPOSAT", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Als das Kr\u00e4nzelein mit den sch\u00f6nen Blumen,", "tokens": ["Als", "das", "Kr\u00e4n\u00b7zel\u00b7ein", "mit", "den", "sch\u00f6\u00b7nen", "Blu\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.4": {"text": "Die man sonsten selten thut bekommen.\u00ab", "tokens": ["Die", "man", "sons\u00b7ten", "sel\u00b7ten", "thut", "be\u00b7kom\u00b7men", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "PIS", "ADV", "ADJD", "VVFIN", "VVINF", "$.", "$("], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.9": {"line.1": {"text": "\u00bbein Demant, ein Stein gar hart und theuer,", "tokens": ["\u00bb", "ein", "De\u00b7mant", ",", "ein", "Stein", "gar", "hart", "und", "theu\u00b7er", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "$,", "ART", "NN", "ADV", "ADJD", "KON", "ADJD", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Welchen doch verzehren kann das Feuer;", "tokens": ["Wel\u00b7chen", "doch", "ver\u00b7zeh\u00b7ren", "kann", "das", "Feu\u00b7er", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "VVINF", "VMFIN", "ART", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Ist kaum meinem Herzen zu vergleichen,", "tokens": ["Ist", "kaum", "mei\u00b7nem", "Her\u00b7zen", "zu", "ver\u00b7glei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PPOSAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "Drum th\u00e4t es das Kr\u00e4nzelein erweichen.\u00ab", "tokens": ["Drum", "th\u00e4t", "es", "das", "Kr\u00e4n\u00b7zel\u00b7ein", "er\u00b7wei\u00b7chen", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PAV", "VVFIN", "PPER", "ART", "NN", "VVINF", "$.", "$("], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.10": {"line.1": {"text": "\u00bbvon mir sag dem allersch\u00f6nsten Herzen,", "tokens": ["\u00bb", "von", "mir", "sag", "dem", "al\u00b7ler\u00b7sch\u00f6ns\u00b7ten", "Her\u00b7zen", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "PPER", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Eitel Freud' und Wonn' ohn' alle Schmerzen;", "tokens": ["Ei\u00b7tel", "Freud'", "und", "Wonn'", "ohn'", "al\u00b7le", "Schmer\u00b7zen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "KON", "NN", "APPR", "PIAT", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Thu ihr f\u00fcr das Geschenk gro\u00dfen Dank sagen:", "tokens": ["Thu", "ihr", "f\u00fcr", "das", "Ge\u00b7schenk", "gro\u00b7\u00dfen", "Dank", "sa\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ART", "NN", "ADJA", "NN", "VVINF", "$."], "meter": "+-+-+-+--+-", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Fr\u00f6hlich bin ich, weil sie mir ist gewogen.\u00ab", "tokens": ["Fr\u00f6h\u00b7lich", "bin", "ich", ",", "weil", "sie", "mir", "ist", "ge\u00b7wo\u00b7gen", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADJD", "VAFIN", "PPER", "$,", "KOUS", "PPER", "PPER", "VAFIN", "VVPP", "$.", "$("], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}}, "stanza.11": {"line.1": {"text": "\u00bbsprich, ich will ihr'r wieder nicht vergessen,", "tokens": ["\u00bb", "sprich", ",", "ich", "will", "ih\u00b7r'r", "wie\u00b7der", "nicht", "ver\u00b7ges\u00b7sen", ","], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "$,", "PPER", "VMFIN", "PPER", "ADV", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ob ich mich gleich nicht kann hoch ermessen!", "tokens": ["Ob", "ich", "mich", "gleich", "nicht", "kann", "hoch", "er\u00b7mes\u00b7sen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ADV", "PTKNEG", "VMFIN", "ADJD", "VVINF", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Schwing dich auf, sag' ihrem rothen Mund:", "tokens": ["Schwing", "dich", "auf", ",", "sag'", "ih\u00b7rem", "ro\u00b7then", "Mund", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKVZ", "$,", "VVFIN", "PPOSAT", "ADJA", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Gute Nacht, Gl\u00fcck, Heil zu aller Stund.\u00ab", "tokens": ["Gu\u00b7te", "Nacht", ",", "Gl\u00fcck", ",", "Heil", "zu", "al\u00b7ler", "Stund", ".", "\u00ab"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADJA", "NN", "$,", "NN", "$,", "NN", "APPR", "PIAT", "NN", "$.", "$("], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.12": {"line.1": {"text": "\u00bbschwing' dich auf, Frau Nachtigall, geschwinde,", "tokens": ["\u00bb", "schwing'", "dich", "auf", ",", "Frau", "Nach\u00b7ti\u00b7gall", ",", "ge\u00b7schwin\u00b7de", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["$(", "VVFIN", "PPER", "PTKVZ", "$,", "NN", "NN", "$,", "ADJA", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Vor meines Liebsten Fensterlein dich finde;", "tokens": ["Vor", "mei\u00b7nes", "Liebs\u00b7ten", "Fens\u00b7ter\u00b7lein", "dich", "fin\u00b7de", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Sing' ihm das Lied, welches, ohn Beschweren,", "tokens": ["Sing'", "ihm", "das", "Lied", ",", "wel\u00b7ches", ",", "ohn", "Be\u00b7schwe\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NE", "PPER", "ART", "NN", "$,", "PRELS", "$,", "KOUI", "NN", "$,"], "meter": "+--++-+-+-", "measure": "dactylic.init"}, "line.4": {"text": "Mir erdacht, mein'm Schatz zu Ruhm und Ehren.\u00ab", "tokens": ["Mir", "er\u00b7dacht", ",", "mein'm", "Schatz", "zu", "Ruhm", "und", "Eh\u00b7ren", ".", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVPP", "$,", "PPOSAT", "NN", "APPR", "NN", "KON", "NN", "$.", "$("], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.13": {"line.1": {"text": "\u00bbich komm' her von eurer Sch\u00f6nen, Zarten,", "tokens": ["\u00bb", "ich", "komm'", "her", "von", "eu\u00b7rer", "Sch\u00f6\u00b7nen", ",", "Zar\u00b7ten", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "ADV", "APPR", "PPOSAT", "NN", "$,", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Welche mich aus ihrem Rosengarten,", "tokens": ["Wel\u00b7che", "mich", "aus", "ih\u00b7rem", "Ro\u00b7sen\u00b7gar\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Sendet zu euch sammt einem Kranz geringe,", "tokens": ["Sen\u00b7det", "zu", "euch", "sammt", "ei\u00b7nem", "Kranz", "ge\u00b7rin\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PPER", "APPR", "ART", "NN", "ADJA", "$,"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.4": {"text": "Den ich euch von ihrentwegen bringe.\u00ab", "tokens": ["Den", "ich", "euch", "von", "ih\u00b7rent\u00b7we\u00b7gen", "brin\u00b7ge", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "PPER", "PRF", "APPR", "PPOSAT", "VVFIN", "$.", "$("], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.14": {"line.1": {"text": "\u00bbgl\u00fcck und Heil sie w\u00fcnscht von Herzensgrunde", "tokens": ["\u00bb", "gl\u00fcck", "und", "Heil", "sie", "w\u00fcnscht", "von", "Her\u00b7zens\u00b7grun\u00b7de"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "ADJD", "KON", "NN", "PPER", "VVFIN", "APPR", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Ihrem Schatz zu jeder Zeit und Stunde,", "tokens": ["Ih\u00b7rem", "Schatz", "zu", "je\u00b7der", "Zeit", "und", "Stun\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "PIAT", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Ihr zartes Herze ist gar sehr besessen", "tokens": ["Ihr", "zar\u00b7tes", "Her\u00b7ze", "ist", "gar", "sehr", "be\u00b7ses\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN", "VAFIN", "ADV", "ADV", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Sie kann ihres Liebsten nicht vergessen.\u00ab", "tokens": ["Sie", "kann", "ih\u00b7res", "Liebs\u00b7ten", "nicht", "ver\u00b7ges\u00b7sen", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VMFIN", "PPOSAT", "NN", "PTKNEG", "VVPP", "$.", "$("], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.15": {"line.1": {"text": "\u00bbje l\u00e4nger, je lieber hei\u00dft ein Bl\u00fcmelein,", "tokens": ["\u00bb", "je", "l\u00e4n\u00b7ger", ",", "je", "lie\u00b7ber", "hei\u00dft", "ein", "Bl\u00fc\u00b7me\u00b7lein", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "ADJD", "$,", "ADV", "ADV", "VVFIN", "ART", "NN", "$,"], "meter": "+---+-+-+-+", "measure": "dactylic.init"}, "line.2": {"text": "Daraus hat sie gemacht das Ehrenkr\u00e4nzelein,", "tokens": ["Da\u00b7raus", "hat", "sie", "ge\u00b7macht", "das", "Eh\u00b7ren\u00b7kr\u00e4n\u00b7zel\u00b7ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "PPER", "VVPP", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Augentrost ist darunter gemenget,", "tokens": ["Au\u00b7gen\u00b7trost", "ist", "da\u00b7run\u00b7ter", "ge\u00b7men\u00b7get", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PAV", "VVPP", "$,"], "meter": "+-+--+--+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Vergi\u00df mein nicht mit eingesprenget.\u00ab", "tokens": ["Ver\u00b7gi\u00df", "mein", "nicht", "mit", "ein\u00b7ge\u00b7spren\u00b7get", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVIMP", "PPOSAT", "PTKNEG", "APPR", "VVFIN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "\u00bbauch ist so viel Ehrenprei\u00df darinnen,", "tokens": ["\u00bb", "auch", "ist", "so", "viel", "Eh\u00b7ren\u00b7prei\u00df", "da\u00b7rin\u00b7nen", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VAFIN", "ADV", "PIAT", "NN", "ADV", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "So werdet ihr des Wohlgemuthes innen;", "tokens": ["So", "wer\u00b7det", "ihr", "des", "Wohl\u00b7ge\u00b7mu\u00b7thes", "in\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ART", "NN", "ADV", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Der Kranzb\u00fcgel ist mit Ehren gewunden,", "tokens": ["Der", "Kranz\u00b7b\u00fc\u00b7gel", "ist", "mit", "Eh\u00b7ren", "ge\u00b7wun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "APPR", "NN", "VAPP", "$,"], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Ein treues Herzelein hat ihn gebunden.\u00ab", "tokens": ["Ein", "treu\u00b7es", "Her\u00b7ze\u00b7lein", "hat", "ihn", "ge\u00b7bun\u00b7den", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "PPER", "VVPP", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.17": {"line.1": {"text": "\u00bbmerkt noch mehr, was sie mir hat befohlen,", "tokens": ["\u00bb", "merkt", "noch", "mehr", ",", "was", "sie", "mir", "hat", "be\u00b7foh\u00b7len", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "ADV", "ADV", "$,", "PRELS", "PPER", "PPER", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Das sag' ich euch ganz frey und unverholen:", "tokens": ["Das", "sag'", "ich", "euch", "ganz", "frey", "und", "un\u00b7ver\u00b7ho\u00b7len", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "PPER", "ADV", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Ohn' Antwort soll ich nicht wieder kommen,", "tokens": ["Ohn'", "Ant\u00b7wort", "soll", "ich", "nicht", "wie\u00b7der", "kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VMFIN", "PPER", "PTKNEG", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "Darum merkt wohl, was ihr von mir vernommen.\u00ab \u2013", "tokens": ["Da\u00b7rum", "merkt", "wohl", ",", "was", "ihr", "von", "mir", "ver\u00b7nom\u00b7men", ".", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PAV", "VVFIN", "ADV", "$,", "PWS", "PPER", "APPR", "PPER", "VVPP", "$.", "$(", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.18": {"line.1": {"text": "\u00bbflei\u00dfig hab' ich dein' Botschaft verstanden,", "tokens": ["\u00bb", "flei\u00b7\u00dfig", "hab'", "ich", "dein'", "Bot\u00b7schaft", "ver\u00b7stan\u00b7den", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "VAFIN", "PPER", "PPOSAT", "NN", "VVPP", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Antwort soll auch seyn bei mir vorhanden;", "tokens": ["Ant\u00b7wort", "soll", "auch", "seyn", "bei", "mir", "vor\u00b7han\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "ADV", "VAINF", "APPR", "PPER", "ADJD", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Schwing' dich auf mit deinem zarten Gefieder", "tokens": ["Schwing'", "dich", "auf", "mit", "dei\u00b7nem", "zar\u00b7ten", "Ge\u00b7fie\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVIMP", "PPER", "APPR", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+--+-", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Und gr\u00fc\u00dfe mir mein tausend Herzelein wieder.\u00ab", "tokens": ["Und", "gr\u00fc\u00b7\u00dfe", "mir", "mein", "tau\u00b7send", "Her\u00b7ze\u00b7lein", "wie\u00b7der", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "PPER", "PPOSAT", "CARD", "NN", "ADV", "$.", "$("], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}}, "stanza.19": {"line.1": {"text": "\u00bbnichts liebers h\u00e4tte sie mir k\u00f6nnen schicken,", "tokens": ["\u00bb", "nichts", "lie\u00b7bers", "h\u00e4t\u00b7te", "sie", "mir", "k\u00f6n\u00b7nen", "schi\u00b7cken", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PIS", "ADV", "VAFIN", "PPER", "PPER", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Dadurch sie th\u00e4t mein junges Herz erquicken;", "tokens": ["Da\u00b7durch", "sie", "th\u00e4t", "mein", "jun\u00b7ges", "Herz", "er\u00b7qui\u00b7cken", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PPER", "VVFIN", "PPOSAT", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Als das Kr\u00e4nzelein mit den sch\u00f6nen Blumen,", "tokens": ["Als", "das", "Kr\u00e4n\u00b7zel\u00b7ein", "mit", "den", "sch\u00f6\u00b7nen", "Blu\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.4": {"text": "Die man sonsten selten thut bekommen.\u00ab", "tokens": ["Die", "man", "sons\u00b7ten", "sel\u00b7ten", "thut", "be\u00b7kom\u00b7men", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "PIS", "ADV", "ADJD", "VVFIN", "VVINF", "$.", "$("], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.20": {"line.1": {"text": "\u00bbein Demant, ein Stein gar hart und theuer,", "tokens": ["\u00bb", "ein", "De\u00b7mant", ",", "ein", "Stein", "gar", "hart", "und", "theu\u00b7er", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "$,", "ART", "NN", "ADV", "ADJD", "KON", "ADJD", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Welchen doch verzehren kann das Feuer;", "tokens": ["Wel\u00b7chen", "doch", "ver\u00b7zeh\u00b7ren", "kann", "das", "Feu\u00b7er", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "VVINF", "VMFIN", "ART", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Ist kaum meinem Herzen zu vergleichen,", "tokens": ["Ist", "kaum", "mei\u00b7nem", "Her\u00b7zen", "zu", "ver\u00b7glei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PPOSAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "Drum th\u00e4t es das Kr\u00e4nzelein erweichen.\u00ab", "tokens": ["Drum", "th\u00e4t", "es", "das", "Kr\u00e4n\u00b7zel\u00b7ein", "er\u00b7wei\u00b7chen", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PAV", "VVFIN", "PPER", "ART", "NN", "VVINF", "$.", "$("], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.21": {"line.1": {"text": "\u00bbvon mir sag dem allersch\u00f6nsten Herzen,", "tokens": ["\u00bb", "von", "mir", "sag", "dem", "al\u00b7ler\u00b7sch\u00f6ns\u00b7ten", "Her\u00b7zen", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "PPER", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Eitel Freud' und Wonn' ohn' alle Schmerzen;", "tokens": ["Ei\u00b7tel", "Freud'", "und", "Wonn'", "ohn'", "al\u00b7le", "Schmer\u00b7zen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "KON", "NN", "APPR", "PIAT", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Thu ihr f\u00fcr das Geschenk gro\u00dfen Dank sagen:", "tokens": ["Thu", "ihr", "f\u00fcr", "das", "Ge\u00b7schenk", "gro\u00b7\u00dfen", "Dank", "sa\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ART", "NN", "ADJA", "NN", "VVINF", "$."], "meter": "+-+-+-+--+-", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Fr\u00f6hlich bin ich, weil sie mir ist gewogen.\u00ab", "tokens": ["Fr\u00f6h\u00b7lich", "bin", "ich", ",", "weil", "sie", "mir", "ist", "ge\u00b7wo\u00b7gen", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADJD", "VAFIN", "PPER", "$,", "KOUS", "PPER", "PPER", "VAFIN", "VVPP", "$.", "$("], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}}, "stanza.22": {"line.1": {"text": "\u00bbsprich, ich will ihr'r wieder nicht vergessen,", "tokens": ["\u00bb", "sprich", ",", "ich", "will", "ih\u00b7r'r", "wie\u00b7der", "nicht", "ver\u00b7ges\u00b7sen", ","], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "$,", "PPER", "VMFIN", "PPER", "ADV", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ob ich mich gleich nicht kann hoch ermessen!", "tokens": ["Ob", "ich", "mich", "gleich", "nicht", "kann", "hoch", "er\u00b7mes\u00b7sen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ADV", "PTKNEG", "VMFIN", "ADJD", "VVINF", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Schwing dich auf, sag' ihrem rothen Mund:", "tokens": ["Schwing", "dich", "auf", ",", "sag'", "ih\u00b7rem", "ro\u00b7then", "Mund", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKVZ", "$,", "VVFIN", "PPOSAT", "ADJA", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Gute Nacht, Gl\u00fcck, Heil zu aller Stund.\u00ab", "tokens": ["Gu\u00b7te", "Nacht", ",", "Gl\u00fcck", ",", "Heil", "zu", "al\u00b7ler", "Stund", ".", "\u00ab"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADJA", "NN", "$,", "NN", "$,", "NN", "APPR", "PIAT", "NN", "$.", "$("], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}}}}