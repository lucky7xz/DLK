{"dta.poem.21409": {"metadata": {"author": {"name": "Heine, Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "Caput XXIII.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1844", "urn": "urn:nbn:de:kobv:b4-30602-6", "language": ["de:0.71", "no:0.28"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "\u201everwelkt, entbl\u00e4ttert, zertreten sogar", "tokens": ["\u201e", "ver\u00b7welkt", ",", "ent\u00b7bl\u00e4t\u00b7tert", ",", "zer\u00b7tre\u00b7ten", "so\u00b7gar"], "token_info": ["punct", "word", "punct", "word", "punct", "word", "word"], "pos": ["$(", "VVPP", "$,", "VVPP", "$,", "VVFIN", "ADV"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Von rohen Schicksalsf\u00fc\u00dfen \u2013", "tokens": ["Von", "ro\u00b7hen", "Schick\u00b7sals\u00b7f\u00fc\u00b7\u00dfen", "\u2013"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Mein Freund, das ist auf Erden das Loos", "tokens": ["Mein", "Freund", ",", "das", "ist", "auf", "Er\u00b7den", "das", "Loos"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "$,", "PDS", "VAFIN", "APPR", "NN", "ART", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Von allem Sch\u00f6nen und S\u00fc\u00dfen!\u201c", "tokens": ["Von", "al\u00b7lem", "Sch\u00f6\u00b7nen", "und", "S\u00fc\u00b7\u00dfen", "!", "\u201c"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "PIS", "NN", "KON", "NN", "$.", "$("], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.2": {"line.1": {"text": "Wer bist du? \u2013 rief ich \u2013 du schaust mich an", "tokens": ["Wer", "bist", "du", "?", "\u2013", "rief", "ich", "\u2013", "du", "schaust", "mich", "an"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWS", "VAFIN", "PPER", "$.", "$(", "VVFIN", "PPER", "$(", "PPER", "VVFIN", "PPER", "PTKVZ"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Wie\u2019n Traum aus alten Zeiten \u2013", "tokens": ["Wie'n", "Traum", "aus", "al\u00b7ten", "Zei\u00b7ten", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Wo wohnst du, gro\u00dfes Frauenbild?", "tokens": ["Wo", "wohnst", "du", ",", "gro\u00b7\u00dfes", "Frau\u00b7en\u00b7bild", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und darf ich dich begleiten?", "tokens": ["Und", "darf", "ich", "dich", "be\u00b7glei\u00b7ten", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "PRF", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Da l\u00e4chelte das Weib und sprach:", "tokens": ["Da", "l\u00e4\u00b7chel\u00b7te", "das", "Weib", "und", "sprach", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u201edu irrst dich, ich bin eine feine,", "tokens": ["\u201e", "du", "irrst", "dich", ",", "ich", "bin", "ei\u00b7ne", "fei\u00b7ne", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "PPER", "$,", "PPER", "VAFIN", "ART", "ADJA", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Anst\u00e4nd\u2019ge, moralische Person;", "tokens": ["An\u00b7st\u00e4n\u00b7d'\u00b7ge", ",", "mo\u00b7ra\u00b7li\u00b7sche", "Per\u00b7son", ";"], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "ADJA", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "Du irrst dich, ich bin nicht so Eine.", "tokens": ["Du", "irrst", "dich", ",", "ich", "bin", "nicht", "so", "Ei\u00b7ne", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$,", "PPER", "VAFIN", "PTKNEG", "ADV", "ART", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "\u201eich bin nicht so eine kleine Mamsell,", "tokens": ["\u201e", "ich", "bin", "nicht", "so", "ei\u00b7ne", "klei\u00b7ne", "Mam\u00b7sell", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "PTKNEG", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.2": {"text": "So eine welsche Lorettinn \u2013", "tokens": ["So", "ei\u00b7ne", "wel\u00b7sche", "Lo\u00b7ret\u00b7tinn", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}, "line.3": {"text": "Denn wisse: ich bin Hammonia,", "tokens": ["Denn", "wis\u00b7se", ":", "ich", "bin", "Ham\u00b7mo\u00b7nia", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "PPER", "VAFIN", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Hamburgs besch\u00fctzende G\u00f6ttinn!", "tokens": ["Ham\u00b7burgs", "be\u00b7sch\u00fct\u00b7zen\u00b7de", "G\u00f6t\u00b7tinn", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}}}}}