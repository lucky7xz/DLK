{"dta.poem.10358": {"metadata": {"author": {"name": "Heine, Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "XiX.  \n  Lebensgru\u00df .", "genre": "Lyrik", "period": "N.A.", "pub_year": "1827", "urn": "urn:nbn:de:kobv:b4-200905192211", "language": ["de:0.99"], "booktitle": "Heine, Heinrich: Buch der Lieder. Hamburg, 1827."}, "poem": {"stanza.1": {"line.1": {"text": "Eine gro\u00dfe Landstra\u00df' ist unsre Erd',", "tokens": ["Ei\u00b7ne", "gro\u00b7\u00dfe", "Land\u00b7stra\u00df'", "ist", "uns\u00b7re", "Erd'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.2": {"text": "Wir Menschen sind Passagiere;", "tokens": ["Wir", "Men\u00b7schen", "sind", "Pas\u00b7sa\u00b7gie\u00b7re", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "VAFIN", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Man rennet und jaget, zu Fu\u00df und zu Pferd,", "tokens": ["Man", "ren\u00b7net", "und", "ja\u00b7get", ",", "zu", "Fu\u00df", "und", "zu", "Pferd", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "KON", "VVFIN", "$,", "APPR", "NN", "KON", "APPR", "NN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "Wie L\u00e4ufer oder Couriere.", "tokens": ["Wie", "L\u00e4u\u00b7fer", "o\u00b7der", "Cou\u00b7ri\u00b7e\u00b7re", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Man f\u00e4hrt sich vor\u00fcber, man nicket, man gr\u00fc\u00dft", "tokens": ["Man", "f\u00e4hrt", "sich", "vor\u00b7\u00fc\u00b7ber", ",", "man", "ni\u00b7cket", ",", "man", "gr\u00fc\u00dft"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["PIS", "VVFIN", "PRF", "PTKVZ", "$,", "PIS", "VVFIN", "$,", "PIS", "VVFIN"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "Mit dem Taschentuch' aus der Carosse;", "tokens": ["Mit", "dem", "Ta\u00b7schen\u00b7tuch'", "aus", "der", "Ca\u00b7ros\u00b7se", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Man h\u00e4tte sich gerne geherzt und gek\u00fc\u00dft, \u2014", "tokens": ["Man", "h\u00e4t\u00b7te", "sich", "ger\u00b7ne", "ge\u00b7herzt", "und", "ge\u00b7k\u00fc\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PIS", "VAFIN", "PRF", "ADV", "VVPP", "KON", "VVPP", "$,", "$("], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "Doch jagen von hinnen die Rosse.", "tokens": ["Doch", "ja\u00b7gen", "von", "hin\u00b7nen", "die", "Ros\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ADV", "ART", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.3": {"line.1": {"text": "Kaum trafen wir uns auf derselben Station,", "tokens": ["Kaum", "tra\u00b7fen", "wir", "uns", "auf", "der\u00b7sel\u00b7ben", "Sta\u00b7ti\u00b7on", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Herzliebster Prinz Alexander,", "tokens": ["Herz\u00b7liebs\u00b7ter", "Prinz", "A\u00b7lex\u00b7an\u00b7der", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "NE", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Da bl\u00e4st schon zur Abfahrt der Postillon", "tokens": ["Da", "bl\u00e4st", "schon", "zur", "Ab\u00b7fahrt", "der", "Pos\u00b7til\u00b7lon"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ADV", "APPRART", "NN", "ART", "NN"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Und bl\u00e4st uns schon auseinander.", "tokens": ["Und", "bl\u00e4st", "uns", "schon", "aus\u00b7ein\u00b7an\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "PTKVZ", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}}}}