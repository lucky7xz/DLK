{"dta.poem.9244": {"metadata": {"author": {"name": "Weise, Christian", "birth": "N.A.", "death": "N.A."}, "title": "ViI.  \n Eine h\u00f6fliche Entschuldigung.", "genre": "Lyrik; Drama; Prosa", "period": "N.A.", "pub_year": "1701", "urn": "urn:nbn:de:kobv:b4-25043-0", "language": ["de:0.99"], "booktitle": "Weise, Christian: \u00dcberfl\u00fc\u00dfige Gedancken Der gr\u00fcnenden jugend. Leipzig, 1701."}, "poem": {"stanza.1": {"line.1": {"text": "Achnein/ ich m\u00f6chte nicht/ ich bin zur kirm\u00df gebete\u0303/", "tokens": ["A\u00b7chnein", "/", "ich", "m\u00f6ch\u00b7te", "nicht", "/", "ich", "bin", "zur", "kirm\u00df", "ge\u00b7bet\u1ebd", "/"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$(", "PPER", "VMFIN", "PTKNEG", "$(", "PPER", "VAFIN", "APPRART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und ich bed\u00fcrffte fast/", "tokens": ["Und", "ich", "be\u00b7d\u00fcrff\u00b7te", "fast", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ADV", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Noch selber einen gast/", "tokens": ["Noch", "sel\u00b7ber", "ei\u00b7nen", "gast", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Drum werd ich mir so weit wohl kein paar schuh ver-", "tokens": ["Drum", "werd", "ich", "mir", "so", "weit", "wohl", "kein", "paar", "schuh", "ver"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PAV", "VAFIN", "PPER", "PPER", "ADV", "ADJD", "ADV", "PIAT", "PIAT", "ADJA", "TRUNC"], "meter": "-+-+-+--+--", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Die leute sind gar schlim bericht/ ", "tokens": ["Die", "leu\u00b7te", "sind", "gar", "schlim", "be\u00b7richt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ach nein ich m\u00f6chte nicht!", "tokens": ["Ach", "nein", "ich", "m\u00f6ch\u00b7te", "nicht", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKANT", "PPER", "VMFIN", "PTKNEG", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "2. Ach nein ich m\u00f6chte nicht/ ich esse keinen braten", "tokens": ["Ach", "nein", "ich", "m\u00f6ch\u00b7te", "nicht", "/", "ich", "es\u00b7se", "kei\u00b7nen", "bra\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "PTKANT", "PPER", "VMFIN", "PTKNEG", "$(", "PPER", "VVFIN", "PIAT", "ADJA"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der nach der k\u00fcche schmeckt/", "tokens": ["Der", "nach", "der", "k\u00fc\u00b7che", "schmeckt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "ADJA", "VVFIN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Wer gerne teller leckt/", "tokens": ["Wer", "ger\u00b7ne", "tel\u00b7ler", "leckt", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "ADJD", "VVFIN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Der komm/ und lasse sich auf meinem herde rathen/", "tokens": ["Der", "komm", "/", "und", "las\u00b7se", "sich", "auf", "mei\u00b7nem", "her\u00b7de", "ra\u00b7then", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "$(", "KON", "VVFIN", "PRF", "APPR", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ich bin auf nichts so sehr verpicht.", "tokens": ["Ich", "bin", "auf", "nichts", "so", "sehr", "ver\u00b7picht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "PIS", "ADV", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ach nein ich m\u00f6chte nicht.", "tokens": ["Ach", "nein", "ich", "m\u00f6ch\u00b7te", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKANT", "PPER", "VMFIN", "PTKNEG", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "3. Ach nein/ ich m\u00f6chte nicht/ die kuchen sind zu d\u00fcnne/", "tokens": ["Ach", "nein", "/", "ich", "m\u00f6ch\u00b7te", "nicht", "/", "die", "ku\u00b7chen", "sind", "zu", "d\u00fcn\u00b7ne", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKANT", "$(", "PPER", "VMFIN", "PTKNEG", "$(", "ART", "ADJA", "VAFIN", "APPR", "NE", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die butter ist zu arg/", "tokens": ["Die", "but\u00b7ter", "ist", "zu", "arg", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PTKA", "ADJD", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Die hefen gehn zu starck/", "tokens": ["Die", "he\u00b7fen", "gehn", "zu", "starck", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "PTKZU", "VVFIN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Und die rosinen sind gar sparsamlich darinne/", "tokens": ["Und", "die", "ro\u00b7si\u00b7nen", "sind", "gar", "spar\u00b7sam\u00b7lich", "da\u00b7rin\u00b7ne", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "VAFIN", "ADV", "ADJD", "PAV", "$("], "meter": "--+--+-+-+-+-", "measure": "anapaest.di.plus"}, "line.5": {"text": "Der rand ist mager und zubricht/", "tokens": ["Der", "rand", "ist", "ma\u00b7ger", "und", "zu\u00b7bricht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "KON", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ach nein ich m\u00f6chte nicht.", "tokens": ["Ach", "nein", "ich", "m\u00f6ch\u00b7te", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKANT", "PPER", "VMFIN", "PTKNEG", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "4. Ach nein ich m\u00f6chte nicht/ ich mu\u00df es nur bekennen/", "tokens": ["Ach", "nein", "ich", "m\u00f6ch\u00b7te", "nicht", "/", "ich", "mu\u00df", "es", "nur", "be\u00b7ken\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKANT", "PPER", "VMFIN", "PTKNEG", "$(", "PPER", "VMFIN", "PPER", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die suppe kocht zu scharff/", "tokens": ["Die", "sup\u00b7pe", "kocht", "zu", "scharff", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKA", "ADJD", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und wer es nicht bedarff/", "tokens": ["Und", "wer", "es", "nicht", "be\u00b7darff", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "PTKNEG", "ADJD", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Der wird sich warlich nicht das maul dabey verbren\u0303en/", "tokens": ["Der", "wird", "sich", "war\u00b7lich", "nicht", "das", "maul", "da\u00b7bey", "ver\u00b7bre\u00f1en", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PRF", "ADV", "PTKNEG", "ART", "NN", "PAV", "VVINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Der hencker h\u00e4lt euch doch das liecht/", "tokens": ["Der", "hen\u00b7cker", "h\u00e4lt", "euch", "doch", "das", "liecht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADV", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ach nein/ ich m\u00f6chte nicht.", "tokens": ["Ach", "nein", "/", "ich", "m\u00f6ch\u00b7te", "nicht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "PTKANT", "$(", "PPER", "VMFIN", "PTKNEG", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "5. Ach nein ich m\u00f6chte nicht/ ietzt leb ich in der faste/", "tokens": ["Ach", "nein", "ich", "m\u00f6ch\u00b7te", "nicht", "/", "ietzt", "leb", "ich", "in", "der", "fas\u00b7te", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKANT", "PPER", "VMFIN", "PTKNEG", "$(", "ADV", "VVFIN", "PPER", "APPR", "ART", "ADJA", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Da e\u00df ich selten viel/", "tokens": ["Da", "e\u00df", "ich", "sel\u00b7ten", "viel", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "ADV", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Doch wer nicht warten will/", "tokens": ["Doch", "wer", "nicht", "war\u00b7ten", "will", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PTKNEG", "VVINF", "VMFIN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Der komme nur zu mir fr\u00fch morgens her zu gaste/", "tokens": ["Der", "kom\u00b7me", "nur", "zu", "mir", "fr\u00fch", "mor\u00b7gens", "her", "zu", "gas\u00b7te", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "APPR", "PPER", "ADJD", "ADV", "APZR", "PTKZU", "VVFIN", "$("], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Die tafel ist schon angericht/", "tokens": ["Die", "ta\u00b7fel", "ist", "schon", "an\u00b7ge\u00b7richt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ach nein ich m\u00f6chte nicht.", "tokens": ["Ach", "nein", "ich", "m\u00f6ch\u00b7te", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKANT", "PPER", "VMFIN", "PTKNEG", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}}}}