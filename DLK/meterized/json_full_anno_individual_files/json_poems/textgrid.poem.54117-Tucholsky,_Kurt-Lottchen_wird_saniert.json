{"textgrid.poem.54117": {"metadata": {"author": {"name": "Tucholsky, Kurt", "birth": "N.A.", "death": "N.A."}, "title": "Lottchen wird saniert", "genre": "verse", "period": "N.A.", "pub_year": 1912, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "\u00bbund kosten Zinsen! Also weiter:", "tokens": ["\u00bb", "und", "kos\u00b7ten", "Zin\u00b7sen", "!", "Al\u00b7so", "wei\u00b7ter", ":"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "KON", "ADJA", "NN", "$.", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Louis Brest . . . . . . . . . . . . . . . . . . . .209", "tokens": ["Lou\u00b7is", "Brest", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".209"], "token_info": ["word", "word", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "number"], "pos": ["NE", "NE", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$("], "meter": "+-+", "measure": "trochaic.di"}, "line.3": {"text": "Wer\u00dfhofen . . . . . . . . . . . . . . . . . . . . . 54", "tokens": ["Wer\u00df\u00b7ho\u00b7fen", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", "54"], "token_info": ["word", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "number"], "pos": ["NN", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "CARD"], "meter": "-+-", "measure": "amphibrach.single"}, "line.4": {"text": "Was ist das?\u00ab", "tokens": ["Was", "ist", "das", "?", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["PWS", "VAFIN", "PDS", "$.", "$("], "meter": "-+-", "measure": "amphibrach.single"}, "line.5": {"text": "\u00bbdas ist das, wo ich dir neulich gesagt habe!\u00ab", "tokens": ["\u00bb", "das", "ist", "das", ",", "wo", "ich", "dir", "neu\u00b7lich", "ge\u00b7sagt", "ha\u00b7be", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PDS", "VAFIN", "PDS", "$,", "PWAV", "PPER", "PPER", "ADV", "VVPP", "VAFIN", "$.", "$("], "meter": "-+-+--+--+--", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "\u00bbdavon hast du nichts gesagt!\u00ab", "tokens": ["\u00bb", "da\u00b7von", "hast", "du", "nichts", "ge\u00b7sagt", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PAV", "VAFIN", "PPER", "PIS", "VVPP", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "\u00bbwem?\u00ab", "tokens": ["\u00bb", "wem", "?", "\u00ab"], "token_info": ["punct", "word", "punct", "punct"], "pos": ["$(", "PWS", "$.", "$("], "meter": "+", "measure": "single.up"}, "line.2": {"text": "\u00bbder Kleiderkasse. Nu weiter!\u00ab", "tokens": ["\u00bb", "der", "Klei\u00b7der\u00b7kas\u00b7se", ".", "Nu", "wei\u00b7ter", "!", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["$(", "ART", "NN", "$.", "ADV", "PTKVZ", "$.", "$("], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "\u00bbalso wovon ich das alles bezahlen soll . . . ich wei\u00df es nicht. Ich wei\u00df es wirklich nicht.", "tokens": ["\u00bb", "al\u00b7so", "wo\u00b7von", "ich", "das", "al\u00b7les", "be\u00b7zah\u00b7len", "soll", ".", ".", ".", "ich", "wei\u00df", "es", "nicht", ".", "Ich", "wei\u00df", "es", "wirk\u00b7lich", "nicht", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "PWAV", "PPER", "ART", "PIS", "VVINF", "VMFIN", "$.", "$.", "$.", "PPER", "VVFIN", "PPER", "PTKNEG", "$.", "PPER", "VVFIN", "PPER", "ADJD", "PTKNEG", "$."], "meter": "+-+-+-+--+-+-+-+-+-+-+", "measure": "trochaic.octa.plus.relaxed"}, "line.4": {"text": "Wer\u00dfhofen . . . . . . . . . . . . . . . . . . . . . 54", "tokens": ["Wer\u00df\u00b7ho\u00b7fen", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", "54"], "token_info": ["word", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "number"], "pos": ["NN", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "CARD"], "meter": "-+-", "measure": "amphibrach.single"}, "line.5": {"text": "Postscheck . . . . . . . . . . . . . . . . . . . . . 28", "tokens": ["Post\u00b7scheck", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", "28"], "token_info": ["word", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "number"], "pos": ["NE", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "CARD"], "meter": "+-", "measure": "trochaic.single"}, "line.6": {"text": "\u2013 was hei\u00dft Postscheck achtundzwanzig . . . ?\u00ab", "tokens": ["\u2013", "was", "hei\u00dft", "Post\u00b7scheck", "acht\u00b7und\u00b7zwan\u00b7zig", ".", ".", ".", "?", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct", "punct", "punct", "punct"], "pos": ["$(", "PWS", "VVFIN", "NN", "CARD", "$.", "$.", "$.", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "\u00bbund kosten Zinsen! Also weiter:", "tokens": ["\u00bb", "und", "kos\u00b7ten", "Zin\u00b7sen", "!", "Al\u00b7so", "wei\u00b7ter", ":"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "KON", "ADJA", "NN", "$.", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Louis Brest . . . . . . . . . . . . . . . . . . . .209", "tokens": ["Lou\u00b7is", "Brest", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".209"], "token_info": ["word", "word", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "number"], "pos": ["NE", "NE", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$("], "meter": "+-+", "measure": "trochaic.di"}, "line.3": {"text": "Wer\u00dfhofen . . . . . . . . . . . . . . . . . . . . . 54", "tokens": ["Wer\u00df\u00b7ho\u00b7fen", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", "54"], "token_info": ["word", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "number"], "pos": ["NN", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "CARD"], "meter": "-+-", "measure": "amphibrach.single"}, "line.4": {"text": "Was ist das?\u00ab", "tokens": ["Was", "ist", "das", "?", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["PWS", "VAFIN", "PDS", "$.", "$("], "meter": "-+-", "measure": "amphibrach.single"}, "line.5": {"text": "\u00bbdas ist das, wo ich dir neulich gesagt habe!\u00ab", "tokens": ["\u00bb", "das", "ist", "das", ",", "wo", "ich", "dir", "neu\u00b7lich", "ge\u00b7sagt", "ha\u00b7be", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PDS", "VAFIN", "PDS", "$,", "PWAV", "PPER", "PPER", "ADV", "VVPP", "VAFIN", "$.", "$("], "meter": "-+-+--+--+--", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "\u00bbdavon hast du nichts gesagt!\u00ab", "tokens": ["\u00bb", "da\u00b7von", "hast", "du", "nichts", "ge\u00b7sagt", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PAV", "VAFIN", "PPER", "PIS", "VVPP", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "\u00bbwem?\u00ab", "tokens": ["\u00bb", "wem", "?", "\u00ab"], "token_info": ["punct", "word", "punct", "punct"], "pos": ["$(", "PWS", "$.", "$("], "meter": "+", "measure": "single.up"}, "line.2": {"text": "\u00bbder Kleiderkasse. Nu weiter!\u00ab", "tokens": ["\u00bb", "der", "Klei\u00b7der\u00b7kas\u00b7se", ".", "Nu", "wei\u00b7ter", "!", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["$(", "ART", "NN", "$.", "ADV", "PTKVZ", "$.", "$("], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "\u00bbalso wovon ich das alles bezahlen soll . . . ich wei\u00df es nicht. Ich wei\u00df es wirklich nicht.", "tokens": ["\u00bb", "al\u00b7so", "wo\u00b7von", "ich", "das", "al\u00b7les", "be\u00b7zah\u00b7len", "soll", ".", ".", ".", "ich", "wei\u00df", "es", "nicht", ".", "Ich", "wei\u00df", "es", "wirk\u00b7lich", "nicht", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "PWAV", "PPER", "ART", "PIS", "VVINF", "VMFIN", "$.", "$.", "$.", "PPER", "VVFIN", "PPER", "PTKNEG", "$.", "PPER", "VVFIN", "PPER", "ADJD", "PTKNEG", "$."], "meter": "+-+-+-+--+-+-+-+-+-+-+", "measure": "trochaic.octa.plus.relaxed"}, "line.4": {"text": "Wer\u00dfhofen . . . . . . . . . . . . . . . . . . . . . 54", "tokens": ["Wer\u00df\u00b7ho\u00b7fen", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", "54"], "token_info": ["word", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "number"], "pos": ["NN", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "CARD"], "meter": "-+-", "measure": "amphibrach.single"}, "line.5": {"text": "Postscheck . . . . . . . . . . . . . . . . . . . . . 28", "tokens": ["Post\u00b7scheck", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", "28"], "token_info": ["word", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "number"], "pos": ["NE", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "CARD"], "meter": "+-", "measure": "trochaic.single"}, "line.6": {"text": "\u2013 was hei\u00dft Postscheck achtundzwanzig . . . ?\u00ab", "tokens": ["\u2013", "was", "hei\u00dft", "Post\u00b7scheck", "acht\u00b7und\u00b7zwan\u00b7zig", ".", ".", ".", "?", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct", "punct", "punct", "punct"], "pos": ["$(", "PWS", "VVFIN", "NN", "CARD", "$.", "$.", "$.", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}}}}