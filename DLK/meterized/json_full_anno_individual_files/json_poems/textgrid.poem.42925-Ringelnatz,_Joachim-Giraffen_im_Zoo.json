{"textgrid.poem.42925": {"metadata": {"author": {"name": "Ringelnatz, Joachim", "birth": "N.A.", "death": "N.A."}, "title": "Giraffen im Zoo", "genre": "verse", "period": "N.A.", "pub_year": 1908, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wenn sich die Giraffen recken,", "tokens": ["Wenn", "sich", "die", "Gir\u00b7af\u00b7fen", "re\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "ART", "NN", "VVINF", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Hochlaub sucht die spitze Zunge,", "tokens": ["Hoch\u00b7laub", "sucht", "die", "spit\u00b7ze", "Zun\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Das ihnen so schmeckt, wie junge", "tokens": ["Das", "ih\u00b7nen", "so", "schmeckt", ",", "wie", "jun\u00b7ge"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["PDS", "PPER", "ADV", "VVFIN", "$,", "PWAV", "ADJA"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Fr\u00fchkartoffeln mit Butter mir schmecken.", "tokens": ["Fr\u00fch\u00b7kar\u00b7tof\u00b7feln", "mit", "But\u00b7ter", "mir", "schme\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "PPER", "VVINF", "$."], "meter": "+-+--+--+-", "measure": "trochaic.tetra.relaxed"}}, "stanza.2": {"line.1": {"text": "Hohe H\u00e4lse. Ihre Flecken", "tokens": ["Ho\u00b7he", "H\u00e4l\u00b7se", ".", "Ih\u00b7re", "Fle\u00b7cken"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ADJA", "NN", "$.", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sehen aus wie sch\u00f6n gerostet.", "tokens": ["Se\u00b7hen", "aus", "wie", "sch\u00f6n", "ge\u00b7ros\u00b7tet", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "KOKOM", "ADJD", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Ihre langsame und weiche", "tokens": ["Ih\u00b7re", "lang\u00b7sa\u00b7me", "und", "wei\u00b7che"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "ADJA", "KON", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "R\u00fchrend warme Schnauze kostet", "tokens": ["R\u00fch\u00b7rend", "war\u00b7me", "Schnau\u00b7ze", "kos\u00b7tet"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJD", "ADJA", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Von dem Heu, das ich nun reiche.", "tokens": ["Von", "dem", "Heu", ",", "das", "ich", "nun", "rei\u00b7che", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "PRELS", "PPER", "ADV", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Lauscht ihr Ohr nach allen Seiten,", "tokens": ["Lauscht", "ihr", "Ohr", "nach", "al\u00b7len", "Sei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "APPR", "PIAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sucht nach wild vertrauten T\u00f6nen.", "tokens": ["Sucht", "nach", "wild", "ver\u00b7trau\u00b7ten", "T\u00f6\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ADJD", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Da sie von uns weiter schreiten,", "tokens": ["Da", "sie", "von", "uns", "wei\u00b7ter", "schrei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PPER", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Tr\u00e4umt in ihren stillen, sch\u00f6nen", "tokens": ["Tr\u00e4umt", "in", "ih\u00b7ren", "stil\u00b7len", ",", "sch\u00f6\u00b7nen"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["VVFIN", "APPR", "PPOSAT", "ADJA", "$,", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Augen etwas, was ersch\u00fcttert,", "tokens": ["Au\u00b7gen", "et\u00b7was", ",", "was", "er\u00b7sch\u00fct\u00b7tert", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "ADV", "$,", "PRELS", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Hoheit. So, als ob sie w\u00fc\u00dften,", "tokens": ["Ho\u00b7heit", ".", "So", ",", "als", "ob", "sie", "w\u00fc\u00df\u00b7ten", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "ADV", "$,", "KOKOM", "KOUS", "PPER", "VVFIN", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.2": {"text": "Da\u00df nicht Menschen, sondern da\u00df ein", "tokens": ["Da\u00df", "nicht", "Men\u00b7schen", ",", "son\u00b7dern", "da\u00df", "ein"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "PTKNEG", "NN", "$,", "KON", "KOUS", "ART"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Schicksal sie jetzt anders f\u00fcttert.", "tokens": ["Schick\u00b7sal", "sie", "jetzt", "an\u00b7ders", "f\u00fct\u00b7tert", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "ADV", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Wenn sich die Giraffen recken,", "tokens": ["Wenn", "sich", "die", "Gir\u00b7af\u00b7fen", "re\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "ART", "NN", "VVINF", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Hochlaub sucht die spitze Zunge,", "tokens": ["Hoch\u00b7laub", "sucht", "die", "spit\u00b7ze", "Zun\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Das ihnen so schmeckt, wie junge", "tokens": ["Das", "ih\u00b7nen", "so", "schmeckt", ",", "wie", "jun\u00b7ge"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["PDS", "PPER", "ADV", "VVFIN", "$,", "PWAV", "ADJA"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Fr\u00fchkartoffeln mit Butter mir schmecken.", "tokens": ["Fr\u00fch\u00b7kar\u00b7tof\u00b7feln", "mit", "But\u00b7ter", "mir", "schme\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "PPER", "VVINF", "$."], "meter": "+-+--+--+-", "measure": "trochaic.tetra.relaxed"}}, "stanza.7": {"line.1": {"text": "Hohe H\u00e4lse. Ihre Flecken", "tokens": ["Ho\u00b7he", "H\u00e4l\u00b7se", ".", "Ih\u00b7re", "Fle\u00b7cken"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ADJA", "NN", "$.", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sehen aus wie sch\u00f6n gerostet.", "tokens": ["Se\u00b7hen", "aus", "wie", "sch\u00f6n", "ge\u00b7ros\u00b7tet", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "KOKOM", "ADJD", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Ihre langsame und weiche", "tokens": ["Ih\u00b7re", "lang\u00b7sa\u00b7me", "und", "wei\u00b7che"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "ADJA", "KON", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "R\u00fchrend warme Schnauze kostet", "tokens": ["R\u00fch\u00b7rend", "war\u00b7me", "Schnau\u00b7ze", "kos\u00b7tet"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJD", "ADJA", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Von dem Heu, das ich nun reiche.", "tokens": ["Von", "dem", "Heu", ",", "das", "ich", "nun", "rei\u00b7che", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "PRELS", "PPER", "ADV", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Lauscht ihr Ohr nach allen Seiten,", "tokens": ["Lauscht", "ihr", "Ohr", "nach", "al\u00b7len", "Sei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "APPR", "PIAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sucht nach wild vertrauten T\u00f6nen.", "tokens": ["Sucht", "nach", "wild", "ver\u00b7trau\u00b7ten", "T\u00f6\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ADJD", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Da sie von uns weiter schreiten,", "tokens": ["Da", "sie", "von", "uns", "wei\u00b7ter", "schrei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PPER", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Tr\u00e4umt in ihren stillen, sch\u00f6nen", "tokens": ["Tr\u00e4umt", "in", "ih\u00b7ren", "stil\u00b7len", ",", "sch\u00f6\u00b7nen"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["VVFIN", "APPR", "PPOSAT", "ADJA", "$,", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Augen etwas, was ersch\u00fcttert,", "tokens": ["Au\u00b7gen", "et\u00b7was", ",", "was", "er\u00b7sch\u00fct\u00b7tert", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "ADV", "$,", "PRELS", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Hoheit. So, als ob sie w\u00fc\u00dften,", "tokens": ["Ho\u00b7heit", ".", "So", ",", "als", "ob", "sie", "w\u00fc\u00df\u00b7ten", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "ADV", "$,", "KOKOM", "KOUS", "PPER", "VVFIN", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.2": {"text": "Da\u00df nicht Menschen, sondern da\u00df ein", "tokens": ["Da\u00df", "nicht", "Men\u00b7schen", ",", "son\u00b7dern", "da\u00df", "ein"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "PTKNEG", "NN", "$,", "KON", "KOUS", "ART"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Schicksal sie jetzt anders f\u00fcttert.", "tokens": ["Schick\u00b7sal", "sie", "jetzt", "an\u00b7ders", "f\u00fct\u00b7tert", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "ADV", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}}}}