{"textgrid.poem.42885": {"metadata": {"author": {"name": "Ringelnatz, Joachim", "birth": "N.A.", "death": "N.A."}, "title": "Zu einem Geschenk", "genre": "verse", "period": "N.A.", "pub_year": 1908, "urn": "N.A.", "language": ["de:0.85", "nl:0.14"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ich wollte dir was dedizieren,", "tokens": ["Ich", "woll\u00b7te", "dir", "was", "de\u00b7di\u00b7zie\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "PIS", "VVINF", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Nein schenken; was nicht zuviel kostet.", "tokens": ["Nein", "schen\u00b7ken", ";", "was", "nicht", "zu\u00b7viel", "kos\u00b7tet", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "VVINF", "$.", "PWS", "PTKNEG", "PIS", "VVFIN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "Aber was aus Blech ist, rostet,", "tokens": ["A\u00b7ber", "was", "aus", "Blech", "ist", ",", "ros\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "PWS", "APPR", "NN", "VAFIN", "$,", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und die Messinggegenst\u00e4nde oxydieren.", "tokens": ["Und", "die", "Mes\u00b7sing\u00b7ge\u00b7gen\u00b7st\u00e4n\u00b7de", "o\u00b7xyd\u00b7ie\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.5": {"text": "Und was kosten soll es eben doch.", "tokens": ["Und", "was", "kos\u00b7ten", "soll", "es", "e\u00b7ben", "doch", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VVINF", "VMFIN", "PPER", "ADV", "ADV", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.6": {"text": "Denn aus M\u00fche mach ich extra noch", "tokens": ["Denn", "aus", "M\u00fc\u00b7he", "mach", "ich", "ex\u00b7tra", "noch"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "NN", "VVFIN", "PPER", "ADV", "ADV"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.7": {"text": "Was hinzu, auch kleine Witze.", "tokens": ["Was", "hin\u00b7zu", ",", "auch", "klei\u00b7ne", "Wit\u00b7ze", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "PTKVZ", "$,", "ADV", "ADJA", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "W\u00e4r' bei dem, was ich besitze,", "tokens": ["W\u00e4r'", "bei", "dem", ",", "was", "ich", "be\u00b7sit\u00b7ze", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "ART", "$,", "PWS", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "Etwas Altert\u00fcmliches dabei \u2013 \u2013", "tokens": ["Et\u00b7was", "Al\u00b7ter\u00b7t\u00fcm\u00b7li\u00b7ches", "da\u00b7bei", "\u2013", "\u2013"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["ADV", "ADJA", "PAV", "$(", "$("], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.10": {"text": "Doch was n\u00fctzt dir eine Lanzenspitze!", "tokens": ["Doch", "was", "n\u00fctzt", "dir", "ei\u00b7ne", "Lan\u00b7zens\u00b7pit\u00b7ze", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.11": {"text": "An dem Bierkrug sind die beiden", "tokens": ["An", "dem", "Bier\u00b7krug", "sind", "die", "bei\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "VAFIN", "ART", "PIAT"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.12": {"text": "L\u00f6wenk\u00f6pfe schon entzwei.", "tokens": ["L\u00f6\u00b7wen\u00b7k\u00f6p\u00b7fe", "schon", "ent\u00b7zwei", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ADV", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.13": {"text": "Und den Buddha mag ich selber leiden.", "tokens": ["Und", "den", "Budd\u00b7ha", "mag", "ich", "sel\u00b7ber", "lei\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VMFIN", "PPER", "ADV", "VVINF", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.14": {"text": "Und du sammelst keine Schmetterlinge,", "tokens": ["Und", "du", "sam\u00b7melst", "kei\u00b7ne", "Schmet\u00b7ter\u00b7lin\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PIAT", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.15": {"text": "Die mein Freund aus China mitgebracht.", "tokens": ["Die", "mein", "Freund", "aus", "Chi\u00b7na", "mit\u00b7ge\u00b7bracht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "APPR", "NE", "VVPP", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.16": {"text": "Nein \u2013 das Sofa und so gro\u00dfe Dinge", "tokens": ["Nein", "\u2013", "das", "So\u00b7fa", "und", "so", "gro\u00b7\u00dfe", "Din\u00b7ge"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "$(", "ART", "NN", "KON", "ADV", "ADJA", "NN"], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}, "line.17": {"text": "Kommen \u00fcberhaupt nicht in Betracht.", "tokens": ["Kom\u00b7men", "\u00fc\u00b7ber\u00b7haupt", "nicht", "in", "Be\u00b7tracht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "PTKNEG", "APPR", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.18": {"text": "Au\u00dferdem geh\u00f6ren sie nicht mir.", "tokens": ["Au\u00b7\u00dfer\u00b7dem", "ge\u00b7h\u00f6\u00b7ren", "sie", "nicht", "mir", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "PTKNEG", "PPER", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.19": {"text": "Ach, ich hab' die ganze letzte Nacht", "tokens": ["Ach", ",", "ich", "hab'", "die", "gan\u00b7ze", "letz\u00b7te", "Nacht"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ITJ", "$,", "PPER", "VAFIN", "ART", "ADJA", "ADJA", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.20": {"text": "Rumgegr\u00fcbelt, was ich dir", "tokens": ["Rum\u00b7ge\u00b7gr\u00fc\u00b7belt", ",", "was", "ich", "dir"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["VVFIN", "$,", "PWS", "PPER", "PPER"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.21": {"text": "Geben k\u00f6nnte. Schlief deshalb nur eine,", "tokens": ["Ge\u00b7ben", "k\u00f6nn\u00b7te", ".", "Schlief", "des\u00b7halb", "nur", "ei\u00b7ne", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "$.", "VVFIN", "PAV", "ADV", "ART", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.22": {"text": "Allerh\u00f6chstens zwei von sieben Stunden,", "tokens": ["Al\u00b7ler\u00b7h\u00f6chs\u00b7tens", "zwei", "von", "sie\u00b7ben", "Stun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "CARD", "APPR", "CARD", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.23": {"text": "Und zum Schlu\u00df hab' ich doch nur dies kleine,", "tokens": ["Und", "zum", "Schlu\u00df", "hab'", "ich", "doch", "nur", "dies", "klei\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "NN", "VAFIN", "PPER", "ADV", "ADV", "PDS", "ADJA", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.24": {"text": "Lumpige beschi\u00dfne Ding gefunden.", "tokens": ["Lum\u00b7pi\u00b7ge", "be\u00b7schi\u00df\u00b7ne", "Ding", "ge\u00b7fun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "ADJA", "NN", "VVPP", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.25": {"text": "Aber gern hab' ich f\u00fcr dich gewacht.", "tokens": ["A\u00b7ber", "gern", "hab'", "ich", "f\u00fcr", "dich", "ge\u00b7wacht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "PPER", "APPR", "PPER", "VVPP", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.26": {"text": "Was ich nicht vermochte, tu du's: Dr\u00fccke du", "tokens": ["Was", "ich", "nicht", "ver\u00b7moch\u00b7te", ",", "tu", "du's", ":", "Dr\u00fc\u00b7cke", "du"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["PWS", "PPER", "PTKNEG", "VVFIN", "$,", "NE", "NE", "$.", "VVFIN", "PPER"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.27": {"text": "Nun ein Auge zu.", "tokens": ["Nun", "ein", "Au\u00b7ge", "zu", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "PTKVZ", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.28": {"text": "Und bedenke,", "tokens": ["Und", "be\u00b7den\u00b7ke", ","], "token_info": ["word", "word", "punct"], "pos": ["KON", "VVFIN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.29": {"text": "Da\u00df ich dir f\u00fcnf Stunden Wache schenke.", "tokens": ["Da\u00df", "ich", "dir", "f\u00fcnf", "Stun\u00b7den", "Wa\u00b7che", "schen\u00b7ke", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "CARD", "NN", "NN", "VVFIN", "$."], "meter": "--+-+-+-+-", "measure": "anapaest.init"}, "line.30": {"text": "La\u00df mich auch in Zukunft nicht in Ruh.", "tokens": ["La\u00df", "mich", "auch", "in", "Zu\u00b7kunft", "nicht", "in", "Ruh", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ADV", "APPR", "NN", "PTKNEG", "APPR", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.2": {"line.1": {"text": "Ich wollte dir was dedizieren,", "tokens": ["Ich", "woll\u00b7te", "dir", "was", "de\u00b7di\u00b7zie\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "PIS", "VVINF", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Nein schenken; was nicht zuviel kostet.", "tokens": ["Nein", "schen\u00b7ken", ";", "was", "nicht", "zu\u00b7viel", "kos\u00b7tet", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "VVINF", "$.", "PWS", "PTKNEG", "PIS", "VVFIN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "Aber was aus Blech ist, rostet,", "tokens": ["A\u00b7ber", "was", "aus", "Blech", "ist", ",", "ros\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "PWS", "APPR", "NN", "VAFIN", "$,", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und die Messinggegenst\u00e4nde oxydieren.", "tokens": ["Und", "die", "Mes\u00b7sing\u00b7ge\u00b7gen\u00b7st\u00e4n\u00b7de", "o\u00b7xyd\u00b7ie\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.5": {"text": "Und was kosten soll es eben doch.", "tokens": ["Und", "was", "kos\u00b7ten", "soll", "es", "e\u00b7ben", "doch", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VVINF", "VMFIN", "PPER", "ADV", "ADV", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.6": {"text": "Denn aus M\u00fche mach ich extra noch", "tokens": ["Denn", "aus", "M\u00fc\u00b7he", "mach", "ich", "ex\u00b7tra", "noch"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "NN", "VVFIN", "PPER", "ADV", "ADV"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.7": {"text": "Was hinzu, auch kleine Witze.", "tokens": ["Was", "hin\u00b7zu", ",", "auch", "klei\u00b7ne", "Wit\u00b7ze", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "PTKVZ", "$,", "ADV", "ADJA", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "W\u00e4r' bei dem, was ich besitze,", "tokens": ["W\u00e4r'", "bei", "dem", ",", "was", "ich", "be\u00b7sit\u00b7ze", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "ART", "$,", "PWS", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "Etwas Altert\u00fcmliches dabei \u2013 \u2013", "tokens": ["Et\u00b7was", "Al\u00b7ter\u00b7t\u00fcm\u00b7li\u00b7ches", "da\u00b7bei", "\u2013", "\u2013"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["ADV", "ADJA", "PAV", "$(", "$("], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.10": {"text": "Doch was n\u00fctzt dir eine Lanzenspitze!", "tokens": ["Doch", "was", "n\u00fctzt", "dir", "ei\u00b7ne", "Lan\u00b7zens\u00b7pit\u00b7ze", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.11": {"text": "An dem Bierkrug sind die beiden", "tokens": ["An", "dem", "Bier\u00b7krug", "sind", "die", "bei\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "VAFIN", "ART", "PIAT"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.12": {"text": "L\u00f6wenk\u00f6pfe schon entzwei.", "tokens": ["L\u00f6\u00b7wen\u00b7k\u00f6p\u00b7fe", "schon", "ent\u00b7zwei", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ADV", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.13": {"text": "Und den Buddha mag ich selber leiden.", "tokens": ["Und", "den", "Budd\u00b7ha", "mag", "ich", "sel\u00b7ber", "lei\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VMFIN", "PPER", "ADV", "VVINF", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.14": {"text": "Und du sammelst keine Schmetterlinge,", "tokens": ["Und", "du", "sam\u00b7melst", "kei\u00b7ne", "Schmet\u00b7ter\u00b7lin\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PIAT", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.15": {"text": "Die mein Freund aus China mitgebracht.", "tokens": ["Die", "mein", "Freund", "aus", "Chi\u00b7na", "mit\u00b7ge\u00b7bracht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "APPR", "NE", "VVPP", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.16": {"text": "Nein \u2013 das Sofa und so gro\u00dfe Dinge", "tokens": ["Nein", "\u2013", "das", "So\u00b7fa", "und", "so", "gro\u00b7\u00dfe", "Din\u00b7ge"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "$(", "ART", "NN", "KON", "ADV", "ADJA", "NN"], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}, "line.17": {"text": "Kommen \u00fcberhaupt nicht in Betracht.", "tokens": ["Kom\u00b7men", "\u00fc\u00b7ber\u00b7haupt", "nicht", "in", "Be\u00b7tracht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "PTKNEG", "APPR", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.18": {"text": "Au\u00dferdem geh\u00f6ren sie nicht mir.", "tokens": ["Au\u00b7\u00dfer\u00b7dem", "ge\u00b7h\u00f6\u00b7ren", "sie", "nicht", "mir", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "PTKNEG", "PPER", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.19": {"text": "Ach, ich hab' die ganze letzte Nacht", "tokens": ["Ach", ",", "ich", "hab'", "die", "gan\u00b7ze", "letz\u00b7te", "Nacht"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ITJ", "$,", "PPER", "VAFIN", "ART", "ADJA", "ADJA", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.20": {"text": "Rumgegr\u00fcbelt, was ich dir", "tokens": ["Rum\u00b7ge\u00b7gr\u00fc\u00b7belt", ",", "was", "ich", "dir"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["VVFIN", "$,", "PWS", "PPER", "PPER"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.21": {"text": "Geben k\u00f6nnte. Schlief deshalb nur eine,", "tokens": ["Ge\u00b7ben", "k\u00f6nn\u00b7te", ".", "Schlief", "des\u00b7halb", "nur", "ei\u00b7ne", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "$.", "VVFIN", "PAV", "ADV", "ART", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.22": {"text": "Allerh\u00f6chstens zwei von sieben Stunden,", "tokens": ["Al\u00b7ler\u00b7h\u00f6chs\u00b7tens", "zwei", "von", "sie\u00b7ben", "Stun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "CARD", "APPR", "CARD", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.23": {"text": "Und zum Schlu\u00df hab' ich doch nur dies kleine,", "tokens": ["Und", "zum", "Schlu\u00df", "hab'", "ich", "doch", "nur", "dies", "klei\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "NN", "VAFIN", "PPER", "ADV", "ADV", "PDS", "ADJA", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.24": {"text": "Lumpige beschi\u00dfne Ding gefunden.", "tokens": ["Lum\u00b7pi\u00b7ge", "be\u00b7schi\u00df\u00b7ne", "Ding", "ge\u00b7fun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "ADJA", "NN", "VVPP", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.25": {"text": "Aber gern hab' ich f\u00fcr dich gewacht.", "tokens": ["A\u00b7ber", "gern", "hab'", "ich", "f\u00fcr", "dich", "ge\u00b7wacht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "PPER", "APPR", "PPER", "VVPP", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.26": {"text": "Was ich nicht vermochte, tu du's: Dr\u00fccke du", "tokens": ["Was", "ich", "nicht", "ver\u00b7moch\u00b7te", ",", "tu", "du's", ":", "Dr\u00fc\u00b7cke", "du"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["PWS", "PPER", "PTKNEG", "VVFIN", "$,", "NE", "NE", "$.", "VVFIN", "PPER"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.27": {"text": "Nun ein Auge zu.", "tokens": ["Nun", "ein", "Au\u00b7ge", "zu", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "PTKVZ", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.28": {"text": "Und bedenke,", "tokens": ["Und", "be\u00b7den\u00b7ke", ","], "token_info": ["word", "word", "punct"], "pos": ["KON", "VVFIN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.29": {"text": "Da\u00df ich dir f\u00fcnf Stunden Wache schenke.", "tokens": ["Da\u00df", "ich", "dir", "f\u00fcnf", "Stun\u00b7den", "Wa\u00b7che", "schen\u00b7ke", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "CARD", "NN", "NN", "VVFIN", "$."], "meter": "--+-+-+-+-", "measure": "anapaest.init"}, "line.30": {"text": "La\u00df mich auch in Zukunft nicht in Ruh.", "tokens": ["La\u00df", "mich", "auch", "in", "Zu\u00b7kunft", "nicht", "in", "Ruh", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ADV", "APPR", "NN", "PTKNEG", "APPR", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}}}}