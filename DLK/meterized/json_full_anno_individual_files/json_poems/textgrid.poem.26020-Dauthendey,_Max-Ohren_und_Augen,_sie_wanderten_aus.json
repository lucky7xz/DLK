{"textgrid.poem.26020": {"metadata": {"author": {"name": "Dauthendey, Max", "birth": "N.A.", "death": "N.A."}, "title": "Ohren und Augen, sie wanderten aus", "genre": "verse", "period": "N.A.", "pub_year": 1892, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Sehnsucht verbrennt wie Feuer mein Haus,", "tokens": ["Sehn\u00b7sucht", "ver\u00b7brennt", "wie", "Feu\u00b7er", "mein", "Haus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "KOKOM", "NN", "PPOSAT", "NN", "$,"], "meter": "---+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Ohren und Augen, sie wanderten aus,", "tokens": ["Oh\u00b7ren", "und", "Au\u00b7gen", ",", "sie", "wan\u00b7der\u00b7ten", "aus", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "$,", "PPER", "VVFIN", "PTKVZ", "$,"], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.3": {"text": "Wandern, ach, h\u00e4tten sie dich gefunden,", "tokens": ["Wan\u00b7dern", ",", "ach", ",", "h\u00e4t\u00b7ten", "sie", "dich", "ge\u00b7fun\u00b7den", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ITJ", "$,", "VAFIN", "PPER", "PRF", "VVPP", "$,"], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}, "line.4": {"text": "Kl\u00e4glich verdursten die Tage und Stunden.", "tokens": ["Kl\u00e4g\u00b7lich", "ver\u00b7durs\u00b7ten", "die", "Ta\u00b7ge", "und", "Stun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ART", "NN", "KON", "NN", "$."], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.5": {"text": "Ich sto\u00dfe mein Herz hinaus vor die T\u00fcre,", "tokens": ["Ich", "sto\u00b7\u00dfe", "mein", "Herz", "hin\u00b7aus", "vor", "die", "T\u00fc\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "APZR", "APPR", "ART", "NN", "$,"], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Da\u00df ich es nicht als Leichnam sp\u00fcre.", "tokens": ["Da\u00df", "ich", "es", "nicht", "als", "Leich\u00b7nam", "sp\u00fc\u00b7re", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "PTKNEG", "KOUS", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Sehnsucht verbrennt wie Feuer mein Haus,", "tokens": ["Sehn\u00b7sucht", "ver\u00b7brennt", "wie", "Feu\u00b7er", "mein", "Haus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "KOKOM", "NN", "PPOSAT", "NN", "$,"], "meter": "---+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Ohren und Augen, sie wanderten aus,", "tokens": ["Oh\u00b7ren", "und", "Au\u00b7gen", ",", "sie", "wan\u00b7der\u00b7ten", "aus", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "$,", "PPER", "VVFIN", "PTKVZ", "$,"], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.3": {"text": "Wandern, ach, h\u00e4tten sie dich gefunden,", "tokens": ["Wan\u00b7dern", ",", "ach", ",", "h\u00e4t\u00b7ten", "sie", "dich", "ge\u00b7fun\u00b7den", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ITJ", "$,", "VAFIN", "PPER", "PRF", "VVPP", "$,"], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}, "line.4": {"text": "Kl\u00e4glich verdursten die Tage und Stunden.", "tokens": ["Kl\u00e4g\u00b7lich", "ver\u00b7durs\u00b7ten", "die", "Ta\u00b7ge", "und", "Stun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ART", "NN", "KON", "NN", "$."], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.5": {"text": "Ich sto\u00dfe mein Herz hinaus vor die T\u00fcre,", "tokens": ["Ich", "sto\u00b7\u00dfe", "mein", "Herz", "hin\u00b7aus", "vor", "die", "T\u00fc\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "APZR", "APPR", "ART", "NN", "$,"], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Da\u00df ich es nicht als Leichnam sp\u00fcre.", "tokens": ["Da\u00df", "ich", "es", "nicht", "als", "Leich\u00b7nam", "sp\u00fc\u00b7re", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "PTKNEG", "KOUS", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}