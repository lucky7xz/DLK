{"dta.poem.10110": {"metadata": {"author": {"name": "Brockes, Barthold Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "N\u00fctzliche Betrachtung einer pr\u00e4chtigen  \n Nichtigkeit.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1735", "urn": "urn:nbn:de:kobv:b4-20086-0", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Ich sahe j\u00fcngst, nicht sonder Freude,", "tokens": ["Ich", "sa\u00b7he", "j\u00fcngst", ",", "nicht", "son\u00b7der", "Freu\u00b7de", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "PTKNEG", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ein zier- und k\u00fcnstliches Geb\u00e4ude,", "tokens": ["Ein", "zier", "und", "k\u00fcnst\u00b7li\u00b7ches", "Ge\u00b7b\u00e4u\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "TRUNC", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Erhaben in der Lufft an einem Orte stehn,", "tokens": ["Er\u00b7ha\u00b7ben", "in", "der", "Lufft", "an", "ei\u00b7nem", "Or\u00b7te", "stehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wo ich vor kurtzer Zeit noch nichts gesehn.", "tokens": ["Wo", "ich", "vor", "kurt\u00b7zer", "Zeit", "noch", "nichts", "ge\u00b7sehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "APPR", "ADJA", "NN", "ADV", "PIS", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Die Regel-recht verfertigte Figur", "tokens": ["Die", "Re\u00b7gel\u00b7recht", "ver\u00b7fer\u00b7tig\u00b7te", "Fi\u00b7gur"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "War gantz vollkommen rund:", "tokens": ["War", "gantz", "voll\u00b7kom\u00b7men", "rund", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADJD", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Die Balcken, W\u00e4nd\u2019 und alles war nicht nur", "tokens": ["Die", "Bal\u00b7cken", ",", "W\u00e4nd'", "und", "al\u00b7les", "war", "nicht", "nur"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "NN", "KON", "PIS", "VAFIN", "PTKNEG", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Poliret, glatt, voll Glantz und herrlich bunt;", "tokens": ["Po\u00b7li\u00b7ret", ",", "glatt", ",", "voll", "Glantz", "und", "herr\u00b7lich", "bunt", ";"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ADJD", "$,", "ADJD", "NN", "KON", "ADJD", "ADJD", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.5": {"text": "Sie waren, wenn zumahl die Sonne sie bestrahlet,", "tokens": ["Sie", "wa\u00b7ren", ",", "wenn", "zu\u00b7mahl", "die", "Son\u00b7ne", "sie", "be\u00b7strah\u00b7let", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "KOUS", "ADV", "ART", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Mit solchen Farben \u00fcbermahlet,", "tokens": ["Mit", "sol\u00b7chen", "Far\u00b7ben", "\u00fc\u00b7ber\u00b7mah\u00b7let", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Die mehr als c\u00f6rperlich. Der Jris buntes Kleid", "tokens": ["Die", "mehr", "als", "c\u00f6r\u00b7per\u00b7lich", ".", "Der", "Jris", "bun\u00b7tes", "Kleid"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "PIAT", "KOKOM", "ADJD", "$.", "ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.8": {"text": "Verlohr bey dieser Pracht den Prei\u00df. An diesen Schein", "tokens": ["Ver\u00b7lohr", "bey", "die\u00b7ser", "Pracht", "den", "Prei\u00df", ".", "An", "die\u00b7sen", "Schein"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "APPR", "PDAT", "NN", "ART", "NN", "$.", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Kann nicht nur kein Opal, mit seiner Lieblichkeit", "tokens": ["Kann", "nicht", "nur", "kein", "O\u00b7pal", ",", "mit", "sei\u00b7ner", "Lieb\u00b7lich\u00b7keit"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VMFIN", "PTKNEG", "ADV", "PIAT", "NN", "$,", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Der spielenden gemischten Farben, reichen;", "tokens": ["Der", "spie\u00b7len\u00b7den", "ge\u00b7mischten", "Far\u00b7ben", ",", "rei\u00b7chen", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "$,", "VVFIN", "$."], "meter": "-+-+-++-+-", "measure": "unknown.measure.penta"}, "line.11": {"text": "Es mu\u00df so gar ein Demant-Stein", "tokens": ["Es", "mu\u00df", "so", "gar", "ein", "De\u00b7mant\u00b7Stein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ADV", "ADV", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Der Farben feurigem und bunten Wechsel weichen.", "tokens": ["Der", "Far\u00b7ben", "feu\u00b7ri\u00b7gem", "und", "bun\u00b7ten", "Wech\u00b7sel", "wei\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "KON", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Ich sage nicht zu viel,", "tokens": ["Ich", "sa\u00b7ge", "nicht", "zu", "viel", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "PTKA", "PIS", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.14": {"text": "Und kann ich diese Pracht und dieses Farben-Spiel", "tokens": ["Und", "kann", "ich", "die\u00b7se", "Pracht", "und", "die\u00b7ses", "Fa\u00b7rben\u00b7Spiel"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VMFIN", "PPER", "PDAT", "NN", "KON", "PDAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Geliebter Leser, dir gar deutlich zeigen.", "tokens": ["Ge\u00b7lieb\u00b7ter", "Le\u00b7ser", ",", "dir", "gar", "deut\u00b7lich", "zei\u00b7gen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "PPER", "ADV", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Was aber meinest du, wer der Bewohner wol", "tokens": ["Was", "a\u00b7ber", "mei\u00b7nest", "du", ",", "wer", "der", "Be\u00b7woh\u00b7ner", "wol"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWS", "ADV", "VVFIN", "PPER", "$,", "PWS", "ART", "NN", "ADV"], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Von diesem Pallast sey; wem dieses Lufft-Schlo\u00df eigen,", "tokens": ["Von", "die\u00b7sem", "Pal\u00b7last", "sey", ";", "wem", "die\u00b7ses", "Lufft\u00b7Schlo\u00df", "ei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "VAFIN", "$.", "PWS", "PDAT", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und wer es wol erbaut? Ein M\u00f6rder, ein Tyrann,", "tokens": ["Und", "wer", "es", "wol", "er\u00b7baut", "?", "Ein", "M\u00f6r\u00b7der", ",", "ein", "Ty\u00b7rann", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "ADV", "VVPP", "$.", "ART", "NN", "$,", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ein R\u00e4uber, welcher nichts als alles w\u00fcrgen kann,", "tokens": ["Ein", "R\u00e4u\u00b7ber", ",", "wel\u00b7cher", "nichts", "als", "al\u00b7les", "w\u00fcr\u00b7gen", "kann", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PIS", "KOKOM", "PIS", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Was ihm zu nahe kommt; der unvers\u00f6hnlich ist,", "tokens": ["Was", "ihm", "zu", "na\u00b7he", "kommt", ";", "der", "un\u00b7ver\u00b7s\u00f6hn\u00b7lich", "ist", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "PTKA", "ADJD", "VVFIN", "$.", "ART", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und der, Lycaon gleich, die G\u00e4ste w\u00fcrgt und frisst.", "tokens": ["Und", "der", ",", "Ly\u00b7ca\u00b7on", "gleich", ",", "die", "G\u00e4s\u00b7te", "w\u00fcrgt", "und", "frisst", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "$,", "NE", "ADV", "$,", "ART", "NN", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Kurtz: Wilt du ihn und seinen Pallast kennen,", "tokens": ["Kurtz", ":", "Wilt", "du", "ihn", "und", "sei\u00b7nen", "Pal\u00b7last", "ken\u00b7nen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$.", "VMFIN", "PPER", "PPER", "KON", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "So darfst du nur den Blick der regen Spinne g\u00f6nnen,", "tokens": ["So", "darfst", "du", "nur", "den", "Blick", "der", "re\u00b7gen", "Spin\u00b7ne", "g\u00f6n\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "ART", "NN", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Und ihr Gewebe sehn. Sprich nicht: ich t\u00e4usche dich,", "tokens": ["Und", "ihr", "Ge\u00b7we\u00b7be", "sehn", ".", "Sprich", "nicht", ":", "ich", "t\u00e4u\u00b7sche", "dich", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVINF", "$.", "VVIMP", "PTKNEG", "$.", "PPER", "VVFIN", "PPER", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Und mach\u2019 aus M\u00fccken Elephanten,", "tokens": ["Und", "mach'", "aus", "M\u00fc\u00b7cken", "E\u00b7le\u00b7phan\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "NN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Aus Spinneweben Diamanten.", "tokens": ["Aus", "Spin\u00b7ne\u00b7we\u00b7ben", "Di\u00b7a\u00b7man\u00b7ten", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Nein, h\u00f6re mich erst aus: dann tadle mich.", "tokens": ["Nein", ",", "h\u00f6\u00b7re", "mich", "erst", "aus", ":", "dann", "tad\u00b7le", "mich", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "VVFIN", "PPER", "ADV", "PTKVZ", "$.", "ADV", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Es zeigt uns die Natur von allen Wundern schier", "tokens": ["Es", "zeigt", "uns", "die", "Na\u00b7tur", "von", "al\u00b7len", "Wun\u00b7dern", "schier"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "ART", "NN", "APPR", "PIAT", "NN", "ADJD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Nichts, das so Wunder-reich,", "tokens": ["Nichts", ",", "das", "so", "Wun\u00b7der\u00b7reich", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["PIS", "$,", "PRELS", "ADV", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Als die\u00df verworffne Thier.", "tokens": ["Als", "die\u00df", "ver\u00b7worff\u00b7ne", "Thier", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDS", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Ist dieser K\u00fcnstlerin wol ie ein K\u00fcnstler gleich?", "tokens": ["Ist", "die\u00b7ser", "K\u00fcnst\u00b7le\u00b7rin", "wol", "ie", "ein", "K\u00fcnst\u00b7ler", "gleich", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PDAT", "NN", "ADV", "ADV", "ART", "NN", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Der F\u00e4den, die so d\u00fcnn und zart,", "tokens": ["Der", "F\u00e4\u00b7den", ",", "die", "so", "d\u00fcnn", "und", "zart", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ADV", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und doch so z\u00e4h\u2019 und starck, auf so geschickte Art,", "tokens": ["Und", "doch", "so", "z\u00e4h'", "und", "starck", ",", "auf", "so", "ge\u00b7schick\u00b7te", "Art", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "ADJD", "KON", "ADJD", "$,", "APPR", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Ohn\u2019 Hand und Finger, spinnen kann?", "tokens": ["Ohn'", "Hand", "und", "Fin\u00b7ger", ",", "spin\u00b7nen", "kann", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$,", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Wer gab sich ie zu ihrem Meister an?", "tokens": ["Wer", "gab", "sich", "ie", "zu", "ih\u00b7rem", "Meis\u00b7ter", "an", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PRF", "ADV", "APPR", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Wer zeiget ihr der Symmetrie Gesetze,", "tokens": ["Wer", "zei\u00b7get", "ihr", "der", "Sym\u00b7me\u00b7trie", "Ge\u00b7set\u00b7ze", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Nach welchen sie ihr n\u00fctz- und zierlich Netze", "tokens": ["Nach", "wel\u00b7chen", "sie", "ihr", "n\u00fctz", "und", "zier\u00b7lich", "Net\u00b7ze"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PWAT", "PPER", "PPOSAT", "TRUNC", "KON", "ADJD", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "Zu ihrer Wohn- und Nahrung webt?", "tokens": ["Zu", "ih\u00b7rer", "Wohn", "und", "Nah\u00b7rung", "webt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "TRUNC", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Wie wunderbar ist, da\u00df ein solcher Faden", "tokens": ["Wie", "wun\u00b7der\u00b7bar", "ist", ",", "da\u00df", "ein", "sol\u00b7cher", "Fa\u00b7den"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWAV", "ADJD", "VAFIN", "$,", "KOUS", "ART", "PIAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "So starck, da\u00df er sich l\u00e4sst mit ihrer Last beladen!", "tokens": ["So", "starck", ",", "da\u00df", "er", "sich", "l\u00e4sst", "mit", "ih\u00b7rer", "Last", "be\u00b7la\u00b7den", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "KOUS", "PPER", "PRF", "VVFIN", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wie wunderbar, da\u00df er an alles klebt,", "tokens": ["Wie", "wun\u00b7der\u00b7bar", ",", "da\u00df", "er", "an", "al\u00b7les", "klebt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "$,", "KOUS", "PPER", "APPR", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Was er nur einst ber\u00fchrt, und zwar so fest,", "tokens": ["Was", "er", "nur", "einst", "be\u00b7r\u00fchrt", ",", "und", "zwar", "so", "fest", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "ADV", "VVPP", "$,", "KON", "ADV", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Da\u00df er sich gleich zur Br\u00fccke brauchen l\u00e4sst,", "tokens": ["Da\u00df", "er", "sich", "gleich", "zur", "Br\u00fc\u00b7cke", "brau\u00b7chen", "l\u00e4sst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ADV", "APPRART", "NN", "VVFIN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Wor\u00fcber alsobald von einer Seit\u2019 zur andern", "tokens": ["Wo\u00b7r\u00fc\u00b7ber", "al\u00b7so\u00b7bald", "von", "ei\u00b7ner", "Seit'", "zur", "an\u00b7dern"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PAV", "ADV", "APPR", "ART", "NN", "APPRART", "ADJA"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Die Spinnerin vermag zu wandern!", "tokens": ["Die", "Spin\u00b7ne\u00b7rin", "ver\u00b7mag", "zu", "wan\u00b7dern", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Wer lehrte sie, wann sie die Wand", "tokens": ["Wer", "lehr\u00b7te", "sie", ",", "wann", "sie", "die", "Wand"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "PPER", "$,", "PWAV", "PPER", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "An des Gewebes langen St\u00fctzen,", "tokens": ["An", "des", "Ge\u00b7we\u00b7bes", "lan\u00b7gen", "St\u00fct\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Die blo\u00df durch ihre Kunst in solcher Ordnung sitzen,", "tokens": ["Die", "blo\u00df", "durch", "ih\u00b7re", "Kunst", "in", "sol\u00b7cher", "Ord\u00b7nung", "sit\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "PPOSAT", "NN", "APPR", "PIAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "In einer netten R\u00fcndung spannt;", "tokens": ["In", "ei\u00b7ner", "net\u00b7ten", "R\u00fcn\u00b7dung", "spannt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Da\u00df, ehe sie den Faden feste macht,", "tokens": ["Da\u00df", ",", "e\u00b7he", "sie", "den", "Fa\u00b7den", "fes\u00b7te", "macht", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$,", "KOUS", "PPER", "ART", "NN", "ADJA", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Sie ihn, mit grossem Vorbedacht,", "tokens": ["Sie", "ihn", ",", "mit", "gros\u00b7sem", "Vor\u00b7be\u00b7dacht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "PPER", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Mit einem Fu\u00df vorher verl\u00e4ngt,", "tokens": ["Mit", "ei\u00b7nem", "Fu\u00df", "vor\u00b7her", "ver\u00b7l\u00e4ngt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Damit, wann Wind und Luft die Wohnung dr\u00e4ngt\u2019,", "tokens": ["Da\u00b7mit", ",", "wann", "Wind", "und", "Luft", "die", "Woh\u00b7nung", "dr\u00e4ngt'", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "$,", "PWAV", "NN", "KON", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Und etwan gar zu hefftig z\u00f6ge,", "tokens": ["Und", "et\u00b7wan", "gar", "zu", "heff\u00b7tig", "z\u00f6\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "PTKA", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Dieselbe nicht zerreissen m\u00f6ge.", "tokens": ["Die\u00b7sel\u00b7be", "nicht", "zer\u00b7reis\u00b7sen", "m\u00f6\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDAT", "PTKNEG", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Wer wies\u2019 ihr, da\u00df, wenn wo von ungefehr", "tokens": ["Wer", "wies'", "ihr", ",", "da\u00df", ",", "wenn", "wo", "von", "un\u00b7ge\u00b7fehr"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "PPER", "$,", "KOUS", "$,", "KOUS", "PWAV", "APPR", "ADJD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Ein Bl\u00e4ttchen, oder sonst was, in ihr Netze f\u00e4llt,", "tokens": ["Ein", "Bl\u00e4tt\u00b7chen", ",", "o\u00b7der", "sonst", "was", ",", "in", "ihr", "Net\u00b7ze", "f\u00e4llt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "KON", "ADV", "PIS", "$,", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Sie ieden Faden, der es h\u00e4lt,", "tokens": ["Sie", "ie\u00b7den", "Fa\u00b7den", ",", "der", "es", "h\u00e4lt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "PIAT", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Nicht nur zerbeisst, nein, mit dem Fu\u00df,", "tokens": ["Nicht", "nur", "zer\u00b7beisst", ",", "nein", ",", "mit", "dem", "Fu\u00df", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "VVFIN", "$,", "PTKANT", "$,", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Da\u00df es hinausw\u00e4rts fallen mu\u00df,", "tokens": ["Da\u00df", "es", "hin\u00b7aus\u00b7w\u00e4rts", "fal\u00b7len", "mu\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und es das Netz im Fallen nicht versehre,", "tokens": ["Und", "es", "das", "Netz", "im", "Fal\u00b7len", "nicht", "ver\u00b7seh\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ART", "NN", "APPRART", "NN", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Hinausw\u00e4rts st\u00f6\u00dft: wie ich, da\u00df solches offt geschehn,", "tokens": ["Hin\u00b7aus\u00b7w\u00e4rts", "st\u00f6\u00dft", ":", "wie", "ich", ",", "da\u00df", "sol\u00b7ches", "offt", "ge\u00b7schehn", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$.", "PWAV", "PPER", "$,", "KOUS", "PIS", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Offt mit verwunderndem Erstaunen angesehn,", "tokens": ["Offt", "mit", "ver\u00b7wun\u00b7dern\u00b7dem", "Er\u00b7stau\u00b7nen", "an\u00b7ge\u00b7sehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Und wie es iederman,", "tokens": ["Und", "wie", "es", "ie\u00b7der\u00b7man", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPER", "PIS", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.10": {"text": "Durch Einwurff eines Blats, gar leicht probiren kann.", "tokens": ["Durch", "Ein\u00b7wurff", "ei\u00b7nes", "Blats", ",", "gar", "leicht", "pro\u00b7bi\u00b7ren", "kann", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ART", "NN", "$,", "ADV", "ADJD", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "Von ihrer Schlauigkeit, die Fliegen und die M\u00fccken,", "tokens": ["Von", "ih\u00b7rer", "Schlau\u00b7ig\u00b7keit", ",", "die", "Flie\u00b7gen", "und", "die", "M\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "ART", "NN", "KON", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Zu ihrer Nahrung zu ber\u00fccken;", "tokens": ["Zu", "ih\u00b7rer", "Nah\u00b7rung", "zu", "be\u00b7r\u00fc\u00b7cken", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Auch wie sie die Natur schon in der Jugend lehrt,", "tokens": ["Auch", "wie", "sie", "die", "Na\u00b7tur", "schon", "in", "der", "Ju\u00b7gend", "lehrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "PPER", "ART", "NN", "ADV", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Da\u00df, weil die kleine Brut in solcher Menge,", "tokens": ["Da\u00df", ",", "weil", "die", "klei\u00b7ne", "Brut", "in", "sol\u00b7cher", "Men\u00b7ge", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$,", "KOUS", "ART", "ADJA", "NN", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Wie sie hervor kommt, sich an einem Ort nicht nehrt,", "tokens": ["Wie", "sie", "her\u00b7vor", "kommt", ",", "sich", "an", "ei\u00b7nem", "Ort", "nicht", "nehrt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PTKVZ", "VVFIN", "$,", "PRF", "APPR", "ART", "NN", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Sie F\u00e4den von gnugsamer L\u00e4nge,", "tokens": ["Sie", "F\u00e4\u00b7den", "von", "gnug\u00b7sa\u00b7mer", "L\u00e4n\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Da\u00df es sie tragen kann,", "tokens": ["Da\u00df", "es", "sie", "tra\u00b7gen", "kann", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "Bey stillem Wetter von sich lassen;", "tokens": ["Bey", "stil\u00b7lem", "Wet\u00b7ter", "von", "sich", "las\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "APPR", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Die iede dann,", "tokens": ["Die", "ie\u00b7de", "dann", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "PIAT", "ADV", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.10": {"text": "Wohin ein Ungefehr sie bringet,", "tokens": ["Wo\u00b7hin", "ein", "Un\u00b7ge\u00b7fehr", "sie", "brin\u00b7get", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Sich durch die Lufft zur neuen Heymat schwinget:", "tokens": ["Sich", "durch", "die", "Lufft", "zur", "neu\u00b7en", "Hey\u00b7mat", "schwin\u00b7get", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "ART", "NN", "APPRART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Woselbst sie denn so gleich sich h\u00e4u\u00dflich niederl\u00e4sst;", "tokens": ["Wo\u00b7selbst", "sie", "denn", "so", "gleich", "sich", "h\u00e4u\u00df\u00b7lich", "nie\u00b7der\u00b7l\u00e4sst", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "ADV", "ADV", "PRF", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Auch wie im Fall sie gleich an ihrem Faden fest;", "tokens": ["Auch", "wie", "im", "Fall", "sie", "gleich", "an", "ih\u00b7rem", "Fa\u00b7den", "fest", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "APPRART", "NN", "PPER", "ADV", "APPR", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Und da\u00df recht eigentlich die Spinnen blo\u00df allein", "tokens": ["Und", "da\u00df", "recht", "ei\u00b7gent\u00b7lich", "die", "Spin\u00b7nen", "blo\u00df", "al\u00b7lein"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "ADV", "ADV", "ART", "NN", "ADV", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Der Lufft Bewohnerinnen seyn;", "tokens": ["Der", "Lufft", "Be\u00b7woh\u00b7ne\u00b7rin\u00b7nen", "seyn", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Von allem diesen will ich nichts gedencken,", "tokens": ["Von", "al\u00b7lem", "die\u00b7sen", "will", "ich", "nichts", "ge\u00b7den\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "PDAT", "VMFIN", "PPER", "PIS", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.17": {"text": "Und mich noch einst, indem sie gar zu sch\u00f6n,", "tokens": ["Und", "mich", "noch", "einst", ",", "in\u00b7dem", "sie", "gar", "zu", "sch\u00f6n", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ADV", "ADV", "$,", "KOUS", "PPER", "ADV", "PTKA", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.18": {"text": "Ob wir es gleich nicht immer deutlich sehn,", "tokens": ["Ob", "wir", "es", "gleich", "nicht", "im\u00b7mer", "deut\u00b7lich", "sehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "ADV", "PTKNEG", "ADV", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.19": {"text": "Zur Sch\u00f6nheit ihrer Wohnung lencken.", "tokens": ["Zur", "Sch\u00f6n\u00b7heit", "ih\u00b7rer", "Woh\u00b7nung", "len\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Wenn man ihr glatt Geweb in hellen Sonnen-Strahlen", "tokens": ["Wenn", "man", "ihr", "glatt", "Ge\u00b7web", "in", "hel\u00b7len", "Son\u00b7nen\u00b7Strah\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "PPER", "ADJD", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Recht mit Aufmercksamkeit erwegt,", "tokens": ["Recht", "mit", "Auf\u00b7merck\u00b7sam\u00b7keit", "er\u00b7wegt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und, wie mit buntem Schein sich alle F\u00e4den mahlen,", "tokens": ["Und", ",", "wie", "mit", "bun\u00b7tem", "Schein", "sich", "al\u00b7le", "F\u00e4\u00b7den", "mah\u00b7len", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "PWAV", "APPR", "ADJA", "NN", "PRF", "PIAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der sonderlich, wenn sich die Lufft ein wenig regt,", "tokens": ["Der", "son\u00b7der\u00b7lich", ",", "wenn", "sich", "die", "Lufft", "ein", "we\u00b7nig", "regt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "$,", "KOUS", "PRF", "ART", "NN", "ART", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Mit kleinen Blitzen spielt, und bald in gelben, gr\u00fcnen,", "tokens": ["Mit", "klei\u00b7nen", "Blit\u00b7zen", "spielt", ",", "und", "bald", "in", "gel\u00b7ben", ",", "gr\u00fc\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "$,", "KON", "ADV", "APPR", "ADJA", "$,", "ADJA", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Bald einem rothen Feur, gleich funckelnden Rubinen,", "tokens": ["Bald", "ei\u00b7nem", "ro\u00b7then", "Feur", ",", "gleich", "fun\u00b7ckeln\u00b7den", "Ru\u00b7bi\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "$,", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Gl\u00e4ntzt, schimmert, wallt und glimmt, bewundernd \u00fcberlegt;", "tokens": ["Gl\u00e4ntzt", ",", "schim\u00b7mert", ",", "wallt", "und", "glimmt", ",", "be\u00b7wun\u00b7dernd", "\u00fc\u00b7ber\u00b7legt", ";"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "$,", "VVFIN", "$,", "VVFIN", "KON", "VVFIN", "$,", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "F\u00e4llt die Betrachtung uns wol nicht mit Unrecht ein:", "tokens": ["F\u00e4llt", "die", "Be\u00b7trach\u00b7tung", "uns", "wol", "nicht", "mit", "Un\u00b7recht", "ein", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "PPER", "ADV", "PTKNEG", "APPR", "NN", "PTKVZ", "$."], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.9": {"text": "Wie angenehm mu\u00df nicht in dem so bunten Schein,", "tokens": ["Wie", "an\u00b7ge\u00b7nehm", "mu\u00df", "nicht", "in", "dem", "so", "bun\u00b7ten", "Schein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VMFIN", "PTKNEG", "APPR", "ART", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Den Spinnen ihre Wohnung seyn!", "tokens": ["Den", "Spin\u00b7nen", "ih\u00b7re", "Woh\u00b7nung", "seyn", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Wo ist ein F\u00fcrstlicher Pallast,", "tokens": ["Wo", "ist", "ein", "F\u00fcrst\u00b7li\u00b7cher", "Pal\u00b7last", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.12": {"text": "Der solchen Demant-Schein in seinen W\u00e4nden fasst?", "tokens": ["Der", "sol\u00b7chen", "De\u00b7mant\u00b7Schein", "in", "sei\u00b7nen", "W\u00e4n\u00b7den", "fasst", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Zumahl wenn man bedenckt, da\u00df in der That,", "tokens": ["Zu\u00b7mahl", "wenn", "man", "be\u00b7denckt", ",", "da\u00df", "in", "der", "That", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PIS", "VVFIN", "$,", "KOUS", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "Stat zweyer, eine Spinn\u2019 acht Augen hat,", "tokens": ["Stat", "zwey\u00b7er", ",", "ei\u00b7ne", "Spinn'", "acht", "Au\u00b7gen", "hat", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "$,", "ART", "NN", "CARD", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.15": {"text": "Womit sie ja, an ihren bunten Sch\u00e4tzen,", "tokens": ["Wo\u00b7mit", "sie", "ja", ",", "an", "ih\u00b7ren", "bun\u00b7ten", "Sch\u00e4t\u00b7zen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "$,", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.16": {"text": "Noch drey mahl mehr als wir sich kann ergetzen.", "tokens": ["Noch", "drey", "mahl", "mehr", "als", "wir", "sich", "kann", "er\u00b7get\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "CARD", "ADV", "ADV", "KOUS", "PPER", "PRF", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.10": {"line.1": {"text": "Ja selber in des Mondes Licht", "tokens": ["Ja", "sel\u00b7ber", "in", "des", "Mon\u00b7des", "Licht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "ADV", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Fehlt ihr dergleichen Glantz und Schimmer nicht,", "tokens": ["Fehlt", "ihr", "derg\u00b7lei\u00b7chen", "Glantz", "und", "Schim\u00b7mer", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PIS", "NN", "KON", "NN", "PTKNEG", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Und ist ihr Haus sodann nicht minder sch\u00f6n,", "tokens": ["Und", "ist", "ihr", "Haus", "so\u00b7dann", "nicht", "min\u00b7der", "sch\u00f6n", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPOSAT", "NN", "ADV", "PTKNEG", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Wie ich sie einst des Nachts, durchs Fenster wircken sehn.", "tokens": ["Wie", "ich", "sie", "einst", "des", "Nachts", ",", "durchs", "Fens\u00b7ter", "wir\u00b7cken", "sehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PPER", "ADV", "ART", "ADV", "$,", "APPRART", "NN", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "So hell schien ihr Gespinnst, so schimmernd und so rein,", "tokens": ["So", "hell", "schien", "ihr", "Ge\u00b7spinnst", ",", "so", "schim\u00b7mernd", "und", "so", "rein", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "PPOSAT", "NN", "$,", "ADV", "ADJD", "KON", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Als w\u00e4r ein ieder Draht ein Theil vom Monden-Schein.", "tokens": ["Als", "w\u00e4r", "ein", "ie\u00b7der", "Draht", "ein", "Theil", "vom", "Mon\u00b7den\u00b7Schein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VAFIN", "ART", "PIAT", "NN", "ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Sie wei\u00df in ihrem Schlo\u00df von keinem Schatten nicht:", "tokens": ["Sie", "wei\u00df", "in", "ih\u00b7rem", "Schlo\u00df", "von", "kei\u00b7nem", "Schat\u00b7ten", "nicht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN", "APPR", "PIAT", "NN", "PTKNEG", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Jhr gantz Geb\u00e4ude steht des Nachts im Silber-Licht;", "tokens": ["Ihr", "gantz", "Ge\u00b7b\u00e4u\u00b7de", "steht", "des", "Nachts", "im", "Sil\u00b7ber\u00b7Licht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "NN", "VVFIN", "ART", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Des Tages kann kein sch\u00fctternder Brillant,", "tokens": ["Des", "Ta\u00b7ges", "kann", "kein", "sch\u00fct\u00b7tern\u00b7der", "Bril\u00b7lant", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "An einer stoltzen Hand,", "tokens": ["An", "ei\u00b7ner", "stolt\u00b7zen", "Hand", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.11": {"text": "Mit mehr Ver\u00e4nderung von Feur und Farben schimmern,", "tokens": ["Mit", "mehr", "Ver\u00b7\u00e4n\u00b7de\u00b7rung", "von", "Feur", "und", "Far\u00b7ben", "schim\u00b7mern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "APPR", "NN", "KON", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Als wir, in ihren hellen Zimmern,", "tokens": ["Als", "wir", ",", "in", "ih\u00b7ren", "hel\u00b7len", "Zim\u00b7mern", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Ein buntes Feur best\u00e4ndig, Wunder-sch\u00f6n", "tokens": ["Ein", "bun\u00b7tes", "Feur", "be\u00b7st\u00e4n\u00b7dig", ",", "Wun\u00b7der\u00b7sch\u00f6n"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["ART", "ADJA", "NN", "ADJD", "$,", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "Sich \u00e4ndern, blitzen, gl\u00fchn, vergehn,", "tokens": ["Sich", "\u00e4n\u00b7dern", ",", "blit\u00b7zen", ",", "gl\u00fchn", ",", "ver\u00b7gehn", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PRF", "VVINF", "$,", "VVFIN", "$,", "VVFIN", "$,", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Und wieder\u00fcm entstehen sehn.", "tokens": ["Und", "wie\u00b7de\u00b7r\u00fcm", "ent\u00b7ste\u00b7hen", "sehn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Mir fiel, bey des Gespinnstes Schein,", "tokens": ["Mir", "fiel", ",", "bey", "des", "Ge\u00b7spinns\u00b7tes", "Schein", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Indem ich seine Pracht erwegte,", "tokens": ["In\u00b7dem", "ich", "sei\u00b7ne", "Pracht", "er\u00b7weg\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und auch zugleich dabey sein Wesen \u00fcberlegte,", "tokens": ["Und", "auch", "zu\u00b7gleich", "da\u00b7bey", "sein", "We\u00b7sen", "\u00fc\u00b7ber\u00b7leg\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "PAV", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Nachfolgende Betrachtung ein:", "tokens": ["Nach\u00b7fol\u00b7gen\u00b7de", "Be\u00b7trach\u00b7tung", "ein", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "PTKVZ", "$."], "meter": "-+---+-+", "measure": "dactylic.init"}}, "stanza.12": {"line.1": {"text": "Von Eitelkeit und Stoltz kann auf der Erden", "tokens": ["Von", "Ei\u00b7tel\u00b7keit", "und", "Stoltz", "kann", "auf", "der", "Er\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN", "VMFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Kein besser Sinn-Bild ie gefunden werden,", "tokens": ["Kein", "bes\u00b7ser", "Sinn\u00b7Bild", "ie", "ge\u00b7fun\u00b7den", "wer\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "ADV", "VVPP", "VAINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Als wie der bunte Glantz, der Spinneweben schm\u00fcckt.", "tokens": ["Als", "wie", "der", "bun\u00b7te", "Glantz", ",", "der", "Spin\u00b7ne\u00b7we\u00b7ben", "schm\u00fcckt", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "KOKOM", "ART", "ADJA", "NN", "$,", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die Nichtigkeit, die Daur, und Unbest\u00e4ndigkeit,", "tokens": ["Die", "Nich\u00b7tig\u00b7keit", ",", "die", "Daur", ",", "und", "Un\u00b7be\u00b7st\u00e4n\u00b7dig\u00b7keit", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "$,", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wird durch die\u00df Vorbild recht uat\u00fcrlich ausgedr\u00fcckt.", "tokens": ["Wird", "durch", "die\u00df", "Vor\u00b7bild", "recht", "u\u00b7a\u00b7t\u00fcr\u00b7lich", "aus\u00b7ge\u00b7dr\u00fcckt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "PDS", "NN", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.13": {"line.1": {"text": "Mit Diamanten br\u00fcstet sich", "tokens": ["Mit", "Di\u00b7a\u00b7man\u00b7ten", "br\u00fcs\u00b7tet", "sich"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NN", "VVFIN", "PRF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein stoltzer Narr mit Unrecht nur;", "tokens": ["Ein", "stolt\u00b7zer", "Narr", "mit", "Un\u00b7recht", "nur", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da ja die spielende Natur", "tokens": ["Da", "ja", "die", "spie\u00b7len\u00b7de", "Na\u00b7tur"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "ART", "ADJA", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Denselben Schein und Glantz, den eigentlich", "tokens": ["Den\u00b7sel\u00b7ben", "Schein", "und", "Glantz", ",", "den", "ei\u00b7gent\u00b7lich"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["PDAT", "NN", "KON", "NN", "$,", "PRELS", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Ein k\u00f6stlicher gesch\u00e4tzter Demant heget,", "tokens": ["Ein", "k\u00f6st\u00b7li\u00b7cher", "ge\u00b7sch\u00e4tz\u00b7ter", "De\u00b7mant", "he\u00b7get", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Auch Spinneweben eingepr\u00e4get,", "tokens": ["Auch", "Spin\u00b7ne\u00b7we\u00b7ben", "ein\u00b7ge\u00b7pr\u00e4\u00b7get", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Zum Zeichen, da\u00df sie beide Tand.", "tokens": ["Zum", "Zei\u00b7chen", ",", "da\u00df", "sie", "bei\u00b7de", "Tand", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "KOUS", "PPER", "PIAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "So wie die Fliegen nun der bunte Draht verstrickt,", "tokens": ["So", "wie", "die", "Flie\u00b7gen", "nun", "der", "bun\u00b7te", "Draht", "ver\u00b7strickt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "ART", "NN", "ADV", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "So wird, durch bunten Glantz von Gold und Diamant,", "tokens": ["So", "wird", ",", "durch", "bun\u00b7ten", "Glantz", "von", "Gold", "und", "Di\u00b7a\u00b7mant", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "$,", "APPR", "ADJA", "NN", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die Menschheit, leider! auch ber\u00fcckt,", "tokens": ["Die", "Menschheit", ",", "lei\u00b7der", "!", "auch", "be\u00b7r\u00fcckt", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADV", "$.", "ADV", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und in das Ungl\u00fccks-Garn getrieben.", "tokens": ["Und", "in", "das", "Un\u00b7gl\u00fccks\u00b7Garn", "ge\u00b7trie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "Kaum hatt\u2019 ich die\u00df Gedicht geschrieben,", "tokens": ["Kaum", "hatt'", "ich", "die\u00df", "Ge\u00b7dicht", "ge\u00b7schrie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PDS", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Da fing ich an, von einem Ort zum andern", "tokens": ["Da", "fing", "ich", "an", ",", "von", "ei\u00b7nem", "Ort", "zum", "an\u00b7dern"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PTKVZ", "$,", "APPR", "ART", "NN", "APPRART", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "In der Allee bald auf-bald ab zu wandern.", "tokens": ["In", "der", "Al\u00b7lee", "bald", "auf\u00b7bald", "ab", "zu", "wan\u00b7dern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADV", "ADJD", "PTKVZ", "PTKZU", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Der Seiger gieng auf vier; die Sonne senckte sich.", "tokens": ["Der", "Sei\u00b7ger", "gieng", "auf", "vier", ";", "die", "Son\u00b7ne", "senck\u00b7te", "sich", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "CARD", "$.", "ART", "NN", "VVFIN", "PRF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wie ich nun Westen-w\u00e4rts an einen Gang gelangte,", "tokens": ["Wie", "ich", "nun", "Wes\u00b7ten\u00b7w\u00e4rts", "an", "ei\u00b7nen", "Gang", "ge\u00b7lang\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "NN", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Der auch durch B\u00e4ume gieng; entsetzt\u2019 ich mich", "tokens": ["Der", "auch", "durch", "B\u00e4u\u00b7me", "gieng", ";", "ent\u00b7setzt'", "ich", "mich"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADV", "APPR", "NN", "VVFIN", "$.", "VVFIN", "PPER", "PRF"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "F\u00fcr eine bunte Gluht, die in derselben prangte.", "tokens": ["F\u00fcr", "ei\u00b7ne", "bun\u00b7te", "Gluht", ",", "die", "in", "der\u00b7sel\u00b7ben", "prang\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,", "PRELS", "APPR", "PDAT", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.16": {"line.1": {"text": "Viel tausend zarte Regen-Bogen", "tokens": ["Viel", "tau\u00b7send", "zar\u00b7te", "Re\u00b7gen\u00b7Bo\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ADJD", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sah\u2019 ich von Baum zu Baum, fast ohne Zahl, gezogen.", "tokens": ["Sah'", "ich", "von", "Baum", "zu", "Baum", ",", "fast", "oh\u00b7ne", "Zahl", ",", "ge\u00b7zo\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "NE", "APPR", "NE", "$,", "ADV", "APPR", "NN", "$,", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Sie schienen aus Chrystall gedreht, aus Gold gesponnen;", "tokens": ["Sie", "schie\u00b7nen", "aus", "Chrys\u00b7tall", "ge\u00b7dreht", ",", "aus", "Gold", "ge\u00b7spon\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NE", "VVFIN", "$,", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Beweglich waren sie; sie wallten auf und ab:", "tokens": ["Be\u00b7weg\u00b7lich", "wa\u00b7ren", "sie", ";", "sie", "wall\u00b7ten", "auf", "und", "ab", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "PPER", "$.", "PPER", "VVFIN", "PTKVZ", "KON", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Das denn im hellen Strahl der Sonnen", "tokens": ["Das", "denn", "im", "hel\u00b7len", "Strahl", "der", "Son\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "ADV", "APPRART", "ADJA", "NN", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Ein Wunder-schones Schau-Spiel gab.", "tokens": ["Ein", "Wun\u00b7der\u00b7scho\u00b7nes", "Schau\u00b7Spiel", "gab", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Ein Schau-Platz aus geschliffenen Crystallen", "tokens": ["Ein", "Schau\u00b7Platz", "aus", "ge\u00b7schlif\u00b7fe\u00b7nen", "Crys\u00b7tal\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+---+-", "measure": "unknown.measure.tetra"}, "line.8": {"text": "Kann sch\u00f6ner nicht in unser Auge fallen.", "tokens": ["Kann", "sch\u00f6\u00b7ner", "nicht", "in", "un\u00b7ser", "Au\u00b7ge", "fal\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADJD", "PTKNEG", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.17": {"line.1": {"text": "Ein dick Geb\u00fcsch, das gantz zu Ende stund,", "tokens": ["Ein", "dick", "Ge\u00b7b\u00fcsch", ",", "das", "gantz", "zu", "En\u00b7de", "stund", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "$,", "PRELS", "ADV", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "War ein beschatteter und dunckler Grund,", "tokens": ["War", "ein", "be\u00b7schat\u00b7te\u00b7ter", "und", "dunck\u00b7ler", "Grund", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "ADJA", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Worauf die bunte Pracht noch tausend mahl so sch\u00f6n,", "tokens": ["Wo\u00b7rauf", "die", "bun\u00b7te", "Pracht", "noch", "tau\u00b7send", "mahl", "so", "sch\u00f6n", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "ADJA", "NN", "ADV", "CARD", "ADV", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So hell, so Feuer-reich, so voller Glantz zu sehn.", "tokens": ["So", "hell", ",", "so", "Feu\u00b7er\u00b7reich", ",", "so", "vol\u00b7ler", "Glantz", "zu", "sehn", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "ADV", "ADJD", "$,", "ADV", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Es stellt so bunten Schein, so sch\u00f6n gef\u00e4rbte Zier,", "tokens": ["Es", "stellt", "so", "bun\u00b7ten", "Schein", ",", "so", "sch\u00f6n", "ge\u00b7f\u00e4rb\u00b7te", "Zier", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADJA", "NN", "$,", "ADV", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und wie so wunderbar, so herrlich sie geschm\u00fccket,", "tokens": ["Und", "wie", "so", "wun\u00b7der\u00b7bar", ",", "so", "herr\u00b7lich", "sie", "ge\u00b7schm\u00fc\u00b7cket", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ADV", "ADJD", "$,", "ADV", "ADJD", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Unm\u00f6glich sich ein menschlich Auge f\u00fcr,", "tokens": ["Un\u00b7m\u00f6g\u00b7lich", "sich", "ein", "menschlich", "Au\u00b7ge", "f\u00fcr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "PRF", "ART", "ADJD", "NN", "APPR", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Das diese Pracht nicht selbst erblicket.", "tokens": ["Das", "die\u00b7se", "Pracht", "nicht", "selbst", "er\u00b7bli\u00b7cket", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PDAT", "NN", "PTKNEG", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Bis es zuletzt mich auf den Sch\u00f6pfer zog,", "tokens": ["Bis", "es", "zu\u00b7letzt", "mich", "auf", "den", "Sch\u00f6p\u00b7fer", "zog", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PPER", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Und so zu dencken mich bewog:", "tokens": ["Und", "so", "zu", "den\u00b7cken", "mich", "be\u00b7wog", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PTKZU", "VVINF", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.18": {"line.1": {"text": "Wie reich an Herrlichkeit, an Schein,", "tokens": ["Wie", "reich", "an", "Herr\u00b7lich\u00b7keit", ",", "an", "Schein", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "APPR", "NN", "$,", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "An Glantz, an Sch\u00f6nheit, Pracht und Licht,", "tokens": ["An", "Glantz", ",", "an", "Sch\u00f6n\u00b7heit", ",", "Pracht", "und", "Licht", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "APPR", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mu\u00df der gewaltge Sch\u00f6pfer nicht", "tokens": ["Mu\u00df", "der", "ge\u00b7walt\u00b7ge", "Sch\u00f6p\u00b7fer", "nicht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VMFIN", "ART", "ADJA", "NN", "PTKNEG"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "In Seinen Allmachts-Tieffen seyn!", "tokens": ["In", "Sei\u00b7nen", "All\u00b7machts\u00b7Tief\u00b7fen", "seyn", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "(man schau\u2019 es nicht ohn Andacht an!)", "tokens": ["(", "man", "schau'", "es", "nicht", "ohn", "An\u00b7dacht", "an", "!", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PIS", "VVFIN", "PPER", "PTKNEG", "APPR", "NN", "PTKVZ", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Da er, was Nichts, so hoch erheben,", "tokens": ["Da", "er", ",", "was", "Nichts", ",", "so", "hoch", "er\u00b7he\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "PRELS", "PIS", "$,", "ADV", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Und auch so gar die Spinneweben", "tokens": ["Und", "auch", "so", "gar", "die", "Spin\u00b7ne\u00b7we\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "ADV", "ADV", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "So Wunder-w\u00fcrdig schm\u00fccken kann.", "tokens": ["So", "Wun\u00b7der\u00b7w\u00fcr\u00b7dig", "schm\u00fc\u00b7cken", "kann", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.19": {"line.1": {"text": "Allein, da ich mit aufmercksamen Blicken", "tokens": ["Al\u00b7lein", ",", "da", "ich", "mit", "auf\u00b7merck\u00b7sa\u00b7men", "Bli\u00b7cken"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "$,", "KOUS", "PPER", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Der spinnen bunt Gespinnst noch eins betracht\u2019;", "tokens": ["Der", "spin\u00b7nen", "bunt", "Ge\u00b7spinnst", "noch", "eins", "be\u00b7tracht'", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJD", "NN", "ADV", "PIS", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Nehm ich Bewundrungs-voll in Acht,", "tokens": ["Nehm", "ich", "Be\u00b7wun\u00b7drungs\u00b7voll", "in", "Acht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "APPR", "CARD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Da\u00df alle Sch\u00f6nheit anders nichts,", "tokens": ["Da\u00df", "al\u00b7le", "Sch\u00f6n\u00b7heit", "an\u00b7ders", "nichts", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "NN", "ADV", "PIS", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Als ", "tokens": ["Als"], "token_info": ["word"], "pos": ["KOUS"], "meter": "+", "measure": "single.up"}, "line.6": {"text": "Von welchem uns nur blo\u00df der Spinnen Werck die Pracht", "tokens": ["Von", "wel\u00b7chem", "uns", "nur", "blo\u00df", "der", "Spin\u00b7nen", "Werck", "die", "Pracht"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PRELS", "PPER", "ADV", "ADV", "ART", "NN", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Die sonst nicht sichtbar, sichtbar macht:", "tokens": ["Die", "sonst", "nicht", "sicht\u00b7bar", ",", "sicht\u00b7bar", "macht", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADV", "PTKNEG", "ADJD", "$,", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.20": {"line.1": {"text": "Auch Spinnenwebe scheint gesponnen", "tokens": ["Auch", "Spin\u00b7nen\u00b7we\u00b7be", "scheint", "ge\u00b7spon\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "NN", "VVFIN", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Zum Lobe Des, der sie bereit:", "tokens": ["Zum", "Lo\u00b7be", "Des", ",", "der", "sie", "be\u00b7reit", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "$,", "PRELS", "PPER", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Es zeigt uns ihr Gespinnst der Sonnen,", "tokens": ["Es", "zeigt", "uns", "ihr", "Ge\u00b7spinnst", "der", "Son\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PPOSAT", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wie die, des Sch\u00f6pfers, Herrlichkeit.", "tokens": ["Wie", "die", ",", "des", "Sch\u00f6p\u00b7fers", ",", "Herr\u00b7lich\u00b7keit", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["PWAV", "ART", "$,", "ART", "NN", "$,", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}