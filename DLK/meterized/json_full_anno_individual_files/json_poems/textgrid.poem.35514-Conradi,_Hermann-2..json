{"textgrid.poem.35514": {"metadata": {"author": {"name": "Conradi, Hermann", "birth": "N.A.", "death": "N.A."}, "title": "2.", "genre": "verse", "period": "N.A.", "pub_year": 1876, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wie bist du pl\u00f6tzlich \u00fcber mich gekommen,", "tokens": ["Wie", "bist", "du", "pl\u00f6tz\u00b7lich", "\u00fc\u00b7ber", "mich", "ge\u00b7kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PPER", "ADJD", "APPR", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Du Zug der Sehnsucht, der mich m\u00e4chtig packt?", "tokens": ["Du", "Zug", "der", "Sehn\u00b7sucht", ",", "der", "mich", "m\u00e4ch\u00b7tig", "packt", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "ART", "NN", "$,", "PRELS", "PPER", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Ich war so lustig mit dem Strom geschwommen", "tokens": ["Ich", "war", "so", "lus\u00b7tig", "mit", "dem", "Strom", "ge\u00b7schwom\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "APPR", "ART", "NN", "VVPP"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und ward so zahm, voll H\u00f6flichkeit und Takt!", "tokens": ["Und", "ward", "so", "zahm", ",", "voll", "H\u00f6f\u00b7lich\u00b7keit", "und", "Takt", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "ADJD", "$,", "ADJD", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Weit hinter mir lag all mein unstet Brausen,", "tokens": ["Weit", "hin\u00b7ter", "mir", "lag", "all", "mein", "un\u00b7stet", "Brau\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "PPER", "VVFIN", "PIAT", "PPOSAT", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Der \u00bbgute Ton\u00ab ward mir Respektsmoment ...", "tokens": ["Der", "\u00bb", "gu\u00b7te", "Ton", "\u00ab", "ward", "mir", "Res\u00b7pekts\u00b7mo\u00b7ment", "..."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "$(", "ADJA", "NN", "$(", "VAFIN", "PPER", "NN", "$("], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Ich f\u00fcgte mich und machte keine Flausen", "tokens": ["Ich", "f\u00fcg\u00b7te", "mich", "und", "mach\u00b7te", "kei\u00b7ne", "Flau\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "KON", "VVFIN", "PIAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und ward \u2013 \u00bbvern\u00fcnftig\u00ab, wie man das so nennt ...", "tokens": ["Und", "ward", "\u2013", "\u00bb", "ver\u00b7n\u00fcnf\u00b7tig", "\u00ab", ",", "wie", "man", "das", "so", "nennt", "..."], "token_info": ["word", "word", "punct", "punct", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "$(", "$(", "ADJD", "$(", "$,", "PWAV", "PIS", "ART", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Ich sa\u00df mit Hinz und Kunz an einem Tische", "tokens": ["Ich", "sa\u00df", "mit", "Hinz", "und", "Kunz", "an", "ei\u00b7nem", "Ti\u00b7sche"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "NN", "KON", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und der Beschr\u00e4nktheit reichte ich die Hand ...", "tokens": ["Und", "der", "Be\u00b7schr\u00e4nk\u00b7theit", "reich\u00b7te", "ich", "die", "Hand", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "PPER", "ART", "NN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Und ruhte nicht, bis ich auf einem Wische", "tokens": ["Und", "ruh\u00b7te", "nicht", ",", "bis", "ich", "auf", "ei\u00b7nem", "Wi\u00b7sche"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PTKNEG", "$,", "KOUS", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Verb\u00fcrgt, verbrieft mein \u2013 Lob der Narrheit fand.", "tokens": ["Ver\u00b7b\u00fcrgt", ",", "ver\u00b7brieft", "mein", "\u2013", "Lob", "der", "Nar\u00b7rheit", "fand", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "VVFIN", "PPOSAT", "$(", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Da hatten sie es sauber hingeschrieben,", "tokens": ["Da", "hat\u00b7ten", "sie", "es", "sau\u00b7ber", "hin\u00b7ge\u00b7schrie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PPER", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Auf Pergament, verbr\u00e4mt voll Phantasie:", "tokens": ["Auf", "Per\u00b7ga\u00b7ment", ",", "ver\u00b7br\u00e4mt", "voll", "Phan\u00b7ta\u00b7sie", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "VVFIN", "ADJD", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Ich w\u00e4r' auf rechten Wegen stets geblieben", "tokens": ["Ich", "w\u00e4r'", "auf", "rech\u00b7ten", "We\u00b7gen", "stets", "ge\u00b7blie\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "APPR", "ADJA", "NN", "ADV", "VVPP"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und h\u00e4tte ebenso gedacht wie sie ...", "tokens": ["Und", "h\u00e4t\u00b7te", "e\u00b7ben\u00b7so", "ge\u00b7dacht", "wie", "sie", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "VVPP", "KOKOM", "PPER", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "Und h\u00e4tte ebenso wie sie gelogen \u2013", "tokens": ["Und", "h\u00e4t\u00b7te", "e\u00b7ben\u00b7so", "wie", "sie", "ge\u00b7lo\u00b7gen", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "KOKOM", "PPER", "VVPP", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "War's auch ein wenig anders ausgedr\u00fcckt \u2013", "tokens": ["Wa\u00b7r's", "auch", "ein", "we\u00b7nig", "an\u00b7ders", "aus\u00b7ge\u00b7dr\u00fcckt", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "PIS", "ADV", "VVPP", "$("], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Und h\u00e4tte ebenso wie sie betrogen,", "tokens": ["Und", "h\u00e4t\u00b7te", "e\u00b7ben\u00b7so", "wie", "sie", "be\u00b7tro\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "KOKOM", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "W\u00e4r' ebenso wie sie herumgekr\u00fcckt ...", "tokens": ["W\u00e4r'", "e\u00b7ben\u00b7so", "wie", "sie", "her\u00b7um\u00b7ge\u00b7kr\u00fcckt", "..."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "KOKOM", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "(nat\u00fcrlich gab's auch hierf\u00fcr andre Worte,", "tokens": ["(", "na\u00b7t\u00fcr\u00b7lich", "gab's", "auch", "hier\u00b7f\u00fcr", "and\u00b7re", "Wor\u00b7te", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VVFIN", "ADV", "PAV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Doch war der Sinn derselbe, denk' ich, wohl! ...)", "tokens": ["Doch", "war", "der", "Sinn", "der\u00b7sel\u00b7be", ",", "denk'", "ich", ",", "wohl", "!", "...", ")"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct", "punct", "punct"], "pos": ["KON", "VAFIN", "ART", "NN", "PDAT", "$,", "VVFIN", "PPER", "$,", "ADV", "$.", "$(", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Und unterweil verschrumpft' ich und verdorrte,", "tokens": ["Und", "un\u00b7ter\u00b7weil", "ver\u00b7schrumpft'", "ich", "und", "ver\u00b7dorr\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und die ", "tokens": ["Und", "die"], "token_info": ["word", "word"], "pos": ["KON", "ART"], "meter": "+-", "measure": "trochaic.single"}}, "stanza.7": {"line.1": {"text": "So ging auch heute mir der Tag zu Ende,", "tokens": ["So", "ging", "auch", "heu\u00b7te", "mir", "der", "Tag", "zu", "En\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "ADV", "PPER", "ART", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "In bl\u00f6dem Einerlei vertan, verbracht ...", "tokens": ["In", "bl\u00f6\u00b7dem", "Ei\u00b7ner\u00b7lei", "ver\u00b7tan", ",", "ver\u00b7bracht", "..."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVPP", "$,", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Da lodert's pl\u00f6tzlich auf wie Feuerbr\u00e4nde", "tokens": ["Da", "lo\u00b7dert's", "pl\u00f6tz\u00b7lich", "auf", "wie", "Feu\u00b7er\u00b7br\u00e4n\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ADJD", "PTKVZ", "KOKOM", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "In meiner Brust in stiller Mitternacht! ...", "tokens": ["In", "mei\u00b7ner", "Brust", "in", "stil\u00b7ler", "Mit\u00b7ter\u00b7nacht", "!", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "PPOSAT", "NN", "APPR", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.8": {"line.1": {"text": "Da pl\u00f6tzlich sch\u00e4umt es auf wie Katarakte \u2013", "tokens": ["Da", "pl\u00f6tz\u00b7lich", "sch\u00e4umt", "es", "auf", "wie", "Ka\u00b7ta\u00b7rak\u00b7te", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "PPER", "PTKVZ", "KOKOM", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Es schreit der Sturm und peitscht mein totes Blut \u2013", "tokens": ["Es", "schreit", "der", "Sturm", "und", "peitscht", "mein", "to\u00b7tes", "Blut", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "KON", "VVFIN", "PPOSAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Und vor mir steht die Wirklichkeit, die nackte:", "tokens": ["Und", "vor", "mir", "steht", "die", "Wirk\u00b7lich\u00b7keit", ",", "die", "nack\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "APPR", "PPER", "VVFIN", "ART", "NN", "$,", "PRELS", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.9": {"line.1": {"text": "Was ich verh\u00f6hnt, verlacht, mit Recht verachtet", "tokens": ["Was", "ich", "ver\u00b7h\u00f6hnt", ",", "ver\u00b7lacht", ",", "mit", "Recht", "ver\u00b7ach\u00b7tet"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["PWS", "PPER", "VVPP", "$,", "VVPP", "$,", "APPR", "NN", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Dereinst, als jung mein Herz und lauter noch:", "tokens": ["De\u00b7reinst", ",", "als", "jung", "mein", "Herz", "und", "lau\u00b7ter", "noch", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "ADJD", "PPOSAT", "NN", "KON", "ADJD", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Ich hab' es jahrelang voll Flei\u00df ertrachtet", "tokens": ["Ich", "hab'", "es", "jah\u00b7re\u00b7lang", "voll", "Flei\u00df", "ert\u00b7rach\u00b7tet"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PPER", "ADJD", "ADJD", "NN", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und manchmal war's, da\u00df ich zu Kreuze kroch!", "tokens": ["Und", "manch\u00b7mal", "wa\u00b7r's", ",", "da\u00df", "ich", "zu", "Kreu\u00b7ze", "kroch", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "$,", "KOUS", "PPER", "APPR", "NN", "VVFIN", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}}, "stanza.10": {"line.1": {"text": "Und manchmal war's, da\u00df ich den Geist geschunden,", "tokens": ["Und", "manch\u00b7mal", "wa\u00b7r's", ",", "da\u00df", "ich", "den", "Geist", "ge\u00b7schun\u00b7den", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "$,", "KOUS", "PPER", "ART", "NN", "VVPP", "$,"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Da\u00df er wie auf der Marterbank gest\u00f6hnt \u2013", "tokens": ["Da\u00df", "er", "wie", "auf", "der", "Mar\u00b7ter\u00b7bank", "ge\u00b7st\u00f6hnt", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "KOKOM", "APPR", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Da lag er, \u00fcberdeckt von tausend Wunden,", "tokens": ["Da", "lag", "er", ",", "\u00fc\u00b7berd\u00b7eckt", "von", "tau\u00b7send", "Wun\u00b7den", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "VVFIN", "APPR", "CARD", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Der arme Kerl, vom P\u00f6bel strohgekr\u00f6nt! ...", "tokens": ["Der", "ar\u00b7me", "Kerl", ",", "vom", "P\u00f6\u00b7bel", "stroh\u00b7ge\u00b7kr\u00f6nt", "!", "..."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "APPRART", "NN", "VVFIN", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.11": {"line.1": {"text": "Und endlich dann \u2013 dann hatt' ich ihn bezwungen", "tokens": ["Und", "end\u00b7lich", "dann", "\u2013", "dann", "hatt'", "ich", "ihn", "be\u00b7zwun\u00b7gen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "ADV", "$(", "ADV", "VAFIN", "PPER", "PPER", "VVPP"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und ihn geknechtet mit Verr\u00e4terhand \u2013", "tokens": ["Und", "ihn", "ge\u00b7knech\u00b7tet", "mit", "Ver\u00b7r\u00e4\u00b7ter\u00b7hand", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVPP", "APPR", "NN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Das Kunstst\u00fcck war mir ganz famos gelungen:", "tokens": ["Das", "Kunst\u00b7st\u00fcck", "war", "mir", "ganz", "fa\u00b7mos", "ge\u00b7lun\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Da\u00df schlie\u00dflich alles ich \u2013 \u00bbnat\u00fcrlich\u00ab fand! ...", "tokens": ["Da\u00df", "schlie\u00df\u00b7lich", "al\u00b7les", "ich", "\u2013", "\u00bb", "na\u00b7t\u00fcr\u00b7lich", "\u00ab", "fand", "!", "..."], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "punct", "word", "punct", "punct"], "pos": ["KOUS", "ADV", "PIS", "PPER", "$(", "$(", "ADV", "$(", "VVFIN", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.12": {"line.1": {"text": "Und nun! Und nun! O feuer\u00e4ugig Wunder,", "tokens": ["Und", "nun", "!", "Und", "nun", "!", "O", "feu\u00b7e\u00b7r\u00e4u\u00b7gig", "Wun\u00b7der", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$.", "KON", "ADV", "$.", "NE", "ADJD", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Das sich herausgebar aus n\u00e4cht'gem Scho\u00df!", "tokens": ["Das", "sich", "her\u00b7aus\u00b7ge\u00b7bar", "aus", "n\u00e4cht'\u00b7gem", "Scho\u00df", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PRF", "ADJD", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Vor mir zerst\u00e4ubt der taube, tote Plunder", "tokens": ["Vor", "mir", "zer\u00b7st\u00e4ubt", "der", "tau\u00b7be", ",", "to\u00b7te", "Plun\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "PPER", "VVFIN", "ART", "ADJA", "$,", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.13": {"line.1": {"text": "Ich find' sie wieder, all die alten Pfade,", "tokens": ["Ich", "find'", "sie", "wie\u00b7der", ",", "all", "die", "al\u00b7ten", "Pfa\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "$,", "PIAT", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ein \u00fcberirdisch Licht beflammt die Spur \u2013", "tokens": ["Ein", "\u00fc\u00b7be\u00b7rir\u00b7disch", "Licht", "be\u00b7flammt", "die", "Spur", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "VVFIN", "ART", "NN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Durch eines ", "tokens": ["Durch", "ei\u00b7nes"], "token_info": ["word", "word"], "pos": ["APPR", "ART"], "meter": "-+-", "measure": "amphibrach.single"}, "line.4": {"text": "Kehr' ich zur\u00fcck zur Wahrheit und Natur!", "tokens": ["Kehr'", "ich", "zu\u00b7r\u00fcck", "zur", "Wahr\u00b7heit", "und", "Na\u00b7tur", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "PTKVZ", "APPRART", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.14": {"line.1": {"text": "Ich kehr' zum Leben und zu seinen Quellen,", "tokens": ["Ich", "kehr'", "zum", "Le\u00b7ben", "und", "zu", "sei\u00b7nen", "Quel\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "KON", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Sein wahres Wesen gibt sich heiter kund,", "tokens": ["Sein", "wah\u00b7res", "We\u00b7sen", "gibt", "sich", "hei\u00b7ter", "kund", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVFIN", "PRF", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Vor meinem Blick will sich das Tiefste hellen", "tokens": ["Vor", "mei\u00b7nem", "Blick", "will", "sich", "das", "Tiefs\u00b7te", "hel\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "VMFIN", "PRF", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und offen liegt mir aller Dinge Grund ...", "tokens": ["Und", "of\u00b7fen", "liegt", "mir", "al\u00b7ler", "Din\u00b7ge", "Grund", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "PPER", "PIAT", "NN", "NN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.15": {"line.1": {"text": "In m\u00e4cht'gen Wogen rollt in Herz und Hirn mir", "tokens": ["In", "m\u00e4cht'\u00b7gen", "Wo\u00b7gen", "rollt", "in", "Herz", "und", "Hirn", "mir"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "APPR", "NN", "KON", "NN", "PPER"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die Kraft zur\u00fcck, ", "tokens": ["Die", "Kraft", "zu\u00b7r\u00fcck", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "Der Muskel knollt, graniten wird die Stirn mir:", "tokens": ["Der", "Mus\u00b7kel", "knollt", ",", "gra\u00b7ni\u00b7ten", "wird", "die", "Stirn", "mir", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "ADJA", "VAFIN", "ART", "NN", "PPER", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.16": {"line.1": {"text": "Wie bist du pl\u00f6tzlich \u00fcber mich gekommen,", "tokens": ["Wie", "bist", "du", "pl\u00f6tz\u00b7lich", "\u00fc\u00b7ber", "mich", "ge\u00b7kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PPER", "ADJD", "APPR", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Du Zug der Sehnsucht, der mich m\u00e4chtig packt?", "tokens": ["Du", "Zug", "der", "Sehn\u00b7sucht", ",", "der", "mich", "m\u00e4ch\u00b7tig", "packt", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "ART", "NN", "$,", "PRELS", "PPER", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Ich war so lustig mit dem Strom geschwommen", "tokens": ["Ich", "war", "so", "lus\u00b7tig", "mit", "dem", "Strom", "ge\u00b7schwom\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "APPR", "ART", "NN", "VVPP"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und ward so zahm, voll H\u00f6flichkeit und Takt!", "tokens": ["Und", "ward", "so", "zahm", ",", "voll", "H\u00f6f\u00b7lich\u00b7keit", "und", "Takt", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "ADJD", "$,", "ADJD", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.17": {"line.1": {"text": "Weit hinter mir lag all mein unstet Brausen,", "tokens": ["Weit", "hin\u00b7ter", "mir", "lag", "all", "mein", "un\u00b7stet", "Brau\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "PPER", "VVFIN", "PIAT", "PPOSAT", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Der \u00bbgute Ton\u00ab ward mir Respektsmoment ...", "tokens": ["Der", "\u00bb", "gu\u00b7te", "Ton", "\u00ab", "ward", "mir", "Res\u00b7pekts\u00b7mo\u00b7ment", "..."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "$(", "ADJA", "NN", "$(", "VAFIN", "PPER", "NN", "$("], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Ich f\u00fcgte mich und machte keine Flausen", "tokens": ["Ich", "f\u00fcg\u00b7te", "mich", "und", "mach\u00b7te", "kei\u00b7ne", "Flau\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "KON", "VVFIN", "PIAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und ward \u2013 \u00bbvern\u00fcnftig\u00ab, wie man das so nennt ...", "tokens": ["Und", "ward", "\u2013", "\u00bb", "ver\u00b7n\u00fcnf\u00b7tig", "\u00ab", ",", "wie", "man", "das", "so", "nennt", "..."], "token_info": ["word", "word", "punct", "punct", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "$(", "$(", "ADJD", "$(", "$,", "PWAV", "PIS", "ART", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.18": {"line.1": {"text": "Ich sa\u00df mit Hinz und Kunz an einem Tische", "tokens": ["Ich", "sa\u00df", "mit", "Hinz", "und", "Kunz", "an", "ei\u00b7nem", "Ti\u00b7sche"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "NN", "KON", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und der Beschr\u00e4nktheit reichte ich die Hand ...", "tokens": ["Und", "der", "Be\u00b7schr\u00e4nk\u00b7theit", "reich\u00b7te", "ich", "die", "Hand", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "PPER", "ART", "NN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Und ruhte nicht, bis ich auf einem Wische", "tokens": ["Und", "ruh\u00b7te", "nicht", ",", "bis", "ich", "auf", "ei\u00b7nem", "Wi\u00b7sche"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PTKNEG", "$,", "KOUS", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Verb\u00fcrgt, verbrieft mein \u2013 Lob der Narrheit fand.", "tokens": ["Ver\u00b7b\u00fcrgt", ",", "ver\u00b7brieft", "mein", "\u2013", "Lob", "der", "Nar\u00b7rheit", "fand", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "VVFIN", "PPOSAT", "$(", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.19": {"line.1": {"text": "Da hatten sie es sauber hingeschrieben,", "tokens": ["Da", "hat\u00b7ten", "sie", "es", "sau\u00b7ber", "hin\u00b7ge\u00b7schrie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PPER", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Auf Pergament, verbr\u00e4mt voll Phantasie:", "tokens": ["Auf", "Per\u00b7ga\u00b7ment", ",", "ver\u00b7br\u00e4mt", "voll", "Phan\u00b7ta\u00b7sie", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "VVFIN", "ADJD", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Ich w\u00e4r' auf rechten Wegen stets geblieben", "tokens": ["Ich", "w\u00e4r'", "auf", "rech\u00b7ten", "We\u00b7gen", "stets", "ge\u00b7blie\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "APPR", "ADJA", "NN", "ADV", "VVPP"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und h\u00e4tte ebenso gedacht wie sie ...", "tokens": ["Und", "h\u00e4t\u00b7te", "e\u00b7ben\u00b7so", "ge\u00b7dacht", "wie", "sie", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "VVPP", "KOKOM", "PPER", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.20": {"line.1": {"text": "Und h\u00e4tte ebenso wie sie gelogen \u2013", "tokens": ["Und", "h\u00e4t\u00b7te", "e\u00b7ben\u00b7so", "wie", "sie", "ge\u00b7lo\u00b7gen", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "KOKOM", "PPER", "VVPP", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "War's auch ein wenig anders ausgedr\u00fcckt \u2013", "tokens": ["Wa\u00b7r's", "auch", "ein", "we\u00b7nig", "an\u00b7ders", "aus\u00b7ge\u00b7dr\u00fcckt", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "PIS", "ADV", "VVPP", "$("], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Und h\u00e4tte ebenso wie sie betrogen,", "tokens": ["Und", "h\u00e4t\u00b7te", "e\u00b7ben\u00b7so", "wie", "sie", "be\u00b7tro\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "KOKOM", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "W\u00e4r' ebenso wie sie herumgekr\u00fcckt ...", "tokens": ["W\u00e4r'", "e\u00b7ben\u00b7so", "wie", "sie", "her\u00b7um\u00b7ge\u00b7kr\u00fcckt", "..."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "KOKOM", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.21": {"line.1": {"text": "(nat\u00fcrlich gab's auch hierf\u00fcr andre Worte,", "tokens": ["(", "na\u00b7t\u00fcr\u00b7lich", "gab's", "auch", "hier\u00b7f\u00fcr", "and\u00b7re", "Wor\u00b7te", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VVFIN", "ADV", "PAV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Doch war der Sinn derselbe, denk' ich, wohl! ...)", "tokens": ["Doch", "war", "der", "Sinn", "der\u00b7sel\u00b7be", ",", "denk'", "ich", ",", "wohl", "!", "...", ")"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct", "punct", "punct"], "pos": ["KON", "VAFIN", "ART", "NN", "PDAT", "$,", "VVFIN", "PPER", "$,", "ADV", "$.", "$(", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Und unterweil verschrumpft' ich und verdorrte,", "tokens": ["Und", "un\u00b7ter\u00b7weil", "ver\u00b7schrumpft'", "ich", "und", "ver\u00b7dorr\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und die ", "tokens": ["Und", "die"], "token_info": ["word", "word"], "pos": ["KON", "ART"], "meter": "+-", "measure": "trochaic.single"}}, "stanza.22": {"line.1": {"text": "So ging auch heute mir der Tag zu Ende,", "tokens": ["So", "ging", "auch", "heu\u00b7te", "mir", "der", "Tag", "zu", "En\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "ADV", "PPER", "ART", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "In bl\u00f6dem Einerlei vertan, verbracht ...", "tokens": ["In", "bl\u00f6\u00b7dem", "Ei\u00b7ner\u00b7lei", "ver\u00b7tan", ",", "ver\u00b7bracht", "..."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVPP", "$,", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Da lodert's pl\u00f6tzlich auf wie Feuerbr\u00e4nde", "tokens": ["Da", "lo\u00b7dert's", "pl\u00f6tz\u00b7lich", "auf", "wie", "Feu\u00b7er\u00b7br\u00e4n\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ADJD", "PTKVZ", "KOKOM", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "In meiner Brust in stiller Mitternacht! ...", "tokens": ["In", "mei\u00b7ner", "Brust", "in", "stil\u00b7ler", "Mit\u00b7ter\u00b7nacht", "!", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "PPOSAT", "NN", "APPR", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.23": {"line.1": {"text": "Da pl\u00f6tzlich sch\u00e4umt es auf wie Katarakte \u2013", "tokens": ["Da", "pl\u00f6tz\u00b7lich", "sch\u00e4umt", "es", "auf", "wie", "Ka\u00b7ta\u00b7rak\u00b7te", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "PPER", "PTKVZ", "KOKOM", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Es schreit der Sturm und peitscht mein totes Blut \u2013", "tokens": ["Es", "schreit", "der", "Sturm", "und", "peitscht", "mein", "to\u00b7tes", "Blut", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "KON", "VVFIN", "PPOSAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Und vor mir steht die Wirklichkeit, die nackte:", "tokens": ["Und", "vor", "mir", "steht", "die", "Wirk\u00b7lich\u00b7keit", ",", "die", "nack\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "APPR", "PPER", "VVFIN", "ART", "NN", "$,", "PRELS", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.24": {"line.1": {"text": "Was ich verh\u00f6hnt, verlacht, mit Recht verachtet", "tokens": ["Was", "ich", "ver\u00b7h\u00f6hnt", ",", "ver\u00b7lacht", ",", "mit", "Recht", "ver\u00b7ach\u00b7tet"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["PWS", "PPER", "VVPP", "$,", "VVPP", "$,", "APPR", "NN", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Dereinst, als jung mein Herz und lauter noch:", "tokens": ["De\u00b7reinst", ",", "als", "jung", "mein", "Herz", "und", "lau\u00b7ter", "noch", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "ADJD", "PPOSAT", "NN", "KON", "ADJD", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Ich hab' es jahrelang voll Flei\u00df ertrachtet", "tokens": ["Ich", "hab'", "es", "jah\u00b7re\u00b7lang", "voll", "Flei\u00df", "ert\u00b7rach\u00b7tet"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PPER", "ADJD", "ADJD", "NN", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und manchmal war's, da\u00df ich zu Kreuze kroch!", "tokens": ["Und", "manch\u00b7mal", "wa\u00b7r's", ",", "da\u00df", "ich", "zu", "Kreu\u00b7ze", "kroch", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "$,", "KOUS", "PPER", "APPR", "NN", "VVFIN", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}}, "stanza.25": {"line.1": {"text": "Und manchmal war's, da\u00df ich den Geist geschunden,", "tokens": ["Und", "manch\u00b7mal", "wa\u00b7r's", ",", "da\u00df", "ich", "den", "Geist", "ge\u00b7schun\u00b7den", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "$,", "KOUS", "PPER", "ART", "NN", "VVPP", "$,"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Da\u00df er wie auf der Marterbank gest\u00f6hnt \u2013", "tokens": ["Da\u00df", "er", "wie", "auf", "der", "Mar\u00b7ter\u00b7bank", "ge\u00b7st\u00f6hnt", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "KOKOM", "APPR", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Da lag er, \u00fcberdeckt von tausend Wunden,", "tokens": ["Da", "lag", "er", ",", "\u00fc\u00b7berd\u00b7eckt", "von", "tau\u00b7send", "Wun\u00b7den", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "VVFIN", "APPR", "CARD", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Der arme Kerl, vom P\u00f6bel strohgekr\u00f6nt! ...", "tokens": ["Der", "ar\u00b7me", "Kerl", ",", "vom", "P\u00f6\u00b7bel", "stroh\u00b7ge\u00b7kr\u00f6nt", "!", "..."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "APPRART", "NN", "VVFIN", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.26": {"line.1": {"text": "Und endlich dann \u2013 dann hatt' ich ihn bezwungen", "tokens": ["Und", "end\u00b7lich", "dann", "\u2013", "dann", "hatt'", "ich", "ihn", "be\u00b7zwun\u00b7gen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "ADV", "$(", "ADV", "VAFIN", "PPER", "PPER", "VVPP"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und ihn geknechtet mit Verr\u00e4terhand \u2013", "tokens": ["Und", "ihn", "ge\u00b7knech\u00b7tet", "mit", "Ver\u00b7r\u00e4\u00b7ter\u00b7hand", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVPP", "APPR", "NN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Das Kunstst\u00fcck war mir ganz famos gelungen:", "tokens": ["Das", "Kunst\u00b7st\u00fcck", "war", "mir", "ganz", "fa\u00b7mos", "ge\u00b7lun\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Da\u00df schlie\u00dflich alles ich \u2013 \u00bbnat\u00fcrlich\u00ab fand! ...", "tokens": ["Da\u00df", "schlie\u00df\u00b7lich", "al\u00b7les", "ich", "\u2013", "\u00bb", "na\u00b7t\u00fcr\u00b7lich", "\u00ab", "fand", "!", "..."], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "punct", "word", "punct", "punct"], "pos": ["KOUS", "ADV", "PIS", "PPER", "$(", "$(", "ADV", "$(", "VVFIN", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.27": {"line.1": {"text": "Und nun! Und nun! O feuer\u00e4ugig Wunder,", "tokens": ["Und", "nun", "!", "Und", "nun", "!", "O", "feu\u00b7e\u00b7r\u00e4u\u00b7gig", "Wun\u00b7der", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$.", "KON", "ADV", "$.", "NE", "ADJD", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Das sich herausgebar aus n\u00e4cht'gem Scho\u00df!", "tokens": ["Das", "sich", "her\u00b7aus\u00b7ge\u00b7bar", "aus", "n\u00e4cht'\u00b7gem", "Scho\u00df", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PRF", "ADJD", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Vor mir zerst\u00e4ubt der taube, tote Plunder", "tokens": ["Vor", "mir", "zer\u00b7st\u00e4ubt", "der", "tau\u00b7be", ",", "to\u00b7te", "Plun\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "PPER", "VVFIN", "ART", "ADJA", "$,", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.28": {"line.1": {"text": "Ich find' sie wieder, all die alten Pfade,", "tokens": ["Ich", "find'", "sie", "wie\u00b7der", ",", "all", "die", "al\u00b7ten", "Pfa\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "$,", "PIAT", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ein \u00fcberirdisch Licht beflammt die Spur \u2013", "tokens": ["Ein", "\u00fc\u00b7be\u00b7rir\u00b7disch", "Licht", "be\u00b7flammt", "die", "Spur", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "VVFIN", "ART", "NN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Durch eines ", "tokens": ["Durch", "ei\u00b7nes"], "token_info": ["word", "word"], "pos": ["APPR", "ART"], "meter": "-+-", "measure": "amphibrach.single"}, "line.4": {"text": "Kehr' ich zur\u00fcck zur Wahrheit und Natur!", "tokens": ["Kehr'", "ich", "zu\u00b7r\u00fcck", "zur", "Wahr\u00b7heit", "und", "Na\u00b7tur", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "PTKVZ", "APPRART", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.29": {"line.1": {"text": "Ich kehr' zum Leben und zu seinen Quellen,", "tokens": ["Ich", "kehr'", "zum", "Le\u00b7ben", "und", "zu", "sei\u00b7nen", "Quel\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "KON", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Sein wahres Wesen gibt sich heiter kund,", "tokens": ["Sein", "wah\u00b7res", "We\u00b7sen", "gibt", "sich", "hei\u00b7ter", "kund", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVFIN", "PRF", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Vor meinem Blick will sich das Tiefste hellen", "tokens": ["Vor", "mei\u00b7nem", "Blick", "will", "sich", "das", "Tiefs\u00b7te", "hel\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "VMFIN", "PRF", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und offen liegt mir aller Dinge Grund ...", "tokens": ["Und", "of\u00b7fen", "liegt", "mir", "al\u00b7ler", "Din\u00b7ge", "Grund", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "PPER", "PIAT", "NN", "NN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.30": {"line.1": {"text": "In m\u00e4cht'gen Wogen rollt in Herz und Hirn mir", "tokens": ["In", "m\u00e4cht'\u00b7gen", "Wo\u00b7gen", "rollt", "in", "Herz", "und", "Hirn", "mir"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "APPR", "NN", "KON", "NN", "PPER"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die Kraft zur\u00fcck, ", "tokens": ["Die", "Kraft", "zu\u00b7r\u00fcck", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "Der Muskel knollt, graniten wird die Stirn mir:", "tokens": ["Der", "Mus\u00b7kel", "knollt", ",", "gra\u00b7ni\u00b7ten", "wird", "die", "Stirn", "mir", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "ADJA", "VAFIN", "ART", "NN", "PPER", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}}}}