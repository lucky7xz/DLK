{"textgrid.poem.32532": {"metadata": {"author": {"name": "Lessing, Gotthold Ephraim", "birth": "N.A.", "death": "N.A."}, "title": "XiII. Die Brille", "genre": "verse", "period": "N.A.", "pub_year": 1755, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Dem alten Freiherrn von Chrysant,", "tokens": ["Dem", "al\u00b7ten", "Frei\u00b7herrn", "von", "Chry\u00b7sant", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "NE", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Wagts Amor, einen Streich zu spielen.", "tokens": ["Wagts", "A\u00b7mor", ",", "ei\u00b7nen", "Streich", "zu", "spie\u00b7len", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "F\u00fcr einen Hagestolz bekannt,", "tokens": ["F\u00fcr", "ei\u00b7nen", "Ha\u00b7ge\u00b7stolz", "be\u00b7kannt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Fing, um die Sechzig, er sich wieder an zu f\u00fchlen.", "tokens": ["Fing", ",", "um", "die", "Sech\u00b7zig", ",", "er", "sich", "wie\u00b7der", "an", "zu", "f\u00fch\u00b7len", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "KOUI", "ART", "CARD", "$,", "PPER", "PRF", "ADV", "PTKVZ", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Es flatterte, von Alt und Jung begafft,", "tokens": ["Es", "flat\u00b7ter\u00b7te", ",", "von", "Alt", "und", "Jung", "be\u00b7gafft", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "APPR", "NN", "KON", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Mit Reizen ganz besondrer Kraft,", "tokens": ["Mit", "Rei\u00b7zen", "ganz", "be\u00b7sond\u00b7rer", "Kraft", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ein B\u00fcrgerm\u00e4dchen in der Nachbarschaft.", "tokens": ["Ein", "B\u00fcr\u00b7ger\u00b7m\u00e4d\u00b7chen", "in", "der", "Nach\u00b7bar\u00b7schaft", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Dies B\u00fcrgerm\u00e4dchen hie\u00df Finette.", "tokens": ["Dies", "B\u00fcr\u00b7ger\u00b7m\u00e4d\u00b7chen", "hie\u00df", "Fi\u00b7net\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "NN", "VVFIN", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Finette ward des Freiherrn Siegerin.", "tokens": ["Fi\u00b7net\u00b7te", "ward", "des", "Frei\u00b7herrn", "Sie\u00b7ge\u00b7rin", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Ihr Bild stand mit ihm auf, und ging mit ihm zu Bette.", "tokens": ["Ihr", "Bild", "stand", "mit", "ihm", "auf", ",", "und", "ging", "mit", "ihm", "zu", "Bet\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "APPR", "PPER", "PTKVZ", "$,", "KON", "VVFIN", "APPR", "PPER", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Da dacht' in seinem Sinn", "tokens": ["Da", "dacht'", "in", "sei\u00b7nem", "Sinn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Der Freiherr: \u00bbUnd warum denn nur ihr Bild?", "tokens": ["Der", "Frei\u00b7herr", ":", "\u00bb", "Und", "wa\u00b7rum", "denn", "nur", "ihr", "Bild", "?"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$.", "$(", "KON", "PWAV", "ADV", "ADV", "PPOSAT", "NN", "$."], "meter": "-+---+-+-+", "measure": "dactylic.init"}, "line.5": {"text": "Ihr Bild, das zwar den Kopf, doch nicht die Arme f\u00fcllt?", "tokens": ["Ihr", "Bild", ",", "das", "zwar", "den", "Kopf", ",", "doch", "nicht", "die", "Ar\u00b7me", "f\u00fcllt", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PRELS", "ADV", "ART", "NN", "$,", "ADV", "PTKNEG", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Sie selbst steh' mit mir auf, und geh' mit mir zu Bette.", "tokens": ["Sie", "selbst", "steh'", "mit", "mir", "auf", ",", "und", "geh'", "mit", "mir", "zu", "Bet\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "APPR", "PPER", "PTKVZ", "$,", "KON", "VVFIN", "APPR", "PPER", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Sie werde meine Frau! Es schelte, wer da schilt;", "tokens": ["Sie", "wer\u00b7de", "mei\u00b7ne", "Frau", "!", "Es", "schel\u00b7te", ",", "wer", "da", "schilt", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "NN", "$.", "PPER", "VVFIN", "$,", "PWS", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Gen\u00e4d'ge Tant' und Nicht' und Schw\u00e4gerin!", "tokens": ["Ge\u00b7n\u00e4d'\u00b7ge", "Tant'", "und", "Nicht'", "und", "Schw\u00e4\u00b7ge\u00b7rin", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "KON", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Finett' ist meine Frau, und - ihre Dienerin.\u00ab", "tokens": ["Fi\u00b7nett'", "ist", "mei\u00b7ne", "Frau", ",", "und", "ih\u00b7re", "Die\u00b7ne\u00b7rin", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "VAFIN", "PPOSAT", "NN", "$,", "KON", "$(", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}}, "stanza.4": {"line.1": {"text": "Schon so gewi\u00df? Man wird es h\u00f6ren.", "tokens": ["Schon", "so", "ge\u00b7wi\u00df", "?", "Man", "wird", "es", "h\u00f6\u00b7ren", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "$.", "PIS", "VAFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Der Freiherr k\u00f6mmt, sich zu erkl\u00e4ren,", "tokens": ["Der", "Frei\u00b7herr", "k\u00f6mmt", ",", "sich", "zu", "er\u00b7kl\u00e4\u00b7ren", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "PRF", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Ergreift das M\u00e4dchen bei der Hand,", "tokens": ["Er\u00b7greift", "das", "M\u00e4d\u00b7chen", "bei", "der", "Hand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Tut, wie ein Freiherr, ganz bekannt,", "tokens": ["Tut", ",", "wie", "ein", "Frei\u00b7herr", ",", "ganz", "be\u00b7kannt", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "PWAV", "ART", "NN", "$,", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und spricht: \u00bbIch, Freiherr von Chrysant,", "tokens": ["Und", "spricht", ":", "\u00bb", "Ich", ",", "Frei\u00b7herr", "von", "Chry\u00b7sant", ","], "token_info": ["word", "word", "punct", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "$(", "PPER", "$,", "NN", "APPR", "NE", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Ich habe Sie, mein Kind, zu meiner Frau ersehen.", "tokens": ["Ich", "ha\u00b7be", "Sie", ",", "mein", "Kind", ",", "zu", "mei\u00b7ner", "Frau", "er\u00b7se\u00b7hen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "$,", "PPOSAT", "NN", "$,", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Sie wird sich hoffentlich nicht selbst im Lichte stehen.", "tokens": ["Sie", "wird", "sich", "hof\u00b7fent\u00b7lich", "nicht", "selbst", "im", "Lich\u00b7te", "ste\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PRF", "ADV", "PTKNEG", "ADV", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-++--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.8": {"text": "Ich habe Guts die H\u00fcll' und F\u00fclle.\u00ab", "tokens": ["Ich", "ha\u00b7be", "Guts", "die", "H\u00fcll'", "und", "F\u00fcl\u00b7le", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VAFIN", "NN", "ART", "NN", "KON", "NN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Und hierauf las er ihr, durch eine gro\u00dfe Brille", "tokens": ["Und", "hier\u00b7auf", "las", "er", "ihr", ",", "durch", "ei\u00b7ne", "gro\u00b7\u00dfe", "Bril\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "PAV", "VVFIN", "PPER", "PPER", "$,", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Von einem gro\u00dfen Zettel ab,", "tokens": ["Von", "ei\u00b7nem", "gro\u00b7\u00dfen", "Zet\u00b7tel", "ab", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Wie viel ihm Gott an G\u00fctern gab;", "tokens": ["Wie", "viel", "ihm", "Gott", "an", "G\u00fc\u00b7tern", "gab", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "PPER", "NN", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Wie reich er sie beschenken wolle;", "tokens": ["Wie", "reich", "er", "sie", "be\u00b7schen\u00b7ken", "wol\u00b7le", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "PPER", "PPER", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Welch gro\u00dfen Witwenschatz sie einmal haben solle.", "tokens": ["Welch", "gro\u00b7\u00dfen", "Wit\u00b7wen\u00b7schatz", "sie", "ein\u00b7mal", "ha\u00b7ben", "sol\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "PPER", "ADV", "VAINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Dies alles las der reiche Mann", "tokens": ["Dies", "al\u00b7les", "las", "der", "rei\u00b7che", "Mann"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "PIS", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Ihr von dem Zettel ab, und guckte durch die Brille", "tokens": ["Ihr", "von", "dem", "Zet\u00b7tel", "ab", ",", "und", "guck\u00b7te", "durch", "die", "Bril\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "APPR", "ART", "NN", "PTKVZ", "$,", "KON", "VVFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Bei jedem Punkte sie begierig an.", "tokens": ["Bei", "je\u00b7dem", "Punk\u00b7te", "sie", "be\u00b7gie\u00b7rig", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "PPER", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "\u00bbnun, Kind, was ist Ihr Wille?\u00ab", "tokens": ["\u00bb", "nun", ",", "Kind", ",", "was", "ist", "Ihr", "Wil\u00b7le", "?", "\u00ab"], "token_info": ["punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADV", "$,", "NN", "$,", "PWS", "VAFIN", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Mit diesen Worten schwieg der Freiherr stille,", "tokens": ["Mit", "die\u00b7sen", "Wor\u00b7ten", "schwieg", "der", "Frei\u00b7herr", "stil\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "VVFIN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und nahm mit diesen Worten seine Brille -", "tokens": ["Und", "nahm", "mit", "die\u00b7sen", "Wor\u00b7ten", "sei\u00b7ne", "Bril\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "PDAT", "NN", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "(denn, dacht' er, wird das M\u00e4dchen nun", "tokens": ["(", "denn", ",", "dacht'", "er", ",", "wird", "das", "M\u00e4d\u00b7chen", "nun"], "token_info": ["punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["$(", "ADV", "$,", "VVFIN", "PPER", "$,", "VAFIN", "ART", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "So wie ein kluges M\u00e4dchen tun;", "tokens": ["So", "wie", "ein", "klu\u00b7ges", "M\u00e4d\u00b7chen", "tun", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wird mich und sie ihr schnelles Ja begl\u00fccken;", "tokens": ["Wird", "mich", "und", "sie", "ihr", "schnel\u00b7les", "Ja", "be\u00b7gl\u00fc\u00b7cken", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "KON", "PPER", "PPOSAT", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Werd' ich den ersten Ku\u00df auf ihre Lippen dr\u00fccken:", "tokens": ["Werd'", "ich", "den", "ers\u00b7ten", "Ku\u00df", "auf", "ih\u00b7re", "Lip\u00b7pen", "dr\u00fc\u00b7cken", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "So k\u00f6nnt' ich, im Entz\u00fccken,", "tokens": ["So", "k\u00f6nnt'", "ich", ",", "im", "Ent\u00b7z\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "$,", "APPRART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.9": {"text": "Die teure Brille leicht zerknicken!) -", "tokens": ["Die", "teu\u00b7re", "Bril\u00b7le", "leicht", "zer\u00b7kni\u00b7cken", "!", ")"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word"], "pos": ["ART", "ADJA", "NN", "ADJD", "VVINF", "$.", "$(", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Die teure Brille wohlbed\u00e4chtig ab.", "tokens": ["Die", "teu\u00b7re", "Bril\u00b7le", "wohl\u00b7be\u00b7d\u00e4ch\u00b7tig", "ab", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Finette, der dies Zeit sich zu bedenken gab,", "tokens": ["Fi\u00b7net\u00b7te", ",", "der", "dies", "Zeit", "sich", "zu", "be\u00b7den\u00b7ken", "gab", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PRELS", "PDS", "NN", "PRF", "PTKZU", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Bedachte sich, und sprach nach reiflichem Bedenken:", "tokens": ["Be\u00b7dach\u00b7te", "sich", ",", "und", "sprach", "nach", "reif\u00b7li\u00b7chem", "Be\u00b7den\u00b7ken", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "$,", "KON", "VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "\u00bbsie sprechen, gn\u00e4d'ger Herr, vom Freien und vom Schenken:", "tokens": ["\u00bb", "sie", "spre\u00b7chen", ",", "gn\u00e4d'\u00b7ger", "Herr", ",", "vom", "Frei\u00b7en", "und", "vom", "Schen\u00b7ken", ":"], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVINF", "$,", "ADJA", "NN", "$,", "APPRART", "NN", "KON", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Ach! gn\u00e4d'ger Herr, das alles w\u00e4r' sehr sch\u00f6n!", "tokens": ["Ach", "!", "gn\u00e4d'\u00b7ger", "Herr", ",", "das", "al\u00b7les", "w\u00e4r'", "sehr", "sch\u00f6n", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$.", "ADJA", "NN", "$,", "PRELS", "PIS", "VAFIN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.15": {"text": "Ich w\u00fcrd' in Sammt und Seide gehn -", "tokens": ["Ich", "w\u00fcrd'", "in", "Sammt", "und", "Sei\u00b7de", "gehn"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "APPR", "NN", "KON", "NN", "VVINF", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Was gehn? Ich w\u00fcrde nicht mehr gehn;", "tokens": ["Was", "gehn", "?", "Ich", "w\u00fcr\u00b7de", "nicht", "mehr", "gehn", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVINF", "$.", "PPER", "VAFIN", "PTKNEG", "ADV", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "Ich w\u00fcrde stolz mit Sechsen fahren.", "tokens": ["Ich", "w\u00fcr\u00b7de", "stolz", "mit", "Sech\u00b7sen", "fah\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.18": {"text": "Mir w\u00fcrden ganze Scharen", "tokens": ["Mir", "w\u00fcr\u00b7den", "gan\u00b7ze", "Scha\u00b7ren"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.19": {"text": "Von Dienern zu Gebote stehn.", "tokens": ["Von", "Die\u00b7nern", "zu", "Ge\u00b7bo\u00b7te", "stehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.20": {"text": "Ach! wie gesagt, das alles w\u00e4r' sehr sch\u00f6n,", "tokens": ["Ach", "!", "wie", "ge\u00b7sagt", ",", "das", "al\u00b7les", "w\u00e4r'", "sehr", "sch\u00f6n", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$.", "PWAV", "VVPP", "$,", "PRELS", "PIS", "VAFIN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.21": {"text": "Wenn ich - wenn ich - -\u00ab", "tokens": ["Wenn", "ich", "wenn", "ich", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$(", "KOUS", "PPER", "$(", "$(", "$("], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.22": {"text": "\u00bb", "tokens": ["\u00bb"], "token_info": ["punct"], "pos": ["$("]}, "line.23": {"text": "(hier sahe man den alten Herrn sich bl\u00e4hn,)", "tokens": ["(", "hier", "sa\u00b7he", "man", "den", "al\u00b7ten", "Herrn", "sich", "bl\u00e4hn", ",", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADV", "VVFIN", "PIS", "ART", "ADJA", "NN", "PRF", "VVINF", "$,", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "\u00bbwenn ich nur nicht verschworen h\u00e4tte - -\u00ab", "tokens": ["\u00bb", "wenn", "ich", "nur", "nicht", "ver\u00b7schwo\u00b7ren", "h\u00e4t\u00b7te", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "PPER", "ADV", "PTKNEG", "VVPP", "VAFIN", "$(", "$(", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "\u00bbverschworen? was? Finette,", "tokens": ["\u00bb", "ver\u00b7schwo\u00b7ren", "?", "was", "?", "Fi\u00b7net\u00b7te", ","], "token_info": ["punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["$(", "VVINF", "$.", "PWS", "$.", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Verschworen nicht zu frein? -", "tokens": ["Ver\u00b7schwo\u00b7ren", "nicht", "zu", "frein", "?"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["NN", "PTKNEG", "PTKZU", "PTKVZ", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "O Grille, rief der Freiherr, Grille!\u00ab", "tokens": ["O", "Gril\u00b7le", ",", "rief", "der", "Frei\u00b7herr", ",", "Gril\u00b7le", "!", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct", "punct"], "pos": ["NE", "NE", "$,", "VVFIN", "ART", "NN", "$,", "NN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Und griff nach seiner Brille,", "tokens": ["Und", "griff", "nach", "sei\u00b7ner", "Bril\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Und nahm das M\u00e4dchen durch die Brille", "tokens": ["Und", "nahm", "das", "M\u00e4d\u00b7chen", "durch", "die", "Bril\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ART", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Nochmals in Augenschein,", "tokens": ["Noch\u00b7mals", "in", "Au\u00b7gen\u00b7schein", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "$,"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.8": {"text": "Und rief best\u00e4ndig: \u00bbGrille! Grille!", "tokens": ["Und", "rief", "be\u00b7st\u00e4n\u00b7dig", ":", "\u00bb", "Gril\u00b7le", "!", "Gril\u00b7le", "!"], "token_info": ["word", "word", "word", "punct", "punct", "word", "punct", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "$.", "$(", "NN", "$.", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Verschworen nicht zu frein!\u00ab", "tokens": ["Ver\u00b7schwo\u00b7ren", "nicht", "zu", "frein", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "PTKNEG", "PTKZU", "PTKVZ", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "\u00bbbeh\u00fcte!\u00ab sprach Finette,", "tokens": ["\u00bb", "be\u00b7h\u00fc\u00b7te", "!", "\u00ab", "sprach", "Fi\u00b7net\u00b7te", ","], "token_info": ["punct", "word", "punct", "punct", "word", "word", "punct"], "pos": ["$(", "VVFIN", "$.", "$(", "VVFIN", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "\u00bbverschworen nur mir keinen Mann zu frein,", "tokens": ["\u00bb", "ver\u00b7schwo\u00b7ren", "nur", "mir", "kei\u00b7nen", "Mann", "zu", "frein", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "ADV", "PPER", "PIAT", "NN", "PTKZU", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Der so, wie Ihre Gnaden pflegt,", "tokens": ["Der", "so", ",", "wie", "Ih\u00b7re", "Gna\u00b7den", "pflegt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "$,", "PWAV", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Augen in der Tasche tr\u00e4gt!\u00ab", "tokens": ["Die", "Au\u00b7gen", "in", "der", "Ta\u00b7sche", "tr\u00e4gt", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "VVFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Dem alten Freiherrn von Chrysant,", "tokens": ["Dem", "al\u00b7ten", "Frei\u00b7herrn", "von", "Chry\u00b7sant", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "NE", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Wagts Amor, einen Streich zu spielen.", "tokens": ["Wagts", "A\u00b7mor", ",", "ei\u00b7nen", "Streich", "zu", "spie\u00b7len", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "F\u00fcr einen Hagestolz bekannt,", "tokens": ["F\u00fcr", "ei\u00b7nen", "Ha\u00b7ge\u00b7stolz", "be\u00b7kannt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Fing, um die Sechzig, er sich wieder an zu f\u00fchlen.", "tokens": ["Fing", ",", "um", "die", "Sech\u00b7zig", ",", "er", "sich", "wie\u00b7der", "an", "zu", "f\u00fch\u00b7len", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "KOUI", "ART", "CARD", "$,", "PPER", "PRF", "ADV", "PTKVZ", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Es flatterte, von Alt und Jung begafft,", "tokens": ["Es", "flat\u00b7ter\u00b7te", ",", "von", "Alt", "und", "Jung", "be\u00b7gafft", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "APPR", "NN", "KON", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Mit Reizen ganz besondrer Kraft,", "tokens": ["Mit", "Rei\u00b7zen", "ganz", "be\u00b7sond\u00b7rer", "Kraft", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ein B\u00fcrgerm\u00e4dchen in der Nachbarschaft.", "tokens": ["Ein", "B\u00fcr\u00b7ger\u00b7m\u00e4d\u00b7chen", "in", "der", "Nach\u00b7bar\u00b7schaft", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Dies B\u00fcrgerm\u00e4dchen hie\u00df Finette.", "tokens": ["Dies", "B\u00fcr\u00b7ger\u00b7m\u00e4d\u00b7chen", "hie\u00df", "Fi\u00b7net\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "NN", "VVFIN", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Finette ward des Freiherrn Siegerin.", "tokens": ["Fi\u00b7net\u00b7te", "ward", "des", "Frei\u00b7herrn", "Sie\u00b7ge\u00b7rin", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Ihr Bild stand mit ihm auf, und ging mit ihm zu Bette.", "tokens": ["Ihr", "Bild", "stand", "mit", "ihm", "auf", ",", "und", "ging", "mit", "ihm", "zu", "Bet\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "APPR", "PPER", "PTKVZ", "$,", "KON", "VVFIN", "APPR", "PPER", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Da dacht' in seinem Sinn", "tokens": ["Da", "dacht'", "in", "sei\u00b7nem", "Sinn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Der Freiherr: \u00bbUnd warum denn nur ihr Bild?", "tokens": ["Der", "Frei\u00b7herr", ":", "\u00bb", "Und", "wa\u00b7rum", "denn", "nur", "ihr", "Bild", "?"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$.", "$(", "KON", "PWAV", "ADV", "ADV", "PPOSAT", "NN", "$."], "meter": "-+---+-+-+", "measure": "dactylic.init"}, "line.5": {"text": "Ihr Bild, das zwar den Kopf, doch nicht die Arme f\u00fcllt?", "tokens": ["Ihr", "Bild", ",", "das", "zwar", "den", "Kopf", ",", "doch", "nicht", "die", "Ar\u00b7me", "f\u00fcllt", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PRELS", "ADV", "ART", "NN", "$,", "ADV", "PTKNEG", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Sie selbst steh' mit mir auf, und geh' mit mir zu Bette.", "tokens": ["Sie", "selbst", "steh'", "mit", "mir", "auf", ",", "und", "geh'", "mit", "mir", "zu", "Bet\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "APPR", "PPER", "PTKVZ", "$,", "KON", "VVFIN", "APPR", "PPER", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Sie werde meine Frau! Es schelte, wer da schilt;", "tokens": ["Sie", "wer\u00b7de", "mei\u00b7ne", "Frau", "!", "Es", "schel\u00b7te", ",", "wer", "da", "schilt", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "NN", "$.", "PPER", "VVFIN", "$,", "PWS", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Gen\u00e4d'ge Tant' und Nicht' und Schw\u00e4gerin!", "tokens": ["Ge\u00b7n\u00e4d'\u00b7ge", "Tant'", "und", "Nicht'", "und", "Schw\u00e4\u00b7ge\u00b7rin", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "KON", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Finett' ist meine Frau, und - ihre Dienerin.\u00ab", "tokens": ["Fi\u00b7nett'", "ist", "mei\u00b7ne", "Frau", ",", "und", "ih\u00b7re", "Die\u00b7ne\u00b7rin", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "VAFIN", "PPOSAT", "NN", "$,", "KON", "$(", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}}, "stanza.11": {"line.1": {"text": "Schon so gewi\u00df? Man wird es h\u00f6ren.", "tokens": ["Schon", "so", "ge\u00b7wi\u00df", "?", "Man", "wird", "es", "h\u00f6\u00b7ren", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "$.", "PIS", "VAFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Der Freiherr k\u00f6mmt, sich zu erkl\u00e4ren,", "tokens": ["Der", "Frei\u00b7herr", "k\u00f6mmt", ",", "sich", "zu", "er\u00b7kl\u00e4\u00b7ren", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "PRF", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Ergreift das M\u00e4dchen bei der Hand,", "tokens": ["Er\u00b7greift", "das", "M\u00e4d\u00b7chen", "bei", "der", "Hand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Tut, wie ein Freiherr, ganz bekannt,", "tokens": ["Tut", ",", "wie", "ein", "Frei\u00b7herr", ",", "ganz", "be\u00b7kannt", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "PWAV", "ART", "NN", "$,", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und spricht: \u00bbIch, Freiherr von Chrysant,", "tokens": ["Und", "spricht", ":", "\u00bb", "Ich", ",", "Frei\u00b7herr", "von", "Chry\u00b7sant", ","], "token_info": ["word", "word", "punct", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "$(", "PPER", "$,", "NN", "APPR", "NE", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Ich habe Sie, mein Kind, zu meiner Frau ersehen.", "tokens": ["Ich", "ha\u00b7be", "Sie", ",", "mein", "Kind", ",", "zu", "mei\u00b7ner", "Frau", "er\u00b7se\u00b7hen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "$,", "PPOSAT", "NN", "$,", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Sie wird sich hoffentlich nicht selbst im Lichte stehen.", "tokens": ["Sie", "wird", "sich", "hof\u00b7fent\u00b7lich", "nicht", "selbst", "im", "Lich\u00b7te", "ste\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PRF", "ADV", "PTKNEG", "ADV", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-++--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.8": {"text": "Ich habe Guts die H\u00fcll' und F\u00fclle.\u00ab", "tokens": ["Ich", "ha\u00b7be", "Guts", "die", "H\u00fcll'", "und", "F\u00fcl\u00b7le", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VAFIN", "NN", "ART", "NN", "KON", "NN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Und hierauf las er ihr, durch eine gro\u00dfe Brille", "tokens": ["Und", "hier\u00b7auf", "las", "er", "ihr", ",", "durch", "ei\u00b7ne", "gro\u00b7\u00dfe", "Bril\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "PAV", "VVFIN", "PPER", "PPER", "$,", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Von einem gro\u00dfen Zettel ab,", "tokens": ["Von", "ei\u00b7nem", "gro\u00b7\u00dfen", "Zet\u00b7tel", "ab", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Wie viel ihm Gott an G\u00fctern gab;", "tokens": ["Wie", "viel", "ihm", "Gott", "an", "G\u00fc\u00b7tern", "gab", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "PPER", "NN", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Wie reich er sie beschenken wolle;", "tokens": ["Wie", "reich", "er", "sie", "be\u00b7schen\u00b7ken", "wol\u00b7le", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "PPER", "PPER", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Welch gro\u00dfen Witwenschatz sie einmal haben solle.", "tokens": ["Welch", "gro\u00b7\u00dfen", "Wit\u00b7wen\u00b7schatz", "sie", "ein\u00b7mal", "ha\u00b7ben", "sol\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "PPER", "ADV", "VAINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Dies alles las der reiche Mann", "tokens": ["Dies", "al\u00b7les", "las", "der", "rei\u00b7che", "Mann"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "PIS", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Ihr von dem Zettel ab, und guckte durch die Brille", "tokens": ["Ihr", "von", "dem", "Zet\u00b7tel", "ab", ",", "und", "guck\u00b7te", "durch", "die", "Bril\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "APPR", "ART", "NN", "PTKVZ", "$,", "KON", "VVFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Bei jedem Punkte sie begierig an.", "tokens": ["Bei", "je\u00b7dem", "Punk\u00b7te", "sie", "be\u00b7gie\u00b7rig", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "PPER", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.12": {"line.1": {"text": "\u00bbnun, Kind, was ist Ihr Wille?\u00ab", "tokens": ["\u00bb", "nun", ",", "Kind", ",", "was", "ist", "Ihr", "Wil\u00b7le", "?", "\u00ab"], "token_info": ["punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADV", "$,", "NN", "$,", "PWS", "VAFIN", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Mit diesen Worten schwieg der Freiherr stille,", "tokens": ["Mit", "die\u00b7sen", "Wor\u00b7ten", "schwieg", "der", "Frei\u00b7herr", "stil\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "VVFIN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und nahm mit diesen Worten seine Brille -", "tokens": ["Und", "nahm", "mit", "die\u00b7sen", "Wor\u00b7ten", "sei\u00b7ne", "Bril\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "PDAT", "NN", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "(denn, dacht' er, wird das M\u00e4dchen nun", "tokens": ["(", "denn", ",", "dacht'", "er", ",", "wird", "das", "M\u00e4d\u00b7chen", "nun"], "token_info": ["punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["$(", "ADV", "$,", "VVFIN", "PPER", "$,", "VAFIN", "ART", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "So wie ein kluges M\u00e4dchen tun;", "tokens": ["So", "wie", "ein", "klu\u00b7ges", "M\u00e4d\u00b7chen", "tun", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wird mich und sie ihr schnelles Ja begl\u00fccken;", "tokens": ["Wird", "mich", "und", "sie", "ihr", "schnel\u00b7les", "Ja", "be\u00b7gl\u00fc\u00b7cken", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "KON", "PPER", "PPOSAT", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Werd' ich den ersten Ku\u00df auf ihre Lippen dr\u00fccken:", "tokens": ["Werd'", "ich", "den", "ers\u00b7ten", "Ku\u00df", "auf", "ih\u00b7re", "Lip\u00b7pen", "dr\u00fc\u00b7cken", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "So k\u00f6nnt' ich, im Entz\u00fccken,", "tokens": ["So", "k\u00f6nnt'", "ich", ",", "im", "Ent\u00b7z\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "$,", "APPRART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.9": {"text": "Die teure Brille leicht zerknicken!) -", "tokens": ["Die", "teu\u00b7re", "Bril\u00b7le", "leicht", "zer\u00b7kni\u00b7cken", "!", ")"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word"], "pos": ["ART", "ADJA", "NN", "ADJD", "VVINF", "$.", "$(", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Die teure Brille wohlbed\u00e4chtig ab.", "tokens": ["Die", "teu\u00b7re", "Bril\u00b7le", "wohl\u00b7be\u00b7d\u00e4ch\u00b7tig", "ab", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Finette, der dies Zeit sich zu bedenken gab,", "tokens": ["Fi\u00b7net\u00b7te", ",", "der", "dies", "Zeit", "sich", "zu", "be\u00b7den\u00b7ken", "gab", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PRELS", "PDS", "NN", "PRF", "PTKZU", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Bedachte sich, und sprach nach reiflichem Bedenken:", "tokens": ["Be\u00b7dach\u00b7te", "sich", ",", "und", "sprach", "nach", "reif\u00b7li\u00b7chem", "Be\u00b7den\u00b7ken", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "$,", "KON", "VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "\u00bbsie sprechen, gn\u00e4d'ger Herr, vom Freien und vom Schenken:", "tokens": ["\u00bb", "sie", "spre\u00b7chen", ",", "gn\u00e4d'\u00b7ger", "Herr", ",", "vom", "Frei\u00b7en", "und", "vom", "Schen\u00b7ken", ":"], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVINF", "$,", "ADJA", "NN", "$,", "APPRART", "NN", "KON", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Ach! gn\u00e4d'ger Herr, das alles w\u00e4r' sehr sch\u00f6n!", "tokens": ["Ach", "!", "gn\u00e4d'\u00b7ger", "Herr", ",", "das", "al\u00b7les", "w\u00e4r'", "sehr", "sch\u00f6n", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$.", "ADJA", "NN", "$,", "PRELS", "PIS", "VAFIN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.15": {"text": "Ich w\u00fcrd' in Sammt und Seide gehn -", "tokens": ["Ich", "w\u00fcrd'", "in", "Sammt", "und", "Sei\u00b7de", "gehn"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "APPR", "NN", "KON", "NN", "VVINF", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Was gehn? Ich w\u00fcrde nicht mehr gehn;", "tokens": ["Was", "gehn", "?", "Ich", "w\u00fcr\u00b7de", "nicht", "mehr", "gehn", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVINF", "$.", "PPER", "VAFIN", "PTKNEG", "ADV", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "Ich w\u00fcrde stolz mit Sechsen fahren.", "tokens": ["Ich", "w\u00fcr\u00b7de", "stolz", "mit", "Sech\u00b7sen", "fah\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.18": {"text": "Mir w\u00fcrden ganze Scharen", "tokens": ["Mir", "w\u00fcr\u00b7den", "gan\u00b7ze", "Scha\u00b7ren"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.19": {"text": "Von Dienern zu Gebote stehn.", "tokens": ["Von", "Die\u00b7nern", "zu", "Ge\u00b7bo\u00b7te", "stehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.20": {"text": "Ach! wie gesagt, das alles w\u00e4r' sehr sch\u00f6n,", "tokens": ["Ach", "!", "wie", "ge\u00b7sagt", ",", "das", "al\u00b7les", "w\u00e4r'", "sehr", "sch\u00f6n", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$.", "PWAV", "VVPP", "$,", "PRELS", "PIS", "VAFIN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.21": {"text": "Wenn ich - wenn ich - -\u00ab", "tokens": ["Wenn", "ich", "wenn", "ich", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$(", "KOUS", "PPER", "$(", "$(", "$("], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.22": {"text": "\u00bb", "tokens": ["\u00bb"], "token_info": ["punct"], "pos": ["$("]}, "line.23": {"text": "(hier sahe man den alten Herrn sich bl\u00e4hn,)", "tokens": ["(", "hier", "sa\u00b7he", "man", "den", "al\u00b7ten", "Herrn", "sich", "bl\u00e4hn", ",", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADV", "VVFIN", "PIS", "ART", "ADJA", "NN", "PRF", "VVINF", "$,", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.13": {"line.1": {"text": "\u00bbwenn ich nur nicht verschworen h\u00e4tte - -\u00ab", "tokens": ["\u00bb", "wenn", "ich", "nur", "nicht", "ver\u00b7schwo\u00b7ren", "h\u00e4t\u00b7te", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "PPER", "ADV", "PTKNEG", "VVPP", "VAFIN", "$(", "$(", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "\u00bbverschworen? was? Finette,", "tokens": ["\u00bb", "ver\u00b7schwo\u00b7ren", "?", "was", "?", "Fi\u00b7net\u00b7te", ","], "token_info": ["punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["$(", "VVINF", "$.", "PWS", "$.", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Verschworen nicht zu frein? -", "tokens": ["Ver\u00b7schwo\u00b7ren", "nicht", "zu", "frein", "?"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["NN", "PTKNEG", "PTKZU", "PTKVZ", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "O Grille, rief der Freiherr, Grille!\u00ab", "tokens": ["O", "Gril\u00b7le", ",", "rief", "der", "Frei\u00b7herr", ",", "Gril\u00b7le", "!", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct", "punct"], "pos": ["NE", "NE", "$,", "VVFIN", "ART", "NN", "$,", "NN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Und griff nach seiner Brille,", "tokens": ["Und", "griff", "nach", "sei\u00b7ner", "Bril\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Und nahm das M\u00e4dchen durch die Brille", "tokens": ["Und", "nahm", "das", "M\u00e4d\u00b7chen", "durch", "die", "Bril\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ART", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Nochmals in Augenschein,", "tokens": ["Noch\u00b7mals", "in", "Au\u00b7gen\u00b7schein", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "$,"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.8": {"text": "Und rief best\u00e4ndig: \u00bbGrille! Grille!", "tokens": ["Und", "rief", "be\u00b7st\u00e4n\u00b7dig", ":", "\u00bb", "Gril\u00b7le", "!", "Gril\u00b7le", "!"], "token_info": ["word", "word", "word", "punct", "punct", "word", "punct", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "$.", "$(", "NN", "$.", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Verschworen nicht zu frein!\u00ab", "tokens": ["Ver\u00b7schwo\u00b7ren", "nicht", "zu", "frein", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "PTKNEG", "PTKZU", "PTKVZ", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.14": {"line.1": {"text": "\u00bbbeh\u00fcte!\u00ab sprach Finette,", "tokens": ["\u00bb", "be\u00b7h\u00fc\u00b7te", "!", "\u00ab", "sprach", "Fi\u00b7net\u00b7te", ","], "token_info": ["punct", "word", "punct", "punct", "word", "word", "punct"], "pos": ["$(", "VVFIN", "$.", "$(", "VVFIN", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "\u00bbverschworen nur mir keinen Mann zu frein,", "tokens": ["\u00bb", "ver\u00b7schwo\u00b7ren", "nur", "mir", "kei\u00b7nen", "Mann", "zu", "frein", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "ADV", "PPER", "PIAT", "NN", "PTKZU", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Der so, wie Ihre Gnaden pflegt,", "tokens": ["Der", "so", ",", "wie", "Ih\u00b7re", "Gna\u00b7den", "pflegt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "$,", "PWAV", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Augen in der Tasche tr\u00e4gt!\u00ab", "tokens": ["Die", "Au\u00b7gen", "in", "der", "Ta\u00b7sche", "tr\u00e4gt", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "VVFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}