{"dta.poem.8611": {"metadata": {"author": {"name": "Lenau, Nikolaus", "birth": "N.A.", "death": "N.A."}, "title": "Marie und Wilhelm.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1832", "urn": "urn:nbn:de:kobv:b4-200905193572", "language": ["de:0.99"], "booktitle": "Lenau, Nikolaus: Gedichte. Stuttgart, 1832."}, "poem": {"stanza.1": {"line.1": {"text": "Im Abendschein am Fenster sa\u00df", "tokens": ["Im", "A\u00b7bend\u00b7schein", "am", "Fens\u00b7ter", "sa\u00df"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "APPRART", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Allein mit ihrem Harme", "tokens": ["Al\u00b7lein", "mit", "ih\u00b7rem", "Har\u00b7me"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Marie, das Antlitz welk und bla\u00df", "tokens": ["Ma\u00b7rie", ",", "das", "Ant\u00b7litz", "welk", "und", "bla\u00df"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NE", "$,", "ART", "NN", "ADJD", "KON", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Gesenkt auf ihre Arme.", "tokens": ["Ge\u00b7senkt", "auf", "ih\u00b7re", "Ar\u00b7me", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVPP", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "So sa\u00df das M\u00e4dchen still und sann,", "tokens": ["So", "sa\u00df", "das", "M\u00e4d\u00b7chen", "still", "und", "sann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "PTKVZ", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sann nach den alten Zeiten,", "tokens": ["Sann", "nach", "den", "al\u00b7ten", "Zei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und manche hei\u00dfe Thr\u00e4ne rann", "tokens": ["Und", "man\u00b7che", "hei\u00b7\u00dfe", "Thr\u00e4\u00b7ne", "rann"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PIAT", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Den sch\u00f6nen alten Zeiten:", "tokens": ["Den", "sch\u00f6\u00b7nen", "al\u00b7ten", "Zei\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Als sie im trauten H\u00fcttlein noch", "tokens": ["Als", "sie", "im", "trau\u00b7ten", "H\u00fctt\u00b7lein", "noch"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPRART", "ADJA", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Bei lieben Eltern wohnte,", "tokens": ["Bei", "lie\u00b7ben", "El\u00b7tern", "wohn\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und s\u00fc\u00dfer Gottesfriede noch", "tokens": ["Und", "s\u00fc\u00b7\u00dfer", "Got\u00b7tes\u00b7frie\u00b7de", "noch"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ADJA", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der reinen Seele lohnte;", "tokens": ["Der", "rei\u00b7nen", "See\u00b7le", "lohn\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Als sie so fromm zur Kirche ging,", "tokens": ["Als", "sie", "so", "fromm", "zur", "Kir\u00b7che", "ging", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und ihre Wange gl\u00fchte,", "tokens": ["Und", "ih\u00b7re", "Wan\u00b7ge", "gl\u00fch\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Wenn jedes Aug' im Dorfe hing", "tokens": ["Wenn", "je\u00b7des", "Aug'", "im", "Dor\u00b7fe", "hing"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PIAT", "NN", "APPRART", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "An ihrer Jugendbl\u00fcthe.", "tokens": ["An", "ih\u00b7rer", "Ju\u00b7gend\u00b7bl\u00fc\u00b7the", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Als sie am lauten Erlenbach", "tokens": ["Als", "sie", "am", "lau\u00b7ten", "Er\u00b7len\u00b7bach"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dem Wilhelm, freudetrunken,", "tokens": ["Dem", "Wil\u00b7helm", ",", "freu\u00b7de\u00b7trun\u00b7ken", ","], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["ART", "NE", "$,", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Das erste Wort der Liebe sprach,", "tokens": ["Das", "ers\u00b7te", "Wort", "der", "Lie\u00b7be", "sprach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und ihm ans Herz gesunken;", "tokens": ["Und", "ihm", "ans", "Herz", "ge\u00b7sun\u00b7ken", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Und er sie nannte \u201es\u00fc\u00dfe Braut!\u201c \u2014", "tokens": ["Und", "er", "sie", "nann\u00b7te", "\u201e", "s\u00fc\u00b7\u00dfe", "Braut", "!", "\u201c"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "punct", "punct"], "pos": ["KON", "PPER", "PPER", "VVFIN", "$(", "ADJA", "NN", "$.", "$(", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u201edas Alles ist vor\u00fcber!\u201c", "tokens": ["\u201e", "das", "Al\u00b7les", "ist", "vor\u00b7\u00fc\u00b7ber", "!", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PDS", "PIS", "VAFIN", "ADV", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "So dachte sie, und schluchzte laut,", "tokens": ["So", "dach\u00b7te", "sie", ",", "und", "schluchz\u00b7te", "laut", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "KON", "VVFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ihr Herz ward immer tr\u00fcber.", "tokens": ["Ihr", "Herz", "ward", "im\u00b7mer", "tr\u00fc\u00b7ber", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADV", "ADJD", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "\u201ees kam der Feind im Sturmeslauf", "tokens": ["\u201e", "es", "kam", "der", "Feind", "im", "Stur\u00b7mes\u00b7lauf"], "token_info": ["punct", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "PPER", "VVFIN", "ART", "NN", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u201emit grimmen Todesstreichen;", "tokens": ["\u201e", "mit", "grim\u00b7men", "To\u00b7des\u00b7strei\u00b7chen", ";"], "token_info": ["punct", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "\u201edas H\u00fcttlein sank ein Aschenhauf,", "tokens": ["\u201e", "das", "H\u00fctt\u00b7lein", "sank", "ein", "A\u00b7schen\u00b7hauf", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "\u201edie Eltern \u2014 wunde Leichen.", "tokens": ["\u201e", "die", "El\u00b7tern", "wun\u00b7de", "Lei\u00b7chen", "."], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "$(", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "\u201edie Eltern todt! Er in die Welt!", "tokens": ["\u201e", "die", "El\u00b7tern", "todt", "!", "Er", "in", "die", "Welt", "!"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "ADJD", "$.", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u201edie Thr\u00e4ne rann vergebens!", "tokens": ["\u201e", "die", "Thr\u00e4\u00b7ne", "rann", "ver\u00b7ge\u00b7bens", "!"], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "VVFIN", "ADV", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "\u201eich in die Nacht hinausgestellt", "tokens": ["\u201e", "ich", "in", "die", "Nacht", "hin\u00b7aus\u00b7ge\u00b7stellt"], "token_info": ["punct", "word", "word", "word", "word", "word"], "pos": ["$(", "PPER", "APPR", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "\u201edes unbekannten Lebens! \u2014", "tokens": ["\u201e", "des", "un\u00b7be\u00b7kann\u00b7ten", "Le\u00b7bens", "!"], "token_info": ["punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ART", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "\u201eda gl\u00e4nzt' ein milder Strahl daher", "tokens": ["\u201e", "da", "gl\u00e4nzt'", "ein", "mil\u00b7der", "Strahl", "da\u00b7her"], "token_info": ["punct", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "ADV", "VVFIN", "ART", "ADJA", "NN", "PAV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u201eim hoffnunglosen Dunkel,", "tokens": ["\u201e", "im", "hoff\u00b7nun\u00b7glo\u00b7sen", "Dun\u00b7kel", ","], "token_info": ["punct", "word", "word", "word", "punct"], "pos": ["$(", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "\u201eein b\u00f6ses Irrlicht, lockend sehr", "tokens": ["\u201e", "ein", "b\u00f6\u00b7ses", "Irr\u00b7licht", ",", "lo\u00b7ckend", "sehr"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word"], "pos": ["$(", "ART", "ADJA", "NN", "$,", "ADJD", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "\u201emit lieblichem Gefunkel:\u201c", "tokens": ["\u201e", "mit", "lieb\u00b7li\u00b7chem", "Ge\u00b7fun\u00b7kel", ":", "\u201c"], "token_info": ["punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "APPR", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "\u201e\u201eLa\u00df ab zu klagen, Kind, la\u00df ab!", "tokens": ["\u201e", "\u201e", "La\u00df", "ab", "zu", "kla\u00b7gen", ",", "Kind", ",", "la\u00df", "ab", "!"], "token_info": ["punct", "punct", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["$(", "$(", "VVIMP", "PTKVZ", "PTKZU", "VVINF", "$,", "NN", "$,", "VVIMP", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u201e\u201eKomm, folge deinem Sterne!", "tokens": ["\u201e", "\u201e", "Komm", ",", "fol\u00b7ge", "dei\u00b7nem", "Ster\u00b7ne", "!"], "token_info": ["punct", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "$(", "VVFIN", "$,", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "\u201e\u201eDie Eltern k\u00fchlt und heilt das Grab,", "tokens": ["\u201e", "\u201e", "Die", "El\u00b7tern", "k\u00fchlt", "und", "heilt", "das", "Grab", ","], "token_info": ["punct", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "$(", "ART", "NN", "VVFIN", "KON", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "\u201e\u201eDen Br\u00e4utigam die Ferne!\u201c\u201c", "tokens": ["\u201e", "\u201e", "Den", "Br\u00e4u\u00b7ti\u00b7gam", "die", "Fer\u00b7ne", "!", "\u201c", "\u201c"], "token_info": ["punct", "punct", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["$(", "$(", "ART", "NE", "ART", "NN", "$.", "$(", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "\u201e\u201eBald sollst du als begl\u00fcckte Frau", "tokens": ["\u201e", "\u201e", "Bald", "sollst", "du", "als", "be\u00b7gl\u00fcck\u00b7te", "Frau"], "token_info": ["punct", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "$(", "ADV", "VMFIN", "PPER", "KOUS", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u201e\u201eGenesen aller Leiden;", "tokens": ["\u201e", "\u201e", "Ge\u00b7ne\u00b7sen", "al\u00b7ler", "Lei\u00b7den", ";"], "token_info": ["punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "$(", "NN", "PIAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "\u201e\u201eKomm, folge mir zur Liebesau", "tokens": ["\u201e", "\u201e", "Komm", ",", "fol\u00b7ge", "mir", "zur", "Lie\u00b7be\u00b7sau"], "token_info": ["punct", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["$(", "$(", "VVFIN", "$,", "VVFIN", "PPER", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "\u201e\u201eVoll ewig gr\u00fcner Freuden!\u201c\u201c", "tokens": ["\u201e", "\u201e", "Voll", "e\u00b7wig", "gr\u00fc\u00b7ner", "Freu\u00b7den", "!", "\u201c", "\u201c"], "token_info": ["punct", "punct", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["$(", "$(", "ADJD", "ADJD", "ADJA", "NN", "$.", "$(", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "\u201eich wischte mit treuloser Hand", "tokens": ["\u201e", "ich", "wischte", "mit", "treu\u00b7lo\u00b7ser", "Hand"], "token_info": ["punct", "word", "word", "word", "word", "word"], "pos": ["$(", "PPER", "VVFIN", "APPR", "ADJA", "NN"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.2": {"text": "\u201edie Thr\u00e4nen von der Wange,", "tokens": ["\u201e", "die", "Thr\u00e4\u00b7nen", "von", "der", "Wan\u00b7ge", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "\u201eund ging \u2014 und ging \u2014 das Irrlicht schwand", "tokens": ["\u201e", "und", "ging", "und", "ging", "das", "Irr\u00b7licht", "schwand"], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["$(", "KON", "VVFIN", "$(", "KON", "VVFIN", "$(", "ART", "NN", "VVFIN"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.4": {"text": "\u201eam furchtbar steilen Hange!", "tokens": ["\u201e", "am", "furcht\u00b7bar", "stei\u00b7len", "Han\u00b7ge", "!"], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PTKA", "ADJD", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.13": {"line.1": {"text": "\u201enun ist mein Herz so grabesdumpf,", "tokens": ["\u201e", "nun", "ist", "mein", "Herz", "so", "gra\u00b7bes\u00b7dumpf", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VAFIN", "PPOSAT", "NN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u201everlassen wie die W\u00fcste,", "tokens": ["\u201e", "ver\u00b7las\u00b7sen", "wie", "die", "W\u00fcs\u00b7te", ","], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVPP", "KOKOM", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "\u201eseit in den bodenlosen Sumpf", "tokens": ["\u201e", "seit", "in", "den", "bo\u00b7den\u00b7lo\u00b7sen", "Sumpf"], "token_info": ["punct", "word", "word", "word", "word", "word"], "pos": ["$(", "ADV", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "\u201egesunken ich der L\u00fcste!\u201c \u2014", "tokens": ["\u201e", "ge\u00b7sun\u00b7ken", "ich", "der", "L\u00fcs\u00b7te", "!", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["$(", "VVPP", "PPER", "ART", "NN", "$.", "$(", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.14": {"line.1": {"text": "Marie blickt in die Nacht hinein", "tokens": ["Ma\u00b7rie", "blickt", "in", "die", "Nacht", "hin\u00b7ein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "APPR", "ART", "NN", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Aus ihrem stillen Zimmer;", "tokens": ["Aus", "ih\u00b7rem", "stil\u00b7len", "Zim\u00b7mer", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Schon ist am Himmel Sternenschein", "tokens": ["Schon", "ist", "am", "Him\u00b7mel", "Ster\u00b7nen\u00b7schein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "APPRART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und sanfter Mondenschimmer.", "tokens": ["Und", "sanf\u00b7ter", "Mon\u00b7den\u00b7schim\u00b7mer", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.15": {"line.1": {"text": "Im Garten ruft die Nachtigall,", "tokens": ["Im", "Gar\u00b7ten", "ruft", "die", "Nach\u00b7ti\u00b7gall", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sie scheint in bangen Weisen", "tokens": ["Sie", "scheint", "in", "ban\u00b7gen", "Wei\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Zu klagen um des M\u00e4dchens Fall,", "tokens": ["Zu", "kla\u00b7gen", "um", "des", "M\u00e4d\u00b7chens", "Fall", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "APPR", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Unschuld s\u00fc\u00df zu preisen.", "tokens": ["Die", "Un\u00b7schuld", "s\u00fc\u00df", "zu", "prei\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.16": {"line.1": {"text": "Und leise kommt der Abendwind,", "tokens": ["Und", "lei\u00b7se", "kommt", "der", "Ab\u00b7end\u00b7wind", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der ihren Locken schmeichelt,", "tokens": ["Der", "ih\u00b7ren", "Lo\u00b7cken", "schmei\u00b7chelt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Als wollt' er tr\u00f6sten, ihr gelind", "tokens": ["Als", "wollt'", "er", "tr\u00f6s\u00b7ten", ",", "ihr", "ge\u00b7lind"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["KOUS", "VMFIN", "PPER", "VVINF", "$,", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die bleiche Wange streichelt.", "tokens": ["Die", "blei\u00b7che", "Wan\u00b7ge", "strei\u00b7chelt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.17": {"line.1": {"text": "Geh fort, o West, vom M\u00e4dchen, geh!", "tokens": ["Geh", "fort", ",", "o", "West", ",", "vom", "M\u00e4d\u00b7chen", ",", "geh", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["NE", "PTKVZ", "$,", "FM", "FM", "$,", "APPRART", "NN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "La\u00df ruhn den welken Flieder!", "tokens": ["La\u00df", "ruhn", "den", "wel\u00b7ken", "Flie\u00b7der", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Du thust ihr mit den Bl\u00fcthen weh,", "tokens": ["Du", "thust", "ihr", "mit", "den", "Bl\u00fc\u00b7then", "weh", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die du auf sie streust nieder! \u2014 \u2014", "tokens": ["Die", "du", "auf", "sie", "streust", "nie\u00b7der", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["ART", "PPER", "APPR", "PPER", "VVFIN", "PTKVZ", "$.", "$(", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.18": {"line.1": {"text": "Da \u00f6ffnet sich das K\u00e4mmerlein:", "tokens": ["Da", "\u00f6ff\u00b7net", "sich", "das", "K\u00e4m\u00b7mer\u00b7lein", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Es ruft ein Mann: \u201eMaria!\u201c", "tokens": ["Es", "ruft", "ein", "Mann", ":", "\u201e", "Ma\u00b7ria", "!", "\u201c"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$.", "$(", "NE", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Die Freude sto\u00dft ihn wild herein:", "tokens": ["Die", "Freu\u00b7de", "sto\u00dft", "ihn", "wild", "her\u00b7ein", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "\u201eo meine Braut Maria!\u201c", "tokens": ["\u201e", "o", "mei\u00b7ne", "Braut", "Ma\u00b7ria", "!", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "FM", "PPOSAT", "NN", "NE", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.19": {"line.1": {"text": "\u201eich habe nun mein Gl\u00fcck erjagt,", "tokens": ["\u201e", "ich", "ha\u00b7be", "nun", "mein", "Gl\u00fcck", "er\u00b7jagt", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "ADV", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u201emich durch die Welt getrieben;", "tokens": ["\u201e", "mich", "durch", "die", "Welt", "ge\u00b7trie\u00b7ben", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "\u201ehab' viel gelitten, viel gewagt,", "tokens": ["\u201e", "hab'", "viel", "ge\u00b7lit\u00b7ten", ",", "viel", "ge\u00b7wagt", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "VAFIN", "ADV", "VVPP", "$,", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "\u201eund bin dir treu geblieben!\u201c", "tokens": ["\u201e", "und", "bin", "dir", "treu", "ge\u00b7blie\u00b7ben", "!", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "KON", "VAFIN", "PPER", "ADJD", "VVPP", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.20": {"line.1": {"text": "\u201ewenn schier mein Herz vor Leide brach", "tokens": ["\u201e", "wenn", "schier", "mein", "Herz", "vor", "Lei\u00b7de", "brach"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "KOUS", "PPER", "PPOSAT", "NN", "APPR", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u201ean lieblos fremdem Orte,", "tokens": ["\u201e", "an", "lieb\u00b7los", "frem\u00b7dem", "Or\u00b7te", ","], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "\u201eso dacht' ich an den Erlenbach,", "tokens": ["\u201e", "so", "dacht'", "ich", "an", "den", "Er\u00b7len\u00b7bach", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "\u201eich dacht' an deine Worte!\u201c \u2014", "tokens": ["\u201e", "ich", "dacht'", "an", "dei\u00b7ne", "Wor\u00b7te", "!", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["$(", "PPER", "VVFIN", "APPR", "PPOSAT", "NN", "$.", "$(", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.21": {"line.1": {"text": "Er pre\u00dft sie selig an das Herz;", "tokens": ["Er", "pre\u00dft", "sie", "se\u00b7lig", "an", "das", "Herz", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADJD", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sie aber mu\u00df sich wenden,", "tokens": ["Sie", "a\u00b7ber", "mu\u00df", "sich", "wen\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VMFIN", "PRF", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Sie h\u00fcllt, zerknickt von ihrem Schmerz,", "tokens": ["Sie", "h\u00fcllt", ",", "zer\u00b7knickt", "von", "ih\u00b7rem", "Schmerz", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Das Antlitz mit den H\u00e4nden.", "tokens": ["Das", "Ant\u00b7litz", "mit", "den", "H\u00e4n\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.22": {"line.1": {"text": "Und leichenbla\u00df und zitternd bricht,", "tokens": ["Und", "lei\u00b7chen\u00b7bla\u00df", "und", "zit\u00b7ternd", "bricht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "KON", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sie hin zu seinen F\u00fc\u00dfen;", "tokens": ["Sie", "hin", "zu", "sei\u00b7nen", "F\u00fc\u00b7\u00dfen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Er weint, er deckt ihr Angesicht", "tokens": ["Er", "weint", ",", "er", "deckt", "ihr", "An\u00b7ge\u00b7sicht"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mit feurig bangen K\u00fcssen.", "tokens": ["Mit", "feu\u00b7rig", "ban\u00b7gen", "K\u00fcs\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJD", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.23": {"line.1": {"text": "\u201emir nicht den Ku\u00df! bin sein nicht werth;", "tokens": ["\u201e", "mir", "nicht", "den", "Ku\u00df", "!", "bin", "sein", "nicht", "werth", ";"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "PTKNEG", "ART", "NN", "$.", "VAFIN", "PPOSAT", "PTKNEG", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u201etief sank ich ins Verderben!", "tokens": ["\u201e", "tief", "sank", "ich", "ins", "Ver\u00b7der\u00b7ben", "!"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "VVFIN", "PPER", "APPRART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "\u201ebin treulos, Wilhelm, und entehrt!", "tokens": ["\u201e", "bin", "treu\u00b7los", ",", "Wil\u00b7helm", ",", "und", "ent\u00b7ehrt", "!"], "token_info": ["punct", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["$(", "VAFIN", "ADJD", "$,", "NE", "$,", "KON", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "\u201ezieh fort, und la\u00df mich sterben!\u201c \u2014", "tokens": ["\u201e", "zieh", "fort", ",", "und", "la\u00df", "mich", "ster\u00b7ben", "!", "\u201c"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["$(", "VVFIN", "PTKVZ", "$,", "KON", "VVIMP", "PPER", "VVINF", "$.", "$(", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.24": {"line.1": {"text": "Wie also sie zu Wilhelm sprach,", "tokens": ["Wie", "al\u00b7so", "sie", "zu", "Wil\u00b7helm", "sprach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "PPER", "APPR", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da schied er, schwer beklommen,", "tokens": ["Da", "schied", "er", ",", "schwer", "be\u00b7klom\u00b7men", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Ging still hinaus zum Erlenbach,", "tokens": ["Ging", "still", "hin\u00b7aus", "zum", "Er\u00b7len\u00b7bach", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "ADV", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der ihn mit fort genommen.", "tokens": ["Der", "ihn", "mit", "fort", "ge\u00b7nom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "PTKVZ", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}}}}