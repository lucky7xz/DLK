{"textgrid.poem.53941": {"metadata": {"author": {"name": "Tucholsky, Kurt", "birth": "N.A.", "death": "N.A."}, "title": "Wenn die Igel in der Abendstunde", "genre": "verse", "period": "N.A.", "pub_year": 1912, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wenn die Igel in der Abendstunde", "tokens": ["Wenn", "die", "I\u00b7gel", "in", "der", "A\u00b7bends\u00b7tun\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "APPR", "ART", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "still nach ihren M\u00e4usen gehn,", "tokens": ["still", "nach", "ih\u00b7ren", "M\u00e4u\u00b7sen", "gehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "PPOSAT", "NN", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "hing auch ich verz\u00fcckt an deinem Munde,", "tokens": ["hing", "auch", "ich", "ver\u00b7z\u00fcckt", "an", "dei\u00b7nem", "Mun\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PPER", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "und es war um mich geschehn \u2013", "tokens": ["und", "es", "war", "um", "mich", "ge\u00b7schehn", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "APPR", "PPER", "VVPP", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Anna-Luise \u2013!", "tokens": ["An\u00b7na\u00b7Lui\u00b7se", "\u2013", "!"], "token_info": ["word", "punct", "punct"], "pos": ["NE", "$(", "$."], "meter": "+-+-", "measure": "trochaic.di"}}, "stanza.2": {"line.1": {"text": "Dein Papa ist k\u00fchn und Geometer,", "tokens": ["Dein", "Pa\u00b7pa", "ist", "k\u00fchn", "und", "Geo\u00b7me\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADJD", "KON", "NN", "$,"], "meter": "--+-+-+--", "measure": "anapaest.init"}, "line.2": {"text": "er hat zwei Kanarienv\u00f6gelein;", "tokens": ["er", "hat", "zwei", "Ka\u00b7na\u00b7ri\u00b7en\u00b7v\u00f6\u00b7ge\u00b7lein", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "CARD", "NN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "auf den Sonnabend aber geht er", "tokens": ["auf", "den", "Sonn\u00b7a\u00b7bend", "a\u00b7ber", "geht", "er"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ADV", "VVFIN", "PPER"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "gern zum Pilsner in 'n Gesangverein \u2013", "tokens": ["gern", "zum", "Pils\u00b7ner", "in", "'n", "Ge\u00b7sang\u00b7ver\u00b7ein", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "APPR", "ART", "NN", "$("], "meter": "--+--+-+-+", "measure": "anapaest.di.plus"}, "line.5": {"text": "Anna-Luise \u2013!", "tokens": ["An\u00b7na\u00b7Lui\u00b7se", "\u2013", "!"], "token_info": ["word", "punct", "punct"], "pos": ["NE", "$(", "$."], "meter": "+-+-", "measure": "trochaic.di"}}, "stanza.3": {"line.1": {"text": "Sagt' ich: \u00bbWirst die meine du in B\u00e4lde?\u00ab,", "tokens": ["Sagt'", "ich", ":", "\u00bb", "Wirst", "die", "mei\u00b7ne", "du", "in", "B\u00e4l\u00b7de", "?", "\u00ab", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["VVFIN", "PPER", "$.", "$(", "VAFIN", "ART", "VVFIN", "PPER", "APPR", "NN", "$.", "$(", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "blicktest du voll s\u00fc\u00dfer Tr\u00e4umerei", "tokens": ["blick\u00b7test", "du", "voll", "s\u00fc\u00b7\u00dfer", "Tr\u00e4u\u00b7me\u00b7rei"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADJD", "ADJA", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "auf das gr\u00fcne Vandervelde,", "tokens": ["auf", "das", "gr\u00fc\u00b7ne", "Van\u00b7der\u00b7vel\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "und du dachtest dir dein Teil dabei,", "tokens": ["und", "du", "dach\u00b7test", "dir", "dein", "Teil", "da\u00b7bei", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPER", "PPOSAT", "NN", "PAV", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.5": {"text": "Anna-Luise \u2013!", "tokens": ["An\u00b7na\u00b7Lui\u00b7se", "\u2013", "!"], "token_info": ["word", "punct", "punct"], "pos": ["NE", "$(", "$."], "meter": "+-+-", "measure": "trochaic.di"}}, "stanza.4": {"line.1": {"text": "Und du gabst dich mir im Unterholze", "tokens": ["Und", "du", "gabst", "dich", "mir", "im", "Un\u00b7ter\u00b7hol\u00b7ze"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "PPER", "PPER", "APPRART", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "einmal hin und einmal her,", "tokens": ["ein\u00b7mal", "hin", "und", "ein\u00b7mal", "her", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKVZ", "KON", "ADV", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "und du fragtest mich mit deutschem Stolze,", "tokens": ["und", "du", "frag\u00b7test", "mich", "mit", "deut\u00b7schem", "Stol\u00b7ze", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PRF", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "ob ich auch im Krieg gewesen w\u00e4r . . .", "tokens": ["ob", "ich", "auch", "im", "Krieg", "ge\u00b7we\u00b7sen", "w\u00e4r", ".", ".", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["KOUS", "PPER", "ADV", "APPRART", "NN", "VAPP", "VAFIN", "$.", "$.", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.5": {"text": "Anna-Luise \u2013!", "tokens": ["An\u00b7na\u00b7Lui\u00b7se", "\u2013", "!"], "token_info": ["word", "punct", "punct"], "pos": ["NE", "$(", "$."], "meter": "+-+-", "measure": "trochaic.di"}}, "stanza.5": {"line.1": {"text": "Ach, ich habe dich ja so belogen!", "tokens": ["Ach", ",", "ich", "ha\u00b7be", "dich", "ja", "so", "be\u00b7lo\u00b7gen", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "PPER", "VAFIN", "PPER", "ADV", "ADV", "VVPP", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Hab gesagt, mir w\u00e4r ein Kreuz von Eisen wert,", "tokens": ["Hab", "ge\u00b7sagt", ",", "mir", "w\u00e4r", "ein", "Kreuz", "von", "Ei\u00b7sen", "wert", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVPP", "$,", "PPER", "VAFIN", "ART", "NN", "APPR", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.3": {"text": "als Gefreiter w\u00e4r ich ausgezogen,", "tokens": ["als", "Ge\u00b7frei\u00b7ter", "w\u00e4r", "ich", "aus\u00b7ge\u00b7zo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "VAFIN", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "und als Hauptmann w\u00e4r ich heimgekehrt \u2013", "tokens": ["und", "als", "Haupt\u00b7mann", "w\u00e4r", "ich", "heim\u00b7ge\u00b7kehrt", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "NN", "VAFIN", "PPER", "VVFIN", "$("], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.5": {"text": "Anna-Luise \u2013!", "tokens": ["An\u00b7na\u00b7Lui\u00b7se", "\u2013", "!"], "token_info": ["word", "punct", "punct"], "pos": ["NE", "$(", "$."], "meter": "+-+-", "measure": "trochaic.di"}}, "stanza.6": {"line.1": {"text": "Als wir standen bei der Eberesche,", "tokens": ["Als", "wir", "stan\u00b7den", "bei", "der", "E\u00b7be\u00b7re\u00b7sche", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "wo der Kronprinz einst gepflanzet hat,", "tokens": ["wo", "der", "Kron\u00b7prinz", "einst", "ge\u00b7pflan\u00b7zet", "hat", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "ADV", "VVPP", "VAFIN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "raschelte ganz leise deine W\u00e4sche,", "tokens": ["ra\u00b7schel\u00b7te", "ganz", "lei\u00b7se", "dei\u00b7ne", "W\u00e4\u00b7sche", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADJD", "PPOSAT", "NN", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "und du strichst dir deine R\u00f6cke glatt,", "tokens": ["und", "du", "strichst", "dir", "dei\u00b7ne", "R\u00f6\u00b7cke", "glatt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPER", "PPOSAT", "NN", "ADJD", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.5": {"text": "Anna-Luise \u2013!", "tokens": ["An\u00b7na\u00b7Lui\u00b7se", "\u2013", "!"], "token_info": ["word", "punct", "punct"], "pos": ["NE", "$(", "$."], "meter": "+-+-", "measure": "trochaic.di"}}, "stanza.7": {"line.1": {"text": "M\u00f6chtest nie wo andershin du strichen!", "tokens": ["M\u00f6ch\u00b7test", "nie", "wo", "an\u00b7der\u00b7shin", "du", "stri\u00b7chen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "PWAV", "ADV", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Siehst du dort die ersten Sterne gehn?", "tokens": ["Siehst", "du", "dort", "die", "ers\u00b7ten", "Ster\u00b7ne", "gehn", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Habe Dank f\u00fcr alle unvergesserlichen", "tokens": ["Ha\u00b7be", "Dank", "f\u00fcr", "al\u00b7le", "un\u00b7ver\u00b7ges\u00b7ser\u00b7li\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "APPR", "PIAT", "ADJA"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.4": {"text": "Stunden und auf Wiedersehn!", "tokens": ["Stun\u00b7den", "und", "auf", "Wie\u00b7der\u00b7sehn", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "APPR", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Anna-Luise \u2013!", "tokens": ["An\u00b7na\u00b7Lui\u00b7se", "\u2013", "!"], "token_info": ["word", "punct", "punct"], "pos": ["NE", "$(", "$."], "meter": "+-+-", "measure": "trochaic.di"}}, "stanza.8": {"line.1": {"text": "Denn der sch\u00f6nste Platz, der hier auf Erden mein,", "tokens": ["Denn", "der", "sch\u00f6ns\u00b7te", "Platz", ",", "der", "hier", "auf", "Er\u00b7den", "mein", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "$,", "PRELS", "ADV", "APPR", "NN", "PPOSAT", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.2": {"text": "das ist Heidelberg in Wien am Rhein,", "tokens": ["das", "ist", "Hei\u00b7del\u00b7berg", "in", "Wi\u00b7en", "am", "Rhein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "NE", "APPR", "NE", "APPRART", "NE", "$,"], "meter": "--+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Seemannslos.", "tokens": ["See\u00b7manns\u00b7los", "."], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.4": {"text": "Keine, die wie du die Fl\u00f6te bliese . . . !", "tokens": ["Kei\u00b7ne", ",", "die", "wie", "du", "die", "Fl\u00f6\u00b7te", "blie\u00b7se", ".", ".", ".", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct", "punct"], "pos": ["PIAT", "$,", "PRELS", "KOKOM", "PPER", "ART", "NN", "VVFIN", "$.", "$.", "$.", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.5": {"text": "Lebe wohl! Leb wohl.", "tokens": ["Le\u00b7be", "wohl", "!", "Leb", "wohl", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["VVIMP", "ADV", "$.", "VVIMP", "ADV", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.6": {"text": "Anna-Luise \u2013!", "tokens": ["An\u00b7na\u00b7Lui\u00b7se", "\u2013", "!"], "token_info": ["word", "punct", "punct"], "pos": ["NE", "$(", "$."], "meter": "+-+-", "measure": "trochaic.di"}}, "stanza.9": {"line.1": {"text": "Wenn die Igel in der Abendstunde", "tokens": ["Wenn", "die", "I\u00b7gel", "in", "der", "A\u00b7bends\u00b7tun\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "APPR", "ART", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "still nach ihren M\u00e4usen gehn,", "tokens": ["still", "nach", "ih\u00b7ren", "M\u00e4u\u00b7sen", "gehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "PPOSAT", "NN", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "hing auch ich verz\u00fcckt an deinem Munde,", "tokens": ["hing", "auch", "ich", "ver\u00b7z\u00fcckt", "an", "dei\u00b7nem", "Mun\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PPER", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "und es war um mich geschehn \u2013", "tokens": ["und", "es", "war", "um", "mich", "ge\u00b7schehn", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "APPR", "PPER", "VVPP", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Anna-Luise \u2013!", "tokens": ["An\u00b7na\u00b7Lui\u00b7se", "\u2013", "!"], "token_info": ["word", "punct", "punct"], "pos": ["NE", "$(", "$."], "meter": "+-+-", "measure": "trochaic.di"}}, "stanza.10": {"line.1": {"text": "Dein Papa ist k\u00fchn und Geometer,", "tokens": ["Dein", "Pa\u00b7pa", "ist", "k\u00fchn", "und", "Geo\u00b7me\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADJD", "KON", "NN", "$,"], "meter": "--+-+-+--", "measure": "anapaest.init"}, "line.2": {"text": "er hat zwei Kanarienv\u00f6gelein;", "tokens": ["er", "hat", "zwei", "Ka\u00b7na\u00b7ri\u00b7en\u00b7v\u00f6\u00b7ge\u00b7lein", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "CARD", "NN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "auf den Sonnabend aber geht er", "tokens": ["auf", "den", "Sonn\u00b7a\u00b7bend", "a\u00b7ber", "geht", "er"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ADV", "VVFIN", "PPER"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "gern zum Pilsner in 'n Gesangverein \u2013", "tokens": ["gern", "zum", "Pils\u00b7ner", "in", "'n", "Ge\u00b7sang\u00b7ver\u00b7ein", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "APPR", "ART", "NN", "$("], "meter": "--+--+-+-+", "measure": "anapaest.di.plus"}, "line.5": {"text": "Anna-Luise \u2013!", "tokens": ["An\u00b7na\u00b7Lui\u00b7se", "\u2013", "!"], "token_info": ["word", "punct", "punct"], "pos": ["NE", "$(", "$."], "meter": "+-+-", "measure": "trochaic.di"}}, "stanza.11": {"line.1": {"text": "Sagt' ich: \u00bbWirst die meine du in B\u00e4lde?\u00ab,", "tokens": ["Sagt'", "ich", ":", "\u00bb", "Wirst", "die", "mei\u00b7ne", "du", "in", "B\u00e4l\u00b7de", "?", "\u00ab", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["VVFIN", "PPER", "$.", "$(", "VAFIN", "ART", "VVFIN", "PPER", "APPR", "NN", "$.", "$(", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "blicktest du voll s\u00fc\u00dfer Tr\u00e4umerei", "tokens": ["blick\u00b7test", "du", "voll", "s\u00fc\u00b7\u00dfer", "Tr\u00e4u\u00b7me\u00b7rei"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADJD", "ADJA", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "auf das gr\u00fcne Vandervelde,", "tokens": ["auf", "das", "gr\u00fc\u00b7ne", "Van\u00b7der\u00b7vel\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "und du dachtest dir dein Teil dabei,", "tokens": ["und", "du", "dach\u00b7test", "dir", "dein", "Teil", "da\u00b7bei", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPER", "PPOSAT", "NN", "PAV", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.5": {"text": "Anna-Luise \u2013!", "tokens": ["An\u00b7na\u00b7Lui\u00b7se", "\u2013", "!"], "token_info": ["word", "punct", "punct"], "pos": ["NE", "$(", "$."], "meter": "+-+-", "measure": "trochaic.di"}}, "stanza.12": {"line.1": {"text": "Und du gabst dich mir im Unterholze", "tokens": ["Und", "du", "gabst", "dich", "mir", "im", "Un\u00b7ter\u00b7hol\u00b7ze"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "PPER", "PPER", "APPRART", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "einmal hin und einmal her,", "tokens": ["ein\u00b7mal", "hin", "und", "ein\u00b7mal", "her", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKVZ", "KON", "ADV", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "und du fragtest mich mit deutschem Stolze,", "tokens": ["und", "du", "frag\u00b7test", "mich", "mit", "deut\u00b7schem", "Stol\u00b7ze", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PRF", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "ob ich auch im Krieg gewesen w\u00e4r . . .", "tokens": ["ob", "ich", "auch", "im", "Krieg", "ge\u00b7we\u00b7sen", "w\u00e4r", ".", ".", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["KOUS", "PPER", "ADV", "APPRART", "NN", "VAPP", "VAFIN", "$.", "$.", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.5": {"text": "Anna-Luise \u2013!", "tokens": ["An\u00b7na\u00b7Lui\u00b7se", "\u2013", "!"], "token_info": ["word", "punct", "punct"], "pos": ["NE", "$(", "$."], "meter": "+-+-", "measure": "trochaic.di"}}, "stanza.13": {"line.1": {"text": "Ach, ich habe dich ja so belogen!", "tokens": ["Ach", ",", "ich", "ha\u00b7be", "dich", "ja", "so", "be\u00b7lo\u00b7gen", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "PPER", "VAFIN", "PPER", "ADV", "ADV", "VVPP", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Hab gesagt, mir w\u00e4r ein Kreuz von Eisen wert,", "tokens": ["Hab", "ge\u00b7sagt", ",", "mir", "w\u00e4r", "ein", "Kreuz", "von", "Ei\u00b7sen", "wert", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVPP", "$,", "PPER", "VAFIN", "ART", "NN", "APPR", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.3": {"text": "als Gefreiter w\u00e4r ich ausgezogen,", "tokens": ["als", "Ge\u00b7frei\u00b7ter", "w\u00e4r", "ich", "aus\u00b7ge\u00b7zo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "VAFIN", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "und als Hauptmann w\u00e4r ich heimgekehrt \u2013", "tokens": ["und", "als", "Haupt\u00b7mann", "w\u00e4r", "ich", "heim\u00b7ge\u00b7kehrt", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "NN", "VAFIN", "PPER", "VVFIN", "$("], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.5": {"text": "Anna-Luise \u2013!", "tokens": ["An\u00b7na\u00b7Lui\u00b7se", "\u2013", "!"], "token_info": ["word", "punct", "punct"], "pos": ["NE", "$(", "$."], "meter": "+-+-", "measure": "trochaic.di"}}, "stanza.14": {"line.1": {"text": "Als wir standen bei der Eberesche,", "tokens": ["Als", "wir", "stan\u00b7den", "bei", "der", "E\u00b7be\u00b7re\u00b7sche", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "wo der Kronprinz einst gepflanzet hat,", "tokens": ["wo", "der", "Kron\u00b7prinz", "einst", "ge\u00b7pflan\u00b7zet", "hat", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "ADV", "VVPP", "VAFIN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "raschelte ganz leise deine W\u00e4sche,", "tokens": ["ra\u00b7schel\u00b7te", "ganz", "lei\u00b7se", "dei\u00b7ne", "W\u00e4\u00b7sche", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADJD", "PPOSAT", "NN", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "und du strichst dir deine R\u00f6cke glatt,", "tokens": ["und", "du", "strichst", "dir", "dei\u00b7ne", "R\u00f6\u00b7cke", "glatt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPER", "PPOSAT", "NN", "ADJD", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.5": {"text": "Anna-Luise \u2013!", "tokens": ["An\u00b7na\u00b7Lui\u00b7se", "\u2013", "!"], "token_info": ["word", "punct", "punct"], "pos": ["NE", "$(", "$."], "meter": "+-+-", "measure": "trochaic.di"}}, "stanza.15": {"line.1": {"text": "M\u00f6chtest nie wo andershin du strichen!", "tokens": ["M\u00f6ch\u00b7test", "nie", "wo", "an\u00b7der\u00b7shin", "du", "stri\u00b7chen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "PWAV", "ADV", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Siehst du dort die ersten Sterne gehn?", "tokens": ["Siehst", "du", "dort", "die", "ers\u00b7ten", "Ster\u00b7ne", "gehn", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Habe Dank f\u00fcr alle unvergesserlichen", "tokens": ["Ha\u00b7be", "Dank", "f\u00fcr", "al\u00b7le", "un\u00b7ver\u00b7ges\u00b7ser\u00b7li\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "APPR", "PIAT", "ADJA"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.4": {"text": "Stunden und auf Wiedersehn!", "tokens": ["Stun\u00b7den", "und", "auf", "Wie\u00b7der\u00b7sehn", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "APPR", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Anna-Luise \u2013!", "tokens": ["An\u00b7na\u00b7Lui\u00b7se", "\u2013", "!"], "token_info": ["word", "punct", "punct"], "pos": ["NE", "$(", "$."], "meter": "+-+-", "measure": "trochaic.di"}}, "stanza.16": {"line.1": {"text": "Denn der sch\u00f6nste Platz, der hier auf Erden mein,", "tokens": ["Denn", "der", "sch\u00f6ns\u00b7te", "Platz", ",", "der", "hier", "auf", "Er\u00b7den", "mein", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "$,", "PRELS", "ADV", "APPR", "NN", "PPOSAT", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.2": {"text": "das ist Heidelberg in Wien am Rhein,", "tokens": ["das", "ist", "Hei\u00b7del\u00b7berg", "in", "Wi\u00b7en", "am", "Rhein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "NE", "APPR", "NE", "APPRART", "NE", "$,"], "meter": "--+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Seemannslos.", "tokens": ["See\u00b7manns\u00b7los", "."], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.4": {"text": "Keine, die wie du die Fl\u00f6te bliese . . . !", "tokens": ["Kei\u00b7ne", ",", "die", "wie", "du", "die", "Fl\u00f6\u00b7te", "blie\u00b7se", ".", ".", ".", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct", "punct"], "pos": ["PIAT", "$,", "PRELS", "KOKOM", "PPER", "ART", "NN", "VVFIN", "$.", "$.", "$.", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.5": {"text": "Lebe wohl! Leb wohl.", "tokens": ["Le\u00b7be", "wohl", "!", "Leb", "wohl", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["VVIMP", "ADV", "$.", "VVIMP", "ADV", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.6": {"text": "Anna-Luise \u2013!", "tokens": ["An\u00b7na\u00b7Lui\u00b7se", "\u2013", "!"], "token_info": ["word", "punct", "punct"], "pos": ["NE", "$(", "$."], "meter": "+-+-", "measure": "trochaic.di"}}}}}