{"textgrid.poem.34278": {"metadata": {"author": {"name": "Lenz, Jakob Michael Reinhold", "birth": "N.A.", "death": "N.A."}, "title": "1L: Ach, bist du fort? aus welchen g\u00fcldnen Tr\u00e4umen", "genre": "verse", "period": "N.A.", "pub_year": 1772, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ach, bist du fort? aus welchen g\u00fcldnen Tr\u00e4umen", "tokens": ["Ach", ",", "bist", "du", "fort", "?", "aus", "wel\u00b7chen", "g\u00fcld\u00b7nen", "Tr\u00e4u\u00b7men"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ITJ", "$,", "VAFIN", "PPER", "PTKVZ", "$.", "APPR", "PWAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Erwach' ich jetzt zu meiner Qual!", "tokens": ["Er\u00b7wach'", "ich", "jetzt", "zu", "mei\u00b7ner", "Qual", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Kein Bitten hielt dich auf, du wolltest doch nicht s\u00e4umen,", "tokens": ["Kein", "Bit\u00b7ten", "hielt", "dich", "auf", ",", "du", "woll\u00b7test", "doch", "nicht", "s\u00e4u\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "PPER", "PTKVZ", "$,", "PPER", "VMFIN", "ADV", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Du flogst davon zum zweitenmal.", "tokens": ["Du", "flogst", "da\u00b7von", "zum", "zwei\u00b7ten\u00b7mal", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PAV", "APPRART", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Zum zweitenmal sah ich dich Abschied nehmen,", "tokens": ["Zum", "zwei\u00b7ten\u00b7mal", "sah", "ich", "dich", "Ab\u00b7schied", "neh\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADV", "VVFIN", "PPER", "PRF", "NN", "VVINF", "$,"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Dein g\u00f6ttlich Aug' in Thr\u00e4nen stehn,", "tokens": ["Dein", "g\u00f6tt\u00b7lich", "Aug'", "in", "Thr\u00e4\u00b7nen", "stehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "F\u00fcr deine Freundinnen \u2013 des J\u00fcnglings stummes Gr\u00e4men", "tokens": ["F\u00fcr", "dei\u00b7ne", "Freun\u00b7din\u00b7nen", "\u2013", "des", "J\u00fcng\u00b7lings", "stum\u00b7mes", "Gr\u00e4\u00b7men"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "$(", "ART", "NN", "ADJA", "NN"], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Blieb unbemerkt, ward nicht gesehn.", "tokens": ["Blieb", "un\u00b7be\u00b7merkt", ",", "ward", "nicht", "ge\u00b7sehn", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "$,", "VAFIN", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "O warum wandtest du die holden Blicke", "tokens": ["O", "wa\u00b7rum", "wand\u00b7test", "du", "die", "hol\u00b7den", "Bli\u00b7cke"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "PWAV", "VVFIN", "PPER", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Beim Abschied immer von ihm ab?", "tokens": ["Beim", "Ab\u00b7schied", "im\u00b7mer", "von", "ihm", "ab", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADV", "APPR", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "O warum lie\u00dfest du ihm nichts, ihm nichts zur\u00fccke", "tokens": ["O", "wa\u00b7rum", "lie\u00b7\u00dfest", "du", "ihm", "nichts", ",", "ihm", "nichts", "zu\u00b7r\u00fc\u00b7cke"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NE", "PWAV", "VVFIN", "PPER", "PPER", "PIS", "$,", "PPER", "PIS", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Als die Verzweiflung und das Grab?", "tokens": ["Als", "die", "Ver\u00b7zwei\u00b7flung", "und", "das", "Grab", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "KON", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Wie ist die Munterkeit von ihm gewichen!", "tokens": ["Wie", "ist", "die", "Mun\u00b7ter\u00b7keit", "von", "ihm", "ge\u00b7wi\u00b7chen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "ART", "NN", "APPR", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die Sonne scheint ihm schwarz, der Boden leer,", "tokens": ["Die", "Son\u00b7ne", "scheint", "ihm", "schwarz", ",", "der", "Bo\u00b7den", "leer", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADJD", "$,", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Die B\u00e4ume bl\u00fchn ihm schwarz, die Bl\u00e4tter sind verblichen,", "tokens": ["Die", "B\u00e4u\u00b7me", "bl\u00fchn", "ihm", "schwarz", ",", "die", "Bl\u00e4t\u00b7ter", "sind", "ver\u00b7bli\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADJD", "$,", "ART", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und alles welket um ihn her.", "tokens": ["Und", "al\u00b7les", "wel\u00b7ket", "um", "ihn", "her", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "APPR", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Er l\u00e4uft in Gegenden wo er mit dir gegangen,", "tokens": ["Er", "l\u00e4uft", "in", "Ge\u00b7gen\u00b7den", "wo", "er", "mit", "dir", "ge\u00b7gan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "PWAV", "PPER", "APPR", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Im krummen Bogengang, im Wald, am Bach \u2013", "tokens": ["Im", "krum\u00b7men", "Bo\u00b7gen\u00b7gang", ",", "im", "Wald", ",", "am", "Bach", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "$,", "APPRART", "NN", "$,", "APPRART", "NN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Und findet dich nicht mehr \u2013 und weinet voll Verlangen", "tokens": ["Und", "fin\u00b7det", "dich", "nicht", "mehr", "\u2013", "und", "wei\u00b7net", "voll", "Ver\u00b7lan\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "PTKNEG", "ADV", "$(", "KON", "VVFIN", "ADJD", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und voll Verzweiflung dort dir nach.", "tokens": ["Und", "voll", "Ver\u00b7zwei\u00b7flung", "dort", "dir", "nach", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "NN", "ADV", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Dann in die Stadt zur\u00fcck, doch die erweckt ihm Grauen,", "tokens": ["Dann", "in", "die", "Stadt", "zu\u00b7r\u00fcck", ",", "doch", "die", "er\u00b7weckt", "ihm", "Grau\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "PTKVZ", "$,", "ADV", "ART", "VVFIN", "PPER", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Er findet dich nicht mehr, Vollkommenheit!", "tokens": ["Er", "fin\u00b7det", "dich", "nicht", "mehr", ",", "Voll\u00b7kom\u00b7men\u00b7heit", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKNEG", "ADV", "$,", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Ein andrer mag nach jenen Puppen schauen,", "tokens": ["Ein", "an\u00b7drer", "mag", "nach", "je\u00b7nen", "Pup\u00b7pen", "schau\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VMFIN", "APPR", "PDAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Ihm sind die N\u00e4rrinnen verleid't.", "tokens": ["Ihm", "sind", "die", "N\u00e4r\u00b7rin\u00b7nen", "ver\u00b7leid'", "t."], "token_info": ["word", "word", "word", "word", "word", "abbreviation"], "pos": ["PPER", "VAFIN", "ART", "NN", "VVFIN", "NE"], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.7": {"line.1": {"text": "O la\u00df dich doch, o la\u00df dich doch erflehen,", "tokens": ["O", "la\u00df", "dich", "doch", ",", "o", "la\u00df", "dich", "doch", "er\u00b7fle\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "ADV", "$,", "FM", "VVIMP", "PPER", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und schreib' ihm einmal nur \u2013 ob du ihn liebst!", "tokens": ["Und", "schreib'", "ihm", "ein\u00b7mal", "nur", "\u2013", "ob", "du", "ihn", "liebst", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "ADV", "$(", "KOUS", "PPER", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Ach, oder la\u00df ihn nie dich wiedersehen,", "tokens": ["Ach", ",", "o\u00b7der", "la\u00df", "ihn", "nie", "dich", "wie\u00b7der\u00b7se\u00b7hen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "KON", "VVIMP", "PPER", "ADV", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Wenn du ihm diesen Trost nicht giebst!", "tokens": ["Wenn", "du", "ihm", "die\u00b7sen", "Trost", "nicht", "giebst", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "PDAT", "NN", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Wie? nie dich wiedersehn? \u2013 Entsetzlicher Gedanke!", "tokens": ["Wie", "?", "nie", "dich", "wie\u00b7der\u00b7sehn", "?", "\u2013", "Ent\u00b7setz\u00b7li\u00b7cher", "Ge\u00b7dan\u00b7ke", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["PWAV", "$.", "ADV", "PPER", "VVINF", "$.", "$(", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Str\u00f6m' alle deine Qual auf mich!", "tokens": ["Str\u00f6m'", "al\u00b7le", "dei\u00b7ne", "Qual", "auf", "mich", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PPOSAT", "NN", "APPR", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ich f\u00fchl', ich f\u00fchl' ihn ganz \u2013 es ist zu viel \u2013 ich wanke \u2013", "tokens": ["Ich", "f\u00fchl'", ",", "ich", "f\u00fchl'", "ihn", "ganz", "\u2013", "es", "ist", "zu", "viel", "\u2013", "ich", "wan\u00b7ke", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VVFIN", "PPER", "ADV", "$(", "PPER", "VAFIN", "PTKA", "PIS", "$(", "PPER", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ich sterbe, Grausame \u2013 f\u00fcr dich!", "tokens": ["Ich", "ster\u00b7be", ",", "Grau\u00b7sa\u00b7me", "\u2013", "f\u00fcr", "dich", "!"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "NN", "$(", "APPR", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Ach, bist du fort? aus welchen g\u00fcldnen Tr\u00e4umen", "tokens": ["Ach", ",", "bist", "du", "fort", "?", "aus", "wel\u00b7chen", "g\u00fcld\u00b7nen", "Tr\u00e4u\u00b7men"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ITJ", "$,", "VAFIN", "PPER", "PTKVZ", "$.", "APPR", "PWAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Erwach' ich jetzt zu meiner Qual!", "tokens": ["Er\u00b7wach'", "ich", "jetzt", "zu", "mei\u00b7ner", "Qual", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Kein Bitten hielt dich auf, du wolltest doch nicht s\u00e4umen,", "tokens": ["Kein", "Bit\u00b7ten", "hielt", "dich", "auf", ",", "du", "woll\u00b7test", "doch", "nicht", "s\u00e4u\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "PPER", "PTKVZ", "$,", "PPER", "VMFIN", "ADV", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Du flogst davon zum zweitenmal.", "tokens": ["Du", "flogst", "da\u00b7von", "zum", "zwei\u00b7ten\u00b7mal", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PAV", "APPRART", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Zum zweitenmal sah ich dich Abschied nehmen,", "tokens": ["Zum", "zwei\u00b7ten\u00b7mal", "sah", "ich", "dich", "Ab\u00b7schied", "neh\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADV", "VVFIN", "PPER", "PRF", "NN", "VVINF", "$,"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Dein g\u00f6ttlich Aug' in Thr\u00e4nen stehn,", "tokens": ["Dein", "g\u00f6tt\u00b7lich", "Aug'", "in", "Thr\u00e4\u00b7nen", "stehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "F\u00fcr deine Freundinnen \u2013 des J\u00fcnglings stummes Gr\u00e4men", "tokens": ["F\u00fcr", "dei\u00b7ne", "Freun\u00b7din\u00b7nen", "\u2013", "des", "J\u00fcng\u00b7lings", "stum\u00b7mes", "Gr\u00e4\u00b7men"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "$(", "ART", "NN", "ADJA", "NN"], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Blieb unbemerkt, ward nicht gesehn.", "tokens": ["Blieb", "un\u00b7be\u00b7merkt", ",", "ward", "nicht", "ge\u00b7sehn", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "$,", "VAFIN", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "O warum wandtest du die holden Blicke", "tokens": ["O", "wa\u00b7rum", "wand\u00b7test", "du", "die", "hol\u00b7den", "Bli\u00b7cke"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "PWAV", "VVFIN", "PPER", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Beim Abschied immer von ihm ab?", "tokens": ["Beim", "Ab\u00b7schied", "im\u00b7mer", "von", "ihm", "ab", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADV", "APPR", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "O warum lie\u00dfest du ihm nichts, ihm nichts zur\u00fccke", "tokens": ["O", "wa\u00b7rum", "lie\u00b7\u00dfest", "du", "ihm", "nichts", ",", "ihm", "nichts", "zu\u00b7r\u00fc\u00b7cke"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NE", "PWAV", "VVFIN", "PPER", "PPER", "PIS", "$,", "PPER", "PIS", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Als die Verzweiflung und das Grab?", "tokens": ["Als", "die", "Ver\u00b7zwei\u00b7flung", "und", "das", "Grab", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "KON", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Wie ist die Munterkeit von ihm gewichen!", "tokens": ["Wie", "ist", "die", "Mun\u00b7ter\u00b7keit", "von", "ihm", "ge\u00b7wi\u00b7chen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "ART", "NN", "APPR", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die Sonne scheint ihm schwarz, der Boden leer,", "tokens": ["Die", "Son\u00b7ne", "scheint", "ihm", "schwarz", ",", "der", "Bo\u00b7den", "leer", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADJD", "$,", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Die B\u00e4ume bl\u00fchn ihm schwarz, die Bl\u00e4tter sind verblichen,", "tokens": ["Die", "B\u00e4u\u00b7me", "bl\u00fchn", "ihm", "schwarz", ",", "die", "Bl\u00e4t\u00b7ter", "sind", "ver\u00b7bli\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADJD", "$,", "ART", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und alles welket um ihn her.", "tokens": ["Und", "al\u00b7les", "wel\u00b7ket", "um", "ihn", "her", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "APPR", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Er l\u00e4uft in Gegenden wo er mit dir gegangen,", "tokens": ["Er", "l\u00e4uft", "in", "Ge\u00b7gen\u00b7den", "wo", "er", "mit", "dir", "ge\u00b7gan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "PWAV", "PPER", "APPR", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Im krummen Bogengang, im Wald, am Bach \u2013", "tokens": ["Im", "krum\u00b7men", "Bo\u00b7gen\u00b7gang", ",", "im", "Wald", ",", "am", "Bach", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "$,", "APPRART", "NN", "$,", "APPRART", "NN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Und findet dich nicht mehr \u2013 und weinet voll Verlangen", "tokens": ["Und", "fin\u00b7det", "dich", "nicht", "mehr", "\u2013", "und", "wei\u00b7net", "voll", "Ver\u00b7lan\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "PTKNEG", "ADV", "$(", "KON", "VVFIN", "ADJD", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und voll Verzweiflung dort dir nach.", "tokens": ["Und", "voll", "Ver\u00b7zwei\u00b7flung", "dort", "dir", "nach", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "NN", "ADV", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Dann in die Stadt zur\u00fcck, doch die erweckt ihm Grauen,", "tokens": ["Dann", "in", "die", "Stadt", "zu\u00b7r\u00fcck", ",", "doch", "die", "er\u00b7weckt", "ihm", "Grau\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "PTKVZ", "$,", "ADV", "ART", "VVFIN", "PPER", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Er findet dich nicht mehr, Vollkommenheit!", "tokens": ["Er", "fin\u00b7det", "dich", "nicht", "mehr", ",", "Voll\u00b7kom\u00b7men\u00b7heit", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKNEG", "ADV", "$,", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Ein andrer mag nach jenen Puppen schauen,", "tokens": ["Ein", "an\u00b7drer", "mag", "nach", "je\u00b7nen", "Pup\u00b7pen", "schau\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VMFIN", "APPR", "PDAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Ihm sind die N\u00e4rrinnen verleid't.", "tokens": ["Ihm", "sind", "die", "N\u00e4r\u00b7rin\u00b7nen", "ver\u00b7leid'", "t."], "token_info": ["word", "word", "word", "word", "word", "abbreviation"], "pos": ["PPER", "VAFIN", "ART", "NN", "VVFIN", "NE"], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.15": {"line.1": {"text": "O la\u00df dich doch, o la\u00df dich doch erflehen,", "tokens": ["O", "la\u00df", "dich", "doch", ",", "o", "la\u00df", "dich", "doch", "er\u00b7fle\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "ADV", "$,", "FM", "VVIMP", "PPER", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und schreib' ihm einmal nur \u2013 ob du ihn liebst!", "tokens": ["Und", "schreib'", "ihm", "ein\u00b7mal", "nur", "\u2013", "ob", "du", "ihn", "liebst", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "ADV", "$(", "KOUS", "PPER", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Ach, oder la\u00df ihn nie dich wiedersehen,", "tokens": ["Ach", ",", "o\u00b7der", "la\u00df", "ihn", "nie", "dich", "wie\u00b7der\u00b7se\u00b7hen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "KON", "VVIMP", "PPER", "ADV", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Wenn du ihm diesen Trost nicht giebst!", "tokens": ["Wenn", "du", "ihm", "die\u00b7sen", "Trost", "nicht", "giebst", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "PDAT", "NN", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "Wie? nie dich wiedersehn? \u2013 Entsetzlicher Gedanke!", "tokens": ["Wie", "?", "nie", "dich", "wie\u00b7der\u00b7sehn", "?", "\u2013", "Ent\u00b7setz\u00b7li\u00b7cher", "Ge\u00b7dan\u00b7ke", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["PWAV", "$.", "ADV", "PPER", "VVINF", "$.", "$(", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Str\u00f6m' alle deine Qual auf mich!", "tokens": ["Str\u00f6m'", "al\u00b7le", "dei\u00b7ne", "Qual", "auf", "mich", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PPOSAT", "NN", "APPR", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ich f\u00fchl', ich f\u00fchl' ihn ganz \u2013 es ist zu viel \u2013 ich wanke \u2013", "tokens": ["Ich", "f\u00fchl'", ",", "ich", "f\u00fchl'", "ihn", "ganz", "\u2013", "es", "ist", "zu", "viel", "\u2013", "ich", "wan\u00b7ke", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VVFIN", "PPER", "ADV", "$(", "PPER", "VAFIN", "PTKA", "PIS", "$(", "PPER", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ich sterbe, Grausame \u2013 f\u00fcr dich!", "tokens": ["Ich", "ster\u00b7be", ",", "Grau\u00b7sa\u00b7me", "\u2013", "f\u00fcr", "dich", "!"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "NN", "$(", "APPR", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}