{"textgrid.poem.35539": {"metadata": {"author": {"name": "Conradi, Hermann", "birth": "N.A.", "death": "N.A."}, "title": "Meta", "genre": "verse", "period": "N.A.", "pub_year": 1876, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Am Donnerstag kam Meta in die Schule,", "tokens": ["Am", "Don\u00b7ners\u00b7tag", "kam", "Me\u00b7ta", "in", "die", "Schu\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "NE", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Am Donnerstag nach Ostern. \u2013 Wie das Kind", "tokens": ["Am", "Don\u00b7ners\u00b7tag", "nach", "Os\u00b7tern", ".", "\u2013", "Wie", "das", "Kind"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word"], "pos": ["APPRART", "NN", "APPR", "NN", "$.", "$(", "PWAV", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Sich drauf gefreut hat! Wie sein kleines Herz", "tokens": ["Sich", "drauf", "ge\u00b7freut", "hat", "!", "Wie", "sein", "klei\u00b7nes", "Herz"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PRF", "PAV", "VVPP", "VAFIN", "$.", "PWAV", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Der M\u00e4dchentr\u00e4ume bunte F\u00fclle tr\u00e4umte!", "tokens": ["Der", "M\u00e4d\u00b7chen\u00b7tr\u00e4u\u00b7me", "bun\u00b7te", "F\u00fcl\u00b7le", "tr\u00e4um\u00b7te", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Die Tage all vorher hat's von dem einen,", "tokens": ["Die", "Ta\u00b7ge", "all", "vor\u00b7her", "hat's", "von", "dem", "ei\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PIAT", "ADV", "VAFIN", "APPR", "ART", "ART", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Von diesem einen immer nur geplaudert \u2013", "tokens": ["Von", "die\u00b7sem", "ei\u00b7nen", "im\u00b7mer", "nur", "ge\u00b7plau\u00b7dert", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "ART", "ADV", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Selbst in den festen Jugendschlaf schlich sich", "tokens": ["Selbst", "in", "den", "fes\u00b7ten", "Ju\u00b7gend\u00b7schlaf", "schlich", "sich"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN", "ADJD", "PRF"], "meter": "---+-+-++-", "measure": "unknown.measure.tetra"}, "line.8": {"text": "Die Neugier lockernd ... Und dann kam der Tag ...", "tokens": ["Die", "Neu\u00b7gier", "lo\u00b7ckernd", "...", "Und", "dann", "kam", "der", "Tag", "..."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "$(", "KON", "ADV", "VVFIN", "ART", "NN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Und kaum zu b\u00e4ndigen von der Hand der Mutter,", "tokens": ["Und", "kaum", "zu", "b\u00e4n\u00b7di\u00b7gen", "von", "der", "Hand", "der", "Mut\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PTKZU", "VVINF", "APPR", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.10": {"text": "Die es zur Schule brachte, war das M\u00e4dchen ...", "tokens": ["Die", "es", "zur", "Schu\u00b7le", "brach\u00b7te", ",", "war", "das", "M\u00e4d\u00b7chen", "..."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPRART", "NN", "VVFIN", "$,", "VAFIN", "ART", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "Nachher kam's zu mir. In den braunen Augen", "tokens": ["Nach\u00b7her", "kam's", "zu", "mir", ".", "In", "den", "brau\u00b7nen", "Au\u00b7gen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "APPR", "PPER", "$.", "APPR", "ART", "ADJA", "NN"], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.12": {"text": "Stand klares Leuchten ... und der Freude Schimmer", "tokens": ["Stand", "kla\u00b7res", "Leuch\u00b7ten", "...", "und", "der", "Freu\u00b7de", "Schim\u00b7mer"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "ADJA", "NN", "$(", "KON", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "Entz\u00fcckte hold das zarte Angesicht ...", "tokens": ["Ent\u00b7z\u00fcck\u00b7te", "hold", "das", "zar\u00b7te", "An\u00b7ge\u00b7sicht", "..."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "Die kleinen d\u00fcnnen Finger hielten tapfer", "tokens": ["Die", "klei\u00b7nen", "d\u00fcn\u00b7nen", "Fin\u00b7ger", "hiel\u00b7ten", "tap\u00b7fer"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "ADJA", "NN", "VVFIN", "ADJD"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.15": {"text": "Die rote D\u00fcte, die fast gr\u00f6\u00dfer war,", "tokens": ["Die", "ro\u00b7te", "D\u00fc\u00b7te", ",", "die", "fast", "gr\u00f6\u00b7\u00dfer", "war", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PRELS", "ADV", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.16": {"text": "Denn's ganze winzige Pers\u00f6nchen ... \u00bbOnkel!", "tokens": ["Denn's", "gan\u00b7ze", "win\u00b7zi\u00b7ge", "Per\u00b7s\u00f6n\u00b7chen", "...", "\u00bb", "On\u00b7kel", "!"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "$(", "$(", "NN", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.17": {"text": "Das hat der Lehrer mir geschenkt \u2013\u00ab ich nickte ...", "tokens": ["Das", "hat", "der", "Leh\u00b7rer", "mir", "ge\u00b7schenkt", "\u2013", "\u00ab", "ich", "nick\u00b7te", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "PPER", "VVPP", "$(", "$(", "PPER", "VVFIN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.18": {"text": "Und lie\u00df die Hand nach einer Mandel suchen ...", "tokens": ["Und", "lie\u00df", "die", "Hand", "nach", "ei\u00b7ner", "Man\u00b7del", "su\u00b7chen", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.19": {"text": "Und krabbelte ganz unten eine auf ...", "tokens": ["Und", "krab\u00b7bel\u00b7te", "ganz", "un\u00b7ten", "ei\u00b7ne", "auf", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ADV", "ART", "APPR", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.20": {"text": "Und bi\u00df sie durch ... und schob das gr\u00f6\u00dfte St\u00fcck", "tokens": ["Und", "bi\u00df", "sie", "durch", "...", "und", "schob", "das", "gr\u00f6\u00df\u00b7te", "St\u00fcck"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "APPR", "$(", "KON", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.21": {"text": "Dem Leckerm\u00e4dchen durch die schmalen Lippen ...", "tokens": ["Dem", "Le\u00b7cker\u00b7m\u00e4d\u00b7chen", "durch", "die", "schma\u00b7len", "Lip\u00b7pen", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.22": {"text": "Dann lachten wir ... und weich ward mir die Brust,", "tokens": ["Dann", "lach\u00b7ten", "wir", "...", "und", "weich", "ward", "mir", "die", "Brust", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$(", "KON", "ADJD", "VAFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.23": {"text": "Verschollenes hob aus D\u00e4mmertiefen sich,", "tokens": ["Ver\u00b7schol\u00b7le\u00b7nes", "hob", "aus", "D\u00e4m\u00b7mer\u00b7tie\u00b7fen", "sich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "APPR", "NN", "PRF", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.24": {"text": "Drin's lang bedeckt gelegen ... kam ... und ging", "tokens": ["Drin's", "lang", "be\u00b7deckt", "ge\u00b7le\u00b7gen", "...", "kam", "...", "und", "ging"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["ADV", "ADJD", "ADJD", "VVPP", "$(", "VVFIN", "$(", "KON", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.25": {"text": "Vorbei ... die Mandelbrocken schluckt' ich hinter ...", "tokens": ["Vor\u00b7bei", "...", "die", "Man\u00b7del\u00b7bro\u00b7cken", "schluckt'", "ich", "hin\u00b7ter", "..."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$(", "ART", "NN", "VVFIN", "PPER", "APPR", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.26": {"text": "Und k\u00fc\u00dfte Metas kleinen, roten Mund ...", "tokens": ["Und", "k\u00fc\u00df\u00b7te", "Me\u00b7tas", "klei\u00b7nen", ",", "ro\u00b7ten", "Mund", "..."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VVFIN", "NE", "ADJA", "$,", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Zum ersten Male heute soll das Kind", "tokens": ["Zum", "ers\u00b7ten", "Ma\u00b7le", "heu\u00b7te", "soll", "das", "Kind"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "ADJA", "NN", "ADV", "VMFIN", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Allein zur Schule gehn ... Nun weint's und schreit:", "tokens": ["Al\u00b7lein", "zur", "Schu\u00b7le", "gehn", "...", "Nun", "weint's", "und", "schreit", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "VVINF", "$(", "ADV", "VVFIN", "KON", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Es kann den Weg nicht finden ... und die Furcht", "tokens": ["Es", "kann", "den", "Weg", "nicht", "fin\u00b7den", "...", "und", "die", "Furcht"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ART", "NN", "PTKNEG", "VVINF", "$(", "KON", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Schn\u00fcrt ihm das kleine Herz zusammen ... das", "tokens": ["Schn\u00fcrt", "ihm", "das", "klei\u00b7ne", "Herz", "zu\u00b7sam\u00b7men", "...", "das"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "NN", "PTKVZ", "$(", "ART"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Vorgestern noch in heller Freude schlug", "tokens": ["Vor\u00b7ges\u00b7tern", "noch", "in", "hel\u00b7ler", "Freu\u00b7de", "schlug"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "APPR", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Und sich zum Richtplatz seiner Reinheit sehnte ...", "tokens": ["Und", "sich", "zum", "Richt\u00b7platz", "sei\u00b7ner", "Rein\u00b7heit", "sehn\u00b7te", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "APPRART", "NN", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Tiefsinn der Kindheit! \u2013 Sich aufs Leben freuen,", "tokens": ["Tief\u00b7sinn", "der", "Kind\u00b7heit", "!", "\u2013", "Sich", "aufs", "Le\u00b7ben", "freu\u00b7en", ","], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "$.", "$(", "PRF", "APPRART", "NN", "VVINF", "$,"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.8": {"text": "Es nicht erwarten k\u00f6nnen. \u2013 Ach! Wir alle,", "tokens": ["Es", "nicht", "er\u00b7war\u00b7ten", "k\u00f6n\u00b7nen", ".", "\u2013", "Ach", "!", "Wir", "al\u00b7le", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "PTKNEG", "VVINF", "VMINF", "$.", "$(", "ITJ", "$.", "PPER", "PIS", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Die wir nun alt und m\u00fcd geworden sind,", "tokens": ["Die", "wir", "nun", "alt", "und", "m\u00fcd", "ge\u00b7wor\u00b7den", "sind", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "ADJD", "KON", "ADJD", "VAPP", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Wir haben's auch einmal getan! Doch keiner,", "tokens": ["Wir", "ha\u00b7ben's", "auch", "ein\u00b7mal", "ge\u00b7tan", "!", "Doch", "kei\u00b7ner", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "VVPP", "$.", "KON", "PIS", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "Den nicht auch einmal j\u00e4h die Furcht gepackt", "tokens": ["Den", "nicht", "auch", "ein\u00b7mal", "j\u00e4h", "die", "Furcht", "ge\u00b7packt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "PTKNEG", "ADV", "ADV", "ADJD", "ART", "NN", "VVPP"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "Vor dieses Lebens ungeheurem Wirrwarr \u2013", "tokens": ["Vor", "die\u00b7ses", "Le\u00b7bens", "un\u00b7ge\u00b7heu\u00b7rem", "Wirr\u00b7warr", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "Der nicht auch einmal bangte, ob er nicht", "tokens": ["Der", "nicht", "auch", "ein\u00b7mal", "bang\u00b7te", ",", "ob", "er", "nicht"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "PTKNEG", "ADV", "ADV", "VVFIN", "$,", "KOUS", "PPER", "PTKNEG"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "In diesem Dickicht doch den Weg verl\u00f6re ...", "tokens": ["In", "die\u00b7sem", "Di\u00b7ckicht", "doch", "den", "Weg", "ver\u00b7l\u00f6\u00b7re", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "ADV", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.15": {"text": "Und nimmermehr zu seinem Ziele kehre \u2013?", "tokens": ["Und", "nim\u00b7mer\u00b7mehr", "zu", "sei\u00b7nem", "Zie\u00b7le", "keh\u00b7re", "\u2013", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ADV", "APPR", "PPOSAT", "NN", "VVFIN", "$(", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.16": {"text": "Es stockt sein Fu\u00df ... und ratlos irrt sein Blick ...", "tokens": ["Es", "stockt", "sein", "Fu\u00df", "...", "und", "rat\u00b7los", "irrt", "sein", "Blick", "..."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "$(", "KON", "ADJD", "VVFIN", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.17": {"text": "Sein Atem steht ... Mein Gott! Nun doch zur\u00fcck \u2013?", "tokens": ["Sein", "A\u00b7tem", "steht", "...", "Mein", "Gott", "!", "Nun", "doch", "zu\u00b7r\u00fcck", "\u2013", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "$(", "PPOSAT", "NN", "$.", "ADV", "ADV", "PTKVZ", "$(", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.18": {"text": "Nein! Vorw\u00e4rts! Nun? Ach irgendwo ein Pfad", "tokens": ["Nein", "!", "Vor\u00b7w\u00e4rts", "!", "Nun", "?", "Ach", "ir\u00b7gend\u00b7wo", "ein", "Pfad"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["PTKANT", "$.", "ADV", "$.", "ADV", "$.", "ITJ", "ADV", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.19": {"text": "Wird sich schon finden \u2013 ob's der rechte ist \u2013", "tokens": ["Wird", "sich", "schon", "fin\u00b7den", "\u2013", "ob's", "der", "rech\u00b7te", "ist", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PRF", "ADV", "VVINF", "$(", "KOUS", "ART", "ADJA", "VAFIN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.20": {"text": "Wer w\u00fc\u00dfte es! \u2013 Das aber wissen wir:", "tokens": ["Wer", "w\u00fc\u00df\u00b7te", "es", "!", "\u2013", "Das", "a\u00b7ber", "wis\u00b7sen", "wir", ":"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "$.", "$(", "PDS", "ADV", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.21": {"text": "Zur Wirklichkeit den Irrtum umzubiegen:", "tokens": ["Zur", "Wirk\u00b7lich\u00b7keit", "den", "Irr\u00b7tum", "um\u00b7zu\u00b7bie\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.22": {"text": "Wir klugen Menschen nennen's eine \u00bb", "tokens": ["Wir", "klu\u00b7gen", "Men\u00b7schen", "nen\u00b7nen's", "ei\u00b7ne", "\u00bb"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "VVFIN", "ART", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.23": {"text": "Und f\u00fcr die allerletzte Nacht die Herberg' \u2013", "tokens": ["Und", "f\u00fcr", "die", "al\u00b7ler\u00b7letz\u00b7te", "Nacht", "die", "Her\u00b7ber\u00b7g'", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Kann schlie\u00dflich auch an ", "tokens": ["Kann", "schlie\u00df\u00b7lich", "auch", "an"], "token_info": ["word", "word", "word", "word"], "pos": ["VMFIN", "ADV", "ADV", "APPR"], "meter": "-+--+", "measure": "iambic.di.chol"}}, "stanza.3": {"line.1": {"text": "Ob Meta morgen wieder weinen wird \u2013? ...", "tokens": ["Ob", "Me\u00b7ta", "mor\u00b7gen", "wie\u00b7der", "wei\u00b7nen", "wird", "\u2013", "?", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["KOUS", "NE", "ADV", "ADV", "VVINF", "VAFIN", "$(", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Am Donnerstag kam Meta in die Schule,", "tokens": ["Am", "Don\u00b7ners\u00b7tag", "kam", "Me\u00b7ta", "in", "die", "Schu\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "NE", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Am Donnerstag nach Ostern. \u2013 Wie das Kind", "tokens": ["Am", "Don\u00b7ners\u00b7tag", "nach", "Os\u00b7tern", ".", "\u2013", "Wie", "das", "Kind"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word"], "pos": ["APPRART", "NN", "APPR", "NN", "$.", "$(", "PWAV", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Sich drauf gefreut hat! Wie sein kleines Herz", "tokens": ["Sich", "drauf", "ge\u00b7freut", "hat", "!", "Wie", "sein", "klei\u00b7nes", "Herz"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PRF", "PAV", "VVPP", "VAFIN", "$.", "PWAV", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Der M\u00e4dchentr\u00e4ume bunte F\u00fclle tr\u00e4umte!", "tokens": ["Der", "M\u00e4d\u00b7chen\u00b7tr\u00e4u\u00b7me", "bun\u00b7te", "F\u00fcl\u00b7le", "tr\u00e4um\u00b7te", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Die Tage all vorher hat's von dem einen,", "tokens": ["Die", "Ta\u00b7ge", "all", "vor\u00b7her", "hat's", "von", "dem", "ei\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PIAT", "ADV", "VAFIN", "APPR", "ART", "ART", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Von diesem einen immer nur geplaudert \u2013", "tokens": ["Von", "die\u00b7sem", "ei\u00b7nen", "im\u00b7mer", "nur", "ge\u00b7plau\u00b7dert", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "ART", "ADV", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Selbst in den festen Jugendschlaf schlich sich", "tokens": ["Selbst", "in", "den", "fes\u00b7ten", "Ju\u00b7gend\u00b7schlaf", "schlich", "sich"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN", "ADJD", "PRF"], "meter": "---+-+-++-", "measure": "unknown.measure.tetra"}, "line.8": {"text": "Die Neugier lockernd ... Und dann kam der Tag ...", "tokens": ["Die", "Neu\u00b7gier", "lo\u00b7ckernd", "...", "Und", "dann", "kam", "der", "Tag", "..."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "$(", "KON", "ADV", "VVFIN", "ART", "NN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Und kaum zu b\u00e4ndigen von der Hand der Mutter,", "tokens": ["Und", "kaum", "zu", "b\u00e4n\u00b7di\u00b7gen", "von", "der", "Hand", "der", "Mut\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PTKZU", "VVINF", "APPR", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.10": {"text": "Die es zur Schule brachte, war das M\u00e4dchen ...", "tokens": ["Die", "es", "zur", "Schu\u00b7le", "brach\u00b7te", ",", "war", "das", "M\u00e4d\u00b7chen", "..."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPRART", "NN", "VVFIN", "$,", "VAFIN", "ART", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "Nachher kam's zu mir. In den braunen Augen", "tokens": ["Nach\u00b7her", "kam's", "zu", "mir", ".", "In", "den", "brau\u00b7nen", "Au\u00b7gen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "APPR", "PPER", "$.", "APPR", "ART", "ADJA", "NN"], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.12": {"text": "Stand klares Leuchten ... und der Freude Schimmer", "tokens": ["Stand", "kla\u00b7res", "Leuch\u00b7ten", "...", "und", "der", "Freu\u00b7de", "Schim\u00b7mer"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "ADJA", "NN", "$(", "KON", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "Entz\u00fcckte hold das zarte Angesicht ...", "tokens": ["Ent\u00b7z\u00fcck\u00b7te", "hold", "das", "zar\u00b7te", "An\u00b7ge\u00b7sicht", "..."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "Die kleinen d\u00fcnnen Finger hielten tapfer", "tokens": ["Die", "klei\u00b7nen", "d\u00fcn\u00b7nen", "Fin\u00b7ger", "hiel\u00b7ten", "tap\u00b7fer"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "ADJA", "NN", "VVFIN", "ADJD"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.15": {"text": "Die rote D\u00fcte, die fast gr\u00f6\u00dfer war,", "tokens": ["Die", "ro\u00b7te", "D\u00fc\u00b7te", ",", "die", "fast", "gr\u00f6\u00b7\u00dfer", "war", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PRELS", "ADV", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.16": {"text": "Denn's ganze winzige Pers\u00f6nchen ... \u00bbOnkel!", "tokens": ["Denn's", "gan\u00b7ze", "win\u00b7zi\u00b7ge", "Per\u00b7s\u00f6n\u00b7chen", "...", "\u00bb", "On\u00b7kel", "!"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "$(", "$(", "NN", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.17": {"text": "Das hat der Lehrer mir geschenkt \u2013\u00ab ich nickte ...", "tokens": ["Das", "hat", "der", "Leh\u00b7rer", "mir", "ge\u00b7schenkt", "\u2013", "\u00ab", "ich", "nick\u00b7te", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "PPER", "VVPP", "$(", "$(", "PPER", "VVFIN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.18": {"text": "Und lie\u00df die Hand nach einer Mandel suchen ...", "tokens": ["Und", "lie\u00df", "die", "Hand", "nach", "ei\u00b7ner", "Man\u00b7del", "su\u00b7chen", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.19": {"text": "Und krabbelte ganz unten eine auf ...", "tokens": ["Und", "krab\u00b7bel\u00b7te", "ganz", "un\u00b7ten", "ei\u00b7ne", "auf", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ADV", "ART", "APPR", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.20": {"text": "Und bi\u00df sie durch ... und schob das gr\u00f6\u00dfte St\u00fcck", "tokens": ["Und", "bi\u00df", "sie", "durch", "...", "und", "schob", "das", "gr\u00f6\u00df\u00b7te", "St\u00fcck"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "APPR", "$(", "KON", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.21": {"text": "Dem Leckerm\u00e4dchen durch die schmalen Lippen ...", "tokens": ["Dem", "Le\u00b7cker\u00b7m\u00e4d\u00b7chen", "durch", "die", "schma\u00b7len", "Lip\u00b7pen", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.22": {"text": "Dann lachten wir ... und weich ward mir die Brust,", "tokens": ["Dann", "lach\u00b7ten", "wir", "...", "und", "weich", "ward", "mir", "die", "Brust", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$(", "KON", "ADJD", "VAFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.23": {"text": "Verschollenes hob aus D\u00e4mmertiefen sich,", "tokens": ["Ver\u00b7schol\u00b7le\u00b7nes", "hob", "aus", "D\u00e4m\u00b7mer\u00b7tie\u00b7fen", "sich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "APPR", "NN", "PRF", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.24": {"text": "Drin's lang bedeckt gelegen ... kam ... und ging", "tokens": ["Drin's", "lang", "be\u00b7deckt", "ge\u00b7le\u00b7gen", "...", "kam", "...", "und", "ging"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["ADV", "ADJD", "ADJD", "VVPP", "$(", "VVFIN", "$(", "KON", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.25": {"text": "Vorbei ... die Mandelbrocken schluckt' ich hinter ...", "tokens": ["Vor\u00b7bei", "...", "die", "Man\u00b7del\u00b7bro\u00b7cken", "schluckt'", "ich", "hin\u00b7ter", "..."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$(", "ART", "NN", "VVFIN", "PPER", "APPR", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.26": {"text": "Und k\u00fc\u00dfte Metas kleinen, roten Mund ...", "tokens": ["Und", "k\u00fc\u00df\u00b7te", "Me\u00b7tas", "klei\u00b7nen", ",", "ro\u00b7ten", "Mund", "..."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VVFIN", "NE", "ADJA", "$,", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "Zum ersten Male heute soll das Kind", "tokens": ["Zum", "ers\u00b7ten", "Ma\u00b7le", "heu\u00b7te", "soll", "das", "Kind"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "ADJA", "NN", "ADV", "VMFIN", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Allein zur Schule gehn ... Nun weint's und schreit:", "tokens": ["Al\u00b7lein", "zur", "Schu\u00b7le", "gehn", "...", "Nun", "weint's", "und", "schreit", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "VVINF", "$(", "ADV", "VVFIN", "KON", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Es kann den Weg nicht finden ... und die Furcht", "tokens": ["Es", "kann", "den", "Weg", "nicht", "fin\u00b7den", "...", "und", "die", "Furcht"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ART", "NN", "PTKNEG", "VVINF", "$(", "KON", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Schn\u00fcrt ihm das kleine Herz zusammen ... das", "tokens": ["Schn\u00fcrt", "ihm", "das", "klei\u00b7ne", "Herz", "zu\u00b7sam\u00b7men", "...", "das"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "NN", "PTKVZ", "$(", "ART"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Vorgestern noch in heller Freude schlug", "tokens": ["Vor\u00b7ges\u00b7tern", "noch", "in", "hel\u00b7ler", "Freu\u00b7de", "schlug"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "APPR", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Und sich zum Richtplatz seiner Reinheit sehnte ...", "tokens": ["Und", "sich", "zum", "Richt\u00b7platz", "sei\u00b7ner", "Rein\u00b7heit", "sehn\u00b7te", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "APPRART", "NN", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Tiefsinn der Kindheit! \u2013 Sich aufs Leben freuen,", "tokens": ["Tief\u00b7sinn", "der", "Kind\u00b7heit", "!", "\u2013", "Sich", "aufs", "Le\u00b7ben", "freu\u00b7en", ","], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "$.", "$(", "PRF", "APPRART", "NN", "VVINF", "$,"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.8": {"text": "Es nicht erwarten k\u00f6nnen. \u2013 Ach! Wir alle,", "tokens": ["Es", "nicht", "er\u00b7war\u00b7ten", "k\u00f6n\u00b7nen", ".", "\u2013", "Ach", "!", "Wir", "al\u00b7le", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "PTKNEG", "VVINF", "VMINF", "$.", "$(", "ITJ", "$.", "PPER", "PIS", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Die wir nun alt und m\u00fcd geworden sind,", "tokens": ["Die", "wir", "nun", "alt", "und", "m\u00fcd", "ge\u00b7wor\u00b7den", "sind", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "ADJD", "KON", "ADJD", "VAPP", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Wir haben's auch einmal getan! Doch keiner,", "tokens": ["Wir", "ha\u00b7ben's", "auch", "ein\u00b7mal", "ge\u00b7tan", "!", "Doch", "kei\u00b7ner", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "VVPP", "$.", "KON", "PIS", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "Den nicht auch einmal j\u00e4h die Furcht gepackt", "tokens": ["Den", "nicht", "auch", "ein\u00b7mal", "j\u00e4h", "die", "Furcht", "ge\u00b7packt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "PTKNEG", "ADV", "ADV", "ADJD", "ART", "NN", "VVPP"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "Vor dieses Lebens ungeheurem Wirrwarr \u2013", "tokens": ["Vor", "die\u00b7ses", "Le\u00b7bens", "un\u00b7ge\u00b7heu\u00b7rem", "Wirr\u00b7warr", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "Der nicht auch einmal bangte, ob er nicht", "tokens": ["Der", "nicht", "auch", "ein\u00b7mal", "bang\u00b7te", ",", "ob", "er", "nicht"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "PTKNEG", "ADV", "ADV", "VVFIN", "$,", "KOUS", "PPER", "PTKNEG"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "In diesem Dickicht doch den Weg verl\u00f6re ...", "tokens": ["In", "die\u00b7sem", "Di\u00b7ckicht", "doch", "den", "Weg", "ver\u00b7l\u00f6\u00b7re", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "ADV", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.15": {"text": "Und nimmermehr zu seinem Ziele kehre \u2013?", "tokens": ["Und", "nim\u00b7mer\u00b7mehr", "zu", "sei\u00b7nem", "Zie\u00b7le", "keh\u00b7re", "\u2013", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ADV", "APPR", "PPOSAT", "NN", "VVFIN", "$(", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.16": {"text": "Es stockt sein Fu\u00df ... und ratlos irrt sein Blick ...", "tokens": ["Es", "stockt", "sein", "Fu\u00df", "...", "und", "rat\u00b7los", "irrt", "sein", "Blick", "..."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "$(", "KON", "ADJD", "VVFIN", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.17": {"text": "Sein Atem steht ... Mein Gott! Nun doch zur\u00fcck \u2013?", "tokens": ["Sein", "A\u00b7tem", "steht", "...", "Mein", "Gott", "!", "Nun", "doch", "zu\u00b7r\u00fcck", "\u2013", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "$(", "PPOSAT", "NN", "$.", "ADV", "ADV", "PTKVZ", "$(", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.18": {"text": "Nein! Vorw\u00e4rts! Nun? Ach irgendwo ein Pfad", "tokens": ["Nein", "!", "Vor\u00b7w\u00e4rts", "!", "Nun", "?", "Ach", "ir\u00b7gend\u00b7wo", "ein", "Pfad"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["PTKANT", "$.", "ADV", "$.", "ADV", "$.", "ITJ", "ADV", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.19": {"text": "Wird sich schon finden \u2013 ob's der rechte ist \u2013", "tokens": ["Wird", "sich", "schon", "fin\u00b7den", "\u2013", "ob's", "der", "rech\u00b7te", "ist", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PRF", "ADV", "VVINF", "$(", "KOUS", "ART", "ADJA", "VAFIN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.20": {"text": "Wer w\u00fc\u00dfte es! \u2013 Das aber wissen wir:", "tokens": ["Wer", "w\u00fc\u00df\u00b7te", "es", "!", "\u2013", "Das", "a\u00b7ber", "wis\u00b7sen", "wir", ":"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "$.", "$(", "PDS", "ADV", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.21": {"text": "Zur Wirklichkeit den Irrtum umzubiegen:", "tokens": ["Zur", "Wirk\u00b7lich\u00b7keit", "den", "Irr\u00b7tum", "um\u00b7zu\u00b7bie\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.22": {"text": "Wir klugen Menschen nennen's eine \u00bb", "tokens": ["Wir", "klu\u00b7gen", "Men\u00b7schen", "nen\u00b7nen's", "ei\u00b7ne", "\u00bb"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "VVFIN", "ART", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.23": {"text": "Und f\u00fcr die allerletzte Nacht die Herberg' \u2013", "tokens": ["Und", "f\u00fcr", "die", "al\u00b7ler\u00b7letz\u00b7te", "Nacht", "die", "Her\u00b7ber\u00b7g'", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Kann schlie\u00dflich auch an ", "tokens": ["Kann", "schlie\u00df\u00b7lich", "auch", "an"], "token_info": ["word", "word", "word", "word"], "pos": ["VMFIN", "ADV", "ADV", "APPR"], "meter": "-+--+", "measure": "iambic.di.chol"}}, "stanza.6": {"line.1": {"text": "Ob Meta morgen wieder weinen wird \u2013? ...", "tokens": ["Ob", "Me\u00b7ta", "mor\u00b7gen", "wie\u00b7der", "wei\u00b7nen", "wird", "\u2013", "?", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["KOUS", "NE", "ADV", "ADV", "VVINF", "VAFIN", "$(", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}}}}