{"textgrid.poem.52877": {"metadata": {"author": {"name": "Dingelstedt, Franz von", "birth": "N.A.", "death": "N.A."}, "title": "1L: Das ist der Dom mit seinen Mirakeln,", "genre": "verse", "period": "N.A.", "pub_year": 1847, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Das ist der Dom mit seinen Mirakeln,", "tokens": ["Das", "ist", "der", "Dom", "mit", "sei\u00b7nen", "Mi\u00b7ra\u00b7keln", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Mit Heiligen aus Stein und Holz,", "tokens": ["Mit", "Hei\u00b7li\u00b7gen", "aus", "Stein", "und", "Holz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mit kostbaren Knochen in Tabernakeln,", "tokens": ["Mit", "kost\u00b7ba\u00b7ren", "Kno\u00b7chen", "in", "Ta\u00b7ber\u00b7na\u00b7keln", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "APPR", "NN", "$,"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Mit Kuppeln, S\u00e4ulen und T\u00fcrmen stolz.", "tokens": ["Mit", "Kup\u00b7peln", ",", "S\u00e4u\u00b7len", "und", "T\u00fcr\u00b7men", "stolz", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "KON", "NN", "ADJD", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.2": {"line.1": {"text": "Vom Hochaltar dringt ein schwacher Schimmer,", "tokens": ["Vom", "Hoc\u00b7hal\u00b7tar", "dringt", "ein", "schwa\u00b7cher", "Schim\u00b7mer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Ein Wehen bl\u00e4st durch die G\u00e4nge hin,", "tokens": ["Ein", "We\u00b7hen", "bl\u00e4st", "durch", "die", "G\u00e4n\u00b7ge", "hin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "In den Orgelpfeifen Kindergewimmer: \u2013", "tokens": ["In", "den", "Or\u00b7gel\u00b7pfei\u00b7fen", "Kin\u00b7der\u00b7ge\u00b7wim\u00b7mer", ":", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "ART", "NN", "NN", "$.", "$("], "meter": "--+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Es graut mich! Was ich doch kindisch bin!", "tokens": ["Es", "graut", "mich", "!", "Was", "ich", "doch", "kin\u00b7disch", "bin", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$.", "PWS", "PPER", "ADV", "ADJD", "VAFIN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.3": {"line.1": {"text": "Seit zwanzig Jahren nicht dringewesen,", "tokens": ["Seit", "zwan\u00b7zig", "Jah\u00b7ren", "nicht", "drin\u00b7ge\u00b7we\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "CARD", "NN", "PTKNEG", "VVINF", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Zur Beichte nicht, nicht zum Sakrament, \u2013", "tokens": ["Zur", "Beich\u00b7te", "nicht", ",", "nicht", "zum", "Sak\u00b7ra\u00b7ment", ",", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["APPRART", "NN", "PTKNEG", "$,", "PTKNEG", "APPRART", "NN", "$,", "$("], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Daheim nicht in der Bibel gelesen, \u2013", "tokens": ["Da\u00b7heim", "nicht", "in", "der", "Bi\u00b7bel", "ge\u00b7le\u00b7sen", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PAV", "PTKNEG", "APPR", "ART", "NN", "VVPP", "$,", "$("], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Ob mich der alte Herr-Gott noch kennt?", "tokens": ["Ob", "mich", "der", "al\u00b7te", "Herr\u00b7Gott", "noch", "kennt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.4": {"line.1": {"text": "Ich will an die schallenden Pforten pochen.", "tokens": ["Ich", "will", "an", "die", "schal\u00b7len\u00b7den", "Pfor\u00b7ten", "po\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPR", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Die sind verschlossen. Niemand zu Haus ...", "tokens": ["Die", "sind", "ver\u00b7schlos\u00b7sen", ".", "Nie\u00b7mand", "zu", "Haus", "..."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "VVPP", "$.", "PIS", "APPR", "NN", "$("], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Was ist das? Hat hier ein Mensch gesprochen?", "tokens": ["Was", "ist", "das", "?", "Hat", "hier", "ein", "Mensch", "ge\u00b7spro\u00b7chen", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PDS", "$.", "VAFIN", "ADV", "ART", "NN", "VVPP", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Lacht mich die H\u00f6lle von drinnen aus?", "tokens": ["Lacht", "mich", "die", "H\u00f6l\u00b7le", "von", "drin\u00b7nen", "aus", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "APPR", "ADV", "PTKVZ", "$."], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}}, "stanza.5": {"line.1": {"text": "Ich soll mit den \u00dcbrigen wiederkommen,", "tokens": ["Ich", "soll", "mit", "den", "\u00dcb\u00b7ri\u00b7gen", "wie\u00b7der\u00b7kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Reingewaschen, sonntagsfr\u00fch,", "tokens": ["Rein\u00b7ge\u00b7wa\u00b7schen", ",", "sonn\u00b7tags\u00b7fr\u00fch", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$,", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Mit den abonnierten Wochen-Frommen,", "tokens": ["Mit", "den", "a\u00b7bon\u00b7nier\u00b7ten", "Wo\u00b7chen\u00b7From\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "So glei\u00dfnerisch und so bigott wie sie.", "tokens": ["So", "glei\u00df\u00b7ne\u00b7risch", "und", "so", "bi\u00b7gott", "wie", "sie", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KON", "ADV", "ADJD", "KOKOM", "PPER", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "Nein, ich will mich nicht in die H\u00fcrde sperren,", "tokens": ["Nein", ",", "ich", "will", "mich", "nicht", "in", "die", "H\u00fcr\u00b7de", "sper\u00b7ren", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PPER", "VMFIN", "PPER", "PTKNEG", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Vom Hunde gejagt, mit der \u00fcbrigen Herd',", "tokens": ["Vom", "Hun\u00b7de", "ge\u00b7jagt", ",", "mit", "der", "\u00fcb\u00b7ri\u00b7gen", "Herd'", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVPP", "$,", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.3": {"text": "Wenn du der Herr bist unter den Herren,", "tokens": ["Wenn", "du", "der", "Herr", "bist", "un\u00b7ter", "den", "Her\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VAFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Suche mich, so ich dir etwas wert.", "tokens": ["Su\u00b7che", "mich", ",", "so", "ich", "dir", "et\u00b7was", "wert", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "ADV", "PPER", "PPER", "ADV", "ADJD", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.7": {"line.1": {"text": "Geschrieben steht: Es ist gr\u00f6\u00dfere Freude", "tokens": ["Ge\u00b7schrie\u00b7ben", "steht", ":", "Es", "ist", "gr\u00f6\u00b7\u00dfe\u00b7re", "Freu\u00b7de"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "$.", "PPER", "VAFIN", "ADJA", "NN"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "\u00dcber ein einzig verirrtes Tier", "tokens": ["\u00dc\u00b7ber", "ein", "ein\u00b7zig", "ver\u00b7irr\u00b7tes", "Tier"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJD", "ADJA", "NN"], "meter": "+-+---+-+", "measure": "unknown.measure.tetra"}, "line.3": {"text": "Als \u00fcber eine gesammelte Weide, \u2013", "tokens": ["Als", "\u00fc\u00b7ber", "ei\u00b7ne", "ge\u00b7sam\u00b7mel\u00b7te", "Wei\u00b7de", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "APPR", "ART", "ADJA", "NN", "$,", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Wohlan, mein Hirt, ich irre nach dir.", "tokens": ["Wo\u00b7hlan", ",", "mein", "Hirt", ",", "ich", "ir\u00b7re", "nach", "dir", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PPOSAT", "NN", "$,", "PPER", "VVFIN", "APPR", "PPER", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.8": {"line.1": {"text": "Ich stehe allein an deinen Pforten,", "tokens": ["Ich", "ste\u00b7he", "al\u00b7lein", "an", "dei\u00b7nen", "Pfor\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Sie tun sich nicht auf, dein Haus bleibt stumm,", "tokens": ["Sie", "tun", "sich", "nicht", "auf", ",", "dein", "Haus", "bleibt", "stumm", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "PTKNEG", "PTKVZ", "$,", "PPOSAT", "NN", "VVFIN", "ADJD", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Die Nacht ist schwarz und tonlos 'worden,", "tokens": ["Die", "Nacht", "ist", "schwarz", "und", "ton\u00b7los", "'wor\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "KON", "ADJD", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Der Mond h\u00e4ngt dr\u00e4uende Schleier um.", "tokens": ["Der", "Mond", "h\u00e4ngt", "dr\u00e4u\u00b7en\u00b7de", "Schlei\u00b7er", "um", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.9": {"line.1": {"text": "Ein Strahl nur noch aus den finstern Gr\u00fcnden,", "tokens": ["Ein", "Strahl", "nur", "noch", "aus", "den", "fins\u00b7tern", "Gr\u00fcn\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ADV", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Er trifft das vergoldete Kreuz von Erz:", "tokens": ["Er", "trifft", "das", "ver\u00b7gol\u00b7de\u00b7te", "Kreuz", "von", "Erz", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "APPR", "NN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Kannst du, Beleuchter, das kalte entz\u00fcnden,", "tokens": ["Kannst", "du", ",", "Be\u00b7leuch\u00b7ter", ",", "das", "kal\u00b7te", "ent\u00b7z\u00fcn\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "$,", "NN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.4": {"text": "Kannst du entz\u00fcnden mein k\u00e4lteres Herz?", "tokens": ["Kannst", "du", "ent\u00b7z\u00fcn\u00b7den", "mein", "k\u00e4l\u00b7te\u00b7res", "Herz", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "VVFIN", "PPOSAT", "ADJA", "NN", "$."], "meter": "+--+--+--+", "measure": "dactylic.tetra"}}, "stanza.10": {"line.1": {"text": "Das ist der Dom mit seinen Mirakeln,", "tokens": ["Das", "ist", "der", "Dom", "mit", "sei\u00b7nen", "Mi\u00b7ra\u00b7keln", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Mit Heiligen aus Stein und Holz,", "tokens": ["Mit", "Hei\u00b7li\u00b7gen", "aus", "Stein", "und", "Holz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mit kostbaren Knochen in Tabernakeln,", "tokens": ["Mit", "kost\u00b7ba\u00b7ren", "Kno\u00b7chen", "in", "Ta\u00b7ber\u00b7na\u00b7keln", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "APPR", "NN", "$,"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Mit Kuppeln, S\u00e4ulen und T\u00fcrmen stolz.", "tokens": ["Mit", "Kup\u00b7peln", ",", "S\u00e4u\u00b7len", "und", "T\u00fcr\u00b7men", "stolz", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "KON", "NN", "ADJD", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.11": {"line.1": {"text": "Vom Hochaltar dringt ein schwacher Schimmer,", "tokens": ["Vom", "Hoc\u00b7hal\u00b7tar", "dringt", "ein", "schwa\u00b7cher", "Schim\u00b7mer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Ein Wehen bl\u00e4st durch die G\u00e4nge hin,", "tokens": ["Ein", "We\u00b7hen", "bl\u00e4st", "durch", "die", "G\u00e4n\u00b7ge", "hin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "In den Orgelpfeifen Kindergewimmer: \u2013", "tokens": ["In", "den", "Or\u00b7gel\u00b7pfei\u00b7fen", "Kin\u00b7der\u00b7ge\u00b7wim\u00b7mer", ":", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "ART", "NN", "NN", "$.", "$("], "meter": "--+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Es graut mich! Was ich doch kindisch bin!", "tokens": ["Es", "graut", "mich", "!", "Was", "ich", "doch", "kin\u00b7disch", "bin", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$.", "PWS", "PPER", "ADV", "ADJD", "VAFIN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.12": {"line.1": {"text": "Seit zwanzig Jahren nicht dringewesen,", "tokens": ["Seit", "zwan\u00b7zig", "Jah\u00b7ren", "nicht", "drin\u00b7ge\u00b7we\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "CARD", "NN", "PTKNEG", "VVINF", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Zur Beichte nicht, nicht zum Sakrament, \u2013", "tokens": ["Zur", "Beich\u00b7te", "nicht", ",", "nicht", "zum", "Sak\u00b7ra\u00b7ment", ",", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["APPRART", "NN", "PTKNEG", "$,", "PTKNEG", "APPRART", "NN", "$,", "$("], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Daheim nicht in der Bibel gelesen, \u2013", "tokens": ["Da\u00b7heim", "nicht", "in", "der", "Bi\u00b7bel", "ge\u00b7le\u00b7sen", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PAV", "PTKNEG", "APPR", "ART", "NN", "VVPP", "$,", "$("], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Ob mich der alte Herr-Gott noch kennt?", "tokens": ["Ob", "mich", "der", "al\u00b7te", "Herr\u00b7Gott", "noch", "kennt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.13": {"line.1": {"text": "Ich will an die schallenden Pforten pochen.", "tokens": ["Ich", "will", "an", "die", "schal\u00b7len\u00b7den", "Pfor\u00b7ten", "po\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPR", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Die sind verschlossen. Niemand zu Haus ...", "tokens": ["Die", "sind", "ver\u00b7schlos\u00b7sen", ".", "Nie\u00b7mand", "zu", "Haus", "..."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "VVPP", "$.", "PIS", "APPR", "NN", "$("], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Was ist das? Hat hier ein Mensch gesprochen?", "tokens": ["Was", "ist", "das", "?", "Hat", "hier", "ein", "Mensch", "ge\u00b7spro\u00b7chen", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PDS", "$.", "VAFIN", "ADV", "ART", "NN", "VVPP", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Lacht mich die H\u00f6lle von drinnen aus?", "tokens": ["Lacht", "mich", "die", "H\u00f6l\u00b7le", "von", "drin\u00b7nen", "aus", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "APPR", "ADV", "PTKVZ", "$."], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}}, "stanza.14": {"line.1": {"text": "Ich soll mit den \u00dcbrigen wiederkommen,", "tokens": ["Ich", "soll", "mit", "den", "\u00dcb\u00b7ri\u00b7gen", "wie\u00b7der\u00b7kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Reingewaschen, sonntagsfr\u00fch,", "tokens": ["Rein\u00b7ge\u00b7wa\u00b7schen", ",", "sonn\u00b7tags\u00b7fr\u00fch", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$,", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Mit den abonnierten Wochen-Frommen,", "tokens": ["Mit", "den", "a\u00b7bon\u00b7nier\u00b7ten", "Wo\u00b7chen\u00b7From\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "So glei\u00dfnerisch und so bigott wie sie.", "tokens": ["So", "glei\u00df\u00b7ne\u00b7risch", "und", "so", "bi\u00b7gott", "wie", "sie", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KON", "ADV", "ADJD", "KOKOM", "PPER", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.15": {"line.1": {"text": "Nein, ich will mich nicht in die H\u00fcrde sperren,", "tokens": ["Nein", ",", "ich", "will", "mich", "nicht", "in", "die", "H\u00fcr\u00b7de", "sper\u00b7ren", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PPER", "VMFIN", "PPER", "PTKNEG", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Vom Hunde gejagt, mit der \u00fcbrigen Herd',", "tokens": ["Vom", "Hun\u00b7de", "ge\u00b7jagt", ",", "mit", "der", "\u00fcb\u00b7ri\u00b7gen", "Herd'", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVPP", "$,", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.3": {"text": "Wenn du der Herr bist unter den Herren,", "tokens": ["Wenn", "du", "der", "Herr", "bist", "un\u00b7ter", "den", "Her\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VAFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Suche mich, so ich dir etwas wert.", "tokens": ["Su\u00b7che", "mich", ",", "so", "ich", "dir", "et\u00b7was", "wert", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "ADV", "PPER", "PPER", "ADV", "ADJD", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.16": {"line.1": {"text": "Geschrieben steht: Es ist gr\u00f6\u00dfere Freude", "tokens": ["Ge\u00b7schrie\u00b7ben", "steht", ":", "Es", "ist", "gr\u00f6\u00b7\u00dfe\u00b7re", "Freu\u00b7de"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "$.", "PPER", "VAFIN", "ADJA", "NN"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "\u00dcber ein einzig verirrtes Tier", "tokens": ["\u00dc\u00b7ber", "ein", "ein\u00b7zig", "ver\u00b7irr\u00b7tes", "Tier"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJD", "ADJA", "NN"], "meter": "+-+---+-+", "measure": "unknown.measure.tetra"}, "line.3": {"text": "Als \u00fcber eine gesammelte Weide, \u2013", "tokens": ["Als", "\u00fc\u00b7ber", "ei\u00b7ne", "ge\u00b7sam\u00b7mel\u00b7te", "Wei\u00b7de", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "APPR", "ART", "ADJA", "NN", "$,", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Wohlan, mein Hirt, ich irre nach dir.", "tokens": ["Wo\u00b7hlan", ",", "mein", "Hirt", ",", "ich", "ir\u00b7re", "nach", "dir", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PPOSAT", "NN", "$,", "PPER", "VVFIN", "APPR", "PPER", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.17": {"line.1": {"text": "Ich stehe allein an deinen Pforten,", "tokens": ["Ich", "ste\u00b7he", "al\u00b7lein", "an", "dei\u00b7nen", "Pfor\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Sie tun sich nicht auf, dein Haus bleibt stumm,", "tokens": ["Sie", "tun", "sich", "nicht", "auf", ",", "dein", "Haus", "bleibt", "stumm", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "PTKNEG", "PTKVZ", "$,", "PPOSAT", "NN", "VVFIN", "ADJD", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Die Nacht ist schwarz und tonlos 'worden,", "tokens": ["Die", "Nacht", "ist", "schwarz", "und", "ton\u00b7los", "'wor\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "KON", "ADJD", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Der Mond h\u00e4ngt dr\u00e4uende Schleier um.", "tokens": ["Der", "Mond", "h\u00e4ngt", "dr\u00e4u\u00b7en\u00b7de", "Schlei\u00b7er", "um", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.18": {"line.1": {"text": "Ein Strahl nur noch aus den finstern Gr\u00fcnden,", "tokens": ["Ein", "Strahl", "nur", "noch", "aus", "den", "fins\u00b7tern", "Gr\u00fcn\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ADV", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Er trifft das vergoldete Kreuz von Erz:", "tokens": ["Er", "trifft", "das", "ver\u00b7gol\u00b7de\u00b7te", "Kreuz", "von", "Erz", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "APPR", "NN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Kannst du, Beleuchter, das kalte entz\u00fcnden,", "tokens": ["Kannst", "du", ",", "Be\u00b7leuch\u00b7ter", ",", "das", "kal\u00b7te", "ent\u00b7z\u00fcn\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "$,", "NN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.4": {"text": "Kannst du entz\u00fcnden mein k\u00e4lteres Herz?", "tokens": ["Kannst", "du", "ent\u00b7z\u00fcn\u00b7den", "mein", "k\u00e4l\u00b7te\u00b7res", "Herz", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "VVFIN", "PPOSAT", "ADJA", "NN", "$."], "meter": "+--+--+--+", "measure": "dactylic.tetra"}}}}}