{"textgrid.poem.41461": {"metadata": {"author": {"name": "Hagedorn, Friedrich von", "birth": "N.A.", "death": "N.A."}, "title": "Melson", "genre": "verse", "period": "N.A.", "pub_year": 1731, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Der Dollmetsch, welcher oft mehr Sprachen, als er wu\u00dfte,", "tokens": ["Der", "Doll\u00b7metsch", ",", "wel\u00b7cher", "oft", "mehr", "Spra\u00b7chen", ",", "als", "er", "wu\u00df\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ADV", "PIAT", "NN", "$,", "KOUS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Vor seiner K\u00f6nigin", "tokens": ["Vor", "sei\u00b7ner", "K\u00f6\u00b7ni\u00b7gin"], "token_info": ["word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Der schlaue Melson fand durch seine Munterkeit", "tokens": ["Der", "schlau\u00b7e", "Mel\u00b7son", "fand", "durch", "sei\u00b7ne", "Mun\u00b7ter\u00b7keit"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Den Rath, den nur der Witz verleiht.", "tokens": ["Den", "Rath", ",", "den", "nur", "der", "Witz", "ver\u00b7leiht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Einst k\u00f6mmt aus Indien ein schwarzer Abgesandter,", "tokens": ["Einst", "k\u00f6mmt", "aus", "In\u00b7di\u00b7en", "ein", "schwar\u00b7zer", "Ab\u00b7ge\u00b7sand\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "NE", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Erscheinet vor dem Thron, und f\u00e4ngt den Vortrag an,", "tokens": ["Er\u00b7schei\u00b7net", "vor", "dem", "Thron", ",", "und", "f\u00e4ngt", "den", "Vor\u00b7trag", "an", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "$,", "KON", "VVFIN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Den er nicht \u00fcbersetzen kann;", "tokens": ["Den", "er", "nicht", "\u00fc\u00b7bers\u00b7et\u00b7zen", "kann", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PTKNEG", "VVINF", "VMFIN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.8": {"text": "Denn keine Sprache war dem Melson unbekannter.", "tokens": ["Denn", "kei\u00b7ne", "Spra\u00b7che", "war", "dem", "Mel\u00b7son", "un\u00b7be\u00b7kann\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "VAFIN", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Doch hilft die List ihm aus. Ihm winkt die K\u00f6nigin.", "tokens": ["Doch", "hilft", "die", "List", "ihm", "aus", ".", "Ihm", "winkt", "die", "K\u00f6\u00b7ni\u00b7gin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "PPER", "PTKVZ", "$.", "PPER", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Er n\u00e4hert sich, und spricht: Die\u00df ist der Rede Sinn:", "tokens": ["Er", "n\u00e4\u00b7hert", "sich", ",", "und", "spricht", ":", "Die\u00df", "ist", "der", "Re\u00b7de", "Sinn", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "$,", "KON", "VVFIN", "$.", "PDS", "VAFIN", "ART", "NN", "NN", "$."], "meter": "-++--+-+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.2": {"line.1": {"text": "Gro\u00dfm\u00e4chtigste, dein Ruhm dringt bis in unsre Grenzen.", "tokens": ["Gro\u00df\u00b7m\u00e4ch\u00b7tigs\u00b7te", ",", "dein", "Ruhm", "dringt", "bis", "in", "uns\u00b7re", "Gren\u00b7zen", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "$,", "PPOSAT", "NN", "VVFIN", "ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Nur dich verehrt ein jeder Theil der Welt.", "tokens": ["Nur", "dich", "ver\u00b7ehrt", "ein", "je\u00b7der", "Theil", "der", "Welt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VVFIN", "ART", "PIAT", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Wo sollte nicht, in Marmor aufgestellt,", "tokens": ["Wo", "soll\u00b7te", "nicht", ",", "in", "Mar\u00b7mor", "auf\u00b7ge\u00b7stellt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "PTKNEG", "$,", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Dein Bild und Lob den sp\u00e4tsten Enkeln gl\u00e4nzen?", "tokens": ["Dein", "Bild", "und", "Lob", "den", "sp\u00e4ts\u00b7ten", "En\u00b7keln", "gl\u00e4n\u00b7zen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "NN", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Es ist dir Brama hold. Zur Ehre schuf er dich.", "tokens": ["Es", "ist", "dir", "Bra\u00b7ma", "hold", ".", "Zur", "Eh\u00b7re", "schuf", "er", "dich", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "NE", "ADJD", "$.", "APPRART", "NN", "VVFIN", "PPER", "PRF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Dein Anblick, wie dein Geist, ist mehr als k\u00f6niglich.", "tokens": ["Dein", "An\u00b7blick", ",", "wie", "dein", "Geist", ",", "ist", "mehr", "als", "k\u00f6\u00b7nig\u00b7lich", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PWAV", "PPOSAT", "NN", "$,", "VAFIN", "PIS", "KOKOM", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Die\u00df h\u00f6rte Tavernier, der sich im Saal befand.", "tokens": ["Die\u00df", "h\u00f6r\u00b7te", "Ta\u00b7ver\u00b7nier", ",", "der", "sich", "im", "Saal", "be\u00b7fand", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "NN", "$,", "PRELS", "PRF", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Des Fremden Sprache war ihm ganz genau bekannt.", "tokens": ["Des", "Frem\u00b7den", "Spra\u00b7che", "war", "ihm", "ganz", "ge\u00b7nau", "be\u00b7kannt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VAFIN", "PPER", "ADV", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Er hatte, wie man wei\u00df, von seinen vielen Reisen", "tokens": ["Er", "hat\u00b7te", ",", "wie", "man", "wei\u00df", ",", "von", "sei\u00b7nen", "vie\u00b7len", "Rei\u00b7sen"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "$,", "PWAV", "PIS", "VVFIN", "$,", "APPR", "PPOSAT", "PIAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Mehr, als ein Stammbuch, aufzuweisen.", "tokens": ["Mehr", ",", "als", "ein", "Stamm\u00b7buch", ",", "auf\u00b7zu\u00b7wei\u00b7sen", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["PIS", "$,", "KOUS", "ART", "NN", "$,", "VVIZU", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Er sagte: K\u00f6nigin, was Melson jetzo spricht,", "tokens": ["Er", "sag\u00b7te", ":", "K\u00f6\u00b7ni\u00b7gin", ",", "was", "Mel\u00b7son", "jet\u00b7zo", "spricht", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "NN", "$,", "PRELS", "NE", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Das redet der Gesandte nicht.", "tokens": ["Das", "re\u00b7det", "der", "Ge\u00b7sand\u00b7te", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ART", "NN", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Wer wird, sprach Melson drauf, den Mischmasch wissen wollen?", "tokens": ["Wer", "wird", ",", "sprach", "Mel\u00b7son", "drauf", ",", "den", "Mischmasch", "wis\u00b7sen", "wol\u00b7len", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "$,", "VVFIN", "NE", "PTKVZ", "$,", "ART", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Mir liegt die Pflicht der Ehrfurcht ob.", "tokens": ["Mir", "liegt", "die", "Pflicht", "der", "Ehr\u00b7furcht", "ob", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ART", "NN", "KOUS", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die K\u00f6nigin verdient das Lob:", "tokens": ["Die", "K\u00f6\u00b7ni\u00b7gin", "ver\u00b7dient", "das", "Lob", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und hat er's nicht gesagt, so h\u00e4tt' er's sagen sollen.", "tokens": ["Und", "hat", "er's", "nicht", "ge\u00b7sagt", ",", "so", "h\u00e4tt'", "er's", "sa\u00b7gen", "sol\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PIS", "PTKNEG", "VVPP", "$,", "ADV", "VAFIN", "PIS", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Der Dollmetsch, welcher oft mehr Sprachen, als er wu\u00dfte,", "tokens": ["Der", "Doll\u00b7metsch", ",", "wel\u00b7cher", "oft", "mehr", "Spra\u00b7chen", ",", "als", "er", "wu\u00df\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ADV", "PIAT", "NN", "$,", "KOUS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Vor seiner K\u00f6nigin", "tokens": ["Vor", "sei\u00b7ner", "K\u00f6\u00b7ni\u00b7gin"], "token_info": ["word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Der schlaue Melson fand durch seine Munterkeit", "tokens": ["Der", "schlau\u00b7e", "Mel\u00b7son", "fand", "durch", "sei\u00b7ne", "Mun\u00b7ter\u00b7keit"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Den Rath, den nur der Witz verleiht.", "tokens": ["Den", "Rath", ",", "den", "nur", "der", "Witz", "ver\u00b7leiht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Einst k\u00f6mmt aus Indien ein schwarzer Abgesandter,", "tokens": ["Einst", "k\u00f6mmt", "aus", "In\u00b7di\u00b7en", "ein", "schwar\u00b7zer", "Ab\u00b7ge\u00b7sand\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "NE", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Erscheinet vor dem Thron, und f\u00e4ngt den Vortrag an,", "tokens": ["Er\u00b7schei\u00b7net", "vor", "dem", "Thron", ",", "und", "f\u00e4ngt", "den", "Vor\u00b7trag", "an", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "$,", "KON", "VVFIN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Den er nicht \u00fcbersetzen kann;", "tokens": ["Den", "er", "nicht", "\u00fc\u00b7bers\u00b7et\u00b7zen", "kann", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PTKNEG", "VVINF", "VMFIN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.8": {"text": "Denn keine Sprache war dem Melson unbekannter.", "tokens": ["Denn", "kei\u00b7ne", "Spra\u00b7che", "war", "dem", "Mel\u00b7son", "un\u00b7be\u00b7kann\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "VAFIN", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Doch hilft die List ihm aus. Ihm winkt die K\u00f6nigin.", "tokens": ["Doch", "hilft", "die", "List", "ihm", "aus", ".", "Ihm", "winkt", "die", "K\u00f6\u00b7ni\u00b7gin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "PPER", "PTKVZ", "$.", "PPER", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Er n\u00e4hert sich, und spricht: Die\u00df ist der Rede Sinn:", "tokens": ["Er", "n\u00e4\u00b7hert", "sich", ",", "und", "spricht", ":", "Die\u00df", "ist", "der", "Re\u00b7de", "Sinn", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "$,", "KON", "VVFIN", "$.", "PDS", "VAFIN", "ART", "NN", "NN", "$."], "meter": "-++--+-+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.6": {"line.1": {"text": "Gro\u00dfm\u00e4chtigste, dein Ruhm dringt bis in unsre Grenzen.", "tokens": ["Gro\u00df\u00b7m\u00e4ch\u00b7tigs\u00b7te", ",", "dein", "Ruhm", "dringt", "bis", "in", "uns\u00b7re", "Gren\u00b7zen", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "$,", "PPOSAT", "NN", "VVFIN", "ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Nur dich verehrt ein jeder Theil der Welt.", "tokens": ["Nur", "dich", "ver\u00b7ehrt", "ein", "je\u00b7der", "Theil", "der", "Welt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VVFIN", "ART", "PIAT", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Wo sollte nicht, in Marmor aufgestellt,", "tokens": ["Wo", "soll\u00b7te", "nicht", ",", "in", "Mar\u00b7mor", "auf\u00b7ge\u00b7stellt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "PTKNEG", "$,", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Dein Bild und Lob den sp\u00e4tsten Enkeln gl\u00e4nzen?", "tokens": ["Dein", "Bild", "und", "Lob", "den", "sp\u00e4ts\u00b7ten", "En\u00b7keln", "gl\u00e4n\u00b7zen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "NN", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Es ist dir Brama hold. Zur Ehre schuf er dich.", "tokens": ["Es", "ist", "dir", "Bra\u00b7ma", "hold", ".", "Zur", "Eh\u00b7re", "schuf", "er", "dich", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "NE", "ADJD", "$.", "APPRART", "NN", "VVFIN", "PPER", "PRF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Dein Anblick, wie dein Geist, ist mehr als k\u00f6niglich.", "tokens": ["Dein", "An\u00b7blick", ",", "wie", "dein", "Geist", ",", "ist", "mehr", "als", "k\u00f6\u00b7nig\u00b7lich", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PWAV", "PPOSAT", "NN", "$,", "VAFIN", "PIS", "KOKOM", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Die\u00df h\u00f6rte Tavernier, der sich im Saal befand.", "tokens": ["Die\u00df", "h\u00f6r\u00b7te", "Ta\u00b7ver\u00b7nier", ",", "der", "sich", "im", "Saal", "be\u00b7fand", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "NN", "$,", "PRELS", "PRF", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Des Fremden Sprache war ihm ganz genau bekannt.", "tokens": ["Des", "Frem\u00b7den", "Spra\u00b7che", "war", "ihm", "ganz", "ge\u00b7nau", "be\u00b7kannt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VAFIN", "PPER", "ADV", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Er hatte, wie man wei\u00df, von seinen vielen Reisen", "tokens": ["Er", "hat\u00b7te", ",", "wie", "man", "wei\u00df", ",", "von", "sei\u00b7nen", "vie\u00b7len", "Rei\u00b7sen"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "$,", "PWAV", "PIS", "VVFIN", "$,", "APPR", "PPOSAT", "PIAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Mehr, als ein Stammbuch, aufzuweisen.", "tokens": ["Mehr", ",", "als", "ein", "Stamm\u00b7buch", ",", "auf\u00b7zu\u00b7wei\u00b7sen", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["PIS", "$,", "KOUS", "ART", "NN", "$,", "VVIZU", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Er sagte: K\u00f6nigin, was Melson jetzo spricht,", "tokens": ["Er", "sag\u00b7te", ":", "K\u00f6\u00b7ni\u00b7gin", ",", "was", "Mel\u00b7son", "jet\u00b7zo", "spricht", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "NN", "$,", "PRELS", "NE", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Das redet der Gesandte nicht.", "tokens": ["Das", "re\u00b7det", "der", "Ge\u00b7sand\u00b7te", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ART", "NN", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Wer wird, sprach Melson drauf, den Mischmasch wissen wollen?", "tokens": ["Wer", "wird", ",", "sprach", "Mel\u00b7son", "drauf", ",", "den", "Mischmasch", "wis\u00b7sen", "wol\u00b7len", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "$,", "VVFIN", "NE", "PTKVZ", "$,", "ART", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Mir liegt die Pflicht der Ehrfurcht ob.", "tokens": ["Mir", "liegt", "die", "Pflicht", "der", "Ehr\u00b7furcht", "ob", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ART", "NN", "KOUS", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die K\u00f6nigin verdient das Lob:", "tokens": ["Die", "K\u00f6\u00b7ni\u00b7gin", "ver\u00b7dient", "das", "Lob", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und hat er's nicht gesagt, so h\u00e4tt' er's sagen sollen.", "tokens": ["Und", "hat", "er's", "nicht", "ge\u00b7sagt", ",", "so", "h\u00e4tt'", "er's", "sa\u00b7gen", "sol\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PIS", "PTKNEG", "VVPP", "$,", "ADV", "VAFIN", "PIS", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}