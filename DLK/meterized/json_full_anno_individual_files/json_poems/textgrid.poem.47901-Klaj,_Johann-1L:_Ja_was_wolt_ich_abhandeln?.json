{"textgrid.poem.47901": {"metadata": {"author": {"name": "Klaj, Johann", "birth": "N.A.", "death": "N.A."}, "title": "1L: Ja/ was wolt ich abhandeln?", "genre": "verse", "period": "N.A.", "pub_year": 1636, "urn": "N.A.", "language": ["de:0.42", "nl:0.42", "en:0.14"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ja/ was wolt ich abhandeln?", "tokens": ["Ja", "/", "was", "wolt", "ich", "ab\u00b7han\u00b7deln", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$(", "PWS", "VMFIN", "PPER", "VVINF", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.2": {"text": "Worvon wolt ich reden?", "tokens": ["Wor\u00b7von", "wolt", "ich", "re\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "PPER", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.2": {"line.1": {"text": "Es ist ein Gott in uns/ ein Geist/ wenn der sich reget/", "tokens": ["Es", "ist", "ein", "Gott", "in", "uns", "/", "ein", "Geist", "/", "wenn", "der", "sich", "re\u00b7get", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "APPR", "PPER", "$(", "ART", "NN", "$(", "KOUS", "ART", "PRF", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Brent unser Geist auch an/ und sich wie Gott beweget.", "tokens": ["Brent", "un\u00b7ser", "Geist", "auch", "an", "/", "und", "sich", "wie", "Gott", "be\u00b7we\u00b7get", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPOSAT", "NN", "ADV", "PTKVZ", "$(", "KON", "PRF", "KOKOM", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Wie der Poet die Tafel nimt zur Hand/", "tokens": ["Wie", "der", "Po\u00b7et", "die", "Ta\u00b7fel", "nimt", "zur", "Hand", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "ART", "NN", "VVFIN", "APPRART", "NN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Vnd suchet das/ was nirgend ist im Land/", "tokens": ["Vnd", "su\u00b7chet", "das", "/", "was", "nir\u00b7gend", "ist", "im", "Land", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "$(", "PWS", "ADV", "VAFIN", "APPRART", "NN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Vnd findets auch/ der macht/ da\u00df L\u00e4pperey", "tokens": ["Vnd", "fin\u00b7dets", "auch", "/", "der", "macht", "/", "da\u00df", "L\u00e4p\u00b7pe\u00b7rey"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "$(", "ART", "VVFIN", "$(", "KOUS", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Der Unwarheit der Warheit \u00e4hnlich sey.", "tokens": ["Der", "Un\u00b7war\u00b7heit", "der", "War\u00b7heit", "\u00e4hn\u00b7lich", "sey", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Was sol uns jetzt der Streit/ mit Pfeilen/ Pfriemen/ St\u00f6kken/", "tokens": ["Was", "sol", "uns", "jetzt", "der", "Streit", "/", "mit", "Pfei\u00b7len", "/", "Pfrie\u00b7men", "/", "St\u00f6k\u00b7ken", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PWS", "VMFIN", "PPER", "ADV", "ART", "NN", "$(", "APPR", "NN", "$(", "NN", "$(", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Vnd der bepralte Sturm mit Th\u00fcrnen und mit B\u00f6kken/", "tokens": ["Vnd", "der", "be\u00b7pral\u00b7te", "Sturm", "mit", "Th\u00fcr\u00b7nen", "und", "mit", "B\u00f6k\u00b7ken", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "APPR", "NN", "KON", "APPR", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "\u2013 \u2013 \u2013 \u2013 \u2013 wir haben in die Schlacht", "tokens": ["\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "wir", "ha\u00b7ben", "in", "die", "Schlacht"], "token_info": ["punct", "punct", "punct", "punct", "punct", "word", "word", "word", "word", "word"], "pos": ["$(", "$(", "$(", "$(", "$(", "PPER", "VAFIN", "APPR", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Den Donner selbst geholt/ den Blitz darein gebracht/", "tokens": ["Den", "Don\u00b7ner", "selbst", "ge\u00b7holt", "/", "den", "Blitz", "da\u00b7rein", "ge\u00b7bracht", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVPP", "$(", "ART", "NN", "PAV", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Der Glut und Eisen speyt/ f\u00fcr dem die Mauren fallen/", "tokens": ["Der", "Glut", "und", "Ei\u00b7sen", "speyt", "/", "f\u00fcr", "dem", "die", "Mau\u00b7ren", "fal\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "VVFIN", "$(", "APPR", "PRELS", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Die Th\u00fcrne Spr\u00fcnge thun/ Gebirg und Th\u00e4ler schallen/", "tokens": ["Die", "Th\u00fcr\u00b7ne", "Spr\u00fcn\u00b7ge", "thun", "/", "Ge\u00b7birg", "und", "Th\u00e4\u00b7ler", "schal\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVINF", "$(", "NN", "KON", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Das wilde Meer erschrikt/ wir mischen uns zusammen", "tokens": ["Das", "wil\u00b7de", "Meer", "er\u00b7schrikt", "/", "wir", "mi\u00b7schen", "uns", "zu\u00b7sam\u00b7men"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVPP", "$(", "PPER", "VVFIN", "PPER", "PTKVZ"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Die Elemente selbst und fordern mit den Flammen", "tokens": ["Die", "E\u00b7le\u00b7men\u00b7te", "selbst", "und", "for\u00b7dern", "mit", "den", "Flam\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADV", "KON", "VVFIN", "APPR", "ART", "NN"], "meter": "+-+--+-+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.9": {"text": "Das blaue Himmeldach/ so gantz best\u00fcrtzet steht/", "tokens": ["Das", "blau\u00b7e", "Him\u00b7mel\u00b7dach", "/", "so", "gantz", "be\u00b7st\u00fcrt\u00b7zet", "steht", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$(", "ADV", "ADV", "ADJD", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Wann unsers Pulvers Macht dem Feind entgegen geht.", "tokens": ["Wann", "un\u00b7sers", "Pul\u00b7vers", "Macht", "dem", "Feind", "ent\u00b7ge\u00b7gen", "geht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "NN", "NN", "ART", "NN", "PTKVZ", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "\u2013 \u2013 \u2013 \u2013 Wie Etna/ wenn er streuet", "tokens": ["\u2013", "\u2013", "\u2013", "\u2013", "Wie", "Et\u00b7na", "/", "wenn", "er", "streu\u00b7et"], "token_info": ["punct", "punct", "punct", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["$(", "$(", "$(", "$(", "PWAV", "NE", "$(", "KOUS", "PPER", "VVFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Die Flammen in die Lufft/ und siedend Hartz ausspeyet/", "tokens": ["Die", "Flam\u00b7men", "in", "die", "Lufft", "/", "und", "sie\u00b7dend", "Hartz", "aus\u00b7spe\u00b7yet", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$(", "KON", "CARD", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und durch den holen Schlund bald schwarze Wolken bl\u00e4st/", "tokens": ["Und", "durch", "den", "ho\u00b7len", "Schlund", "bald", "schwar\u00b7ze", "Wol\u00b7ken", "bl\u00e4st", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "ADV", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Bald gantze Kl\u00fcfften Stein und Kugeln fliegen l\u00e4st.", "tokens": ["Bald", "gant\u00b7ze", "Kl\u00fcff\u00b7ten", "Stein", "und", "Ku\u00b7geln", "flie\u00b7gen", "l\u00e4st", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "NN", "KON", "NN", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "\u2013 \u2013 \u2013 Das bleiche Meer ergrimt/", "tokens": ["\u2013", "\u2013", "\u2013", "Das", "blei\u00b7che", "Meer", "er\u00b7grimt", "/"], "token_info": ["punct", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "$(", "$(", "ART", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Es f\u00fchlt den scharfen Nord/ der alle Sonne nimt/", "tokens": ["Es", "f\u00fchlt", "den", "schar\u00b7fen", "Nord", "/", "der", "al\u00b7le", "Son\u00b7ne", "nimt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "$(", "ART", "PIAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Vnd macht den Tag zu Nacht/ die tr\u00fcben Wellen toben/", "tokens": ["Vnd", "macht", "den", "Tag", "zu", "Nacht", "/", "die", "tr\u00fc\u00b7ben", "Wel\u00b7len", "to\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "APPR", "NN", "$(", "ART", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der Wolken Vnmuht geust noch eine See von oben/", "tokens": ["Der", "Wol\u00b7ken", "Vn\u00b7muht", "geust", "noch", "ei\u00b7ne", "See", "von", "o\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVPP", "ADV", "ART", "NN", "APPR", "ADV", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Hingegen diese See klimt auf/ und Himmel an/", "tokens": ["Hin\u00b7ge\u00b7gen", "die\u00b7se", "See", "klimt", "auf", "/", "und", "Him\u00b7mel", "an", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PDAT", "NN", "VVFIN", "APPR", "$(", "KON", "NN", "PTKVZ", "$("], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.6": {"text": "Des schnellen Blitzes Glantz f\u00fchrt eine liechte Bahn", "tokens": ["Des", "schnel\u00b7len", "Blit\u00b7zes", "Glantz", "f\u00fchrt", "ei\u00b7ne", "liech\u00b7te", "Bahn"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "NN", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Durch das gesaltzne Meer/ der Donner holt zusammen/", "tokens": ["Durch", "das", "ge\u00b7saltz\u00b7ne", "Meer", "/", "der", "Don\u00b7ner", "holt", "zu\u00b7sam\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$(", "ART", "NN", "VVFIN", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Sein Schrekken/ Furcht und Angst/ und schmeltzt mit rauen Flammen", "tokens": ["Sein", "Schrek\u00b7ken", "/", "Furcht", "und", "Angst", "/", "und", "schmeltzt", "mit", "rau\u00b7en", "Flam\u00b7men"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "$(", "NN", "KON", "NN", "$(", "KON", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Den sehr erhitzten Schaum/ die Luffte suchen Lufft/", "tokens": ["Den", "sehr", "er\u00b7hitz\u00b7ten", "Schaum", "/", "die", "Luff\u00b7te", "su\u00b7chen", "Lufft", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJA", "NN", "$(", "ART", "NN", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Das Schiff steigt bald empor/ und f\u00e4lt bald in die Klufft", "tokens": ["Das", "Schiff", "steigt", "bald", "em\u00b7por", "/", "und", "f\u00e4lt", "bald", "in", "die", "Klufft"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ADV", "PTKVZ", "$(", "KON", "VVFIN", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Der Erden/ die es fleucht: \u2013 \u2013 \u2013", "tokens": ["Der", "Er\u00b7den", "/", "die", "es", "fleucht", ":", "\u2013", "\u2013", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "punct", "punct", "punct"], "pos": ["ART", "NN", "$(", "PRELS", "PPER", "VVFIN", "$.", "$(", "$(", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Unser edler Spielender besinget die Kummerwenderin/ die Laute/ wundersch\u00f6n:", "tokens": ["Un\u00b7ser", "ed\u00b7ler", "Spie\u00b7len\u00b7der", "be\u00b7sin\u00b7get", "die", "Kum\u00b7mer\u00b7wen\u00b7de\u00b7rin", "/", "die", "Lau\u00b7te", "/", "wun\u00b7der\u00b7sch\u00f6n", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVFIN", "ART", "NN", "$(", "ART", "NN", "$(", "ADJD", "$."], "meter": "+-+-+-+-+--+-+-+-+-+-+", "measure": "trochaic.octa.plus.relaxed"}}, "stanza.8": {"line.1": {"text": "H\u00f6rt dieses Wunderspiel/ des Himmels Gegenhall/", "tokens": ["H\u00f6rt", "die\u00b7ses", "Wun\u00b7der\u00b7spiel", "/", "des", "Him\u00b7mels", "Ge\u00b7gen\u00b7hall", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVIMP", "PDAT", "NN", "$(", "ART", "NN", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ein unbesintes Holtz/ das unsern Sinn erreget/", "tokens": ["Ein", "un\u00b7be\u00b7sin\u00b7tes", "Holtz", "/", "das", "un\u00b7sern", "Sinn", "er\u00b7re\u00b7get", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$(", "ART", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Es t\u00f6net im Geh\u00f6r der Lufftvermengte Schall/", "tokens": ["Es", "t\u00f6\u00b7net", "im", "Ge\u00b7h\u00f6r", "der", "Lufft\u00b7ver\u00b7meng\u00b7te", "Schall", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die tode S\u00e4ite lebt/ sie bebet und beweget/", "tokens": ["Die", "to\u00b7de", "S\u00e4i\u00b7te", "lebt", "/", "sie", "be\u00b7bet", "und", "be\u00b7we\u00b7get", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$(", "PPER", "VVFIN", "KON", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Durch Kunstge\u00fcbte Hand/ wie kan der Faden klingen:", "tokens": ["Durch", "Kunst\u00b7ge\u00b7\u00fcb\u00b7te", "Hand", "/", "wie", "kan", "der", "Fa\u00b7den", "klin\u00b7gen", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "NN", "$(", "PWAV", "VMFIN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Der leere Lautenbauch f\u00fcllt unsre Ohren an/", "tokens": ["Der", "lee\u00b7re", "Lau\u00b7ten\u00b7bauch", "f\u00fcllt", "uns\u00b7re", "Oh\u00b7ren", "an", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PPOSAT", "NN", "PTKVZ", "$("], "meter": "-+-+-++--+-+", "measure": "iambic.hexa.relaxed"}, "line.7": {"text": "Den wilden Tigermuht kan dieser Finger zwingen/", "tokens": ["Den", "wil\u00b7den", "Ti\u00b7ger\u00b7muht", "kan", "die\u00b7ser", "Fin\u00b7ger", "zwin\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VMFIN", "PDAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Ist auch ein Meisterst\u00fckk/ das diesem gleichen kan?", "tokens": ["Ist", "auch", "ein", "Meis\u00b7ter\u00b7st\u00fckk", "/", "das", "die\u00b7sem", "glei\u00b7chen", "kan", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "$(", "ART", "PDAT", "ADJA", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Lasset uns/ lasset uns schauen im Garten/", "tokens": ["Las\u00b7set", "uns", "/", "las\u00b7set", "uns", "schau\u00b7en", "im", "Gar\u00b7ten", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$(", "VVFIN", "PPER", "VVFIN", "APPRART", "NN", "$("], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.2": {"text": "Mindern der g\u00fcldenen Tulipen Zahl/", "tokens": ["Min\u00b7dern", "der", "g\u00fcl\u00b7de\u00b7nen", "Tu\u00b7li\u00b7pen", "Zahl", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "NN", "$("], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.3": {"text": "Wollen wir arme noch morgen erwarten/", "tokens": ["Wol\u00b7len", "wir", "ar\u00b7me", "noch", "mor\u00b7gen", "er\u00b7war\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJA", "ADV", "ADV", "VVINF", "$("], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.4": {"text": "Sind wir nicht sterblichen allezumal/", "tokens": ["Sind", "wir", "nicht", "sterb\u00b7li\u00b7chen", "al\u00b7le\u00b7zu\u00b7mal", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PTKNEG", "VVFIN", "ADV", "$("], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.5": {"text": "Auf/ eilet zu gehen/", "tokens": ["Auf", "/", "ei\u00b7let", "zu", "ge\u00b7hen", "/"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "$(", "VVFIN", "PTKZU", "VVINF", "$("], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.6": {"text": "Die Blumen entstehen/", "tokens": ["Die", "Blu\u00b7men", "ent\u00b7ste\u00b7hen", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "$("], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.7": {"text": "Der Winter bald komt/", "tokens": ["Der", "Win\u00b7ter", "bald", "komt", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVFIN", "$("], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.8": {"text": "Die Felder bereiffet/", "tokens": ["Die", "Fel\u00b7der", "be\u00b7reif\u00b7fet", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$("], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.9": {"text": "Die Wiesen zerschleiffet/", "tokens": ["Die", "Wie\u00b7sen", "zer\u00b7schleif\u00b7fet", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$("], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.10": {"text": "Alte beh\u00e4gliche Lust uns benimt.", "tokens": ["Al\u00b7te", "be\u00b7h\u00e4g\u00b7li\u00b7che", "Lust", "uns", "be\u00b7nimt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJA", "NN", "PPER", "VVFIN", "$."], "meter": "+--+--+--+", "measure": "dactylic.tetra"}}, "stanza.10": {"line.1": {"text": "Wie standhafft auch darinn der Reinach sich gewehret/", "tokens": ["Wie", "stand\u00b7hafft", "auch", "da\u00b7rinn", "der", "Rei\u00b7nach", "sich", "ge\u00b7weh\u00b7ret", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "ADV", "PAV", "ART", "NN", "PRF", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Bis da\u00df man Pferd und Hund und Katzen aufgezehret/", "tokens": ["Bis", "da\u00df", "man", "Pferd", "und", "Hund", "und", "Kat\u00b7zen", "auf\u00b7ge\u00b7zeh\u00b7ret", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "KOUS", "PIS", "NN", "KON", "NN", "KON", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Auch ungeschlachte H\u00e4ut und rohes Leder gessen/", "tokens": ["Auch", "un\u00b7ge\u00b7schlach\u00b7te", "H\u00e4ut", "und", "ro\u00b7hes", "Le\u00b7der", "ges\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "KON", "ADJA", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die Leut einander selbst ermordet und gefressen!", "tokens": ["Die", "Leut", "ein\u00b7an\u00b7der", "selbst", "er\u00b7mor\u00b7det", "und", "ge\u00b7fres\u00b7sen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ADV", "VVPP", "KON", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die Matten schlepten nur f\u00fcr Hunger ihre Glieder/", "tokens": ["Die", "Mat\u00b7ten", "schlep\u00b7ten", "nur", "f\u00fcr", "Hun\u00b7ger", "ih\u00b7re", "Glie\u00b7der", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "APPR", "NN", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Man sah sie f\u00fcr Gespenst und nicht f\u00fcr Menschen an/", "tokens": ["Man", "sah", "sie", "f\u00fcr", "Ge\u00b7spenst", "und", "nicht", "f\u00fcr", "Men\u00b7schen", "an", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "APPR", "NN", "KON", "PTKNEG", "APPR", "NN", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Vnd wenn sie einen Schu\u00df aus aller Macht gethan/", "tokens": ["Vnd", "wenn", "sie", "ei\u00b7nen", "Schu\u00df", "aus", "al\u00b7ler", "Macht", "ge\u00b7than", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ART", "NN", "APPR", "PIAT", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "So fielen sie darvon samt den Musqweten nider.", "tokens": ["So", "fie\u00b7len", "sie", "dar\u00b7von", "samt", "den", "Mus\u00b7qwe\u00b7ten", "ni\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PAV", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "-+--+-+--+-+-", "measure": "iambic.penta.relaxed"}}, "stanza.11": {"line.1": {"text": "Wie sahe man ihn da die freye Hand erschwingen/", "tokens": ["Wie", "sa\u00b7he", "man", "ihn", "da", "die", "frey\u00b7e", "Hand", "er\u00b7schwin\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PIS", "PPER", "ADV", "ART", "ADJA", "NN", "VVPP", "$("], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Jetzt mit gezuktem Rohr/ jetzt mit entbl\u00f6stem Schwert/", "tokens": ["Jetzt", "mit", "ge\u00b7zuk\u00b7tem", "Rohr", "/", "jetzt", "mit", "ent\u00b7bl\u00f6s\u00b7tem", "Schwert", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ADJA", "NN", "$(", "ADV", "APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und/ wo er hingewandt das Streitgewohnte Pferd/", "tokens": ["Und", "/", "wo", "er", "hin\u00b7ge\u00b7wandt", "das", "Streit\u00b7ge\u00b7wohn\u00b7te", "Pferd", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$(", "PWAV", "PPER", "VVFIN", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Den Seinen neue Krafft den Feinden Schrekken geben:", "tokens": ["Den", "Sei\u00b7nen", "neu\u00b7e", "Krafft", "den", "Fein\u00b7den", "Schrek\u00b7ken", "ge\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "ADJA", "NN", "ART", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Das blankgef\u00fchrte Schwert den Geber vieler Siege/", "tokens": ["Das", "blank\u00b7ge\u00b7f\u00fchr\u00b7te", "Schwert", "den", "Ge\u00b7ber", "vie\u00b7ler", "Sie\u00b7ge", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "PIAT", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Das in des Sachsen Faust den Feinde machte bang/", "tokens": ["Das", "in", "des", "Sach\u00b7sen", "Faust", "den", "Fein\u00b7de", "mach\u00b7te", "bang", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "APPR", "ART", "NN", "NN", "ART", "NN", "VVFIN", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und dann der schwartze Hengst/ der mit dem stoltzen Gang", "tokens": ["Und", "dann", "der", "schwart\u00b7ze", "Hengst", "/", "der", "mit", "dem", "stolt\u00b7zen", "Gang"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "ART", "ADJA", "NN", "$(", "ART", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und mutigem Galop anzeigte/ wen er tr\u00fcge.", "tokens": ["Und", "mu\u00b7ti\u00b7gem", "Ga\u00b7lop", "an\u00b7zeig\u00b7te", "/", "wen", "er", "tr\u00fc\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "VVFIN", "$(", "PWS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.12": {"line.1": {"text": "D. Flemming in der Reise nach Persien erzehlet einen Schiffbruch nicht sonder Mitleiden:", "tokens": ["D.", "Flem\u00b7ming", "in", "der", "Rei\u00b7se", "nach", "Per\u00b7si\u00b7en", "er\u00b7zeh\u00b7let", "ei\u00b7nen", "Schiff\u00b7bruch", "nicht", "son\u00b7der", "Mit\u00b7lei\u00b7den", ":"], "token_info": ["abbreviation", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "APPR", "ART", "NN", "APPR", "NE", "VVFIN", "ART", "NN", "PTKNEG", "ADJA", "NN", "$."], "meter": "-+--+--+-+-+-+-+--+--+-", "measure": "amphibrach.tri.plus"}}, "stanza.13": {"line.1": {"text": "Der sichre Steuermannthat fast/ als ob er schlief/", "tokens": ["Der", "sich\u00b7re", "Steu\u00b7er\u00b7mannt\u00b7hat", "fast", "/", "als", "ob", "er", "schlief", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "$(", "KOKOM", "KOUS", "PPER", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Bis das verirte Schiff mit allen Segeln lief", "tokens": ["Bis", "das", "ver\u00b7ir\u00b7te", "Schiff", "mit", "al\u00b7len", "Se\u00b7geln", "lief"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "APPR", "PIAT", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Auf Oelands harten Grund: Ach m\u00f6chten wir nur sehen/", "tokens": ["Auf", "O\u00b7e\u00b7lands", "har\u00b7ten", "Grund", ":", "Ach", "m\u00f6ch\u00b7ten", "wir", "nur", "se\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "ADJA", "NN", "$.", "NN", "VMFIN", "PPER", "ADV", "VVINF", "$("], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}, "line.4": {"text": "War aller unser Wort/ Ach wie wird uns geschehen:", "tokens": ["War", "al\u00b7ler", "un\u00b7ser", "Wort", "/", "Ach", "wie", "wird", "uns", "ge\u00b7sche\u00b7hen", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIAT", "PPOSAT", "NN", "$(", "NN", "KOKOM", "VAFIN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ein jeder fiel erblast auf sein Gesichte hin/", "tokens": ["Ein", "je\u00b7der", "fiel", "er\u00b7blast", "auf", "sein", "Ge\u00b7sich\u00b7te", "hin", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VVFIN", "ADJD", "APPR", "PPOSAT", "NN", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Ein jeder ruffte laut: Hilf Jesu/ wo ich bin!", "tokens": ["Ein", "je\u00b7der", "ruff\u00b7te", "laut", ":", "Hilf", "Je\u00b7su", "/", "wo", "ich", "bin", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VVFIN", "ADJD", "$.", "NE", "NE", "$(", "PWAV", "PPER", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Das Schiff/ das obenher von Winden war zerrissen/", "tokens": ["Das", "Schiff", "/", "das", "o\u00b7ben\u00b7her", "von", "Win\u00b7den", "war", "zer\u00b7ris\u00b7sen", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "ART", "ADJA", "APPR", "NN", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Ward von der Fluten Macht nun unten auch geschmissen/", "tokens": ["Ward", "von", "der", "Flu\u00b7ten", "Macht", "nun", "un\u00b7ten", "auch", "ge\u00b7schmis\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "ART", "NN", "NN", "ADV", "ADV", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "\u2013 \u2013 \u2013 Das Rohr sprang pl\u00f6tzlich ab/", "tokens": ["\u2013", "\u2013", "\u2013", "Das", "Rohr", "sprang", "pl\u00f6tz\u00b7lich", "ab", "/"], "token_info": ["punct", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "$(", "$(", "ART", "NN", "VVFIN", "ADJD", "PTKVZ", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.10": {"text": "Hier sahen wir den Tod/ hier sahen wir das Grab.", "tokens": ["Hier", "sa\u00b7hen", "wir", "den", "Tod", "/", "hier", "sa\u00b7hen", "wir", "das", "Grab", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "$(", "ADV", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Der Kiehl gieng morsentzwey/ mit Krachen und mit Sch\u00fcttern/", "tokens": ["Der", "Kiehl", "gieng", "mor\u00b7sent\u00b7zwey", "/", "mit", "Kra\u00b7chen", "und", "mit", "Sch\u00fct\u00b7tern", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "NE", "$(", "APPR", "NN", "KON", "APPR", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Die Palnken huben an zu zittern und zu splittern/", "tokens": ["Die", "Paln\u00b7ken", "hu\u00b7ben", "an", "zu", "zit\u00b7tern", "und", "zu", "split\u00b7tern", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "PTKZU", "VVINF", "KON", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Die See brach h\u00e4uffig ein/ das tode Schiff ertrank/", "tokens": ["Die", "See", "brach", "h\u00e4uf\u00b7fig", "ein", "/", "das", "to\u00b7de", "Schiff", "er\u00b7trank", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJD", "ART", "$(", "ART", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Das leuchte Gut flo\u00df weg/ das schwere das versank.", "tokens": ["Das", "leuch\u00b7te", "Gut", "flo\u00df", "weg", "/", "das", "schwe\u00b7re", "das", "ver\u00b7sank", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PTKVZ", "$(", "PDS", "VVFIN", "PDS", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.14": {"line.1": {"text": "Der Schlesische Poet Tscherning hat ein lustiges und possirliches H\u00fcndlein also besungen:", "tokens": ["Der", "Schle\u00b7si\u00b7sche", "Po\u00b7et", "Tscher\u00b7ning", "hat", "ein", "lus\u00b7ti\u00b7ges", "und", "pos\u00b7sir\u00b7li\u00b7ches", "H\u00fcnd\u00b7lein", "al\u00b7so", "be\u00b7sun\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NE", "VAFIN", "ART", "ADJA", "KON", "ADJA", "NN", "ADV", "VVINF", "$."], "meter": "-+-+--+-+-+-+-+-+-+-+--+-", "measure": "iambic.octa.plus.relaxed"}}, "stanza.15": {"line.1": {"text": "Freude des Herren und Liebe der Frauen/", "tokens": ["Freu\u00b7de", "des", "Her\u00b7ren", "und", "Lie\u00b7be", "der", "Frau\u00b7en", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "KON", "NN", "ART", "NN", "$("], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.2": {"text": "Keiner kan ohne Gel\u00e4chter dich schauen/", "tokens": ["Kei\u00b7ner", "kan", "oh\u00b7ne", "Ge\u00b7l\u00e4ch\u00b7ter", "dich", "schau\u00b7en", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "APPR", "NN", "PPER", "VVINF", "$("], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.3": {"text": "Weilen du/ balden die Tafel gedekt/", "tokens": ["Wei\u00b7len", "du", "/", "bal\u00b7den", "die", "Ta\u00b7fel", "ge\u00b7dekt", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$(", "VVFIN", "ART", "NN", "VVPP", "$("], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.4": {"text": "Bringest dem eigene Sch\u00fcssel getragen/", "tokens": ["Brin\u00b7gest", "dem", "ei\u00b7ge\u00b7ne", "Sch\u00fcs\u00b7sel", "ge\u00b7tra\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "VVPP", "$("], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.5": {"text": "L\u00e4cherlich ist so sie jrgend verstekt/", "tokens": ["L\u00e4\u00b7cher\u00b7lich", "ist", "so", "sie", "jr\u00b7gend", "vers\u00b7tekt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "ADV", "PPER", "ADJD", "VVPP", "$("], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.6": {"text": "Das eivrige Suchen/", "tokens": ["Das", "eiv\u00b7ri\u00b7ge", "Su\u00b7chen", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$("], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.7": {"text": "Das hungrige Pochen/", "tokens": ["Das", "hung\u00b7ri\u00b7ge", "Po\u00b7chen", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$("], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.8": {"text": "Beh\u00e4gliches Springen/", "tokens": ["Be\u00b7h\u00e4g\u00b7li\u00b7ches", "Sprin\u00b7gen", "/"], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$("], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.9": {"text": "Das freundliche Ringen.", "tokens": ["Das", "freund\u00b7li\u00b7che", "Rin\u00b7gen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.10": {"text": "Und wie er etwan ferner schertzet.", "tokens": ["Und", "wie", "er", "et\u00b7wan", "fer\u00b7ner", "schert\u00b7zet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPER", "ADV", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "Zu Rom wird alle Jahr ein neuer Raht erkoren/", "tokens": ["Zu", "Rom", "wird", "al\u00b7le", "Jahr", "ein", "neu\u00b7er", "Raht", "er\u00b7ko\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VAFIN", "PIAT", "NN", "ART", "ADJA", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ein K\u00f6nig und Poet die werden nur geboren.", "tokens": ["Ein", "K\u00f6\u00b7nig", "und", "Po\u00b7et", "die", "wer\u00b7den", "nur", "ge\u00b7bo\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "ART", "VAFIN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.17": {"line.1": {"text": "Wolt Alexander wol einschlaffen mit Vergn\u00fcgen/", "tokens": ["Wolt", "A\u00b7lex\u00b7an\u00b7der", "wol", "ein\u00b7schlaf\u00b7fen", "mit", "Ver\u00b7gn\u00fc\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "ADV", "VVPP", "APPR", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "So musten Buch und Dolch zu seinen H\u00e4ubten ligen.", "tokens": ["So", "mus\u00b7ten", "Buch", "und", "Dolch", "zu", "sei\u00b7nen", "H\u00e4ub\u00b7ten", "li\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "NN", "KON", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.18": {"line.1": {"text": "Ey h\u00f6rt den K\u00f6mermann von mir so herrlich sprechen/", "tokens": ["Ey", "h\u00f6rt", "den", "K\u00f6\u00b7mer\u00b7mann", "von", "mir", "so", "herr\u00b7lich", "spre\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ART", "NN", "APPR", "PPER", "ADV", "ADJD", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Blo\u00dfmein Get\u00f6n/ mein Laut/ kunt jede Feinde brechen/", "tokens": ["Blo\u00df\u00b7mein", "Ge\u00b7t\u00f6n", "/", "mein", "Laut", "/", "kunt", "je\u00b7de", "Fein\u00b7de", "bre\u00b7chen", "/"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "$(", "PPOSAT", "APPR", "$(", "ADJD", "PIAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die Tugend nam aus mir den Donner in die Hand/", "tokens": ["Die", "Tu\u00b7gend", "nam", "aus", "mir", "den", "Don\u00b7ner", "in", "die", "Hand", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "PPER", "ART", "NN", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Da schwang sich das Gewehr/ da bebten Leut und Land.", "tokens": ["Da", "schwang", "sich", "das", "Ge\u00b7wehr", "/", "da", "beb\u00b7ten", "Leut", "und", "Land", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "ART", "NN", "$(", "ADV", "VVFIN", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Schau den bemahlten Schild in festen H\u00e4nden dr\u00f6nen/", "tokens": ["Schau", "den", "be\u00b7mahl\u00b7ten", "Schild", "in", "fes\u00b7ten", "H\u00e4n\u00b7den", "dr\u00f6\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "APPR", "ADJA", "NN", "VVINF", "$("], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.6": {"text": "Den Pral die L\u00f6wenstimm/ das Feldgeschrey/ das T\u00f6nen", "tokens": ["Den", "Pral", "die", "L\u00f6\u00b7wen\u00b7stimm", "/", "das", "Feld\u00b7ge\u00b7schrey", "/", "das", "T\u00f6\u00b7nen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "ART", "NN", "$(", "ART", "NN", "$(", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Sich wirbelt hoch hinauf bis zu der Wolken Gang/", "tokens": ["Sich", "wir\u00b7belt", "hoch", "hin\u00b7auf", "bis", "zu", "der", "Wol\u00b7ken", "Gang", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "VVFIN", "ADJD", "ADV", "ADV", "APPR", "ART", "NN", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Dem R\u00f6mer wider mich wurd angst und Hasenbang.", "tokens": ["Dem", "R\u00f6\u00b7mer", "wi\u00b7der", "mich", "wurd", "angst", "und", "Ha\u00b7sen\u00b7bang", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPER", "VAFIN", "VVPP", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.19": {"line.1": {"text": "Auf ihr Edlen Teutschen/ aufhochgeehrte greise Helden/", "tokens": ["Auf", "ihr", "Ed\u00b7len", "Teut\u00b7schen", "/", "auf\u00b7hoch\u00b7geehr\u00b7te", "grei\u00b7se", "Hel\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$(", "VVFIN", "ADJA", "NN", "$("], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}, "line.2": {"text": "F\u00f6rdert unsrer Sprachenschmuk/ man wird euren Ruhm vermelden/", "tokens": ["F\u00f6r\u00b7dert", "uns\u00b7rer", "Spra\u00b7chen\u00b7schmuk", "/", "man", "wird", "eu\u00b7ren", "Ruhm", "ver\u00b7mel\u00b7den", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPOSAT", "NN", "$(", "PIS", "VAFIN", "PPOSAT", "NN", "VVINF", "$("], "meter": "+-+-+-+--+-+-+-", "measure": "trochaic.septa.relaxed"}, "line.3": {"text": "Wo der grosse Karel stehet/", "tokens": ["Wo", "der", "gros\u00b7se", "Ka\u00b7rel", "ste\u00b7het", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADJA", "NN", "VVFIN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Der auf liechten Sternen gehet.", "tokens": ["Der", "auf", "liech\u00b7ten", "Ster\u00b7nen", "ge\u00b7het", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Auf ihr alten Teutschen auf/ auf hochgeehrte greise Helden/", "tokens": ["Auf", "ihr", "al\u00b7ten", "Teut\u00b7schen", "auf", "/", "auf", "hoch\u00b7geehr\u00b7te", "grei\u00b7se", "Hel\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "APPR", "$(", "APPR", "ADJA", "ADJA", "NN", "$("], "meter": "+-+-+-+--+-+-+-", "measure": "trochaic.septa.relaxed"}, "line.6": {"text": "Liebet unsrer Sprachen Zier/ man wird euer Lob vermelden/", "tokens": ["Lie\u00b7bet", "uns\u00b7rer", "Spra\u00b7chen", "Zier", "/", "man", "wird", "eu\u00b7er", "Lob", "ver\u00b7mel\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "NN", "$(", "PIS", "VAFIN", "PPOSAT", "NN", "VVINF", "$("], "meter": "+-+-+-+--+-+-+-", "measure": "trochaic.septa.relaxed"}, "line.7": {"text": "Wo der K\u00e4iser Rudolf stehet/", "tokens": ["Wo", "der", "K\u00e4i\u00b7ser", "Ru\u00b7dolf", "ste\u00b7het", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "NE", "VVFIN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Der auf blanken Sternen gehet.", "tokens": ["Der", "auf", "blan\u00b7ken", "Ster\u00b7nen", "ge\u00b7het", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "Auf ihr grossen Helden/ auf folget euren Teutschen Ahnen/", "tokens": ["Auf", "ihr", "gros\u00b7sen", "Hel\u00b7den", "/", "auf", "fol\u00b7get", "eu\u00b7ren", "Teut\u00b7schen", "Ah\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$(", "APPR", "VVFIN", "PPOSAT", "ADJA", "NN", "$("], "meter": "+-+-+----+-+-+-", "measure": "unknown.measure.hexa"}, "line.10": {"text": "Hier k\u00f6nt ihr euch einen Weg zu der Ewigkeit hinbahnen/", "tokens": ["Hier", "k\u00f6nt", "ihr", "euch", "ei\u00b7nen", "Weg", "zu", "der", "E\u00b7wig\u00b7keit", "hin\u00b7bah\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "ART", "NN", "APPR", "ART", "NN", "VVINF", "$("], "meter": "-+--+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.11": {"text": "Da\u00df man wird auf vielen Ch\u00f6ren", "tokens": ["Da\u00df", "man", "wird", "auf", "vie\u00b7len", "Ch\u00f6\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "VAFIN", "APPR", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.12": {"text": "N\u00fcrnberg/ N\u00fcrnberg r\u00fchmen h\u00f6ren.", "tokens": ["N\u00fcrn\u00b7berg", "/", "N\u00fcrn\u00b7berg", "r\u00fch\u00b7men", "h\u00f6\u00b7ren", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$(", "NE", "VVINF", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.13": {"text": "Liebet die lieblich vergn\u00fcgende Sprach/", "tokens": ["Lie\u00b7bet", "die", "lieb\u00b7lich", "ver\u00b7gn\u00fc\u00b7gen\u00b7de", "Sprach", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJD", "ADJA", "NN", "$("], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.14": {"text": "Deren Verm\u00f6gen keine zugleichen/", "tokens": ["De\u00b7ren", "Ver\u00b7m\u00f6\u00b7gen", "kei\u00b7ne", "zu\u00b7glei\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PIAT", "ADJA", "$("], "meter": "+--+-+--+-", "measure": "iambic.tetra.invert"}, "line.15": {"text": "Deren Bewegen andere weichen/", "tokens": ["De\u00b7ren", "Be\u00b7we\u00b7gen", "an\u00b7de\u00b7re", "wei\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PIS", "VVINF", "$("], "meter": "+--+-+--+-", "measure": "iambic.tetra.invert"}, "line.16": {"text": "Keiner k\u00f6mt ihrer Geschiklichkeit nach.", "tokens": ["Kei\u00b7ner", "k\u00f6mt", "ih\u00b7rer", "Ge\u00b7schik\u00b7lich\u00b7keit", "nach", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "+-----+--+", "measure": "iambic.tri.chol"}, "line.17": {"text": "Ich hab es gewagt/", "tokens": ["Ich", "hab", "es", "ge\u00b7wagt", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "VVPP", "$("], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.18": {"text": "Am ersten zu singen", "tokens": ["Am", "ers\u00b7ten", "zu", "sin\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["APPRART", "ADJA", "PTKZU", "VVINF"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.19": {"text": "Von Himmlischen Dingen/", "tokens": ["Von", "Himm\u00b7li\u00b7schen", "Din\u00b7gen", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$("], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.20": {"text": "Jetz hab ichs gewagt", "tokens": ["Jetz", "hab", "ichs", "ge\u00b7wagt"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PIS", "VVPP"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.21": {"text": "Die Rede zu bringen", "tokens": ["Die", "Re\u00b7de", "zu", "brin\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "PTKZU", "VVINF"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.22": {"text": "Und lassen erklingen/", "tokens": ["Und", "las\u00b7sen", "er\u00b7klin\u00b7gen", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "VVINF", "VVINF", "$("], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.23": {"text": "Was Teutschen behagt/", "tokens": ["Was", "Teut\u00b7schen", "be\u00b7hagt", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["PWS", "NN", "VVPP", "$("], "meter": "-+--+", "measure": "iambic.di.chol"}}, "stanza.20": {"line.1": {"text": "Ja/ was wolt ich abhandeln?", "tokens": ["Ja", "/", "was", "wolt", "ich", "ab\u00b7han\u00b7deln", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$(", "PWS", "VMFIN", "PPER", "VVINF", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.2": {"text": "Worvon wolt ich reden?", "tokens": ["Wor\u00b7von", "wolt", "ich", "re\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "PPER", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.21": {"line.1": {"text": "Es ist ein Gott in uns/ ein Geist/ wenn der sich reget/", "tokens": ["Es", "ist", "ein", "Gott", "in", "uns", "/", "ein", "Geist", "/", "wenn", "der", "sich", "re\u00b7get", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "APPR", "PPER", "$(", "ART", "NN", "$(", "KOUS", "ART", "PRF", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Brent unser Geist auch an/ und sich wie Gott beweget.", "tokens": ["Brent", "un\u00b7ser", "Geist", "auch", "an", "/", "und", "sich", "wie", "Gott", "be\u00b7we\u00b7get", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPOSAT", "NN", "ADV", "PTKVZ", "$(", "KON", "PRF", "KOKOM", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.22": {"line.1": {"text": "Wie der Poet die Tafel nimt zur Hand/", "tokens": ["Wie", "der", "Po\u00b7et", "die", "Ta\u00b7fel", "nimt", "zur", "Hand", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "ART", "NN", "VVFIN", "APPRART", "NN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Vnd suchet das/ was nirgend ist im Land/", "tokens": ["Vnd", "su\u00b7chet", "das", "/", "was", "nir\u00b7gend", "ist", "im", "Land", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "$(", "PWS", "ADV", "VAFIN", "APPRART", "NN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Vnd findets auch/ der macht/ da\u00df L\u00e4pperey", "tokens": ["Vnd", "fin\u00b7dets", "auch", "/", "der", "macht", "/", "da\u00df", "L\u00e4p\u00b7pe\u00b7rey"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "$(", "ART", "VVFIN", "$(", "KOUS", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Der Unwarheit der Warheit \u00e4hnlich sey.", "tokens": ["Der", "Un\u00b7war\u00b7heit", "der", "War\u00b7heit", "\u00e4hn\u00b7lich", "sey", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.23": {"line.1": {"text": "Was sol uns jetzt der Streit/ mit Pfeilen/ Pfriemen/ St\u00f6kken/", "tokens": ["Was", "sol", "uns", "jetzt", "der", "Streit", "/", "mit", "Pfei\u00b7len", "/", "Pfrie\u00b7men", "/", "St\u00f6k\u00b7ken", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PWS", "VMFIN", "PPER", "ADV", "ART", "NN", "$(", "APPR", "NN", "$(", "NN", "$(", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Vnd der bepralte Sturm mit Th\u00fcrnen und mit B\u00f6kken/", "tokens": ["Vnd", "der", "be\u00b7pral\u00b7te", "Sturm", "mit", "Th\u00fcr\u00b7nen", "und", "mit", "B\u00f6k\u00b7ken", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "APPR", "NN", "KON", "APPR", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "\u2013 \u2013 \u2013 \u2013 \u2013 wir haben in die Schlacht", "tokens": ["\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "wir", "ha\u00b7ben", "in", "die", "Schlacht"], "token_info": ["punct", "punct", "punct", "punct", "punct", "word", "word", "word", "word", "word"], "pos": ["$(", "$(", "$(", "$(", "$(", "PPER", "VAFIN", "APPR", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Den Donner selbst geholt/ den Blitz darein gebracht/", "tokens": ["Den", "Don\u00b7ner", "selbst", "ge\u00b7holt", "/", "den", "Blitz", "da\u00b7rein", "ge\u00b7bracht", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVPP", "$(", "ART", "NN", "PAV", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Der Glut und Eisen speyt/ f\u00fcr dem die Mauren fallen/", "tokens": ["Der", "Glut", "und", "Ei\u00b7sen", "speyt", "/", "f\u00fcr", "dem", "die", "Mau\u00b7ren", "fal\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "VVFIN", "$(", "APPR", "PRELS", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Die Th\u00fcrne Spr\u00fcnge thun/ Gebirg und Th\u00e4ler schallen/", "tokens": ["Die", "Th\u00fcr\u00b7ne", "Spr\u00fcn\u00b7ge", "thun", "/", "Ge\u00b7birg", "und", "Th\u00e4\u00b7ler", "schal\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVINF", "$(", "NN", "KON", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Das wilde Meer erschrikt/ wir mischen uns zusammen", "tokens": ["Das", "wil\u00b7de", "Meer", "er\u00b7schrikt", "/", "wir", "mi\u00b7schen", "uns", "zu\u00b7sam\u00b7men"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVPP", "$(", "PPER", "VVFIN", "PPER", "PTKVZ"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Die Elemente selbst und fordern mit den Flammen", "tokens": ["Die", "E\u00b7le\u00b7men\u00b7te", "selbst", "und", "for\u00b7dern", "mit", "den", "Flam\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADV", "KON", "VVFIN", "APPR", "ART", "NN"], "meter": "+-+--+-+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.9": {"text": "Das blaue Himmeldach/ so gantz best\u00fcrtzet steht/", "tokens": ["Das", "blau\u00b7e", "Him\u00b7mel\u00b7dach", "/", "so", "gantz", "be\u00b7st\u00fcrt\u00b7zet", "steht", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$(", "ADV", "ADV", "ADJD", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Wann unsers Pulvers Macht dem Feind entgegen geht.", "tokens": ["Wann", "un\u00b7sers", "Pul\u00b7vers", "Macht", "dem", "Feind", "ent\u00b7ge\u00b7gen", "geht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "NN", "NN", "ART", "NN", "PTKVZ", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.24": {"line.1": {"text": "\u2013 \u2013 \u2013 \u2013 Wie Etna/ wenn er streuet", "tokens": ["\u2013", "\u2013", "\u2013", "\u2013", "Wie", "Et\u00b7na", "/", "wenn", "er", "streu\u00b7et"], "token_info": ["punct", "punct", "punct", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["$(", "$(", "$(", "$(", "PWAV", "NE", "$(", "KOUS", "PPER", "VVFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Die Flammen in die Lufft/ und siedend Hartz ausspeyet/", "tokens": ["Die", "Flam\u00b7men", "in", "die", "Lufft", "/", "und", "sie\u00b7dend", "Hartz", "aus\u00b7spe\u00b7yet", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$(", "KON", "CARD", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und durch den holen Schlund bald schwarze Wolken bl\u00e4st/", "tokens": ["Und", "durch", "den", "ho\u00b7len", "Schlund", "bald", "schwar\u00b7ze", "Wol\u00b7ken", "bl\u00e4st", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "ADV", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Bald gantze Kl\u00fcfften Stein und Kugeln fliegen l\u00e4st.", "tokens": ["Bald", "gant\u00b7ze", "Kl\u00fcff\u00b7ten", "Stein", "und", "Ku\u00b7geln", "flie\u00b7gen", "l\u00e4st", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "NN", "KON", "NN", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.25": {"line.1": {"text": "\u2013 \u2013 \u2013 Das bleiche Meer ergrimt/", "tokens": ["\u2013", "\u2013", "\u2013", "Das", "blei\u00b7che", "Meer", "er\u00b7grimt", "/"], "token_info": ["punct", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "$(", "$(", "ART", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Es f\u00fchlt den scharfen Nord/ der alle Sonne nimt/", "tokens": ["Es", "f\u00fchlt", "den", "schar\u00b7fen", "Nord", "/", "der", "al\u00b7le", "Son\u00b7ne", "nimt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "$(", "ART", "PIAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Vnd macht den Tag zu Nacht/ die tr\u00fcben Wellen toben/", "tokens": ["Vnd", "macht", "den", "Tag", "zu", "Nacht", "/", "die", "tr\u00fc\u00b7ben", "Wel\u00b7len", "to\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "APPR", "NN", "$(", "ART", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der Wolken Vnmuht geust noch eine See von oben/", "tokens": ["Der", "Wol\u00b7ken", "Vn\u00b7muht", "geust", "noch", "ei\u00b7ne", "See", "von", "o\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVPP", "ADV", "ART", "NN", "APPR", "ADV", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Hingegen diese See klimt auf/ und Himmel an/", "tokens": ["Hin\u00b7ge\u00b7gen", "die\u00b7se", "See", "klimt", "auf", "/", "und", "Him\u00b7mel", "an", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PDAT", "NN", "VVFIN", "APPR", "$(", "KON", "NN", "PTKVZ", "$("], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.6": {"text": "Des schnellen Blitzes Glantz f\u00fchrt eine liechte Bahn", "tokens": ["Des", "schnel\u00b7len", "Blit\u00b7zes", "Glantz", "f\u00fchrt", "ei\u00b7ne", "liech\u00b7te", "Bahn"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "NN", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Durch das gesaltzne Meer/ der Donner holt zusammen/", "tokens": ["Durch", "das", "ge\u00b7saltz\u00b7ne", "Meer", "/", "der", "Don\u00b7ner", "holt", "zu\u00b7sam\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$(", "ART", "NN", "VVFIN", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Sein Schrekken/ Furcht und Angst/ und schmeltzt mit rauen Flammen", "tokens": ["Sein", "Schrek\u00b7ken", "/", "Furcht", "und", "Angst", "/", "und", "schmeltzt", "mit", "rau\u00b7en", "Flam\u00b7men"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "$(", "NN", "KON", "NN", "$(", "KON", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Den sehr erhitzten Schaum/ die Luffte suchen Lufft/", "tokens": ["Den", "sehr", "er\u00b7hitz\u00b7ten", "Schaum", "/", "die", "Luff\u00b7te", "su\u00b7chen", "Lufft", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJA", "NN", "$(", "ART", "NN", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Das Schiff steigt bald empor/ und f\u00e4lt bald in die Klufft", "tokens": ["Das", "Schiff", "steigt", "bald", "em\u00b7por", "/", "und", "f\u00e4lt", "bald", "in", "die", "Klufft"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ADV", "PTKVZ", "$(", "KON", "VVFIN", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Der Erden/ die es fleucht: \u2013 \u2013 \u2013", "tokens": ["Der", "Er\u00b7den", "/", "die", "es", "fleucht", ":", "\u2013", "\u2013", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "punct", "punct", "punct"], "pos": ["ART", "NN", "$(", "PRELS", "PPER", "VVFIN", "$.", "$(", "$(", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.26": {"line.1": {"text": "Unser edler Spielender besinget die Kummerwenderin/ die Laute/ wundersch\u00f6n:", "tokens": ["Un\u00b7ser", "ed\u00b7ler", "Spie\u00b7len\u00b7der", "be\u00b7sin\u00b7get", "die", "Kum\u00b7mer\u00b7wen\u00b7de\u00b7rin", "/", "die", "Lau\u00b7te", "/", "wun\u00b7der\u00b7sch\u00f6n", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVFIN", "ART", "NN", "$(", "ART", "NN", "$(", "ADJD", "$."], "meter": "+-+-+-+-+--+-+-+-+-+-+", "measure": "trochaic.octa.plus.relaxed"}}, "stanza.27": {"line.1": {"text": "H\u00f6rt dieses Wunderspiel/ des Himmels Gegenhall/", "tokens": ["H\u00f6rt", "die\u00b7ses", "Wun\u00b7der\u00b7spiel", "/", "des", "Him\u00b7mels", "Ge\u00b7gen\u00b7hall", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVIMP", "PDAT", "NN", "$(", "ART", "NN", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ein unbesintes Holtz/ das unsern Sinn erreget/", "tokens": ["Ein", "un\u00b7be\u00b7sin\u00b7tes", "Holtz", "/", "das", "un\u00b7sern", "Sinn", "er\u00b7re\u00b7get", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$(", "ART", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Es t\u00f6net im Geh\u00f6r der Lufftvermengte Schall/", "tokens": ["Es", "t\u00f6\u00b7net", "im", "Ge\u00b7h\u00f6r", "der", "Lufft\u00b7ver\u00b7meng\u00b7te", "Schall", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die tode S\u00e4ite lebt/ sie bebet und beweget/", "tokens": ["Die", "to\u00b7de", "S\u00e4i\u00b7te", "lebt", "/", "sie", "be\u00b7bet", "und", "be\u00b7we\u00b7get", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$(", "PPER", "VVFIN", "KON", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Durch Kunstge\u00fcbte Hand/ wie kan der Faden klingen:", "tokens": ["Durch", "Kunst\u00b7ge\u00b7\u00fcb\u00b7te", "Hand", "/", "wie", "kan", "der", "Fa\u00b7den", "klin\u00b7gen", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "NN", "$(", "PWAV", "VMFIN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Der leere Lautenbauch f\u00fcllt unsre Ohren an/", "tokens": ["Der", "lee\u00b7re", "Lau\u00b7ten\u00b7bauch", "f\u00fcllt", "uns\u00b7re", "Oh\u00b7ren", "an", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PPOSAT", "NN", "PTKVZ", "$("], "meter": "-+-+-++--+-+", "measure": "iambic.hexa.relaxed"}, "line.7": {"text": "Den wilden Tigermuht kan dieser Finger zwingen/", "tokens": ["Den", "wil\u00b7den", "Ti\u00b7ger\u00b7muht", "kan", "die\u00b7ser", "Fin\u00b7ger", "zwin\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VMFIN", "PDAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Ist auch ein Meisterst\u00fckk/ das diesem gleichen kan?", "tokens": ["Ist", "auch", "ein", "Meis\u00b7ter\u00b7st\u00fckk", "/", "das", "die\u00b7sem", "glei\u00b7chen", "kan", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "$(", "ART", "PDAT", "ADJA", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.28": {"line.1": {"text": "Lasset uns/ lasset uns schauen im Garten/", "tokens": ["Las\u00b7set", "uns", "/", "las\u00b7set", "uns", "schau\u00b7en", "im", "Gar\u00b7ten", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$(", "VVFIN", "PPER", "VVFIN", "APPRART", "NN", "$("], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.2": {"text": "Mindern der g\u00fcldenen Tulipen Zahl/", "tokens": ["Min\u00b7dern", "der", "g\u00fcl\u00b7de\u00b7nen", "Tu\u00b7li\u00b7pen", "Zahl", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "NN", "$("], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.3": {"text": "Wollen wir arme noch morgen erwarten/", "tokens": ["Wol\u00b7len", "wir", "ar\u00b7me", "noch", "mor\u00b7gen", "er\u00b7war\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJA", "ADV", "ADV", "VVINF", "$("], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.4": {"text": "Sind wir nicht sterblichen allezumal/", "tokens": ["Sind", "wir", "nicht", "sterb\u00b7li\u00b7chen", "al\u00b7le\u00b7zu\u00b7mal", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PTKNEG", "VVFIN", "ADV", "$("], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.5": {"text": "Auf/ eilet zu gehen/", "tokens": ["Auf", "/", "ei\u00b7let", "zu", "ge\u00b7hen", "/"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "$(", "VVFIN", "PTKZU", "VVINF", "$("], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.6": {"text": "Die Blumen entstehen/", "tokens": ["Die", "Blu\u00b7men", "ent\u00b7ste\u00b7hen", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "$("], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.7": {"text": "Der Winter bald komt/", "tokens": ["Der", "Win\u00b7ter", "bald", "komt", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVFIN", "$("], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.8": {"text": "Die Felder bereiffet/", "tokens": ["Die", "Fel\u00b7der", "be\u00b7reif\u00b7fet", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$("], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.9": {"text": "Die Wiesen zerschleiffet/", "tokens": ["Die", "Wie\u00b7sen", "zer\u00b7schleif\u00b7fet", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$("], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.10": {"text": "Alte beh\u00e4gliche Lust uns benimt.", "tokens": ["Al\u00b7te", "be\u00b7h\u00e4g\u00b7li\u00b7che", "Lust", "uns", "be\u00b7nimt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJA", "NN", "PPER", "VVFIN", "$."], "meter": "+--+--+--+", "measure": "dactylic.tetra"}}, "stanza.29": {"line.1": {"text": "Wie standhafft auch darinn der Reinach sich gewehret/", "tokens": ["Wie", "stand\u00b7hafft", "auch", "da\u00b7rinn", "der", "Rei\u00b7nach", "sich", "ge\u00b7weh\u00b7ret", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "ADV", "PAV", "ART", "NN", "PRF", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Bis da\u00df man Pferd und Hund und Katzen aufgezehret/", "tokens": ["Bis", "da\u00df", "man", "Pferd", "und", "Hund", "und", "Kat\u00b7zen", "auf\u00b7ge\u00b7zeh\u00b7ret", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "KOUS", "PIS", "NN", "KON", "NN", "KON", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Auch ungeschlachte H\u00e4ut und rohes Leder gessen/", "tokens": ["Auch", "un\u00b7ge\u00b7schlach\u00b7te", "H\u00e4ut", "und", "ro\u00b7hes", "Le\u00b7der", "ges\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "KON", "ADJA", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die Leut einander selbst ermordet und gefressen!", "tokens": ["Die", "Leut", "ein\u00b7an\u00b7der", "selbst", "er\u00b7mor\u00b7det", "und", "ge\u00b7fres\u00b7sen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ADV", "VVPP", "KON", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die Matten schlepten nur f\u00fcr Hunger ihre Glieder/", "tokens": ["Die", "Mat\u00b7ten", "schlep\u00b7ten", "nur", "f\u00fcr", "Hun\u00b7ger", "ih\u00b7re", "Glie\u00b7der", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "APPR", "NN", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Man sah sie f\u00fcr Gespenst und nicht f\u00fcr Menschen an/", "tokens": ["Man", "sah", "sie", "f\u00fcr", "Ge\u00b7spenst", "und", "nicht", "f\u00fcr", "Men\u00b7schen", "an", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "APPR", "NN", "KON", "PTKNEG", "APPR", "NN", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Vnd wenn sie einen Schu\u00df aus aller Macht gethan/", "tokens": ["Vnd", "wenn", "sie", "ei\u00b7nen", "Schu\u00df", "aus", "al\u00b7ler", "Macht", "ge\u00b7than", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ART", "NN", "APPR", "PIAT", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "So fielen sie darvon samt den Musqweten nider.", "tokens": ["So", "fie\u00b7len", "sie", "dar\u00b7von", "samt", "den", "Mus\u00b7qwe\u00b7ten", "ni\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PAV", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "-+--+-+--+-+-", "measure": "iambic.penta.relaxed"}}, "stanza.30": {"line.1": {"text": "Wie sahe man ihn da die freye Hand erschwingen/", "tokens": ["Wie", "sa\u00b7he", "man", "ihn", "da", "die", "frey\u00b7e", "Hand", "er\u00b7schwin\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PIS", "PPER", "ADV", "ART", "ADJA", "NN", "VVPP", "$("], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Jetzt mit gezuktem Rohr/ jetzt mit entbl\u00f6stem Schwert/", "tokens": ["Jetzt", "mit", "ge\u00b7zuk\u00b7tem", "Rohr", "/", "jetzt", "mit", "ent\u00b7bl\u00f6s\u00b7tem", "Schwert", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ADJA", "NN", "$(", "ADV", "APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und/ wo er hingewandt das Streitgewohnte Pferd/", "tokens": ["Und", "/", "wo", "er", "hin\u00b7ge\u00b7wandt", "das", "Streit\u00b7ge\u00b7wohn\u00b7te", "Pferd", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$(", "PWAV", "PPER", "VVFIN", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Den Seinen neue Krafft den Feinden Schrekken geben:", "tokens": ["Den", "Sei\u00b7nen", "neu\u00b7e", "Krafft", "den", "Fein\u00b7den", "Schrek\u00b7ken", "ge\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "ADJA", "NN", "ART", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Das blankgef\u00fchrte Schwert den Geber vieler Siege/", "tokens": ["Das", "blank\u00b7ge\u00b7f\u00fchr\u00b7te", "Schwert", "den", "Ge\u00b7ber", "vie\u00b7ler", "Sie\u00b7ge", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "PIAT", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Das in des Sachsen Faust den Feinde machte bang/", "tokens": ["Das", "in", "des", "Sach\u00b7sen", "Faust", "den", "Fein\u00b7de", "mach\u00b7te", "bang", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "APPR", "ART", "NN", "NN", "ART", "NN", "VVFIN", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und dann der schwartze Hengst/ der mit dem stoltzen Gang", "tokens": ["Und", "dann", "der", "schwart\u00b7ze", "Hengst", "/", "der", "mit", "dem", "stolt\u00b7zen", "Gang"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "ART", "ADJA", "NN", "$(", "ART", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und mutigem Galop anzeigte/ wen er tr\u00fcge.", "tokens": ["Und", "mu\u00b7ti\u00b7gem", "Ga\u00b7lop", "an\u00b7zeig\u00b7te", "/", "wen", "er", "tr\u00fc\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "VVFIN", "$(", "PWS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.31": {"line.1": {"text": "D. Flemming in der Reise nach Persien erzehlet einen Schiffbruch nicht sonder Mitleiden:", "tokens": ["D.", "Flem\u00b7ming", "in", "der", "Rei\u00b7se", "nach", "Per\u00b7si\u00b7en", "er\u00b7zeh\u00b7let", "ei\u00b7nen", "Schiff\u00b7bruch", "nicht", "son\u00b7der", "Mit\u00b7lei\u00b7den", ":"], "token_info": ["abbreviation", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "APPR", "ART", "NN", "APPR", "NE", "VVFIN", "ART", "NN", "PTKNEG", "ADJA", "NN", "$."], "meter": "-+--+--+-+-+-+-+--+--+-", "measure": "amphibrach.tri.plus"}}, "stanza.32": {"line.1": {"text": "Der sichre Steuermannthat fast/ als ob er schlief/", "tokens": ["Der", "sich\u00b7re", "Steu\u00b7er\u00b7mannt\u00b7hat", "fast", "/", "als", "ob", "er", "schlief", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "$(", "KOKOM", "KOUS", "PPER", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Bis das verirte Schiff mit allen Segeln lief", "tokens": ["Bis", "das", "ver\u00b7ir\u00b7te", "Schiff", "mit", "al\u00b7len", "Se\u00b7geln", "lief"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "APPR", "PIAT", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Auf Oelands harten Grund: Ach m\u00f6chten wir nur sehen/", "tokens": ["Auf", "O\u00b7e\u00b7lands", "har\u00b7ten", "Grund", ":", "Ach", "m\u00f6ch\u00b7ten", "wir", "nur", "se\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "ADJA", "NN", "$.", "NN", "VMFIN", "PPER", "ADV", "VVINF", "$("], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}, "line.4": {"text": "War aller unser Wort/ Ach wie wird uns geschehen:", "tokens": ["War", "al\u00b7ler", "un\u00b7ser", "Wort", "/", "Ach", "wie", "wird", "uns", "ge\u00b7sche\u00b7hen", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIAT", "PPOSAT", "NN", "$(", "NN", "KOKOM", "VAFIN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ein jeder fiel erblast auf sein Gesichte hin/", "tokens": ["Ein", "je\u00b7der", "fiel", "er\u00b7blast", "auf", "sein", "Ge\u00b7sich\u00b7te", "hin", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VVFIN", "ADJD", "APPR", "PPOSAT", "NN", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Ein jeder ruffte laut: Hilf Jesu/ wo ich bin!", "tokens": ["Ein", "je\u00b7der", "ruff\u00b7te", "laut", ":", "Hilf", "Je\u00b7su", "/", "wo", "ich", "bin", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VVFIN", "ADJD", "$.", "NE", "NE", "$(", "PWAV", "PPER", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Das Schiff/ das obenher von Winden war zerrissen/", "tokens": ["Das", "Schiff", "/", "das", "o\u00b7ben\u00b7her", "von", "Win\u00b7den", "war", "zer\u00b7ris\u00b7sen", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "ART", "ADJA", "APPR", "NN", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Ward von der Fluten Macht nun unten auch geschmissen/", "tokens": ["Ward", "von", "der", "Flu\u00b7ten", "Macht", "nun", "un\u00b7ten", "auch", "ge\u00b7schmis\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "ART", "NN", "NN", "ADV", "ADV", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "\u2013 \u2013 \u2013 Das Rohr sprang pl\u00f6tzlich ab/", "tokens": ["\u2013", "\u2013", "\u2013", "Das", "Rohr", "sprang", "pl\u00f6tz\u00b7lich", "ab", "/"], "token_info": ["punct", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "$(", "$(", "ART", "NN", "VVFIN", "ADJD", "PTKVZ", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.10": {"text": "Hier sahen wir den Tod/ hier sahen wir das Grab.", "tokens": ["Hier", "sa\u00b7hen", "wir", "den", "Tod", "/", "hier", "sa\u00b7hen", "wir", "das", "Grab", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "$(", "ADV", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Der Kiehl gieng morsentzwey/ mit Krachen und mit Sch\u00fcttern/", "tokens": ["Der", "Kiehl", "gieng", "mor\u00b7sent\u00b7zwey", "/", "mit", "Kra\u00b7chen", "und", "mit", "Sch\u00fct\u00b7tern", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "NE", "$(", "APPR", "NN", "KON", "APPR", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Die Palnken huben an zu zittern und zu splittern/", "tokens": ["Die", "Paln\u00b7ken", "hu\u00b7ben", "an", "zu", "zit\u00b7tern", "und", "zu", "split\u00b7tern", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "PTKZU", "VVINF", "KON", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Die See brach h\u00e4uffig ein/ das tode Schiff ertrank/", "tokens": ["Die", "See", "brach", "h\u00e4uf\u00b7fig", "ein", "/", "das", "to\u00b7de", "Schiff", "er\u00b7trank", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJD", "ART", "$(", "ART", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Das leuchte Gut flo\u00df weg/ das schwere das versank.", "tokens": ["Das", "leuch\u00b7te", "Gut", "flo\u00df", "weg", "/", "das", "schwe\u00b7re", "das", "ver\u00b7sank", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PTKVZ", "$(", "PDS", "VVFIN", "PDS", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.33": {"line.1": {"text": "Der Schlesische Poet Tscherning hat ein lustiges und possirliches H\u00fcndlein also besungen:", "tokens": ["Der", "Schle\u00b7si\u00b7sche", "Po\u00b7et", "Tscher\u00b7ning", "hat", "ein", "lus\u00b7ti\u00b7ges", "und", "pos\u00b7sir\u00b7li\u00b7ches", "H\u00fcnd\u00b7lein", "al\u00b7so", "be\u00b7sun\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NE", "VAFIN", "ART", "ADJA", "KON", "ADJA", "NN", "ADV", "VVINF", "$."], "meter": "-+-+--+-+-+-+-+-+-+-+--+-", "measure": "iambic.octa.plus.relaxed"}}, "stanza.34": {"line.1": {"text": "Freude des Herren und Liebe der Frauen/", "tokens": ["Freu\u00b7de", "des", "Her\u00b7ren", "und", "Lie\u00b7be", "der", "Frau\u00b7en", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "KON", "NN", "ART", "NN", "$("], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.2": {"text": "Keiner kan ohne Gel\u00e4chter dich schauen/", "tokens": ["Kei\u00b7ner", "kan", "oh\u00b7ne", "Ge\u00b7l\u00e4ch\u00b7ter", "dich", "schau\u00b7en", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "APPR", "NN", "PPER", "VVINF", "$("], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.3": {"text": "Weilen du/ balden die Tafel gedekt/", "tokens": ["Wei\u00b7len", "du", "/", "bal\u00b7den", "die", "Ta\u00b7fel", "ge\u00b7dekt", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$(", "VVFIN", "ART", "NN", "VVPP", "$("], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.4": {"text": "Bringest dem eigene Sch\u00fcssel getragen/", "tokens": ["Brin\u00b7gest", "dem", "ei\u00b7ge\u00b7ne", "Sch\u00fcs\u00b7sel", "ge\u00b7tra\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "VVPP", "$("], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.5": {"text": "L\u00e4cherlich ist so sie jrgend verstekt/", "tokens": ["L\u00e4\u00b7cher\u00b7lich", "ist", "so", "sie", "jr\u00b7gend", "vers\u00b7tekt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "ADV", "PPER", "ADJD", "VVPP", "$("], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.6": {"text": "Das eivrige Suchen/", "tokens": ["Das", "eiv\u00b7ri\u00b7ge", "Su\u00b7chen", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$("], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.7": {"text": "Das hungrige Pochen/", "tokens": ["Das", "hung\u00b7ri\u00b7ge", "Po\u00b7chen", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$("], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.8": {"text": "Beh\u00e4gliches Springen/", "tokens": ["Be\u00b7h\u00e4g\u00b7li\u00b7ches", "Sprin\u00b7gen", "/"], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$("], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.9": {"text": "Das freundliche Ringen.", "tokens": ["Das", "freund\u00b7li\u00b7che", "Rin\u00b7gen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.10": {"text": "Und wie er etwan ferner schertzet.", "tokens": ["Und", "wie", "er", "et\u00b7wan", "fer\u00b7ner", "schert\u00b7zet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPER", "ADV", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.35": {"line.1": {"text": "Zu Rom wird alle Jahr ein neuer Raht erkoren/", "tokens": ["Zu", "Rom", "wird", "al\u00b7le", "Jahr", "ein", "neu\u00b7er", "Raht", "er\u00b7ko\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VAFIN", "PIAT", "NN", "ART", "ADJA", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ein K\u00f6nig und Poet die werden nur geboren.", "tokens": ["Ein", "K\u00f6\u00b7nig", "und", "Po\u00b7et", "die", "wer\u00b7den", "nur", "ge\u00b7bo\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "ART", "VAFIN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.36": {"line.1": {"text": "Wolt Alexander wol einschlaffen mit Vergn\u00fcgen/", "tokens": ["Wolt", "A\u00b7lex\u00b7an\u00b7der", "wol", "ein\u00b7schlaf\u00b7fen", "mit", "Ver\u00b7gn\u00fc\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "ADV", "VVPP", "APPR", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "So musten Buch und Dolch zu seinen H\u00e4ubten ligen.", "tokens": ["So", "mus\u00b7ten", "Buch", "und", "Dolch", "zu", "sei\u00b7nen", "H\u00e4ub\u00b7ten", "li\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "NN", "KON", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.37": {"line.1": {"text": "Ey h\u00f6rt den K\u00f6mermann von mir so herrlich sprechen/", "tokens": ["Ey", "h\u00f6rt", "den", "K\u00f6\u00b7mer\u00b7mann", "von", "mir", "so", "herr\u00b7lich", "spre\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ART", "NN", "APPR", "PPER", "ADV", "ADJD", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Blo\u00dfmein Get\u00f6n/ mein Laut/ kunt jede Feinde brechen/", "tokens": ["Blo\u00df\u00b7mein", "Ge\u00b7t\u00f6n", "/", "mein", "Laut", "/", "kunt", "je\u00b7de", "Fein\u00b7de", "bre\u00b7chen", "/"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "$(", "PPOSAT", "APPR", "$(", "ADJD", "PIAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die Tugend nam aus mir den Donner in die Hand/", "tokens": ["Die", "Tu\u00b7gend", "nam", "aus", "mir", "den", "Don\u00b7ner", "in", "die", "Hand", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "PPER", "ART", "NN", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Da schwang sich das Gewehr/ da bebten Leut und Land.", "tokens": ["Da", "schwang", "sich", "das", "Ge\u00b7wehr", "/", "da", "beb\u00b7ten", "Leut", "und", "Land", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "ART", "NN", "$(", "ADV", "VVFIN", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Schau den bemahlten Schild in festen H\u00e4nden dr\u00f6nen/", "tokens": ["Schau", "den", "be\u00b7mahl\u00b7ten", "Schild", "in", "fes\u00b7ten", "H\u00e4n\u00b7den", "dr\u00f6\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "APPR", "ADJA", "NN", "VVINF", "$("], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.6": {"text": "Den Pral die L\u00f6wenstimm/ das Feldgeschrey/ das T\u00f6nen", "tokens": ["Den", "Pral", "die", "L\u00f6\u00b7wen\u00b7stimm", "/", "das", "Feld\u00b7ge\u00b7schrey", "/", "das", "T\u00f6\u00b7nen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "ART", "NN", "$(", "ART", "NN", "$(", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Sich wirbelt hoch hinauf bis zu der Wolken Gang/", "tokens": ["Sich", "wir\u00b7belt", "hoch", "hin\u00b7auf", "bis", "zu", "der", "Wol\u00b7ken", "Gang", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "VVFIN", "ADJD", "ADV", "ADV", "APPR", "ART", "NN", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Dem R\u00f6mer wider mich wurd angst und Hasenbang.", "tokens": ["Dem", "R\u00f6\u00b7mer", "wi\u00b7der", "mich", "wurd", "angst", "und", "Ha\u00b7sen\u00b7bang", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPER", "VAFIN", "VVPP", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.38": {"line.1": {"text": "Auf ihr Edlen Teutschen/ aufhochgeehrte greise Helden/", "tokens": ["Auf", "ihr", "Ed\u00b7len", "Teut\u00b7schen", "/", "auf\u00b7hoch\u00b7geehr\u00b7te", "grei\u00b7se", "Hel\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$(", "VVFIN", "ADJA", "NN", "$("], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}, "line.2": {"text": "F\u00f6rdert unsrer Sprachenschmuk/ man wird euren Ruhm vermelden/", "tokens": ["F\u00f6r\u00b7dert", "uns\u00b7rer", "Spra\u00b7chen\u00b7schmuk", "/", "man", "wird", "eu\u00b7ren", "Ruhm", "ver\u00b7mel\u00b7den", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPOSAT", "NN", "$(", "PIS", "VAFIN", "PPOSAT", "NN", "VVINF", "$("], "meter": "+-+-+-+--+-+-+-", "measure": "trochaic.septa.relaxed"}, "line.3": {"text": "Wo der grosse Karel stehet/", "tokens": ["Wo", "der", "gros\u00b7se", "Ka\u00b7rel", "ste\u00b7het", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADJA", "NN", "VVFIN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Der auf liechten Sternen gehet.", "tokens": ["Der", "auf", "liech\u00b7ten", "Ster\u00b7nen", "ge\u00b7het", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Auf ihr alten Teutschen auf/ auf hochgeehrte greise Helden/", "tokens": ["Auf", "ihr", "al\u00b7ten", "Teut\u00b7schen", "auf", "/", "auf", "hoch\u00b7geehr\u00b7te", "grei\u00b7se", "Hel\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "APPR", "$(", "APPR", "ADJA", "ADJA", "NN", "$("], "meter": "+-+-+-+--+-+-+-", "measure": "trochaic.septa.relaxed"}, "line.6": {"text": "Liebet unsrer Sprachen Zier/ man wird euer Lob vermelden/", "tokens": ["Lie\u00b7bet", "uns\u00b7rer", "Spra\u00b7chen", "Zier", "/", "man", "wird", "eu\u00b7er", "Lob", "ver\u00b7mel\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "NN", "$(", "PIS", "VAFIN", "PPOSAT", "NN", "VVINF", "$("], "meter": "+-+-+-+--+-+-+-", "measure": "trochaic.septa.relaxed"}, "line.7": {"text": "Wo der K\u00e4iser Rudolf stehet/", "tokens": ["Wo", "der", "K\u00e4i\u00b7ser", "Ru\u00b7dolf", "ste\u00b7het", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "NE", "VVFIN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Der auf blanken Sternen gehet.", "tokens": ["Der", "auf", "blan\u00b7ken", "Ster\u00b7nen", "ge\u00b7het", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "Auf ihr grossen Helden/ auf folget euren Teutschen Ahnen/", "tokens": ["Auf", "ihr", "gros\u00b7sen", "Hel\u00b7den", "/", "auf", "fol\u00b7get", "eu\u00b7ren", "Teut\u00b7schen", "Ah\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$(", "APPR", "VVFIN", "PPOSAT", "ADJA", "NN", "$("], "meter": "+-+-+----+-+-+-", "measure": "unknown.measure.hexa"}, "line.10": {"text": "Hier k\u00f6nt ihr euch einen Weg zu der Ewigkeit hinbahnen/", "tokens": ["Hier", "k\u00f6nt", "ihr", "euch", "ei\u00b7nen", "Weg", "zu", "der", "E\u00b7wig\u00b7keit", "hin\u00b7bah\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "ART", "NN", "APPR", "ART", "NN", "VVINF", "$("], "meter": "-+--+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.11": {"text": "Da\u00df man wird auf vielen Ch\u00f6ren", "tokens": ["Da\u00df", "man", "wird", "auf", "vie\u00b7len", "Ch\u00f6\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "VAFIN", "APPR", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.12": {"text": "N\u00fcrnberg/ N\u00fcrnberg r\u00fchmen h\u00f6ren.", "tokens": ["N\u00fcrn\u00b7berg", "/", "N\u00fcrn\u00b7berg", "r\u00fch\u00b7men", "h\u00f6\u00b7ren", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$(", "NE", "VVINF", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.13": {"text": "Liebet die lieblich vergn\u00fcgende Sprach/", "tokens": ["Lie\u00b7bet", "die", "lieb\u00b7lich", "ver\u00b7gn\u00fc\u00b7gen\u00b7de", "Sprach", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJD", "ADJA", "NN", "$("], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.14": {"text": "Deren Verm\u00f6gen keine zugleichen/", "tokens": ["De\u00b7ren", "Ver\u00b7m\u00f6\u00b7gen", "kei\u00b7ne", "zu\u00b7glei\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PIAT", "ADJA", "$("], "meter": "+--+-+--+-", "measure": "iambic.tetra.invert"}, "line.15": {"text": "Deren Bewegen andere weichen/", "tokens": ["De\u00b7ren", "Be\u00b7we\u00b7gen", "an\u00b7de\u00b7re", "wei\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PIS", "VVINF", "$("], "meter": "+--+-+--+-", "measure": "iambic.tetra.invert"}, "line.16": {"text": "Keiner k\u00f6mt ihrer Geschiklichkeit nach.", "tokens": ["Kei\u00b7ner", "k\u00f6mt", "ih\u00b7rer", "Ge\u00b7schik\u00b7lich\u00b7keit", "nach", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "+-----+--+", "measure": "iambic.tri.chol"}, "line.17": {"text": "Ich hab es gewagt/", "tokens": ["Ich", "hab", "es", "ge\u00b7wagt", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "VVPP", "$("], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.18": {"text": "Am ersten zu singen", "tokens": ["Am", "ers\u00b7ten", "zu", "sin\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["APPRART", "ADJA", "PTKZU", "VVINF"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.19": {"text": "Von Himmlischen Dingen/", "tokens": ["Von", "Himm\u00b7li\u00b7schen", "Din\u00b7gen", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$("], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.20": {"text": "Jetz hab ichs gewagt", "tokens": ["Jetz", "hab", "ichs", "ge\u00b7wagt"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PIS", "VVPP"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.21": {"text": "Die Rede zu bringen", "tokens": ["Die", "Re\u00b7de", "zu", "brin\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "PTKZU", "VVINF"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.22": {"text": "Und lassen erklingen/", "tokens": ["Und", "las\u00b7sen", "er\u00b7klin\u00b7gen", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "VVINF", "VVINF", "$("], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.23": {"text": "Was Teutschen behagt/", "tokens": ["Was", "Teut\u00b7schen", "be\u00b7hagt", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["PWS", "NN", "VVPP", "$("], "meter": "-+--+", "measure": "iambic.di.chol"}}}}}