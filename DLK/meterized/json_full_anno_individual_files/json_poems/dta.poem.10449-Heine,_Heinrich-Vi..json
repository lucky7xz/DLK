{"dta.poem.10449": {"metadata": {"author": {"name": "Heine, Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "Vi.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1827", "urn": "urn:nbn:de:kobv:b4-200905192211", "language": ["de:0.99"], "booktitle": "Heine, Heinrich: Buch der Lieder. Hamburg, 1827."}, "poem": {"stanza.1": {"line.1": {"text": "Als ich, auf der Reise, zuf\u00e4llig", "tokens": ["Als", "ich", ",", "auf", "der", "Rei\u00b7se", ",", "zu\u00b7f\u00e4l\u00b7lig"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["KOUS", "PPER", "$,", "APPR", "ART", "NN", "$,", "ADJD"], "meter": "--+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Meines Liebchens Familie fand,", "tokens": ["Mei\u00b7nes", "Lieb\u00b7chens", "Fa\u00b7mi\u00b7lie", "fand", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "NN", "VVFIN", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Schwesterchen, Vater und Mutter,", "tokens": ["Schwes\u00b7ter\u00b7chen", ",", "Va\u00b7ter", "und", "Mut\u00b7ter", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "KON", "NN", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.4": {"text": "Sie haben mich freudig erkannt.", "tokens": ["Sie", "ha\u00b7ben", "mich", "freu\u00b7dig", "er\u00b7kannt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADJD", "VVPP", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.2": {"line.1": {"text": "Sie fragten nach meinem Befinden,", "tokens": ["Sie", "frag\u00b7ten", "nach", "mei\u00b7nem", "Be\u00b7fin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Und sagten selber sogleich:", "tokens": ["Und", "sag\u00b7ten", "sel\u00b7ber", "sog\u00b7leich", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ADV", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Ich h\u00e4tte mich gar nicht ver\u00e4ndert,", "tokens": ["Ich", "h\u00e4t\u00b7te", "mich", "gar", "nicht", "ver\u00b7\u00e4n\u00b7dert", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Nur mein Gesicht sey bleich.", "tokens": ["Nur", "mein", "Ge\u00b7sicht", "sey", "bleich", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "VAFIN", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Ich fragte nach Muhmen und Basen,", "tokens": ["Ich", "frag\u00b7te", "nach", "Muh\u00b7men", "und", "Ba\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Nach manchem langweil'gen Gesell'n,", "tokens": ["Nach", "man\u00b7chem", "lang\u00b7weil'\u00b7gen", "Ge\u00b7sell'n", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-++--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Und nach dem kleinen H\u00fcndchen,", "tokens": ["Und", "nach", "dem", "klei\u00b7nen", "H\u00fcnd\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Mit seinem sanften Bell'n.", "tokens": ["Mit", "sei\u00b7nem", "sanf\u00b7ten", "Bell'", "n."], "token_info": ["word", "word", "word", "word", "abbreviation"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "NE"], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Auch nach der verm\u00e4hlten Geliebten", "tokens": ["Auch", "nach", "der", "ver\u00b7m\u00e4hl\u00b7ten", "Ge\u00b7lieb\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Fragte ich nebenbei;", "tokens": ["Frag\u00b7te", "ich", "ne\u00b7ben\u00b7bei", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Und freundlich gab man zur Antwort:", "tokens": ["Und", "freund\u00b7lich", "gab", "man", "zur", "Ant\u00b7wort", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "PIS", "APPRART", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Da\u00df sie in den Wochen sey.", "tokens": ["Da\u00df", "sie", "in", "den", "Wo\u00b7chen", "sey", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ART", "NN", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Und freundlich gratulirt' ich,", "tokens": ["Und", "freund\u00b7lich", "gra\u00b7tu\u00b7lirt'", "ich", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "PPER", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Und lispelte liebevoll:", "tokens": ["Und", "lis\u00b7pel\u00b7te", "lie\u00b7be\u00b7voll", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Da\u00df man sie von mir recht herzlich", "tokens": ["Da\u00df", "man", "sie", "von", "mir", "recht", "herz\u00b7lich"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "PPER", "APPR", "PPER", "ADV", "ADJD"], "meter": "+---+-+-", "measure": "dactylic.init"}, "line.4": {"text": "Viel tausendmal gr\u00fc\u00dfen soll.", "tokens": ["Viel", "tau\u00b7send\u00b7mal", "gr\u00fc\u00b7\u00dfen", "soll", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVINF", "VMFIN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.6": {"line.1": {"text": "Schwesterchen rief dazwischen:", "tokens": ["Schwes\u00b7ter\u00b7chen", "rief", "da\u00b7zwi\u00b7schen", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PAV", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.2": {"text": "Das H\u00fcndchen, sanft und klein,", "tokens": ["Das", "H\u00fcnd\u00b7chen", ",", "sanft", "und", "klein", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ist gro\u00df und toll geworden,", "tokens": ["Ist", "gro\u00df", "und", "toll", "ge\u00b7wor\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "KON", "ADJD", "VAPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und ward ertr\u00e4nkt, im Rhein.", "tokens": ["Und", "ward", "er\u00b7tr\u00e4nkt", ",", "im", "Rhein", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VAFIN", "VVPP", "$,", "APPRART", "NE", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Die Kleine gleicht der Geliebten,", "tokens": ["Die", "Klei\u00b7ne", "gleicht", "der", "Ge\u00b7lieb\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Besonders, wenn sie lacht;", "tokens": ["Be\u00b7son\u00b7ders", ",", "wenn", "sie", "lacht", ";"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KOUS", "PPER", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Sie hat dieselben Augen,", "tokens": ["Sie", "hat", "die\u00b7sel\u00b7ben", "Au\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PDAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Die mich so elend gemacht.", "tokens": ["Die", "mich", "so", "e\u00b7lend", "ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}}}}