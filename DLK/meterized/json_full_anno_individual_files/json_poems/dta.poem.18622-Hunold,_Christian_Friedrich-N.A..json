{"dta.poem.18622": {"metadata": {"author": {"name": "Hunold, Christian Friedrich", "birth": "N.A.", "death": "N.A."}, "title": "N.A.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1702", "urn": "urn:nbn:de:kobv:b4-200905197766", "language": ["de:0.99"], "booktitle": "Hunold, Christian Friedrich: Die Edle Bem\u00fchung m\u00fcssiger Stunden. Hamburg, 1702."}, "poem": {"stanza.1": {"line.1": {"text": "Ich habe nur gethalt.", "tokens": ["Ich", "ha\u00b7be", "nur", "ge\u00b7thalt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Das h\u00e4tt'stu sollen wissen/", "tokens": ["Das", "h\u00e4tt'\u00b7stu", "sol\u00b7len", "wis\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "In Schertzen und in K\u00fcssen/", "tokens": ["In", "Schert\u00b7zen", "und", "in", "K\u00fcs\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "APPR", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "War alles lauter Schertz/", "tokens": ["War", "al\u00b7les", "lau\u00b7ter", "Schertz", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "PIAT", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Und wenn", "tokens": ["Und", "wenn"], "token_info": ["word", "word"], "pos": ["KON", "KOUS"], "meter": "-+", "measure": "iambic.single"}, "line.6": {"text": "Ein wenig Lust genossen/", "tokens": ["Ein", "we\u00b7nig", "Lust", "ge\u00b7nos\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VVPP", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "So wars ein kahler Possen.", "tokens": ["So", "wars", "ein", "kah\u00b7ler", "Pos\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Geschmiert", "tokens": ["Ge\u00b7schmiert"], "token_info": ["word"], "pos": ["VVPP"], "meter": "-+", "measure": "iambic.single"}, "line.9": {"text": "Ich habe nur gethalt.", "tokens": ["Ich", "ha\u00b7be", "nur", "ge\u00b7thalt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Ich habe nur gethalt.", "tokens": ["Ich", "ha\u00b7be", "nur", "ge\u00b7thalt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Und h\u00e4tten ja die Minen", "tokens": ["Und", "h\u00e4t\u00b7ten", "ja", "die", "Mi\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "ADV", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Verbindlich gnug geschienen/", "tokens": ["Ver\u00b7bind\u00b7lich", "gnug", "ge\u00b7schie\u00b7nen", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "ADV", "VVPP", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "So hab' ich doch gelacht/", "tokens": ["So", "hab'", "ich", "doch", "ge\u00b7lacht", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "VVPP", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Und bey mir selbst gedacht/", "tokens": ["Und", "bey", "mir", "selbst", "ge\u00b7dacht", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPER", "ADV", "VVPP", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Du Einfalt wirst veriret/", "tokens": ["Du", "Ein\u00b7falt", "wirst", "ve\u00b7ri\u00b7ret", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "VAFIN", "VVPP", "$("], "meter": "-+--+--", "measure": "iambic.di.relaxed"}, "line.7": {"text": "Und hinters ", "tokens": ["Und", "hin\u00b7ters"], "token_info": ["word", "word"], "pos": ["KON", "ADV"], "meter": "-+-", "measure": "amphibrach.single"}, "line.8": {"text": "Geschmiert ist nicht gemahlt", "tokens": ["Ge\u00b7schmiert", "ist", "nicht", "ge\u00b7mahlt"], "token_info": ["word", "word", "word", "word"], "pos": ["VVPP", "VAFIN", "PTKNEG", "VVPP"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "Ich habe nur gethalt.", "tokens": ["Ich", "ha\u00b7be", "nur", "ge\u00b7thalt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Ich habe nur gethalt.", "tokens": ["Ich", "ha\u00b7be", "nur", "ge\u00b7thalt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Auch bey verliebten Liedern", "tokens": ["Auch", "bey", "ver\u00b7lieb\u00b7ten", "Lie\u00b7dern"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "APPR", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Wolt' ich die Poltzen fiedern", "tokens": ["Wolt'", "ich", "die", "Polt\u00b7zen", "fie\u00b7dern"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VMFIN", "PPER", "ART", "NN", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Bi\u00df du geschossen seyst.", "tokens": ["Bi\u00df", "du", "ge\u00b7schos\u00b7sen", "seyst", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVPP", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Wenn du es eben weist", "tokens": ["Wenn", "du", "es", "e\u00b7ben", "weist"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PPER", "ADV", "VVFIN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Ich kan sie leicht verdrehen/", "tokens": ["Ich", "kan", "sie", "leicht", "ver\u00b7dre\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADJD", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Weil sie auf Schrauben stehen.", "tokens": ["Weil", "sie", "auf", "Schrau\u00b7ben", "ste\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Geschmiert ist nicht gemahlt/ ", "tokens": ["Ge\u00b7schmiert", "ist", "nicht", "ge\u00b7mahlt", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "PTKNEG", "VVPP", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "Ich habe nur gethalt.", "tokens": ["Ich", "ha\u00b7be", "nur", "ge\u00b7thalt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Ich habe nur gethalt", "tokens": ["Ich", "ha\u00b7be", "nur", "ge\u00b7thalt"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "VVPP"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Ich muste hertzlich lachen/", "tokens": ["Ich", "mus\u00b7te", "hertz\u00b7lich", "la\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADJD", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Da\u00df du in Liebes-Sachen", "tokens": ["Da\u00df", "du", "in", "Lie\u00b7bes\u00b7Sa\u00b7chen"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "So wenig noch gelernt/", "tokens": ["So", "we\u00b7nig", "noch", "ge\u00b7lernt", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "VVPP", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Mein Hertz war weit entfernt/", "tokens": ["Mein", "Hertz", "war", "weit", "ent\u00b7fernt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADJD", "VVPP", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Wenn ichs an deines dr\u00fcckte", "tokens": ["Wenn", "ichs", "an", "dei\u00b7nes", "dr\u00fcck\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "APPR", "PPOSAT", "VVFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Damit ich dich ber\u00fcckte", "tokens": ["Da\u00b7mit", "ich", "dich", "be\u00b7r\u00fcck\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PRF", "VVFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Geschmiert ist nicht g'mahlt", "tokens": ["Ge\u00b7schmiert", "ist", "nicht", "g'\u00b7mahlt"], "token_info": ["word", "word", "word", "word"], "pos": ["VVPP", "VAFIN", "PTKNEG", "VVFIN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "Ich habe nur gethalt.", "tokens": ["Ich", "ha\u00b7be", "nur", "ge\u00b7thalt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Ich habe nur gethalt.", "tokens": ["Ich", "ha\u00b7be", "nur", "ge\u00b7thalt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Du sponst bey deiner Freude", "tokens": ["Du", "sponst", "bey", "dei\u00b7ner", "Freu\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Versichert schlechte Seyde/", "tokens": ["Ver\u00b7si\u00b7chert", "schlech\u00b7te", "Sey\u00b7de", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["VVPP", "VVFIN", "NE", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Das Band ist mor\u00df entzwey.", "tokens": ["Das", "Band", "ist", "mor\u00df", "ent\u00b7zwey", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Ich schwatzte viel von Treu", "tokens": ["Ich", "schwatz\u00b7te", "viel", "von", "Treu"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Dich niemahls zu verlassen/", "tokens": ["Dich", "nie\u00b7mahls", "zu", "ver\u00b7las\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Das hie\u00df/ du soltest passen/", "tokens": ["Das", "hie\u00df", "/", "du", "sol\u00b7test", "pas\u00b7sen", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "$(", "PPER", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Geschmiert ist nicht gemahlt", "tokens": ["Ge\u00b7schmiert", "ist", "nicht", "ge\u00b7mahlt"], "token_info": ["word", "word", "word", "word"], "pos": ["VVPP", "VAFIN", "PTKNEG", "VVPP"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "Ich habe nur gethalt.", "tokens": ["Ich", "ha\u00b7be", "nur", "ge\u00b7thalt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Ich habe nur gethalt.", "tokens": ["Ich", "ha\u00b7be", "nur", "ge\u00b7thalt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Ich werde von den K\u00fcssen", "tokens": ["Ich", "wer\u00b7de", "von", "den", "K\u00fcs\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Zuletzt noch speyen m\u00fcssen/", "tokens": ["Zu\u00b7letzt", "noch", "spe\u00b7yen", "m\u00fcs\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Sie steigen mir schon auf/", "tokens": ["Sie", "stei\u00b7gen", "mir", "schon", "auf", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "APPR", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Dr\u00fcm nehm' ich Pillen drauf.", "tokens": ["Dr\u00fcm", "nehm'", "ich", "Pil\u00b7len", "drauf", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Da\u00df sich der Eckel wende/", "tokens": ["Da\u00df", "sich", "der", "E\u00b7ckel", "wen\u00b7de", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Das Lied hat", "tokens": ["Das", "Lied", "hat"], "token_info": ["word", "word", "word"], "pos": ["ART", "NN", "VAFIN"], "meter": "-+-", "measure": "amphibrach.single"}, "line.8": {"text": "Geschmiert ist nicht gemahlt", "tokens": ["Ge\u00b7schmiert", "ist", "nicht", "ge\u00b7mahlt"], "token_info": ["word", "word", "word", "word"], "pos": ["VVPP", "VAFIN", "PTKNEG", "VVPP"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "Ich habe nur gethalt.", "tokens": ["Ich", "ha\u00b7be", "nur", "ge\u00b7thalt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}}}}