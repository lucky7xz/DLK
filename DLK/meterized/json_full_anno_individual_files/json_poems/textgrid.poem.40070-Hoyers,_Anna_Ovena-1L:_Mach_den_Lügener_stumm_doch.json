{"textgrid.poem.40070": {"metadata": {"author": {"name": "Hoyers, Anna Ovena", "birth": "N.A.", "death": "N.A."}, "title": "1L: Mach den L\u00fcgener stumm doch/", "genre": "verse", "period": "N.A.", "pub_year": 1644, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Mach den L\u00fcgener stumm doch/", "tokens": ["Mach", "den", "L\u00fc\u00b7ge\u00b7ner", "stumm", "doch", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ADJD", "ADV", "$("], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.2": {"text": "Vnd den der b\u00f6\u00df ist/ fromb doch.", "tokens": ["Vnd", "den", "der", "b\u00f6\u00df", "ist", "/", "fromb", "doch", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ART", "ART", "ADJD", "VAFIN", "$(", "VVIMP", "ADV", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Ihr Fromme hertzen in gemein", "tokens": ["Ihr", "From\u00b7me", "hert\u00b7zen", "in", "ge\u00b7mein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Lasst euch/ bitt ich/ di\u00df klein B\u00fcchlein", "tokens": ["Lasst", "euch", "/", "bitt", "ich", "/", "di\u00df", "klein", "B\u00fcch\u00b7lein"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "PPER", "$(", "VVFIN", "PPER", "$(", "PDS", "ADJD", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Lieb umb der Warheit willen seyn.", "tokens": ["Lieb", "umb", "der", "War\u00b7heit", "wil\u00b7len", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "NN", "VAINF", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Nemts an von mir/ so/ wie ichs hir", "tokens": ["Nemts", "an", "von", "mir", "/", "so", "/", "wie", "ichs", "hir"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["ADV", "APPR", "APPR", "PPER", "$(", "ADV", "$(", "KOKOM", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Euch ", "tokens": ["Euch"], "token_info": ["word"], "pos": ["PPER"], "meter": "-", "measure": "single.down"}, "line.6": {"text": "Leset und ", "tokens": ["Le\u00b7set", "und"], "token_info": ["word", "word"], "pos": ["NE", "KON"], "meter": "+--", "measure": "dactylic.init"}, "line.7": {"text": "Es wird darin gezeiget schlecht", "tokens": ["Es", "wird", "da\u00b7rin", "ge\u00b7zei\u00b7get", "schlecht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PAV", "VVPP", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Die art der klugen Letter-knecht.", "tokens": ["Die", "art", "der", "klu\u00b7gen", "Let\u00b7ter\u00b7knecht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Was Babels Bulen sind f\u00fcr leut", "tokens": ["Was", "Ba\u00b7bels", "Bu\u00b7len", "sind", "f\u00fcr", "leut"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "NE", "NE", "VAFIN", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Welche die Welt regiren heut.", "tokens": ["Wel\u00b7che", "die", "Welt", "re\u00b7gi\u00b7ren", "heut", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "NN", "VVFIN", "ADV", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.11": {"text": "Fur ihrem thun gewarnet seyt;", "tokens": ["Fur", "ih\u00b7rem", "thun", "ge\u00b7war\u00b7net", "seyt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "VVINF", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Gehorchet seiner trewen Lehr;", "tokens": ["Ge\u00b7hor\u00b7chet", "sei\u00b7ner", "tre\u00b7wen", "Lehr", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Liebet Warheit/ gebt Gott die Ehr/", "tokens": ["Lie\u00b7bet", "War\u00b7heit", "/", "gebt", "Gott", "die", "Ehr", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "$(", "VVFIN", "NN", "ART", "NN", "$("], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.14": {"text": "Vnd lasst euch nicht verf\u00fchren mehr;", "tokens": ["Vnd", "lasst", "euch", "nicht", "ver\u00b7f\u00fch\u00b7ren", "mehr", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PTKNEG", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Sonst werdet ihrs beklagen sehr/", "tokens": ["Sonst", "wer\u00b7det", "ihrs", "be\u00b7kla\u00b7gen", "sehr", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "VVFIN", "ADV", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Vnd wird die straff euch fallen schwer.", "tokens": ["Vnd", "wird", "die", "straff", "euch", "fal\u00b7len", "schwer", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ART", "VVFIN", "PPER", "VVFIN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Kommet suchet lieben Leut/", "tokens": ["Kom\u00b7met", "su\u00b7chet", "lie\u00b7ben", "Leut", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ADJA", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Seyt nicht al\u00df die blinden:", "tokens": ["Seyt", "nicht", "al\u00df", "die", "blin\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PTKNEG", "KOUS", "ART", "ADJA", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Lasset Warheit euch bey zeit", "tokens": ["Las\u00b7set", "War\u00b7heit", "euch", "bey", "zeit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "NN", "PPER", "APPR", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Reinigen von sunden;", "tokens": ["Rei\u00b7ni\u00b7gen", "von", "sun\u00b7den", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPR", "NE", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.5": {"text": "Denn ihr gesicht bringt ein Liecht", "tokens": ["Denn", "ihr", "ge\u00b7sicht", "bringt", "ein", "Liecht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVPP", "VVFIN", "ART", "NN"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.6": {"text": "Das nicht wird verschwinden:", "tokens": ["Das", "nicht", "wird", "ver\u00b7schwin\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "PTKNEG", "VAFIN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.7": {"text": "Sie kompt nun bald/ mit gewalt/", "tokens": ["Sie", "kompt", "nun", "bald", "/", "mit", "ge\u00b7walt", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "$(", "APPR", "NN", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "Vnd wird \u00fcberwinden", "tokens": ["Vnd", "wird", "\u00fc\u00b7berw\u00b7in\u00b7den"], "token_info": ["word", "word", "word"], "pos": ["KON", "VAFIN", "VVINF"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.9": {"text": "Die L\u00fcgener nah' und fern/", "tokens": ["Die", "L\u00fc\u00b7ge\u00b7ner", "nah'", "und", "fern", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "KON", "ADJD", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.10": {"text": "Sampt all' die euch schinden:", "tokens": ["Sampt", "all'", "die", "euch", "schin\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ART", "PPER", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.11": {"text": "Steht Warheit bey/ r\u00fchmt sie frey/", "tokens": ["Steht", "War\u00b7heit", "bey", "/", "r\u00fchmt", "sie", "frey", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "APPR", "$(", "VVFIN", "PPER", "ADJD", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.12": {"text": "Lasst das Maul nicht binden:", "tokens": ["Lasst", "das", "Maul", "nicht", "bin\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "PTKNEG", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.13": {"text": "Es hang' ihr an/ jedermann/", "tokens": ["Es", "hang'", "ihr", "an", "/", "je\u00b7der\u00b7mann", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKVZ", "$(", "PIS", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.14": {"text": "Keiner bleib dahinden.", "tokens": ["Kei\u00b7ner", "bleib", "da\u00b7hin\u00b7den", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PAV", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.4": {"line.1": {"text": "Denn Frommen Hertzen wolbekant/", "tokens": ["Denn", "From\u00b7men", "Hert\u00b7zen", "wol\u00b7be\u00b7kant", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "NN", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Von einer Frawen au\u00dfgesant/", "tokens": ["Von", "ei\u00b7ner", "Fra\u00b7wen", "au\u00df\u00b7ge\u00b7sant", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Zu suchen Herberg hie im Land:", "tokens": ["Zu", "su\u00b7chen", "Her\u00b7berg", "hie", "im", "Land", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "M\u00f6cht ich sie finden bey jemand/", "tokens": ["M\u00f6cht", "ich", "sie", "fin\u00b7den", "bey", "je\u00b7mand", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PPER", "VVFIN", "APPR", "PIS", "$("], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.5": {"text": "So wer' mein m\u00fch' wol angewandt;", "tokens": ["So", "wer'", "mein", "m\u00fch'", "wol", "an\u00b7ge\u00b7wandt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPOSAT", "VMFIN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Gott beh\u00fct' mich f\u00fcr sp\u00f6tters hand.", "tokens": ["Gott", "be\u00b7h\u00fct'", "mich", "f\u00fcr", "sp\u00f6t\u00b7ters", "hand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PRF", "APPR", "ADJA", "NN", "$."], "meter": "+----+-+", "measure": "dactylic.init"}}, "stanza.5": {"line.1": {"text": "Dein heller Stern/", "tokens": ["Dein", "hel\u00b7ler", "Stern", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$("], "meter": "-+-+", "measure": "iambic.di"}, "line.2": {"text": "Jag von uns fern", "tokens": ["Jag", "von", "uns", "fern"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "APPR", "PPER", "ADJD"], "meter": "+--+", "measure": "iambic.di.chol"}, "line.3": {"text": "Die Cantzel-herrn", "tokens": ["Die", "Cant\u00b7zel\u00b7herrn"], "token_info": ["word", "word"], "pos": ["ART", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.4": {"text": "So unrecht lehrn/", "tokens": ["So", "un\u00b7recht", "lehrn", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "NN", "VVINF", "$("], "meter": "-+-+", "measure": "iambic.di"}, "line.5": {"text": "Die Schrifft verkehrn/", "tokens": ["Die", "Schrifft", "ver\u00b7kehrn", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "$("], "meter": "-+-+", "measure": "iambic.di"}, "line.6": {"text": "Das gute wehrn/", "tokens": ["Das", "gu\u00b7te", "wehrn", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$("], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "Vnd wieder dich", "tokens": ["Vnd", "wie\u00b7der", "dich"], "token_info": ["word", "word", "word"], "pos": ["KON", "ADV", "PPER"], "meter": "-+-+", "measure": "iambic.di"}, "line.8": {"text": "Aufflehnen sich/", "tokens": ["Auf\u00b7fleh\u00b7nen", "sich", "/"], "token_info": ["word", "word", "punct"], "pos": ["APPR", "PRF", "$("], "meter": "-+-+", "measure": "iambic.di"}, "line.9": {"text": "Ihr, Macht zerbrich:", "tokens": ["Ihr", ",", "Macht", "zer\u00b7brich", ":"], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["PPER", "$,", "NN", "ADJD", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.10": {"text": "Erh\u00f6re mich/", "tokens": ["Er\u00b7h\u00f6\u00b7re", "mich", "/"], "token_info": ["word", "word", "punct"], "pos": ["VVFIN", "PPER", "$("], "meter": "-+-+", "measure": "iambic.di"}, "line.11": {"text": "Al\u00dfdenn prei\u00df ich", "tokens": ["Al\u00df\u00b7denn", "prei\u00df", "ich"], "token_info": ["word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER"], "meter": "-+-+", "measure": "iambic.di"}, "line.12": {"text": "Dich Ewiglich.", "tokens": ["Dich", "E\u00b7wig\u00b7lich", "."], "token_info": ["word", "word", "punct"], "pos": ["PPER", "ADV", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.6": {"line.1": {"text": "Mach den L\u00fcgener stumm doch/", "tokens": ["Mach", "den", "L\u00fc\u00b7ge\u00b7ner", "stumm", "doch", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ADJD", "ADV", "$("], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.2": {"text": "Vnd den der b\u00f6\u00df ist/ fromb doch.", "tokens": ["Vnd", "den", "der", "b\u00f6\u00df", "ist", "/", "fromb", "doch", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ART", "ART", "ADJD", "VAFIN", "$(", "VVIMP", "ADV", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Ihr Fromme hertzen in gemein", "tokens": ["Ihr", "From\u00b7me", "hert\u00b7zen", "in", "ge\u00b7mein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Lasst euch/ bitt ich/ di\u00df klein B\u00fcchlein", "tokens": ["Lasst", "euch", "/", "bitt", "ich", "/", "di\u00df", "klein", "B\u00fcch\u00b7lein"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "PPER", "$(", "VVFIN", "PPER", "$(", "PDS", "ADJD", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Lieb umb der Warheit willen seyn.", "tokens": ["Lieb", "umb", "der", "War\u00b7heit", "wil\u00b7len", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "NN", "VAINF", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Nemts an von mir/ so/ wie ichs hir", "tokens": ["Nemts", "an", "von", "mir", "/", "so", "/", "wie", "ichs", "hir"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["ADV", "APPR", "APPR", "PPER", "$(", "ADV", "$(", "KOKOM", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Euch ", "tokens": ["Euch"], "token_info": ["word"], "pos": ["PPER"], "meter": "-", "measure": "single.down"}, "line.6": {"text": "Leset und ", "tokens": ["Le\u00b7set", "und"], "token_info": ["word", "word"], "pos": ["NE", "KON"], "meter": "+--", "measure": "dactylic.init"}, "line.7": {"text": "Es wird darin gezeiget schlecht", "tokens": ["Es", "wird", "da\u00b7rin", "ge\u00b7zei\u00b7get", "schlecht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PAV", "VVPP", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Die art der klugen Letter-knecht.", "tokens": ["Die", "art", "der", "klu\u00b7gen", "Let\u00b7ter\u00b7knecht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Was Babels Bulen sind f\u00fcr leut", "tokens": ["Was", "Ba\u00b7bels", "Bu\u00b7len", "sind", "f\u00fcr", "leut"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "NE", "NE", "VAFIN", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Welche die Welt regiren heut.", "tokens": ["Wel\u00b7che", "die", "Welt", "re\u00b7gi\u00b7ren", "heut", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "NN", "VVFIN", "ADV", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.11": {"text": "Fur ihrem thun gewarnet seyt;", "tokens": ["Fur", "ih\u00b7rem", "thun", "ge\u00b7war\u00b7net", "seyt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "VVINF", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Gehorchet seiner trewen Lehr;", "tokens": ["Ge\u00b7hor\u00b7chet", "sei\u00b7ner", "tre\u00b7wen", "Lehr", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Liebet Warheit/ gebt Gott die Ehr/", "tokens": ["Lie\u00b7bet", "War\u00b7heit", "/", "gebt", "Gott", "die", "Ehr", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "$(", "VVFIN", "NN", "ART", "NN", "$("], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.14": {"text": "Vnd lasst euch nicht verf\u00fchren mehr;", "tokens": ["Vnd", "lasst", "euch", "nicht", "ver\u00b7f\u00fch\u00b7ren", "mehr", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PTKNEG", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Sonst werdet ihrs beklagen sehr/", "tokens": ["Sonst", "wer\u00b7det", "ihrs", "be\u00b7kla\u00b7gen", "sehr", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "VVFIN", "ADV", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Vnd wird die straff euch fallen schwer.", "tokens": ["Vnd", "wird", "die", "straff", "euch", "fal\u00b7len", "schwer", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ART", "VVFIN", "PPER", "VVFIN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Kommet suchet lieben Leut/", "tokens": ["Kom\u00b7met", "su\u00b7chet", "lie\u00b7ben", "Leut", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ADJA", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Seyt nicht al\u00df die blinden:", "tokens": ["Seyt", "nicht", "al\u00df", "die", "blin\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PTKNEG", "KOUS", "ART", "ADJA", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Lasset Warheit euch bey zeit", "tokens": ["Las\u00b7set", "War\u00b7heit", "euch", "bey", "zeit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "NN", "PPER", "APPR", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Reinigen von sunden;", "tokens": ["Rei\u00b7ni\u00b7gen", "von", "sun\u00b7den", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPR", "NE", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.5": {"text": "Denn ihr gesicht bringt ein Liecht", "tokens": ["Denn", "ihr", "ge\u00b7sicht", "bringt", "ein", "Liecht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVPP", "VVFIN", "ART", "NN"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.6": {"text": "Das nicht wird verschwinden:", "tokens": ["Das", "nicht", "wird", "ver\u00b7schwin\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "PTKNEG", "VAFIN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.7": {"text": "Sie kompt nun bald/ mit gewalt/", "tokens": ["Sie", "kompt", "nun", "bald", "/", "mit", "ge\u00b7walt", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "$(", "APPR", "NN", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "Vnd wird \u00fcberwinden", "tokens": ["Vnd", "wird", "\u00fc\u00b7berw\u00b7in\u00b7den"], "token_info": ["word", "word", "word"], "pos": ["KON", "VAFIN", "VVINF"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.9": {"text": "Die L\u00fcgener nah' und fern/", "tokens": ["Die", "L\u00fc\u00b7ge\u00b7ner", "nah'", "und", "fern", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "KON", "ADJD", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.10": {"text": "Sampt all' die euch schinden:", "tokens": ["Sampt", "all'", "die", "euch", "schin\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ART", "PPER", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.11": {"text": "Steht Warheit bey/ r\u00fchmt sie frey/", "tokens": ["Steht", "War\u00b7heit", "bey", "/", "r\u00fchmt", "sie", "frey", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "APPR", "$(", "VVFIN", "PPER", "ADJD", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.12": {"text": "Lasst das Maul nicht binden:", "tokens": ["Lasst", "das", "Maul", "nicht", "bin\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "PTKNEG", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.13": {"text": "Es hang' ihr an/ jedermann/", "tokens": ["Es", "hang'", "ihr", "an", "/", "je\u00b7der\u00b7mann", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKVZ", "$(", "PIS", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.14": {"text": "Keiner bleib dahinden.", "tokens": ["Kei\u00b7ner", "bleib", "da\u00b7hin\u00b7den", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PAV", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.9": {"line.1": {"text": "Denn Frommen Hertzen wolbekant/", "tokens": ["Denn", "From\u00b7men", "Hert\u00b7zen", "wol\u00b7be\u00b7kant", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "NN", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Von einer Frawen au\u00dfgesant/", "tokens": ["Von", "ei\u00b7ner", "Fra\u00b7wen", "au\u00df\u00b7ge\u00b7sant", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Zu suchen Herberg hie im Land:", "tokens": ["Zu", "su\u00b7chen", "Her\u00b7berg", "hie", "im", "Land", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "M\u00f6cht ich sie finden bey jemand/", "tokens": ["M\u00f6cht", "ich", "sie", "fin\u00b7den", "bey", "je\u00b7mand", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PPER", "VVFIN", "APPR", "PIS", "$("], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.5": {"text": "So wer' mein m\u00fch' wol angewandt;", "tokens": ["So", "wer'", "mein", "m\u00fch'", "wol", "an\u00b7ge\u00b7wandt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPOSAT", "VMFIN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Gott beh\u00fct' mich f\u00fcr sp\u00f6tters hand.", "tokens": ["Gott", "be\u00b7h\u00fct'", "mich", "f\u00fcr", "sp\u00f6t\u00b7ters", "hand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PRF", "APPR", "ADJA", "NN", "$."], "meter": "+----+-+", "measure": "dactylic.init"}}, "stanza.10": {"line.1": {"text": "Dein heller Stern/", "tokens": ["Dein", "hel\u00b7ler", "Stern", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$("], "meter": "-+-+", "measure": "iambic.di"}, "line.2": {"text": "Jag von uns fern", "tokens": ["Jag", "von", "uns", "fern"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "APPR", "PPER", "ADJD"], "meter": "+--+", "measure": "iambic.di.chol"}, "line.3": {"text": "Die Cantzel-herrn", "tokens": ["Die", "Cant\u00b7zel\u00b7herrn"], "token_info": ["word", "word"], "pos": ["ART", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.4": {"text": "So unrecht lehrn/", "tokens": ["So", "un\u00b7recht", "lehrn", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "NN", "VVINF", "$("], "meter": "-+-+", "measure": "iambic.di"}, "line.5": {"text": "Die Schrifft verkehrn/", "tokens": ["Die", "Schrifft", "ver\u00b7kehrn", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "$("], "meter": "-+-+", "measure": "iambic.di"}, "line.6": {"text": "Das gute wehrn/", "tokens": ["Das", "gu\u00b7te", "wehrn", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$("], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "Vnd wieder dich", "tokens": ["Vnd", "wie\u00b7der", "dich"], "token_info": ["word", "word", "word"], "pos": ["KON", "ADV", "PPER"], "meter": "-+-+", "measure": "iambic.di"}, "line.8": {"text": "Aufflehnen sich/", "tokens": ["Auf\u00b7fleh\u00b7nen", "sich", "/"], "token_info": ["word", "word", "punct"], "pos": ["APPR", "PRF", "$("], "meter": "-+-+", "measure": "iambic.di"}, "line.9": {"text": "Ihr, Macht zerbrich:", "tokens": ["Ihr", ",", "Macht", "zer\u00b7brich", ":"], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["PPER", "$,", "NN", "ADJD", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.10": {"text": "Erh\u00f6re mich/", "tokens": ["Er\u00b7h\u00f6\u00b7re", "mich", "/"], "token_info": ["word", "word", "punct"], "pos": ["VVFIN", "PPER", "$("], "meter": "-+-+", "measure": "iambic.di"}, "line.11": {"text": "Al\u00dfdenn prei\u00df ich", "tokens": ["Al\u00df\u00b7denn", "prei\u00df", "ich"], "token_info": ["word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER"], "meter": "-+-+", "measure": "iambic.di"}, "line.12": {"text": "Dich Ewiglich.", "tokens": ["Dich", "E\u00b7wig\u00b7lich", "."], "token_info": ["word", "word", "punct"], "pos": ["PPER", "ADV", "$."], "meter": "-+-+", "measure": "iambic.di"}}}}}