{"textgrid.poem.55920": {"metadata": {"author": {"name": "Rilke, Rainer Maria", "birth": "N.A.", "death": "N.A."}, "title": "Buddha", "genre": "verse", "period": "N.A.", "pub_year": 1900, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Als ob er horchte. Stille: eine Ferne...", "tokens": ["Als", "ob", "er", "horch\u00b7te", ".", "Stil\u00b7le", ":", "ei\u00b7ne", "Fer\u00b7ne", "..."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "PPER", "VVFIN", "$.", "NN", "$.", "ART", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Wir halten ein und h\u00f6ren sie nicht mehr.", "tokens": ["Wir", "hal\u00b7ten", "ein", "und", "h\u00f6\u00b7ren", "sie", "nicht", "mehr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKVZ", "KON", "VVFIN", "PPER", "PTKNEG", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Und er ist Stern. Und andre gro\u00dfe Sterne,", "tokens": ["Und", "er", "ist", "Stern", ".", "Und", "and\u00b7re", "gro\u00b7\u00dfe", "Ster\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "NN", "$.", "KON", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "die wir nicht sehen, stehen um ihn her.", "tokens": ["die", "wir", "nicht", "se\u00b7hen", ",", "ste\u00b7hen", "um", "ihn", "her", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PTKNEG", "VVINF", "$,", "VVFIN", "APPR", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "O er ist Alles. Wirklich, warten wir,", "tokens": ["O", "er", "ist", "Al\u00b7les", ".", "Wirk\u00b7lich", ",", "war\u00b7ten", "wir", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NE", "PPER", "VAFIN", "PIS", "$.", "ADJD", "$,", "VVFIN", "PPER", "$,"], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "da\u00df er uns s\u00e4he? Sollte er bed\u00fcrfen?", "tokens": ["da\u00df", "er", "uns", "s\u00e4\u00b7he", "?", "Soll\u00b7te", "er", "be\u00b7d\u00fcr\u00b7fen", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "VVFIN", "$.", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und wenn wir hier uns vor ihm niederw\u00fcrfen,", "tokens": ["Und", "wenn", "wir", "hier", "uns", "vor", "ihm", "nie\u00b7der\u00b7w\u00fcr\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "PPER", "APPR", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "er bliebe tief und tr\u00e4ge wie ein Tier.", "tokens": ["er", "blie\u00b7be", "tief", "und", "tr\u00e4\u00b7ge", "wie", "ein", "Tier", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "KON", "VVFIN", "KOKOM", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Denn das, was uns zu seinen F\u00fc\u00dfen rei\u00dft,", "tokens": ["Denn", "das", ",", "was", "uns", "zu", "sei\u00b7nen", "F\u00fc\u00b7\u00dfen", "rei\u00dft", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "$,", "PRELS", "PPER", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "das kreist in ihm seit Millionen Jahren.", "tokens": ["das", "kreist", "in", "ihm", "seit", "Mil\u00b7lion\u00b7en", "Jah\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPR", "PPER", "APPR", "NN", "NN", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Er, der vergi\u00dft was wir erfahren", "tokens": ["Er", ",", "der", "ver\u00b7gi\u00dft", "was", "wir", "er\u00b7fah\u00b7ren"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "$,", "PRELS", "VVFIN", "PWS", "PPER", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "und der erf\u00e4hrt was uns verweist.", "tokens": ["und", "der", "er\u00b7f\u00e4hrt", "was", "uns", "ver\u00b7weist", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "VVFIN", "PWS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Als ob er horchte. Stille: eine Ferne...", "tokens": ["Als", "ob", "er", "horch\u00b7te", ".", "Stil\u00b7le", ":", "ei\u00b7ne", "Fer\u00b7ne", "..."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "PPER", "VVFIN", "$.", "NN", "$.", "ART", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Wir halten ein und h\u00f6ren sie nicht mehr.", "tokens": ["Wir", "hal\u00b7ten", "ein", "und", "h\u00f6\u00b7ren", "sie", "nicht", "mehr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKVZ", "KON", "VVFIN", "PPER", "PTKNEG", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Und er ist Stern. Und andre gro\u00dfe Sterne,", "tokens": ["Und", "er", "ist", "Stern", ".", "Und", "and\u00b7re", "gro\u00b7\u00dfe", "Ster\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "NN", "$.", "KON", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "die wir nicht sehen, stehen um ihn her.", "tokens": ["die", "wir", "nicht", "se\u00b7hen", ",", "ste\u00b7hen", "um", "ihn", "her", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PTKNEG", "VVINF", "$,", "VVFIN", "APPR", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "O er ist Alles. Wirklich, warten wir,", "tokens": ["O", "er", "ist", "Al\u00b7les", ".", "Wirk\u00b7lich", ",", "war\u00b7ten", "wir", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NE", "PPER", "VAFIN", "PIS", "$.", "ADJD", "$,", "VVFIN", "PPER", "$,"], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "da\u00df er uns s\u00e4he? Sollte er bed\u00fcrfen?", "tokens": ["da\u00df", "er", "uns", "s\u00e4\u00b7he", "?", "Soll\u00b7te", "er", "be\u00b7d\u00fcr\u00b7fen", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "VVFIN", "$.", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und wenn wir hier uns vor ihm niederw\u00fcrfen,", "tokens": ["Und", "wenn", "wir", "hier", "uns", "vor", "ihm", "nie\u00b7der\u00b7w\u00fcr\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "PPER", "APPR", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "er bliebe tief und tr\u00e4ge wie ein Tier.", "tokens": ["er", "blie\u00b7be", "tief", "und", "tr\u00e4\u00b7ge", "wie", "ein", "Tier", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "KON", "VVFIN", "KOKOM", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "Denn das, was uns zu seinen F\u00fc\u00dfen rei\u00dft,", "tokens": ["Denn", "das", ",", "was", "uns", "zu", "sei\u00b7nen", "F\u00fc\u00b7\u00dfen", "rei\u00dft", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "$,", "PRELS", "PPER", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "das kreist in ihm seit Millionen Jahren.", "tokens": ["das", "kreist", "in", "ihm", "seit", "Mil\u00b7lion\u00b7en", "Jah\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPR", "PPER", "APPR", "NN", "NN", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Er, der vergi\u00dft was wir erfahren", "tokens": ["Er", ",", "der", "ver\u00b7gi\u00dft", "was", "wir", "er\u00b7fah\u00b7ren"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "$,", "PRELS", "VVFIN", "PWS", "PPER", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "und der erf\u00e4hrt was uns verweist.", "tokens": ["und", "der", "er\u00b7f\u00e4hrt", "was", "uns", "ver\u00b7weist", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "VVFIN", "PWS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}