{"textgrid.poem.41400": {"metadata": {"author": {"name": "Hagedorn, Friedrich von", "birth": "N.A.", "death": "N.A."}, "title": "Aurelius und Beelzebub", "genre": "verse", "period": "N.A.", "pub_year": 1731, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Es wird Aurel, der nichts, als Armuth, scheut,", "tokens": ["Es", "wird", "Au\u00b7rel", ",", "der", "nichts", ",", "als", "Ar\u00b7muth", ",", "scheut", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VAFIN", "NE", "$,", "PRELS", "PIS", "$,", "KOUS", "NN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Zum Mammonsknecht, zum Harpax unsrer Zeit.", "tokens": ["Zum", "Mam\u00b7mons\u00b7knecht", ",", "zum", "Har\u00b7pax", "uns\u00b7rer", "Zeit", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "APPRART", "NE", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Ihm ist der Klang von vielen todten Sch\u00e4tzen", "tokens": ["Ihm", "ist", "der", "Klang", "von", "vie\u00b7len", "tod\u00b7ten", "Sch\u00e4t\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "NN", "APPR", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Ein Saitenspiel, das Z\u00e4hlen ein Erg\u00f6tzen.", "tokens": ["Ein", "Sai\u00b7ten\u00b7spiel", ",", "das", "Z\u00e4h\u00b7len", "ein", "Er\u00b7g\u00f6t\u00b7zen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Oft schl\u00e4ft der Thor, noch hungrig und mit Pein,", "tokens": ["Oft", "schl\u00e4ft", "der", "Thor", ",", "noch", "hung\u00b7rig", "und", "mit", "Pein", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$,", "ADV", "ADJD", "KON", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Vom H\u00fcten matt, auf vollen S\u00e4cken ein;", "tokens": ["Vom", "H\u00fc\u00b7ten", "matt", ",", "auf", "vol\u00b7len", "S\u00e4\u00b7cken", "ein", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PTKVZ", "$,", "APPR", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Denn Geld und Geiz nimmt t\u00e4glich bei ihm zu;", "tokens": ["Denn", "Geld", "und", "Geiz", "nimmt", "t\u00e4g\u00b7lich", "bei", "ihm", "zu", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "KON", "NN", "VVFIN", "ADJD", "APPR", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Geld ist sein Trost, sein Leben, seine Ruh',", "tokens": ["Geld", "ist", "sein", "Trost", ",", "sein", "Le\u00b7ben", ",", "sei\u00b7ne", "Ruh'", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPOSAT", "NN", "$,", "PPOSAT", "NN", "$,", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Sein Herr, sein Gott. Stets nagt ein scharfer Neid", "tokens": ["Sein", "Herr", ",", "sein", "Gott", ".", "Stets", "nagt", "ein", "schar\u00b7fer", "Neid"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "$,", "PPOSAT", "NN", "$.", "ADV", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Sein blutend Herz. J\u00fcngst mehrt' ein vielfach Leid", "tokens": ["Sein", "blu\u00b7tend", "Herz", ".", "J\u00fcngst", "mehrt'", "ein", "viel\u00b7fach", "Leid"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "ADJD", "NN", "$.", "NN", "VVFIN", "ART", "PIAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Des Wuchrers Qual und Unzufriedenheit.", "tokens": ["Des", "Wuc\u00b7hrers", "Qual", "und", "Un\u00b7zu\u00b7frie\u00b7den\u00b7heit", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Der Wittwen Fluch? Beraubter Waisen Ach?", "tokens": ["Der", "Witt\u00b7wen", "Fluch", "?", "Be\u00b7raub\u00b7ter", "Wai\u00b7sen", "Ach", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$.", "NN", "NN", "ITJ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Die Reue? Nein. Dergleichen Kleinigkeit", "tokens": ["Die", "Reu\u00b7e", "?", "Nein", ".", "Derg\u00b7lei\u00b7chen", "Klei\u00b7nig\u00b7keit"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word"], "pos": ["ART", "NN", "$.", "PTKANT", "$.", "PIS", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Gibt Reichen jetzt kein gro\u00dfes Ungemach.", "tokens": ["Gibt", "Rei\u00b7chen", "jetzt", "kein", "gro\u00b7\u00dfes", "Un\u00b7ge\u00b7mach", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "ADV", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Was wichtigers: Zu sp\u00e4t erfolgte Renten,", "tokens": ["Was", "wich\u00b7ti\u00b7gers", ":", "Zu", "sp\u00e4t", "er\u00b7folg\u00b7te", "Ren\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "$.", "PTKA", "ADJD", "VVFIN", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Ein drohender Protest, zu wenige Procenten,", "tokens": ["Ein", "dro\u00b7hen\u00b7der", "Pro\u00b7test", ",", "zu", "we\u00b7ni\u00b7ge", "Pro\u00b7cen\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Ein viel zu mildes Jahr, der zu f\u00fcrwitz'ge Zoll.", "tokens": ["Ein", "viel", "zu", "mil\u00b7des", "Jahr", ",", "der", "zu", "f\u00fcr\u00b7witz'\u00b7ge", "Zoll", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "ADJA", "NN", "$,", "PRELS", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Dies alles f\u00fcllt sein Herz mit Unmuth, Zorn und Groll.", "tokens": ["Dies", "al\u00b7les", "f\u00fcllt", "sein", "Herz", "mit", "Un\u00b7muth", ",", "Zorn", "und", "Groll", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "PIS", "VVFIN", "PPOSAT", "NN", "APPR", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Er wird zuletzt verzweiflungsvoll.", "tokens": ["Er", "wird", "zu\u00b7letzt", "ver\u00b7zwei\u00b7flungs\u00b7voll", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Als er so gro\u00dfer Noth zu peinlich nachgedacht,", "tokens": ["Als", "er", "so", "gro\u00b7\u00dfer", "Noth", "zu", "pein\u00b7lich", "nach\u00b7ge\u00b7dacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADJA", "NN", "PTKA", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ruft der Unsinnige sogar in einer Nacht", "tokens": ["Ruft", "der", "Un\u00b7sin\u00b7ni\u00b7ge", "so\u00b7gar", "in", "ei\u00b7ner", "Nacht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "NN", "ADV", "APPR", "ART", "NN"], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.3": {"text": "Den Satan an, und Satan schickt ihm gleich", "tokens": ["Den", "Sa\u00b7tan", "an", ",", "und", "Sa\u00b7tan", "schickt", "ihm", "gleich"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "PTKVZ", "$,", "KON", "NN", "VVFIN", "PPER", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Den gr\u00f6\u00dften Herrn aus seinem Reich,", "tokens": ["Den", "gr\u00f6\u00df\u00b7ten", "Herrn", "aus", "sei\u00b7nem", "Reich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Der jetzt, den Alten zu ber\u00fccken,", "tokens": ["Der", "jetzt", ",", "den", "Al\u00b7ten", "zu", "be\u00b7r\u00fc\u00b7cken", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "$,", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "In einer neuen Tracht erschien,", "tokens": ["In", "ei\u00b7ner", "neu\u00b7en", "Tracht", "er\u00b7schien", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Wol zehnmal sch\u00f6ner, als wir ihn", "tokens": ["Wol", "zehn\u00b7mal", "sch\u00f6\u00b7ner", ",", "als", "wir", "ihn"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "ADV", "ADJD", "$,", "KOUS", "PPER", "PPER"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.8": {"text": "In den Gem\u00e4lden oft erblicken,", "tokens": ["In", "den", "Ge\u00b7m\u00e4l\u00b7den", "oft", "er\u00b7bli\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Wo ihm die Augen funkelnd gl\u00fchn,", "tokens": ["Wo", "ihm", "die", "Au\u00b7gen", "fun\u00b7kelnd", "gl\u00fchn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "NN", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Und H\u00f6rner seine Stirne schm\u00fccken.", "tokens": ["Und", "H\u00f6r\u00b7ner", "sei\u00b7ne", "Stir\u00b7ne", "schm\u00fc\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Er hatte weder Schweif noch Klauen,", "tokens": ["Er", "hat\u00b7te", "we\u00b7der", "Schweif", "noch", "Klau\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "KON", "NN", "ADV", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Der H\u00f6lle zaubernde Gewalt", "tokens": ["Der", "H\u00f6l\u00b7le", "zau\u00b7bern\u00b7de", "Ge\u00b7walt"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ADJA", "NN"], "meter": "-+-+---+", "measure": "unknown.measure.tri"}, "line.13": {"text": "Gab ihm die menschliche Gestalt,", "tokens": ["Gab", "ihm", "die", "menschli\u00b7che", "Ge\u00b7stalt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.14": {"text": "Und keinem durfte vor ihm grauen.", "tokens": ["Und", "kei\u00b7nem", "durf\u00b7te", "vor", "ihm", "grau\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VMFIN", "APPR", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "Er \u00fcberkam, nach unsrer Stutzer Art,", "tokens": ["Er", "\u00fc\u00b7ber\u00b7kam", ",", "nach", "uns\u00b7rer", "Stut\u00b7zer", "Art", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "APPR", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.16": {"text": "Ein sch\u00f6nes leeres Haubt, ein wohl gepudert Haar,", "tokens": ["Ein", "sch\u00f6\u00b7nes", "lee\u00b7res", "Haubt", ",", "ein", "wohl", "ge\u00b7pu\u00b7dert", "Haar", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "$,", "ART", "ADV", "VVPP", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Wobei zugleich dem Kinnchen ohne Bart", "tokens": ["Wo\u00b7bei", "zu\u00b7gleich", "dem", "Kinn\u00b7chen", "oh\u00b7ne", "Bart"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADV", "ART", "NN", "APPR", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.18": {"text": "Ein Fl\u00fcgelwerk von Band, anstatt des Schattens, war.", "tokens": ["Ein", "Fl\u00fc\u00b7gel\u00b7werk", "von", "Band", ",", "an\u00b7statt", "des", "Schat\u00b7tens", ",", "war", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "$,", "KOUI", "ART", "NN", "$,", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Er selbst, wie seine Pracht, war ohne Fehl und Tadel,", "tokens": ["Er", "selbst", ",", "wie", "sei\u00b7ne", "Pracht", ",", "war", "oh\u00b7ne", "Fehl", "und", "Ta\u00b7del", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "$,", "PWAV", "PPOSAT", "NN", "$,", "VAFIN", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Und Herr und Kleid von gleichem Adel.", "tokens": ["Und", "Herr", "und", "Kleid", "von", "glei\u00b7chem", "A\u00b7del", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "KON", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Nur lie\u00df man ihm (so lautet der Bericht)", "tokens": ["Nur", "lie\u00df", "man", "ihm", "(", "so", "lau\u00b7tet", "der", "Be\u00b7richt", ")"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "PPER", "$(", "ADV", "VVFIN", "ART", "NN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Den einen Pferdefu\u00df. Warum? Das wei\u00df ich nicht.", "tokens": ["Den", "ei\u00b7nen", "Pfer\u00b7de\u00b7fu\u00df", ".", "Wa\u00b7rum", "?", "Das", "wei\u00df", "ich", "nicht", "."], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "$.", "PWAV", "$.", "PDS", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Er war ja sonst, ohn' allen Zweifel,", "tokens": ["Er", "war", "ja", "sonst", ",", "ohn'", "al\u00b7len", "Zwei\u00b7fel", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "$,", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ein h\u00fcbscher, recht galanter Teufel.", "tokens": ["Ein", "h\u00fcb\u00b7scher", ",", "recht", "ga\u00b7lan\u00b7ter", "Teu\u00b7fel", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "$,", "ADJD", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Bald fand der karge Greis den l\u00e4ngst gesuchten Rath,", "tokens": ["Bald", "fand", "der", "kar\u00b7ge", "Greis", "den", "l\u00e4ngst", "ge\u00b7such\u00b7ten", "Rath", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "ART", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Als dieser Cavalier zu ihm ins Zimmer trat.", "tokens": ["Als", "die\u00b7ser", "Ca\u00b7va\u00b7lier", "zu", "ihm", "ins", "Zim\u00b7mer", "trat", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDAT", "NN", "APPR", "PPER", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Mein Herr, wie hei\u00dfen Sie? ... Beelzebub ... Willkommen!", "tokens": ["Mein", "Herr", ",", "wie", "hei\u00b7\u00dfen", "Sie", "?", "...", "Beel\u00b7ze\u00b7bub", "...", "Will\u00b7kom\u00b7men", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "punct", "word", "punct", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PWAV", "VVFIN", "PPER", "$.", "$(", "NE", "$(", "NN", "$."], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Der Oberste der Teufel? ... Ja ...", "tokens": ["Der", "O\u00b7bers\u00b7te", "der", "Teu\u00b7fel", "?", "...", "Ja", "..."], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$.", "$(", "PTKANT", "$("], "meter": "-+---+-+", "measure": "dactylic.init"}, "line.3": {"text": "Ich hatt' es nicht in Acht genommen,", "tokens": ["Ich", "hatt'", "es", "nicht", "in", "Acht", "ge\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "PTKNEG", "APPR", "CARD", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Weil ich noch nicht auf dero F\u00fc\u00dfe sah.", "tokens": ["Weil", "ich", "noch", "nicht", "auf", "de\u00b7ro", "F\u00fc\u00b7\u00dfe", "sah", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PTKNEG", "APPR", "PRELAT", "NN", "VVFIN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.5": {"text": "Sie setzen sich ... Wie geht es in der H\u00f6llen? ...", "tokens": ["Sie", "set\u00b7zen", "sich", "...", "Wie", "geht", "es", "in", "der", "H\u00f6l\u00b7len", "?", "..."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "PRF", "$(", "PWAV", "VVFIN", "PPER", "APPR", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Wie lebt mein reicher Oheim da? ...", "tokens": ["Wie", "lebt", "mein", "rei\u00b7cher", "O\u00b7heim", "da", "?", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWAV", "VVFIN", "PPOSAT", "ADJA", "NN", "PTKVZ", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Recht wie ein F\u00fcrst.. Und wie befindet sich", "tokens": ["Recht", "wie", "ein", "F\u00fcrst", "..", "Und", "wie", "be\u00b7fin\u00b7det", "sich"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "KOKOM", "ART", "NN", "$.", "KON", "PWAV", "VVFIN", "PRF"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Der Lucifer? ... Ich bitte dich,", "tokens": ["Der", "Lu\u00b7ci\u00b7fer", "?", "...", "Ich", "bit\u00b7te", "dich", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NE", "$.", "$(", "PPER", "VVFIN", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Die Complimente einzustellen.", "tokens": ["Die", "Com\u00b7pli\u00b7men\u00b7te", "ein\u00b7zu\u00b7stel\u00b7len", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVIZU", "$."], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.10": {"text": "Dich reich zu machen, komm' ich hier.", "tokens": ["Dich", "reich", "zu", "ma\u00b7chen", ",", "komm'", "ich", "hier", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "PTKZU", "VVINF", "$,", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Ich bin dein Retter. Folge mir.", "tokens": ["Ich", "bin", "dein", "Ret\u00b7ter", ".", "Fol\u00b7ge", "mir", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "NN", "$.", "NN", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Sein F\u00fchrer bringet ihn in einen \u00f6den Wald", "tokens": ["Sein", "F\u00fch\u00b7rer", "brin\u00b7get", "ihn", "in", "ei\u00b7nen", "\u00f6\u00b7den", "Wald"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Von heiligen bemoosten alten Eichen,", "tokens": ["Von", "hei\u00b7li\u00b7gen", "be\u00b7moos\u00b7ten", "al\u00b7ten", "Ei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Den Sitz des Czernebocks, der Gnomen Aufenthalt,", "tokens": ["Den", "Sitz", "des", "Czer\u00b7ne\u00b7bocks", ",", "der", "Gno\u00b7men", "Auf\u00b7ent\u00b7halt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die Schlachtbank vieler Opferleichen.", "tokens": ["Die", "Schlacht\u00b7bank", "vie\u00b7ler", "Op\u00b7fer\u00b7lei\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PIAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Hier herrscht, fast tausend Jahr', ein schwarzer wilder Schrecken", "tokens": ["Hier", "herrscht", ",", "fast", "tau\u00b7send", "Jahr'", ",", "ein", "schwar\u00b7zer", "wil\u00b7der", "Schre\u00b7cken"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "$,", "ADV", "CARD", "NN", "$,", "ART", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "In grauser Finsterni\u00df. Den unwirthbaren Sitz", "tokens": ["In", "grau\u00b7ser", "Fins\u00b7ter\u00b7ni\u00df", ".", "Den", "un\u00b7wirth\u00b7ba\u00b7ren", "Sitz"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "$.", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Verkl\u00e4rt, doch selten nur, ein rother schneller Blitz.", "tokens": ["Ver\u00b7kl\u00e4rt", ",", "doch", "sel\u00b7ten", "nur", ",", "ein", "ro\u00b7ther", "schnel\u00b7ler", "Blitz", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "ADV", "ADJD", "ADV", "$,", "ART", "ADJA", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Hier sollte sich der Trost Aurels entdecken.", "tokens": ["Hier", "soll\u00b7te", "sich", "der", "Trost", "Au\u00b7rels", "ent\u00b7de\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PRF", "ART", "NN", "NE", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Hier blieb der Fliegenf\u00fcrst und sein Gef\u00e4hrte stehn.", "tokens": ["Hier", "blieb", "der", "Flie\u00b7gen\u00b7f\u00fcrst", "und", "sein", "Ge\u00b7f\u00e4hr\u00b7te", "stehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "KON", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Er stampft dreimal: dreimal erbebt der Grund:", "tokens": ["Er", "stampft", "drei\u00b7mal", ":", "drei\u00b7mal", "er\u00b7bebt", "der", "Grund", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$.", "ADV", "VVFIN", "ART", "NN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.11": {"text": "Es \u00f6ffnet sich ein lichter, tiefer Schlund,", "tokens": ["Es", "\u00f6ff\u00b7net", "sich", "ein", "lich\u00b7ter", ",", "tie\u00b7fer", "Schlund", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "ART", "ADJD", "$,", "ADJA", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.12": {"text": "Und l\u00e4\u00dft im Augenblick so gro\u00dfe Baarschaft sehn,", "tokens": ["Und", "l\u00e4\u00dft", "im", "Au\u00b7gen\u00b7blick", "so", "gro\u00b7\u00dfe", "Baar\u00b7schaft", "sehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPRART", "NN", "ADV", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Als w\u00fcrde fast der Reichthum aller Welt,", "tokens": ["Als", "w\u00fcr\u00b7de", "fast", "der", "Reicht\u00b7hum", "al\u00b7ler", "Welt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VAFIN", "ADV", "ART", "NN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "Hier an Geschmeid' und Gold, den Augen dargestellt.", "tokens": ["Hier", "an", "Ge\u00b7schmeid'", "und", "Gold", ",", "den", "Au\u00b7gen", "dar\u00b7ge\u00b7stellt", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "KON", "NN", "$,", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Sieh', spricht der H\u00f6llengeist, auf diesem Platz", "tokens": ["Sieh'", ",", "spricht", "der", "H\u00f6l\u00b7len\u00b7geist", ",", "auf", "die\u00b7sem", "Platz"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NE", "$,", "VVFIN", "ART", "NN", "$,", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.16": {"text": "Liegt ein Geschenk f\u00fcr dich, der Schatz.", "tokens": ["Liegt", "ein", "Ge\u00b7schenk", "f\u00fcr", "dich", ",", "der", "Schatz", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "APPR", "PPER", "$,", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Wie wird der Filz durch dieses Wort entz\u00fcckt!", "tokens": ["Wie", "wird", "der", "Filz", "durch", "die\u00b7ses", "Wort", "ent\u00b7z\u00fcckt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "ART", "NN", "APPR", "PDAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Kein ird'sches Paradies scheint ihm so sch\u00f6n geschm\u00fcckt,", "tokens": ["Kein", "ird'\u00b7sches", "Pa\u00b7ra\u00b7dies", "scheint", "ihm", "so", "sch\u00f6n", "ge\u00b7schm\u00fcckt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "VVFIN", "PPER", "ADV", "ADJD", "VVPP", "$,"], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "So reich an innerm Werth. Kein Thumherr, kein Pr\u00e4lat,", "tokens": ["So", "reich", "an", "in\u00b7nerm", "Werth", ".", "Kein", "Thum\u00b7herr", ",", "kein", "Pr\u00e4\u00b7lat", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ADJD", "APPR", "ADJA", "NN", "$.", "PIAT", "NN", "$,", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der seiner Pfr\u00fcnde Zins in Rheinwein vor sich hat,", "tokens": ["Der", "sei\u00b7ner", "Pfr\u00fcn\u00b7de", "Zins", "in", "Rhein\u00b7wein", "vor", "sich", "hat", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "NE", "APPR", "NE", "APPR", "PRF", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Kein Bischof, der erfreut, an einem Kirchweihfest,", "tokens": ["Kein", "Bi\u00b7schof", ",", "der", "er\u00b7freut", ",", "an", "ei\u00b7nem", "Kirch\u00b7weih\u00b7fest", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "$,", "PRELS", "ADJD", "$,", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Das erste Glas besieht, das er sich reichen l\u00e4\u00dft,", "tokens": ["Das", "ers\u00b7te", "Glas", "be\u00b7sieht", ",", "das", "er", "sich", "rei\u00b7chen", "l\u00e4\u00dft", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,", "PRELS", "PPER", "PRF", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Wei\u00df mit so merklichem, doch wohlbefugtem, Sehnen", "tokens": ["Wei\u00df", "mit", "so", "merk\u00b7li\u00b7chem", ",", "doch", "wohl\u00b7be\u00b7fug\u00b7tem", ",", "Seh\u00b7nen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word"], "pos": ["VVFIN", "APPR", "ADV", "ADJA", "$,", "ADV", "ADJA", "$,", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Sein fromm und fett Gesicht durch L\u00e4cheln auszudehnen.", "tokens": ["Sein", "fromm", "und", "fett", "Ge\u00b7sicht", "durch", "L\u00e4\u00b7cheln", "aus\u00b7zu\u00b7deh\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJD", "KON", "ADJD", "NN", "APPR", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Er streckt frohlockend aus die hoffnungsreiche Hand.", "tokens": ["Er", "streckt", "froh\u00b7lo\u00b7ckend", "aus", "die", "hoff\u00b7nungs\u00b7rei\u00b7che", "Hand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Wiewol, o harter Zwang! Gl\u00fcck voller Unbestand!", "tokens": ["Wie\u00b7wol", ",", "o", "har\u00b7ter", "Zwang", "!", "Gl\u00fcck", "vol\u00b7ler", "Un\u00b7be\u00b7stand", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "$,", "FM", "ADJA", "NN", "$.", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Halt, ruft Beelzebub, dies ist dir zwar gegeben,", "tokens": ["Halt", ",", "ruft", "Beel\u00b7ze\u00b7bub", ",", "dies", "ist", "dir", "zwar", "ge\u00b7ge\u00b7ben", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "NE", "$,", "PDS", "VAFIN", "PPER", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.12": {"text": "Allein vor morgen nicht zu heben.", "tokens": ["Al\u00b7lein", "vor", "mor\u00b7gen", "nicht", "zu", "he\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ADV", "PTKNEG", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Der Schatz versinkt auf dieses Donnerwort.", "tokens": ["Der", "Schatz", "ver\u00b7sinkt", "auf", "die\u00b7ses", "Don\u00b7ner\u00b7wort", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "PDAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Gestrenger Herr! wie kurz ist meine Freude!", "tokens": ["Ge\u00b7stren\u00b7ger", "Herr", "!", "wie", "kurz", "ist", "mei\u00b7ne", "Freu\u00b7de", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$.", "PWAV", "ADJD", "VAFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Betrogener Aurel! wie findest du den Ort?", "tokens": ["Be\u00b7tro\u00b7ge\u00b7ner", "Au\u00b7rel", "!", "wie", "fin\u00b7dest", "du", "den", "Ort", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "$.", "PWAV", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "-+---+-+-+-+", "measure": "dactylic.init"}, "line.4": {"text": "Den Busch? die Kluft? den Schatz? ... Er ist und bleibet dein.", "tokens": ["Den", "Busch", "?", "die", "Kluft", "?", "den", "Schatz", "?", "...", "Er", "ist", "und", "blei\u00b7bet", "dein", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$.", "ART", "NN", "$.", "ART", "NN", "$.", "$(", "PPER", "VAFIN", "KON", "VVFIN", "PPOSAT", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Betrogen! Was? Ich ein Betr\u00fcger? ... Nein ....", "tokens": ["Be\u00b7tro\u00b7gen", "!", "Was", "?", "Ich", "ein", "Be\u00b7tr\u00fc\u00b7ger", "?", "...", "Nein", "...."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct", "punct", "word", "punct"], "pos": ["NN", "$.", "PWS", "$.", "PPER", "ART", "NN", "$.", "$(", "PTKANT", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Sei klug, und la\u00df ein Zeichen dort,", "tokens": ["Sei", "klug", ",", "und", "la\u00df", "ein", "Zei\u00b7chen", "dort", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAIMP", "ADJD", "$,", "KON", "VVIMP", "ART", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und nimm dir, wann es tagt, das Gold und das Geschmeide.", "tokens": ["Und", "nimm", "dir", ",", "wann", "es", "tagt", ",", "das", "Gold", "und", "das", "Ge\u00b7schmei\u00b7de", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVIMP", "PPER", "$,", "PWAV", "PPER", "VVFIN", "$,", "ART", "NN", "KON", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.10": {"line.1": {"text": "Gleich setzt er tiefgeb\u00fcckt sich und ein Zeichen hin.", "tokens": ["Gleich", "setzt", "er", "tief\u00b7ge\u00b7b\u00fcckt", "sich", "und", "ein", "Zei\u00b7chen", "hin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "PRF", "KON", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Er jauchzt mit neuvergn\u00fcgtem Sinn,", "tokens": ["Er", "jauchzt", "mit", "neu\u00b7ver\u00b7gn\u00fcg\u00b7tem", "Sinn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und sagt aufs zierlichste mit vielen Worten Dank.", "tokens": ["Und", "sagt", "aufs", "zier\u00b7lichs\u00b7te", "mit", "vie\u00b7len", "Wor\u00b7ten", "Dank", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPRART", "ADJA", "APPR", "PIAT", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Beelzebub verschwand, standsm\u00e4\u00dfig mit Gestank.", "tokens": ["Beel\u00b7ze\u00b7bub", "ver\u00b7schwand", ",", "stands\u00b7m\u00e4\u00b7\u00dfig", "mit", "Ge\u00b7stank", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "$,", "ADJD", "APPR", "NN", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.5": {"text": "Es springt Aurel um den bemerkten Platz,", "tokens": ["Es", "springt", "Au\u00b7rel", "um", "den", "be\u00b7merk\u00b7ten", "Platz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NE", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Als ob er seinen Fund schon h\u00e4tte;", "tokens": ["Als", "ob", "er", "sei\u00b7nen", "Fund", "schon", "h\u00e4t\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "PPER", "PPOSAT", "NN", "ADV", "VAFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Doch st\u00f6\u00dft er sich an einen Baum.", "tokens": ["Doch", "st\u00f6\u00dft", "er", "sich", "an", "ei\u00b7nen", "Baum", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PRF", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Aurel erwacht, (denn alles war ein Traum)", "tokens": ["Au\u00b7rel", "er\u00b7wacht", ",", "(", "denn", "al\u00b7les", "war", "ein", "Traum", ")"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVPP", "$,", "$(", "KON", "PIS", "VAFIN", "ART", "NN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Und von dem vorgestellten Schatz", "tokens": ["Und", "von", "dem", "vor\u00b7ge\u00b7stell\u00b7ten", "Schatz"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Bleibt nur das Zeichen in dem Bette.", "tokens": ["Bleibt", "nur", "das", "Zei\u00b7chen", "in", "dem", "Bet\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Es ist der Geiz der Teufel vieler Alten,", "tokens": ["Es", "ist", "der", "Geiz", "der", "Teu\u00b7fel", "vie\u00b7ler", "Al\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "ART", "NN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und der Beelzebub, der lockend sie beth\u00f6rt.", "tokens": ["Und", "der", "Beel\u00b7ze\u00b7bub", ",", "der", "lo\u00b7ckend", "sie", "be\u00b7th\u00f6rt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "PRELS", "ADJD", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.3": {"text": "Ihr ungebrauchter Schatz ist aber nicht mehr werth,", "tokens": ["Ihr", "un\u00b7ge\u00b7brauch\u00b7ter", "Schatz", "ist", "a\u00b7ber", "nicht", "mehr", "werth", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VAFIN", "ADV", "PTKNEG", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Als was Aurel allhier erhalten.", "tokens": ["Als", "was", "Au\u00b7rel", "all\u00b7hier", "er\u00b7hal\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "NN", "ADV", "VVPP", "$."], "meter": "--+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.12": {"line.1": {"text": "Es wird Aurel, der nichts, als Armuth, scheut,", "tokens": ["Es", "wird", "Au\u00b7rel", ",", "der", "nichts", ",", "als", "Ar\u00b7muth", ",", "scheut", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VAFIN", "NE", "$,", "PRELS", "PIS", "$,", "KOUS", "NN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Zum Mammonsknecht, zum Harpax unsrer Zeit.", "tokens": ["Zum", "Mam\u00b7mons\u00b7knecht", ",", "zum", "Har\u00b7pax", "uns\u00b7rer", "Zeit", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "APPRART", "NE", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Ihm ist der Klang von vielen todten Sch\u00e4tzen", "tokens": ["Ihm", "ist", "der", "Klang", "von", "vie\u00b7len", "tod\u00b7ten", "Sch\u00e4t\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "NN", "APPR", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Ein Saitenspiel, das Z\u00e4hlen ein Erg\u00f6tzen.", "tokens": ["Ein", "Sai\u00b7ten\u00b7spiel", ",", "das", "Z\u00e4h\u00b7len", "ein", "Er\u00b7g\u00f6t\u00b7zen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Oft schl\u00e4ft der Thor, noch hungrig und mit Pein,", "tokens": ["Oft", "schl\u00e4ft", "der", "Thor", ",", "noch", "hung\u00b7rig", "und", "mit", "Pein", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$,", "ADV", "ADJD", "KON", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Vom H\u00fcten matt, auf vollen S\u00e4cken ein;", "tokens": ["Vom", "H\u00fc\u00b7ten", "matt", ",", "auf", "vol\u00b7len", "S\u00e4\u00b7cken", "ein", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PTKVZ", "$,", "APPR", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Denn Geld und Geiz nimmt t\u00e4glich bei ihm zu;", "tokens": ["Denn", "Geld", "und", "Geiz", "nimmt", "t\u00e4g\u00b7lich", "bei", "ihm", "zu", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "KON", "NN", "VVFIN", "ADJD", "APPR", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Geld ist sein Trost, sein Leben, seine Ruh',", "tokens": ["Geld", "ist", "sein", "Trost", ",", "sein", "Le\u00b7ben", ",", "sei\u00b7ne", "Ruh'", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPOSAT", "NN", "$,", "PPOSAT", "NN", "$,", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Sein Herr, sein Gott. Stets nagt ein scharfer Neid", "tokens": ["Sein", "Herr", ",", "sein", "Gott", ".", "Stets", "nagt", "ein", "schar\u00b7fer", "Neid"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "$,", "PPOSAT", "NN", "$.", "ADV", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Sein blutend Herz. J\u00fcngst mehrt' ein vielfach Leid", "tokens": ["Sein", "blu\u00b7tend", "Herz", ".", "J\u00fcngst", "mehrt'", "ein", "viel\u00b7fach", "Leid"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "ADJD", "NN", "$.", "NN", "VVFIN", "ART", "PIAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Des Wuchrers Qual und Unzufriedenheit.", "tokens": ["Des", "Wuc\u00b7hrers", "Qual", "und", "Un\u00b7zu\u00b7frie\u00b7den\u00b7heit", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.13": {"line.1": {"text": "Der Wittwen Fluch? Beraubter Waisen Ach?", "tokens": ["Der", "Witt\u00b7wen", "Fluch", "?", "Be\u00b7raub\u00b7ter", "Wai\u00b7sen", "Ach", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$.", "NN", "NN", "ITJ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Die Reue? Nein. Dergleichen Kleinigkeit", "tokens": ["Die", "Reu\u00b7e", "?", "Nein", ".", "Derg\u00b7lei\u00b7chen", "Klei\u00b7nig\u00b7keit"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word"], "pos": ["ART", "NN", "$.", "PTKANT", "$.", "PIS", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Gibt Reichen jetzt kein gro\u00dfes Ungemach.", "tokens": ["Gibt", "Rei\u00b7chen", "jetzt", "kein", "gro\u00b7\u00dfes", "Un\u00b7ge\u00b7mach", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "ADV", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Was wichtigers: Zu sp\u00e4t erfolgte Renten,", "tokens": ["Was", "wich\u00b7ti\u00b7gers", ":", "Zu", "sp\u00e4t", "er\u00b7folg\u00b7te", "Ren\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "$.", "PTKA", "ADJD", "VVFIN", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Ein drohender Protest, zu wenige Procenten,", "tokens": ["Ein", "dro\u00b7hen\u00b7der", "Pro\u00b7test", ",", "zu", "we\u00b7ni\u00b7ge", "Pro\u00b7cen\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Ein viel zu mildes Jahr, der zu f\u00fcrwitz'ge Zoll.", "tokens": ["Ein", "viel", "zu", "mil\u00b7des", "Jahr", ",", "der", "zu", "f\u00fcr\u00b7witz'\u00b7ge", "Zoll", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "ADJA", "NN", "$,", "PRELS", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Dies alles f\u00fcllt sein Herz mit Unmuth, Zorn und Groll.", "tokens": ["Dies", "al\u00b7les", "f\u00fcllt", "sein", "Herz", "mit", "Un\u00b7muth", ",", "Zorn", "und", "Groll", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "PIS", "VVFIN", "PPOSAT", "NN", "APPR", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Er wird zuletzt verzweiflungsvoll.", "tokens": ["Er", "wird", "zu\u00b7letzt", "ver\u00b7zwei\u00b7flungs\u00b7voll", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Als er so gro\u00dfer Noth zu peinlich nachgedacht,", "tokens": ["Als", "er", "so", "gro\u00b7\u00dfer", "Noth", "zu", "pein\u00b7lich", "nach\u00b7ge\u00b7dacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADJA", "NN", "PTKA", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ruft der Unsinnige sogar in einer Nacht", "tokens": ["Ruft", "der", "Un\u00b7sin\u00b7ni\u00b7ge", "so\u00b7gar", "in", "ei\u00b7ner", "Nacht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "NN", "ADV", "APPR", "ART", "NN"], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.3": {"text": "Den Satan an, und Satan schickt ihm gleich", "tokens": ["Den", "Sa\u00b7tan", "an", ",", "und", "Sa\u00b7tan", "schickt", "ihm", "gleich"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "PTKVZ", "$,", "KON", "NN", "VVFIN", "PPER", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Den gr\u00f6\u00dften Herrn aus seinem Reich,", "tokens": ["Den", "gr\u00f6\u00df\u00b7ten", "Herrn", "aus", "sei\u00b7nem", "Reich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Der jetzt, den Alten zu ber\u00fccken,", "tokens": ["Der", "jetzt", ",", "den", "Al\u00b7ten", "zu", "be\u00b7r\u00fc\u00b7cken", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "$,", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "In einer neuen Tracht erschien,", "tokens": ["In", "ei\u00b7ner", "neu\u00b7en", "Tracht", "er\u00b7schien", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Wol zehnmal sch\u00f6ner, als wir ihn", "tokens": ["Wol", "zehn\u00b7mal", "sch\u00f6\u00b7ner", ",", "als", "wir", "ihn"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "ADV", "ADJD", "$,", "KOUS", "PPER", "PPER"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.8": {"text": "In den Gem\u00e4lden oft erblicken,", "tokens": ["In", "den", "Ge\u00b7m\u00e4l\u00b7den", "oft", "er\u00b7bli\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Wo ihm die Augen funkelnd gl\u00fchn,", "tokens": ["Wo", "ihm", "die", "Au\u00b7gen", "fun\u00b7kelnd", "gl\u00fchn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "NN", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Und H\u00f6rner seine Stirne schm\u00fccken.", "tokens": ["Und", "H\u00f6r\u00b7ner", "sei\u00b7ne", "Stir\u00b7ne", "schm\u00fc\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Er hatte weder Schweif noch Klauen,", "tokens": ["Er", "hat\u00b7te", "we\u00b7der", "Schweif", "noch", "Klau\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "KON", "NN", "ADV", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Der H\u00f6lle zaubernde Gewalt", "tokens": ["Der", "H\u00f6l\u00b7le", "zau\u00b7bern\u00b7de", "Ge\u00b7walt"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ADJA", "NN"], "meter": "-+-+---+", "measure": "unknown.measure.tri"}, "line.13": {"text": "Gab ihm die menschliche Gestalt,", "tokens": ["Gab", "ihm", "die", "menschli\u00b7che", "Ge\u00b7stalt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.14": {"text": "Und keinem durfte vor ihm grauen.", "tokens": ["Und", "kei\u00b7nem", "durf\u00b7te", "vor", "ihm", "grau\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VMFIN", "APPR", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "Er \u00fcberkam, nach unsrer Stutzer Art,", "tokens": ["Er", "\u00fc\u00b7ber\u00b7kam", ",", "nach", "uns\u00b7rer", "Stut\u00b7zer", "Art", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "APPR", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.16": {"text": "Ein sch\u00f6nes leeres Haubt, ein wohl gepudert Haar,", "tokens": ["Ein", "sch\u00f6\u00b7nes", "lee\u00b7res", "Haubt", ",", "ein", "wohl", "ge\u00b7pu\u00b7dert", "Haar", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "$,", "ART", "ADV", "VVPP", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Wobei zugleich dem Kinnchen ohne Bart", "tokens": ["Wo\u00b7bei", "zu\u00b7gleich", "dem", "Kinn\u00b7chen", "oh\u00b7ne", "Bart"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADV", "ART", "NN", "APPR", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.18": {"text": "Ein Fl\u00fcgelwerk von Band, anstatt des Schattens, war.", "tokens": ["Ein", "Fl\u00fc\u00b7gel\u00b7werk", "von", "Band", ",", "an\u00b7statt", "des", "Schat\u00b7tens", ",", "war", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "$,", "KOUI", "ART", "NN", "$,", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Er selbst, wie seine Pracht, war ohne Fehl und Tadel,", "tokens": ["Er", "selbst", ",", "wie", "sei\u00b7ne", "Pracht", ",", "war", "oh\u00b7ne", "Fehl", "und", "Ta\u00b7del", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "$,", "PWAV", "PPOSAT", "NN", "$,", "VAFIN", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Und Herr und Kleid von gleichem Adel.", "tokens": ["Und", "Herr", "und", "Kleid", "von", "glei\u00b7chem", "A\u00b7del", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "KON", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "Nur lie\u00df man ihm (so lautet der Bericht)", "tokens": ["Nur", "lie\u00df", "man", "ihm", "(", "so", "lau\u00b7tet", "der", "Be\u00b7richt", ")"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "PPER", "$(", "ADV", "VVFIN", "ART", "NN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Den einen Pferdefu\u00df. Warum? Das wei\u00df ich nicht.", "tokens": ["Den", "ei\u00b7nen", "Pfer\u00b7de\u00b7fu\u00df", ".", "Wa\u00b7rum", "?", "Das", "wei\u00df", "ich", "nicht", "."], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "$.", "PWAV", "$.", "PDS", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Er war ja sonst, ohn' allen Zweifel,", "tokens": ["Er", "war", "ja", "sonst", ",", "ohn'", "al\u00b7len", "Zwei\u00b7fel", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "$,", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ein h\u00fcbscher, recht galanter Teufel.", "tokens": ["Ein", "h\u00fcb\u00b7scher", ",", "recht", "ga\u00b7lan\u00b7ter", "Teu\u00b7fel", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "$,", "ADJD", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "Bald fand der karge Greis den l\u00e4ngst gesuchten Rath,", "tokens": ["Bald", "fand", "der", "kar\u00b7ge", "Greis", "den", "l\u00e4ngst", "ge\u00b7such\u00b7ten", "Rath", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "ART", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Als dieser Cavalier zu ihm ins Zimmer trat.", "tokens": ["Als", "die\u00b7ser", "Ca\u00b7va\u00b7lier", "zu", "ihm", "ins", "Zim\u00b7mer", "trat", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDAT", "NN", "APPR", "PPER", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.17": {"line.1": {"text": "Mein Herr, wie hei\u00dfen Sie? ... Beelzebub ... Willkommen!", "tokens": ["Mein", "Herr", ",", "wie", "hei\u00b7\u00dfen", "Sie", "?", "...", "Beel\u00b7ze\u00b7bub", "...", "Will\u00b7kom\u00b7men", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "punct", "word", "punct", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PWAV", "VVFIN", "PPER", "$.", "$(", "NE", "$(", "NN", "$."], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Der Oberste der Teufel? ... Ja ...", "tokens": ["Der", "O\u00b7bers\u00b7te", "der", "Teu\u00b7fel", "?", "...", "Ja", "..."], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$.", "$(", "PTKANT", "$("], "meter": "-+---+-+", "measure": "dactylic.init"}, "line.3": {"text": "Ich hatt' es nicht in Acht genommen,", "tokens": ["Ich", "hatt'", "es", "nicht", "in", "Acht", "ge\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "PTKNEG", "APPR", "CARD", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Weil ich noch nicht auf dero F\u00fc\u00dfe sah.", "tokens": ["Weil", "ich", "noch", "nicht", "auf", "de\u00b7ro", "F\u00fc\u00b7\u00dfe", "sah", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PTKNEG", "APPR", "PRELAT", "NN", "VVFIN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.5": {"text": "Sie setzen sich ... Wie geht es in der H\u00f6llen? ...", "tokens": ["Sie", "set\u00b7zen", "sich", "...", "Wie", "geht", "es", "in", "der", "H\u00f6l\u00b7len", "?", "..."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "PRF", "$(", "PWAV", "VVFIN", "PPER", "APPR", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Wie lebt mein reicher Oheim da? ...", "tokens": ["Wie", "lebt", "mein", "rei\u00b7cher", "O\u00b7heim", "da", "?", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWAV", "VVFIN", "PPOSAT", "ADJA", "NN", "PTKVZ", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Recht wie ein F\u00fcrst.. Und wie befindet sich", "tokens": ["Recht", "wie", "ein", "F\u00fcrst", "..", "Und", "wie", "be\u00b7fin\u00b7det", "sich"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "KOKOM", "ART", "NN", "$.", "KON", "PWAV", "VVFIN", "PRF"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Der Lucifer? ... Ich bitte dich,", "tokens": ["Der", "Lu\u00b7ci\u00b7fer", "?", "...", "Ich", "bit\u00b7te", "dich", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NE", "$.", "$(", "PPER", "VVFIN", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Die Complimente einzustellen.", "tokens": ["Die", "Com\u00b7pli\u00b7men\u00b7te", "ein\u00b7zu\u00b7stel\u00b7len", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVIZU", "$."], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.10": {"text": "Dich reich zu machen, komm' ich hier.", "tokens": ["Dich", "reich", "zu", "ma\u00b7chen", ",", "komm'", "ich", "hier", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "PTKZU", "VVINF", "$,", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Ich bin dein Retter. Folge mir.", "tokens": ["Ich", "bin", "dein", "Ret\u00b7ter", ".", "Fol\u00b7ge", "mir", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "NN", "$.", "NN", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.18": {"line.1": {"text": "Sein F\u00fchrer bringet ihn in einen \u00f6den Wald", "tokens": ["Sein", "F\u00fch\u00b7rer", "brin\u00b7get", "ihn", "in", "ei\u00b7nen", "\u00f6\u00b7den", "Wald"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Von heiligen bemoosten alten Eichen,", "tokens": ["Von", "hei\u00b7li\u00b7gen", "be\u00b7moos\u00b7ten", "al\u00b7ten", "Ei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Den Sitz des Czernebocks, der Gnomen Aufenthalt,", "tokens": ["Den", "Sitz", "des", "Czer\u00b7ne\u00b7bocks", ",", "der", "Gno\u00b7men", "Auf\u00b7ent\u00b7halt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die Schlachtbank vieler Opferleichen.", "tokens": ["Die", "Schlacht\u00b7bank", "vie\u00b7ler", "Op\u00b7fer\u00b7lei\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PIAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Hier herrscht, fast tausend Jahr', ein schwarzer wilder Schrecken", "tokens": ["Hier", "herrscht", ",", "fast", "tau\u00b7send", "Jahr'", ",", "ein", "schwar\u00b7zer", "wil\u00b7der", "Schre\u00b7cken"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "$,", "ADV", "CARD", "NN", "$,", "ART", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "In grauser Finsterni\u00df. Den unwirthbaren Sitz", "tokens": ["In", "grau\u00b7ser", "Fins\u00b7ter\u00b7ni\u00df", ".", "Den", "un\u00b7wirth\u00b7ba\u00b7ren", "Sitz"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "$.", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Verkl\u00e4rt, doch selten nur, ein rother schneller Blitz.", "tokens": ["Ver\u00b7kl\u00e4rt", ",", "doch", "sel\u00b7ten", "nur", ",", "ein", "ro\u00b7ther", "schnel\u00b7ler", "Blitz", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "ADV", "ADJD", "ADV", "$,", "ART", "ADJA", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Hier sollte sich der Trost Aurels entdecken.", "tokens": ["Hier", "soll\u00b7te", "sich", "der", "Trost", "Au\u00b7rels", "ent\u00b7de\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PRF", "ART", "NN", "NE", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Hier blieb der Fliegenf\u00fcrst und sein Gef\u00e4hrte stehn.", "tokens": ["Hier", "blieb", "der", "Flie\u00b7gen\u00b7f\u00fcrst", "und", "sein", "Ge\u00b7f\u00e4hr\u00b7te", "stehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "KON", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Er stampft dreimal: dreimal erbebt der Grund:", "tokens": ["Er", "stampft", "drei\u00b7mal", ":", "drei\u00b7mal", "er\u00b7bebt", "der", "Grund", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$.", "ADV", "VVFIN", "ART", "NN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.11": {"text": "Es \u00f6ffnet sich ein lichter, tiefer Schlund,", "tokens": ["Es", "\u00f6ff\u00b7net", "sich", "ein", "lich\u00b7ter", ",", "tie\u00b7fer", "Schlund", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "ART", "ADJD", "$,", "ADJA", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.12": {"text": "Und l\u00e4\u00dft im Augenblick so gro\u00dfe Baarschaft sehn,", "tokens": ["Und", "l\u00e4\u00dft", "im", "Au\u00b7gen\u00b7blick", "so", "gro\u00b7\u00dfe", "Baar\u00b7schaft", "sehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPRART", "NN", "ADV", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Als w\u00fcrde fast der Reichthum aller Welt,", "tokens": ["Als", "w\u00fcr\u00b7de", "fast", "der", "Reicht\u00b7hum", "al\u00b7ler", "Welt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VAFIN", "ADV", "ART", "NN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "Hier an Geschmeid' und Gold, den Augen dargestellt.", "tokens": ["Hier", "an", "Ge\u00b7schmeid'", "und", "Gold", ",", "den", "Au\u00b7gen", "dar\u00b7ge\u00b7stellt", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "KON", "NN", "$,", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Sieh', spricht der H\u00f6llengeist, auf diesem Platz", "tokens": ["Sieh'", ",", "spricht", "der", "H\u00f6l\u00b7len\u00b7geist", ",", "auf", "die\u00b7sem", "Platz"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NE", "$,", "VVFIN", "ART", "NN", "$,", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.16": {"text": "Liegt ein Geschenk f\u00fcr dich, der Schatz.", "tokens": ["Liegt", "ein", "Ge\u00b7schenk", "f\u00fcr", "dich", ",", "der", "Schatz", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "APPR", "PPER", "$,", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.19": {"line.1": {"text": "Wie wird der Filz durch dieses Wort entz\u00fcckt!", "tokens": ["Wie", "wird", "der", "Filz", "durch", "die\u00b7ses", "Wort", "ent\u00b7z\u00fcckt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "ART", "NN", "APPR", "PDAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Kein ird'sches Paradies scheint ihm so sch\u00f6n geschm\u00fcckt,", "tokens": ["Kein", "ird'\u00b7sches", "Pa\u00b7ra\u00b7dies", "scheint", "ihm", "so", "sch\u00f6n", "ge\u00b7schm\u00fcckt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "VVFIN", "PPER", "ADV", "ADJD", "VVPP", "$,"], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "So reich an innerm Werth. Kein Thumherr, kein Pr\u00e4lat,", "tokens": ["So", "reich", "an", "in\u00b7nerm", "Werth", ".", "Kein", "Thum\u00b7herr", ",", "kein", "Pr\u00e4\u00b7lat", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ADJD", "APPR", "ADJA", "NN", "$.", "PIAT", "NN", "$,", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der seiner Pfr\u00fcnde Zins in Rheinwein vor sich hat,", "tokens": ["Der", "sei\u00b7ner", "Pfr\u00fcn\u00b7de", "Zins", "in", "Rhein\u00b7wein", "vor", "sich", "hat", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "NE", "APPR", "NE", "APPR", "PRF", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Kein Bischof, der erfreut, an einem Kirchweihfest,", "tokens": ["Kein", "Bi\u00b7schof", ",", "der", "er\u00b7freut", ",", "an", "ei\u00b7nem", "Kirch\u00b7weih\u00b7fest", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "$,", "PRELS", "ADJD", "$,", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Das erste Glas besieht, das er sich reichen l\u00e4\u00dft,", "tokens": ["Das", "ers\u00b7te", "Glas", "be\u00b7sieht", ",", "das", "er", "sich", "rei\u00b7chen", "l\u00e4\u00dft", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,", "PRELS", "PPER", "PRF", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Wei\u00df mit so merklichem, doch wohlbefugtem, Sehnen", "tokens": ["Wei\u00df", "mit", "so", "merk\u00b7li\u00b7chem", ",", "doch", "wohl\u00b7be\u00b7fug\u00b7tem", ",", "Seh\u00b7nen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word"], "pos": ["VVFIN", "APPR", "ADV", "ADJA", "$,", "ADV", "ADJA", "$,", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Sein fromm und fett Gesicht durch L\u00e4cheln auszudehnen.", "tokens": ["Sein", "fromm", "und", "fett", "Ge\u00b7sicht", "durch", "L\u00e4\u00b7cheln", "aus\u00b7zu\u00b7deh\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJD", "KON", "ADJD", "NN", "APPR", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Er streckt frohlockend aus die hoffnungsreiche Hand.", "tokens": ["Er", "streckt", "froh\u00b7lo\u00b7ckend", "aus", "die", "hoff\u00b7nungs\u00b7rei\u00b7che", "Hand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Wiewol, o harter Zwang! Gl\u00fcck voller Unbestand!", "tokens": ["Wie\u00b7wol", ",", "o", "har\u00b7ter", "Zwang", "!", "Gl\u00fcck", "vol\u00b7ler", "Un\u00b7be\u00b7stand", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "$,", "FM", "ADJA", "NN", "$.", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Halt, ruft Beelzebub, dies ist dir zwar gegeben,", "tokens": ["Halt", ",", "ruft", "Beel\u00b7ze\u00b7bub", ",", "dies", "ist", "dir", "zwar", "ge\u00b7ge\u00b7ben", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "NE", "$,", "PDS", "VAFIN", "PPER", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.12": {"text": "Allein vor morgen nicht zu heben.", "tokens": ["Al\u00b7lein", "vor", "mor\u00b7gen", "nicht", "zu", "he\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ADV", "PTKNEG", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.20": {"line.1": {"text": "Der Schatz versinkt auf dieses Donnerwort.", "tokens": ["Der", "Schatz", "ver\u00b7sinkt", "auf", "die\u00b7ses", "Don\u00b7ner\u00b7wort", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "PDAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Gestrenger Herr! wie kurz ist meine Freude!", "tokens": ["Ge\u00b7stren\u00b7ger", "Herr", "!", "wie", "kurz", "ist", "mei\u00b7ne", "Freu\u00b7de", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$.", "PWAV", "ADJD", "VAFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Betrogener Aurel! wie findest du den Ort?", "tokens": ["Be\u00b7tro\u00b7ge\u00b7ner", "Au\u00b7rel", "!", "wie", "fin\u00b7dest", "du", "den", "Ort", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "$.", "PWAV", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "-+---+-+-+-+", "measure": "dactylic.init"}, "line.4": {"text": "Den Busch? die Kluft? den Schatz? ... Er ist und bleibet dein.", "tokens": ["Den", "Busch", "?", "die", "Kluft", "?", "den", "Schatz", "?", "...", "Er", "ist", "und", "blei\u00b7bet", "dein", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$.", "ART", "NN", "$.", "ART", "NN", "$.", "$(", "PPER", "VAFIN", "KON", "VVFIN", "PPOSAT", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Betrogen! Was? Ich ein Betr\u00fcger? ... Nein ....", "tokens": ["Be\u00b7tro\u00b7gen", "!", "Was", "?", "Ich", "ein", "Be\u00b7tr\u00fc\u00b7ger", "?", "...", "Nein", "...."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct", "punct", "word", "punct"], "pos": ["NN", "$.", "PWS", "$.", "PPER", "ART", "NN", "$.", "$(", "PTKANT", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Sei klug, und la\u00df ein Zeichen dort,", "tokens": ["Sei", "klug", ",", "und", "la\u00df", "ein", "Zei\u00b7chen", "dort", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAIMP", "ADJD", "$,", "KON", "VVIMP", "ART", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und nimm dir, wann es tagt, das Gold und das Geschmeide.", "tokens": ["Und", "nimm", "dir", ",", "wann", "es", "tagt", ",", "das", "Gold", "und", "das", "Ge\u00b7schmei\u00b7de", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVIMP", "PPER", "$,", "PWAV", "PPER", "VVFIN", "$,", "ART", "NN", "KON", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.21": {"line.1": {"text": "Gleich setzt er tiefgeb\u00fcckt sich und ein Zeichen hin.", "tokens": ["Gleich", "setzt", "er", "tief\u00b7ge\u00b7b\u00fcckt", "sich", "und", "ein", "Zei\u00b7chen", "hin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "PRF", "KON", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Er jauchzt mit neuvergn\u00fcgtem Sinn,", "tokens": ["Er", "jauchzt", "mit", "neu\u00b7ver\u00b7gn\u00fcg\u00b7tem", "Sinn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und sagt aufs zierlichste mit vielen Worten Dank.", "tokens": ["Und", "sagt", "aufs", "zier\u00b7lichs\u00b7te", "mit", "vie\u00b7len", "Wor\u00b7ten", "Dank", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPRART", "ADJA", "APPR", "PIAT", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Beelzebub verschwand, standsm\u00e4\u00dfig mit Gestank.", "tokens": ["Beel\u00b7ze\u00b7bub", "ver\u00b7schwand", ",", "stands\u00b7m\u00e4\u00b7\u00dfig", "mit", "Ge\u00b7stank", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "$,", "ADJD", "APPR", "NN", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.5": {"text": "Es springt Aurel um den bemerkten Platz,", "tokens": ["Es", "springt", "Au\u00b7rel", "um", "den", "be\u00b7merk\u00b7ten", "Platz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NE", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Als ob er seinen Fund schon h\u00e4tte;", "tokens": ["Als", "ob", "er", "sei\u00b7nen", "Fund", "schon", "h\u00e4t\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "PPER", "PPOSAT", "NN", "ADV", "VAFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Doch st\u00f6\u00dft er sich an einen Baum.", "tokens": ["Doch", "st\u00f6\u00dft", "er", "sich", "an", "ei\u00b7nen", "Baum", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PRF", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Aurel erwacht, (denn alles war ein Traum)", "tokens": ["Au\u00b7rel", "er\u00b7wacht", ",", "(", "denn", "al\u00b7les", "war", "ein", "Traum", ")"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVPP", "$,", "$(", "KON", "PIS", "VAFIN", "ART", "NN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Und von dem vorgestellten Schatz", "tokens": ["Und", "von", "dem", "vor\u00b7ge\u00b7stell\u00b7ten", "Schatz"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Bleibt nur das Zeichen in dem Bette.", "tokens": ["Bleibt", "nur", "das", "Zei\u00b7chen", "in", "dem", "Bet\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.22": {"line.1": {"text": "Es ist der Geiz der Teufel vieler Alten,", "tokens": ["Es", "ist", "der", "Geiz", "der", "Teu\u00b7fel", "vie\u00b7ler", "Al\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "ART", "NN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und der Beelzebub, der lockend sie beth\u00f6rt.", "tokens": ["Und", "der", "Beel\u00b7ze\u00b7bub", ",", "der", "lo\u00b7ckend", "sie", "be\u00b7th\u00f6rt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "PRELS", "ADJD", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.3": {"text": "Ihr ungebrauchter Schatz ist aber nicht mehr werth,", "tokens": ["Ihr", "un\u00b7ge\u00b7brauch\u00b7ter", "Schatz", "ist", "a\u00b7ber", "nicht", "mehr", "werth", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VAFIN", "ADV", "PTKNEG", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Als was Aurel allhier erhalten.", "tokens": ["Als", "was", "Au\u00b7rel", "all\u00b7hier", "er\u00b7hal\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "NN", "ADV", "VVPP", "$."], "meter": "--+-+--+-", "measure": "iambic.tri.relaxed"}}}}}