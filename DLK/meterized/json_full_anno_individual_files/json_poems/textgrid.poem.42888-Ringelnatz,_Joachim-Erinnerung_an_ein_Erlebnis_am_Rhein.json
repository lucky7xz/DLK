{"textgrid.poem.42888": {"metadata": {"author": {"name": "Ringelnatz, Joachim", "birth": "N.A.", "death": "N.A."}, "title": "Erinnerung an ein Erlebnis am Rhein", "genre": "verse", "period": "N.A.", "pub_year": 1908, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ja, ja! \u2013 Ich wei\u00df. \u2013 Du wei\u00dft. \u2013", "tokens": ["Ja", ",", "ja", "!", "\u2013", "Ich", "wei\u00df", ".", "\u2013", "Du", "wei\u00dft", ".", "\u2013"], "token_info": ["word", "punct", "word", "punct", "punct", "word", "word", "punct", "punct", "word", "word", "punct", "punct"], "pos": ["PTKANT", "$,", "ADV", "$.", "$(", "PPER", "VVFIN", "$.", "$(", "PPER", "VVFIN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Vor neunundzwanzig Jahren \u2013", "tokens": ["Vor", "neun\u00b7und\u00b7zwan\u00b7zig", "Jah\u00b7ren", "\u2013"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "CARD", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Wie z\u00e4rtlich gr\u00fcn wir waren! \u2013", "tokens": ["Wie", "z\u00e4rt\u00b7lich", "gr\u00fcn", "wir", "wa\u00b7ren", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWAV", "ADJD", "VVFIN", "PPER", "VAFIN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Damals. \u2013 Wie dankbar dreist! \u2013", "tokens": ["Da\u00b7mals", ".", "\u2013", "Wie", "dank\u00b7bar", "dreist", "!", "\u2013"], "token_info": ["word", "punct", "punct", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "$.", "$(", "PWAV", "ADJD", "VVFIN", "$.", "$("], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.5": {"text": "Und brauchte gar nicht mal am Rhein \u2013", "tokens": ["Und", "brauch\u00b7te", "gar", "nicht", "mal", "am", "Rhein", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "PTKNEG", "ADV", "APPRART", "NE", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Es konnte irgend anderswo,", "tokens": ["Es", "konn\u00b7te", "ir\u00b7gend", "an\u00b7ders\u00b7wo", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Vor schwarzen Mauern und auf Stroh", "tokens": ["Vor", "schwar\u00b7zen", "Mau\u00b7ern", "und", "auf", "Stroh"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "KON", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Gewesen sein. \u2013", "tokens": ["Ge\u00b7we\u00b7sen", "sein", ".", "\u2013"], "token_info": ["word", "word", "punct", "punct"], "pos": ["VVPP", "VAINF", "$.", "$("], "meter": "-+-+", "measure": "iambic.di"}, "line.9": {"text": "Weil wir doch wir, und weil wir so \u2013", "tokens": ["Weil", "wir", "doch", "wir", ",", "und", "weil", "wir", "so", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PPER", "$,", "KON", "KOUS", "PPER", "ADV", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "So waren. \u2013", "tokens": ["So", "wa\u00b7ren", ".", "\u2013"], "token_info": ["word", "word", "punct", "punct"], "pos": ["ADV", "VAFIN", "$.", "$("], "meter": "-+-", "measure": "amphibrach.single"}, "line.11": {"text": "Vor neunundzwanzig Jahren.", "tokens": ["Vor", "neun\u00b7und\u00b7zwan\u00b7zig", "Jah\u00b7ren", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "CARD", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Weil man nicht suchte, was man fand. \u2013", "tokens": ["Weil", "man", "nicht", "such\u00b7te", ",", "was", "man", "fand", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PIS", "PTKNEG", "VVFIN", "$,", "PRELS", "PIS", "VVFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Nun klingt das r\u00fchrsam hell", "tokens": ["Nun", "klingt", "das", "r\u00fchr\u00b7sam", "hell"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "ADJD", "ADJD"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Wie \u00bbAde, du mein lieb Heimatland\u00ab", "tokens": ["Wie", "\u00bb", "A\u00b7de", ",", "du", "mein", "lieb", "Hei\u00b7mat\u00b7land", "\u00ab"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$(", "NN", "$,", "PPER", "PPOSAT", "ADJD", "NN", "$("], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Aus einem Karussell.", "tokens": ["Aus", "ei\u00b7nem", "Ka\u00b7rus\u00b7sell", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Ja, ja! \u2013 Ich wei\u00df. \u2013 Du wei\u00dft. \u2013", "tokens": ["Ja", ",", "ja", "!", "\u2013", "Ich", "wei\u00df", ".", "\u2013", "Du", "wei\u00dft", ".", "\u2013"], "token_info": ["word", "punct", "word", "punct", "punct", "word", "word", "punct", "punct", "word", "word", "punct", "punct"], "pos": ["PTKANT", "$,", "ADV", "$.", "$(", "PPER", "VVFIN", "$.", "$(", "PPER", "VVFIN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Vor neunundzwanzig Jahren \u2013", "tokens": ["Vor", "neun\u00b7und\u00b7zwan\u00b7zig", "Jah\u00b7ren", "\u2013"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "CARD", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Wie z\u00e4rtlich gr\u00fcn wir waren! \u2013", "tokens": ["Wie", "z\u00e4rt\u00b7lich", "gr\u00fcn", "wir", "wa\u00b7ren", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWAV", "ADJD", "VVFIN", "PPER", "VAFIN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Damals. \u2013 Wie dankbar dreist! \u2013", "tokens": ["Da\u00b7mals", ".", "\u2013", "Wie", "dank\u00b7bar", "dreist", "!", "\u2013"], "token_info": ["word", "punct", "punct", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "$.", "$(", "PWAV", "ADJD", "VVFIN", "$.", "$("], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.5": {"text": "Und brauchte gar nicht mal am Rhein \u2013", "tokens": ["Und", "brauch\u00b7te", "gar", "nicht", "mal", "am", "Rhein", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "PTKNEG", "ADV", "APPRART", "NE", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Es konnte irgend anderswo,", "tokens": ["Es", "konn\u00b7te", "ir\u00b7gend", "an\u00b7ders\u00b7wo", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Vor schwarzen Mauern und auf Stroh", "tokens": ["Vor", "schwar\u00b7zen", "Mau\u00b7ern", "und", "auf", "Stroh"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "KON", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Gewesen sein. \u2013", "tokens": ["Ge\u00b7we\u00b7sen", "sein", ".", "\u2013"], "token_info": ["word", "word", "punct", "punct"], "pos": ["VVPP", "VAINF", "$.", "$("], "meter": "-+-+", "measure": "iambic.di"}, "line.9": {"text": "Weil wir doch wir, und weil wir so \u2013", "tokens": ["Weil", "wir", "doch", "wir", ",", "und", "weil", "wir", "so", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PPER", "$,", "KON", "KOUS", "PPER", "ADV", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "So waren. \u2013", "tokens": ["So", "wa\u00b7ren", ".", "\u2013"], "token_info": ["word", "word", "punct", "punct"], "pos": ["ADV", "VAFIN", "$.", "$("], "meter": "-+-", "measure": "amphibrach.single"}, "line.11": {"text": "Vor neunundzwanzig Jahren.", "tokens": ["Vor", "neun\u00b7und\u00b7zwan\u00b7zig", "Jah\u00b7ren", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "CARD", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Weil man nicht suchte, was man fand. \u2013", "tokens": ["Weil", "man", "nicht", "such\u00b7te", ",", "was", "man", "fand", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PIS", "PTKNEG", "VVFIN", "$,", "PRELS", "PIS", "VVFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Nun klingt das r\u00fchrsam hell", "tokens": ["Nun", "klingt", "das", "r\u00fchr\u00b7sam", "hell"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "ADJD", "ADJD"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Wie \u00bbAde, du mein lieb Heimatland\u00ab", "tokens": ["Wie", "\u00bb", "A\u00b7de", ",", "du", "mein", "lieb", "Hei\u00b7mat\u00b7land", "\u00ab"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$(", "NN", "$,", "PPER", "PPOSAT", "ADJD", "NN", "$("], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Aus einem Karussell.", "tokens": ["Aus", "ei\u00b7nem", "Ka\u00b7rus\u00b7sell", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}}}}