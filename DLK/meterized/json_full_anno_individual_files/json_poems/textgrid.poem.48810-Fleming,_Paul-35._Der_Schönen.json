{"textgrid.poem.48810": {"metadata": {"author": {"name": "Fleming, Paul", "birth": "N.A.", "death": "N.A."}, "title": "35. Der Sch\u00f6nen", "genre": "verse", "period": "N.A.", "pub_year": 1624, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Nicht, da\u00df du sch\u00f6ne nur alleine soltest sein;", "tokens": ["Nicht", ",", "da\u00df", "du", "sch\u00f6\u00b7ne", "nur", "al\u00b7lei\u00b7ne", "sol\u00b7test", "sein", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "$,", "KOUS", "PPER", "VVFIN", "ADV", "ADV", "VMFIN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "du bist auch keusch, auch from, wie deine Schwestern beide,", "tokens": ["du", "bist", "auch", "keusch", ",", "auch", "from", ",", "wie", "dei\u00b7ne", "Schwes\u00b7tern", "bei\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "$,", "ADV", "ADJD", "$,", "PWAV", "PPOSAT", "NN", "PIS", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "die sch\u00f6n auch sind wie du. Trutz allem Ha\u00df' und Neide,", "tokens": ["die", "sch\u00f6n", "auch", "sind", "wie", "du", ".", "Trutz", "al\u00b7lem", "Ha\u00df'", "und", "Nei\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "ADV", "VAFIN", "KOKOM", "PPER", "$.", "NN", "PIS", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "an den drei St\u00fccken kommt ihr g\u00e4nzlich \u00fcberein.", "tokens": ["an", "den", "drei", "St\u00fc\u00b7cken", "kommt", "ihr", "g\u00e4nz\u00b7lich", "\u00fc\u00b7be\u00b7re\u00b7in", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "CARD", "NN", "VVFIN", "PPER", "ADJD", "PTKVZ", "$."], "meter": "+--+-+-+-+--+", "measure": "iambic.hexa.invert"}}, "stanza.2": {"line.1": {"text": "Doch schreib ich, Sch\u00f6ne, dir hier zu nur einen Schein", "tokens": ["Doch", "schreib", "ich", ",", "Sch\u00f6\u00b7ne", ",", "dir", "hier", "zu", "nur", "ei\u00b7nen", "Schein"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "$,", "NN", "$,", "PPER", "ADV", "APPR", "ADV", "ART", "NN"], "meter": "-+-+-++--+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "und nenne dich nach dir, nicht etwan dir zu Leide,", "tokens": ["und", "nen\u00b7ne", "dich", "nach", "dir", ",", "nicht", "et\u00b7wan", "dir", "zu", "Lei\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "APPR", "PPER", "$,", "PTKNEG", "ADV", "PPER", "APPR", "NN", "$,"], "meter": "-+-+-+-++--+-", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "nein, sondern da\u00df ich nur die Namen unterscheide.", "tokens": ["nein", ",", "son\u00b7dern", "da\u00df", "ich", "nur", "die", "Na\u00b7men", "un\u00b7ter\u00b7schei\u00b7de", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "KON", "KOUS", "PPER", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Sonst seid ihr ganz gleich eins, gleich from, gleich keusch, gleich rein.", "tokens": ["Sonst", "seid", "ihr", "ganz", "gleich", "eins", ",", "gleich", "from", ",", "gleich", "keusch", ",", "gleich", "rein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ADV", "PIS", "$,", "ADV", "ADJD", "$,", "ADV", "ADJD", "$,", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "O Jungfrau, sonst zu Nichts als Tugend nur geberen,", "tokens": ["O", "Jung\u00b7frau", ",", "sonst", "zu", "Nichts", "als", "Tu\u00b7gend", "nur", "ge\u00b7be\u00b7ren", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "ADV", "APPR", "PIS", "KOKOM", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "in welche Zier und Zucht zusammen sich verschworen,", "tokens": ["in", "wel\u00b7che", "Zier", "und", "Zucht", "zu\u00b7sam\u00b7men", "sich", "ver\u00b7schwo\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PWAT", "NN", "KON", "NN", "VVFIN", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "verzeih mir diesen Fehl, du g\u00f6tlichs Menschenkind,", "tokens": ["ver\u00b7zeih", "mir", "die\u00b7sen", "Fehl", ",", "du", "g\u00f6t\u00b7lichs", "Men\u00b7schen\u00b7kind", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "PDAT", "NN", "$,", "PPER", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "da\u00df ich dein w\u00fcrdigs Lob nicht w\u00fcrdig kan erh\u00f6hen,", "tokens": ["da\u00df", "ich", "dein", "w\u00fcr\u00b7digs", "Lob", "nicht", "w\u00fcr\u00b7dig", "kan", "er\u00b7h\u00f6\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "ADJA", "NN", "PTKNEG", "ADJD", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "von dem die Suada selbst mit Willen mu\u00df gestehen,", "tokens": ["von", "dem", "die", "Sua\u00b7da", "selbst", "mit", "Wil\u00b7len", "mu\u00df", "ge\u00b7ste\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "ART", "NN", "ADV", "APPR", "NN", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "da\u00df tausent Zungen ihr hierzu zu wenig sind.", "tokens": ["da\u00df", "tau\u00b7sent", "Zun\u00b7gen", "ihr", "hier\u00b7zu", "zu", "we\u00b7nig", "sind", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "CARD", "NN", "PPER", "PAV", "PTKA", "PIS", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Nicht, da\u00df du sch\u00f6ne nur alleine soltest sein;", "tokens": ["Nicht", ",", "da\u00df", "du", "sch\u00f6\u00b7ne", "nur", "al\u00b7lei\u00b7ne", "sol\u00b7test", "sein", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "$,", "KOUS", "PPER", "VVFIN", "ADV", "ADV", "VMFIN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "du bist auch keusch, auch from, wie deine Schwestern beide,", "tokens": ["du", "bist", "auch", "keusch", ",", "auch", "from", ",", "wie", "dei\u00b7ne", "Schwes\u00b7tern", "bei\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "$,", "ADV", "ADJD", "$,", "PWAV", "PPOSAT", "NN", "PIS", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "die sch\u00f6n auch sind wie du. Trutz allem Ha\u00df' und Neide,", "tokens": ["die", "sch\u00f6n", "auch", "sind", "wie", "du", ".", "Trutz", "al\u00b7lem", "Ha\u00df'", "und", "Nei\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "ADV", "VAFIN", "KOKOM", "PPER", "$.", "NN", "PIS", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "an den drei St\u00fccken kommt ihr g\u00e4nzlich \u00fcberein.", "tokens": ["an", "den", "drei", "St\u00fc\u00b7cken", "kommt", "ihr", "g\u00e4nz\u00b7lich", "\u00fc\u00b7be\u00b7re\u00b7in", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "CARD", "NN", "VVFIN", "PPER", "ADJD", "PTKVZ", "$."], "meter": "+--+-+-+-+--+", "measure": "iambic.hexa.invert"}}, "stanza.6": {"line.1": {"text": "Doch schreib ich, Sch\u00f6ne, dir hier zu nur einen Schein", "tokens": ["Doch", "schreib", "ich", ",", "Sch\u00f6\u00b7ne", ",", "dir", "hier", "zu", "nur", "ei\u00b7nen", "Schein"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "$,", "NN", "$,", "PPER", "ADV", "APPR", "ADV", "ART", "NN"], "meter": "-+-+-++--+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "und nenne dich nach dir, nicht etwan dir zu Leide,", "tokens": ["und", "nen\u00b7ne", "dich", "nach", "dir", ",", "nicht", "et\u00b7wan", "dir", "zu", "Lei\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "APPR", "PPER", "$,", "PTKNEG", "ADV", "PPER", "APPR", "NN", "$,"], "meter": "-+-+-+-++--+-", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "nein, sondern da\u00df ich nur die Namen unterscheide.", "tokens": ["nein", ",", "son\u00b7dern", "da\u00df", "ich", "nur", "die", "Na\u00b7men", "un\u00b7ter\u00b7schei\u00b7de", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "KON", "KOUS", "PPER", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Sonst seid ihr ganz gleich eins, gleich from, gleich keusch, gleich rein.", "tokens": ["Sonst", "seid", "ihr", "ganz", "gleich", "eins", ",", "gleich", "from", ",", "gleich", "keusch", ",", "gleich", "rein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ADV", "PIS", "$,", "ADV", "ADJD", "$,", "ADV", "ADJD", "$,", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "O Jungfrau, sonst zu Nichts als Tugend nur geberen,", "tokens": ["O", "Jung\u00b7frau", ",", "sonst", "zu", "Nichts", "als", "Tu\u00b7gend", "nur", "ge\u00b7be\u00b7ren", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "ADV", "APPR", "PIS", "KOKOM", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "in welche Zier und Zucht zusammen sich verschworen,", "tokens": ["in", "wel\u00b7che", "Zier", "und", "Zucht", "zu\u00b7sam\u00b7men", "sich", "ver\u00b7schwo\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PWAT", "NN", "KON", "NN", "VVFIN", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "verzeih mir diesen Fehl, du g\u00f6tlichs Menschenkind,", "tokens": ["ver\u00b7zeih", "mir", "die\u00b7sen", "Fehl", ",", "du", "g\u00f6t\u00b7lichs", "Men\u00b7schen\u00b7kind", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "PDAT", "NN", "$,", "PPER", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "da\u00df ich dein w\u00fcrdigs Lob nicht w\u00fcrdig kan erh\u00f6hen,", "tokens": ["da\u00df", "ich", "dein", "w\u00fcr\u00b7digs", "Lob", "nicht", "w\u00fcr\u00b7dig", "kan", "er\u00b7h\u00f6\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "ADJA", "NN", "PTKNEG", "ADJD", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "von dem die Suada selbst mit Willen mu\u00df gestehen,", "tokens": ["von", "dem", "die", "Sua\u00b7da", "selbst", "mit", "Wil\u00b7len", "mu\u00df", "ge\u00b7ste\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "ART", "NN", "ADV", "APPR", "NN", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "da\u00df tausent Zungen ihr hierzu zu wenig sind.", "tokens": ["da\u00df", "tau\u00b7sent", "Zun\u00b7gen", "ihr", "hier\u00b7zu", "zu", "we\u00b7nig", "sind", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "CARD", "NN", "PPER", "PAV", "PTKA", "PIS", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}