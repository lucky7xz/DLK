{"textgrid.poem.47922": {"metadata": {"author": {"name": "Rost, Johann Christoph", "birth": "N.A.", "death": "N.A."}, "title": "1L: Kaum drang der Sonnen-Glantz in Gottscheds Schlaff-Gemach,", "genre": "verse", "period": "N.A.", "pub_year": 1741, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Kaum drang der Sonnen-Glantz in Gottscheds Schlaff-Gemach,", "tokens": ["Kaum", "drang", "der", "Son\u00b7nen\u00b7Glantz", "in", "Gott\u00b7scheds", "Schlaff\u00b7Ge\u00b7mach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPR", "NE", "NE", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Als aussen Schwabe schon mit dem Bedienten sprach;", "tokens": ["Als", "aus\u00b7sen", "Schwa\u00b7be", "schon", "mit", "dem", "Be\u00b7dien\u00b7ten", "sprach", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "NN", "ADV", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der kleine Patriot, des Meisters liebster J\u00fcnger,", "tokens": ["Der", "klei\u00b7ne", "Pat\u00b7ri\u00b7ot", ",", "des", "Meis\u00b7ters", "liebs\u00b7ter", "J\u00fcn\u00b7ger", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "In deutscher Prose flinck, im reimen nicht geringer;", "tokens": ["In", "deut\u00b7scher", "Pro\u00b7se", "flinck", ",", "im", "rei\u00b7men", "nicht", "ge\u00b7rin\u00b7ger", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "PTKVZ", "$,", "APPRART", "VVFIN", "PTKNEG", "ADJD", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Zum \u00fcbersetzen schnell, zum tadeln aufgelegt;", "tokens": ["Zum", "\u00fc\u00b7bers\u00b7et\u00b7zen", "schnell", ",", "zum", "ta\u00b7deln", "auf\u00b7ge\u00b7legt", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "ADJD", "$,", "APPRART", "VVINF", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "In dem Philippis-Geist sich noch heroisch regt.", "tokens": ["In", "dem", "Phil\u00b7ip\u00b7pis\u00b7Geist", "sich", "noch", "he\u00b7ro\u00b7isch", "reg\u00b7t."], "token_info": ["word", "word", "word", "word", "word", "word", "abbreviation"], "pos": ["APPR", "ART", "NN", "PRF", "ADV", "ADJD", "NE"], "meter": "--+--+-+--+", "measure": "anapaest.di.plus"}, "line.7": {"text": "Kein muthiger Pigm\u00e4 ist Schwaben zu vergleichen,", "tokens": ["Kein", "mut\u00b7hi\u00b7ger", "Pig\u00b7m\u00e4", "ist", "Schwa\u00b7ben", "zu", "ver\u00b7glei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "VAFIN", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.8": {"text": "Wenn f\u00fcr der Waffen Blitz die Kranche sch\u00fcchtern weichen;", "tokens": ["Wenn", "f\u00fcr", "der", "Waf\u00b7fen", "Blitz", "die", "Kran\u00b7che", "sch\u00fcch\u00b7tern", "wei\u00b7chen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "ART", "NN", "NN", "ART", "NN", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Er gieng weit kecker noch im Zimmer auf und ab,", "tokens": ["Er", "gieng", "weit", "ke\u00b7cker", "noch", "im", "Zim\u00b7mer", "auf", "und", "ab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "ADJD", "ADV", "APPRART", "NN", "PTKVZ", "KON", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Eh der Professor kam und ihm Geh\u00f6re gab.", "tokens": ["Eh", "der", "Pro\u00b7fes\u00b7sor", "kam", "und", "ihm", "Ge\u00b7h\u00f6\u00b7re", "gab", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "VVFIN", "KON", "PPER", "NN", "VVFIN", "$."], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.11": {"text": "Es ruhete di\u00dfmahl sein Meister viel zu lange,", "tokens": ["Es", "ru\u00b7he\u00b7te", "di\u00df\u00b7mahl", "sein", "Meis\u00b7ter", "viel", "zu", "lan\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PPOSAT", "NN", "ADV", "PTKA", "ADV", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Jedoch ein muntrer Kopff wei\u00df nichts vom M\u00fc\u00dfiggange;", "tokens": ["Je\u00b7doch", "ein", "mun\u00b7trer", "Kopff", "wei\u00df", "nichts", "vom", "M\u00fc\u00b7\u00dfig\u00b7gan\u00b7ge", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "VVFIN", "PIS", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Auch er verfertigte, bey der Gelegenheit,", "tokens": ["Auch", "er", "ver\u00b7fer\u00b7tig\u00b7te", ",", "bey", "der", "Ge\u00b7le\u00b7gen\u00b7heit", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VVFIN", "$,", "APPR", "ART", "NN", "$,"], "meter": "+--+--+--+-+", "measure": "dactylic.tri.plus"}, "line.14": {"text": "Den stoltzen Leber-Reim auf Gottscheds Schl\u00e4frigkeit:", "tokens": ["Den", "stolt\u00b7zen", "Le\u00b7ber\u00b7Reim", "auf", "Gott\u00b7scheds", "Schl\u00e4f\u00b7rig\u00b7keit", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "NE", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Die Leber ist vom Hecht und nicht von einem Hummer:", "tokens": ["Die", "Le\u00b7ber", "ist", "vom", "Hecht", "und", "nicht", "von", "ei\u00b7nem", "Hum\u00b7mer", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "APPRART", "NN", "KON", "PTKNEG", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Der Erde Ph\u00f6bus wacht, der meine liegt im Schlummer.", "tokens": ["Der", "Er\u00b7de", "Ph\u00f6\u00b7bus", "wacht", ",", "der", "mei\u00b7ne", "liegt", "im", "Schlum\u00b7mer", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NE", "VVFIN", "$,", "PRELS", "PPOSAT", "VVFIN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Er fuhr schon weiter fort, die Leber ist vom Hecht \u2013 \u2013,", "tokens": ["Er", "fuhr", "schon", "wei\u00b7ter", "fort", ",", "die", "Le\u00b7ber", "ist", "vom", "Hecht", "\u2013", "\u2013", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "PTKVZ", "$,", "ART", "NN", "VAFIN", "APPRART", "NN", "$(", "$(", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Doch st\u00f6hrt ihn Amarant", "tokens": ["Doch", "st\u00f6hrt", "ihn", "A\u00b7ma\u00b7rant"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "NE"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.19": {"text": "Ein Dichter aus der Zeit, die noch ein Wortspiel sch\u00e4tzte;", "tokens": ["Ein", "Dich\u00b7ter", "aus", "der", "Zeit", ",", "die", "noch", "ein", "Wort\u00b7spiel", "sch\u00e4tz\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$,", "PRELS", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Ein T\u00e4ntzer,", "tokens": ["Ein", "T\u00e4nt\u00b7zer", ","], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.21": {"text": "Der redliche Corvin trat in das Vorgemach,", "tokens": ["Der", "red\u00b7li\u00b7che", "Cor\u00b7vin", "trat", "in", "das", "Vor\u00b7ge\u00b7mach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Ihm aber folgete der Drucker Breitkopff nach.", "tokens": ["Ihm", "a\u00b7ber", "fol\u00b7ge\u00b7te", "der", "Dru\u00b7cker", "Breit\u00b7kopff", "nach", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "ART", "NN", "NE", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Was mu\u00df doch, sprach Corvin: der Herr Professor wollen?", "tokens": ["Was", "mu\u00df", "doch", ",", "sprach", "Cor\u00b7vin", ":", "der", "Herr", "Pro\u00b7fes\u00b7sor", "wol\u00b7len", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "ADV", "$,", "VVFIN", "NE", "$.", "ART", "NN", "NN", "VMFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Und das wir dreye nur, sprach Breitkopff, wissen sollen?", "tokens": ["Und", "das", "wir", "drey\u00b7e", "nur", ",", "sprach", "Breit\u00b7kopff", ",", "wis\u00b7sen", "sol\u00b7len", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ART", "PPER", "VVFIN", "ADV", "$,", "VVFIN", "NE", "$,", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Ein ieder rieth; allein, ob es errathen war,", "tokens": ["Ein", "ie\u00b7der", "rieth", ";", "al\u00b7lein", ",", "ob", "es", "er\u00b7ra\u00b7then", "war", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VVFIN", "$.", "ADV", "$,", "KOUS", "PPER", "VVINF", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "War durch des Schicksahls Schlu\u00df noch keinem offenbahr.", "tokens": ["War", "durch", "des", "Schick\u00b7sahls", "Schlu\u00df", "noch", "kei\u00b7nem", "of\u00b7fen\u00b7bahr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "ART", "NN", "NN", "ADV", "PIS", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Doch endlich mu\u00dfte sich die Ungeduld verliehren:", "tokens": ["Doch", "end\u00b7lich", "mu\u00df\u00b7te", "sich", "die", "Un\u00b7ge\u00b7duld", "ver\u00b7lieh\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VMFIN", "PRF", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Der Diener \u00f6ffnete die beyden Stuben-Th\u00fcren.", "tokens": ["Der", "Die\u00b7ner", "\u00f6ff\u00b7ne\u00b7te", "die", "bey\u00b7den", "Stu\u00b7ben\u00b7T\u00b7h\u00fc\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Nicht einer wollte hier der allerletzte seyn,", "tokens": ["Nicht", "ei\u00b7ner", "woll\u00b7te", "hier", "der", "al\u00b7ler\u00b7letz\u00b7te", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "PIS", "VMFIN", "ADV", "ART", "ADJA", "VAINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "Sie drangen alle drey zugleich ins Zimmer ein.", "tokens": ["Sie", "dran\u00b7gen", "al\u00b7le", "drey", "zu\u00b7gleich", "ins", "Zim\u00b7mer", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIAT", "CARD", "ADV", "APPRART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Hier sa\u00df das grosse Paar, Victoria gelassen,", "tokens": ["Hier", "sa\u00df", "das", "gros\u00b7se", "Paar", ",", "Vic\u00b7to\u00b7ria", "ge\u00b7las\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "$,", "NE", "VVPP", "$,"], "meter": "-+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.32": {"text": "Als k\u00f6nnte sie den Schimpff sich nicht zu Hertzen fassen;", "tokens": ["Als", "k\u00f6nn\u00b7te", "sie", "den", "Schimpff", "sich", "nicht", "zu", "Hert\u00b7zen", "fas\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VMFIN", "PPER", "ART", "NN", "PRF", "PTKNEG", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "Nur Gottsched schob f\u00fcr Zorn die Feder-M\u00fctze krumm,", "tokens": ["Nur", "Gott\u00b7sched", "schob", "f\u00fcr", "Zorn", "die", "Fe\u00b7der\u00b7M\u00fct\u00b7ze", "krumm", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NE", "VVFIN", "APPR", "NN", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "Er fing zu reden an, die andern blieben stumm.", "tokens": ["Er", "fing", "zu", "re\u00b7den", "an", ",", "die", "an\u00b7dern", "blie\u00b7ben", "stumm", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKZU", "VVINF", "PTKVZ", "$,", "PRELS", "PIS", "VVFIN", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "Kurtz: Er erzehlete die Neuberische Sache,", "tokens": ["Kurtz", ":", "Er", "er\u00b7zeh\u00b7le\u00b7te", "die", "Neu\u00b7be\u00b7ri\u00b7sche", "Sa\u00b7che", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$.", "PPER", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "Und fragte zum Beschlu\u00df: Ihr Freunde, welche Rache?", "tokens": ["Und", "frag\u00b7te", "zum", "Be\u00b7schlu\u00df", ":", "Ihr", "Freun\u00b7de", ",", "wel\u00b7che", "Ra\u00b7che", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPRART", "NN", "$.", "PPOSAT", "NN", "$,", "PWAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "Ihr Musen machet mir den Beyfall doch bekannt,", "tokens": ["Ihr", "Mu\u00b7sen", "ma\u00b7chet", "mir", "den", "Bey\u00b7fall", "doch", "be\u00b7kannt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "ART", "NN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.38": {"text": "Den seine Rede-Kunst in diesen Hertzen fand?", "tokens": ["Den", "sei\u00b7ne", "Re\u00b7de\u00b7Kunst", "in", "die\u00b7sen", "Hert\u00b7zen", "fand", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "APPR", "PDAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.39": {"text": "Sie nahmen alle Theil an den Beleidigungen;", "tokens": ["Sie", "nah\u00b7men", "al\u00b7le", "Theil", "an", "den", "Be\u00b7lei\u00b7di\u00b7gun\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIAT", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.40": {"text": "Und schriehn: verwegnes Weib! dir ists noch nicht gelungen.", "tokens": ["Und", "schriehn", ":", "ver\u00b7weg\u00b7nes", "Weib", "!", "dir", "ists", "noch", "nicht", "ge\u00b7lun\u00b7gen", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVINF", "$.", "ADJA", "NN", "$.", "PPER", "VAFIN", "ADV", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.41": {"text": "Corvin erbo\u00dfte sich und schrieb im Geiste schon", "tokens": ["Cor\u00b7vin", "er\u00b7bo\u00df\u00b7te", "sich", "und", "schrieb", "im", "Geis\u00b7te", "schon"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "PRF", "KON", "VVFIN", "APPRART", "NN", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.42": {"text": "Der Neuberin zum Trotz, ein Schau-Spiels-Lexicon;", "tokens": ["Der", "Neu\u00b7be\u00b7rin", "zum", "Trotz", ",", "ein", "Schau\u00b7Spiels\u00b7Le\u00b7xi\u00b7con", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "$,", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.43": {"text": "Er bath um ", "tokens": ["Er", "ba\u00b7th", "um"], "token_info": ["word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR"], "meter": "-+-+", "measure": "iambic.di"}, "line.44": {"text": "Und sie noch diese Nacht an Zotens Thorweg schlagen.", "tokens": ["Und", "sie", "noch", "die\u00b7se", "Nacht", "an", "Zo\u00b7tens", "Thor\u00b7weg", "schla\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ADV", "PDAT", "NN", "APPR", "NE", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Doch dieser Vorschlag starb, als er gebohren ward:", "tokens": ["Doch", "die\u00b7ser", "Vor\u00b7schlag", "starb", ",", "als", "er", "ge\u00b7boh\u00b7ren", "ward", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDAT", "NN", "VVFIN", "$,", "KOUS", "PPER", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Dergleichen Rache schien Victorien zu hart;", "tokens": ["Derg\u00b7lei\u00b7chen", "Ra\u00b7che", "schien", "Vic\u00b7to\u00b7ri\u00b7en", "zu", "hart", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "NN", "VVFIN", "NE", "PTKA", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Drum dachte Breitkopff noch den besten Rath zu geben,", "tokens": ["Drum", "dach\u00b7te", "Breit\u00b7kopff", "noch", "den", "bes\u00b7ten", "Rath", "zu", "ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "NE", "ADV", "ART", "ADJA", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und ruffte b\u00fcrgerlich: Mein bi\u00dfgen Witz soll leben!", "tokens": ["Und", "ruff\u00b7te", "b\u00fcr\u00b7ger\u00b7lich", ":", "Mein", "bi\u00df\u00b7gen", "Witz", "soll", "le\u00b7ben", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "$.", "PPOSAT", "ADJA", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Man klage diese Frau bey den Gerichten an,", "tokens": ["Man", "kla\u00b7ge", "die\u00b7se", "Frau", "bey", "den", "Ge\u00b7rich\u00b7ten", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PDAT", "NN", "APPR", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Damit sie schw\u00f6hren mu\u00df, ob sies zum Schimpf gethan.", "tokens": ["Da\u00b7mit", "sie", "schw\u00f6h\u00b7ren", "mu\u00df", ",", "ob", "sies", "zum", "Schimpf", "ge\u00b7than", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVINF", "VMFIN", "$,", "KOUS", "PIS", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Ein schlauer Advocat wird ihr schon Kosten machen,", "tokens": ["Ein", "schlau\u00b7er", "Ad\u00b7vo\u00b7cat", "wird", "ihr", "schon", "Kos\u00b7ten", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "PPER", "ADV", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Mit Schaden wird sie klug und wer wehrt uns zu lachen?", "tokens": ["Mit", "Scha\u00b7den", "wird", "sie", "klug", "und", "wer", "wehrt", "uns", "zu", "la\u00b7chen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VAFIN", "PPER", "ADJD", "KON", "PWS", "VVFIN", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-++--+-", "measure": "iambic.hexa.relaxed"}, "line.9": {"text": "Allein, auch dieses war der Thorheit allzu nah;", "tokens": ["Al\u00b7lein", ",", "auch", "die\u00b7ses", "war", "der", "Thor\u00b7heit", "all\u00b7zu", "nah", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "ADV", "PDS", "VAFIN", "ART", "NN", "PTKA", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Und Gottsched, ob er schon des Mannes Eifer sah,", "tokens": ["Und", "Gott\u00b7sched", ",", "ob", "er", "schon", "des", "Man\u00b7nes", "Ei\u00b7fer", "sah", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "$,", "KOUS", "PPER", "ADV", "ART", "NN", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Verwarf doch seinen Rath, und wartete was Schwabe,", "tokens": ["Ver\u00b7warf", "doch", "sei\u00b7nen", "Rath", ",", "und", "war\u00b7te\u00b7te", "was", "Schwa\u00b7be", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PPOSAT", "NN", "$,", "KON", "VVFIN", "PIS", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Der kleine Fabius, annoch zu rathen habe.", "tokens": ["Der", "klei\u00b7ne", "Fa\u00b7bi\u00b7us", ",", "an\u00b7noch", "zu", "ra\u00b7then", "ha\u00b7be", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NE", "$,", "ADV", "PTKZU", "VVINF", "VAFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Der, dessen tr\u00e4ger Witz und langsamer Verstand", "tokens": ["Der", ",", "des\u00b7sen", "tr\u00e4\u00b7ger", "Witz", "und", "lang\u00b7sa\u00b7mer", "Ver\u00b7stand"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "$,", "PRELAT", "ADJA", "NN", "KON", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Nie sonder grosse M\u00fch das was er suchte fand,", "tokens": ["Nie", "son\u00b7der", "gros\u00b7se", "M\u00fch", "das", "was", "er", "such\u00b7te", "fand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADJA", "NN", "ART", "PRELS", "PPER", "VVFIN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Stand auf, b\u00fcckt, r\u00e4uspert sich, schwieg noch betr\u00e4chtlich stille;", "tokens": ["Stand", "auf", ",", "b\u00fcckt", ",", "r\u00e4us\u00b7pert", "sich", ",", "schwieg", "noch", "be\u00b7tr\u00e4cht\u00b7lich", "stil\u00b7le", ";"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKVZ", "$,", "VVFIN", "$,", "VVFIN", "PRF", "$,", "VVFIN", "ADV", "ADJD", "VVFIN", "$."], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.16": {"text": "Doch endlich brach er lo\u00df: Dein Winck Herr ist mein Wille.", "tokens": ["Doch", "end\u00b7lich", "brach", "er", "lo\u00df", ":", "Dein", "Win\u00b7ck", "Herr", "ist", "mein", "Wil\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "PTKVZ", "$.", "PPOSAT", "NN", "NN", "VAFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.17": {"text": "\u00bbwer k\u00f6mmt Magnifice, dir wohl an Einsicht bey?", "tokens": ["\u00bb", "wer", "k\u00f6mmt", "Mag\u00b7ni\u00b7fi\u00b7ce", ",", "dir", "wohl", "an", "Ein\u00b7sicht", "bey", "?"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "VVFIN", "NE", "$,", "PPER", "ADV", "APPR", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Doch deine G\u00fctigkeit giebt mir ein Urtheil frey.", "tokens": ["Doch", "dei\u00b7ne", "G\u00fc\u00b7tig\u00b7keit", "giebt", "mir", "ein", "Ur\u00b7theil", "frey", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "PPER", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-++--+-+", "measure": "iambic.hexa.relaxed"}, "line.19": {"text": "Die That der Neuberin erschreckt die Biederm\u00e4nner,", "tokens": ["Die", "That", "der", "Neu\u00b7be\u00b7rin", "er\u00b7schreckt", "die", "Bie\u00b7der\u00b7m\u00e4n\u00b7ner", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Befremdet ungemein der reinen Sprache Kenner.", "tokens": ["Be\u00b7frem\u00b7det", "un\u00b7ge\u00b7mein", "der", "rei\u00b7nen", "Spra\u00b7che", "Ken\u00b7ner", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Durch mich den Secretar, spricht die Gesellschafft aus:", "tokens": ["Durch", "mich", "den", "Se\u00b7cre\u00b7tar", ",", "spricht", "die", "Ge\u00b7sell\u00b7schafft", "aus", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ART", "NN", "$,", "VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Verjagt die Ketzerin! Zerst\u00f6hrt ihr Schau-Spiel-Hau\u00df!", "tokens": ["Ver\u00b7jagt", "die", "Ket\u00b7ze\u00b7rin", "!", "Zer\u00b7st\u00f6hrt", "ihr", "Schau\u00b7Spiel\u00b7Hau\u00df", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$.", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Selbst gantz Germanien erstaunt bey dieser Sache;", "tokens": ["Selbst", "gantz", "Ger\u00b7ma\u00b7ni\u00b7en", "er\u00b7staunt", "bey", "die\u00b7ser", "Sa\u00b7che", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "NN", "VVFIN", "APPR", "PDAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Die deutsche Sprache schreiht nebst dem Geschmack um Rache;", "tokens": ["Die", "deut\u00b7sche", "Spra\u00b7che", "schreiht", "nebst", "dem", "Ge\u00b7schmack", "um", "Ra\u00b7che", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "APPR", "ART", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Und ausserdem so bricht der Undanck allenfalls", "tokens": ["Und", "aus\u00b7ser\u00b7dem", "so", "bricht", "der", "Un\u00b7danck", "al\u00b7len\u00b7falls"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PAV", "ADV", "VVFIN", "ART", "NN", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Der frechen Neuberin den schon verwirckten Hal\u00df.", "tokens": ["Der", "fre\u00b7chen", "Neu\u00b7be\u00b7rin", "den", "schon", "ver\u00b7wirck\u00b7ten", "Hal\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "ADV", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Wohlan, la\u00df deinen Kiel von ihren Fehlern schreiben;", "tokens": ["Wo\u00b7hlan", ",", "la\u00df", "dei\u00b7nen", "Kiel", "von", "ih\u00b7ren", "Feh\u00b7lern", "schrei\u00b7ben", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "VVIMP", "PPOSAT", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Dein Fluch wird gantz gewi\u00df an dieser Frau bekleiben:", "tokens": ["Dein", "Fluch", "wird", "gantz", "ge\u00b7wi\u00df", "an", "die\u00b7ser", "Frau", "be\u00b7klei\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADV", "ADV", "APPR", "PDAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Ein Urtheil wurtzelt ein, und gilt bey aller Welt,", "tokens": ["Ein", "Ur\u00b7theil", "wurt\u00b7zelt", "ein", ",", "und", "gilt", "bey", "al\u00b7ler", "Welt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "$,", "KON", "VVFIN", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "Das Breitkopff gr\u00fcndlich druckt und Gottsched zierlich f\u00e4llt.", "tokens": ["Das", "Breit\u00b7kopff", "gr\u00fcnd\u00b7lich", "druckt", "und", "Gott\u00b7sched", "zier\u00b7lich", "f\u00e4llt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "VVFIN", "KON", "NE", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Schreib! grosser Dichter, schreib! die stoltze Frau zu st\u00fcrzen;", "tokens": ["Schreib", "!", "gros\u00b7ser", "Dich\u00b7ter", ",", "schreib", "!", "die", "stolt\u00b7ze", "Frau", "zu", "st\u00fcr\u00b7zen", ";"], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "ADJA", "NN", "$,", "VVFIN", "$.", "ART", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Du hast ja Stoff genung, Satyren anzuw\u00fcrtzen.", "tokens": ["Du", "hast", "ja", "Stoff", "ge\u00b7nung", ",", "Sa\u00b7ty\u00b7ren", "an\u00b7zu\u00b7w\u00fcrt\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "NN", "ADV", "$,", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "Dein Ausspruch, dem die Welt bi\u00dfher ihr Lob geglaubt,", "tokens": ["Dein", "Aus\u00b7spruch", ",", "dem", "die", "Welt", "bi\u00df\u00b7her", "ihr", "Lob", "ge\u00b7glaubt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PRELS", "ART", "NN", "ADV", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "Besitzt allein die Macht, da\u00df er es wieder raubt.", "tokens": ["Be\u00b7sitzt", "al\u00b7lein", "die", "Macht", ",", "da\u00df", "er", "es", "wie\u00b7der", "raubt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "NN", "$,", "KOUS", "PPER", "PPER", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "Was ist ihr Gl\u00fcck? dein Thon; du kanst ihn f\u00f6rmlich dr\u00fccken,", "tokens": ["Was", "ist", "ihr", "Gl\u00fcck", "?", "dein", "Thon", ";", "du", "kanst", "ihn", "f\u00f6rm\u00b7lich", "dr\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPOSAT", "NN", "$.", "PPOSAT", "NN", "$.", "PPER", "VMFIN", "PPER", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "Und wieder, wenn du wilst, in einen Klumpen r\u00fccken;", "tokens": ["Und", "wie\u00b7der", ",", "wenn", "du", "wilst", ",", "in", "ei\u00b7nen", "Klum\u00b7pen", "r\u00fc\u00b7cken", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$,", "KOUS", "PPER", "VMFIN", "$,", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "Drum strafe, weil du kanst, erniedrige das Weib:", "tokens": ["Drum", "stra\u00b7fe", ",", "weil", "du", "kanst", ",", "er\u00b7nied\u00b7ri\u00b7ge", "das", "Weib", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "$,", "KOUS", "PPER", "VMFIN", "$,", "ADJA", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.38": {"text": "Was Schwabe rathen kan, ist weiter nichts als: schreib!", "tokens": ["Was", "Schwa\u00b7be", "ra\u00b7then", "kan", ",", "ist", "wei\u00b7ter", "nichts", "als", ":", "schreib", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PWS", "NN", "VVINF", "VMFIN", "$,", "VAFIN", "ADV", "PIS", "KOKOM", "$.", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.39": {"text": "Der Rath erhielt so gleich die Stimmen aller Viere;", "tokens": ["Der", "Rath", "er\u00b7hielt", "so", "gleich", "die", "Stim\u00b7men", "al\u00b7ler", "Vie\u00b7re", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "ADV", "ART", "NN", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.40": {"text": "Doch Gottsched f\u00fchlte sich zu trocken zur Satyre;", "tokens": ["Doch", "Gott\u00b7sched", "f\u00fchl\u00b7te", "sich", "zu", "tro\u00b7cken", "zur", "Sa\u00b7ty\u00b7re", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "VVFIN", "PRF", "PTKA", "ADJD", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.41": {"text": "Drum trug er Schwaben auf, mit H\u00fclffe des Corvin,", "tokens": ["Drum", "trug", "er", "Schwa\u00b7ben", "auf", ",", "mit", "H\u00fclf\u00b7fe", "des", "Cor\u00b7vin", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "NN", "PTKVZ", "$,", "APPR", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.42": {"text": "Sich f\u00fcr Victorien, statt seiner, zu bem\u00fchn.", "tokens": ["Sich", "f\u00fcr", "Vic\u00b7to\u00b7ri\u00b7en", ",", "statt", "sei\u00b7ner", ",", "zu", "be\u00b7m\u00fchn", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PRF", "APPR", "NE", "$,", "KOUI", "PPOSAT", "$,", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.43": {"text": "Seit dem wir, sprach der Mann, in schweren Aemtern sitzen,", "tokens": ["Seit", "dem", "wir", ",", "sprach", "der", "Mann", ",", "in", "schwe\u00b7ren", "A\u00b7em\u00b7tern", "sit\u00b7zen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "$,", "VVFIN", "ART", "NN", "$,", "APPR", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.44": {"text": "Nebst unsrer Professur, der Stadt, als Rector, n\u00fctzen,", "tokens": ["Nebst", "uns\u00b7rer", "Pro\u00b7fes\u00b7sur", ",", "der", "Stadt", ",", "als", "Rec\u00b7tor", ",", "n\u00fct\u00b7zen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "ART", "NN", "$,", "KOUS", "NN", "$,", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.45": {"text": "Schreibt unser Kiel nicht mehr, so fertig als er schrieb,", "tokens": ["Schreibt", "un\u00b7ser", "Kiel", "nicht", "mehr", ",", "so", "fer\u00b7tig", "als", "er", "schrieb", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "PTKNEG", "ADV", "$,", "ADV", "ADJD", "KOKOM", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.46": {"text": "Wenn ihn ein Nahmens-Fest, und ein Geburths-Tag trieb.", "tokens": ["Wenn", "ihn", "ein", "Nah\u00b7mens\u00b7Fest", ",", "und", "ein", "Ge\u00b7burths\u00b7Tag", "trieb", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "$,", "KON", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.47": {"text": "Zudem, so halten wir nicht viel vom Selbsterfinden;", "tokens": ["Zu\u00b7dem", ",", "so", "hal\u00b7ten", "wir", "nicht", "viel", "vom", "Selbs\u00b7ter\u00b7fin\u00b7den", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "$,", "ADV", "VVFIN", "PPER", "PTKNEG", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.48": {"text": "Die Kr\u00e4ntze, die wir uns als Uebersetzer winden,", "tokens": ["Die", "Kr\u00e4nt\u00b7ze", ",", "die", "wir", "uns", "als", "Ue\u00b7ber\u00b7set\u00b7zer", "win\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "PRF", "KOUS", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.49": {"text": "Sind Lorbern ohne M\u00fch. Die Welt gedenckt an mich,", "tokens": ["Sind", "Lor\u00b7bern", "oh\u00b7ne", "M\u00fch", ".", "Die", "Welt", "ge\u00b7denckt", "an", "mich", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "APPR", "NN", "$.", "ART", "NN", "VVFIN", "APPR", "PPER", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.50": {"text": "Denn meine Schriften ziert auch noch mein Kupferstich.", "tokens": ["Denn", "mei\u00b7ne", "Schrif\u00b7ten", "ziert", "auch", "noch", "mein", "Kup\u00b7fer\u00b7stich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "ADV", "ADV", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.51": {"text": "Ihr Freunde, Gottsched lebt in vielen B\u00fccher-B\u00e4nden,", "tokens": ["Ihr", "Freun\u00b7de", ",", "Gott\u00b7sched", "lebt", "in", "vie\u00b7len", "B\u00fc\u00b7cher\u00b7B\u00e4n\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "NE", "VVFIN", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.52": {"text": "Kan die Unsterblichkeit mir wohl ein Fall entwenden?", "tokens": ["Kan", "die", "U\u00b7nsterb\u00b7lich\u00b7keit", "mir", "wohl", "ein", "Fall", "ent\u00b7wen\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ART", "NN", "PPER", "ADV", "ART", "NN", "VVINF", "$."], "meter": "+-+--+-+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.53": {"text": "Der gr\u00f6ste B\u00fccher-Schatz hebt meinen Nahmen auf,", "tokens": ["Der", "gr\u00f6s\u00b7te", "B\u00fc\u00b7cher\u00b7Schatz", "hebt", "mei\u00b7nen", "Nah\u00b7men", "auf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.54": {"text": "Und Goetten", "tokens": ["Und", "Goet\u00b7ten"], "token_info": ["word", "word"], "pos": ["KON", "NN"], "meter": "-+-", "measure": "amphibrach.single"}, "line.55": {"text": "Und also war di\u00df Werck, f\u00fcr Schwabens Ruhm, beschieden?", "tokens": ["Und", "al\u00b7so", "war", "di\u00df", "Werck", ",", "f\u00fcr", "Schwa\u00b7bens", "Ruhm", ",", "be\u00b7schie\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "PDS", "NN", "$,", "APPR", "NN", "NN", "$,", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.56": {"text": "O nein, Victoria war nicht damit zufrieden.", "tokens": ["O", "nein", ",", "Vic\u00b7to\u00b7ria", "war", "nicht", "da\u00b7mit", "zu\u00b7frie\u00b7den", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PTKANT", "$,", "NE", "VAFIN", "PTKNEG", "PAV", "ADJD", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.57": {"text": "Sie fuhr gantz hitzig auf: Werd ich so schlecht geliebt,", "tokens": ["Sie", "fuhr", "gantz", "hit\u00b7zig", "auf", ":", "Werd", "ich", "so", "schlecht", "ge\u00b7liebt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADJD", "PTKVZ", "$.", "VAFIN", "PPER", "ADV", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.58": {"text": "Da\u00df der Professor sich auch nicht die M\u00fche giebt?", "tokens": ["Da\u00df", "der", "Pro\u00b7fes\u00b7sor", "sich", "auch", "nicht", "die", "M\u00fc\u00b7he", "giebt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "PRF", "ADV", "PTKNEG", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.59": {"text": "Und was entschuldigt ihn? h\u00e4lt ihn die Furcht zur\u00fccke?", "tokens": ["Und", "was", "ent\u00b7schul\u00b7digt", "ihn", "?", "h\u00e4lt", "ihn", "die", "Furcht", "zu\u00b7r\u00fc\u00b7cke", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VVFIN", "PPER", "$.", "VVFIN", "PPER", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.60": {"text": "Wie? oder fehlet es ihm etwan am Geschicke?", "tokens": ["Wie", "?", "o\u00b7der", "feh\u00b7let", "es", "ihm", "et\u00b7wan", "am", "Ge\u00b7schi\u00b7cke", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$.", "KON", "VVFIN", "PPER", "PPER", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-++--+-", "measure": "iambic.hexa.relaxed"}, "line.61": {"text": "\u00bbwohlan, ihm war ein Ku\u00df zur Danckbarkeit bestimmt;", "tokens": ["\u00bb", "wo\u00b7hlan", ",", "ihm", "war", "ein", "Ku\u00df", "zur", "Dan\u00b7ck\u00b7bar\u00b7keit", "be\u00b7stimmt", ";"], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "$,", "PPER", "VAFIN", "ART", "NN", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.62": {"text": "Solls Schwabe seyn, der ihn von meinen Lippen nimmt?", "tokens": ["Solls", "Schwa\u00b7be", "seyn", ",", "der", "ihn", "von", "mei\u00b7nen", "Lip\u00b7pen", "nimmt", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "NN", "VAINF", "$,", "PRELS", "PPER", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.63": {"text": "Du darffst, Victoria, nicht an die Rache dencken:", "tokens": ["Du", "darffst", ",", "Vic\u00b7to\u00b7ria", ",", "nicht", "an", "die", "Ra\u00b7che", "den\u00b7cken", ":"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "NE", "$,", "PTKNEG", "APPR", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.64": {"text": "Dein Liebster scheut sich selbst, die Neuberin zu kr\u00e4ncken.\u00ab", "tokens": ["Dein", "Liebs\u00b7ter", "scheut", "sich", "selbst", ",", "die", "Neu\u00b7be\u00b7rin", "zu", "kr\u00e4n\u00b7cken", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PRF", "ADV", "$,", "ART", "NN", "PTKZU", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.65": {"text": "F\u00fcr Angst fiel dem Corvin, der neue Huth in Staub;", "tokens": ["F\u00fcr", "Angst", "fiel", "dem", "Cor\u00b7vin", ",", "der", "neu\u00b7e", "Huth", "in", "Staub", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "ART", "NN", "$,", "ART", "ADJA", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.66": {"text": "Selbst Breitkopff zitterte, f\u00fcr Furcht, wie Aspenlaub;", "tokens": ["Selbst", "Breit\u00b7kopff", "zit\u00b7ter\u00b7te", ",", "f\u00fcr", "Furcht", ",", "wie", "As\u00b7pen\u00b7laub", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "NE", "VVFIN", "$,", "APPR", "NN", "$,", "PWAV", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.67": {"text": "Und Schwabe sah verwirrt, wie seine Deutschlands-Klage,", "tokens": ["Und", "Schwa\u00b7be", "sah", "ver\u00b7wirrt", ",", "wie", "sei\u00b7ne", "Deut\u00b7schlands\u00b7Kla\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "ADJD", "$,", "PWAV", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.68": {"text": "Die den Eugen beweint, den Helden unsrer Tage.", "tokens": ["Die", "den", "Eu\u00b7gen", "be\u00b7weint", ",", "den", "Hel\u00b7den", "uns\u00b7rer", "Ta\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "VVPP", "$,", "ART", "NN", "PPOSAT", "NN", "$."], "meter": "+-+--+-+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.69": {"text": "Doch Gottscheds Mund gieng auf, drum fiel das Schrecken hin;", "tokens": ["Doch", "Gott\u00b7scheds", "Mund", "gieng", "auf", ",", "drum", "fiel", "das", "Schre\u00b7cken", "hin", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "NN", "VVFIN", "PTKVZ", "$,", "PAV", "VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.70": {"text": "\u00bbich, sprach er, z\u00fcchtige nun selbst die Neuberin.", "tokens": ["\u00bb", "ich", ",", "sprach", "er", ",", "z\u00fcch\u00b7ti\u00b7ge", "nun", "selbst", "die", "Neu\u00b7be\u00b7rin", "."], "token_info": ["punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "$,", "VVFIN", "PPER", "$,", "VVFIN", "ADV", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.71": {"text": "Nur Dint und Feder her! Ihr Freunde, bi\u00df auf morgen!", "tokens": ["Nur", "Dint", "und", "Fe\u00b7der", "her", "!", "Ihr", "Freun\u00b7de", ",", "bi\u00df", "auf", "mor\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "KON", "NN", "PTKVZ", "$.", "PPOSAT", "NN", "$,", "KOUS", "APPR", "ADV", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.72": {"text": "F\u00fcr eingefeuchtt Papier wird schon mein Breitkopff sorgen.\u00ab", "tokens": ["F\u00fcr", "ein\u00b7ge\u00b7feuchtt", "Pa\u00b7pier", "wird", "schon", "mein", "Breit\u00b7kopff", "sor\u00b7gen", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "ART", "NN", "VAFIN", "ADV", "PPOSAT", "NN", "NN", "$.", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.73": {"text": "Kaum hatt er die\u00df gesagt, so sa\u00df er schon und schrieb,", "tokens": ["Kaum", "hatt", "er", "die\u00df", "ge\u00b7sagt", ",", "so", "sa\u00df", "er", "schon", "und", "schrieb", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PDS", "VVPP", "$,", "ADV", "VVFIN", "PPER", "ADV", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.74": {"text": "Und von den dreyen war nur Schwabe, welcher blieb.", "tokens": ["Und", "von", "den", "drey\u00b7en", "war", "nur", "Schwa\u00b7be", ",", "wel\u00b7cher", "blieb", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "CARD", "VAFIN", "ADV", "NN", "$,", "PRELS", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.75": {"text": "Wer Gottscheds Art nicht kennt, der mu\u00df ihn gar nicht kennen:", "tokens": ["Wer", "Gott\u00b7scheds", "Art", "nicht", "kennt", ",", "der", "mu\u00df", "ihn", "gar", "nicht", "ken\u00b7nen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NE", "NN", "PTKNEG", "VVFIN", "$,", "ART", "VMFIN", "PPER", "ADV", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.76": {"text": "Von seinem Kiel ist nie die Fruchtbarkeit zu trennen;", "tokens": ["Von", "sei\u00b7nem", "Kiel", "ist", "nie", "die", "Frucht\u00b7bar\u00b7keit", "zu", "tren\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VAFIN", "ADV", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.77": {"text": "Die Feder ist von ihm mechanisch abgerichtt:", "tokens": ["Die", "Fe\u00b7der", "ist", "von", "ihm", "me\u00b7cha\u00b7nisch", "ab\u00b7ge\u00b7richtt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "APPR", "PPER", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.78": {"text": "Offt schreibt sie von sich selbst, er aber dencket nicht.", "tokens": ["Offt", "schreibt", "sie", "von", "sich", "selbst", ",", "er", "a\u00b7ber", "den\u00b7cket", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "PRF", "ADV", "$,", "PPER", "ADV", "VVFIN", "PTKNEG", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.79": {"text": "Und hieran hat sich offt die Tadelsucht gerieben,", "tokens": ["Und", "hie\u00b7ran", "hat", "sich", "offt", "die", "Ta\u00b7del\u00b7sucht", "ge\u00b7rie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PAV", "VAFIN", "PRF", "ADV", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.80": {"text": "Doch Gottsched hat nicht Schuld; Er hat nie schlecht geschrieben.", "tokens": ["Doch", "Gott\u00b7sched", "hat", "nicht", "Schuld", ";", "Er", "hat", "nie", "schlecht", "ge\u00b7schrie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "VAFIN", "PTKNEG", "NN", "$.", "PPER", "VAFIN", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.81": {"text": "Was kann der Mann daf\u00fcr, wenn sich sein Kiel verirrt,", "tokens": ["Was", "kann", "der", "Mann", "da\u00b7f\u00fcr", ",", "wenn", "sich", "sein", "Kiel", "ver\u00b7irrt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "ART", "NN", "PAV", "$,", "KOUS", "PRF", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.82": {"text": "Und er, wie Phaeton, des Z\u00fcgels m\u00fcde wird?", "tokens": ["Und", "er", ",", "wie", "Phae\u00b7ton", ",", "des", "Z\u00fc\u00b7gels", "m\u00fc\u00b7de", "wird", "?"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "$,", "PWAV", "NE", "$,", "ART", "NN", "ADJD", "VAFIN", "$."], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.83": {"text": "Kurtz, seine Fertigkeit, blieb jetzt auch nicht zur\u00fccke,", "tokens": ["Kurtz", ",", "sei\u00b7ne", "Fer\u00b7tig\u00b7keit", ",", "blieb", "jetzt", "auch", "nicht", "zu\u00b7r\u00fc\u00b7cke", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "PPOSAT", "NN", "$,", "VVFIN", "ADV", "ADV", "PTKNEG", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.84": {"text": "Er schrieb den Bogen voll in einem Augenblicke,", "tokens": ["Er", "schrieb", "den", "Bo\u00b7gen", "voll", "in", "ei\u00b7nem", "Au\u00b7gen\u00b7bli\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADJD", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.85": {"text": "Und las ihn Schwaben vor, der darum bey ihm blieb,", "tokens": ["Und", "las", "ihn", "Schwa\u00b7ben", "vor", ",", "der", "da\u00b7rum", "bey", "ihm", "blieb", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "NN", "PTKVZ", "$,", "PRELS", "PAV", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.86": {"text": "Damit er lernete, wie schnell sein Meister schrieb.", "tokens": ["Da\u00b7mit", "er", "ler\u00b7ne\u00b7te", ",", "wie", "schnell", "sein", "Meis\u00b7ter", "schrieb", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "$,", "PWAV", "ADJD", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.87": {"text": "Es war die Stachel-Schrifft prosaisch aufgesetzet;", "tokens": ["Es", "war", "die", "Sta\u00b7chel\u00b7Schrifft", "pro\u00b7sa\u00b7isch", "auf\u00b7ge\u00b7set\u00b7zet", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.88": {"text": "Recht Wortreich, was Catull an den Suffen gesch\u00e4tzet;", "tokens": ["Recht", "Wort\u00b7reich", ",", "was", "Ca\u00b7tull", "an", "den", "Suf\u00b7fen", "ge\u00b7sch\u00e4t\u00b7zet", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "$,", "PRELS", "NE", "APPR", "ART", "NN", "VVPP", "$."], "meter": "--+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.89": {"text": "Er gab nun \u00f6ffentlich der armen Neuberinn", "tokens": ["Er", "gab", "nun", "\u00f6f\u00b7fent\u00b7lich", "der", "ar\u00b7men", "Neu\u00b7be\u00b7rinn"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "ADJD", "ART", "ADJA", "NN"], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.90": {"text": "Ged\u00e4chtni\u00df-Fehler schuld; Brodneid", "tokens": ["Ge\u00b7d\u00e4cht\u00b7ni\u00df\u00b7Feh\u00b7ler", "schuld", ";", "Bro\u00b7dne\u00b7id"], "token_info": ["word", "word", "punct", "word"], "pos": ["NN", "ADJD", "$.", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.91": {"text": "Sie ward so klein gemacht, als sie kaum gro\u00df gewesen,", "tokens": ["Sie", "ward", "so", "klein", "ge\u00b7macht", ",", "als", "sie", "kaum", "gro\u00df", "ge\u00b7we\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "VVPP", "$,", "KOUS", "PPER", "ADV", "ADJD", "VAPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.92": {"text": "Und die\u00df bekam die Welt im sch\u00f6nsten Druck zu lesen.", "tokens": ["Und", "die\u00df", "be\u00b7kam", "die", "Welt", "im", "sch\u00f6ns\u00b7ten", "Druck", "zu", "le\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VVFIN", "ART", "NN", "APPRART", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.93": {"text": "Selbst Breitkopff setzte sie in eigener Person,", "tokens": ["Selbst", "Breit\u00b7kopff", "setz\u00b7te", "sie", "in", "ei\u00b7ge\u00b7ner", "Per\u00b7son", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NE", "VVFIN", "PPER", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+--++", "measure": "iambic.hexa.relaxed"}, "line.94": {"text": "Und, als Verleger, nahm er auch kein Drucker-Lohn.", "tokens": ["Und", ",", "als", "Ver\u00b7le\u00b7ger", ",", "nahm", "er", "auch", "kein", "Dru\u00b7cke\u00b7rLohn", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "NN", "$,", "VVFIN", "PPER", "ADV", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.95": {"text": "So war der Neuberin ihr Ungl\u00fcck zubereitet;", "tokens": ["So", "war", "der", "Neu\u00b7be\u00b7rin", "ihr", "Un\u00b7gl\u00fcck", "zu\u00b7be\u00b7rei\u00b7tet", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.96": {"text": "Ihr Zeiten merckt es euch, was Gottscheds Zorn bedeutet.", "tokens": ["Ihr", "Zei\u00b7ten", "merckt", "es", "euch", ",", "was", "Gott\u00b7scheds", "Zorn", "be\u00b7deu\u00b7tet", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "PPER", "$,", "PRELS", "NE", "NE", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Kaum drang der Sonnen-Glantz in Gottscheds Schlaff-Gemach,", "tokens": ["Kaum", "drang", "der", "Son\u00b7nen\u00b7Glantz", "in", "Gott\u00b7scheds", "Schlaff\u00b7Ge\u00b7mach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPR", "NE", "NE", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Als aussen Schwabe schon mit dem Bedienten sprach;", "tokens": ["Als", "aus\u00b7sen", "Schwa\u00b7be", "schon", "mit", "dem", "Be\u00b7dien\u00b7ten", "sprach", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "NN", "ADV", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der kleine Patriot, des Meisters liebster J\u00fcnger,", "tokens": ["Der", "klei\u00b7ne", "Pat\u00b7ri\u00b7ot", ",", "des", "Meis\u00b7ters", "liebs\u00b7ter", "J\u00fcn\u00b7ger", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "In deutscher Prose flinck, im reimen nicht geringer;", "tokens": ["In", "deut\u00b7scher", "Pro\u00b7se", "flinck", ",", "im", "rei\u00b7men", "nicht", "ge\u00b7rin\u00b7ger", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "PTKVZ", "$,", "APPRART", "VVFIN", "PTKNEG", "ADJD", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Zum \u00fcbersetzen schnell, zum tadeln aufgelegt;", "tokens": ["Zum", "\u00fc\u00b7bers\u00b7et\u00b7zen", "schnell", ",", "zum", "ta\u00b7deln", "auf\u00b7ge\u00b7legt", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "ADJD", "$,", "APPRART", "VVINF", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "In dem Philippis-Geist sich noch heroisch regt.", "tokens": ["In", "dem", "Phil\u00b7ip\u00b7pis\u00b7Geist", "sich", "noch", "he\u00b7ro\u00b7isch", "reg\u00b7t."], "token_info": ["word", "word", "word", "word", "word", "word", "abbreviation"], "pos": ["APPR", "ART", "NN", "PRF", "ADV", "ADJD", "NE"], "meter": "--+--+-+--+", "measure": "anapaest.di.plus"}, "line.7": {"text": "Kein muthiger Pigm\u00e4 ist Schwaben zu vergleichen,", "tokens": ["Kein", "mut\u00b7hi\u00b7ger", "Pig\u00b7m\u00e4", "ist", "Schwa\u00b7ben", "zu", "ver\u00b7glei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "VAFIN", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.8": {"text": "Wenn f\u00fcr der Waffen Blitz die Kranche sch\u00fcchtern weichen;", "tokens": ["Wenn", "f\u00fcr", "der", "Waf\u00b7fen", "Blitz", "die", "Kran\u00b7che", "sch\u00fcch\u00b7tern", "wei\u00b7chen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "ART", "NN", "NN", "ART", "NN", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Er gieng weit kecker noch im Zimmer auf und ab,", "tokens": ["Er", "gieng", "weit", "ke\u00b7cker", "noch", "im", "Zim\u00b7mer", "auf", "und", "ab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "ADJD", "ADV", "APPRART", "NN", "PTKVZ", "KON", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Eh der Professor kam und ihm Geh\u00f6re gab.", "tokens": ["Eh", "der", "Pro\u00b7fes\u00b7sor", "kam", "und", "ihm", "Ge\u00b7h\u00f6\u00b7re", "gab", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "VVFIN", "KON", "PPER", "NN", "VVFIN", "$."], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.11": {"text": "Es ruhete di\u00dfmahl sein Meister viel zu lange,", "tokens": ["Es", "ru\u00b7he\u00b7te", "di\u00df\u00b7mahl", "sein", "Meis\u00b7ter", "viel", "zu", "lan\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PPOSAT", "NN", "ADV", "PTKA", "ADV", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Jedoch ein muntrer Kopff wei\u00df nichts vom M\u00fc\u00dfiggange;", "tokens": ["Je\u00b7doch", "ein", "mun\u00b7trer", "Kopff", "wei\u00df", "nichts", "vom", "M\u00fc\u00b7\u00dfig\u00b7gan\u00b7ge", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "VVFIN", "PIS", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Auch er verfertigte, bey der Gelegenheit,", "tokens": ["Auch", "er", "ver\u00b7fer\u00b7tig\u00b7te", ",", "bey", "der", "Ge\u00b7le\u00b7gen\u00b7heit", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VVFIN", "$,", "APPR", "ART", "NN", "$,"], "meter": "+--+--+--+-+", "measure": "dactylic.tri.plus"}, "line.14": {"text": "Den stoltzen Leber-Reim auf Gottscheds Schl\u00e4frigkeit:", "tokens": ["Den", "stolt\u00b7zen", "Le\u00b7ber\u00b7Reim", "auf", "Gott\u00b7scheds", "Schl\u00e4f\u00b7rig\u00b7keit", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "NE", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Die Leber ist vom Hecht und nicht von einem Hummer:", "tokens": ["Die", "Le\u00b7ber", "ist", "vom", "Hecht", "und", "nicht", "von", "ei\u00b7nem", "Hum\u00b7mer", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "APPRART", "NN", "KON", "PTKNEG", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Der Erde Ph\u00f6bus wacht, der meine liegt im Schlummer.", "tokens": ["Der", "Er\u00b7de", "Ph\u00f6\u00b7bus", "wacht", ",", "der", "mei\u00b7ne", "liegt", "im", "Schlum\u00b7mer", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NE", "VVFIN", "$,", "PRELS", "PPOSAT", "VVFIN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Er fuhr schon weiter fort, die Leber ist vom Hecht \u2013 \u2013,", "tokens": ["Er", "fuhr", "schon", "wei\u00b7ter", "fort", ",", "die", "Le\u00b7ber", "ist", "vom", "Hecht", "\u2013", "\u2013", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "PTKVZ", "$,", "ART", "NN", "VAFIN", "APPRART", "NN", "$(", "$(", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Doch st\u00f6hrt ihn Amarant", "tokens": ["Doch", "st\u00f6hrt", "ihn", "A\u00b7ma\u00b7rant"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "NE"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.19": {"text": "Ein Dichter aus der Zeit, die noch ein Wortspiel sch\u00e4tzte;", "tokens": ["Ein", "Dich\u00b7ter", "aus", "der", "Zeit", ",", "die", "noch", "ein", "Wort\u00b7spiel", "sch\u00e4tz\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$,", "PRELS", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Ein T\u00e4ntzer,", "tokens": ["Ein", "T\u00e4nt\u00b7zer", ","], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.21": {"text": "Der redliche Corvin trat in das Vorgemach,", "tokens": ["Der", "red\u00b7li\u00b7che", "Cor\u00b7vin", "trat", "in", "das", "Vor\u00b7ge\u00b7mach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Ihm aber folgete der Drucker Breitkopff nach.", "tokens": ["Ihm", "a\u00b7ber", "fol\u00b7ge\u00b7te", "der", "Dru\u00b7cker", "Breit\u00b7kopff", "nach", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "ART", "NN", "NE", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Was mu\u00df doch, sprach Corvin: der Herr Professor wollen?", "tokens": ["Was", "mu\u00df", "doch", ",", "sprach", "Cor\u00b7vin", ":", "der", "Herr", "Pro\u00b7fes\u00b7sor", "wol\u00b7len", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "ADV", "$,", "VVFIN", "NE", "$.", "ART", "NN", "NN", "VMFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Und das wir dreye nur, sprach Breitkopff, wissen sollen?", "tokens": ["Und", "das", "wir", "drey\u00b7e", "nur", ",", "sprach", "Breit\u00b7kopff", ",", "wis\u00b7sen", "sol\u00b7len", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ART", "PPER", "VVFIN", "ADV", "$,", "VVFIN", "NE", "$,", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Ein ieder rieth; allein, ob es errathen war,", "tokens": ["Ein", "ie\u00b7der", "rieth", ";", "al\u00b7lein", ",", "ob", "es", "er\u00b7ra\u00b7then", "war", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VVFIN", "$.", "ADV", "$,", "KOUS", "PPER", "VVINF", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "War durch des Schicksahls Schlu\u00df noch keinem offenbahr.", "tokens": ["War", "durch", "des", "Schick\u00b7sahls", "Schlu\u00df", "noch", "kei\u00b7nem", "of\u00b7fen\u00b7bahr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "ART", "NN", "NN", "ADV", "PIS", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Doch endlich mu\u00dfte sich die Ungeduld verliehren:", "tokens": ["Doch", "end\u00b7lich", "mu\u00df\u00b7te", "sich", "die", "Un\u00b7ge\u00b7duld", "ver\u00b7lieh\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VMFIN", "PRF", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Der Diener \u00f6ffnete die beyden Stuben-Th\u00fcren.", "tokens": ["Der", "Die\u00b7ner", "\u00f6ff\u00b7ne\u00b7te", "die", "bey\u00b7den", "Stu\u00b7ben\u00b7T\u00b7h\u00fc\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Nicht einer wollte hier der allerletzte seyn,", "tokens": ["Nicht", "ei\u00b7ner", "woll\u00b7te", "hier", "der", "al\u00b7ler\u00b7letz\u00b7te", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "PIS", "VMFIN", "ADV", "ART", "ADJA", "VAINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "Sie drangen alle drey zugleich ins Zimmer ein.", "tokens": ["Sie", "dran\u00b7gen", "al\u00b7le", "drey", "zu\u00b7gleich", "ins", "Zim\u00b7mer", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIAT", "CARD", "ADV", "APPRART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Hier sa\u00df das grosse Paar, Victoria gelassen,", "tokens": ["Hier", "sa\u00df", "das", "gros\u00b7se", "Paar", ",", "Vic\u00b7to\u00b7ria", "ge\u00b7las\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "$,", "NE", "VVPP", "$,"], "meter": "-+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.32": {"text": "Als k\u00f6nnte sie den Schimpff sich nicht zu Hertzen fassen;", "tokens": ["Als", "k\u00f6nn\u00b7te", "sie", "den", "Schimpff", "sich", "nicht", "zu", "Hert\u00b7zen", "fas\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VMFIN", "PPER", "ART", "NN", "PRF", "PTKNEG", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "Nur Gottsched schob f\u00fcr Zorn die Feder-M\u00fctze krumm,", "tokens": ["Nur", "Gott\u00b7sched", "schob", "f\u00fcr", "Zorn", "die", "Fe\u00b7der\u00b7M\u00fct\u00b7ze", "krumm", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NE", "VVFIN", "APPR", "NN", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "Er fing zu reden an, die andern blieben stumm.", "tokens": ["Er", "fing", "zu", "re\u00b7den", "an", ",", "die", "an\u00b7dern", "blie\u00b7ben", "stumm", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKZU", "VVINF", "PTKVZ", "$,", "PRELS", "PIS", "VVFIN", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "Kurtz: Er erzehlete die Neuberische Sache,", "tokens": ["Kurtz", ":", "Er", "er\u00b7zeh\u00b7le\u00b7te", "die", "Neu\u00b7be\u00b7ri\u00b7sche", "Sa\u00b7che", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$.", "PPER", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "Und fragte zum Beschlu\u00df: Ihr Freunde, welche Rache?", "tokens": ["Und", "frag\u00b7te", "zum", "Be\u00b7schlu\u00df", ":", "Ihr", "Freun\u00b7de", ",", "wel\u00b7che", "Ra\u00b7che", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPRART", "NN", "$.", "PPOSAT", "NN", "$,", "PWAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "Ihr Musen machet mir den Beyfall doch bekannt,", "tokens": ["Ihr", "Mu\u00b7sen", "ma\u00b7chet", "mir", "den", "Bey\u00b7fall", "doch", "be\u00b7kannt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "ART", "NN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.38": {"text": "Den seine Rede-Kunst in diesen Hertzen fand?", "tokens": ["Den", "sei\u00b7ne", "Re\u00b7de\u00b7Kunst", "in", "die\u00b7sen", "Hert\u00b7zen", "fand", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "APPR", "PDAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.39": {"text": "Sie nahmen alle Theil an den Beleidigungen;", "tokens": ["Sie", "nah\u00b7men", "al\u00b7le", "Theil", "an", "den", "Be\u00b7lei\u00b7di\u00b7gun\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIAT", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.40": {"text": "Und schriehn: verwegnes Weib! dir ists noch nicht gelungen.", "tokens": ["Und", "schriehn", ":", "ver\u00b7weg\u00b7nes", "Weib", "!", "dir", "ists", "noch", "nicht", "ge\u00b7lun\u00b7gen", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVINF", "$.", "ADJA", "NN", "$.", "PPER", "VAFIN", "ADV", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.41": {"text": "Corvin erbo\u00dfte sich und schrieb im Geiste schon", "tokens": ["Cor\u00b7vin", "er\u00b7bo\u00df\u00b7te", "sich", "und", "schrieb", "im", "Geis\u00b7te", "schon"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "PRF", "KON", "VVFIN", "APPRART", "NN", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.42": {"text": "Der Neuberin zum Trotz, ein Schau-Spiels-Lexicon;", "tokens": ["Der", "Neu\u00b7be\u00b7rin", "zum", "Trotz", ",", "ein", "Schau\u00b7Spiels\u00b7Le\u00b7xi\u00b7con", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "$,", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.43": {"text": "Er bath um ", "tokens": ["Er", "ba\u00b7th", "um"], "token_info": ["word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR"], "meter": "-+-+", "measure": "iambic.di"}, "line.44": {"text": "Und sie noch diese Nacht an Zotens Thorweg schlagen.", "tokens": ["Und", "sie", "noch", "die\u00b7se", "Nacht", "an", "Zo\u00b7tens", "Thor\u00b7weg", "schla\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ADV", "PDAT", "NN", "APPR", "NE", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Doch dieser Vorschlag starb, als er gebohren ward:", "tokens": ["Doch", "die\u00b7ser", "Vor\u00b7schlag", "starb", ",", "als", "er", "ge\u00b7boh\u00b7ren", "ward", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDAT", "NN", "VVFIN", "$,", "KOUS", "PPER", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Dergleichen Rache schien Victorien zu hart;", "tokens": ["Derg\u00b7lei\u00b7chen", "Ra\u00b7che", "schien", "Vic\u00b7to\u00b7ri\u00b7en", "zu", "hart", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "NN", "VVFIN", "NE", "PTKA", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Drum dachte Breitkopff noch den besten Rath zu geben,", "tokens": ["Drum", "dach\u00b7te", "Breit\u00b7kopff", "noch", "den", "bes\u00b7ten", "Rath", "zu", "ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "NE", "ADV", "ART", "ADJA", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und ruffte b\u00fcrgerlich: Mein bi\u00dfgen Witz soll leben!", "tokens": ["Und", "ruff\u00b7te", "b\u00fcr\u00b7ger\u00b7lich", ":", "Mein", "bi\u00df\u00b7gen", "Witz", "soll", "le\u00b7ben", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "$.", "PPOSAT", "ADJA", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Man klage diese Frau bey den Gerichten an,", "tokens": ["Man", "kla\u00b7ge", "die\u00b7se", "Frau", "bey", "den", "Ge\u00b7rich\u00b7ten", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PDAT", "NN", "APPR", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Damit sie schw\u00f6hren mu\u00df, ob sies zum Schimpf gethan.", "tokens": ["Da\u00b7mit", "sie", "schw\u00f6h\u00b7ren", "mu\u00df", ",", "ob", "sies", "zum", "Schimpf", "ge\u00b7than", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVINF", "VMFIN", "$,", "KOUS", "PIS", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Ein schlauer Advocat wird ihr schon Kosten machen,", "tokens": ["Ein", "schlau\u00b7er", "Ad\u00b7vo\u00b7cat", "wird", "ihr", "schon", "Kos\u00b7ten", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "PPER", "ADV", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Mit Schaden wird sie klug und wer wehrt uns zu lachen?", "tokens": ["Mit", "Scha\u00b7den", "wird", "sie", "klug", "und", "wer", "wehrt", "uns", "zu", "la\u00b7chen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VAFIN", "PPER", "ADJD", "KON", "PWS", "VVFIN", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-++--+-", "measure": "iambic.hexa.relaxed"}, "line.9": {"text": "Allein, auch dieses war der Thorheit allzu nah;", "tokens": ["Al\u00b7lein", ",", "auch", "die\u00b7ses", "war", "der", "Thor\u00b7heit", "all\u00b7zu", "nah", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "ADV", "PDS", "VAFIN", "ART", "NN", "PTKA", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Und Gottsched, ob er schon des Mannes Eifer sah,", "tokens": ["Und", "Gott\u00b7sched", ",", "ob", "er", "schon", "des", "Man\u00b7nes", "Ei\u00b7fer", "sah", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "$,", "KOUS", "PPER", "ADV", "ART", "NN", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Verwarf doch seinen Rath, und wartete was Schwabe,", "tokens": ["Ver\u00b7warf", "doch", "sei\u00b7nen", "Rath", ",", "und", "war\u00b7te\u00b7te", "was", "Schwa\u00b7be", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PPOSAT", "NN", "$,", "KON", "VVFIN", "PIS", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Der kleine Fabius, annoch zu rathen habe.", "tokens": ["Der", "klei\u00b7ne", "Fa\u00b7bi\u00b7us", ",", "an\u00b7noch", "zu", "ra\u00b7then", "ha\u00b7be", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NE", "$,", "ADV", "PTKZU", "VVINF", "VAFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Der, dessen tr\u00e4ger Witz und langsamer Verstand", "tokens": ["Der", ",", "des\u00b7sen", "tr\u00e4\u00b7ger", "Witz", "und", "lang\u00b7sa\u00b7mer", "Ver\u00b7stand"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "$,", "PRELAT", "ADJA", "NN", "KON", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Nie sonder grosse M\u00fch das was er suchte fand,", "tokens": ["Nie", "son\u00b7der", "gros\u00b7se", "M\u00fch", "das", "was", "er", "such\u00b7te", "fand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADJA", "NN", "ART", "PRELS", "PPER", "VVFIN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Stand auf, b\u00fcckt, r\u00e4uspert sich, schwieg noch betr\u00e4chtlich stille;", "tokens": ["Stand", "auf", ",", "b\u00fcckt", ",", "r\u00e4us\u00b7pert", "sich", ",", "schwieg", "noch", "be\u00b7tr\u00e4cht\u00b7lich", "stil\u00b7le", ";"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKVZ", "$,", "VVFIN", "$,", "VVFIN", "PRF", "$,", "VVFIN", "ADV", "ADJD", "VVFIN", "$."], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.16": {"text": "Doch endlich brach er lo\u00df: Dein Winck Herr ist mein Wille.", "tokens": ["Doch", "end\u00b7lich", "brach", "er", "lo\u00df", ":", "Dein", "Win\u00b7ck", "Herr", "ist", "mein", "Wil\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "PTKVZ", "$.", "PPOSAT", "NN", "NN", "VAFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.17": {"text": "\u00bbwer k\u00f6mmt Magnifice, dir wohl an Einsicht bey?", "tokens": ["\u00bb", "wer", "k\u00f6mmt", "Mag\u00b7ni\u00b7fi\u00b7ce", ",", "dir", "wohl", "an", "Ein\u00b7sicht", "bey", "?"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "VVFIN", "NE", "$,", "PPER", "ADV", "APPR", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Doch deine G\u00fctigkeit giebt mir ein Urtheil frey.", "tokens": ["Doch", "dei\u00b7ne", "G\u00fc\u00b7tig\u00b7keit", "giebt", "mir", "ein", "Ur\u00b7theil", "frey", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "PPER", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-++--+-+", "measure": "iambic.hexa.relaxed"}, "line.19": {"text": "Die That der Neuberin erschreckt die Biederm\u00e4nner,", "tokens": ["Die", "That", "der", "Neu\u00b7be\u00b7rin", "er\u00b7schreckt", "die", "Bie\u00b7der\u00b7m\u00e4n\u00b7ner", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Befremdet ungemein der reinen Sprache Kenner.", "tokens": ["Be\u00b7frem\u00b7det", "un\u00b7ge\u00b7mein", "der", "rei\u00b7nen", "Spra\u00b7che", "Ken\u00b7ner", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Durch mich den Secretar, spricht die Gesellschafft aus:", "tokens": ["Durch", "mich", "den", "Se\u00b7cre\u00b7tar", ",", "spricht", "die", "Ge\u00b7sell\u00b7schafft", "aus", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ART", "NN", "$,", "VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Verjagt die Ketzerin! Zerst\u00f6hrt ihr Schau-Spiel-Hau\u00df!", "tokens": ["Ver\u00b7jagt", "die", "Ket\u00b7ze\u00b7rin", "!", "Zer\u00b7st\u00f6hrt", "ihr", "Schau\u00b7Spiel\u00b7Hau\u00df", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$.", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Selbst gantz Germanien erstaunt bey dieser Sache;", "tokens": ["Selbst", "gantz", "Ger\u00b7ma\u00b7ni\u00b7en", "er\u00b7staunt", "bey", "die\u00b7ser", "Sa\u00b7che", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "NN", "VVFIN", "APPR", "PDAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Die deutsche Sprache schreiht nebst dem Geschmack um Rache;", "tokens": ["Die", "deut\u00b7sche", "Spra\u00b7che", "schreiht", "nebst", "dem", "Ge\u00b7schmack", "um", "Ra\u00b7che", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "APPR", "ART", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Und ausserdem so bricht der Undanck allenfalls", "tokens": ["Und", "aus\u00b7ser\u00b7dem", "so", "bricht", "der", "Un\u00b7danck", "al\u00b7len\u00b7falls"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PAV", "ADV", "VVFIN", "ART", "NN", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Der frechen Neuberin den schon verwirckten Hal\u00df.", "tokens": ["Der", "fre\u00b7chen", "Neu\u00b7be\u00b7rin", "den", "schon", "ver\u00b7wirck\u00b7ten", "Hal\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "ADV", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Wohlan, la\u00df deinen Kiel von ihren Fehlern schreiben;", "tokens": ["Wo\u00b7hlan", ",", "la\u00df", "dei\u00b7nen", "Kiel", "von", "ih\u00b7ren", "Feh\u00b7lern", "schrei\u00b7ben", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "VVIMP", "PPOSAT", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Dein Fluch wird gantz gewi\u00df an dieser Frau bekleiben:", "tokens": ["Dein", "Fluch", "wird", "gantz", "ge\u00b7wi\u00df", "an", "die\u00b7ser", "Frau", "be\u00b7klei\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADV", "ADV", "APPR", "PDAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Ein Urtheil wurtzelt ein, und gilt bey aller Welt,", "tokens": ["Ein", "Ur\u00b7theil", "wurt\u00b7zelt", "ein", ",", "und", "gilt", "bey", "al\u00b7ler", "Welt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "$,", "KON", "VVFIN", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "Das Breitkopff gr\u00fcndlich druckt und Gottsched zierlich f\u00e4llt.", "tokens": ["Das", "Breit\u00b7kopff", "gr\u00fcnd\u00b7lich", "druckt", "und", "Gott\u00b7sched", "zier\u00b7lich", "f\u00e4llt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "VVFIN", "KON", "NE", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Schreib! grosser Dichter, schreib! die stoltze Frau zu st\u00fcrzen;", "tokens": ["Schreib", "!", "gros\u00b7ser", "Dich\u00b7ter", ",", "schreib", "!", "die", "stolt\u00b7ze", "Frau", "zu", "st\u00fcr\u00b7zen", ";"], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "ADJA", "NN", "$,", "VVFIN", "$.", "ART", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Du hast ja Stoff genung, Satyren anzuw\u00fcrtzen.", "tokens": ["Du", "hast", "ja", "Stoff", "ge\u00b7nung", ",", "Sa\u00b7ty\u00b7ren", "an\u00b7zu\u00b7w\u00fcrt\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "NN", "ADV", "$,", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "Dein Ausspruch, dem die Welt bi\u00dfher ihr Lob geglaubt,", "tokens": ["Dein", "Aus\u00b7spruch", ",", "dem", "die", "Welt", "bi\u00df\u00b7her", "ihr", "Lob", "ge\u00b7glaubt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PRELS", "ART", "NN", "ADV", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "Besitzt allein die Macht, da\u00df er es wieder raubt.", "tokens": ["Be\u00b7sitzt", "al\u00b7lein", "die", "Macht", ",", "da\u00df", "er", "es", "wie\u00b7der", "raubt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "NN", "$,", "KOUS", "PPER", "PPER", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "Was ist ihr Gl\u00fcck? dein Thon; du kanst ihn f\u00f6rmlich dr\u00fccken,", "tokens": ["Was", "ist", "ihr", "Gl\u00fcck", "?", "dein", "Thon", ";", "du", "kanst", "ihn", "f\u00f6rm\u00b7lich", "dr\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPOSAT", "NN", "$.", "PPOSAT", "NN", "$.", "PPER", "VMFIN", "PPER", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "Und wieder, wenn du wilst, in einen Klumpen r\u00fccken;", "tokens": ["Und", "wie\u00b7der", ",", "wenn", "du", "wilst", ",", "in", "ei\u00b7nen", "Klum\u00b7pen", "r\u00fc\u00b7cken", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$,", "KOUS", "PPER", "VMFIN", "$,", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "Drum strafe, weil du kanst, erniedrige das Weib:", "tokens": ["Drum", "stra\u00b7fe", ",", "weil", "du", "kanst", ",", "er\u00b7nied\u00b7ri\u00b7ge", "das", "Weib", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "$,", "KOUS", "PPER", "VMFIN", "$,", "ADJA", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.38": {"text": "Was Schwabe rathen kan, ist weiter nichts als: schreib!", "tokens": ["Was", "Schwa\u00b7be", "ra\u00b7then", "kan", ",", "ist", "wei\u00b7ter", "nichts", "als", ":", "schreib", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PWS", "NN", "VVINF", "VMFIN", "$,", "VAFIN", "ADV", "PIS", "KOKOM", "$.", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.39": {"text": "Der Rath erhielt so gleich die Stimmen aller Viere;", "tokens": ["Der", "Rath", "er\u00b7hielt", "so", "gleich", "die", "Stim\u00b7men", "al\u00b7ler", "Vie\u00b7re", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "ADV", "ART", "NN", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.40": {"text": "Doch Gottsched f\u00fchlte sich zu trocken zur Satyre;", "tokens": ["Doch", "Gott\u00b7sched", "f\u00fchl\u00b7te", "sich", "zu", "tro\u00b7cken", "zur", "Sa\u00b7ty\u00b7re", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "VVFIN", "PRF", "PTKA", "ADJD", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.41": {"text": "Drum trug er Schwaben auf, mit H\u00fclffe des Corvin,", "tokens": ["Drum", "trug", "er", "Schwa\u00b7ben", "auf", ",", "mit", "H\u00fclf\u00b7fe", "des", "Cor\u00b7vin", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "NN", "PTKVZ", "$,", "APPR", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.42": {"text": "Sich f\u00fcr Victorien, statt seiner, zu bem\u00fchn.", "tokens": ["Sich", "f\u00fcr", "Vic\u00b7to\u00b7ri\u00b7en", ",", "statt", "sei\u00b7ner", ",", "zu", "be\u00b7m\u00fchn", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PRF", "APPR", "NE", "$,", "KOUI", "PPOSAT", "$,", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.43": {"text": "Seit dem wir, sprach der Mann, in schweren Aemtern sitzen,", "tokens": ["Seit", "dem", "wir", ",", "sprach", "der", "Mann", ",", "in", "schwe\u00b7ren", "A\u00b7em\u00b7tern", "sit\u00b7zen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "$,", "VVFIN", "ART", "NN", "$,", "APPR", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.44": {"text": "Nebst unsrer Professur, der Stadt, als Rector, n\u00fctzen,", "tokens": ["Nebst", "uns\u00b7rer", "Pro\u00b7fes\u00b7sur", ",", "der", "Stadt", ",", "als", "Rec\u00b7tor", ",", "n\u00fct\u00b7zen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "ART", "NN", "$,", "KOUS", "NN", "$,", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.45": {"text": "Schreibt unser Kiel nicht mehr, so fertig als er schrieb,", "tokens": ["Schreibt", "un\u00b7ser", "Kiel", "nicht", "mehr", ",", "so", "fer\u00b7tig", "als", "er", "schrieb", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "PTKNEG", "ADV", "$,", "ADV", "ADJD", "KOKOM", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.46": {"text": "Wenn ihn ein Nahmens-Fest, und ein Geburths-Tag trieb.", "tokens": ["Wenn", "ihn", "ein", "Nah\u00b7mens\u00b7Fest", ",", "und", "ein", "Ge\u00b7burths\u00b7Tag", "trieb", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "$,", "KON", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.47": {"text": "Zudem, so halten wir nicht viel vom Selbsterfinden;", "tokens": ["Zu\u00b7dem", ",", "so", "hal\u00b7ten", "wir", "nicht", "viel", "vom", "Selbs\u00b7ter\u00b7fin\u00b7den", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "$,", "ADV", "VVFIN", "PPER", "PTKNEG", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.48": {"text": "Die Kr\u00e4ntze, die wir uns als Uebersetzer winden,", "tokens": ["Die", "Kr\u00e4nt\u00b7ze", ",", "die", "wir", "uns", "als", "Ue\u00b7ber\u00b7set\u00b7zer", "win\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "PRF", "KOUS", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.49": {"text": "Sind Lorbern ohne M\u00fch. Die Welt gedenckt an mich,", "tokens": ["Sind", "Lor\u00b7bern", "oh\u00b7ne", "M\u00fch", ".", "Die", "Welt", "ge\u00b7denckt", "an", "mich", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "APPR", "NN", "$.", "ART", "NN", "VVFIN", "APPR", "PPER", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.50": {"text": "Denn meine Schriften ziert auch noch mein Kupferstich.", "tokens": ["Denn", "mei\u00b7ne", "Schrif\u00b7ten", "ziert", "auch", "noch", "mein", "Kup\u00b7fer\u00b7stich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "ADV", "ADV", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.51": {"text": "Ihr Freunde, Gottsched lebt in vielen B\u00fccher-B\u00e4nden,", "tokens": ["Ihr", "Freun\u00b7de", ",", "Gott\u00b7sched", "lebt", "in", "vie\u00b7len", "B\u00fc\u00b7cher\u00b7B\u00e4n\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "NE", "VVFIN", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.52": {"text": "Kan die Unsterblichkeit mir wohl ein Fall entwenden?", "tokens": ["Kan", "die", "U\u00b7nsterb\u00b7lich\u00b7keit", "mir", "wohl", "ein", "Fall", "ent\u00b7wen\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ART", "NN", "PPER", "ADV", "ART", "NN", "VVINF", "$."], "meter": "+-+--+-+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.53": {"text": "Der gr\u00f6ste B\u00fccher-Schatz hebt meinen Nahmen auf,", "tokens": ["Der", "gr\u00f6s\u00b7te", "B\u00fc\u00b7cher\u00b7Schatz", "hebt", "mei\u00b7nen", "Nah\u00b7men", "auf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.54": {"text": "Und Goetten", "tokens": ["Und", "Goet\u00b7ten"], "token_info": ["word", "word"], "pos": ["KON", "NN"], "meter": "-+-", "measure": "amphibrach.single"}, "line.55": {"text": "Und also war di\u00df Werck, f\u00fcr Schwabens Ruhm, beschieden?", "tokens": ["Und", "al\u00b7so", "war", "di\u00df", "Werck", ",", "f\u00fcr", "Schwa\u00b7bens", "Ruhm", ",", "be\u00b7schie\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "PDS", "NN", "$,", "APPR", "NN", "NN", "$,", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.56": {"text": "O nein, Victoria war nicht damit zufrieden.", "tokens": ["O", "nein", ",", "Vic\u00b7to\u00b7ria", "war", "nicht", "da\u00b7mit", "zu\u00b7frie\u00b7den", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PTKANT", "$,", "NE", "VAFIN", "PTKNEG", "PAV", "ADJD", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.57": {"text": "Sie fuhr gantz hitzig auf: Werd ich so schlecht geliebt,", "tokens": ["Sie", "fuhr", "gantz", "hit\u00b7zig", "auf", ":", "Werd", "ich", "so", "schlecht", "ge\u00b7liebt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADJD", "PTKVZ", "$.", "VAFIN", "PPER", "ADV", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.58": {"text": "Da\u00df der Professor sich auch nicht die M\u00fche giebt?", "tokens": ["Da\u00df", "der", "Pro\u00b7fes\u00b7sor", "sich", "auch", "nicht", "die", "M\u00fc\u00b7he", "giebt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "PRF", "ADV", "PTKNEG", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.59": {"text": "Und was entschuldigt ihn? h\u00e4lt ihn die Furcht zur\u00fccke?", "tokens": ["Und", "was", "ent\u00b7schul\u00b7digt", "ihn", "?", "h\u00e4lt", "ihn", "die", "Furcht", "zu\u00b7r\u00fc\u00b7cke", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VVFIN", "PPER", "$.", "VVFIN", "PPER", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.60": {"text": "Wie? oder fehlet es ihm etwan am Geschicke?", "tokens": ["Wie", "?", "o\u00b7der", "feh\u00b7let", "es", "ihm", "et\u00b7wan", "am", "Ge\u00b7schi\u00b7cke", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$.", "KON", "VVFIN", "PPER", "PPER", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-++--+-", "measure": "iambic.hexa.relaxed"}, "line.61": {"text": "\u00bbwohlan, ihm war ein Ku\u00df zur Danckbarkeit bestimmt;", "tokens": ["\u00bb", "wo\u00b7hlan", ",", "ihm", "war", "ein", "Ku\u00df", "zur", "Dan\u00b7ck\u00b7bar\u00b7keit", "be\u00b7stimmt", ";"], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "$,", "PPER", "VAFIN", "ART", "NN", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.62": {"text": "Solls Schwabe seyn, der ihn von meinen Lippen nimmt?", "tokens": ["Solls", "Schwa\u00b7be", "seyn", ",", "der", "ihn", "von", "mei\u00b7nen", "Lip\u00b7pen", "nimmt", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "NN", "VAINF", "$,", "PRELS", "PPER", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.63": {"text": "Du darffst, Victoria, nicht an die Rache dencken:", "tokens": ["Du", "darffst", ",", "Vic\u00b7to\u00b7ria", ",", "nicht", "an", "die", "Ra\u00b7che", "den\u00b7cken", ":"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "NE", "$,", "PTKNEG", "APPR", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.64": {"text": "Dein Liebster scheut sich selbst, die Neuberin zu kr\u00e4ncken.\u00ab", "tokens": ["Dein", "Liebs\u00b7ter", "scheut", "sich", "selbst", ",", "die", "Neu\u00b7be\u00b7rin", "zu", "kr\u00e4n\u00b7cken", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PRF", "ADV", "$,", "ART", "NN", "PTKZU", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.65": {"text": "F\u00fcr Angst fiel dem Corvin, der neue Huth in Staub;", "tokens": ["F\u00fcr", "Angst", "fiel", "dem", "Cor\u00b7vin", ",", "der", "neu\u00b7e", "Huth", "in", "Staub", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "ART", "NN", "$,", "ART", "ADJA", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.66": {"text": "Selbst Breitkopff zitterte, f\u00fcr Furcht, wie Aspenlaub;", "tokens": ["Selbst", "Breit\u00b7kopff", "zit\u00b7ter\u00b7te", ",", "f\u00fcr", "Furcht", ",", "wie", "As\u00b7pen\u00b7laub", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "NE", "VVFIN", "$,", "APPR", "NN", "$,", "PWAV", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.67": {"text": "Und Schwabe sah verwirrt, wie seine Deutschlands-Klage,", "tokens": ["Und", "Schwa\u00b7be", "sah", "ver\u00b7wirrt", ",", "wie", "sei\u00b7ne", "Deut\u00b7schlands\u00b7Kla\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "ADJD", "$,", "PWAV", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.68": {"text": "Die den Eugen beweint, den Helden unsrer Tage.", "tokens": ["Die", "den", "Eu\u00b7gen", "be\u00b7weint", ",", "den", "Hel\u00b7den", "uns\u00b7rer", "Ta\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "VVPP", "$,", "ART", "NN", "PPOSAT", "NN", "$."], "meter": "+-+--+-+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.69": {"text": "Doch Gottscheds Mund gieng auf, drum fiel das Schrecken hin;", "tokens": ["Doch", "Gott\u00b7scheds", "Mund", "gieng", "auf", ",", "drum", "fiel", "das", "Schre\u00b7cken", "hin", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "NN", "VVFIN", "PTKVZ", "$,", "PAV", "VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.70": {"text": "\u00bbich, sprach er, z\u00fcchtige nun selbst die Neuberin.", "tokens": ["\u00bb", "ich", ",", "sprach", "er", ",", "z\u00fcch\u00b7ti\u00b7ge", "nun", "selbst", "die", "Neu\u00b7be\u00b7rin", "."], "token_info": ["punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "$,", "VVFIN", "PPER", "$,", "VVFIN", "ADV", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.71": {"text": "Nur Dint und Feder her! Ihr Freunde, bi\u00df auf morgen!", "tokens": ["Nur", "Dint", "und", "Fe\u00b7der", "her", "!", "Ihr", "Freun\u00b7de", ",", "bi\u00df", "auf", "mor\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "KON", "NN", "PTKVZ", "$.", "PPOSAT", "NN", "$,", "KOUS", "APPR", "ADV", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.72": {"text": "F\u00fcr eingefeuchtt Papier wird schon mein Breitkopff sorgen.\u00ab", "tokens": ["F\u00fcr", "ein\u00b7ge\u00b7feuchtt", "Pa\u00b7pier", "wird", "schon", "mein", "Breit\u00b7kopff", "sor\u00b7gen", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "ART", "NN", "VAFIN", "ADV", "PPOSAT", "NN", "NN", "$.", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.73": {"text": "Kaum hatt er die\u00df gesagt, so sa\u00df er schon und schrieb,", "tokens": ["Kaum", "hatt", "er", "die\u00df", "ge\u00b7sagt", ",", "so", "sa\u00df", "er", "schon", "und", "schrieb", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PDS", "VVPP", "$,", "ADV", "VVFIN", "PPER", "ADV", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.74": {"text": "Und von den dreyen war nur Schwabe, welcher blieb.", "tokens": ["Und", "von", "den", "drey\u00b7en", "war", "nur", "Schwa\u00b7be", ",", "wel\u00b7cher", "blieb", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "CARD", "VAFIN", "ADV", "NN", "$,", "PRELS", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.75": {"text": "Wer Gottscheds Art nicht kennt, der mu\u00df ihn gar nicht kennen:", "tokens": ["Wer", "Gott\u00b7scheds", "Art", "nicht", "kennt", ",", "der", "mu\u00df", "ihn", "gar", "nicht", "ken\u00b7nen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NE", "NN", "PTKNEG", "VVFIN", "$,", "ART", "VMFIN", "PPER", "ADV", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.76": {"text": "Von seinem Kiel ist nie die Fruchtbarkeit zu trennen;", "tokens": ["Von", "sei\u00b7nem", "Kiel", "ist", "nie", "die", "Frucht\u00b7bar\u00b7keit", "zu", "tren\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VAFIN", "ADV", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.77": {"text": "Die Feder ist von ihm mechanisch abgerichtt:", "tokens": ["Die", "Fe\u00b7der", "ist", "von", "ihm", "me\u00b7cha\u00b7nisch", "ab\u00b7ge\u00b7richtt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "APPR", "PPER", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.78": {"text": "Offt schreibt sie von sich selbst, er aber dencket nicht.", "tokens": ["Offt", "schreibt", "sie", "von", "sich", "selbst", ",", "er", "a\u00b7ber", "den\u00b7cket", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "PRF", "ADV", "$,", "PPER", "ADV", "VVFIN", "PTKNEG", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.79": {"text": "Und hieran hat sich offt die Tadelsucht gerieben,", "tokens": ["Und", "hie\u00b7ran", "hat", "sich", "offt", "die", "Ta\u00b7del\u00b7sucht", "ge\u00b7rie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PAV", "VAFIN", "PRF", "ADV", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.80": {"text": "Doch Gottsched hat nicht Schuld; Er hat nie schlecht geschrieben.", "tokens": ["Doch", "Gott\u00b7sched", "hat", "nicht", "Schuld", ";", "Er", "hat", "nie", "schlecht", "ge\u00b7schrie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "VAFIN", "PTKNEG", "NN", "$.", "PPER", "VAFIN", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.81": {"text": "Was kann der Mann daf\u00fcr, wenn sich sein Kiel verirrt,", "tokens": ["Was", "kann", "der", "Mann", "da\u00b7f\u00fcr", ",", "wenn", "sich", "sein", "Kiel", "ver\u00b7irrt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "ART", "NN", "PAV", "$,", "KOUS", "PRF", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.82": {"text": "Und er, wie Phaeton, des Z\u00fcgels m\u00fcde wird?", "tokens": ["Und", "er", ",", "wie", "Phae\u00b7ton", ",", "des", "Z\u00fc\u00b7gels", "m\u00fc\u00b7de", "wird", "?"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "$,", "PWAV", "NE", "$,", "ART", "NN", "ADJD", "VAFIN", "$."], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.83": {"text": "Kurtz, seine Fertigkeit, blieb jetzt auch nicht zur\u00fccke,", "tokens": ["Kurtz", ",", "sei\u00b7ne", "Fer\u00b7tig\u00b7keit", ",", "blieb", "jetzt", "auch", "nicht", "zu\u00b7r\u00fc\u00b7cke", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "PPOSAT", "NN", "$,", "VVFIN", "ADV", "ADV", "PTKNEG", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.84": {"text": "Er schrieb den Bogen voll in einem Augenblicke,", "tokens": ["Er", "schrieb", "den", "Bo\u00b7gen", "voll", "in", "ei\u00b7nem", "Au\u00b7gen\u00b7bli\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADJD", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.85": {"text": "Und las ihn Schwaben vor, der darum bey ihm blieb,", "tokens": ["Und", "las", "ihn", "Schwa\u00b7ben", "vor", ",", "der", "da\u00b7rum", "bey", "ihm", "blieb", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "NN", "PTKVZ", "$,", "PRELS", "PAV", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.86": {"text": "Damit er lernete, wie schnell sein Meister schrieb.", "tokens": ["Da\u00b7mit", "er", "ler\u00b7ne\u00b7te", ",", "wie", "schnell", "sein", "Meis\u00b7ter", "schrieb", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "$,", "PWAV", "ADJD", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.87": {"text": "Es war die Stachel-Schrifft prosaisch aufgesetzet;", "tokens": ["Es", "war", "die", "Sta\u00b7chel\u00b7Schrifft", "pro\u00b7sa\u00b7isch", "auf\u00b7ge\u00b7set\u00b7zet", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.88": {"text": "Recht Wortreich, was Catull an den Suffen gesch\u00e4tzet;", "tokens": ["Recht", "Wort\u00b7reich", ",", "was", "Ca\u00b7tull", "an", "den", "Suf\u00b7fen", "ge\u00b7sch\u00e4t\u00b7zet", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "$,", "PRELS", "NE", "APPR", "ART", "NN", "VVPP", "$."], "meter": "--+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.89": {"text": "Er gab nun \u00f6ffentlich der armen Neuberinn", "tokens": ["Er", "gab", "nun", "\u00f6f\u00b7fent\u00b7lich", "der", "ar\u00b7men", "Neu\u00b7be\u00b7rinn"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "ADJD", "ART", "ADJA", "NN"], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.90": {"text": "Ged\u00e4chtni\u00df-Fehler schuld; Brodneid", "tokens": ["Ge\u00b7d\u00e4cht\u00b7ni\u00df\u00b7Feh\u00b7ler", "schuld", ";", "Bro\u00b7dne\u00b7id"], "token_info": ["word", "word", "punct", "word"], "pos": ["NN", "ADJD", "$.", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.91": {"text": "Sie ward so klein gemacht, als sie kaum gro\u00df gewesen,", "tokens": ["Sie", "ward", "so", "klein", "ge\u00b7macht", ",", "als", "sie", "kaum", "gro\u00df", "ge\u00b7we\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "VVPP", "$,", "KOUS", "PPER", "ADV", "ADJD", "VAPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.92": {"text": "Und die\u00df bekam die Welt im sch\u00f6nsten Druck zu lesen.", "tokens": ["Und", "die\u00df", "be\u00b7kam", "die", "Welt", "im", "sch\u00f6ns\u00b7ten", "Druck", "zu", "le\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VVFIN", "ART", "NN", "APPRART", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.93": {"text": "Selbst Breitkopff setzte sie in eigener Person,", "tokens": ["Selbst", "Breit\u00b7kopff", "setz\u00b7te", "sie", "in", "ei\u00b7ge\u00b7ner", "Per\u00b7son", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NE", "VVFIN", "PPER", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+--++", "measure": "iambic.hexa.relaxed"}, "line.94": {"text": "Und, als Verleger, nahm er auch kein Drucker-Lohn.", "tokens": ["Und", ",", "als", "Ver\u00b7le\u00b7ger", ",", "nahm", "er", "auch", "kein", "Dru\u00b7cke\u00b7rLohn", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "NN", "$,", "VVFIN", "PPER", "ADV", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.95": {"text": "So war der Neuberin ihr Ungl\u00fcck zubereitet;", "tokens": ["So", "war", "der", "Neu\u00b7be\u00b7rin", "ihr", "Un\u00b7gl\u00fcck", "zu\u00b7be\u00b7rei\u00b7tet", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.96": {"text": "Ihr Zeiten merckt es euch, was Gottscheds Zorn bedeutet.", "tokens": ["Ihr", "Zei\u00b7ten", "merckt", "es", "euch", ",", "was", "Gott\u00b7scheds", "Zorn", "be\u00b7deu\u00b7tet", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "PPER", "$,", "PRELS", "NE", "NE", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}