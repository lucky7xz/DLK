{"dta.poem.3780": {"metadata": {"author": {"name": "George, Stefan", "birth": "N.A.", "death": "N.A."}, "title": "N.A.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1892", "urn": "urn:nbn:de:kobv:b4-200905191524", "language": ["de:0.99"], "booktitle": "George, Stefan: Algabal. Paris u. a., 1892."}, "poem": {"stanza.1": {"line.1": {"text": "Ich will dass man im volke stirbt und st\u00f6hnt", "tokens": ["Ich", "will", "dass", "man", "im", "vol\u00b7ke", "stirbt", "und", "st\u00f6hnt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "KOUS", "PIS", "APPRART", "ADJA", "VVFIN", "KON", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Und jeder lacher sei ans kreuz geschlagen \u00b7", "tokens": ["Und", "je\u00b7der", "la\u00b7cher", "sei", "ans", "kreuz", "ge\u00b7schla\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PIS", "ADJD", "VAFIN", "APPRART", "NN", "VVPP", "XY"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Es ist ein groll der f\u00fcr mich selber dr\u00f6hnt", "tokens": ["Es", "ist", "ein", "groll", "der", "f\u00fcr", "mich", "sel\u00b7ber", "dr\u00f6hnt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "ADJD", "ART", "APPR", "PPER", "ADV", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Ich bin als EINER so wie SIE als viele", "tokens": ["Ich", "bin", "als", "Ei\u00b7NER", "so", "wie", "SiE", "als", "vie\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "KOKOM", "NE", "ADV", "KOKOM", "NE", "KOUS", "PIS"], "meter": "-+-+---+-+-", "measure": "unknown.measure.tetra"}, "line.2": {"text": "Ich thue was das leben mit mir thut", "tokens": ["Ich", "thue", "was", "das", "le\u00b7ben", "mit", "mir", "thut"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PWS", "PDS", "VVFIN", "APPR", "PPER", "VVFIN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Und tr\u00e4f ich sie mit ruten bis aufs blut", "tokens": ["Und", "tr\u00e4f", "ich", "sie", "mit", "ru\u00b7ten", "bis", "aufs", "blut"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "PPER", "APPR", "VVFIN", "APPR", "APPRART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Sie haben korn und haben fechterspiele", "tokens": ["Sie", "ha\u00b7ben", "korn", "und", "ha\u00b7ben", "fech\u00b7ter\u00b7spie\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "NN", "KON", "VAFIN", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Wenn ich in ihrer tracht und mich vergessend", "tokens": ["Wenn", "ich", "in", "ih\u00b7rer", "tracht", "und", "mich", "ver\u00b7ges\u00b7send"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "PPOSAT", "NN", "KON", "PPER", "VVPP"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Geheim in ihren leeren l\u00e4rm gepasst", "tokens": ["Ge\u00b7heim", "in", "ih\u00b7ren", "lee\u00b7ren", "l\u00e4rm", "ge\u00b7passt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "PPOSAT", "ADJA", "NN", "VVPP"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "- Ich f\u00fcrchte - hab ich nie sie tief gehasst", "tokens": ["Ich", "f\u00fcrch\u00b7te", "hab", "ich", "nie", "sie", "tief", "ge\u00b7hasst"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "PPER", "VVFIN", "$(", "VAFIN", "PPER", "ADV", "PPER", "ADJD", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Der eignen artung h\u00e4rte recht ermessend", "tokens": ["Der", "eig\u00b7nen", "ar\u00b7tung", "h\u00e4r\u00b7te", "recht", "er\u00b7mes\u00b7send"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ADJD", "VVPP"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Dann schloss ich hinter aller schar die riegel", "tokens": ["Dann", "schloss", "ich", "hin\u00b7ter", "al\u00b7ler", "schar", "die", "rie\u00b7gel"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "PIAT", "ADJD", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ich ruhte ohne wunsch und mild und schlicht", "tokens": ["Ich", "ruh\u00b7te", "oh\u00b7ne", "wunsch", "und", "mild", "und", "schlicht"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ADJD", "KON", "ADJD", "KON", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Und beinah einer schwester angesicht", "tokens": ["Und", "bei\u00b7nah", "ei\u00b7ner", "schwes\u00b7ter", "an\u00b7ge\u00b7sicht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Erwiderte dem schauenden ein spiegel", "tokens": ["Er\u00b7wi\u00b7der\u00b7te", "dem", "schau\u00b7en\u00b7den", "ein", "spie\u00b7gel"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "ADJA", "ART", "NN"], "meter": "-+---+---+-", "measure": "dactylic.init"}}}}}