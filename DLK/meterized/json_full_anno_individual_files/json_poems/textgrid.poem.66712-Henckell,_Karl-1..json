{"textgrid.poem.66712": {"metadata": {"author": {"name": "Henckell, Karl", "birth": "N.A.", "death": "N.A."}, "title": "1.", "genre": "verse", "period": "N.A.", "pub_year": 1896, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Am Hause meines Lebens steht ein Wort,", "tokens": ["Am", "Hau\u00b7se", "mei\u00b7nes", "Le\u00b7bens", "steht", "ein", "Wort", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PPOSAT", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Das unverwischbar ist in Lust und Leiden,", "tokens": ["Das", "un\u00b7ver\u00b7wischbar", "ist", "in", "Lust", "und", "Lei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADJD", "VAFIN", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Mag schn\u00f6des Ungl\u00fcck mir das Herz zerschneiden,", "tokens": ["Mag", "schn\u00f6\u00b7des", "Un\u00b7gl\u00fcck", "mir", "das", "Herz", "zer\u00b7schnei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADJA", "NN", "PPER", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Mag Gl\u00fcck mich schaukeln, dauernd bleibt es dort.", "tokens": ["Mag", "Gl\u00fcck", "mich", "schau\u00b7keln", ",", "dau\u00b7ernd", "bleibt", "es", "dort", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "NN", "PPER", "VVFIN", "$,", "ADJD", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Das Wort: \u00bb", "tokens": ["Das", "Wort", ":", "\u00bb"], "token_info": ["word", "word", "punct", "punct"], "pos": ["ART", "NN", "$.", "$("], "meter": "-+", "measure": "iambic.single"}, "line.2": {"text": "Wer Unrecht tr\u00e4gt, an wem sich Henker weiden,", "tokens": ["Wer", "Un\u00b7recht", "tr\u00e4gt", ",", "an", "wem", "sich", "Hen\u00b7ker", "wei\u00b7den", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "VVFIN", "$,", "APPR", "PWS", "PRF", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Wer \u00bbwelt\u00ab-verfemt, wen die \u00bbGerechten\u00ab meiden,", "tokens": ["Wer", "\u00bb", "welt", "\u00ab", ",", "wen", "die", "\u00bb", "Ge\u00b7rech\u00b7ten", "\u00ab", "mei\u00b7den", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PWS", "$(", "NN", "$(", "NE", "$,", "PWS", "ART", "$(", "NN", "$(", "VVINF", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "An meiner Schwelle find' er Heim und Hort.", "tokens": ["An", "mei\u00b7ner", "Schwel\u00b7le", "find'", "er", "Heim", "und", "Hort", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "PPER", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Wer m\u00f6chte sich mit diesem Worte br\u00fcsten!", "tokens": ["Wer", "m\u00f6ch\u00b7te", "sich", "mit", "die\u00b7sem", "Wor\u00b7te", "br\u00fcs\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PRF", "APPR", "PDAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Nicht als ein Lob des Wesens schreib' ich's hin,", "tokens": ["Nicht", "als", "ein", "Lob", "des", "We\u00b7sens", "schreib'", "ich's", "hin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "KOUS", "ART", "NN", "ART", "NN", "VVFIN", "PIS", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Das ich durch solchen Sinnes Richtung bin,", "tokens": ["Das", "ich", "durch", "sol\u00b7chen", "Sin\u00b7nes", "Rich\u00b7tung", "bin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "APPR", "PIAT", "ADJA", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Noch will's nach Tugendlorbeer mich gel\u00fcsten.", "tokens": ["Noch", "will's", "nach", "Tu\u00b7gend\u00b7lor\u00b7beer", "mich", "ge\u00b7l\u00fcs\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "APPR", "NN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Nur zeugt es von dem eingebornen Hange,", "tokens": ["Nur", "zeugt", "es", "von", "dem", "ein\u00b7ge\u00b7bor\u00b7nen", "Han\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Mit dem willkommne Wandrer ich empfange.", "tokens": ["Mit", "dem", "will\u00b7komm\u00b7ne", "Wand\u00b7rer", "ich", "emp\u00b7fan\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "Am Hause meines Lebens steht ein Wort,", "tokens": ["Am", "Hau\u00b7se", "mei\u00b7nes", "Le\u00b7bens", "steht", "ein", "Wort", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PPOSAT", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Das unverwischbar ist in Lust und Leiden,", "tokens": ["Das", "un\u00b7ver\u00b7wischbar", "ist", "in", "Lust", "und", "Lei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADJD", "VAFIN", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Mag schn\u00f6des Ungl\u00fcck mir das Herz zerschneiden,", "tokens": ["Mag", "schn\u00f6\u00b7des", "Un\u00b7gl\u00fcck", "mir", "das", "Herz", "zer\u00b7schnei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADJA", "NN", "PPER", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Mag Gl\u00fcck mich schaukeln, dauernd bleibt es dort.", "tokens": ["Mag", "Gl\u00fcck", "mich", "schau\u00b7keln", ",", "dau\u00b7ernd", "bleibt", "es", "dort", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "NN", "PPER", "VVFIN", "$,", "ADJD", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "Das Wort: \u00bb", "tokens": ["Das", "Wort", ":", "\u00bb"], "token_info": ["word", "word", "punct", "punct"], "pos": ["ART", "NN", "$.", "$("], "meter": "-+", "measure": "iambic.single"}, "line.2": {"text": "Wer Unrecht tr\u00e4gt, an wem sich Henker weiden,", "tokens": ["Wer", "Un\u00b7recht", "tr\u00e4gt", ",", "an", "wem", "sich", "Hen\u00b7ker", "wei\u00b7den", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "VVFIN", "$,", "APPR", "PWS", "PRF", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Wer \u00bbwelt\u00ab-verfemt, wen die \u00bbGerechten\u00ab meiden,", "tokens": ["Wer", "\u00bb", "welt", "\u00ab", ",", "wen", "die", "\u00bb", "Ge\u00b7rech\u00b7ten", "\u00ab", "mei\u00b7den", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PWS", "$(", "NN", "$(", "NE", "$,", "PWS", "ART", "$(", "NN", "$(", "VVINF", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "An meiner Schwelle find' er Heim und Hort.", "tokens": ["An", "mei\u00b7ner", "Schwel\u00b7le", "find'", "er", "Heim", "und", "Hort", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "PPER", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.7": {"line.1": {"text": "Wer m\u00f6chte sich mit diesem Worte br\u00fcsten!", "tokens": ["Wer", "m\u00f6ch\u00b7te", "sich", "mit", "die\u00b7sem", "Wor\u00b7te", "br\u00fcs\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PRF", "APPR", "PDAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Nicht als ein Lob des Wesens schreib' ich's hin,", "tokens": ["Nicht", "als", "ein", "Lob", "des", "We\u00b7sens", "schreib'", "ich's", "hin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "KOUS", "ART", "NN", "ART", "NN", "VVFIN", "PIS", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Das ich durch solchen Sinnes Richtung bin,", "tokens": ["Das", "ich", "durch", "sol\u00b7chen", "Sin\u00b7nes", "Rich\u00b7tung", "bin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "APPR", "PIAT", "ADJA", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.8": {"line.1": {"text": "Noch will's nach Tugendlorbeer mich gel\u00fcsten.", "tokens": ["Noch", "will's", "nach", "Tu\u00b7gend\u00b7lor\u00b7beer", "mich", "ge\u00b7l\u00fcs\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "APPR", "NN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Nur zeugt es von dem eingebornen Hange,", "tokens": ["Nur", "zeugt", "es", "von", "dem", "ein\u00b7ge\u00b7bor\u00b7nen", "Han\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Mit dem willkommne Wandrer ich empfange.", "tokens": ["Mit", "dem", "will\u00b7komm\u00b7ne", "Wand\u00b7rer", "ich", "emp\u00b7fan\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}}}}