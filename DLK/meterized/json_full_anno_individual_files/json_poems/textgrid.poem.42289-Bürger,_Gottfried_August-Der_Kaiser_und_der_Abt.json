{"textgrid.poem.42289": {"metadata": {"author": {"name": "B\u00fcrger, Gottfried August", "birth": "N.A.", "death": "N.A."}, "title": "Der Kaiser und der Abt", "genre": "verse", "period": "N.A.", "pub_year": 1770, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ich will euch erz\u00e4hlen ein M\u00e4rchen, gar schnurrig:", "tokens": ["Ich", "will", "euch", "er\u00b7z\u00e4h\u00b7len", "ein", "M\u00e4r\u00b7chen", ",", "gar", "schnur\u00b7rig", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "VVFIN", "ART", "NN", "$,", "ADV", "ADJD", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.2": {"text": "Es war 'mal ein Kaiser; der Kaiser war kurrig;", "tokens": ["Es", "war", "'mal", "ein", "Kai\u00b7ser", ";", "der", "Kai\u00b7ser", "war", "kur\u00b7rig", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ART", "NN", "$.", "ART", "NN", "VAFIN", "ADJD", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.3": {"text": "Auch war 'mal ein Abt, ein gar stattlicher Herr;", "tokens": ["Auch", "war", "'mal", "ein", "Abt", ",", "ein", "gar", "statt\u00b7li\u00b7cher", "Herr", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "ART", "NN", "$,", "ART", "ADV", "ADJA", "NN", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "Nur schade! sein Sch\u00e4fer war kl\u00fcger, als Er.", "tokens": ["Nur", "scha\u00b7de", "!", "sein", "Sch\u00e4\u00b7fer", "war", "kl\u00fc\u00b7ger", ",", "als", "Er", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$.", "PPOSAT", "NN", "VAFIN", "ADJD", "$,", "KOUS", "PPER", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}}, "stanza.2": {"line.1": {"text": "Dem Kaiser ward's sauer in Hitz' und in K\u00e4lte:", "tokens": ["Dem", "Kai\u00b7ser", "ward's", "sau\u00b7er", "in", "Hitz'", "und", "in", "K\u00e4l\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "APPR", "NN", "KON", "APPR", "NN", "$."], "meter": "-+-+---+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Oft schlief er bepanzert im Kriegesgezelte;", "tokens": ["Oft", "schlief", "er", "be\u00b7pan\u00b7zert", "im", "Krie\u00b7ges\u00b7ge\u00b7zel\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "VVFIN", "APPRART", "NN", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.3": {"text": "Oft hatt' er kaum Wasser zu Schwarzbrot und Wurst;", "tokens": ["Oft", "hatt'", "er", "kaum", "Was\u00b7ser", "zu", "Schwarz\u00b7brot", "und", "Wurst", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "NN", "APPR", "NN", "KON", "NN", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "Und \u00f6fter noch litt' er gar Hunger und Durst.", "tokens": ["Und", "\u00f6f\u00b7ter", "noch", "litt'", "er", "gar", "Hun\u00b7ger", "und", "Durst", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "VVFIN", "PPER", "ADV", "NN", "KON", "NN", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}}, "stanza.3": {"line.1": {"text": "Das Pf\u00e4fflein, das wu\u00dfte sich besser zu hegen,", "tokens": ["Das", "Pf\u00e4f\u00b7flein", ",", "das", "wu\u00df\u00b7te", "sich", "bes\u00b7ser", "zu", "he\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PDS", "VVFIN", "PRF", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.2": {"text": "Und weidlich am Tisch und im Bette zu pflegen.", "tokens": ["Und", "weid\u00b7lich", "am", "Tisch", "und", "im", "Bet\u00b7te", "zu", "pfle\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "APPRART", "NN", "KON", "APPRART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.3": {"text": "Wie Vollmond gl\u00e4nzte sein feinstes Gesicht.", "tokens": ["Wie", "Voll\u00b7mond", "gl\u00e4nz\u00b7te", "sein", "feins\u00b7tes", "Ge\u00b7sicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "VVFIN", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Drei M\u00e4nner umspannten den Schmerbauch ihm nicht.", "tokens": ["Drei", "M\u00e4n\u00b7ner", "um\u00b7spann\u00b7ten", "den", "Schmer\u00b7bauch", "ihm", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "VVFIN", "ART", "NN", "PPER", "PTKNEG", "$."], "meter": "-+--+--++-+", "measure": "iambic.penta.relaxed"}}, "stanza.4": {"line.1": {"text": "D'rob suchte der Kaiser am Pf\u00e4fflein oft Hader.", "tokens": ["D'\u00b7rob", "such\u00b7te", "der", "Kai\u00b7ser", "am", "Pf\u00e4f\u00b7flein", "oft", "Ha\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPRART", "NN", "ADV", "NN", "$."], "meter": "+-+--+--+--+-", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Einst ritt er, mit reisigem Kriegesgeschwader,", "tokens": ["Einst", "ritt", "er", ",", "mit", "rei\u00b7si\u00b7gem", "Krie\u00b7ges\u00b7ge\u00b7schwa\u00b7der", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.3": {"text": "In brennender Hitze des Sommers vorbei.", "tokens": ["In", "bren\u00b7nen\u00b7der", "Hit\u00b7ze", "des", "Som\u00b7mers", "vor\u00b7bei", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ART", "NN", "PTKVZ", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "Das Pf\u00e4fflein spazierte vor seiner Abtei.", "tokens": ["Das", "Pf\u00e4f\u00b7flein", "spa\u00b7zier\u00b7te", "vor", "sei\u00b7ner", "Ab\u00b7tei", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}}, "stanza.5": {"line.1": {"text": "\u00bbha, dachte der Kaiser, zur gl\u00fccklichen Stunde!\u00ab", "tokens": ["\u00bb", "ha", ",", "dach\u00b7te", "der", "Kai\u00b7ser", ",", "zur", "gl\u00fcck\u00b7li\u00b7chen", "Stun\u00b7de", "!", "\u00ab"], "token_info": ["punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ITJ", "$,", "VVFIN", "ART", "NN", "$,", "APPRART", "ADJA", "NN", "$.", "$("], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.2": {"text": "Und gr\u00fc\u00dfte das Pf\u00e4fflein mit h\u00f6hnischem Munde:", "tokens": ["Und", "gr\u00fc\u00df\u00b7te", "das", "Pf\u00e4f\u00b7flein", "mit", "h\u00f6h\u00b7ni\u00b7schem", "Mun\u00b7de", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.3": {"text": "\u00bbknecht Gottes, wie geht's dir? Mir d\u00e4ucht wohl ganz recht,", "tokens": ["\u00bb", "knecht", "Got\u00b7tes", ",", "wie", "geht's", "dir", "?", "Mir", "d\u00e4ucht", "wohl", "ganz", "recht", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "NN", "$,", "PWAV", "VVFIN", "PPER", "$.", "PPER", "VVFIN", "ADV", "ADV", "ADJD", "$,"], "meter": "-+--+-+---+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Das Beten und Fasten bekomme nicht schlecht.", "tokens": ["Das", "Be\u00b7ten", "und", "Fas\u00b7ten", "be\u00b7kom\u00b7me", "nicht", "schlecht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "VVFIN", "PTKNEG", "ADJD", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}}, "stanza.6": {"line.1": {"text": "Doch d\u00e4ucht mir daneben, euch plage viel Weile.", "tokens": ["Doch", "d\u00e4ucht", "mir", "da\u00b7ne\u00b7ben", ",", "euch", "pla\u00b7ge", "viel", "Wei\u00b7le", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PAV", "$,", "PPER", "VVFIN", "PIAT", "NN", "$."], "meter": "-+-+---+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Ihr dankt mir's wohl, wenn ich euch Arbeit erteile,", "tokens": ["Ihr", "dankt", "mir's", "wohl", ",", "wenn", "ich", "euch", "Ar\u00b7beit", "er\u00b7tei\u00b7le", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NE", "ADV", "$,", "KOUS", "PPER", "PPER", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Man r\u00fchmet, ihr w\u00e4ret der pfiffigste Mann,", "tokens": ["Man", "r\u00fch\u00b7met", ",", "ihr", "w\u00e4\u00b7ret", "der", "pfif\u00b7figs\u00b7te", "Mann", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "$,", "PPER", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+--+---+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Ihr h\u00f6rtet das Gr\u00e4schen fast wachsen, sagt man.", "tokens": ["Ihr", "h\u00f6r\u00b7tet", "das", "Gr\u00e4sc\u00b7hen", "fast", "wach\u00b7sen", ",", "sagt", "man", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADV", "VVINF", "$,", "VVFIN", "PIS", "$."], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}}, "stanza.7": {"line.1": {"text": "So geb' ich denn euren zwei t\u00fcchtigen Backen", "tokens": ["So", "geb'", "ich", "denn", "eu\u00b7ren", "zwei", "t\u00fcch\u00b7ti\u00b7gen", "Ba\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "PPOSAT", "CARD", "ADJA", "NN"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.2": {"text": "Zur Kurzweil drei artige N\u00fcsse zu knacken.", "tokens": ["Zur", "Kurz\u00b7weil", "drei", "ar\u00b7ti\u00b7ge", "N\u00fcs\u00b7se", "zu", "kna\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "CARD", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.3": {"text": "Drei Monden von nun an bestimm' ich zur Zeit.", "tokens": ["Drei", "Mon\u00b7den", "von", "nun", "an", "be\u00b7stimm'", "ich", "zur", "Zeit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "APPR", "ADV", "APZR", "VVFIN", "PPER", "APPRART", "NN", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.4": {"text": "Dann will ich auf diese drei Fragen Bescheid.", "tokens": ["Dann", "will", "ich", "auf", "die\u00b7se", "drei", "Fra\u00b7gen", "Be\u00b7scheid", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "APPR", "PDAT", "CARD", "NN", "NN", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}}, "stanza.8": {"line.1": {"text": "Zum ersten: Wann hoch ich, im f\u00fcrstlichen Rate,", "tokens": ["Zum", "ers\u00b7ten", ":", "Wann", "hoch", "ich", ",", "im", "f\u00fcrst\u00b7li\u00b7chen", "Ra\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "$.", "PWAV", "ADJD", "PPER", "$,", "APPRART", "ADJA", "NN", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.2": {"text": "Zu Throne mich zeige im Kaiserornate,", "tokens": ["Zu", "Thro\u00b7ne", "mich", "zei\u00b7ge", "im", "Kai\u00b7ser\u00b7or\u00b7na\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PPER", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.3": {"text": "Dann sollt ihr mir sagen, ein treuer Wardein,", "tokens": ["Dann", "sollt", "ihr", "mir", "sa\u00b7gen", ",", "ein", "treu\u00b7er", "War\u00b7dein", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PPER", "VVINF", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+--+--+---", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Wie viel ich wohl wert, bis zum Heller mag sein?", "tokens": ["Wie", "viel", "ich", "wohl", "wert", ",", "bis", "zum", "Hel\u00b7ler", "mag", "sein", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "PPER", "ADV", "ADJD", "$,", "KOUS", "APPRART", "NN", "VMFIN", "VAINF", "$."], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}}, "stanza.9": {"line.1": {"text": "Zum zweiten sollt ihr mir berechnen und sagen:", "tokens": ["Zum", "zwei\u00b7ten", "sollt", "ihr", "mir", "be\u00b7rech\u00b7nen", "und", "sa\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "VMFIN", "PPER", "PPER", "VVFIN", "KON", "VVINF", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Wie bald ich zu Rosse die Welt mag umjagen?", "tokens": ["Wie", "bald", "ich", "zu", "Ros\u00b7se", "die", "Welt", "mag", "um\u00b7ja\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "PPER", "APPR", "NN", "ART", "NN", "VMFIN", "VVINF", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.3": {"text": "Um keine Minute zu wenig und viel!", "tokens": ["Um", "kei\u00b7ne", "Mi\u00b7nu\u00b7te", "zu", "we\u00b7nig", "und", "viel", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PIAT", "NN", "APPR", "PIS", "KON", "ADV", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "Ich wei\u00df der Bescheid darauf ist euch nur Spiel.", "tokens": ["Ich", "wei\u00df", "der", "Be\u00b7scheid", "da\u00b7rauf", "ist", "euch", "nur", "Spiel", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "PAV", "VAFIN", "PPER", "ADV", "NN", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}}, "stanza.10": {"line.1": {"text": "Zum dritten noch sollst du, o Preis der Pr\u00e4laten,", "tokens": ["Zum", "drit\u00b7ten", "noch", "sollst", "du", ",", "o", "Preis", "der", "Pr\u00e4\u00b7la\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "ADV", "VMFIN", "PPER", "$,", "FM", "NN", "ART", "NN", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.2": {"text": "Aufs H\u00e4rchen mir meine Gedanken erraten.", "tokens": ["Aufs", "H\u00e4r\u00b7chen", "mir", "mei\u00b7ne", "Ge\u00b7dan\u00b7ken", "er\u00b7ra\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PPER", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.3": {"text": "Die will ich dann treulich bekennen: allein", "tokens": ["Die", "will", "ich", "dann", "treu\u00b7lich", "be\u00b7ken\u00b7nen", ":", "al\u00b7lein"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["PDS", "VMFIN", "PPER", "ADV", "ADJD", "VVINF", "$.", "ADV"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "Es soll auch kein Titelchen Wahres d'ran sein.", "tokens": ["Es", "soll", "auch", "kein", "Ti\u00b7tel\u00b7chen", "Wah\u00b7res", "d'\u00b7ran", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "PIAT", "NN", "ADJA", "NE", "VAINF", "$."], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}}, "stanza.11": {"line.1": {"text": "Und k\u00f6nnt ihr mir diese drei Fragen nicht l\u00f6sen,", "tokens": ["Und", "k\u00f6nnt", "ihr", "mir", "die\u00b7se", "drei", "Fra\u00b7gen", "nicht", "l\u00f6\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PPER", "PDAT", "CARD", "NN", "PTKNEG", "VVINF", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.2": {"text": "So seid ihr die l\u00e4ngste Zeit Abt hier gewesen;", "tokens": ["So", "seid", "ihr", "die", "l\u00e4ngs\u00b7te", "Zeit", "Abt", "hier", "ge\u00b7we\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ART", "ADJA", "NN", "NN", "ADV", "VAPP", "$."], "meter": "-+--+-++--+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "So lass' ich euch f\u00fchren zu Esel durchs Land,", "tokens": ["So", "lass'", "ich", "euch", "f\u00fch\u00b7ren", "zu", "E\u00b7sel", "durchs", "Land", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "VVFIN", "APPR", "NN", "APPRART", "NN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "Verkehrt, statt des Zaumes, den Schwanz in der Hand.\u00ab \u2013", "tokens": ["Ver\u00b7kehrt", ",", "statt", "des", "Zau\u00b7mes", ",", "den", "Schwanz", "in", "der", "Hand", ".", "\u00ab", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["VVPP", "$,", "KOUI", "ART", "NN", "$,", "ART", "NN", "APPR", "ART", "NN", "$.", "$(", "$("], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}}, "stanza.12": {"line.1": {"text": "D'rauf trabte der Kaiser mit Lachen von hinnen.", "tokens": ["D'\u00b7rauf", "trab\u00b7te", "der", "Kai\u00b7ser", "mit", "La\u00b7chen", "von", "hin\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "ART", "NN", "APPR", "NN", "APPR", "ADV", "$."], "meter": "--+--+--+--+-", "measure": "anapaest.tetra.plus"}, "line.2": {"text": "Das Pf\u00e4fflein zerri\u00df und zerspli\u00df sich mit Sinnen.", "tokens": ["Das", "Pf\u00e4f\u00b7flein", "zer\u00b7ri\u00df", "und", "zer\u00b7spli\u00df", "sich", "mit", "Sin\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "KON", "VVFIN", "PRF", "APPR", "NN", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.3": {"text": "Kein armer Verbrecher f\u00fchlt mehr Schwulit\u00e4t,", "tokens": ["Kein", "ar\u00b7mer", "Ver\u00b7bre\u00b7cher", "f\u00fchlt", "mehr", "Schwu\u00b7li\u00b7t\u00e4t", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "VVFIN", "PIAT", "NN", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Der vor hochnotpeinlichem Halsgericht steht.", "tokens": ["Der", "vor", "hoch\u00b7not\u00b7pein\u00b7li\u00b7chem", "Hals\u00b7ge\u00b7richt", "steht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "--+-+--+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.13": {"line.1": {"text": "Er schickte nach ein, zwei, drei, vier Un'vers't\u00e4ten,", "tokens": ["Er", "schick\u00b7te", "nach", "ein", ",", "zwei", ",", "drei", ",", "vier", "Un'\u00b7ver\u00b7s'\u00b7t\u00e4\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "$,", "CARD", "$,", "CARD", "$,", "CARD", "NN", "$,"], "meter": "-+------+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Er fragte bei ein, zwei, drei, vier Fakult\u00e4ten,", "tokens": ["Er", "frag\u00b7te", "bei", "ein", ",", "zwei", ",", "drei", ",", "vier", "Fa\u00b7kul\u00b7t\u00e4\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "$,", "CARD", "$,", "CARD", "$,", "CARD", "NN", "$,"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Er zahlte Geb\u00fchren und Sportuln vollauf:", "tokens": ["Er", "zahl\u00b7te", "Ge\u00b7b\u00fch\u00b7ren", "und", "Spor\u00b7tuln", "vol\u00b7lauf", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "KON", "NN", "PTKVZ", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "Doch l\u00f6ste kein Doktor die Fragen ihm auf.", "tokens": ["Doch", "l\u00f6s\u00b7te", "kein", "Dok\u00b7tor", "die", "Fra\u00b7gen", "ihm", "auf", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIAT", "NN", "ART", "NN", "PPER", "PTKVZ", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}}, "stanza.14": {"line.1": {"text": "Schnell wuchsen, bei herzlichem Zagen und Pochen,", "tokens": ["Schnell", "wuch\u00b7sen", ",", "bei", "herz\u00b7li\u00b7chem", "Za\u00b7gen", "und", "Po\u00b7chen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "$,", "APPR", "ADJA", "NN", "KON", "NN", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.2": {"text": "Die Stunden zu Tagen, die Tage zu Wochen,", "tokens": ["Die", "Stun\u00b7den", "zu", "Ta\u00b7gen", ",", "die", "Ta\u00b7ge", "zu", "Wo\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "$,", "ART", "NN", "APPR", "NN", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.3": {"text": "Die Wochen zu Monden; schon kam der Termin!", "tokens": ["Die", "Wo\u00b7chen", "zu", "Mon\u00b7den", ";", "schon", "kam", "der", "Ter\u00b7min", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "$.", "ADV", "VVFIN", "ART", "NN", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "Ihm ward's vor den Augen bald gelb und bald gr\u00fcn.", "tokens": ["Ihm", "ward's", "vor", "den", "Au\u00b7gen", "bald", "gelb", "und", "bald", "gr\u00fcn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "ART", "NN", "ADV", "ADJD", "KON", "ADV", "ADJD", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}}, "stanza.15": {"line.1": {"text": "Nun sucht' er, ein bleicher hohlwangiger Werther,", "tokens": ["Nun", "sucht'", "er", ",", "ein", "blei\u00b7cher", "hohl\u00b7wan\u00b7gi\u00b7ger", "Wert\u00b7her", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "ART", "ADJA", "ADJA", "NN", "$,"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "In W\u00e4ldern und Feldern die einsamsten \u00d6rter.", "tokens": ["In", "W\u00e4l\u00b7dern", "und", "Fel\u00b7dern", "die", "ein\u00b7sams\u00b7ten", "\u00d6r\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Da traf ihn, auf selten betretener Bahn,", "tokens": ["Da", "traf", "ihn", ",", "auf", "sel\u00b7ten", "be\u00b7tre\u00b7te\u00b7ner", "Bahn", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "APPR", "ADJA", "ADJA", "NN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "Hans Bendix, sein Sch\u00e4fer, am Felsenhang an.", "tokens": ["Hans", "Ben\u00b7dix", ",", "sein", "Sch\u00e4\u00b7fer", ",", "am", "Fel\u00b7sen\u00b7hang", "an", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "PPOSAT", "NN", "$,", "APPRART", "NN", "PTKVZ", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}}, "stanza.16": {"line.1": {"text": "\u00bbherr Abt, sprach Hans Bendix, was m\u00f6gt ihr euch gr\u00e4men?", "tokens": ["\u00bb", "herr", "Abt", ",", "sprach", "Hans", "Ben\u00b7dix", ",", "was", "m\u00f6gt", "ihr", "euch", "gr\u00e4\u00b7men", "?"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "NN", "NE", "$,", "VVFIN", "NE", "NE", "$,", "PWS", "VMFIN", "PPER", "PPER", "VVINF", "$."], "meter": "+-+-+--+--+-", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Ihr schwindet ja wahrlich dahin, wie ein Schemen.", "tokens": ["Ihr", "schwin\u00b7det", "ja", "wahr\u00b7lich", "da\u00b7hin", ",", "wie", "ein", "Sche\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "PAV", "$,", "PWAV", "ART", "NN", "$."], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Maria und Joseph! Wie hotzelt ihr ein!", "tokens": ["Ma\u00b7ria", "und", "Jo\u00b7se\u00b7ph", "!", "Wie", "hot\u00b7zelt", "ihr", "ein", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "NE", "$.", "PWAV", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.4": {"text": "Mein Sixchen! Es mu\u00df euch was angethan sein.\u00ab \u2013", "tokens": ["Mein", "Six\u00b7chen", "!", "Es", "mu\u00df", "euch", "was", "an\u00b7ge\u00b7than", "sein", ".", "\u00ab", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PPOSAT", "NN", "$.", "PPER", "VMFIN", "PPER", "PIS", "VVPP", "VAINF", "$.", "$(", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.17": {"line.1": {"text": "\u00bbach, guter Hans Bendix, so mu\u00df sich's wohl schicken.", "tokens": ["\u00bb", "ach", ",", "gu\u00b7ter", "Hans", "Ben\u00b7dix", ",", "so", "mu\u00df", "sich's", "wohl", "schi\u00b7cken", "."], "token_info": ["punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ITJ", "$,", "ADJA", "NE", "NE", "$,", "ADV", "VMFIN", "PIS", "ADV", "VVINF", "$."], "meter": "-+---+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Der Kaiser will gern mir am Zeuge was flicken,", "tokens": ["Der", "Kai\u00b7ser", "will", "gern", "mir", "am", "Zeu\u00b7ge", "was", "fli\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "ADV", "PPER", "APPRART", "NN", "PIS", "VVINF", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.3": {"text": "Und hat mir drei N\u00fcss' auf die Z\u00e4hne gepackt,", "tokens": ["Und", "hat", "mir", "drei", "N\u00fcss'", "auf", "die", "Z\u00e4h\u00b7ne", "ge\u00b7packt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "CARD", "NN", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.4": {"text": "Die schwerlich Beelzebub selber wohl knackt.", "tokens": ["Die", "schwer\u00b7lich", "Beel\u00b7ze\u00b7bub", "sel\u00b7ber", "wohl", "knackt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "ADV", "ADV", "VVFIN", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}}, "stanza.18": {"line.1": {"text": "Zum ersten: Wann hoch Er, im f\u00fcrstlichen Rate,", "tokens": ["Zum", "ers\u00b7ten", ":", "Wann", "hoch", "Er", ",", "im", "f\u00fcrst\u00b7li\u00b7chen", "Ra\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "$.", "PWAV", "ADJD", "PPER", "$,", "APPRART", "ADJA", "NN", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.2": {"text": "Zu Throne sich zeiget, im Kaiserornate,", "tokens": ["Zu", "Thro\u00b7ne", "sich", "zei\u00b7get", ",", "im", "Kai\u00b7ser\u00b7or\u00b7na\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "NN", "PRF", "VVFIN", "$,", "APPRART", "NN", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.3": {"text": "Dann soll ich ihm sagen, ein treuer Wardein,", "tokens": ["Dann", "soll", "ich", "ihm", "sa\u00b7gen", ",", "ein", "treu\u00b7er", "War\u00b7dein", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PPER", "VVINF", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+--+--+---", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Wie viel er wohl wert, bis zum Heller mag sein?", "tokens": ["Wie", "viel", "er", "wohl", "wert", ",", "bis", "zum", "Hel\u00b7ler", "mag", "sein", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "PPER", "ADV", "ADJD", "$,", "KOUS", "APPRART", "NN", "VMFIN", "VAINF", "$."], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}}, "stanza.19": {"line.1": {"text": "Zum zweiten soll ich ihm berechnen und sagen:", "tokens": ["Zum", "zwei\u00b7ten", "soll", "ich", "ihm", "be\u00b7rech\u00b7nen", "und", "sa\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "VMFIN", "PPER", "PPER", "VVFIN", "KON", "VVINF", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Wie bald er zu Rosse die Welt mag umjagen?", "tokens": ["Wie", "bald", "er", "zu", "Ros\u00b7se", "die", "Welt", "mag", "um\u00b7ja\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "PPER", "APPR", "NN", "ART", "NN", "VMFIN", "VVINF", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.3": {"text": "Um keine Minute zu wenig und viel!", "tokens": ["Um", "kei\u00b7ne", "Mi\u00b7nu\u00b7te", "zu", "we\u00b7nig", "und", "viel", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PIAT", "NN", "APPR", "PIS", "KON", "ADV", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "Er meint, der Bescheid darauf w\u00e4re nur Spiel.", "tokens": ["Er", "meint", ",", "der", "Be\u00b7scheid", "da\u00b7rauf", "w\u00e4\u00b7re", "nur", "Spiel", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "ART", "NN", "PAV", "VAFIN", "ADV", "NN", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}}, "stanza.20": {"line.1": {"text": "Zum dritten, ich \u00e4rmster von allen Pr\u00e4laten,", "tokens": ["Zum", "drit\u00b7ten", ",", "ich", "\u00e4rms\u00b7ter", "von", "al\u00b7len", "Pr\u00e4\u00b7la\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "$,", "PPER", "ADJD", "APPR", "PIAT", "NN", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.2": {"text": "Soll ich ihm gar seine Gedanken erraten;", "tokens": ["Soll", "ich", "ihm", "gar", "sei\u00b7ne", "Ge\u00b7dan\u00b7ken", "er\u00b7ra\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PPER", "ADV", "PPOSAT", "NN", "VVINF", "$."], "meter": "+---+--+--+-", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "Die will er mir treulich bekennen: allein", "tokens": ["Die", "will", "er", "mir", "treu\u00b7lich", "be\u00b7ken\u00b7nen", ":", "al\u00b7lein"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["PDS", "VMFIN", "PPER", "PPER", "ADJD", "VVINF", "$.", "ADV"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "Es soll auch kein Titelchen Wahres d'ran sein.", "tokens": ["Es", "soll", "auch", "kein", "Ti\u00b7tel\u00b7chen", "Wah\u00b7res", "d'\u00b7ran", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "PIAT", "NN", "ADJA", "NE", "VAINF", "$."], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}}, "stanza.21": {"line.1": {"text": "Und kann ich ihm diese drei Fragen nicht l\u00f6sen,", "tokens": ["Und", "kann", "ich", "ihm", "die\u00b7se", "drei", "Fra\u00b7gen", "nicht", "l\u00f6\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "PPER", "PDAT", "CARD", "NN", "PTKNEG", "VVINF", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.2": {"text": "So bin ich die l\u00e4ngste Zeit Abt hier gewesen;", "tokens": ["So", "bin", "ich", "die", "l\u00e4ngs\u00b7te", "Zeit", "Abt", "hier", "ge\u00b7we\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ART", "ADJA", "NN", "NN", "ADV", "VAPP", "$."], "meter": "-+--+-++--+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "So l\u00e4\u00dft er mich f\u00fchren zu Esel durch's Land,", "tokens": ["So", "l\u00e4\u00dft", "er", "mich", "f\u00fch\u00b7ren", "zu", "E\u00b7sel", "durch's", "Land", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "VVINF", "APPR", "NN", "APPRART", "NN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "Verkehrt, statt des Zaumes, den Schwanz in der Hand.\u00ab \u2013", "tokens": ["Ver\u00b7kehrt", ",", "statt", "des", "Zau\u00b7mes", ",", "den", "Schwanz", "in", "der", "Hand", ".", "\u00ab", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["VVPP", "$,", "KOUI", "ART", "NN", "$,", "ART", "NN", "APPR", "ART", "NN", "$.", "$(", "$("], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}}, "stanza.22": {"line.1": {"text": "\u00bbnichts weiter? erwidert Hans Bendix mit Lachen,", "tokens": ["\u00bb", "nichts", "wei\u00b7ter", "?", "er\u00b7wi\u00b7dert", "Hans", "Ben\u00b7dix", "mit", "La\u00b7chen", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PIS", "PTKVZ", "$.", "VVFIN", "NE", "NE", "APPR", "NN", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.2": {"text": "Herr, gebt euch zufrieden! das will ich schon machen.", "tokens": ["Herr", ",", "gebt", "euch", "zu\u00b7frie\u00b7den", "!", "das", "will", "ich", "schon", "ma\u00b7chen", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "PPER", "ADJD", "$.", "PDS", "VMFIN", "PPER", "ADV", "VVINF", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.3": {"text": "Nur borgt mir eu'r K\u00e4ppchen, eu'r Kreuzchen und Kleid;", "tokens": ["Nur", "borgt", "mir", "eu'r", "K\u00e4pp\u00b7chen", ",", "eu'r", "Kreuzc\u00b7hen", "und", "Kleid", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPOSAT", "NN", "$,", "PPOSAT", "NN", "KON", "NN", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "So will ich schon geben den rechten Bescheid.", "tokens": ["So", "will", "ich", "schon", "ge\u00b7ben", "den", "rech\u00b7ten", "Be\u00b7scheid", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "VVINF", "ART", "ADJA", "NN", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}}, "stanza.23": {"line.1": {"text": "Versteh' ich gleich nichts von lateinischen Brocken,", "tokens": ["Ver\u00b7steh'", "ich", "gleich", "nichts", "von", "la\u00b7tei\u00b7ni\u00b7schen", "Bro\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ADV", "PIS", "APPR", "ADJA", "NN", "$,"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "So wei\u00df ich den Hund doch vom Ofen zu locken.", "tokens": ["So", "wei\u00df", "ich", "den", "Hund", "doch", "vom", "O\u00b7fen", "zu", "lo\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "ADV", "APPRART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.3": {"text": "Was ihr euch, Gelehrte, f\u00fcr Geld nicht erwerbt,", "tokens": ["Was", "ihr", "euch", ",", "Ge\u00b7lehr\u00b7te", ",", "f\u00fcr", "Geld", "nicht", "er\u00b7werbt", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "PPER", "$,", "NN", "$,", "APPR", "NN", "PTKNEG", "VVFIN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "Das hab' ich von meiner Frau Mutter geerbt.\u00ab", "tokens": ["Das", "hab'", "ich", "von", "mei\u00b7ner", "Frau", "Mut\u00b7ter", "ge\u00b7erbt", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PDS", "VAFIN", "PPER", "APPR", "PPOSAT", "NN", "NN", "VVPP", "$.", "$("], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}}, "stanza.24": {"line.1": {"text": "Da sprang, wie ein B\u00f6cklein, der Abt vor Behagen.", "tokens": ["Da", "sprang", ",", "wie", "ein", "B\u00f6c\u00b7klein", ",", "der", "Abt", "vor", "Be\u00b7ha\u00b7gen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "PWAV", "ART", "NN", "$,", "ART", "NN", "APPR", "NN", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.2": {"text": "Mit K\u00e4ppchen und Kreuzchen, mit Mantel und Kragen,", "tokens": ["Mit", "K\u00e4pp\u00b7chen", "und", "Kreuzc\u00b7hen", ",", "mit", "Man\u00b7tel", "und", "Kra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$,", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.3": {"text": "Ward stattlich Hans Bendix zum Abte geschm\u00fcckt,", "tokens": ["Ward", "statt\u00b7lich", "Hans", "Ben\u00b7dix", "zum", "Ab\u00b7te", "ge\u00b7schm\u00fcckt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "NE", "NE", "APPRART", "NN", "VVPP", "$,"], "meter": "-+---+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Und hurtig zum Kaiser nach Hofe geschickt.", "tokens": ["Und", "hur\u00b7tig", "zum", "Kai\u00b7ser", "nach", "Ho\u00b7fe", "ge\u00b7schickt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "APPRART", "NN", "APPR", "NN", "VVPP", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}}, "stanza.25": {"line.1": {"text": "Hier thronte der Kaiser im f\u00fcrstlichen Rate,", "tokens": ["Hier", "thron\u00b7te", "der", "Kai\u00b7ser", "im", "f\u00fcrst\u00b7li\u00b7chen", "Ra\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPRART", "ADJA", "NN", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.2": {"text": "Hoch prangt' er, mit Zepter und Kron' im Ornate:", "tokens": ["Hoch", "prangt'", "er", ",", "mit", "Zep\u00b7ter", "und", "Kron'", "im", "Or\u00b7na\u00b7te", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "PPER", "$,", "APPR", "NN", "KON", "NN", "APPRART", "NN", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.3": {"text": "\u00bbnun sagt mir, Herr Abt, als ein treuer Wardein,", "tokens": ["\u00bb", "nun", "sagt", "mir", ",", "Herr", "Abt", ",", "als", "ein", "treu\u00b7er", "War\u00b7dein", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VVFIN", "PPER", "$,", "NN", "NE", "$,", "KOUS", "ART", "ADJA", "NN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "Wie viel ich itzt wert, bis zum Heller, mag sein?\u00ab \u2013", "tokens": ["Wie", "viel", "ich", "itzt", "wert", ",", "bis", "zum", "Hel\u00b7ler", ",", "mag", "sein", "?", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "punct", "punct"], "pos": ["PWAV", "PIS", "PPER", "ADV", "ADJD", "$,", "KOUS", "APPRART", "NN", "$,", "VMFIN", "VAINF", "$.", "$(", "$("], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}}, "stanza.26": {"line.1": {"text": "\u00bbf\u00fcr drei\u00dfig Reichsgulden ward Christus verschachert;", "tokens": ["\u00bb", "f\u00fcr", "drei\u00b7\u00dfig", "Reichs\u00b7gul\u00b7den", "ward", "Chris\u00b7tus", "ver\u00b7scha\u00b7chert", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "CARD", "NN", "VAFIN", "NE", "VVPP", "$."], "meter": "-+-+---+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "D'rum g\u00e4b' ich, so sehr ihr auch pochet und prachert,", "tokens": ["D'\u00b7rum", "g\u00e4b'", "ich", ",", "so", "sehr", "ihr", "auch", "po\u00b7chet", "und", "pra\u00b7chert", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "$,", "ADV", "ADV", "PPER", "ADV", "VVFIN", "KON", "VVFIN", "$,"], "meter": "--+--+--+--+-", "measure": "anapaest.tetra.plus"}, "line.3": {"text": "F\u00fcr euch keinen Deut mehr, als zwanzig und neun,", "tokens": ["F\u00fcr", "euch", "kei\u00b7nen", "Deut", "mehr", ",", "als", "zwan\u00b7zig", "und", "neun", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "PIAT", "NN", "ADV", "$,", "KOUS", "CARD", "KON", "CARD", "$,"], "meter": "+-+-+--+--+", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Denn Einen m\u00fc\u00dft ihr doch wohl minder wert sein.\u00ab \u2013", "tokens": ["Denn", "Ei\u00b7nen", "m\u00fc\u00dft", "ihr", "doch", "wohl", "min\u00b7der", "wert", "sein", ".", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["KON", "ART", "VMFIN", "PPER", "ADV", "ADV", "ADV", "ADJD", "VAINF", "$.", "$(", "$("], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}}, "stanza.27": {"line.1": {"text": "\u00bbhum, sagte der Kaiser, der Grund l\u00e4\u00dft sich h\u00f6ren,", "tokens": ["\u00bb", "hum", ",", "sag\u00b7te", "der", "Kai\u00b7ser", ",", "der", "Grund", "l\u00e4\u00dft", "sich", "h\u00f6\u00b7ren", ","], "token_info": ["punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "FM.la", "$,", "VVFIN", "ART", "NN", "$,", "ART", "NN", "VVFIN", "PRF", "VVINF", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.2": {"text": "Und mag den durchlauchtigen Stolz wohl bekehren.", "tokens": ["Und", "mag", "den", "durch\u00b7lauch\u00b7ti\u00b7gen", "Stolz", "wohl", "be\u00b7keh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ART", "ADJA", "NN", "ADV", "VVINF", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.3": {"text": "Nie h\u00e4tt' ich, bei meiner hochf\u00fcrstlichen Ehr'!", "tokens": ["Nie", "h\u00e4tt'", "ich", ",", "bei", "mei\u00b7ner", "hoch\u00b7f\u00fcrst\u00b7li\u00b7chen", "Ehr'", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "$,", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "+---+-++--+", "measure": "iambic.penta.chol"}, "line.4": {"text": "Geglaubet, da\u00df so spottwohlfeil ich w\u00e4r'.", "tokens": ["Ge\u00b7glau\u00b7bet", ",", "da\u00df", "so", "spott\u00b7wohl\u00b7feil", "ich", "w\u00e4r'", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KOUS", "ADV", "KOUS", "PPER", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.28": {"line.1": {"text": "Nun aber sollst du mir berechnen und sagen:", "tokens": ["Nun", "a\u00b7ber", "sollst", "du", "mir", "be\u00b7rech\u00b7nen", "und", "sa\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VMFIN", "PPER", "PPER", "VVFIN", "KON", "VVINF", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Wie bald ich zu Rosse die Welt mag umjagen?", "tokens": ["Wie", "bald", "ich", "zu", "Ros\u00b7se", "die", "Welt", "mag", "um\u00b7ja\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "PPER", "APPR", "NN", "ART", "NN", "VMFIN", "VVINF", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.3": {"text": "Um keine Minute zu wenig und viel!", "tokens": ["Um", "kei\u00b7ne", "Mi\u00b7nu\u00b7te", "zu", "we\u00b7nig", "und", "viel", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PIAT", "NN", "APPR", "PIS", "KON", "ADV", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "Ist dir der Bescheid darauf auch nur ein Spiel?\u00ab \u2013", "tokens": ["Ist", "dir", "der", "Be\u00b7scheid", "da\u00b7rauf", "auch", "nur", "ein", "Spiel", "?", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["VAFIN", "PPER", "ART", "NN", "PAV", "ADV", "ADV", "ART", "NN", "$.", "$(", "$("], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}}, "stanza.29": {"line.1": {"text": "\u00bbherr, wenn mit der Sonn' ihr fr\u00fch sattelt und reitet,", "tokens": ["\u00bb", "herr", ",", "wenn", "mit", "der", "Sonn'", "ihr", "fr\u00fch", "sat\u00b7telt", "und", "rei\u00b7tet", ","], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PTKVZ", "$,", "KOUS", "APPR", "ART", "NN", "PPER", "ADJD", "VVFIN", "KON", "VVFIN", "$,"], "meter": "+---+--+--+-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Und stets sie in einerlei Tempo begleitet,", "tokens": ["Und", "stets", "sie", "in", "ei\u00b7ner\u00b7lei", "Tem\u00b7po", "be\u00b7glei\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "PIAT", "NN", "VVPP", "$,"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "So setz' ich mein Kreuz und mein K\u00e4ppchen daran,", "tokens": ["So", "setz'", "ich", "mein", "Kreuz", "und", "mein", "K\u00e4pp\u00b7chen", "da\u00b7ran", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPOSAT", "NN", "KON", "PPOSAT", "NN", "PAV", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "In zweimal zw\u00f6lf Stunden in alles gethan.\u00ab \u2013", "tokens": ["In", "zwei\u00b7mal", "zw\u00f6lf", "Stun\u00b7den", "in", "al\u00b7les", "ge\u00b7than", ".", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["APPR", "ADV", "CARD", "NN", "APPR", "PIS", "VVPP", "$.", "$(", "$("], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}}, "stanza.30": {"line.1": {"text": "\u00bbha, lachte der Kaiser, vortrefflicher Haber!", "tokens": ["\u00bb", "ha", ",", "lach\u00b7te", "der", "Kai\u00b7ser", ",", "vor\u00b7treff\u00b7li\u00b7cher", "Ha\u00b7ber", "!"], "token_info": ["punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "ITJ", "$,", "VVFIN", "ART", "NN", "$,", "ADJA", "NN", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.2": {"text": "Ihr futtert die Pferde mit ", "tokens": ["Ihr", "fut\u00b7tert", "die", "Pfer\u00b7de", "mit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Der Mann, der das ", "tokens": ["Der", "Mann", ",", "der", "das"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "ART"], "meter": "-+-+", "measure": "iambic.di"}, "line.4": {"text": "Hat sicher aus H\u00e4ckerling Gold schon gemacht.", "tokens": ["Hat", "si\u00b7cher", "aus", "H\u00e4\u00b7cker\u00b7ling", "Gold", "schon", "ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "APPR", "NE", "NN", "ADV", "VVPP", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}}, "stanza.31": {"line.1": {"text": "Nun aber zum dritten, nun nimm dich zusammen!", "tokens": ["Nun", "a\u00b7ber", "zum", "drit\u00b7ten", ",", "nun", "nimm", "dich", "zu\u00b7sam\u00b7men", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPRART", "ADJA", "$,", "ADV", "VVIMP", "PPER", "PTKVZ", "$."], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Sonst mu\u00df ich dich dennoch zum Esel verdammen.", "tokens": ["Sonst", "mu\u00df", "ich", "dich", "den\u00b7noch", "zum", "E\u00b7sel", "ver\u00b7dam\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PRF", "ADV", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Was denk' ich, das falsch ist? das bringe heraus!", "tokens": ["Was", "denk'", "ich", ",", "das", "falsch", "ist", "?", "das", "brin\u00b7ge", "he\u00b7raus", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "$,", "PRELS", "ADJD", "VAFIN", "$.", "PDS", "VVFIN", "PTKVZ", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "Nur bleib mir mit ", "tokens": ["Nur", "bleib", "mir", "mit"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPR"], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.32": {"line.1": {"text": "\u00bbihr denket, ich sei der Herr Abt von St. Gallen.\u00ab \u2013", "tokens": ["\u00bb", "ihr", "den\u00b7ket", ",", "ich", "sei", "der", "Herr", "Abt", "von", "St.", "Gal\u00b7len", ".", "\u00ab", "\u2013"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "abbreviation", "word", "punct", "punct", "punct"], "pos": ["$(", "PPER", "VVFIN", "$,", "PPER", "VAFIN", "ART", "NN", "NE", "APPR", "NE", "NE", "$.", "$(", "$("], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "\u00bbganz recht! Und das kann von der Wahrheit nicht fallen.\u00ab \u2013", "tokens": ["\u00bb", "ganz", "recht", "!", "Und", "das", "kann", "von", "der", "Wahr\u00b7heit", "nicht", "fal\u00b7len", ".", "\u00ab", "\u2013"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["$(", "ADV", "ADJD", "$.", "KON", "PDS", "VMFIN", "APPR", "ART", "NN", "PTKNEG", "VVINF", "$.", "$(", "$("], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.3": {"text": "\u00bbsein Diener, Herr Kaiser! Euch tr\u00fcget eu'r Sinn:", "tokens": ["\u00bb", "sein", "Die\u00b7ner", ",", "Herr", "Kai\u00b7ser", "!", "Euch", "tr\u00fc\u00b7get", "eu'r", "Sinn", ":"], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPOSAT", "NN", "$,", "NN", "NN", "$.", "PPER", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "Denn wi\u00dft, da\u00df ich Bendix, sein Sch\u00e4fer, nur bin!\u00ab \u2013", "tokens": ["Denn", "wi\u00dft", ",", "da\u00df", "ich", "Ben\u00b7dix", ",", "sein", "Sch\u00e4\u00b7fer", ",", "nur", "bin", "!", "\u00ab", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "punct", "punct"], "pos": ["KON", "VVFIN", "$,", "KOUS", "PPER", "NE", "$,", "PPOSAT", "NN", "$,", "ADV", "VAFIN", "$.", "$(", "$("], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}}, "stanza.33": {"line.1": {"text": "\u00bbwas Henker! Du bist nicht der Abt von St. Gallen?\u00ab", "tokens": ["\u00bb", "was", "Hen\u00b7ker", "!", "Du", "bist", "nicht", "der", "Abt", "von", "St.", "Gal\u00b7len", "?", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "abbreviation", "word", "punct", "punct"], "pos": ["$(", "PWS", "NN", "$.", "PPER", "VAFIN", "PTKNEG", "ART", "NN", "APPR", "NE", "NE", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Rief hurtig, als w\u00e4r' er vom Himmel gefallen,", "tokens": ["Rief", "hur\u00b7tig", ",", "als", "w\u00e4r'", "er", "vom", "Him\u00b7mel", "ge\u00b7fal\u00b7len", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "$,", "KOKOM", "VAFIN", "PPER", "APPRART", "NN", "VVPP", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.3": {"text": "Der Kaiser mit frohem Erstaunen darein;", "tokens": ["Der", "Kai\u00b7ser", "mit", "fro\u00b7hem", "Er\u00b7stau\u00b7nen", "da\u00b7rein", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ADJA", "NN", "PAV", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "\u00bbwohlan denn, so sollst du von nun an es sein!", "tokens": ["\u00bb", "wo\u00b7hlan", "denn", ",", "so", "sollst", "du", "von", "nun", "an", "es", "sein", "!"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "ADV", "$,", "ADV", "VMFIN", "PPER", "APPR", "ADV", "APPR", "PPER", "VAINF", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}}, "stanza.34": {"line.1": {"text": "Ich will dich belehnen mit Ring und mit Stabe.", "tokens": ["Ich", "will", "dich", "be\u00b7leh\u00b7nen", "mit", "Ring", "und", "mit", "Sta\u00b7be", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "VVFIN", "APPR", "NN", "KON", "APPR", "NN", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.2": {"text": "Dein Vorfahr besteige den Esel und trabe!", "tokens": ["Dein", "Vor\u00b7fahr", "be\u00b7stei\u00b7ge", "den", "E\u00b7sel", "und", "tra\u00b7be", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ART", "NN", "KON", "VVFIN", "$."], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Und lerne fortan erst quid iuris verstehn!", "tokens": ["Und", "ler\u00b7ne", "for\u00b7tan", "erst", "quid", "i\u00b7u\u00b7ris", "ver\u00b7stehn", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "FM", "FM", "FM", "FM", "FM", "VVINF", "$."], "meter": "-+-+--+-+--+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Denn wenn man will ernten, so mu\u00df man auch s\u00e4'n.\u00ab \u2013", "tokens": ["Denn", "wenn", "man", "will", "ern\u00b7ten", ",", "so", "mu\u00df", "man", "auch", "s\u00e4'", "n.", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "abbreviation", "punct", "punct"], "pos": ["KON", "KOUS", "PIS", "VMFIN", "VVINF", "$,", "ADV", "VMFIN", "PIS", "ADV", "VVFIN", "NE", "$(", "$("], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}}, "stanza.35": {"line.1": {"text": "\u00bbmit Gunsten, Herr Kaiser! Das la\u00dft nur h\u00fcbsch bleiben!", "tokens": ["\u00bb", "mit", "Guns\u00b7ten", ",", "Herr", "Kai\u00b7ser", "!", "Das", "la\u00dft", "nur", "h\u00fcbsch", "blei\u00b7ben", "!"], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "NN", "$,", "NN", "NN", "$.", "PDS", "VVFIN", "ADV", "ADJD", "VVINF", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.2": {"text": "Ich kann ja nicht lesen, noch rechnen und schreiben;", "tokens": ["Ich", "kann", "ja", "nicht", "le\u00b7sen", ",", "noch", "rech\u00b7nen", "und", "schrei\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "PTKNEG", "VVINF", "$,", "ADV", "VVINF", "KON", "VVINF", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.3": {"text": "Auch wei\u00df ich kein sterbendes W\u00f6rtchen Latein.", "tokens": ["Auch", "wei\u00df", "ich", "kein", "ster\u00b7ben\u00b7des", "W\u00f6rt\u00b7chen", "La\u00b7tein."], "token_info": ["word", "word", "word", "word", "word", "word", "abbreviation"], "pos": ["ADV", "VVFIN", "PPER", "PIAT", "ADJA", "NN", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Was H\u00e4nschen vers\u00e4umet holt Hans nicht mehr ein.\u00ab \u2013", "tokens": ["Was", "H\u00e4n\u00b7schen", "ver\u00b7s\u00e4u\u00b7met", "holt", "Hans", "nicht", "mehr", "ein", ".", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PWS", "NN", "VVFIN", "VVFIN", "NE", "PTKNEG", "ADV", "PTKVZ", "$.", "$(", "$("], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}}, "stanza.36": {"line.1": {"text": "\u00bbach, guter Hans Bendix, das ist ja recht schade!", "tokens": ["\u00bb", "ach", ",", "gu\u00b7ter", "Hans", "Ben\u00b7dix", ",", "das", "ist", "ja", "recht", "scha\u00b7de", "!"], "token_info": ["punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ITJ", "$,", "ADJA", "NE", "NE", "$,", "PDS", "VAFIN", "ADV", "ADJD", "VVFIN", "$."], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Erbitte demnach dir ein' andere Gnade!", "tokens": ["Er\u00b7bit\u00b7te", "dem\u00b7nach", "dir", "ein'", "an\u00b7de\u00b7re", "Gna\u00b7de", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PAV", "PPER", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Sehr hat mich erg\u00f6tzet dein lustiger Schwank:", "tokens": ["Sehr", "hat", "mich", "er\u00b7g\u00f6t\u00b7zet", "dein", "lus\u00b7ti\u00b7ger", "Schwank", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "VVFIN", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "D'rum soll dich auch wieder erg\u00f6tzen mein Dank.\u00ab \u2013", "tokens": ["D'\u00b7rum", "soll", "dich", "auch", "wie\u00b7der", "er\u00b7g\u00f6t\u00b7zen", "mein", "Dank", ".", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PAV", "VMFIN", "PPER", "ADV", "ADV", "VVFIN", "PPOSAT", "NN", "$.", "$(", "$("], "meter": "+-+--+--+--+", "measure": "trochaic.penta.relaxed"}}, "stanza.37": {"line.1": {"text": "\u00bbherr Kaiser, gro\u00df hab' ich so eben nichts n\u00f6tig:", "tokens": ["\u00bb", "herr", "Kai\u00b7ser", ",", "gro\u00df", "hab'", "ich", "so", "e\u00b7ben", "nichts", "n\u00f6\u00b7tig", ":"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "NN", "NN", "$,", "ADJD", "VAFIN", "PPER", "ADV", "ADV", "PIS", "ADJD", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Doch seid ihr im Ernst mir zu Gnaden erb\u00f6tig,", "tokens": ["Doch", "seid", "ihr", "im", "Ernst", "mir", "zu", "Gna\u00b7den", "er\u00b7b\u00f6\u00b7tig", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "APPRART", "NN", "PPER", "APPR", "NN", "ADJD", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.3": {"text": "So will ich mir bitten zum ehrlichen Lohn,", "tokens": ["So", "will", "ich", "mir", "bit\u00b7ten", "zum", "ehr\u00b7li\u00b7chen", "Lohn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PPER", "VVFIN", "APPRART", "ADJA", "NN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "F\u00fcr meinen hochw\u00fcrdigen Herren Pardon.\u00ab \u2013", "tokens": ["F\u00fcr", "mei\u00b7nen", "hoch\u00b7w\u00fcr\u00b7di\u00b7gen", "Her\u00b7ren", "Par\u00b7don", ".", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "NN", "$.", "$(", "$("], "meter": "-+-+---+--+", "measure": "iambic.tetra.chol"}}, "stanza.38": {"line.1": {"text": "\u00bbha bravo! Du tr\u00e4gst, wie ich merke, Geselle,", "tokens": ["\u00bb", "ha", "bra\u00b7vo", "!", "Du", "tr\u00e4gst", ",", "wie", "ich", "mer\u00b7ke", ",", "Ge\u00b7sel\u00b7le", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["$(", "ITJ", "ITJ", "$.", "PPER", "VVFIN", "$,", "PWAV", "PPER", "VVFIN", "$,", "NN", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.2": {"text": "Das Herz, wie den Kopf, auf der richtigen Stelle.", "tokens": ["Das", "Herz", ",", "wie", "den", "Kopf", ",", "auf", "der", "rich\u00b7ti\u00b7gen", "Stel\u00b7le", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PWAV", "ART", "NN", "$,", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.3": {"text": "D'rum sei der Pardon ihm in Gnaden gew\u00e4hrt,", "tokens": ["D'\u00b7rum", "sei", "der", "Par\u00b7don", "ihm", "in", "Gna\u00b7den", "ge\u00b7w\u00e4hrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "ART", "NN", "PPER", "APPR", "NN", "VVPP", "$,"], "meter": "--+--+--+--+", "measure": "anapaest.tetra.plus"}, "line.4": {"text": "Und obenein dir ein Panisbrief beschert:", "tokens": ["Und", "o\u00b7be\u00b7nein", "dir", "ein", "Pa\u00b7nis\u00b7brief", "be\u00b7schert", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PPER", "ART", "NN", "VVPP", "$."], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}}, "stanza.39": {"line.1": {"text": "Wir lassen dem Abt von St. Gallen entbieten:", "tokens": ["Wir", "las\u00b7sen", "dem", "Abt", "von", "St.", "Gal\u00b7len", "ent\u00b7bie\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "abbreviation", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "NE", "NE", "VVFIN", "$."], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Hans Bendix soll ihm nicht die Schafe mehr h\u00fcten.", "tokens": ["Hans", "Ben\u00b7dix", "soll", "ihm", "nicht", "die", "Scha\u00b7fe", "mehr", "h\u00fc\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VMFIN", "PPER", "PTKNEG", "ART", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Der Abt soll sein pflegen, nach unserm Gebot,", "tokens": ["Der", "Abt", "soll", "sein", "pfle\u00b7gen", ",", "nach", "un\u00b7serm", "Ge\u00b7bot", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PPOSAT", "VVINF", "$,", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "Umsonst, bis an seinen sanftseligen Tod.\u00ab", "tokens": ["Um\u00b7sonst", ",", "bis", "an", "sei\u00b7nen", "sanft\u00b7se\u00b7li\u00b7gen", "Tod", ".", "\u00ab"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "$,", "KOUS", "APPR", "PPOSAT", "ADJA", "NN", "$.", "$("], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}}, "stanza.40": {"line.1": {"text": "Ich will euch erz\u00e4hlen ein M\u00e4rchen, gar schnurrig:", "tokens": ["Ich", "will", "euch", "er\u00b7z\u00e4h\u00b7len", "ein", "M\u00e4r\u00b7chen", ",", "gar", "schnur\u00b7rig", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "VVFIN", "ART", "NN", "$,", "ADV", "ADJD", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.2": {"text": "Es war 'mal ein Kaiser; der Kaiser war kurrig;", "tokens": ["Es", "war", "'mal", "ein", "Kai\u00b7ser", ";", "der", "Kai\u00b7ser", "war", "kur\u00b7rig", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ART", "NN", "$.", "ART", "NN", "VAFIN", "ADJD", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.3": {"text": "Auch war 'mal ein Abt, ein gar stattlicher Herr;", "tokens": ["Auch", "war", "'mal", "ein", "Abt", ",", "ein", "gar", "statt\u00b7li\u00b7cher", "Herr", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "ART", "NN", "$,", "ART", "ADV", "ADJA", "NN", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "Nur schade! sein Sch\u00e4fer war kl\u00fcger, als Er.", "tokens": ["Nur", "scha\u00b7de", "!", "sein", "Sch\u00e4\u00b7fer", "war", "kl\u00fc\u00b7ger", ",", "als", "Er", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$.", "PPOSAT", "NN", "VAFIN", "ADJD", "$,", "KOUS", "PPER", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}}, "stanza.41": {"line.1": {"text": "Dem Kaiser ward's sauer in Hitz' und in K\u00e4lte:", "tokens": ["Dem", "Kai\u00b7ser", "ward's", "sau\u00b7er", "in", "Hitz'", "und", "in", "K\u00e4l\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "APPR", "NN", "KON", "APPR", "NN", "$."], "meter": "-+-+---+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Oft schlief er bepanzert im Kriegesgezelte;", "tokens": ["Oft", "schlief", "er", "be\u00b7pan\u00b7zert", "im", "Krie\u00b7ges\u00b7ge\u00b7zel\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "VVFIN", "APPRART", "NN", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.3": {"text": "Oft hatt' er kaum Wasser zu Schwarzbrot und Wurst;", "tokens": ["Oft", "hatt'", "er", "kaum", "Was\u00b7ser", "zu", "Schwarz\u00b7brot", "und", "Wurst", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "NN", "APPR", "NN", "KON", "NN", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "Und \u00f6fter noch litt' er gar Hunger und Durst.", "tokens": ["Und", "\u00f6f\u00b7ter", "noch", "litt'", "er", "gar", "Hun\u00b7ger", "und", "Durst", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "VVFIN", "PPER", "ADV", "NN", "KON", "NN", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}}, "stanza.42": {"line.1": {"text": "Das Pf\u00e4fflein, das wu\u00dfte sich besser zu hegen,", "tokens": ["Das", "Pf\u00e4f\u00b7flein", ",", "das", "wu\u00df\u00b7te", "sich", "bes\u00b7ser", "zu", "he\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PDS", "VVFIN", "PRF", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.2": {"text": "Und weidlich am Tisch und im Bette zu pflegen.", "tokens": ["Und", "weid\u00b7lich", "am", "Tisch", "und", "im", "Bet\u00b7te", "zu", "pfle\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "APPRART", "NN", "KON", "APPRART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.3": {"text": "Wie Vollmond gl\u00e4nzte sein feinstes Gesicht.", "tokens": ["Wie", "Voll\u00b7mond", "gl\u00e4nz\u00b7te", "sein", "feins\u00b7tes", "Ge\u00b7sicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "VVFIN", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Drei M\u00e4nner umspannten den Schmerbauch ihm nicht.", "tokens": ["Drei", "M\u00e4n\u00b7ner", "um\u00b7spann\u00b7ten", "den", "Schmer\u00b7bauch", "ihm", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "VVFIN", "ART", "NN", "PPER", "PTKNEG", "$."], "meter": "-+--+--++-+", "measure": "iambic.penta.relaxed"}}, "stanza.43": {"line.1": {"text": "D'rob suchte der Kaiser am Pf\u00e4fflein oft Hader.", "tokens": ["D'\u00b7rob", "such\u00b7te", "der", "Kai\u00b7ser", "am", "Pf\u00e4f\u00b7flein", "oft", "Ha\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPRART", "NN", "ADV", "NN", "$."], "meter": "+-+--+--+--+-", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Einst ritt er, mit reisigem Kriegesgeschwader,", "tokens": ["Einst", "ritt", "er", ",", "mit", "rei\u00b7si\u00b7gem", "Krie\u00b7ges\u00b7ge\u00b7schwa\u00b7der", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.3": {"text": "In brennender Hitze des Sommers vorbei.", "tokens": ["In", "bren\u00b7nen\u00b7der", "Hit\u00b7ze", "des", "Som\u00b7mers", "vor\u00b7bei", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ART", "NN", "PTKVZ", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "Das Pf\u00e4fflein spazierte vor seiner Abtei.", "tokens": ["Das", "Pf\u00e4f\u00b7flein", "spa\u00b7zier\u00b7te", "vor", "sei\u00b7ner", "Ab\u00b7tei", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}}, "stanza.44": {"line.1": {"text": "\u00bbha, dachte der Kaiser, zur gl\u00fccklichen Stunde!\u00ab", "tokens": ["\u00bb", "ha", ",", "dach\u00b7te", "der", "Kai\u00b7ser", ",", "zur", "gl\u00fcck\u00b7li\u00b7chen", "Stun\u00b7de", "!", "\u00ab"], "token_info": ["punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ITJ", "$,", "VVFIN", "ART", "NN", "$,", "APPRART", "ADJA", "NN", "$.", "$("], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.2": {"text": "Und gr\u00fc\u00dfte das Pf\u00e4fflein mit h\u00f6hnischem Munde:", "tokens": ["Und", "gr\u00fc\u00df\u00b7te", "das", "Pf\u00e4f\u00b7flein", "mit", "h\u00f6h\u00b7ni\u00b7schem", "Mun\u00b7de", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.3": {"text": "\u00bbknecht Gottes, wie geht's dir? Mir d\u00e4ucht wohl ganz recht,", "tokens": ["\u00bb", "knecht", "Got\u00b7tes", ",", "wie", "geht's", "dir", "?", "Mir", "d\u00e4ucht", "wohl", "ganz", "recht", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "NN", "$,", "PWAV", "VVFIN", "PPER", "$.", "PPER", "VVFIN", "ADV", "ADV", "ADJD", "$,"], "meter": "-+--+-+---+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Das Beten und Fasten bekomme nicht schlecht.", "tokens": ["Das", "Be\u00b7ten", "und", "Fas\u00b7ten", "be\u00b7kom\u00b7me", "nicht", "schlecht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "VVFIN", "PTKNEG", "ADJD", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}}, "stanza.45": {"line.1": {"text": "Doch d\u00e4ucht mir daneben, euch plage viel Weile.", "tokens": ["Doch", "d\u00e4ucht", "mir", "da\u00b7ne\u00b7ben", ",", "euch", "pla\u00b7ge", "viel", "Wei\u00b7le", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PAV", "$,", "PPER", "VVFIN", "PIAT", "NN", "$."], "meter": "-+-+---+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Ihr dankt mir's wohl, wenn ich euch Arbeit erteile,", "tokens": ["Ihr", "dankt", "mir's", "wohl", ",", "wenn", "ich", "euch", "Ar\u00b7beit", "er\u00b7tei\u00b7le", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NE", "ADV", "$,", "KOUS", "PPER", "PPER", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Man r\u00fchmet, ihr w\u00e4ret der pfiffigste Mann,", "tokens": ["Man", "r\u00fch\u00b7met", ",", "ihr", "w\u00e4\u00b7ret", "der", "pfif\u00b7figs\u00b7te", "Mann", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "$,", "PPER", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+--+---+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Ihr h\u00f6rtet das Gr\u00e4schen fast wachsen, sagt man.", "tokens": ["Ihr", "h\u00f6r\u00b7tet", "das", "Gr\u00e4sc\u00b7hen", "fast", "wach\u00b7sen", ",", "sagt", "man", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADV", "VVINF", "$,", "VVFIN", "PIS", "$."], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}}, "stanza.46": {"line.1": {"text": "So geb' ich denn euren zwei t\u00fcchtigen Backen", "tokens": ["So", "geb'", "ich", "denn", "eu\u00b7ren", "zwei", "t\u00fcch\u00b7ti\u00b7gen", "Ba\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "PPOSAT", "CARD", "ADJA", "NN"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.2": {"text": "Zur Kurzweil drei artige N\u00fcsse zu knacken.", "tokens": ["Zur", "Kurz\u00b7weil", "drei", "ar\u00b7ti\u00b7ge", "N\u00fcs\u00b7se", "zu", "kna\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "CARD", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.3": {"text": "Drei Monden von nun an bestimm' ich zur Zeit.", "tokens": ["Drei", "Mon\u00b7den", "von", "nun", "an", "be\u00b7stimm'", "ich", "zur", "Zeit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "APPR", "ADV", "APZR", "VVFIN", "PPER", "APPRART", "NN", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.4": {"text": "Dann will ich auf diese drei Fragen Bescheid.", "tokens": ["Dann", "will", "ich", "auf", "die\u00b7se", "drei", "Fra\u00b7gen", "Be\u00b7scheid", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "APPR", "PDAT", "CARD", "NN", "NN", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}}, "stanza.47": {"line.1": {"text": "Zum ersten: Wann hoch ich, im f\u00fcrstlichen Rate,", "tokens": ["Zum", "ers\u00b7ten", ":", "Wann", "hoch", "ich", ",", "im", "f\u00fcrst\u00b7li\u00b7chen", "Ra\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "$.", "PWAV", "ADJD", "PPER", "$,", "APPRART", "ADJA", "NN", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.2": {"text": "Zu Throne mich zeige im Kaiserornate,", "tokens": ["Zu", "Thro\u00b7ne", "mich", "zei\u00b7ge", "im", "Kai\u00b7ser\u00b7or\u00b7na\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PPER", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.3": {"text": "Dann sollt ihr mir sagen, ein treuer Wardein,", "tokens": ["Dann", "sollt", "ihr", "mir", "sa\u00b7gen", ",", "ein", "treu\u00b7er", "War\u00b7dein", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PPER", "VVINF", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+--+--+---", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Wie viel ich wohl wert, bis zum Heller mag sein?", "tokens": ["Wie", "viel", "ich", "wohl", "wert", ",", "bis", "zum", "Hel\u00b7ler", "mag", "sein", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "PPER", "ADV", "ADJD", "$,", "KOUS", "APPRART", "NN", "VMFIN", "VAINF", "$."], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}}, "stanza.48": {"line.1": {"text": "Zum zweiten sollt ihr mir berechnen und sagen:", "tokens": ["Zum", "zwei\u00b7ten", "sollt", "ihr", "mir", "be\u00b7rech\u00b7nen", "und", "sa\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "VMFIN", "PPER", "PPER", "VVFIN", "KON", "VVINF", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Wie bald ich zu Rosse die Welt mag umjagen?", "tokens": ["Wie", "bald", "ich", "zu", "Ros\u00b7se", "die", "Welt", "mag", "um\u00b7ja\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "PPER", "APPR", "NN", "ART", "NN", "VMFIN", "VVINF", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.3": {"text": "Um keine Minute zu wenig und viel!", "tokens": ["Um", "kei\u00b7ne", "Mi\u00b7nu\u00b7te", "zu", "we\u00b7nig", "und", "viel", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PIAT", "NN", "APPR", "PIS", "KON", "ADV", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "Ich wei\u00df der Bescheid darauf ist euch nur Spiel.", "tokens": ["Ich", "wei\u00df", "der", "Be\u00b7scheid", "da\u00b7rauf", "ist", "euch", "nur", "Spiel", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "PAV", "VAFIN", "PPER", "ADV", "NN", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}}, "stanza.49": {"line.1": {"text": "Zum dritten noch sollst du, o Preis der Pr\u00e4laten,", "tokens": ["Zum", "drit\u00b7ten", "noch", "sollst", "du", ",", "o", "Preis", "der", "Pr\u00e4\u00b7la\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "ADV", "VMFIN", "PPER", "$,", "FM", "NN", "ART", "NN", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.2": {"text": "Aufs H\u00e4rchen mir meine Gedanken erraten.", "tokens": ["Aufs", "H\u00e4r\u00b7chen", "mir", "mei\u00b7ne", "Ge\u00b7dan\u00b7ken", "er\u00b7ra\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PPER", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.3": {"text": "Die will ich dann treulich bekennen: allein", "tokens": ["Die", "will", "ich", "dann", "treu\u00b7lich", "be\u00b7ken\u00b7nen", ":", "al\u00b7lein"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["PDS", "VMFIN", "PPER", "ADV", "ADJD", "VVINF", "$.", "ADV"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "Es soll auch kein Titelchen Wahres d'ran sein.", "tokens": ["Es", "soll", "auch", "kein", "Ti\u00b7tel\u00b7chen", "Wah\u00b7res", "d'\u00b7ran", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "PIAT", "NN", "ADJA", "NE", "VAINF", "$."], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}}, "stanza.50": {"line.1": {"text": "Und k\u00f6nnt ihr mir diese drei Fragen nicht l\u00f6sen,", "tokens": ["Und", "k\u00f6nnt", "ihr", "mir", "die\u00b7se", "drei", "Fra\u00b7gen", "nicht", "l\u00f6\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PPER", "PDAT", "CARD", "NN", "PTKNEG", "VVINF", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.2": {"text": "So seid ihr die l\u00e4ngste Zeit Abt hier gewesen;", "tokens": ["So", "seid", "ihr", "die", "l\u00e4ngs\u00b7te", "Zeit", "Abt", "hier", "ge\u00b7we\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ART", "ADJA", "NN", "NN", "ADV", "VAPP", "$."], "meter": "-+--+-++--+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "So lass' ich euch f\u00fchren zu Esel durchs Land,", "tokens": ["So", "lass'", "ich", "euch", "f\u00fch\u00b7ren", "zu", "E\u00b7sel", "durchs", "Land", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "VVFIN", "APPR", "NN", "APPRART", "NN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "Verkehrt, statt des Zaumes, den Schwanz in der Hand.\u00ab \u2013", "tokens": ["Ver\u00b7kehrt", ",", "statt", "des", "Zau\u00b7mes", ",", "den", "Schwanz", "in", "der", "Hand", ".", "\u00ab", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["VVPP", "$,", "KOUI", "ART", "NN", "$,", "ART", "NN", "APPR", "ART", "NN", "$.", "$(", "$("], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}}, "stanza.51": {"line.1": {"text": "D'rauf trabte der Kaiser mit Lachen von hinnen.", "tokens": ["D'\u00b7rauf", "trab\u00b7te", "der", "Kai\u00b7ser", "mit", "La\u00b7chen", "von", "hin\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "ART", "NN", "APPR", "NN", "APPR", "ADV", "$."], "meter": "--+--+--+--+-", "measure": "anapaest.tetra.plus"}, "line.2": {"text": "Das Pf\u00e4fflein zerri\u00df und zerspli\u00df sich mit Sinnen.", "tokens": ["Das", "Pf\u00e4f\u00b7flein", "zer\u00b7ri\u00df", "und", "zer\u00b7spli\u00df", "sich", "mit", "Sin\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "KON", "VVFIN", "PRF", "APPR", "NN", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.3": {"text": "Kein armer Verbrecher f\u00fchlt mehr Schwulit\u00e4t,", "tokens": ["Kein", "ar\u00b7mer", "Ver\u00b7bre\u00b7cher", "f\u00fchlt", "mehr", "Schwu\u00b7li\u00b7t\u00e4t", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "VVFIN", "PIAT", "NN", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Der vor hochnotpeinlichem Halsgericht steht.", "tokens": ["Der", "vor", "hoch\u00b7not\u00b7pein\u00b7li\u00b7chem", "Hals\u00b7ge\u00b7richt", "steht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "--+-+--+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.52": {"line.1": {"text": "Er schickte nach ein, zwei, drei, vier Un'vers't\u00e4ten,", "tokens": ["Er", "schick\u00b7te", "nach", "ein", ",", "zwei", ",", "drei", ",", "vier", "Un'\u00b7ver\u00b7s'\u00b7t\u00e4\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "$,", "CARD", "$,", "CARD", "$,", "CARD", "NN", "$,"], "meter": "-+------+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Er fragte bei ein, zwei, drei, vier Fakult\u00e4ten,", "tokens": ["Er", "frag\u00b7te", "bei", "ein", ",", "zwei", ",", "drei", ",", "vier", "Fa\u00b7kul\u00b7t\u00e4\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "$,", "CARD", "$,", "CARD", "$,", "CARD", "NN", "$,"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Er zahlte Geb\u00fchren und Sportuln vollauf:", "tokens": ["Er", "zahl\u00b7te", "Ge\u00b7b\u00fch\u00b7ren", "und", "Spor\u00b7tuln", "vol\u00b7lauf", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "KON", "NN", "PTKVZ", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "Doch l\u00f6ste kein Doktor die Fragen ihm auf.", "tokens": ["Doch", "l\u00f6s\u00b7te", "kein", "Dok\u00b7tor", "die", "Fra\u00b7gen", "ihm", "auf", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIAT", "NN", "ART", "NN", "PPER", "PTKVZ", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}}, "stanza.53": {"line.1": {"text": "Schnell wuchsen, bei herzlichem Zagen und Pochen,", "tokens": ["Schnell", "wuch\u00b7sen", ",", "bei", "herz\u00b7li\u00b7chem", "Za\u00b7gen", "und", "Po\u00b7chen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "$,", "APPR", "ADJA", "NN", "KON", "NN", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.2": {"text": "Die Stunden zu Tagen, die Tage zu Wochen,", "tokens": ["Die", "Stun\u00b7den", "zu", "Ta\u00b7gen", ",", "die", "Ta\u00b7ge", "zu", "Wo\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "$,", "ART", "NN", "APPR", "NN", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.3": {"text": "Die Wochen zu Monden; schon kam der Termin!", "tokens": ["Die", "Wo\u00b7chen", "zu", "Mon\u00b7den", ";", "schon", "kam", "der", "Ter\u00b7min", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "$.", "ADV", "VVFIN", "ART", "NN", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "Ihm ward's vor den Augen bald gelb und bald gr\u00fcn.", "tokens": ["Ihm", "ward's", "vor", "den", "Au\u00b7gen", "bald", "gelb", "und", "bald", "gr\u00fcn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "ART", "NN", "ADV", "ADJD", "KON", "ADV", "ADJD", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}}, "stanza.54": {"line.1": {"text": "Nun sucht' er, ein bleicher hohlwangiger Werther,", "tokens": ["Nun", "sucht'", "er", ",", "ein", "blei\u00b7cher", "hohl\u00b7wan\u00b7gi\u00b7ger", "Wert\u00b7her", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "ART", "ADJA", "ADJA", "NN", "$,"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "In W\u00e4ldern und Feldern die einsamsten \u00d6rter.", "tokens": ["In", "W\u00e4l\u00b7dern", "und", "Fel\u00b7dern", "die", "ein\u00b7sams\u00b7ten", "\u00d6r\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Da traf ihn, auf selten betretener Bahn,", "tokens": ["Da", "traf", "ihn", ",", "auf", "sel\u00b7ten", "be\u00b7tre\u00b7te\u00b7ner", "Bahn", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "APPR", "ADJA", "ADJA", "NN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "Hans Bendix, sein Sch\u00e4fer, am Felsenhang an.", "tokens": ["Hans", "Ben\u00b7dix", ",", "sein", "Sch\u00e4\u00b7fer", ",", "am", "Fel\u00b7sen\u00b7hang", "an", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "PPOSAT", "NN", "$,", "APPRART", "NN", "PTKVZ", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}}, "stanza.55": {"line.1": {"text": "\u00bbherr Abt, sprach Hans Bendix, was m\u00f6gt ihr euch gr\u00e4men?", "tokens": ["\u00bb", "herr", "Abt", ",", "sprach", "Hans", "Ben\u00b7dix", ",", "was", "m\u00f6gt", "ihr", "euch", "gr\u00e4\u00b7men", "?"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "NN", "NE", "$,", "VVFIN", "NE", "NE", "$,", "PWS", "VMFIN", "PPER", "PPER", "VVINF", "$."], "meter": "+-+-+--+--+-", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Ihr schwindet ja wahrlich dahin, wie ein Schemen.", "tokens": ["Ihr", "schwin\u00b7det", "ja", "wahr\u00b7lich", "da\u00b7hin", ",", "wie", "ein", "Sche\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "PAV", "$,", "PWAV", "ART", "NN", "$."], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Maria und Joseph! Wie hotzelt ihr ein!", "tokens": ["Ma\u00b7ria", "und", "Jo\u00b7se\u00b7ph", "!", "Wie", "hot\u00b7zelt", "ihr", "ein", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "NE", "$.", "PWAV", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.4": {"text": "Mein Sixchen! Es mu\u00df euch was angethan sein.\u00ab \u2013", "tokens": ["Mein", "Six\u00b7chen", "!", "Es", "mu\u00df", "euch", "was", "an\u00b7ge\u00b7than", "sein", ".", "\u00ab", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PPOSAT", "NN", "$.", "PPER", "VMFIN", "PPER", "PIS", "VVPP", "VAINF", "$.", "$(", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.56": {"line.1": {"text": "\u00bbach, guter Hans Bendix, so mu\u00df sich's wohl schicken.", "tokens": ["\u00bb", "ach", ",", "gu\u00b7ter", "Hans", "Ben\u00b7dix", ",", "so", "mu\u00df", "sich's", "wohl", "schi\u00b7cken", "."], "token_info": ["punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ITJ", "$,", "ADJA", "NE", "NE", "$,", "ADV", "VMFIN", "PIS", "ADV", "VVINF", "$."], "meter": "-+---+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Der Kaiser will gern mir am Zeuge was flicken,", "tokens": ["Der", "Kai\u00b7ser", "will", "gern", "mir", "am", "Zeu\u00b7ge", "was", "fli\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "ADV", "PPER", "APPRART", "NN", "PIS", "VVINF", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.3": {"text": "Und hat mir drei N\u00fcss' auf die Z\u00e4hne gepackt,", "tokens": ["Und", "hat", "mir", "drei", "N\u00fcss'", "auf", "die", "Z\u00e4h\u00b7ne", "ge\u00b7packt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "CARD", "NN", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.4": {"text": "Die schwerlich Beelzebub selber wohl knackt.", "tokens": ["Die", "schwer\u00b7lich", "Beel\u00b7ze\u00b7bub", "sel\u00b7ber", "wohl", "knackt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "ADV", "ADV", "VVFIN", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}}, "stanza.57": {"line.1": {"text": "Zum ersten: Wann hoch Er, im f\u00fcrstlichen Rate,", "tokens": ["Zum", "ers\u00b7ten", ":", "Wann", "hoch", "Er", ",", "im", "f\u00fcrst\u00b7li\u00b7chen", "Ra\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "$.", "PWAV", "ADJD", "PPER", "$,", "APPRART", "ADJA", "NN", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.2": {"text": "Zu Throne sich zeiget, im Kaiserornate,", "tokens": ["Zu", "Thro\u00b7ne", "sich", "zei\u00b7get", ",", "im", "Kai\u00b7ser\u00b7or\u00b7na\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "NN", "PRF", "VVFIN", "$,", "APPRART", "NN", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.3": {"text": "Dann soll ich ihm sagen, ein treuer Wardein,", "tokens": ["Dann", "soll", "ich", "ihm", "sa\u00b7gen", ",", "ein", "treu\u00b7er", "War\u00b7dein", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PPER", "VVINF", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+--+--+---", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Wie viel er wohl wert, bis zum Heller mag sein?", "tokens": ["Wie", "viel", "er", "wohl", "wert", ",", "bis", "zum", "Hel\u00b7ler", "mag", "sein", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "PPER", "ADV", "ADJD", "$,", "KOUS", "APPRART", "NN", "VMFIN", "VAINF", "$."], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}}, "stanza.58": {"line.1": {"text": "Zum zweiten soll ich ihm berechnen und sagen:", "tokens": ["Zum", "zwei\u00b7ten", "soll", "ich", "ihm", "be\u00b7rech\u00b7nen", "und", "sa\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "VMFIN", "PPER", "PPER", "VVFIN", "KON", "VVINF", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Wie bald er zu Rosse die Welt mag umjagen?", "tokens": ["Wie", "bald", "er", "zu", "Ros\u00b7se", "die", "Welt", "mag", "um\u00b7ja\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "PPER", "APPR", "NN", "ART", "NN", "VMFIN", "VVINF", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.3": {"text": "Um keine Minute zu wenig und viel!", "tokens": ["Um", "kei\u00b7ne", "Mi\u00b7nu\u00b7te", "zu", "we\u00b7nig", "und", "viel", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PIAT", "NN", "APPR", "PIS", "KON", "ADV", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "Er meint, der Bescheid darauf w\u00e4re nur Spiel.", "tokens": ["Er", "meint", ",", "der", "Be\u00b7scheid", "da\u00b7rauf", "w\u00e4\u00b7re", "nur", "Spiel", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "ART", "NN", "PAV", "VAFIN", "ADV", "NN", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}}, "stanza.59": {"line.1": {"text": "Zum dritten, ich \u00e4rmster von allen Pr\u00e4laten,", "tokens": ["Zum", "drit\u00b7ten", ",", "ich", "\u00e4rms\u00b7ter", "von", "al\u00b7len", "Pr\u00e4\u00b7la\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "$,", "PPER", "ADJD", "APPR", "PIAT", "NN", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.2": {"text": "Soll ich ihm gar seine Gedanken erraten;", "tokens": ["Soll", "ich", "ihm", "gar", "sei\u00b7ne", "Ge\u00b7dan\u00b7ken", "er\u00b7ra\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PPER", "ADV", "PPOSAT", "NN", "VVINF", "$."], "meter": "+---+--+--+-", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "Die will er mir treulich bekennen: allein", "tokens": ["Die", "will", "er", "mir", "treu\u00b7lich", "be\u00b7ken\u00b7nen", ":", "al\u00b7lein"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["PDS", "VMFIN", "PPER", "PPER", "ADJD", "VVINF", "$.", "ADV"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "Es soll auch kein Titelchen Wahres d'ran sein.", "tokens": ["Es", "soll", "auch", "kein", "Ti\u00b7tel\u00b7chen", "Wah\u00b7res", "d'\u00b7ran", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "PIAT", "NN", "ADJA", "NE", "VAINF", "$."], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}}, "stanza.60": {"line.1": {"text": "Und kann ich ihm diese drei Fragen nicht l\u00f6sen,", "tokens": ["Und", "kann", "ich", "ihm", "die\u00b7se", "drei", "Fra\u00b7gen", "nicht", "l\u00f6\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "PPER", "PDAT", "CARD", "NN", "PTKNEG", "VVINF", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.2": {"text": "So bin ich die l\u00e4ngste Zeit Abt hier gewesen;", "tokens": ["So", "bin", "ich", "die", "l\u00e4ngs\u00b7te", "Zeit", "Abt", "hier", "ge\u00b7we\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ART", "ADJA", "NN", "NN", "ADV", "VAPP", "$."], "meter": "-+--+-++--+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "So l\u00e4\u00dft er mich f\u00fchren zu Esel durch's Land,", "tokens": ["So", "l\u00e4\u00dft", "er", "mich", "f\u00fch\u00b7ren", "zu", "E\u00b7sel", "durch's", "Land", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "VVINF", "APPR", "NN", "APPRART", "NN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "Verkehrt, statt des Zaumes, den Schwanz in der Hand.\u00ab \u2013", "tokens": ["Ver\u00b7kehrt", ",", "statt", "des", "Zau\u00b7mes", ",", "den", "Schwanz", "in", "der", "Hand", ".", "\u00ab", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["VVPP", "$,", "KOUI", "ART", "NN", "$,", "ART", "NN", "APPR", "ART", "NN", "$.", "$(", "$("], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}}, "stanza.61": {"line.1": {"text": "\u00bbnichts weiter? erwidert Hans Bendix mit Lachen,", "tokens": ["\u00bb", "nichts", "wei\u00b7ter", "?", "er\u00b7wi\u00b7dert", "Hans", "Ben\u00b7dix", "mit", "La\u00b7chen", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PIS", "PTKVZ", "$.", "VVFIN", "NE", "NE", "APPR", "NN", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.2": {"text": "Herr, gebt euch zufrieden! das will ich schon machen.", "tokens": ["Herr", ",", "gebt", "euch", "zu\u00b7frie\u00b7den", "!", "das", "will", "ich", "schon", "ma\u00b7chen", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "PPER", "ADJD", "$.", "PDS", "VMFIN", "PPER", "ADV", "VVINF", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.3": {"text": "Nur borgt mir eu'r K\u00e4ppchen, eu'r Kreuzchen und Kleid;", "tokens": ["Nur", "borgt", "mir", "eu'r", "K\u00e4pp\u00b7chen", ",", "eu'r", "Kreuzc\u00b7hen", "und", "Kleid", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPOSAT", "NN", "$,", "PPOSAT", "NN", "KON", "NN", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "So will ich schon geben den rechten Bescheid.", "tokens": ["So", "will", "ich", "schon", "ge\u00b7ben", "den", "rech\u00b7ten", "Be\u00b7scheid", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "VVINF", "ART", "ADJA", "NN", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}}, "stanza.62": {"line.1": {"text": "Versteh' ich gleich nichts von lateinischen Brocken,", "tokens": ["Ver\u00b7steh'", "ich", "gleich", "nichts", "von", "la\u00b7tei\u00b7ni\u00b7schen", "Bro\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ADV", "PIS", "APPR", "ADJA", "NN", "$,"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "So wei\u00df ich den Hund doch vom Ofen zu locken.", "tokens": ["So", "wei\u00df", "ich", "den", "Hund", "doch", "vom", "O\u00b7fen", "zu", "lo\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "ADV", "APPRART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.3": {"text": "Was ihr euch, Gelehrte, f\u00fcr Geld nicht erwerbt,", "tokens": ["Was", "ihr", "euch", ",", "Ge\u00b7lehr\u00b7te", ",", "f\u00fcr", "Geld", "nicht", "er\u00b7werbt", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "PPER", "$,", "NN", "$,", "APPR", "NN", "PTKNEG", "VVFIN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "Das hab' ich von meiner Frau Mutter geerbt.\u00ab", "tokens": ["Das", "hab'", "ich", "von", "mei\u00b7ner", "Frau", "Mut\u00b7ter", "ge\u00b7erbt", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PDS", "VAFIN", "PPER", "APPR", "PPOSAT", "NN", "NN", "VVPP", "$.", "$("], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}}, "stanza.63": {"line.1": {"text": "Da sprang, wie ein B\u00f6cklein, der Abt vor Behagen.", "tokens": ["Da", "sprang", ",", "wie", "ein", "B\u00f6c\u00b7klein", ",", "der", "Abt", "vor", "Be\u00b7ha\u00b7gen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "PWAV", "ART", "NN", "$,", "ART", "NN", "APPR", "NN", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.2": {"text": "Mit K\u00e4ppchen und Kreuzchen, mit Mantel und Kragen,", "tokens": ["Mit", "K\u00e4pp\u00b7chen", "und", "Kreuzc\u00b7hen", ",", "mit", "Man\u00b7tel", "und", "Kra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$,", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.3": {"text": "Ward stattlich Hans Bendix zum Abte geschm\u00fcckt,", "tokens": ["Ward", "statt\u00b7lich", "Hans", "Ben\u00b7dix", "zum", "Ab\u00b7te", "ge\u00b7schm\u00fcckt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "NE", "NE", "APPRART", "NN", "VVPP", "$,"], "meter": "-+---+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Und hurtig zum Kaiser nach Hofe geschickt.", "tokens": ["Und", "hur\u00b7tig", "zum", "Kai\u00b7ser", "nach", "Ho\u00b7fe", "ge\u00b7schickt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "APPRART", "NN", "APPR", "NN", "VVPP", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}}, "stanza.64": {"line.1": {"text": "Hier thronte der Kaiser im f\u00fcrstlichen Rate,", "tokens": ["Hier", "thron\u00b7te", "der", "Kai\u00b7ser", "im", "f\u00fcrst\u00b7li\u00b7chen", "Ra\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPRART", "ADJA", "NN", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.2": {"text": "Hoch prangt' er, mit Zepter und Kron' im Ornate:", "tokens": ["Hoch", "prangt'", "er", ",", "mit", "Zep\u00b7ter", "und", "Kron'", "im", "Or\u00b7na\u00b7te", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "PPER", "$,", "APPR", "NN", "KON", "NN", "APPRART", "NN", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.3": {"text": "\u00bbnun sagt mir, Herr Abt, als ein treuer Wardein,", "tokens": ["\u00bb", "nun", "sagt", "mir", ",", "Herr", "Abt", ",", "als", "ein", "treu\u00b7er", "War\u00b7dein", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VVFIN", "PPER", "$,", "NN", "NE", "$,", "KOUS", "ART", "ADJA", "NN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "Wie viel ich itzt wert, bis zum Heller, mag sein?\u00ab \u2013", "tokens": ["Wie", "viel", "ich", "itzt", "wert", ",", "bis", "zum", "Hel\u00b7ler", ",", "mag", "sein", "?", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "punct", "punct"], "pos": ["PWAV", "PIS", "PPER", "ADV", "ADJD", "$,", "KOUS", "APPRART", "NN", "$,", "VMFIN", "VAINF", "$.", "$(", "$("], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}}, "stanza.65": {"line.1": {"text": "\u00bbf\u00fcr drei\u00dfig Reichsgulden ward Christus verschachert;", "tokens": ["\u00bb", "f\u00fcr", "drei\u00b7\u00dfig", "Reichs\u00b7gul\u00b7den", "ward", "Chris\u00b7tus", "ver\u00b7scha\u00b7chert", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "CARD", "NN", "VAFIN", "NE", "VVPP", "$."], "meter": "-+-+---+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "D'rum g\u00e4b' ich, so sehr ihr auch pochet und prachert,", "tokens": ["D'\u00b7rum", "g\u00e4b'", "ich", ",", "so", "sehr", "ihr", "auch", "po\u00b7chet", "und", "pra\u00b7chert", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "$,", "ADV", "ADV", "PPER", "ADV", "VVFIN", "KON", "VVFIN", "$,"], "meter": "--+--+--+--+-", "measure": "anapaest.tetra.plus"}, "line.3": {"text": "F\u00fcr euch keinen Deut mehr, als zwanzig und neun,", "tokens": ["F\u00fcr", "euch", "kei\u00b7nen", "Deut", "mehr", ",", "als", "zwan\u00b7zig", "und", "neun", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "PIAT", "NN", "ADV", "$,", "KOUS", "CARD", "KON", "CARD", "$,"], "meter": "+-+-+--+--+", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Denn Einen m\u00fc\u00dft ihr doch wohl minder wert sein.\u00ab \u2013", "tokens": ["Denn", "Ei\u00b7nen", "m\u00fc\u00dft", "ihr", "doch", "wohl", "min\u00b7der", "wert", "sein", ".", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["KON", "ART", "VMFIN", "PPER", "ADV", "ADV", "ADV", "ADJD", "VAINF", "$.", "$(", "$("], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}}, "stanza.66": {"line.1": {"text": "\u00bbhum, sagte der Kaiser, der Grund l\u00e4\u00dft sich h\u00f6ren,", "tokens": ["\u00bb", "hum", ",", "sag\u00b7te", "der", "Kai\u00b7ser", ",", "der", "Grund", "l\u00e4\u00dft", "sich", "h\u00f6\u00b7ren", ","], "token_info": ["punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "FM.la", "$,", "VVFIN", "ART", "NN", "$,", "ART", "NN", "VVFIN", "PRF", "VVINF", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.2": {"text": "Und mag den durchlauchtigen Stolz wohl bekehren.", "tokens": ["Und", "mag", "den", "durch\u00b7lauch\u00b7ti\u00b7gen", "Stolz", "wohl", "be\u00b7keh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ART", "ADJA", "NN", "ADV", "VVINF", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.3": {"text": "Nie h\u00e4tt' ich, bei meiner hochf\u00fcrstlichen Ehr'!", "tokens": ["Nie", "h\u00e4tt'", "ich", ",", "bei", "mei\u00b7ner", "hoch\u00b7f\u00fcrst\u00b7li\u00b7chen", "Ehr'", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "$,", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "+---+-++--+", "measure": "iambic.penta.chol"}, "line.4": {"text": "Geglaubet, da\u00df so spottwohlfeil ich w\u00e4r'.", "tokens": ["Ge\u00b7glau\u00b7bet", ",", "da\u00df", "so", "spott\u00b7wohl\u00b7feil", "ich", "w\u00e4r'", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KOUS", "ADV", "KOUS", "PPER", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.67": {"line.1": {"text": "Nun aber sollst du mir berechnen und sagen:", "tokens": ["Nun", "a\u00b7ber", "sollst", "du", "mir", "be\u00b7rech\u00b7nen", "und", "sa\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VMFIN", "PPER", "PPER", "VVFIN", "KON", "VVINF", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Wie bald ich zu Rosse die Welt mag umjagen?", "tokens": ["Wie", "bald", "ich", "zu", "Ros\u00b7se", "die", "Welt", "mag", "um\u00b7ja\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "PPER", "APPR", "NN", "ART", "NN", "VMFIN", "VVINF", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.3": {"text": "Um keine Minute zu wenig und viel!", "tokens": ["Um", "kei\u00b7ne", "Mi\u00b7nu\u00b7te", "zu", "we\u00b7nig", "und", "viel", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PIAT", "NN", "APPR", "PIS", "KON", "ADV", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "Ist dir der Bescheid darauf auch nur ein Spiel?\u00ab \u2013", "tokens": ["Ist", "dir", "der", "Be\u00b7scheid", "da\u00b7rauf", "auch", "nur", "ein", "Spiel", "?", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["VAFIN", "PPER", "ART", "NN", "PAV", "ADV", "ADV", "ART", "NN", "$.", "$(", "$("], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}}, "stanza.68": {"line.1": {"text": "\u00bbherr, wenn mit der Sonn' ihr fr\u00fch sattelt und reitet,", "tokens": ["\u00bb", "herr", ",", "wenn", "mit", "der", "Sonn'", "ihr", "fr\u00fch", "sat\u00b7telt", "und", "rei\u00b7tet", ","], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PTKVZ", "$,", "KOUS", "APPR", "ART", "NN", "PPER", "ADJD", "VVFIN", "KON", "VVFIN", "$,"], "meter": "+---+--+--+-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Und stets sie in einerlei Tempo begleitet,", "tokens": ["Und", "stets", "sie", "in", "ei\u00b7ner\u00b7lei", "Tem\u00b7po", "be\u00b7glei\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "PIAT", "NN", "VVPP", "$,"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "So setz' ich mein Kreuz und mein K\u00e4ppchen daran,", "tokens": ["So", "setz'", "ich", "mein", "Kreuz", "und", "mein", "K\u00e4pp\u00b7chen", "da\u00b7ran", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPOSAT", "NN", "KON", "PPOSAT", "NN", "PAV", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "In zweimal zw\u00f6lf Stunden in alles gethan.\u00ab \u2013", "tokens": ["In", "zwei\u00b7mal", "zw\u00f6lf", "Stun\u00b7den", "in", "al\u00b7les", "ge\u00b7than", ".", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["APPR", "ADV", "CARD", "NN", "APPR", "PIS", "VVPP", "$.", "$(", "$("], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}}, "stanza.69": {"line.1": {"text": "\u00bbha, lachte der Kaiser, vortrefflicher Haber!", "tokens": ["\u00bb", "ha", ",", "lach\u00b7te", "der", "Kai\u00b7ser", ",", "vor\u00b7treff\u00b7li\u00b7cher", "Ha\u00b7ber", "!"], "token_info": ["punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "ITJ", "$,", "VVFIN", "ART", "NN", "$,", "ADJA", "NN", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.2": {"text": "Ihr futtert die Pferde mit ", "tokens": ["Ihr", "fut\u00b7tert", "die", "Pfer\u00b7de", "mit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Der Mann, der das ", "tokens": ["Der", "Mann", ",", "der", "das"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "ART"], "meter": "-+-+", "measure": "iambic.di"}, "line.4": {"text": "Hat sicher aus H\u00e4ckerling Gold schon gemacht.", "tokens": ["Hat", "si\u00b7cher", "aus", "H\u00e4\u00b7cker\u00b7ling", "Gold", "schon", "ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "APPR", "NE", "NN", "ADV", "VVPP", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}}, "stanza.70": {"line.1": {"text": "Nun aber zum dritten, nun nimm dich zusammen!", "tokens": ["Nun", "a\u00b7ber", "zum", "drit\u00b7ten", ",", "nun", "nimm", "dich", "zu\u00b7sam\u00b7men", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPRART", "ADJA", "$,", "ADV", "VVIMP", "PPER", "PTKVZ", "$."], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Sonst mu\u00df ich dich dennoch zum Esel verdammen.", "tokens": ["Sonst", "mu\u00df", "ich", "dich", "den\u00b7noch", "zum", "E\u00b7sel", "ver\u00b7dam\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PRF", "ADV", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Was denk' ich, das falsch ist? das bringe heraus!", "tokens": ["Was", "denk'", "ich", ",", "das", "falsch", "ist", "?", "das", "brin\u00b7ge", "he\u00b7raus", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "$,", "PRELS", "ADJD", "VAFIN", "$.", "PDS", "VVFIN", "PTKVZ", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "Nur bleib mir mit ", "tokens": ["Nur", "bleib", "mir", "mit"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPR"], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.71": {"line.1": {"text": "\u00bbihr denket, ich sei der Herr Abt von St. Gallen.\u00ab \u2013", "tokens": ["\u00bb", "ihr", "den\u00b7ket", ",", "ich", "sei", "der", "Herr", "Abt", "von", "St.", "Gal\u00b7len", ".", "\u00ab", "\u2013"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "abbreviation", "word", "punct", "punct", "punct"], "pos": ["$(", "PPER", "VVFIN", "$,", "PPER", "VAFIN", "ART", "NN", "NE", "APPR", "NE", "NE", "$.", "$(", "$("], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "\u00bbganz recht! Und das kann von der Wahrheit nicht fallen.\u00ab \u2013", "tokens": ["\u00bb", "ganz", "recht", "!", "Und", "das", "kann", "von", "der", "Wahr\u00b7heit", "nicht", "fal\u00b7len", ".", "\u00ab", "\u2013"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["$(", "ADV", "ADJD", "$.", "KON", "PDS", "VMFIN", "APPR", "ART", "NN", "PTKNEG", "VVINF", "$.", "$(", "$("], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.3": {"text": "\u00bbsein Diener, Herr Kaiser! Euch tr\u00fcget eu'r Sinn:", "tokens": ["\u00bb", "sein", "Die\u00b7ner", ",", "Herr", "Kai\u00b7ser", "!", "Euch", "tr\u00fc\u00b7get", "eu'r", "Sinn", ":"], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPOSAT", "NN", "$,", "NN", "NN", "$.", "PPER", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "Denn wi\u00dft, da\u00df ich Bendix, sein Sch\u00e4fer, nur bin!\u00ab \u2013", "tokens": ["Denn", "wi\u00dft", ",", "da\u00df", "ich", "Ben\u00b7dix", ",", "sein", "Sch\u00e4\u00b7fer", ",", "nur", "bin", "!", "\u00ab", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "punct", "punct"], "pos": ["KON", "VVFIN", "$,", "KOUS", "PPER", "NE", "$,", "PPOSAT", "NN", "$,", "ADV", "VAFIN", "$.", "$(", "$("], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}}, "stanza.72": {"line.1": {"text": "\u00bbwas Henker! Du bist nicht der Abt von St. Gallen?\u00ab", "tokens": ["\u00bb", "was", "Hen\u00b7ker", "!", "Du", "bist", "nicht", "der", "Abt", "von", "St.", "Gal\u00b7len", "?", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "abbreviation", "word", "punct", "punct"], "pos": ["$(", "PWS", "NN", "$.", "PPER", "VAFIN", "PTKNEG", "ART", "NN", "APPR", "NE", "NE", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Rief hurtig, als w\u00e4r' er vom Himmel gefallen,", "tokens": ["Rief", "hur\u00b7tig", ",", "als", "w\u00e4r'", "er", "vom", "Him\u00b7mel", "ge\u00b7fal\u00b7len", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "$,", "KOKOM", "VAFIN", "PPER", "APPRART", "NN", "VVPP", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.3": {"text": "Der Kaiser mit frohem Erstaunen darein;", "tokens": ["Der", "Kai\u00b7ser", "mit", "fro\u00b7hem", "Er\u00b7stau\u00b7nen", "da\u00b7rein", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ADJA", "NN", "PAV", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "\u00bbwohlan denn, so sollst du von nun an es sein!", "tokens": ["\u00bb", "wo\u00b7hlan", "denn", ",", "so", "sollst", "du", "von", "nun", "an", "es", "sein", "!"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "ADV", "$,", "ADV", "VMFIN", "PPER", "APPR", "ADV", "APPR", "PPER", "VAINF", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}}, "stanza.73": {"line.1": {"text": "Ich will dich belehnen mit Ring und mit Stabe.", "tokens": ["Ich", "will", "dich", "be\u00b7leh\u00b7nen", "mit", "Ring", "und", "mit", "Sta\u00b7be", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "VVFIN", "APPR", "NN", "KON", "APPR", "NN", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.2": {"text": "Dein Vorfahr besteige den Esel und trabe!", "tokens": ["Dein", "Vor\u00b7fahr", "be\u00b7stei\u00b7ge", "den", "E\u00b7sel", "und", "tra\u00b7be", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ART", "NN", "KON", "VVFIN", "$."], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Und lerne fortan erst quid iuris verstehn!", "tokens": ["Und", "ler\u00b7ne", "for\u00b7tan", "erst", "quid", "i\u00b7u\u00b7ris", "ver\u00b7stehn", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "FM", "FM", "FM", "FM", "FM", "VVINF", "$."], "meter": "-+-+--+-+--+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Denn wenn man will ernten, so mu\u00df man auch s\u00e4'n.\u00ab \u2013", "tokens": ["Denn", "wenn", "man", "will", "ern\u00b7ten", ",", "so", "mu\u00df", "man", "auch", "s\u00e4'", "n.", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "abbreviation", "punct", "punct"], "pos": ["KON", "KOUS", "PIS", "VMFIN", "VVINF", "$,", "ADV", "VMFIN", "PIS", "ADV", "VVFIN", "NE", "$(", "$("], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}}, "stanza.74": {"line.1": {"text": "\u00bbmit Gunsten, Herr Kaiser! Das la\u00dft nur h\u00fcbsch bleiben!", "tokens": ["\u00bb", "mit", "Guns\u00b7ten", ",", "Herr", "Kai\u00b7ser", "!", "Das", "la\u00dft", "nur", "h\u00fcbsch", "blei\u00b7ben", "!"], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "NN", "$,", "NN", "NN", "$.", "PDS", "VVFIN", "ADV", "ADJD", "VVINF", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.2": {"text": "Ich kann ja nicht lesen, noch rechnen und schreiben;", "tokens": ["Ich", "kann", "ja", "nicht", "le\u00b7sen", ",", "noch", "rech\u00b7nen", "und", "schrei\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "PTKNEG", "VVINF", "$,", "ADV", "VVINF", "KON", "VVINF", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.3": {"text": "Auch wei\u00df ich kein sterbendes W\u00f6rtchen Latein.", "tokens": ["Auch", "wei\u00df", "ich", "kein", "ster\u00b7ben\u00b7des", "W\u00f6rt\u00b7chen", "La\u00b7tein."], "token_info": ["word", "word", "word", "word", "word", "word", "abbreviation"], "pos": ["ADV", "VVFIN", "PPER", "PIAT", "ADJA", "NN", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Was H\u00e4nschen vers\u00e4umet holt Hans nicht mehr ein.\u00ab \u2013", "tokens": ["Was", "H\u00e4n\u00b7schen", "ver\u00b7s\u00e4u\u00b7met", "holt", "Hans", "nicht", "mehr", "ein", ".", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PWS", "NN", "VVFIN", "VVFIN", "NE", "PTKNEG", "ADV", "PTKVZ", "$.", "$(", "$("], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}}, "stanza.75": {"line.1": {"text": "\u00bbach, guter Hans Bendix, das ist ja recht schade!", "tokens": ["\u00bb", "ach", ",", "gu\u00b7ter", "Hans", "Ben\u00b7dix", ",", "das", "ist", "ja", "recht", "scha\u00b7de", "!"], "token_info": ["punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ITJ", "$,", "ADJA", "NE", "NE", "$,", "PDS", "VAFIN", "ADV", "ADJD", "VVFIN", "$."], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Erbitte demnach dir ein' andere Gnade!", "tokens": ["Er\u00b7bit\u00b7te", "dem\u00b7nach", "dir", "ein'", "an\u00b7de\u00b7re", "Gna\u00b7de", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PAV", "PPER", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Sehr hat mich erg\u00f6tzet dein lustiger Schwank:", "tokens": ["Sehr", "hat", "mich", "er\u00b7g\u00f6t\u00b7zet", "dein", "lus\u00b7ti\u00b7ger", "Schwank", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "VVFIN", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "D'rum soll dich auch wieder erg\u00f6tzen mein Dank.\u00ab \u2013", "tokens": ["D'\u00b7rum", "soll", "dich", "auch", "wie\u00b7der", "er\u00b7g\u00f6t\u00b7zen", "mein", "Dank", ".", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PAV", "VMFIN", "PPER", "ADV", "ADV", "VVFIN", "PPOSAT", "NN", "$.", "$(", "$("], "meter": "+-+--+--+--+", "measure": "trochaic.penta.relaxed"}}, "stanza.76": {"line.1": {"text": "\u00bbherr Kaiser, gro\u00df hab' ich so eben nichts n\u00f6tig:", "tokens": ["\u00bb", "herr", "Kai\u00b7ser", ",", "gro\u00df", "hab'", "ich", "so", "e\u00b7ben", "nichts", "n\u00f6\u00b7tig", ":"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "NN", "NN", "$,", "ADJD", "VAFIN", "PPER", "ADV", "ADV", "PIS", "ADJD", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Doch seid ihr im Ernst mir zu Gnaden erb\u00f6tig,", "tokens": ["Doch", "seid", "ihr", "im", "Ernst", "mir", "zu", "Gna\u00b7den", "er\u00b7b\u00f6\u00b7tig", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "APPRART", "NN", "PPER", "APPR", "NN", "ADJD", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.3": {"text": "So will ich mir bitten zum ehrlichen Lohn,", "tokens": ["So", "will", "ich", "mir", "bit\u00b7ten", "zum", "ehr\u00b7li\u00b7chen", "Lohn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PPER", "VVFIN", "APPRART", "ADJA", "NN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "F\u00fcr meinen hochw\u00fcrdigen Herren Pardon.\u00ab \u2013", "tokens": ["F\u00fcr", "mei\u00b7nen", "hoch\u00b7w\u00fcr\u00b7di\u00b7gen", "Her\u00b7ren", "Par\u00b7don", ".", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "NN", "$.", "$(", "$("], "meter": "-+-+---+--+", "measure": "iambic.tetra.chol"}}, "stanza.77": {"line.1": {"text": "\u00bbha bravo! Du tr\u00e4gst, wie ich merke, Geselle,", "tokens": ["\u00bb", "ha", "bra\u00b7vo", "!", "Du", "tr\u00e4gst", ",", "wie", "ich", "mer\u00b7ke", ",", "Ge\u00b7sel\u00b7le", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["$(", "ITJ", "ITJ", "$.", "PPER", "VVFIN", "$,", "PWAV", "PPER", "VVFIN", "$,", "NN", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.2": {"text": "Das Herz, wie den Kopf, auf der richtigen Stelle.", "tokens": ["Das", "Herz", ",", "wie", "den", "Kopf", ",", "auf", "der", "rich\u00b7ti\u00b7gen", "Stel\u00b7le", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PWAV", "ART", "NN", "$,", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.3": {"text": "D'rum sei der Pardon ihm in Gnaden gew\u00e4hrt,", "tokens": ["D'\u00b7rum", "sei", "der", "Par\u00b7don", "ihm", "in", "Gna\u00b7den", "ge\u00b7w\u00e4hrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "ART", "NN", "PPER", "APPR", "NN", "VVPP", "$,"], "meter": "--+--+--+--+", "measure": "anapaest.tetra.plus"}, "line.4": {"text": "Und obenein dir ein Panisbrief beschert:", "tokens": ["Und", "o\u00b7be\u00b7nein", "dir", "ein", "Pa\u00b7nis\u00b7brief", "be\u00b7schert", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PPER", "ART", "NN", "VVPP", "$."], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}}, "stanza.78": {"line.1": {"text": "Wir lassen dem Abt von St. Gallen entbieten:", "tokens": ["Wir", "las\u00b7sen", "dem", "Abt", "von", "St.", "Gal\u00b7len", "ent\u00b7bie\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "abbreviation", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "NE", "NE", "VVFIN", "$."], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Hans Bendix soll ihm nicht die Schafe mehr h\u00fcten.", "tokens": ["Hans", "Ben\u00b7dix", "soll", "ihm", "nicht", "die", "Scha\u00b7fe", "mehr", "h\u00fc\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VMFIN", "PPER", "PTKNEG", "ART", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Der Abt soll sein pflegen, nach unserm Gebot,", "tokens": ["Der", "Abt", "soll", "sein", "pfle\u00b7gen", ",", "nach", "un\u00b7serm", "Ge\u00b7bot", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PPOSAT", "VVINF", "$,", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "Umsonst, bis an seinen sanftseligen Tod.\u00ab", "tokens": ["Um\u00b7sonst", ",", "bis", "an", "sei\u00b7nen", "sanft\u00b7se\u00b7li\u00b7gen", "Tod", ".", "\u00ab"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "$,", "KOUS", "APPR", "PPOSAT", "ADJA", "NN", "$.", "$("], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}}}}}