{"dta.poem.21896": {"metadata": {"author": {"name": "Stieler, Kaspar von", "birth": "N.A.", "death": "N.A."}, "title": "1.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1660", "urn": "urn:nbn:de:kobv:b4-20586-2", "language": ["de:0.99"], "booktitle": "Filidor der Dorfferer [i. e. Stieler, Kaspar von]: Die Geharnschte Venus. Hamburg, 1660."}, "poem": {"stanza.1": {"line.1": {"text": "Der Vorraht in Saturnus Welt", "tokens": ["Der", "Vor\u00b7raht", "in", "Sa\u00b7tur\u00b7nus", "Welt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "NE", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "war Korn und reiche Wolle/", "tokens": ["war", "Korn", "und", "rei\u00b7che", "Wol\u00b7le", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "KON", "ADJA", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "ein gr\u00fcner Busch/ ein Brunn ein breites", "tokens": ["ein", "gr\u00fc\u00b7ner", "Busch", "/", "ein", "Brunn", "ein", "brei\u00b7tes"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$(", "ART", "NN", "ART", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "dar lebte man ohn allen Neid und", "tokens": ["dar", "leb\u00b7te", "man", "ohn", "al\u00b7len", "Neid", "und"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PTKVZ", "VVFIN", "PIS", "APPR", "PIAT", "NN", "KON"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Sint da\u00df der Geiz und Hoffartkahm", "tokens": ["Sint", "da\u00df", "der", "Geiz", "und", "Hof\u00b7fart\u00b7kahm"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "KOUS", "ART", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "und Herrschafft nahm", "tokens": ["und", "Herr\u00b7schafft", "nahm"], "token_info": ["word", "word", "word"], "pos": ["KON", "NN", "VVFIN"], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "entstund\u2019 ein Reich des Eisens.", "tokens": ["ent\u00b7stund'", "ein", "Reich", "des", "Ei\u00b7sens", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Man wolte Gold und Sammet tra-", "tokens": ["Man", "wol\u00b7te", "Gold", "und", "Sam\u00b7met", "tra"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VMFIN", "NN", "KON", "NN", "TRUNC"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "die Einfalt samt der Tugend golte nicht.", "tokens": ["die", "Ein\u00b7falt", "samt", "der", "Tu\u00b7gend", "gol\u00b7te", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "VVFIN", "PTKNEG", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Die Sucht h\u00e4lt nu die Jungfern auch", "tokens": ["Die", "Sucht", "h\u00e4lt", "nu", "die", "Jung\u00b7fern", "auch"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ADV", "ART", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "darum werd\u2019 ich vorbey gegangen.", "tokens": ["da\u00b7rum", "werd'", "ich", "vor\u00b7bey", "ge\u00b7gan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Man liebt die Runzel-haut\u2019 den Husten", "tokens": ["Man", "liebt", "die", "Run\u00b7zel\u00b7haut'", "den", "Hus\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Weil Hektor in dem Harnisch schwizzt", "tokens": ["Weil", "Hek\u00b7tor", "in", "dem", "Har\u00b7nisch", "schwizzt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "NE", "APPR", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "liegt Paris in den weichen Federn", "tokens": ["liegt", "Pa\u00b7ris", "in", "den", "wei\u00b7chen", "Fe\u00b7dern"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "NE", "APPR", "ART", "ADJA", "NN"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "und wird in Venus-Krieg erhizzt.", "tokens": ["und", "wird", "in", "Ve\u00b7nus\u00b7Krieg", "er\u00b7hizzt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ich lobe diesen Streit/", "tokens": ["Ich", "lo\u00b7be", "die\u00b7sen", "Streit", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PDAT", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "wo Lieb\u2019 und Freundligkeit", "tokens": ["wo", "Lieb'", "und", "Freund\u00b7lig\u00b7keit"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "NN", "KON", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "mehr/ als wenn mir der Feind ist auf den", "tokens": ["mehr", "/", "als", "wenn", "mir", "der", "Feind", "ist", "auf", "den"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "$(", "KOKOM", "KOUS", "PPER", "ART", "NN", "VAFIN", "APPR", "ART"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Warum solt\u2019 ich um Reichtuhm krie-", "tokens": ["Wa\u00b7rum", "solt'", "ich", "um", "Reich\u00b7tuhm", "krie"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "VMFIN", "PPER", "APPR", "NN", "TRUNC"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "da Lieb\u2019 und Lieb\u2019 im Bette nakkend", "tokens": ["da", "Lieb'", "und", "Lieb'", "im", "Bet\u00b7te", "nak\u00b7kend"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "NN", "KON", "NN", "APPRART", "NN", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Komm/ Pylades/ zu mir/", "tokens": ["Komm", "/", "Py\u00b7la\u00b7des", "/", "zu", "mir", "/"], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "$(", "NE", "$(", "APPR", "PPER", "$("], "meter": "++-+-+", "measure": "iambic.tri"}, "line.2": {"text": "es steht dir meine T\u00fchr", "tokens": ["es", "steht", "dir", "mei\u00b7ne", "T\u00fchr"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "PPOSAT", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "zu allen Zeiten offen.", "tokens": ["zu", "al\u00b7len", "Zei\u00b7ten", "of\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Ich teile mit dir Brot und Wein/", "tokens": ["Ich", "tei\u00b7le", "mit", "dir", "Brot", "und", "Wein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPER", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "das Hau\u00df ist mein und dein.", "tokens": ["das", "Hau\u00df", "ist", "mein", "und", "dein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPOSAT", "KON", "PPOSAT", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Ich gebe dir auch gar den Schl\u00fcssel zu", "tokens": ["Ich", "ge\u00b7be", "dir", "auch", "gar", "den", "Schl\u00fcs\u00b7sel", "zu"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ADV", "ART", "NN", "PTKZU"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Di\u00df alles sey gemeine:", "tokens": ["Di\u00df", "al\u00b7les", "sey", "ge\u00b7mei\u00b7ne", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "PIS", "VAFIN", "ADJA", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "die Liebste bleibe mein alleine/", "tokens": ["die", "Liebs\u00b7te", "blei\u00b7be", "mein", "al\u00b7lei\u00b7ne", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPOSAT", "ADV", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Greiffstu mir hie zu weit; so sag\u2019 ich", "tokens": ["Greiffs\u00b7tu", "mir", "hie", "zu", "weit", ";", "so", "sag'", "ich"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NE", "PPER", "ADV", "PTKA", "ADJD", "$.", "ADV", "VVFIN", "PPER"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Geh hin/ du bist mir eine Last.", "tokens": ["Geh", "hin", "/", "du", "bist", "mir", "ei\u00b7ne", "Last", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PTKVZ", "$(", "PPER", "VAFIN", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Der sagt er sey mit dir aufs Land gefah-", "tokens": ["Der", "sagt", "er", "sey", "mit", "dir", "aufs", "Land", "ge\u00b7fah"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "PPER", "VAFIN", "APPR", "PPER", "APPRART", "NN", "TRUNC"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "er hab\u2019 auff weicher Streu\u2019", "tokens": ["er", "hab'", "auff", "wei\u00b7cher", "Streu'"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "einsmahls mit dir sich d\u00fcrffen paaren.", "tokens": ["eins\u00b7mahls", "mit", "dir", "sich", "d\u00fcrf\u00b7fen", "paa\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPER", "PRF", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "der hat mit dir zu Nacht gesessen/", "tokens": ["der", "hat", "mit", "dir", "zu", "Nacht", "ge\u00b7ses\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "APPR", "PPER", "APPR", "NN", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "der hat mit dir allein gegessen/", "tokens": ["der", "hat", "mit", "dir", "al\u00b7lein", "ge\u00b7ges\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "APPR", "PPER", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "und jener hat wol ehr", "tokens": ["und", "je\u00b7ner", "hat", "wol", "ehr"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PDS", "VAFIN", "ADV", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "dich nakkend angesehen/", "tokens": ["dich", "nak\u00b7kend", "an\u00b7ge\u00b7se\u00b7hen", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "VVPP", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "er wei\u00df an dir ein schwarzes W\u00e4rzge\u0303/", "tokens": ["er", "wei\u00df", "an", "dir", "ein", "schwar\u00b7zes", "W\u00e4rz\u00b7g\u1ebd", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPER", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Was ist denn da\u00df nun mehr?", "tokens": ["Was", "ist", "denn", "da\u00df", "nun", "mehr", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ADV", "KOUS", "ADV", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.10": {"text": "Ich la\u00df es geschehen.", "tokens": ["Ich", "la\u00df", "es", "ge\u00b7sche\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "VVPP", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.11": {"text": "Ein guter Wein", "tokens": ["Ein", "gu\u00b7ter", "Wein"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.12": {"text": "wil ja getrunken sein.", "tokens": ["wil", "ja", "ge\u00b7trun\u00b7ken", "sein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "VVPP", "VAINF", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.13": {"text": "Drum f\u00fcrcht dich nicht/ da\u00df ich dich wer-", "tokens": ["Drum", "f\u00fcrcht", "dich", "nicht", "/", "da\u00df", "ich", "dich", "wer"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "PPER", "PTKNEG", "$(", "KOUS", "PPER", "PRF", "TRUNC"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "ich w\u00fcrde dich/ werstu der sauren/ stehen", "tokens": ["ich", "w\u00fcr\u00b7de", "dich", "/", "wers\u00b7tu", "der", "sau\u00b7ren", "/", "ste\u00b7hen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["PPER", "VAFIN", "PPER", "$(", "VAFIN", "ART", "ADJA", "$(", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "Ich wiche hin zum strengen Norden/", "tokens": ["Ich", "wi\u00b7che", "hin", "zum", "stren\u00b7gen", "Nor\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPRART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "und dennoch f\u00fchlt\u2019 ich Liebe.", "tokens": ["und", "den\u00b7noch", "f\u00fchlt'", "ich", "Lie\u00b7be", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Ich bin Gradivens eigen worden/", "tokens": ["Ich", "bin", "Gra\u00b7di\u00b7vens", "ei\u00b7gen", "wor\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NN", "ADJD", "VAPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "ich pfl\u00fcgt ein hartes Feld/", "tokens": ["ich", "pfl\u00fcgt", "ein", "har\u00b7tes", "Feld", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "ich schiffte durch Ozeans Wellen-welt/", "tokens": ["ich", "schiff\u00b7te", "durch", "O\u00b7ze\u00b7ans", "Wel\u00b7len\u00b7welt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NE", "NE", "$("], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.6": {"text": "und dennoch f\u00fchlt\u2019 ich Liebe.", "tokens": ["und", "den\u00b7noch", "f\u00fchlt'", "ich", "Lie\u00b7be", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Woher? ist den\u0303 vor Liebe nicht ein Raht?", "tokens": ["Wo\u00b7her", "?", "ist", "de\u00f1", "vor", "Lie\u00b7be", "nicht", "ein", "Raht", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$.", "VAFIN", "ADV", "APPR", "NN", "PTKNEG", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Ach! jezt besinn\u2019 ich mich/ da\u00df Amor Fl\u00fc-", "tokens": ["Ach", "!", "jezt", "be\u00b7sinn'", "ich", "mich", "/", "da\u00df", "A\u00b7mor", "Fl\u00fc"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ITJ", "$.", "ADV", "VVFIN", "PPER", "PRF", "$(", "KOUS", "NE", "TRUNC"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "Was r\u00fchmstu alte Tichter-welt/", "tokens": ["Was", "r\u00fchm\u00b7stu", "al\u00b7te", "Tich\u00b7ter\u00b7welt", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "du habest durch dein Singen", "tokens": ["du", "ha\u00b7best", "durch", "dein", "Sin\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "die L\u00f6uen k\u00f6nnen zwingen/", "tokens": ["die", "L\u00f6u\u00b7en", "k\u00f6n\u00b7nen", "zwin\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "und F\u00f6ben au\u00df den Flam\u0303en bringen/", "tokens": ["und", "F\u00f6\u00b7ben", "au\u00df", "den", "Flam\u0303en", "brin\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "APPR", "ART", "NN", "VVINF", "$("], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "du habest manchen Stein an Tebens", "tokens": ["du", "ha\u00b7best", "man\u00b7chen", "Stein", "an", "Te\u00b7bens"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PIAT", "NN", "APPR", "NE"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "durch einen Leyer-klang gestellt!", "tokens": ["durch", "ei\u00b7nen", "Leyer\u00b7klang", "ge\u00b7stellt", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.7": {"text": "Kupido zog mir Seiten auff", "tokens": ["Ku\u00b7pi\u00b7do", "zog", "mir", "Sei\u00b7ten", "auff"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "PPER", "NN", "APPR"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.8": {"text": "und reichte mir den Fiedelbogen/", "tokens": ["und", "reich\u00b7te", "mir", "den", "Fie\u00b7del\u00b7bo\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ART", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "der hat die Rosilis bewogen/", "tokens": ["der", "hat", "die", "Ro\u00b7si\u00b7lis", "be\u00b7wo\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NE", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "da\u00df sie verliebet worden ist.", "tokens": ["da\u00df", "sie", "ver\u00b7lie\u00b7bet", "wor\u00b7den", "ist", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "VAPP", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Kupido sey gek\u00fc\u00dft/", "tokens": ["Ku\u00b7pi\u00b7do", "sey", "ge\u00b7k\u00fc\u00dft", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "VVPP", "$("], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.12": {"text": "du Herzen-dieb.", "tokens": ["du", "Her\u00b7zen\u00b7dieb", "."], "token_info": ["word", "word", "punct"], "pos": ["PPER", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.13": {"text": "Dein Fiedelbogen machts/ sonst w\u00e4r\u2019 ich", "tokens": ["Dein", "Fie\u00b7del\u00b7bo\u00b7gen", "machts", "/", "sonst", "w\u00e4r'", "ich"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VVFIN", "$(", "ADV", "VAFIN", "PPER"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Ach ja! Es ist ein greiser Bahrt/", "tokens": ["Ach", "ja", "!", "Es", "ist", "ein", "grei\u00b7ser", "Bahrt", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "ITJ", "$.", "PPER", "VAFIN", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "dem meine Venus nicht gef\u00e4llet/", "tokens": ["dem", "mei\u00b7ne", "Ve\u00b7nus", "nicht", "ge\u00b7f\u00e4l\u00b7let", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "PTKNEG", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "der ist von keuscher Art.", "tokens": ["der", "ist", "von", "keu\u00b7scher", "Art", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "VAFIN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "die Keuschheit stekket in den Runzeln/", "tokens": ["die", "Keuschheit", "stek\u00b7ket", "in", "den", "Run\u00b7zeln", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ART", "NN", "$("], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.5": {"text": "ich habe keine Runzeln nicht/", "tokens": ["ich", "ha\u00b7be", "kei\u00b7ne", "Run\u00b7zeln", "nicht", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIAT", "NN", "PTKNEG", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Die jungen Leute schmunzeln/", "tokens": ["Die", "jun\u00b7gen", "Leu\u00b7te", "schmun\u00b7zeln", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "wenn sie die Venus lesen:", "tokens": ["wenn", "sie", "die", "Ve\u00b7nus", "le\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "du Bleicher bleichst/ wenn du mein", "tokens": ["du", "Blei\u00b7cher", "bleichst", "/", "wenn", "du", "mein"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "NN", "VVFIN", "$(", "KOUS", "PPER", "PPOSAT"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.9": {"text": "das ist ein tolles Wesen. ", "tokens": ["das", "ist", "ein", "tol\u00b7les", "We\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.10": {"text": "Jezt f\u00e4llt mirs ein/ woher es kommen", "tokens": ["Jezt", "f\u00e4llt", "mirs", "ein", "/", "wo\u00b7her", "es", "kom\u00b7men"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "NE", "ART", "$(", "PWAV", "PPER", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "du bl\u00e4ssest/ weil du f\u00fcrchtst den J\u00fcng-", "tokens": ["du", "bl\u00e4s\u00b7sest", "/", "weil", "du", "f\u00fcrchtst", "den", "J\u00fcng"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$(", "KOUS", "PPER", "VVFIN", "ART", "TRUNC"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Verzweiflung/ Sorge/ Furcht und", "tokens": ["Ver\u00b7zwei\u00b7flung", "/", "Sor\u00b7ge", "/", "Furcht", "und"], "token_info": ["word", "punct", "word", "punct", "word", "word"], "pos": ["NN", "$(", "NN", "$(", "NN", "KON"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Schmerz/ Leiden/ Angst und Quaal/", "tokens": ["Schmerz", "/", "Lei\u00b7den", "/", "Angst", "und", "Qua\u00b7al", "/"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$(", "NN", "$(", "NN", "KON", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "ein Regiment von Gekken/", "tokens": ["ein", "Re\u00b7gi\u00b7ment", "von", "Gek\u00b7ken", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Verspottung ohne Zahl/", "tokens": ["Ver\u00b7spot\u00b7tung", "oh\u00b7ne", "Zahl", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "das ist der Liebe Leib-gedinge.", "tokens": ["das", "ist", "der", "Lie\u00b7be", "Leib\u00b7ge\u00b7din\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "wer das nicht kennt/ der wei\u00df auch", "tokens": ["wer", "das", "nicht", "kennt", "/", "der", "wei\u00df", "auch"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWS", "PDS", "PTKNEG", "VVFIN", "$(", "ART", "VVFIN", "ADV"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.7": {"text": "Sey nu geehrt/ geliebt/ gek\u00fc\u00dft/", "tokens": ["Sey", "nu", "ge\u00b7ehrt", "/", "ge\u00b7liebt", "/", "ge\u00b7k\u00fc\u00dft", "/"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["VAFIN", "ADV", "VVPP", "$(", "VVPP", "$(", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "und sey darbey ein Haubt der Narren.", "tokens": ["und", "sey", "dar\u00b7bey", "ein", "Haubt", "der", "Nar\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PAV", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Wi\u00dft ihr/ wem ich das Lieben wolte g\u00f6n-", "tokens": ["Wi\u00dft", "ihr", "/", "wem", "ich", "das", "Lie\u00b7ben", "wol\u00b7te", "g\u00f6n"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "$(", "PWS", "PPER", "ART", "ADJA", "VMFIN", "TRUNC"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "(nen.", "tokens": ["(", "nen", "."], "token_info": ["punct", "word", "punct"], "pos": ["$(", "VVINF", "$."], "meter": "-", "measure": "single.down"}, "line.11": {"text": "dem (mein\u2019 ich) der mich nie hat lieben k\u00f6n-", "tokens": ["dem", "(", "mein'", "ich", ")", "der", "mich", "nie", "hat", "lie\u00b7ben", "k\u00f6n"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "$(", "VVFIN", "PPER", "$(", "PRELS", "PPER", "ADV", "VAFIN", "ADJA", "TRUNC"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.9": {"line.1": {"text": "Die Nas\u2019 an dir ist Spannen-lang/", "tokens": ["Die", "Nas'", "an", "dir", "ist", "Span\u00b7nen\u00b7lang", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPER", "VAFIN", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "das Maul steht als ein Tohr-weg offen/", "tokens": ["das", "Maul", "steht", "als", "ein", "Tohr\u00b7weg", "of\u00b7fen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "KOKOM", "ART", "NN", "PTKVZ", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "die Z\u00e4ne sind zwey Daumen breit/", "tokens": ["die", "Z\u00e4\u00b7ne", "sind", "zwey", "Dau\u00b7men", "breit", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "CARD", "NN", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "der Wangen Schw\u00e4rz\u2019 ist Qwitten-", "tokens": ["der", "Wan\u00b7gen", "Schw\u00e4rz'", "ist", "Qwit\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "NE", "VAFIN", "TRUNC"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Der Augen Glanz sicht wie die teure Zeit:", "tokens": ["Der", "Au\u00b7gen", "Glanz", "sicht", "wie", "die", "teu\u00b7re", "Zeit", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "KOKOM", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "doch bistu stolz und h\u00e4ltst dich trefflich", "tokens": ["doch", "bis\u00b7tu", "stolz", "und", "h\u00e4ltst", "dich", "treff\u00b7lich"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "ADJD", "KON", "VVFIN", "PRF", "ADJD"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "das macht: ein Mahler hat die Venus", "tokens": ["das", "macht", ":", "ein", "Mah\u00b7ler", "hat", "die", "Ve\u00b7nus"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "$.", "ART", "NN", "VAFIN", "ART", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.8": {"text": "und Mopsa oben an geschrieben/", "tokens": ["und", "Mop\u00b7sa", "o\u00b7ben", "an", "ge\u00b7schrie\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "ADV", "APZR", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Das Bild hastu vor deines angesehn", "tokens": ["Das", "Bild", "has\u00b7tu", "vor", "dei\u00b7nes", "an\u00b7ge\u00b7sehn"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "und meinst es m\u00fc\u00df\u2019 in dich sich jederman", "tokens": ["und", "meinst", "es", "m\u00fc\u00df'", "in", "dich", "sich", "je\u00b7der\u00b7man"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "VMFIN", "APPR", "PPER", "PRF", "PIS"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.10": {"line.1": {"text": "Einst sah\u2019 ich einen alten Narren", "tokens": ["Einst", "sah'", "ich", "ei\u00b7nen", "al\u00b7ten", "Nar\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "die grauen Haare reissen au\u00df", "tokens": ["die", "grau\u00b7en", "Haa\u00b7re", "reis\u00b7sen", "au\u00df"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "vor einer Sch\u00f6nen Haus\u2019", "tokens": ["vor", "ei\u00b7ner", "Sch\u00f6\u00b7nen", "Haus'"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "und wer alldar vor\u00fcber gieng", "tokens": ["und", "wer", "all\u00b7dar", "vor\u00b7\u00fc\u00b7ber", "gieng"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PWS", "ADV", "ADV", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "hub weidlich an zulachen/", "tokens": ["hub", "weid\u00b7lich", "an", "zu\u00b7la\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "da\u00df er erst an-im Alter-fieng", "tokens": ["da\u00df", "er", "erst", "an\u00b7im", "Al\u00b7ter\u00b7fieng"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "die Liebe mit zu machen.", "tokens": ["die", "Lie\u00b7be", "mit", "zu", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Sich/ Alter/ das steht dir nicht an", "tokens": ["Sich", "/", "Al\u00b7ter", "/", "das", "steht", "dir", "nicht", "an"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PRF", "$(", "NN", "$(", "PDS", "VVFIN", "PPER", "PTKNEG", "PTKVZ"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.9": {"text": "und deines gleichen.", "tokens": ["und", "dei\u00b7nes", "glei\u00b7chen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.10": {"text": "Der Jugend/ die mit Rechte lieben kan", "tokens": ["Der", "Ju\u00b7gend", "/", "die", "mit", "Rech\u00b7te", "lie\u00b7ben", "kan"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$(", "ART", "APPR", "NN", "VVINF", "VMFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "und ihrer Liebe Zwekk erreichen/", "tokens": ["und", "ih\u00b7rer", "Lie\u00b7be", "Zwekk", "er\u00b7rei\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "NN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "der geht das Lieben hin.", "tokens": ["der", "geht", "das", "Lie\u00b7ben", "hin", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "VVFIN", "ART", "ADJA", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.13": {"text": "Drum lache nicht/ da\u00df ich verliebet bin.", "tokens": ["Drum", "la\u00b7che", "nicht", "/", "da\u00df", "ich", "ver\u00b7lie\u00b7bet", "bin", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PTKNEG", "$(", "KOUS", "PPER", "VVFIN", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.11": {"line.1": {"text": "Es ist nicht wahr/", "tokens": ["Es", "ist", "nicht", "wahr", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKNEG", "ADJD", "$("], "meter": "-+-+", "measure": "iambic.di"}, "line.2": {"text": "da\u00df Amor den und die verzaubern kan.", "tokens": ["da\u00df", "A\u00b7mor", "den", "und", "die", "ver\u00b7zau\u00b7bern", "kan", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "ART", "KON", "ART", "VVINF", "VMFIN", "$."], "meter": "-+---+-+-+", "measure": "dactylic.init"}, "line.3": {"text": "hier komt es nicht auf einen Segen an/", "tokens": ["hier", "komt", "es", "nicht", "auf", "ei\u00b7nen", "Se\u00b7gen", "an", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PTKNEG", "APPR", "ART", "NN", "PTKVZ", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "nicht auf ein w\u00e4chsern Bild.", "tokens": ["nicht", "auf", "ein", "w\u00e4ch\u00b7sern", "Bild", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Kein Kraut hegt Tessalis das zu dem Lie-", "tokens": ["Kein", "Kraut", "hegt", "Tes\u00b7sa\u00b7lis", "das", "zu", "dem", "Lie"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "VVFIN", "NE", "ART", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "kein Laubfrosch tuhts kein Jungfer-", "tokens": ["kein", "Laub\u00b7fro\u00b7sch", "tuhts", "kein", "Jung\u00b7fer"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "VVFIN", "PIAT", "TRUNC"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.7": {"text": "es ist nicht wahr.", "tokens": ["es", "ist", "nicht", "wahr", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKNEG", "ADJD", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.8": {"text": "Dir Zauberey sizzt in den Augen", "tokens": ["Dir", "Zau\u00b7be\u00b7rey", "sizzt", "in", "den", "Au\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "NN", "VVFIN", "APPR", "ART", "NN"], "meter": "-+--++-+-", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "Sich sie nicht an die Eitelkeit/", "tokens": ["Sich", "sie", "nicht", "an", "die", "Ei\u00b7tel\u00b7keit", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "PPER", "PTKNEG", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "verschweer das K\u00fcssen/", "tokens": ["ver\u00b7schweer", "das", "K\u00fcs\u00b7sen", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "ART", "NN", "$("], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.12": {"line.1": {"text": "Du sprichst: Ich liebe nicht/", "tokens": ["Du", "sprichst", ":", "Ich", "lie\u00b7be", "nicht", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "PPER", "VVFIN", "PTKNEG", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "und dein hoffertiges Gesicht", "tokens": ["und", "dein", "hof\u00b7fer\u00b7ti\u00b7ges", "Ge\u00b7sicht"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "hat bald den Spiegel durchgebohret.", "tokens": ["hat", "bald", "den", "Spie\u00b7gel", "durch\u00b7ge\u00b7boh\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Du gehst durch alle Gassen schw\u00e4nzen", "tokens": ["Du", "gehst", "durch", "al\u00b7le", "Gas\u00b7sen", "schw\u00e4n\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "PIAT", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "und findst dich gern bey Hochzeit-t\u00e4nzen.", "tokens": ["und", "findst", "dich", "gern", "bey", "Hoch\u00b7zeit\u00b7t\u00e4n\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Sonst stehstu an der T\u00fchr", "tokens": ["Sonst", "steh\u00b7stu", "an", "der", "T\u00fchr"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "APPR", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "und liegst am Fenster f\u00fcr und f\u00fcr.", "tokens": ["und", "liegst", "am", "Fens\u00b7ter", "f\u00fcr", "und", "f\u00fcr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPRART", "NN", "APPR", "KON", "APPR", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Florille/ Mein! sind di\u00df der keuschheit Werke/", "tokens": ["Flo\u00b7ril\u00b7le", "/", "Mein", "!", "sind", "di\u00df", "der", "keuschheit", "Wer\u00b7ke", "/"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "PPOSAT", "$.", "VAFIN", "PDS", "ART", "NN", "NN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "die Buhler durch die Augen anzulokke", "tokens": ["die", "Buh\u00b7ler", "durch", "die", "Au\u00b7gen", "an\u00b7zu\u00b7lok\u00b7ke"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Mein! bleibe bey dem Rokken.", "tokens": ["Mein", "!", "blei\u00b7be", "bey", "dem", "Rok\u00b7ken", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "$.", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.11": {"text": "Doch nein. Solltstu dich nicht den Leuten", "tokens": ["Doch", "nein", ".", "Sollts\u00b7tu", "dich", "nicht", "den", "Leu\u00b7ten"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "PTKANT", "$.", "VMFIN", "PPER", "PTKNEG", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "wer kennt\u2019 und w\u00fcrde dich vor eine Keusche", "tokens": ["wer", "kennt'", "und", "w\u00fcr\u00b7de", "dich", "vor", "ei\u00b7ne", "Keu\u00b7sche"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "KON", "VAFIN", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.13": {"line.1": {"text": "Gaminde wei\u00df an allen einen Tadel", "tokens": ["Ga\u00b7min\u00b7de", "wei\u00df", "an", "al\u00b7len", "ei\u00b7nen", "Ta\u00b7del"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "APPR", "PIAT", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "der ist ihr allzuklug und der ein Gekk/", "tokens": ["der", "ist", "ihr", "all\u00b7zu\u00b7klug", "und", "der", "ein", "Gekk", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "VAFIN", "PPER", "ADJD", "KON", "ART", "ART", "NN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "der ist zu still\u2019 und der zu kekk", "tokens": ["der", "ist", "zu", "still'", "und", "der", "zu", "kekk"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "VAFIN", "PTKA", "ADJD", "KON", "ART", "APPR", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "der andre pflegts zurisch zuwagen", "tokens": ["der", "and\u00b7re", "pflegts", "zu\u00b7risch", "zu\u00b7wa\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "PIS", "VVFIN", "ADJD", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "und dieser l\u00e4st sich schlagen.", "tokens": ["und", "die\u00b7ser", "l\u00e4st", "sich", "schla\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VVFIN", "PRF", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Die Arme m\u00fcssen Kurz um weichen/", "tokens": ["Die", "Ar\u00b7me", "m\u00fcs\u00b7sen", "Kurz", "um", "wei\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "ADJD", "APPR", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Und keinem ist sie doch getreu", "tokens": ["Und", "kei\u00b7nem", "ist", "sie", "doch", "ge\u00b7treu"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PIS", "VAFIN", "PPER", "ADV", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Gaminde sich dich f\u00fcr. Die Zeit fleugt fort", "tokens": ["Ga\u00b7min\u00b7de", "sich", "dich", "f\u00fcr", ".", "Die", "Zeit", "fleugt", "fort"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "PRF", "PRF", "APPR", "$.", "ART", "NN", "VVFIN", "PTKVZ"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "wie bald ist deine Sch\u00f6nheit port.", "tokens": ["wie", "bald", "ist", "dei\u00b7ne", "Sch\u00f6n\u00b7heit", "port", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "VAFIN", "PPOSAT", "NN", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Was achts Gaminde: die der Leute lachen/", "tokens": ["Was", "achts", "Ga\u00b7min\u00b7de", ":", "die", "der", "Leu\u00b7te", "la\u00b7chen", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "NN", "$.", "ART", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "kan man zulezt zu Kupplerinnen machen.", "tokens": ["kan", "man", "zu\u00b7lezt", "zu", "Kupp\u00b7le\u00b7rin\u00b7nen", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIS", "ADV", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.14": {"line.1": {"text": "Verschlie\u00df die T\u00fchr mit hundert Schl\u00f6ssern/", "tokens": ["Ver\u00b7schlie\u00df", "die", "T\u00fchr", "mit", "hun\u00b7dert", "Schl\u00f6s\u00b7sern", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "APPR", "CARD", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "der Hund steh auff der Wacht/", "tokens": ["der", "Hund", "steh", "auff", "der", "Wacht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ART", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "die Mutter schlaf\u2019 auch selbst bey ihr zu", "tokens": ["die", "Mut\u00b7ter", "schlaf'", "auch", "selbst", "bey", "ihr", "zu"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ADV", "ADV", "APPR", "PPER", "PTKZU"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "la\u00df sie nicht an der Pforten stehen/", "tokens": ["la\u00df", "sie", "nicht", "an", "der", "Pfor\u00b7ten", "ste\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "PTKNEG", "APPR", "ART", "NN", "VVFIN", "$("], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.5": {"text": "verbiet ihr das Spazieren-gehen:", "tokens": ["ver\u00b7biet", "ihr", "das", "Spa\u00b7zie\u00b7ren\u00b7ge\u00b7hen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Es ist umsonst.", "tokens": ["Es", "ist", "um\u00b7sonst", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "Die Geilheit ist als eine Mau\u00df/", "tokens": ["Die", "Geil\u00b7heit", "ist", "als", "ei\u00b7ne", "Mau\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "KOKOM", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "und \u00fcbet mehr/ als eine Kunst/", "tokens": ["und", "\u00fc\u00b7bet", "mehr", "/", "als", "ei\u00b7ne", "Kunst", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "$(", "KOUS", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "verwahrt die Tugend nicht das Hau\u00df.", "tokens": ["ver\u00b7wahrt", "die", "Tu\u00b7gend", "nicht", "das", "Hau\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "PTKNEG", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "Es ist wol ehr geschehn/", "tokens": ["Es", "ist", "wol", "ehr", "ge\u00b7schehn", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "NN", "VVPP", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "da\u00df eine hat geweinet.", "tokens": ["da\u00df", "ei\u00b7ne", "hat", "ge\u00b7wei\u00b7net", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "wenn ihr die halb-verfaulten Z\u00e4hn\u2019", "tokens": ["wenn", "ihr", "die", "halb\u00b7ver\u00b7faul\u00b7ten", "Z\u00e4hn'"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "au\u00df ihrem Munde Fleisch-lo\u00df blekkten.", "tokens": ["au\u00df", "ih\u00b7rem", "Mun\u00b7de", "Fleischlo\u00df", "blekk\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NN", "VVFIN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Und niemand hat sie denn gemeinet.", "tokens": ["Und", "nie\u00b7mand", "hat", "sie", "denn", "ge\u00b7mei\u00b7net", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VAFIN", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Es hat noch keiner dich genommen.", "tokens": ["Es", "hat", "noch", "kei\u00b7ner", "dich", "ge\u00b7nom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "PIS", "PRF", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Die Zeit kan an dich kommen/", "tokens": ["Die", "Zeit", "kan", "an", "dich", "kom\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "APPR", "PRF", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "da\u00df man dich fragt:", "tokens": ["da\u00df", "man", "dich", "fragt", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPER", "VVFIN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.9": {"text": "weistu vor mich kein sch\u00f6n Gesicht/", "tokens": ["weis\u00b7tu", "vor", "mich", "kein", "sch\u00f6n", "Ge\u00b7sicht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PPER", "PIAT", "ADJD", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "denn dich begehr ich nicht?", "tokens": ["denn", "dich", "be\u00b7gehr", "ich", "nicht", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.16": {"line.1": {"text": "Nim Gold einmahl/ und leg es in das Bette/", "tokens": ["Nim", "Gold", "ein\u00b7mahl", "/", "und", "leg", "es", "in", "das", "Bet\u00b7te", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "ADV", "$(", "KON", "NE", "PPER", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Versuch es ob es W\u00e4rme gibt", "tokens": ["Ver\u00b7such", "es", "ob", "es", "W\u00e4r\u00b7me", "gibt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "PPER", "KOUS", "PPER", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "und ob dichs wieder liebt.", "tokens": ["und", "ob", "dichs", "wie\u00b7der", "liebt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PIS", "ADV", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Ein frisches Bluht/ ein Mund mit Rosen", "tokens": ["Ein", "fri\u00b7sches", "Bluht", "/", "ein", "Mund", "mit", "Ro\u00b7sen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$(", "ART", "NN", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "das ist/ da\u00df Lieb\u2019 und Lieb\u2019 ergezzet.", "tokens": ["das", "ist", "/", "da\u00df", "Lieb'", "und", "Lieb'", "er\u00b7gez\u00b7zet", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "$(", "KOUS", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Vom Gelde mustu Alten sagen/", "tokens": ["Vom", "Gel\u00b7de", "mus\u00b7tu", "Al\u00b7ten", "sa\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VMFIN", "NN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "die sonst nichts liebens wehrt an ihren Lei-", "tokens": ["die", "sonst", "nichts", "lie\u00b7bens", "wehrt", "an", "ih\u00b7ren", "Lei"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "PIS", "ADV", "VVFIN", "APPR", "PPOSAT", "TRUNC"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Nim einen Alten hin:", "tokens": ["Nim", "ei\u00b7nen", "Al\u00b7ten", "hin", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "was gilts? du wirst einst klagen:", "tokens": ["was", "gilts", "?", "du", "wirst", "einst", "kla\u00b7gen", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "$.", "PPER", "VAFIN", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.10": {"text": "Ach! h\u00e4tte mich mein junger Sinn", "tokens": ["Ach", "!", "h\u00e4t\u00b7te", "mich", "mein", "jun\u00b7ger", "Sinn"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["ITJ", "$.", "VAFIN", "PPER", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "zu meines gleichen hingetragen!", "tokens": ["zu", "mei\u00b7nes", "glei\u00b7chen", "hin\u00b7ge\u00b7tra\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.17": {"line.1": {"text": "Ich lobte dich durch meine Leyer/", "tokens": ["Ich", "lob\u00b7te", "dich", "durch", "mei\u00b7ne", "Le\u00b7yer", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "PPOSAT", "NN", "$("], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "das macht\u2019 ich meinte niemand w\u00e4re treuer.", "tokens": ["das", "macht'", "ich", "mein\u00b7te", "nie\u00b7mand", "w\u00e4\u00b7re", "treu\u00b7er", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "VVFIN", "PIS", "VAFIN", "ADJD", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Nun fluch\u2019 ich auf der Feder schnelle fahrt.", "tokens": ["Nun", "fluch'", "ich", "auf", "der", "Fe\u00b7der", "schnel\u00b7le", "fahrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Gebt Feuer her. Ich wil den Vers verbren-", "tokens": ["Gebt", "Feu\u00b7er", "her", ".", "Ich", "wil", "den", "Vers", "ver\u00b7bren"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVIMP", "NN", "PTKVZ", "$.", "PPER", "VMFIN", "ART", "NN", "TRUNC"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Nicht zu geschwinde! Nein.", "tokens": ["Nicht", "zu", "ge\u00b7schwin\u00b7de", "!", "Nein", "."], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["PTKNEG", "PTKZU", "ADJA", "$.", "PTKANT", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Wie wolte man denn sonst erkennen/", "tokens": ["Wie", "wol\u00b7te", "man", "denn", "sonst", "er\u00b7ken\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "PIS", "ADV", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "da\u00df/ was ich schrieb/ solt\u2019 ein Gedichte sein.", "tokens": ["da\u00df", "/", "was", "ich", "schrieb", "/", "solt'", "ein", "Ge\u00b7dich\u00b7te", "sein", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$(", "PWS", "PPER", "VVFIN", "$(", "VMFIN", "ART", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.18": {"line.1": {"text": "W\u00e4rstu nicht sch\u00f6n wie h\u00e4tt\u2019 ich dich gelie-", "tokens": ["W\u00e4rs\u00b7tu", "nicht", "sch\u00f6n", "wie", "h\u00e4tt'", "ich", "dich", "ge\u00b7lie"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PTKNEG", "ADJD", "KOKOM", "VAFIN", "PPER", "PRF", "TRUNC"], "meter": "---+-+-+-+", "measure": "zehnsilber"}, "line.2": {"text": "nu bistu sch\u00f6n so hasset mich der Neid/", "tokens": ["nu", "bis\u00b7tu", "sch\u00f6n", "so", "has\u00b7set", "mich", "der", "Neid", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADJD", "ADV", "VVFIN", "PPER", "ART", "NN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "und g\u00f6nnet mir nicht deine Freundlig-", "tokens": ["und", "g\u00f6n\u00b7net", "mir", "nicht", "dei\u00b7ne", "Freund\u00b7lig"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "PTKNEG", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "W\u00e4rstu nicht sch\u00f6n/ so ha\u00dfte dich ein Je-", "tokens": ["W\u00e4rs\u00b7tu", "nicht", "sch\u00f6n", "/", "so", "ha\u00df\u00b7te", "dich", "ein", "Je"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PTKNEG", "ADJD", "$(", "ADV", "VVFIN", "PRF", "ART", "TRUNC"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "nu/ bistu sch\u00f6n/ so liebt dich jeder wieder.", "tokens": ["nu", "/", "bis\u00b7tu", "sch\u00f6n", "/", "so", "liebt", "dich", "je\u00b7der", "wie\u00b7der", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$(", "ADV", "ADJD", "$(", "ADV", "VVFIN", "PPER", "PIS", "ADV", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Ach! m\u00f6chtestu doch mir nur sch\u00f6ne", "tokens": ["Ach", "!", "m\u00f6ch\u00b7tes\u00b7tu", "doch", "mir", "nur", "sch\u00f6\u00b7ne"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["ITJ", "$.", "VMFIN", "ADV", "PPER", "ADV", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "da\u00df du nu sch\u00f6ne bist/ ist recht und auch nicht", "tokens": ["da\u00df", "du", "nu", "sch\u00f6\u00b7ne", "bist", "/", "ist", "recht", "und", "auch", "nicht"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "ADJA", "VAFIN", "$(", "VAFIN", "ADJD", "KON", "ADV", "PTKNEG"], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}}}}}