{"dta.poem.5496": {"metadata": {"author": {"name": "Brockes, Barthold Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "Annehmlichkeiten des Feuers zur Win-  \n ter-Zeit.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1736", "urn": "urn:nbn:de:kobv:b4-200905198582", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Ach, mein Sch\u00f6pfer, wie erquickend,", "tokens": ["Ach", ",", "mein", "Sch\u00f6p\u00b7fer", ",", "wie", "er\u00b7qui\u00b7ckend", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ITJ", "$,", "PPOSAT", "NN", "$,", "PWAV", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Warm, und lieblich, ja entz\u00fcckend", "tokens": ["Warm", ",", "und", "lieb\u00b7lich", ",", "ja", "ent\u00b7z\u00fc\u00b7ckend"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word"], "pos": ["NN", "$,", "KON", "ADJD", "$,", "ADV", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Ist das Feur zur Winter-Zeit,", "tokens": ["Ist", "das", "Feur", "zur", "Win\u00b7ter\u00b7Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "APPRART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wenn es draussen friert und schneit,", "tokens": ["Wenn", "es", "draus\u00b7sen", "friert", "und", "schneit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VVFIN", "KON", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Und man seinen regen Schimmer,", "tokens": ["Und", "man", "sei\u00b7nen", "re\u00b7gen", "Schim\u00b7mer", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Sieht und f\u00fchlt im warmen Zimmer!", "tokens": ["Sieht", "und", "f\u00fchlt", "im", "war\u00b7men", "Zim\u00b7mer", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KON", "VVFIN", "APPRART", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Die von Frost erstarrten Sehnen", "tokens": ["Die", "von", "Frost", "er\u00b7starr\u00b7ten", "Seh\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "NN", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Fangen an, sich aus zu dehnen,", "tokens": ["Fan\u00b7gen", "an", ",", "sich", "aus", "zu", "deh\u00b7nen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKVZ", "$,", "PRF", "APZR", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und es f\u00fchlet unsre Brust", "tokens": ["Und", "es", "f\u00fch\u00b7let", "uns\u00b7re", "Brust"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Eine s\u00fcsse Ruh und Lust,", "tokens": ["Ei\u00b7ne", "s\u00fcs\u00b7se", "Ruh", "und", "Lust", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Die aus holder W\u00e4rm\u2019 entspringet,", "tokens": ["Die", "aus", "hol\u00b7der", "W\u00e4rm'", "ent\u00b7sprin\u00b7get", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Auch den gantzen Leib durchdringet.", "tokens": ["Auch", "den", "gant\u00b7zen", "Leib", "durch\u00b7drin\u00b7get", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Hat der Nord die Haut versehret;", "tokens": ["Hat", "der", "Nord", "die", "Haut", "ver\u00b7seh\u00b7ret", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wird ein Pflaster ihr gewehret,", "tokens": ["Wird", "ein", "Pflas\u00b7ter", "ihr", "ge\u00b7weh\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Durch des Feuers rege Glut,", "tokens": ["Durch", "des", "Feu\u00b7ers", "re\u00b7ge", "Glut", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADJA", "NN", "$,"], "meter": "+-+---+", "measure": "unknown.measure.tri"}, "line.4": {"text": "Die dem C\u00f6rper sanfte thut,", "tokens": ["Die", "dem", "C\u00f6r\u00b7per", "sanf\u00b7te", "thut", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "VVFIN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Und, was durch den Frost gedr\u00fccket,", "tokens": ["Und", ",", "was", "durch", "den", "Frost", "ge\u00b7dr\u00fc\u00b7cket", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "PRELS", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "+---+-+-", "measure": "dactylic.init"}, "line.6": {"text": "Gleichsam streichelt und erquicket.", "tokens": ["Gleich\u00b7sam", "strei\u00b7chelt", "und", "er\u00b7quic\u00b7ket", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "KON", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Necht f\u00fcr unser gantzes Wesen", "tokens": ["Necht", "f\u00fcr", "un\u00b7ser", "gant\u00b7zes", "We\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Scheint der Glut Natur erlesen;", "tokens": ["Scheint", "der", "Glut", "Na\u00b7tur", "er\u00b7le\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Was die kalte Luft verletzt", "tokens": ["Was", "die", "kal\u00b7te", "Luft", "ver\u00b7letzt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "ART", "ADJA", "NN", "VVPP"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wird durch laue W\u00e4rm\u2019 ersetzt;", "tokens": ["Wird", "durch", "lau\u00b7e", "W\u00e4rm'", "er\u00b7setzt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "ADJA", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Pein und Schmertzen sind gelindert", "tokens": ["Pein", "und", "Schmert\u00b7zen", "sind", "ge\u00b7lin\u00b7dert"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "KON", "NN", "VAFIN", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Und durchs Feuers Kraft vermindert.", "tokens": ["Und", "durchs", "Feu\u00b7ers", "Kraft", "ver\u00b7min\u00b7dert", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "NN", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Ja, des Feuers Glantz und Schimmer", "tokens": ["Ja", ",", "des", "Feu\u00b7ers", "Glantz", "und", "Schim\u00b7mer"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "$,", "ART", "NN", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "L\u00e4sset im erw\u00e4rmten Zimmer,", "tokens": ["L\u00e4s\u00b7set", "im", "er\u00b7w\u00e4rm\u00b7ten", "Zim\u00b7mer", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPRART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Manche Lust die Augen sehn.", "tokens": ["Man\u00b7che", "Lust", "die", "Au\u00b7gen", "sehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Es vergn\u00fcgen kleine Blitze", "tokens": ["Es", "ver\u00b7gn\u00fc\u00b7gen", "klei\u00b7ne", "Blit\u00b7ze"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Uns nicht minder, als die Hitze.", "tokens": ["Uns", "nicht", "min\u00b7der", ",", "als", "die", "Hit\u00b7ze", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "PTKNEG", "ADV", "$,", "KOUS", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Mancherley Gestalten stammen", "tokens": ["Man\u00b7cher\u00b7ley", "Ge\u00b7stal\u00b7ten", "stam\u00b7men"], "token_info": ["word", "word", "word"], "pos": ["PIAT", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Aus bald blau-bald weissen Flammen\u2019,", "tokens": ["Aus", "bald", "blau\u00b7bald", "weis\u00b7sen", "Flam\u00b7men'", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "ADJD", "ADJA", "NN", "$,"], "meter": "+-+-+---", "measure": "unknown.measure.tri"}, "line.3": {"text": "Die wir mit Vergn\u00fcgen sehn,", "tokens": ["Die", "wir", "mit", "Ver\u00b7gn\u00fc\u00b7gen", "sehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "NN", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wie sie sich gespitzt erh\u00f6h\u2019n,", "tokens": ["Wie", "sie", "sich", "ge\u00b7spitzt", "er\u00b7h\u00f6h'n", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PRF", "VVPP", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Da sie recht, als wenn sie leben,", "tokens": ["Da", "sie", "recht", ",", "als", "wenn", "sie", "le\u00b7ben", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "$,", "KOKOM", "KOUS", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Sich bewegen, drehen, schweben.", "tokens": ["Sich", "be\u00b7we\u00b7gen", ",", "dre\u00b7hen", ",", "schwe\u00b7ben", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PRF", "VVINF", "$,", "VVINF", "$,", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Ofters sieht man sie, wie Wellen,", "tokens": ["Of\u00b7ters", "sieht", "man", "sie", ",", "wie", "Wel\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "PPER", "$,", "PWAV", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wallen, sincken, steigen, schwellen,", "tokens": ["Wal\u00b7len", ",", "sin\u00b7cken", ",", "stei\u00b7gen", ",", "schwel\u00b7len", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "$,", "VVFIN", "$,", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Bald verschwinden, bald entstehn,", "tokens": ["Bald", "ver\u00b7schwin\u00b7den", ",", "bald", "ent\u00b7stehn", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVPP", "$,", "ADV", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Bald erscheinen, bald vergehn,", "tokens": ["Bald", "er\u00b7schei\u00b7nen", ",", "bald", "ver\u00b7gehn", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVINF", "$,", "ADV", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Bald sich theilen, bald vereinen,", "tokens": ["Bald", "sich", "thei\u00b7len", ",", "bald", "ver\u00b7ei\u00b7nen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "PRF", "VVINF", "$,", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Schwinden, und aufs neu erscheinen.", "tokens": ["Schwin\u00b7den", ",", "und", "aufs", "neu", "er\u00b7schei\u00b7nen", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KON", "APPRART", "ADJD", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Oefters zeigt sich dem Gesichte,", "tokens": ["Oef\u00b7ters", "zeigt", "sich", "dem", "Ge\u00b7sich\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Mitten in dem hellen Lichte,", "tokens": ["Mit\u00b7ten", "in", "dem", "hel\u00b7len", "Lich\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Ein gedrehter blauer Rauch.", "tokens": ["Ein", "ge\u00b7dreh\u00b7ter", "blau\u00b7er", "Rauch", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Ein stets umgeschwungner Schmauch", "tokens": ["Ein", "stets", "um\u00b7ge\u00b7schwung\u00b7ner", "Schmauch"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADV", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Zeuget hier auf manche Weise", "tokens": ["Zeu\u00b7get", "hier", "auf", "man\u00b7che", "Wei\u00b7se"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "APPR", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Kleine Wolcken, kleine Kreise.", "tokens": ["Klei\u00b7ne", "Wol\u00b7cken", ",", "klei\u00b7ne", "Krei\u00b7se", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "In derselben regem Schwingen", "tokens": ["In", "der\u00b7sel\u00b7ben", "re\u00b7gem", "Schwin\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PDAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sehn wir helle Funcken springen,", "tokens": ["Sehn", "wir", "hel\u00b7le", "Fun\u00b7cken", "sprin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJA", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Die sich durch die Loh erh\u00f6h\u2019n,", "tokens": ["Die", "sich", "durch", "die", "Loh", "er\u00b7h\u00f6h'n", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und, wenn sie entstehn, vergehn,", "tokens": ["Und", ",", "wenn", "sie", "ent\u00b7stehn", ",", "ver\u00b7gehn", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "$,", "KOUS", "PPER", "VVINF", "$,", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Aber doch nicht ohn Vergn\u00fcgen,", "tokens": ["A\u00b7ber", "doch", "nicht", "ohn", "Ver\u00b7gn\u00fc\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PTKNEG", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Wenn man sie besieht, verfliegen.", "tokens": ["Wenn", "man", "sie", "be\u00b7sieht", ",", "ver\u00b7flie\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "PIS", "PPER", "VVFIN", "$,", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Wenn, mit drey getheilten Spitzen,", "tokens": ["Wenn", ",", "mit", "drey", "ge\u00b7theil\u00b7ten", "Spit\u00b7zen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$,", "APPR", "CARD", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Schnelle Flammen lodernd blitzen,", "tokens": ["Schnel\u00b7le", "Flam\u00b7men", "lo\u00b7dernd", "blit\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVPP", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Knastert \u00f6fters, zischt, und pufft", "tokens": ["Knas\u00b7tert", "\u00f6f\u00b7ters", ",", "zischt", ",", "und", "pufft"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word"], "pos": ["NE", "ADV", "$,", "VVFIN", "$,", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Die verschrenckt-gewesne Luft,", "tokens": ["Die", "ver\u00b7schren\u00b7ck\u00b7tge\u00b7wes\u00b7ne", "Luft", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.5": {"text": "Da sie das, was sie gedrenget,", "tokens": ["Da", "sie", "das", ",", "was", "sie", "ge\u00b7dren\u00b7get", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PDS", "$,", "PRELS", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Oft mit starckem Knall zersprenget.", "tokens": ["Oft", "mit", "star\u00b7ckem", "Knall", "zer\u00b7spren\u00b7get", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Ofters sieht man dunckle Stellen", "tokens": ["Of\u00b7ters", "sieht", "man", "dunck\u00b7le", "Stel\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PIS", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Pl\u00f6tzlich durch die Glut erhellen,", "tokens": ["Pl\u00f6tz\u00b7lich", "durch", "die", "Glut", "er\u00b7hel\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wenn die d\u00fcnne Loh\u2019 sich spitzt,", "tokens": ["Wenn", "die", "d\u00fcn\u00b7ne", "Loh'", "sich", "spitzt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "PRF", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und bald hie, bald dorten blitzt,", "tokens": ["Und", "bald", "hie", ",", "bald", "dor\u00b7ten", "blitzt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "$,", "ADV", "ADV", "VVFIN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Wenn die Flammen gantz durchbrechen", "tokens": ["Wenn", "die", "Flam\u00b7men", "gantz", "durch\u00b7bre\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "ADV", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Und wie Schlangen-Zungen stechen.", "tokens": ["Und", "wie", "Schlan\u00b7gen\u00b7Zun\u00b7gen", "ste\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "NN", "VVINF", "$."], "meter": "--+-+-+-", "measure": "anapaest.init"}}, "stanza.12": {"line.1": {"text": "Wenn die Loh\u2019 denn aufw\u00e4rts steiget", "tokens": ["Wenn", "die", "Loh'", "denn", "auf\u00b7w\u00e4rts", "stei\u00b7get"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "KON", "ADV", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und nur weisse Lichter zeiget;", "tokens": ["Und", "nur", "weis\u00b7se", "Lich\u00b7ter", "zei\u00b7get", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Sieht man unten Kohlen gl\u00fchn,", "tokens": ["Sieht", "man", "un\u00b7ten", "Koh\u00b7len", "gl\u00fchn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ADV", "NN", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Als ein funckelnder Rubin,", "tokens": ["Als", "ein", "fun\u00b7ckeln\u00b7der", "Ru\u00b7bin", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NE", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.5": {"text": "Diese zeigen tausend Br\u00fcche", "tokens": ["Die\u00b7se", "zei\u00b7gen", "tau\u00b7send", "Br\u00fc\u00b7che"], "token_info": ["word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "CARD", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Und von Asche tausend Striche.", "tokens": ["Und", "von", "A\u00b7sche", "tau\u00b7send", "Stri\u00b7che", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "CARD", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Da sie alles sonst verzehren,", "tokens": ["Da", "sie", "al\u00b7les", "sonst", "ver\u00b7zeh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIS", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sieht man sie doch Asch geb\u00e4hren;", "tokens": ["Sieht", "man", "sie", "doch", "Asch", "ge\u00b7b\u00e4h\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PPER", "ADV", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Asche, die sie d\u00e4mpft und deckt,", "tokens": ["A\u00b7sche", ",", "die", "sie", "d\u00e4mpft", "und", "deckt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PRELS", "PPER", "VVFIN", "KON", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Sie erh\u00e4lt, erstickt, versteckt.", "tokens": ["Sie", "er\u00b7h\u00e4lt", ",", "er\u00b7stickt", ",", "ver\u00b7steckt", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "VVPP", "$,", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Hierin sieht man tausend Spuren", "tokens": ["Hie\u00b7rin", "sieht", "man", "tau\u00b7send", "Spu\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "PIS", "CARD", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Von verschiedlichen Figuren.", "tokens": ["Von", "ver\u00b7schied\u00b7li\u00b7chen", "Fi\u00b7gu\u00b7ren", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "Man sieht wei\u00df und schwartz sich f\u00fcgen,", "tokens": ["Man", "sieht", "wei\u00df", "und", "schwartz", "sich", "f\u00fc\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "VVFIN", "KON", "ADJD", "PRF", "VVINF", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Asch\u2019 auf schwartzen Kohlen liegen,", "tokens": ["Asch'", "auf", "schwart\u00b7zen", "Koh\u00b7len", "lie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Oefters wie der Schnee so weis,", "tokens": ["Oef\u00b7ters", "wie", "der", "Schnee", "so", "weis", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "ART", "NN", "ADV", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und als h\u00e4tte man, mit Flei\u00df,", "tokens": ["Und", "als", "h\u00e4t\u00b7te", "man", ",", "mit", "Flei\u00df", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "KOKOM", "VAFIN", "PIS", "$,", "APPR", "NN", "$,"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.5": {"text": "Nach der Kunst, die\u2019s Aug\u2019 erfreuet,", "tokens": ["Nach", "der", "Kunst", ",", "die's", "Aug'", "er\u00b7freu\u00b7et", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Loder-Asche drauf gestreuet.", "tokens": ["Lo\u00b7der\u00b7A\u00b7sche", "drauf", "ge\u00b7streu\u00b7et", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "PAV", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.15": {"line.1": {"text": "Ja, wofern man sie betrachtet,", "tokens": ["Ja", ",", "wo\u00b7fern", "man", "sie", "be\u00b7trach\u00b7tet", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "KOUS", "PIS", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und auf Farb\u2019 und Formen achtet,", "tokens": ["Und", "auf", "Fa\u00b7rb'", "und", "For\u00b7men", "ach\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Tauget die Verschiedenheit,", "tokens": ["Tau\u00b7get", "die", "Ver\u00b7schie\u00b7den\u00b7heit", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wenigstens auf kurtze Zeit,", "tokens": ["We\u00b7nigs\u00b7tens", "auf", "kurt\u00b7ze", "Zeit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ADJA", "NN", "$,"], "meter": "+---+-+", "measure": "dactylic.init"}, "line.5": {"text": "Uns, in Bildern vieler Sachen,", "tokens": ["Uns", ",", "in", "Bil\u00b7dern", "vie\u00b7ler", "Sa\u00b7chen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "APPR", "NN", "PIAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Einen Zeitvertreib zu machen.", "tokens": ["Ei\u00b7nen", "Zeit\u00b7ver\u00b7treib", "zu", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.16": {"line.1": {"text": "Wann ich nun, bey sanfter Hitze,", "tokens": ["Wann", "ich", "nun", ",", "bey", "sanf\u00b7ter", "Hit\u00b7ze", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Jm gew\u00e4rmten Zimmer sitze,", "tokens": ["Jm", "ge\u00b7w\u00e4rm\u00b7ten", "Zim\u00b7mer", "sit\u00b7ze", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und seh, in gelassner Ruh,", "tokens": ["Und", "seh", ",", "in", "ge\u00b7lass\u00b7ner", "Ruh", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Meiner Glut Bewegung zu;", "tokens": ["Mei\u00b7ner", "Glut", "Be\u00b7we\u00b7gung", "zu", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Scheinet ihr erw\u00e4rmend Lodern", "tokens": ["Schei\u00b7net", "ihr", "er\u00b7w\u00e4r\u00b7mend", "Lo\u00b7dern"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "VVPP", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Danck f\u00fcr Nutz und Lust zu fodern.", "tokens": ["Danck", "f\u00fcr", "Nutz", "und", "Lust", "zu", "fo\u00b7dern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "APPR", "NN", "KON", "NN", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.17": {"line.1": {"text": "Dann bewegen sich von innen", "tokens": ["Dann", "be\u00b7we\u00b7gen", "sich", "von", "in\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PRF", "APPR", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Eilig meine Seel\u2019 und Sinnen,", "tokens": ["Ei\u00b7lig", "mei\u00b7ne", "Seel'", "und", "Sin\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "PPOSAT", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und mein Geist h\u00e4lt br\u00fcnstiglich,", "tokens": ["Und", "mein", "Geist", "h\u00e4lt", "br\u00fcns\u00b7tig\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Gleich der Gluth, sich \u00fcber sich,", "tokens": ["Gleich", "der", "Gluth", ",", "sich", "\u00fc\u00b7ber", "sich", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "$,", "PRF", "APPR", "PRF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Danckt, erhitzt von Andachts-Flammen,", "tokens": ["Danckt", ",", "er\u00b7hitzt", "von", "An\u00b7dachts\u00b7Flam\u00b7men", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "VVFIN", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Dem, draus Licht und W\u00e4rme stammen.", "tokens": ["Dem", ",", "draus", "Licht", "und", "W\u00e4r\u00b7me", "stam\u00b7men", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "$,", "PAV", "NN", "KON", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.18": {"line.1": {"text": "Denckt zugleich: was w\u00fcrd\u2019 auf Erden", "tokens": ["Denckt", "zu\u00b7gleich", ":", "was", "w\u00fcrd'", "auf", "Er\u00b7den"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "$.", "PWS", "VAFIN", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Doch wol vor ein Zustand werden,", "tokens": ["Doch", "wol", "vor", "ein", "Zu\u00b7stand", "wer\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "ART", "NN", "VAINF", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "H\u00e4tte GOTT die rege Gluth,", "tokens": ["H\u00e4t\u00b7te", "GoTT", "die", "re\u00b7ge", "Gluth", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Die der Haut so sanfte thut,", "tokens": ["Die", "der", "Haut", "so", "sanf\u00b7te", "thut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "ADV", "ADJA", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Zum Gebrauch in unserm Leben,", "tokens": ["Zum", "Ge\u00b7brauch", "in", "un\u00b7serm", "Le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Uns aus Gnaden nicht gegeben?", "tokens": ["Uns", "aus", "Gna\u00b7den", "nicht", "ge\u00b7ge\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "NN", "PTKNEG", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.19": {"line.1": {"text": "Wer demnach, wanns schneit und frieret,", "tokens": ["Wer", "dem\u00b7nach", ",", "wanns", "schneit", "und", "frie\u00b7ret", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PAV", "$,", "PWAV", "ADJD", "KON", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Durch das Feuer Lindrung sp\u00fcret,", "tokens": ["Durch", "das", "Feu\u00b7er", "Lind\u00b7rung", "sp\u00fc\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Dencke billig: GOTT allein", "tokens": ["Den\u00b7cke", "bil\u00b7lig", ":", "GoTT", "al\u00b7lein"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["VVFIN", "ADJD", "$.", "NE", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Giebt dem Feuer W\u00e4rm\u2019 und Schein;", "tokens": ["Giebt", "dem", "Feu\u00b7er", "W\u00e4rm'", "und", "Schein", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "NE", "KON", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Auch zugleich: da\u00df Prei\u00df und Ehre", "tokens": ["Auch", "zu\u00b7gleich", ":", "da\u00df", "Prei\u00df", "und", "Eh\u00b7re"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "$.", "KOUS", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Jhm, mit Recht, daf\u00fcr geh\u00f6re.", "tokens": ["Jhm", ",", "mit", "Recht", ",", "da\u00b7f\u00fcr", "ge\u00b7h\u00f6\u00b7re", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "$,", "APPR", "NN", "$,", "PAV", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.20": {"line.1": {"text": "Nun was kann, f\u00fcr alle Gaben,", "tokens": ["Nun", "was", "kann", ",", "f\u00fcr", "al\u00b7le", "Ga\u00b7ben", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PWS", "VMFIN", "$,", "APPR", "PIAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Unser Sch\u00f6pfer von uns haben", "tokens": ["Un\u00b7ser", "Sch\u00f6p\u00b7fer", "von", "uns", "ha\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "APPR", "PPER", "VAFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "F\u00fcr ein solch unsch\u00e4tzbar Gut,", "tokens": ["F\u00fcr", "ein", "solch", "un\u00b7sch\u00e4tz\u00b7bar", "Gut", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "PIAT", "ADJD", "ADJD", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "Als die rege Kraft der Gluth?", "tokens": ["Als", "die", "re\u00b7ge", "Kraft", "der", "Gluth", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "ART", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Was kann man ihm sonst erweisen,", "tokens": ["Was", "kann", "man", "ihm", "sonst", "er\u00b7wei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PIS", "PPER", "ADV", "VVINF", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Als in unsrer Lust ihn preisen?", "tokens": ["Als", "in", "uns\u00b7rer", "Lust", "ihn", "prei\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "PPOSAT", "NN", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}}}}