{"textgrid.poem.41377": {"metadata": {"author": {"name": "Hagedorn, Friedrich von", "birth": "N.A.", "death": "N.A."}, "title": "Das H\u00fchnchen und der Diamant", "genre": "verse", "period": "N.A.", "pub_year": 1731, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ein verhungert H\u00fchnchen fand", "tokens": ["Ein", "ver\u00b7hun\u00b7gert", "H\u00fchn\u00b7chen", "fand"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "VVFIN", "NN", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Einen feinen Diamant,", "tokens": ["Ei\u00b7nen", "fei\u00b7nen", "Di\u00b7a\u00b7mant", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und verscharrt' ihn in den Sand.", "tokens": ["Und", "ver\u00b7scharrt'", "ihn", "in", "den", "Sand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "M\u00f6chte doch, mich zu erfreun,", "tokens": ["M\u00f6ch\u00b7te", "doch", ",", "mich", "zu", "er\u00b7freun", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "$,", "PPER", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Sprach es, dieser sch\u00f6ne Stein", "tokens": ["Sprach", "es", ",", "die\u00b7ser", "sch\u00f6\u00b7ne", "Stein"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["NN", "PPER", "$,", "PDAT", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Nur ein Weizenk\u00f6rnchen sein!", "tokens": ["Nur", "ein", "Wei\u00b7zen\u00b7k\u00f6rn\u00b7chen", "sein", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Ungl\u00fcckselger Ueberflu\u00df,", "tokens": ["Un\u00b7gl\u00fcck\u00b7sel\u00b7ger", "Ue\u00b7berf\u00b7lu\u00df", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Wo der n\u00f6thigste Genu\u00df", "tokens": ["Wo", "der", "n\u00f6\u00b7thigs\u00b7te", "Ge\u00b7nu\u00df"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "ART", "ADJA", "NN"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.3": {"text": "Unsern Sch\u00e4tzen fehlen mu\u00df!", "tokens": ["Un\u00b7sern", "Sch\u00e4t\u00b7zen", "feh\u00b7len", "mu\u00df", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Ein verhungert H\u00fchnchen fand", "tokens": ["Ein", "ver\u00b7hun\u00b7gert", "H\u00fchn\u00b7chen", "fand"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "VVFIN", "NN", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Einen feinen Diamant,", "tokens": ["Ei\u00b7nen", "fei\u00b7nen", "Di\u00b7a\u00b7mant", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und verscharrt' ihn in den Sand.", "tokens": ["Und", "ver\u00b7scharrt'", "ihn", "in", "den", "Sand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "M\u00f6chte doch, mich zu erfreun,", "tokens": ["M\u00f6ch\u00b7te", "doch", ",", "mich", "zu", "er\u00b7freun", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "$,", "PPER", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Sprach es, dieser sch\u00f6ne Stein", "tokens": ["Sprach", "es", ",", "die\u00b7ser", "sch\u00f6\u00b7ne", "Stein"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["NN", "PPER", "$,", "PDAT", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Nur ein Weizenk\u00f6rnchen sein!", "tokens": ["Nur", "ein", "Wei\u00b7zen\u00b7k\u00f6rn\u00b7chen", "sein", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Ungl\u00fcckselger Ueberflu\u00df,", "tokens": ["Un\u00b7gl\u00fcck\u00b7sel\u00b7ger", "Ue\u00b7berf\u00b7lu\u00df", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Wo der n\u00f6thigste Genu\u00df", "tokens": ["Wo", "der", "n\u00f6\u00b7thigs\u00b7te", "Ge\u00b7nu\u00df"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "ART", "ADJA", "NN"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.3": {"text": "Unsern Sch\u00e4tzen fehlen mu\u00df!", "tokens": ["Un\u00b7sern", "Sch\u00e4t\u00b7zen", "feh\u00b7len", "mu\u00df", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}