{"dta.poem.8510": {"metadata": {"author": {"name": "Droste-H\u00fclshoff, Annette von", "birth": "N.A.", "death": "N.A."}, "title": "2.  \n  M\u00fcnzkraut .", "genre": "Lyrik; Prosa", "period": "N.A.", "pub_year": "1860", "urn": "urn:nbn:de:kobv:b4-200905191007", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Der Fr&#252;hling naht, es streicht der Staar", "tokens": ["Der", "Fr", "&#252;", "hling", "naht", ",", "es", "streicht", "der", "Staar"], "token_info": ["word", "word", "XML_entity", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$(", "VVFIN", "VVFIN", "$,", "PPER", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Am S\u00f6ller um sein altes Nest;", "tokens": ["Am", "S\u00f6l\u00b7ler", "um", "sein", "al\u00b7tes", "Nest", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Schon sind die Th\u00e4ler sonnenklar,", "tokens": ["Schon", "sind", "die", "Th\u00e4\u00b7ler", "son\u00b7nen\u00b7klar", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Doch noch die Scholle hart und fest;", "tokens": ["Doch", "noch", "die", "Schol\u00b7le", "hart", "und", "fest", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "ADJD", "KON", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Nur wo der Strahl vom Felsen prallt,", "tokens": ["Nur", "wo", "der", "Strahl", "vom", "Fel\u00b7sen", "prallt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PWAV", "ART", "NN", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Will m\u00e4chtig sich der Grund erweichen", "tokens": ["Will", "m\u00e4ch\u00b7tig", "sich", "der", "Grund", "er\u00b7wei\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "ADJD", "PRF", "ART", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Und sch\u00fcchtern aus den Windeln schleichen", "tokens": ["Und", "sch\u00fcch\u00b7tern", "aus", "den", "Win\u00b7deln", "schlei\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Der Gr\u00e4ser dichter, lichter Wald.", "tokens": ["Der", "Gr\u00e4\u00b7ser", "dich\u00b7ter", ",", "lich\u00b7ter", "Wald", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Schau dort am Riff \u2014 man sieht es kaum \u2014", "tokens": ["Schau", "dort", "am", "Riff", "man", "sieht", "es", "kaum"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "APPRART", "NN", "$(", "PIS", "VVFIN", "PPER", "ADV", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "So recht vom Sonnenbrand gekocht", "tokens": ["So", "recht", "vom", "Son\u00b7nen\u00b7brand", "ge\u00b7kocht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "APPRART", "NN", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Das kleine Beet, vier Schritte Raum,", "tokens": ["Das", "klei\u00b7ne", "Beet", ",", "vier", "Schrit\u00b7te", "Raum", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "CARD", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Vom Schieferhange \u00fcberjocht,", "tokens": ["Vom", "Schie\u00b7fer\u00b7han\u00b7ge", "\u00fc\u00b7ber\u00b7jocht", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Nach Ost und Westen eingehegt,", "tokens": ["Nach", "Ost", "und", "Wes\u00b7ten", "ein\u00b7ge\u00b7hegt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Mit starken Planken abgeschlagen,", "tokens": ["Mit", "star\u00b7ken", "Plan\u00b7ken", "ab\u00b7ge\u00b7schla\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Als sollt\u2019 es Wunderblumen tragen,", "tokens": ["Als", "sollt'", "es", "Wun\u00b7der\u00b7blu\u00b7men", "tra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VMFIN", "PPER", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Und sind nur Kr\u00e4uter, was es tr\u00e4gt.", "tokens": ["Und", "sind", "nur", "Kr\u00e4u\u00b7ter", ",", "was", "es", "tr\u00e4gt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "NN", "$,", "PWS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Und dort die Frau an Riffes Mitten,", "tokens": ["Und", "dort", "die", "Frau", "an", "Rif\u00b7fes", "Mit\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "APPR", "NN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ach Gott, sie hat wohl viel gelitten!", "tokens": ["Ach", "Gott", ",", "sie", "hat", "wohl", "viel", "ge\u00b7lit\u00b7ten", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "NN", "$,", "PPER", "VAFIN", "ADV", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Sie klimmt so schwer den Steig hinan.", "tokens": ["Sie", "klimmt", "so", "schwer", "den", "Steig", "hi\u00b7nan", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADJD", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Nun steht sie keuchend, l\u00f6s\u2019t das Mieder,", "tokens": ["Nun", "steht", "sie", "keu\u00b7chend", ",", "l\u00f6s't", "das", "Mie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "VVPP", "$,", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Nun sinkt sie an dem Beete nieder,", "tokens": ["Nun", "sinkt", "sie", "an", "dem", "Bee\u00b7te", "nie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Und faltet ihre H\u00e4nde dann:", "tokens": ["Und", "fal\u00b7tet", "ih\u00b7re", "H\u00e4n\u00b7de", "dann", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "\u201eliebe M\u00fcnze, du werther Stab,", "tokens": ["\u201e", "lie\u00b7be", "M\u00fcn\u00b7ze", ",", "du", "wert\u00b7her", "Stab", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADJA", "NN", "$,", "PPER", "ADJA", "NN", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.2": {"text": "Drauf meines Heilands Sohle stand,", "tokens": ["Drauf", "mei\u00b7nes", "Hei\u00b7lands", "Soh\u00b7le", "stand", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PPOSAT", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Als ihm dr\u00fcben im Morgenland", "tokens": ["Als", "ihm", "dr\u00fc\u00b7ben", "im", "Mor\u00b7gen\u00b7land"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "APPRART", "NN"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.4": {"text": "Sanct Battiste die Taufe gab;", "tokens": ["Sanct", "Bat\u00b7tis\u00b7te", "die", "Tau\u00b7fe", "gab", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "ART", "NN", "VVFIN", "$."], "meter": "-----+-+", "measure": "unknown.measure.di"}, "line.5": {"text": "Heiliges Kraut, das aus seinem Leibe", "tokens": ["Hei\u00b7li\u00b7ges", "Kraut", ",", "das", "aus", "sei\u00b7nem", "Lei\u00b7be"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADJA", "NN", "$,", "PRELS", "APPR", "PPOSAT", "NN"], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}, "line.6": {"text": "Ward gesegnet mit Wunderkraft,", "tokens": ["Ward", "ge\u00b7seg\u00b7net", "mit", "Wun\u00b7der\u00b7kraft", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "VVPP", "APPR", "NN", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.7": {"text": "Hilf einer Witw\u2019, einem armen Weibe,", "tokens": ["Hilf", "ei\u00b7ner", "Wit\u00b7w'", ",", "ei\u00b7nem", "ar\u00b7men", "Wei\u00b7be", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "ART", "NN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Das so sorglich um dich geschafft.", "tokens": ["Das", "so", "sorg\u00b7lich", "um", "dich", "ge\u00b7schafft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "ADJD", "APPR", "PPER", "VVPP", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}}, "stanza.5": {"line.1": {"text": "Hier ist Brod, und hier ist Salz und Wein,", "tokens": ["Hier", "ist", "Brod", ",", "und", "hier", "ist", "Salz", "und", "Wein", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "NN", "$,", "KON", "ADV", "VAFIN", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Sieh, ich leg\u2019s in deine Bl\u00e4tter mitten;", "tokens": ["Sieh", ",", "ich", "leg's", "in", "dei\u00b7ne", "Bl\u00e4t\u00b7ter", "mit\u00b7ten", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PPER", "NE", "APPR", "PPOSAT", "NN", "ADV", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Woll nicht z\u00fcrnen, da\u00df das St\u00fcck so klein,", "tokens": ["Woll", "nicht", "z\u00fcr\u00b7nen", ",", "da\u00df", "das", "St\u00fcck", "so", "klein", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PTKNEG", "VVINF", "$,", "KOUS", "ART", "NN", "ADV", "ADJD", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Hab\u2019s von meinem Theile abgeschnitten;", "tokens": ["Hab's", "von", "mei\u00b7nem", "Thei\u00b7le", "ab\u00b7ge\u00b7schnit\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.5": {"text": "Etwas wahrt\u2019 ich, M\u00fcnze gnadenreich,", "tokens": ["Et\u00b7was", "wahrt'", "ich", ",", "M\u00fcn\u00b7ze", "gna\u00b7den\u00b7reich", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "NN", "ADJD", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.6": {"text": "Schaffens halber nur, sonst geb\u2019 ich\u2019s gleich.", "tokens": ["Schaf\u00b7fens", "hal\u00b7ber", "nur", ",", "sonst", "geb'", "ich's", "gleich", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPO", "ADV", "$,", "ADV", "VVFIN", "PIS", "ADV", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.6": {"line.1": {"text": "Mein Knab\u2019 ist krank, du wei\u00dft es wohl,", "tokens": ["Mein", "Knab'", "ist", "krank", ",", "du", "wei\u00dft", "es", "wohl", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADJD", "$,", "PPER", "VVFIN", "PPER", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ich kam ja schon zu sieben Malen,", "tokens": ["Ich", "kam", "ja", "schon", "zu", "sie\u00b7ben", "Ma\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "APPR", "CARD", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und gestern mu\u00dft\u2019 ich in Bregnoles", "tokens": ["Und", "ge\u00b7stern", "mu\u00dft'", "ich", "in", "Breg\u00b7no\u00b7les"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VMFIN", "PPER", "APPR", "NE"], "meter": "+-+-++-+-", "measure": "unknown.measure.penta"}, "line.4": {"text": "Den Trank f\u00fcr ihn so theuer zahlen.", "tokens": ["Den", "Trank", "f\u00fcr", "ihn", "so", "theu\u00b7er", "zah\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPER", "ADV", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Vier hab\u2019 ich, vier, da\u00df Gott erbarm\u2019!", "tokens": ["Vier", "hab'", "ich", ",", "vier", ",", "da\u00df", "Gott", "er\u00b7barm'", "!"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "$,", "CARD", "$,", "KOUS", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Mit diesen H\u00e4nden zu ern\u00e4hren,", "tokens": ["Mit", "die\u00b7sen", "H\u00e4n\u00b7den", "zu", "er\u00b7n\u00e4h\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Und, sieh, so kann\u2019s nicht l\u00e4nger w\u00e4hren,", "tokens": ["Und", ",", "sieh", ",", "so", "kann's", "nicht", "l\u00e4n\u00b7ger", "w\u00e4h\u00b7ren", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "VVFIN", "$,", "ADV", "VMFIN", "PTKNEG", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Denn t\u00e4glich schw\u00e4cher wird mein Arm.", "tokens": ["Denn", "t\u00e4g\u00b7lich", "schw\u00e4\u00b7cher", "wird", "mein", "Arm", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "ADJD", "VAFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "O Madonna, Madonna, meine gn\u00e4dige Frau!", "tokens": ["O", "Ma\u00b7don\u00b7na", ",", "Ma\u00b7don\u00b7na", ",", "mei\u00b7ne", "gn\u00e4\u00b7di\u00b7ge", "Frau", "!"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "NE", "$,", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.2": {"text": "Ich hab\u2019 gefrevelt, nimm\u2019s nicht genau,", "tokens": ["Ich", "hab'", "ge\u00b7fre\u00b7velt", ",", "nim\u00b7m's", "nicht", "ge\u00b7nau", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVPP", "$,", "VVFIN", "PTKNEG", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Ich hab\u2019 ges\u00fcndigt wider Willen!", "tokens": ["Ich", "hab'", "ge\u00b7s\u00fcn\u00b7digt", "wi\u00b7der", "Wil\u00b7len", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVPP", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Nimm, o nimm mir nur kein Kind,", "tokens": ["Nimm", ",", "o", "nimm", "mir", "nur", "kein", "Kind", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "FM", "VVIMP", "PPER", "ADV", "PIAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Will ihm gern den Hunger stillen,", "tokens": ["Will", "ihm", "gern", "den", "Hun\u00b7ger", "stil\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "W\u00e4r\u2019s mit Bettelbrod; nicht Eins", "tokens": ["W\u00e4r's", "mit", "Bet\u00b7tel\u00b7brod", ";", "nicht", "Eins"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["VAFIN", "APPR", "NN", "$.", "PTKNEG", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Kann ich missen, von Allen keins!", "tokens": ["Kann", "ich", "mis\u00b7sen", ",", "von", "Al\u00b7len", "keins", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "VVPP", "$,", "APPR", "NE", "PIAT", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.8": {"line.1": {"text": "Zweimal mu\u00df ich noch den Steig hinan", "tokens": ["Zwei\u00b7mal", "mu\u00df", "ich", "noch", "den", "Steig", "hi\u00b7nan"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "ART", "NN", "PTKVZ"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Siebenmal bin ich nun hier gewesen.", "tokens": ["Sie\u00b7ben\u00b7mal", "bin", "ich", "nun", "hier", "ge\u00b7we\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ADV", "VAPP", "$."], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}}, "stanza.9": {"line.1": {"text": "Heil\u2019ge Frau von Embrun, w\u00e4r\u2019 dann", "tokens": ["Heil'\u00b7ge", "Frau", "von", "E\u00b7mbrun", ",", "w\u00e4r'", "dann"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["ADJA", "NN", "APPR", "NE", "$,", "VAFIN", "ADV"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.2": {"text": "Welk die M\u00fcnze und mein Knab\u2019 genesen,", "tokens": ["Welk", "die", "M\u00fcn\u00b7ze", "und", "mein", "Knab'", "ge\u00b7ne\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "KON", "PPOSAT", "NN", "VVPP", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Gerne will dann an deinem Schrein", "tokens": ["Ger\u00b7ne", "will", "dann", "an", "dei\u00b7nem", "Schrein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "ADV", "APPR", "PPOSAT", "NN"], "meter": "+----+-+", "measure": "dactylic.init"}, "line.4": {"text": "Meinen Treuring opfern, er ist klein,", "tokens": ["Mei\u00b7nen", "Treu\u00b7ring", "op\u00b7fern", ",", "er", "ist", "klein", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVINF", "$,", "PPER", "VAFIN", "ADJD", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.5": {"text": "Nur von Silber, aber fleckenrein;", "tokens": ["Nur", "von", "Sil\u00b7ber", ",", "a\u00b7ber", "fle\u00b7cken\u00b7rein", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "$,", "ADV", "PTKVZ", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.6": {"text": "Denn ich hab\u2019 mit Ehren ihn getragen,", "tokens": ["Denn", "ich", "hab'", "mit", "Eh\u00b7ren", "ihn", "ge\u00b7tra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "APPR", "NN", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.7": {"text": "Darf vor Gott und Menschen mich nicht sch\u00e4men;", "tokens": ["Darf", "vor", "Gott", "und", "Men\u00b7schen", "mich", "nicht", "sch\u00e4\u00b7men", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "APPR", "NN", "KON", "NN", "PPER", "PTKNEG", "VVINF", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.8": {"text": "Milde Fraue, la\u00df mich nicht verzagen,", "tokens": ["Mil\u00b7de", "Frau\u00b7e", ",", "la\u00df", "mich", "nicht", "ver\u00b7za\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "$,", "VVIMP", "PPER", "PTKNEG", "VVINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.9": {"text": "Liebe Dame, woll\u2019 ihn g\u00fctig nehmen,", "tokens": ["Lie\u00b7be", "Da\u00b7me", ",", "woll'", "ihn", "g\u00fc\u00b7tig", "neh\u00b7men", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "$,", "PWAV", "PPER", "ADJD", "VVINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.10": {"text": "Denk, er sei von Golde und Rubin,", "tokens": ["Denk", ",", "er", "sei", "von", "Gol\u00b7de", "und", "Ru\u00b7bin", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PPER", "VAFIN", "APPR", "NN", "KON", "NE", "$,"], "meter": "+-+-+-++-", "measure": "unknown.measure.penta"}, "line.11": {"text": "S\u00fc\u00dfe, heil\u2019ge, werthe Himmelsk\u00f6nigin!\u201c", "tokens": ["S\u00fc\u00b7\u00dfe", ",", "heil'\u00b7ge", ",", "wert\u00b7he", "Him\u00b7mels\u00b7k\u00f6\u00b7ni\u00b7gin", "!", "\u201c"], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "punct"], "pos": ["NN", "$,", "VVFIN", "$,", "VVFIN", "NN", "$.", "$("], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}}}}}