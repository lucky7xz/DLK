{"textgrid.poem.63672": {"metadata": {"author": {"name": "Heyse, Paul", "birth": "N.A.", "death": "N.A."}, "title": "Prolog", "genre": "verse", "period": "N.A.", "pub_year": 1907, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Sie haben's auf den Brettern streng verp\u00f6nt,", "tokens": ["Sie", "ha\u00b7ben's", "auf", "den", "Bret\u00b7tern", "streng", "ver\u00b7p\u00f6nt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "ART", "NN", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Sein Herz in Selbstgespr\u00e4chen zu entladen.", "tokens": ["Sein", "Herz", "in", "Selbst\u00b7ge\u00b7spr\u00e4\u00b7chen", "zu", "ent\u00b7la\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Was Dichter sich erlaubt von Gottes Gnaden,", "tokens": ["Was", "Dich\u00b7ter", "sich", "er\u00b7laubt", "von", "Got\u00b7tes", "Gna\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "PRF", "VVPP", "APPR", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Wird von den J\u00fcngsten als ", "tokens": ["Wird", "von", "den", "J\u00fcng\u00b7sten", "als"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "APPR", "ART", "NN", "KOKOM"], "meter": "+--+-+", "measure": "iambic.tri.invert"}}, "stanza.2": {"line.1": {"text": "Mir, an die alte Technik noch gew\u00f6hnt,", "tokens": ["Mir", ",", "an", "die", "al\u00b7te", "Tech\u00b7nik", "noch", "ge\u00b7w\u00f6hnt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "APPR", "ART", "ADJA", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Scheint: die Natur kommt nicht dabei zu Schaden,", "tokens": ["Scheint", ":", "die", "Na\u00b7tur", "kommt", "nicht", "da\u00b7bei", "zu", "Scha\u00b7den", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$.", "ART", "NN", "VVFIN", "PTKNEG", "PAV", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Da frei von theatralischen Tiraden", "tokens": ["Da", "frei", "von", "the\u00b7at\u00b7ra\u00b7li\u00b7schen", "Ti\u00b7ra\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "\u00bbsein oder Nichtsein\u00ab sehr nat\u00fcrlich t\u00f6nt.", "tokens": ["\u00bb", "sein", "o\u00b7der", "Nich\u00b7tsein", "\u00ab", "sehr", "na\u00b7t\u00fcr\u00b7lich", "t\u00f6nt", "."], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "VAINF", "KON", "NN", "$(", "ADV", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Oft hab' ich mich ertappt in stillen Stunden,", "tokens": ["Oft", "hab'", "ich", "mich", "er\u00b7tappt", "in", "stil\u00b7len", "Stun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PRF", "VVPP", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Wenn ich im Walde tr\u00e4umte vor mich hin,", "tokens": ["Wenn", "ich", "im", "Wal\u00b7de", "tr\u00e4um\u00b7te", "vor", "mich", "hin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPRART", "NN", "VVFIN", "APPR", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Da\u00df mein Gef\u00fchl ein lautes Wort gefunden.", "tokens": ["Da\u00df", "mein", "Ge\u00b7f\u00fchl", "ein", "lau\u00b7tes", "Wort", "ge\u00b7fun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Verlorne Kl\u00e4nge \u2013 manchmal tr\u00fcb der Sinn \u2013,", "tokens": ["Ver\u00b7lor\u00b7ne", "Kl\u00e4n\u00b7ge", "\u2013", "manch\u00b7mal", "tr\u00fcb", "der", "Sinn", "\u2013", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADJA", "NN", "$(", "ADV", "ADJD", "ART", "NN", "$(", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Doch zu Sonetten wollten sie sich runden,", "tokens": ["Doch", "zu", "So\u00b7net\u00b7ten", "woll\u00b7ten", "sie", "sich", "run\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "VMFIN", "PPER", "PRF", "ADJA", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Weil ich nun doch einmal ein Dichter bin.", "tokens": ["Weil", "ich", "nun", "doch", "ein\u00b7mal", "ein", "Dich\u00b7ter", "bin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "ADV", "ART", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "Sie haben's auf den Brettern streng verp\u00f6nt,", "tokens": ["Sie", "ha\u00b7ben's", "auf", "den", "Bret\u00b7tern", "streng", "ver\u00b7p\u00f6nt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "ART", "NN", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Sein Herz in Selbstgespr\u00e4chen zu entladen.", "tokens": ["Sein", "Herz", "in", "Selbst\u00b7ge\u00b7spr\u00e4\u00b7chen", "zu", "ent\u00b7la\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Was Dichter sich erlaubt von Gottes Gnaden,", "tokens": ["Was", "Dich\u00b7ter", "sich", "er\u00b7laubt", "von", "Got\u00b7tes", "Gna\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "PRF", "VVPP", "APPR", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Wird von den J\u00fcngsten als ", "tokens": ["Wird", "von", "den", "J\u00fcng\u00b7sten", "als"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "APPR", "ART", "NN", "KOKOM"], "meter": "+--+-+", "measure": "iambic.tri.invert"}}, "stanza.6": {"line.1": {"text": "Mir, an die alte Technik noch gew\u00f6hnt,", "tokens": ["Mir", ",", "an", "die", "al\u00b7te", "Tech\u00b7nik", "noch", "ge\u00b7w\u00f6hnt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "APPR", "ART", "ADJA", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Scheint: die Natur kommt nicht dabei zu Schaden,", "tokens": ["Scheint", ":", "die", "Na\u00b7tur", "kommt", "nicht", "da\u00b7bei", "zu", "Scha\u00b7den", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$.", "ART", "NN", "VVFIN", "PTKNEG", "PAV", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Da frei von theatralischen Tiraden", "tokens": ["Da", "frei", "von", "the\u00b7at\u00b7ra\u00b7li\u00b7schen", "Ti\u00b7ra\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "\u00bbsein oder Nichtsein\u00ab sehr nat\u00fcrlich t\u00f6nt.", "tokens": ["\u00bb", "sein", "o\u00b7der", "Nich\u00b7tsein", "\u00ab", "sehr", "na\u00b7t\u00fcr\u00b7lich", "t\u00f6nt", "."], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "VAINF", "KON", "NN", "$(", "ADV", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.7": {"line.1": {"text": "Oft hab' ich mich ertappt in stillen Stunden,", "tokens": ["Oft", "hab'", "ich", "mich", "er\u00b7tappt", "in", "stil\u00b7len", "Stun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PRF", "VVPP", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Wenn ich im Walde tr\u00e4umte vor mich hin,", "tokens": ["Wenn", "ich", "im", "Wal\u00b7de", "tr\u00e4um\u00b7te", "vor", "mich", "hin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPRART", "NN", "VVFIN", "APPR", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Da\u00df mein Gef\u00fchl ein lautes Wort gefunden.", "tokens": ["Da\u00df", "mein", "Ge\u00b7f\u00fchl", "ein", "lau\u00b7tes", "Wort", "ge\u00b7fun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.8": {"line.1": {"text": "Verlorne Kl\u00e4nge \u2013 manchmal tr\u00fcb der Sinn \u2013,", "tokens": ["Ver\u00b7lor\u00b7ne", "Kl\u00e4n\u00b7ge", "\u2013", "manch\u00b7mal", "tr\u00fcb", "der", "Sinn", "\u2013", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADJA", "NN", "$(", "ADV", "ADJD", "ART", "NN", "$(", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Doch zu Sonetten wollten sie sich runden,", "tokens": ["Doch", "zu", "So\u00b7net\u00b7ten", "woll\u00b7ten", "sie", "sich", "run\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "VMFIN", "PPER", "PRF", "ADJA", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Weil ich nun doch einmal ein Dichter bin.", "tokens": ["Weil", "ich", "nun", "doch", "ein\u00b7mal", "ein", "Dich\u00b7ter", "bin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "ADV", "ART", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}}}}