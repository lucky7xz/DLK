{"textgrid.poem.47958": {"metadata": {"author": {"name": "M\u00fcller-Jahnke, Clara", "birth": "N.A.", "death": "N.A."}, "title": "Das erste Lied", "genre": "verse", "period": "N.A.", "pub_year": 1882, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Das erste Lied, das ich gesungen, \u2013", "tokens": ["Das", "ers\u00b7te", "Lied", ",", "das", "ich", "ge\u00b7sun\u00b7gen", ",", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PRELS", "PPER", "VVPP", "$,", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "um die Kritik war mir nicht gram, \u2013", "tokens": ["um", "die", "Kri\u00b7tik", "war", "mir", "nicht", "gram", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "ART", "NN", "VAFIN", "PPER", "PTKNEG", "ADJD", "$,", "$("], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "von meinen Lippen ist's geklungen", "tokens": ["von", "mei\u00b7nen", "Lip\u00b7pen", "ist's", "ge\u00b7klun\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "VAFIN", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "so frisch, wie's mir vom Herzen kam.", "tokens": ["so", "frisch", ",", "wie's", "mir", "vom", "Her\u00b7zen", "kam", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "KOUS", "PPER", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Ich reimte \u00bbsehnen\u00ab mit \u00bberkennen\u00ab", "tokens": ["Ich", "reim\u00b7te", "\u00bb", "seh\u00b7nen", "\u00ab", "mit", "\u00bb", "er\u00b7ken\u00b7nen", "\u00ab"], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PPER", "VVFIN", "$(", "VVINF", "$(", "APPR", "$(", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "und \u00bbdich\u00ab mit \u00bbnicht\u00ab und \u00bbTag\u00ab mit \u00bbNacht\u00ab;", "tokens": ["und", "\u00bb", "dich", "\u00ab", "mit", "\u00bb", "nicht", "\u00ab", "und", "\u00bb", "Tag", "\u00ab", "mit", "\u00bb", "Nacht", "\u00ab", ";"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "punct"], "pos": ["KON", "$(", "PPER", "$(", "APPR", "$(", "PTKNEG", "$(", "KON", "$(", "NN", "$(", "APPR", "$(", "NN", "$(", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "doch kann kein F\u00fcrst sich reicher nennen,", "tokens": ["doch", "kann", "kein", "F\u00fcrst", "sich", "rei\u00b7cher", "nen\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PIAT", "NN", "PRF", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "als mich mein erstes Lied gemacht.", "tokens": ["als", "mich", "mein", "ers\u00b7tes", "Lied", "ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Das Kunstgef\u00fchl f\u00fcr Ma\u00df und Einheit", "tokens": ["Das", "Kunst\u00b7ge\u00b7f\u00fchl", "f\u00fcr", "Ma\u00df", "und", "Ein\u00b7heit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "hat mich kein Menschenmund gelehrt,", "tokens": ["hat", "mich", "kein", "Men\u00b7schen\u00b7mund", "ge\u00b7lehrt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PIAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "mit Silbenzahl und Formenreinheit", "tokens": ["mit", "Sil\u00b7ben\u00b7zahl", "und", "For\u00b7men\u00b7rein\u00b7heit"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "hatt' ich mir nie das Herz beschwert . . . .", "tokens": ["hatt'", "ich", "mir", "nie", "das", "Herz", "be\u00b7schwert", ".", ".", ".", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct", "punct"], "pos": ["VAFIN", "PPER", "PPER", "ADV", "ART", "NN", "VVPP", "$.", "$.", "$.", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Ich ahnte nur, da\u00df tief im Grunde", "tokens": ["Ich", "ahn\u00b7te", "nur", ",", "da\u00df", "tief", "im", "Grun\u00b7de"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "$,", "KOUS", "ADJD", "APPRART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "der Zukunft weltverloren schlief", "tokens": ["der", "Zu\u00b7kunft", "welt\u00b7ver\u00b7lo\u00b7ren", "schlief"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "VVINF", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "ein Etwas, das mir jede Stunde", "tokens": ["ein", "Et\u00b7was", ",", "das", "mir", "je\u00b7de", "Stun\u00b7de"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADV", "$,", "PRELS", "PPER", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "ein \u00bbSinge!\u00ab in die Seele rief!", "tokens": ["ein", "\u00bb", "Sin\u00b7ge", "!", "\u00ab", "in", "die", "See\u00b7le", "rief", "!"], "token_info": ["word", "punct", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "$(", "NN", "$.", "$(", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Das erste Lied, das ich gesungen, \u2013", "tokens": ["Das", "ers\u00b7te", "Lied", ",", "das", "ich", "ge\u00b7sun\u00b7gen", ",", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PRELS", "PPER", "VVPP", "$,", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "um die Kritik war mir nicht gram, \u2013", "tokens": ["um", "die", "Kri\u00b7tik", "war", "mir", "nicht", "gram", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "ART", "NN", "VAFIN", "PPER", "PTKNEG", "ADJD", "$,", "$("], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "von meinen Lippen ist's geklungen", "tokens": ["von", "mei\u00b7nen", "Lip\u00b7pen", "ist's", "ge\u00b7klun\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "VAFIN", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "so frisch, wie's mir vom Herzen kam.", "tokens": ["so", "frisch", ",", "wie's", "mir", "vom", "Her\u00b7zen", "kam", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "KOUS", "PPER", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Ich reimte \u00bbsehnen\u00ab mit \u00bberkennen\u00ab", "tokens": ["Ich", "reim\u00b7te", "\u00bb", "seh\u00b7nen", "\u00ab", "mit", "\u00bb", "er\u00b7ken\u00b7nen", "\u00ab"], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PPER", "VVFIN", "$(", "VVINF", "$(", "APPR", "$(", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "und \u00bbdich\u00ab mit \u00bbnicht\u00ab und \u00bbTag\u00ab mit \u00bbNacht\u00ab;", "tokens": ["und", "\u00bb", "dich", "\u00ab", "mit", "\u00bb", "nicht", "\u00ab", "und", "\u00bb", "Tag", "\u00ab", "mit", "\u00bb", "Nacht", "\u00ab", ";"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "punct"], "pos": ["KON", "$(", "PPER", "$(", "APPR", "$(", "PTKNEG", "$(", "KON", "$(", "NN", "$(", "APPR", "$(", "NN", "$(", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "doch kann kein F\u00fcrst sich reicher nennen,", "tokens": ["doch", "kann", "kein", "F\u00fcrst", "sich", "rei\u00b7cher", "nen\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PIAT", "NN", "PRF", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "als mich mein erstes Lied gemacht.", "tokens": ["als", "mich", "mein", "ers\u00b7tes", "Lied", "ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Das Kunstgef\u00fchl f\u00fcr Ma\u00df und Einheit", "tokens": ["Das", "Kunst\u00b7ge\u00b7f\u00fchl", "f\u00fcr", "Ma\u00df", "und", "Ein\u00b7heit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "hat mich kein Menschenmund gelehrt,", "tokens": ["hat", "mich", "kein", "Men\u00b7schen\u00b7mund", "ge\u00b7lehrt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PIAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "mit Silbenzahl und Formenreinheit", "tokens": ["mit", "Sil\u00b7ben\u00b7zahl", "und", "For\u00b7men\u00b7rein\u00b7heit"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "hatt' ich mir nie das Herz beschwert . . . .", "tokens": ["hatt'", "ich", "mir", "nie", "das", "Herz", "be\u00b7schwert", ".", ".", ".", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct", "punct"], "pos": ["VAFIN", "PPER", "PPER", "ADV", "ART", "NN", "VVPP", "$.", "$.", "$.", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Ich ahnte nur, da\u00df tief im Grunde", "tokens": ["Ich", "ahn\u00b7te", "nur", ",", "da\u00df", "tief", "im", "Grun\u00b7de"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "$,", "KOUS", "ADJD", "APPRART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "der Zukunft weltverloren schlief", "tokens": ["der", "Zu\u00b7kunft", "welt\u00b7ver\u00b7lo\u00b7ren", "schlief"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "VVINF", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "ein Etwas, das mir jede Stunde", "tokens": ["ein", "Et\u00b7was", ",", "das", "mir", "je\u00b7de", "Stun\u00b7de"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADV", "$,", "PRELS", "PPER", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "ein \u00bbSinge!\u00ab in die Seele rief!", "tokens": ["ein", "\u00bb", "Sin\u00b7ge", "!", "\u00ab", "in", "die", "See\u00b7le", "rief", "!"], "token_info": ["word", "punct", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "$(", "NN", "$.", "$(", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}