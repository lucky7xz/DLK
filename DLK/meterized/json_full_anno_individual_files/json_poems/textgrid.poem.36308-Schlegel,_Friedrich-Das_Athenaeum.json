{"textgrid.poem.36308": {"metadata": {"author": {"name": "Schlegel, Friedrich", "birth": "N.A.", "death": "N.A."}, "title": "Das Athenaeum", "genre": "verse", "period": "N.A.", "pub_year": 1800, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Der Bildung Strahlen all' in eins zu fassen,", "tokens": ["Der", "Bil\u00b7dung", "Strah\u00b7len", "all'", "in", "eins", "zu", "fas\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "PIS", "APPR", "PIS", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Vom Kranken ganz zu scheiden das Gesunde,", "tokens": ["Vom", "Kran\u00b7ken", "ganz", "zu", "schei\u00b7den", "das", "Ge\u00b7sun\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADV", "PTKZU", "VVINF", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Bestrebten wir uns treu im freien Bunde,", "tokens": ["Be\u00b7streb\u00b7ten", "wir", "uns", "treu", "im", "frei\u00b7en", "Bun\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "ADJD", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und wollten uns auf uns allein verlassen:", "tokens": ["Und", "woll\u00b7ten", "uns", "auf", "uns", "al\u00b7lein", "ver\u00b7las\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "APPR", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Nach alter Weise konnt' ich nie es lassen,", "tokens": ["Nach", "al\u00b7ter", "Wei\u00b7se", "konnt'", "ich", "nie", "es", "las\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VMFIN", "PPER", "ADV", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "So sicher ich auch war der rechten Kunde,", "tokens": ["So", "si\u00b7cher", "ich", "auch", "war", "der", "rech\u00b7ten", "Kun\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "ADV", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Mir neu zu reizen stets des Zweifels Wunde,", "tokens": ["Mir", "neu", "zu", "rei\u00b7zen", "stets", "des", "Zwei\u00b7fels", "Wun\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "PTKZU", "VVINF", "VVFIN", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und was an mir beschr\u00e4nkt mir schien, zu hassen.", "tokens": ["Und", "was", "an", "mir", "be\u00b7schr\u00e4nkt", "mir", "schien", ",", "zu", "has\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PWS", "APPR", "PPER", "VVFIN", "PPER", "VVFIN", "$,", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Nun schreit und schreibt in Ohnmacht sehr gesch\u00e4ftig,", "tokens": ["Nun", "schreit", "und", "schreibt", "in", "Ohn\u00b7macht", "sehr", "ge\u00b7sch\u00e4f\u00b7tig", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KON", "VVFIN", "APPR", "NN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Als w\u00e4r's im tiefsten Herzen tief beleidigt,", "tokens": ["Als", "w\u00e4r's", "im", "tiefs\u00b7ten", "Her\u00b7zen", "tief", "be\u00b7lei\u00b7digt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VAFIN", "APPRART", "ADJA", "NN", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Der Platten Volk von Hamburg bis nach Schwaben.", "tokens": ["Der", "Plat\u00b7ten", "Volk", "von", "Ham\u00b7burg", "bis", "nach", "Schwa\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "APPR", "NE", "KON", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Ob unsern guten Zweck erreicht wir haben,", "tokens": ["Ob", "un\u00b7sern", "gu\u00b7ten", "Zweck", "er\u00b7reicht", "wir", "ha\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "ADJA", "NN", "VVFIN", "PPER", "VAFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Zweifl' ich nicht mehr; es hat's die Tat beeidigt,", "tokens": ["Zweifl'", "ich", "nicht", "mehr", ";", "es", "hat's", "die", "Tat", "be\u00b7ei\u00b7digt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "PTKNEG", "ADV", "$.", "PPER", "VAFIN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Da\u00df unsre Ansicht allgemein und kr\u00e4ftig.", "tokens": ["Da\u00df", "uns\u00b7re", "An\u00b7sicht", "all\u00b7ge\u00b7mein", "und", "kr\u00e4f\u00b7tig", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "Der Bildung Strahlen all' in eins zu fassen,", "tokens": ["Der", "Bil\u00b7dung", "Strah\u00b7len", "all'", "in", "eins", "zu", "fas\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "PIS", "APPR", "PIS", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Vom Kranken ganz zu scheiden das Gesunde,", "tokens": ["Vom", "Kran\u00b7ken", "ganz", "zu", "schei\u00b7den", "das", "Ge\u00b7sun\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADV", "PTKZU", "VVINF", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Bestrebten wir uns treu im freien Bunde,", "tokens": ["Be\u00b7streb\u00b7ten", "wir", "uns", "treu", "im", "frei\u00b7en", "Bun\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "ADJD", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und wollten uns auf uns allein verlassen:", "tokens": ["Und", "woll\u00b7ten", "uns", "auf", "uns", "al\u00b7lein", "ver\u00b7las\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "APPR", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "Nach alter Weise konnt' ich nie es lassen,", "tokens": ["Nach", "al\u00b7ter", "Wei\u00b7se", "konnt'", "ich", "nie", "es", "las\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VMFIN", "PPER", "ADV", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "So sicher ich auch war der rechten Kunde,", "tokens": ["So", "si\u00b7cher", "ich", "auch", "war", "der", "rech\u00b7ten", "Kun\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "ADV", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Mir neu zu reizen stets des Zweifels Wunde,", "tokens": ["Mir", "neu", "zu", "rei\u00b7zen", "stets", "des", "Zwei\u00b7fels", "Wun\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "PTKZU", "VVINF", "VVFIN", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und was an mir beschr\u00e4nkt mir schien, zu hassen.", "tokens": ["Und", "was", "an", "mir", "be\u00b7schr\u00e4nkt", "mir", "schien", ",", "zu", "has\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PWS", "APPR", "PPER", "VVFIN", "PPER", "VVFIN", "$,", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.7": {"line.1": {"text": "Nun schreit und schreibt in Ohnmacht sehr gesch\u00e4ftig,", "tokens": ["Nun", "schreit", "und", "schreibt", "in", "Ohn\u00b7macht", "sehr", "ge\u00b7sch\u00e4f\u00b7tig", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KON", "VVFIN", "APPR", "NN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Als w\u00e4r's im tiefsten Herzen tief beleidigt,", "tokens": ["Als", "w\u00e4r's", "im", "tiefs\u00b7ten", "Her\u00b7zen", "tief", "be\u00b7lei\u00b7digt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VAFIN", "APPRART", "ADJA", "NN", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Der Platten Volk von Hamburg bis nach Schwaben.", "tokens": ["Der", "Plat\u00b7ten", "Volk", "von", "Ham\u00b7burg", "bis", "nach", "Schwa\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "APPR", "NE", "KON", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.8": {"line.1": {"text": "Ob unsern guten Zweck erreicht wir haben,", "tokens": ["Ob", "un\u00b7sern", "gu\u00b7ten", "Zweck", "er\u00b7reicht", "wir", "ha\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "ADJA", "NN", "VVFIN", "PPER", "VAFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Zweifl' ich nicht mehr; es hat's die Tat beeidigt,", "tokens": ["Zweifl'", "ich", "nicht", "mehr", ";", "es", "hat's", "die", "Tat", "be\u00b7ei\u00b7digt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "PTKNEG", "ADV", "$.", "PPER", "VAFIN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Da\u00df unsre Ansicht allgemein und kr\u00e4ftig.", "tokens": ["Da\u00df", "uns\u00b7re", "An\u00b7sicht", "all\u00b7ge\u00b7mein", "und", "kr\u00e4f\u00b7tig", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}}}}