{"textgrid.poem.49624": {"metadata": {"author": {"name": "Thoma, Ludwig", "birth": "N.A.", "death": "N.A."}, "title": "Kassel", "genre": "verse", "period": "N.A.", "pub_year": 1894, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Alter Ha\u00df ist neu entbronnen,", "tokens": ["Al\u00b7ter", "Ha\u00df", "ist", "neu", "ent\u00b7bron\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "VAFIN", "ADJD", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "So wie einst vor K\u00f6niggr\u00e4tz.", "tokens": ["So", "wie", "einst", "vor", "K\u00f6\u00b7nig\u00b7gr\u00e4tz", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "ADV", "APPR", "NN", "$."], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.3": {"text": "Nord und S\u00fcd haut sich mit Wonnen", "tokens": ["Nord", "und", "S\u00fcd", "haut", "sich", "mit", "Won\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "KON", "NN", "VVFIN", "PRF", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und mit Zornmut auf die t\u00eates.", "tokens": ["Und", "mit", "Zorn\u00b7mut", "auf", "die", "t\u00eates", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "APPR", "ART", "ADJA", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "In dem weiten Saal zu Kassel", "tokens": ["In", "dem", "wei\u00b7ten", "Saal", "zu", "Kas\u00b7sel"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "War das Schlacht- und Ehrenfeld;", "tokens": ["War", "das", "Schlacht", "und", "Eh\u00b7ren\u00b7feld", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "TRUNC", "KON", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "F\u00fcrchterlich war das Gequassel,", "tokens": ["F\u00fcrch\u00b7ter\u00b7lich", "war", "das", "Ge\u00b7quas\u00b7sel", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "ART", "NN", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.4": {"text": "Jeder zeigte sich als Held.", "tokens": ["Je\u00b7der", "zeig\u00b7te", "sich", "als", "Held", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PRF", "KOUS", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Mit des Maules Mitrailleuse", "tokens": ["Mit", "des", "Mau\u00b7les", "Mit\u00b7rail\u00b7leu\u00b7se"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und dem schnellen Schnauzgewehr", "tokens": ["Und", "dem", "schnel\u00b7len", "Schn\u00b7auz\u00b7ge\u00b7wehr"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN"], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Fiel der Norden voll Get\u00f6se", "tokens": ["Fiel", "der", "Nor\u00b7den", "voll", "Ge\u00b7t\u00f6\u00b7se"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "NN", "ADJD", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "G\u00e4hlings \u00fcber Bayern her.", "tokens": ["G\u00e4h\u00b7lings", "\u00fc\u00b7ber", "Bay\u00b7ern", "her", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NE", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Statt Granaten, statt der Bomben", "tokens": ["Statt", "Gra\u00b7na\u00b7ten", ",", "statt", "der", "Bom\u00b7ben"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["NN", "NN", "$,", "KOUI", "ART", "NN"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.2": {"text": "Hagelte das Wortgescho\u00df,", "tokens": ["Ha\u00b7gel\u00b7te", "das", "Wort\u00b7ge\u00b7scho\u00df", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und so heftig, da\u00df die Plomben", "tokens": ["Und", "so", "hef\u00b7tig", ",", "da\u00df", "die", "Plom\u00b7ben"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "ADV", "ADJD", "$,", "KOUS", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wurden in den Z\u00e4hnen los.", "tokens": ["Wur\u00b7den", "in", "den", "Z\u00e4h\u00b7nen", "los", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Die bew\u00e4hrte Preu\u00dfenplautze", "tokens": ["Die", "be\u00b7w\u00e4hr\u00b7te", "Preu\u00b7\u00dfen\u00b7plaut\u00b7ze"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Hat die Bayern rungeniert,", "tokens": ["Hat", "die", "Bay\u00b7ern", "run\u00b7ge\u00b7niert", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Weil bekanntlich diese Schnauze", "tokens": ["Weil", "be\u00b7kannt\u00b7lich", "die\u00b7se", "Schnau\u00b7ze"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ADV", "PDAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Dreimal schneller repetiert.", "tokens": ["Drei\u00b7mal", "schnel\u00b7ler", "re\u00b7pe\u00b7tiert", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Alter Ha\u00df ist neu entbronnen,", "tokens": ["Al\u00b7ter", "Ha\u00df", "ist", "neu", "ent\u00b7bron\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "VAFIN", "ADJD", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "So wie einst vor K\u00f6niggr\u00e4tz.", "tokens": ["So", "wie", "einst", "vor", "K\u00f6\u00b7nig\u00b7gr\u00e4tz", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "ADV", "APPR", "NN", "$."], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.3": {"text": "Nord und S\u00fcd haut sich mit Wonnen", "tokens": ["Nord", "und", "S\u00fcd", "haut", "sich", "mit", "Won\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "KON", "NN", "VVFIN", "PRF", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und mit Zornmut auf die t\u00eates.", "tokens": ["Und", "mit", "Zorn\u00b7mut", "auf", "die", "t\u00eates", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "APPR", "ART", "ADJA", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "In dem weiten Saal zu Kassel", "tokens": ["In", "dem", "wei\u00b7ten", "Saal", "zu", "Kas\u00b7sel"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "War das Schlacht- und Ehrenfeld;", "tokens": ["War", "das", "Schlacht", "und", "Eh\u00b7ren\u00b7feld", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "TRUNC", "KON", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "F\u00fcrchterlich war das Gequassel,", "tokens": ["F\u00fcrch\u00b7ter\u00b7lich", "war", "das", "Ge\u00b7quas\u00b7sel", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "ART", "NN", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.4": {"text": "Jeder zeigte sich als Held.", "tokens": ["Je\u00b7der", "zeig\u00b7te", "sich", "als", "Held", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PRF", "KOUS", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Mit des Maules Mitrailleuse", "tokens": ["Mit", "des", "Mau\u00b7les", "Mit\u00b7rail\u00b7leu\u00b7se"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und dem schnellen Schnauzgewehr", "tokens": ["Und", "dem", "schnel\u00b7len", "Schn\u00b7auz\u00b7ge\u00b7wehr"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN"], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Fiel der Norden voll Get\u00f6se", "tokens": ["Fiel", "der", "Nor\u00b7den", "voll", "Ge\u00b7t\u00f6\u00b7se"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "NN", "ADJD", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "G\u00e4hlings \u00fcber Bayern her.", "tokens": ["G\u00e4h\u00b7lings", "\u00fc\u00b7ber", "Bay\u00b7ern", "her", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NE", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Statt Granaten, statt der Bomben", "tokens": ["Statt", "Gra\u00b7na\u00b7ten", ",", "statt", "der", "Bom\u00b7ben"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["NN", "NN", "$,", "KOUI", "ART", "NN"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.2": {"text": "Hagelte das Wortgescho\u00df,", "tokens": ["Ha\u00b7gel\u00b7te", "das", "Wort\u00b7ge\u00b7scho\u00df", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und so heftig, da\u00df die Plomben", "tokens": ["Und", "so", "hef\u00b7tig", ",", "da\u00df", "die", "Plom\u00b7ben"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "ADV", "ADJD", "$,", "KOUS", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wurden in den Z\u00e4hnen los.", "tokens": ["Wur\u00b7den", "in", "den", "Z\u00e4h\u00b7nen", "los", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Die bew\u00e4hrte Preu\u00dfenplautze", "tokens": ["Die", "be\u00b7w\u00e4hr\u00b7te", "Preu\u00b7\u00dfen\u00b7plaut\u00b7ze"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Hat die Bayern rungeniert,", "tokens": ["Hat", "die", "Bay\u00b7ern", "run\u00b7ge\u00b7niert", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Weil bekanntlich diese Schnauze", "tokens": ["Weil", "be\u00b7kannt\u00b7lich", "die\u00b7se", "Schnau\u00b7ze"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ADV", "PDAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Dreimal schneller repetiert.", "tokens": ["Drei\u00b7mal", "schnel\u00b7ler", "re\u00b7pe\u00b7tiert", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}