{"textgrid.poem.48263": {"metadata": {"author": {"name": "Fontane, Theodor", "birth": "N.A.", "death": "N.A."}, "title": "Olaf Kragebeen", "genre": "verse", "period": "N.A.", "pub_year": 1889, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Olaf ", "tokens": ["O\u00b7laf"], "token_info": ["word"], "pos": ["NE"], "meter": "+-", "measure": "trochaic.single"}, "line.2": {"text": "\u00bbstawanger-Fjord liegt noch im Schnee,", "tokens": ["\u00bb", "sta\u00b7wan\u00b7ger\u00b7\u00b7F\u00b7jord", "liegt", "noch", "im", "Schnee", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "NE", "VVFIN", "ADV", "APPRART", "NN", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.3": {"text": "Schnee die Felsen und Schnee die Bucht,", "tokens": ["Schnee", "die", "Fel\u00b7sen", "und", "Schnee", "die", "Bucht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "KON", "NN", "ART", "NN", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.4": {"text": "Und doch ist der Winter schon auf der Flucht,", "tokens": ["Und", "doch", "ist", "der", "Win\u00b7ter", "schon", "auf", "der", "Flucht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "ART", "NN", "ADV", "APPR", "ART", "NN", "$,"], "meter": "--+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Von Westen weht's \u2013 einen Fr\u00fchlingston,", "tokens": ["Von", "Wes\u00b7ten", "weht's", "\u2013", "ei\u00b7nen", "Fr\u00fch\u00b7lings\u00b7ton", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "NN", "NE", "$(", "ART", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Ich f\u00fchl' ihn in Luft und Sonne schon,", "tokens": ["Ich", "f\u00fchl'", "ihn", "in", "Luft", "und", "Son\u00b7ne", "schon", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "NN", "KON", "NN", "ADV", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Und das Meer ein Spiegel ... Steig' ich zu Schiff?", "tokens": ["Und", "das", "Meer", "ein", "Spie\u00b7gel", "...", "Steig'", "ich", "zu", "Schiff", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ART", "NN", "$(", "VVIMP", "PPER", "APPR", "NN", "$."], "meter": "--+-+-+--+", "measure": "iambic.tetra.chol"}, "line.8": {"text": "\u00dcberrasch' ich den Feind auf Kongens-Kliff?", "tokens": ["\u00dc\u00b7ber\u00b7rasch'", "ich", "den", "Feind", "auf", "Kon\u00b7gens\u00b7K\u00b7liff", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "APPR", "NN", "$."], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.9": {"text": "Ihr, meine R\u00e4te zu Land und See,", "tokens": ["Ihr", ",", "mei\u00b7ne", "R\u00e4\u00b7te", "zu", "Land", "und", "See", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PPOSAT", "NN", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "Schreibt euren Rat mir in den Schnee,", "tokens": ["Schreibt", "eu\u00b7ren", "Rat", "mir", "in", "den", "Schnee", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "La\u00dft mich eure Zeichen ersp\u00e4hn,", "tokens": ["La\u00dft", "mich", "eu\u00b7re", "Zei\u00b7chen", "er\u00b7sp\u00e4hn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "PPOSAT", "NN", "VVINF", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.12": {"text": "Ihr, meine Weisen, ihr meine ", "tokens": ["Ihr", ",", "mei\u00b7ne", "Wei\u00b7sen", ",", "ihr", "mei\u00b7ne"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word"], "pos": ["PPER", "$,", "PPOSAT", "NN", "$,", "PPER", "PPOSAT"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.2": {"line.1": {"text": "Und kaum gerufen, so sind sie da,", "tokens": ["Und", "kaum", "ge\u00b7ru\u00b7fen", ",", "so", "sind", "sie", "da", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVPP", "$,", "ADV", "VAFIN", "PPER", "ADV", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Setzen sich um ihn, fern und nah,", "tokens": ["Set\u00b7zen", "sich", "um", "ihn", ",", "fern", "und", "nah", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "APPR", "PPER", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "+----+-+", "measure": "dactylic.init"}, "line.3": {"text": "Aber was er auch lockend tu',", "tokens": ["A\u00b7ber", "was", "er", "auch", "lo\u00b7ckend", "tu'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "ADV", "ADJD", "PTKVZ", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Keine, keine h\u00fcpft auf ihn zu,", "tokens": ["Kei\u00b7ne", ",", "kei\u00b7ne", "h\u00fcpft", "auf", "ihn", "zu", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "$,", "PIAT", "VVFIN", "APPR", "PPER", "PTKVZ", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.5": {"text": "Wenden sich all, ihrer F\u00fc\u00dfe Spur,", "tokens": ["Wen\u00b7den", "sich", "all", ",", "ih\u00b7rer", "F\u00fc\u00b7\u00dfe", "Spur", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIAT", "PRF", "PIAT", "$,", "PPOSAT", "NN", "NN", "$,"], "meter": "+-----+-+", "measure": "dactylic.init"}, "line.6": {"text": "Abgewandt, r\u00fcckw\u00e4rts f\u00fchrt sie nur,", "tokens": ["Ab\u00b7ge\u00b7wandt", ",", "r\u00fcck\u00b7w\u00e4rts", "f\u00fchrt", "sie", "nur", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "ADV", "VVFIN", "PPER", "ADV", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.7": {"text": "R\u00fcckw\u00e4rts h\u00fcpfen sie Schritt um Schritt:", "tokens": ["R\u00fcck\u00b7w\u00e4rts", "h\u00fcp\u00b7fen", "sie", "Schritt", "um", "Schritt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "NN", "APPR", "NN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.8": {"text": "\u00bbkr\u00e4hen, nehmt ihr das Gl\u00fcck mir mit?\u00ab", "tokens": ["\u00bb", "kr\u00e4\u00b7hen", ",", "nehmt", "ihr", "das", "Gl\u00fcck", "mir", "mit", "?", "\u00ab"], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VVINF", "$,", "VVFIN", "PPER", "ART", "NN", "PPER", "PTKVZ", "$.", "$("], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.3": {"line.1": {"text": "Und als er so sprach und als er so sann,", "tokens": ["Und", "als", "er", "so", "sprach", "und", "als", "er", "so", "sann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "VVFIN", "KON", "KOUS", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Erik Jarl, sein Freund, tritt an ihn heran:", "tokens": ["E\u00b7rik", "Jarl", ",", "sein", "Freund", ",", "tritt", "an", "ihn", "he\u00b7ran", ":"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "PPOSAT", "NN", "$,", "VVFIN", "APPR", "PPER", "PTKVZ", "$."], "meter": "--+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "\u00bbk\u00f6nig Olaf, der D\u00e4ne spielt um sein Gl\u00fcck,", "tokens": ["\u00bb", "k\u00f6\u00b7nig", "O\u00b7laf", ",", "der", "D\u00e4\u00b7ne", "spielt", "um", "sein", "Gl\u00fcck", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VMFIN", "NE", "$,", "ART", "NN", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "+--+-+-+--+", "measure": "iambic.penta.invert"}, "line.4": {"text": "Im \u00d6resund hielt's ihn nicht l\u00e4nger zur\u00fcck,", "tokens": ["Im", "\u00d6\u00b7re\u00b7sund", "hielt's", "ihn", "nicht", "l\u00e4n\u00b7ger", "zu\u00b7r\u00fcck", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PPER", "PTKNEG", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.5": {"text": "Aus der Kj\u00f6ge Bucht, aus dem Wassersack,", "tokens": ["Aus", "der", "Kj\u00f6\u00b7ge", "Bucht", ",", "aus", "dem", "Was\u00b7ser\u00b7sack", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "$,", "APPR", "ART", "NN", "$,"], "meter": "--+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Ist er hinaus ins Skager-Rak,", "tokens": ["Ist", "er", "hin\u00b7aus", "ins", "Ska\u00b7ger\u00b7Rak", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Hundert Schiffe f\u00fchrt er, zehnhundert an Bord \u2013", "tokens": ["Hun\u00b7dert", "Schif\u00b7fe", "f\u00fchrt", "er", ",", "zehn\u00b7hun\u00b7dert", "an", "Bord", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "VVFIN", "PPER", "$,", "VVFIN", "APPR", "NN", "$("], "meter": "+-+-+---+-+", "measure": "unknown.measure.penta"}, "line.8": {"text": "Auf, Olaf, auf, aus Stavanger-Fjord!\u00ab", "tokens": ["Auf", ",", "O\u00b7laf", ",", "auf", ",", "aus", "Stavan\u00b7ger\u00b7\u00b7F\u00b7jord", "!", "\u00ab"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "punct", "punct"], "pos": ["APPR", "$,", "NE", "$,", "PTKVZ", "$,", "APPR", "NN", "$.", "$("], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.4": {"line.1": {"text": "Und der K\u00f6nig steigt hinab an das Meer,", "tokens": ["Und", "der", "K\u00f6\u00b7nig", "steigt", "hin\u00b7ab", "an", "das", "Meer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "ADV", "APPR", "ART", "NN", "$,"], "meter": "--+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Seine Kr\u00e4hen kreischen um ihn her,", "tokens": ["Sei\u00b7ne", "Kr\u00e4\u00b7hen", "krei\u00b7schen", "um", "ihn", "her", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "APPR", "PPER", "PTKVZ", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Er h\u00f6rt nicht mehr ihr schrill Geschrei.", "tokens": ["Er", "h\u00f6rt", "nicht", "mehr", "ihr", "schrill", "Ge\u00b7schrei", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "ADV", "PPER", "ADJD", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "\u00bberik Jarl\u00ab, so spricht er, \u00bb", "tokens": ["\u00bb", "e\u00b7rik", "Jarl", "\u00ab", ",", "so", "spricht", "er", ",", "\u00bb"], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VVFIN", "NE", "$(", "$,", "ADV", "VVFIN", "PPER", "$,", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.5": {"text": "Und wankt der D\u00e4ne, so brichst du los,", "tokens": ["Und", "wankt", "der", "D\u00e4\u00b7ne", ",", "so", "brichst", "du", "los", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "$,", "ADV", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Ihr letztes Schiff, es mu\u00df in den Grund,", "tokens": ["Ihr", "letz\u00b7tes", "Schiff", ",", "es", "mu\u00df", "in", "den", "Grund", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,", "PPER", "VMFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.7": {"text": "Nichts darf heim in den \u00d6resund.\u00ab", "tokens": ["Nichts", "darf", "heim", "in", "den", "\u00d6\u00b7re\u00b7sund", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PIS", "VMFIN", "PTKVZ", "APPR", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Sprach es. Und als den Feind er sah,", "tokens": ["Sprach", "es", ".", "Und", "als", "den", "Feind", "er", "sah", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "$.", "KON", "KOUS", "ART", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "In goldener R\u00fcstung stand er da;", "tokens": ["In", "gol\u00b7de\u00b7ner", "R\u00fcs\u00b7tung", "stand", "er", "da", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "PPER", "ADV", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Zu F\u00fc\u00dfen ihm, des Reiches Stolz,", "tokens": ["Zu", "F\u00fc\u00b7\u00dfen", "ihm", ",", "des", "Rei\u00b7ches", "Stolz", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PPER", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Lag der Runenbogen aus Eschenholz,", "tokens": ["Lag", "der", "Ru\u00b7nen\u00b7bo\u00b7gen", "aus", "E\u00b7schen\u00b7holz", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "APPR", "NN", "$,"], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.5": {"text": "Der st\u00e4rkste Bogen in Norderland,", "tokens": ["Der", "st\u00e4rks\u00b7te", "Bo\u00b7gen", "in", "Nor\u00b7der\u00b7land", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "NE", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Keiner spannt ihn, nur Olafs Hand.", "tokens": ["Kei\u00b7ner", "spannt", "ihn", ",", "nur", "O\u00b7lafs", "Hand", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "$,", "ADV", "NE", "NN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.6": {"line.1": {"text": "Und in des Feindes gedoppelte Reihn", "tokens": ["Und", "in", "des", "Fein\u00b7des", "ge\u00b7dop\u00b7pel\u00b7te", "Reihn"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "ADJA", "NN"], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.2": {"text": "Olaf Kragebeen f\u00e4hrt jetzt mitten hinein,", "tokens": ["O\u00b7laf", "Kra\u00b7ge\u00b7been", "f\u00e4hrt", "jetzt", "mit\u00b7ten", "hin\u00b7ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "VVFIN", "ADV", "ADV", "PTKVZ", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.3": {"text": "Erik Jarl, wohl folgt er \u2013 doch nicht zum Sto\u00df,", "tokens": ["E\u00b7rik", "Jarl", ",", "wohl", "folgt", "er", "\u2013", "doch", "nicht", "zum", "Sto\u00df", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "ADV", "VVFIN", "PPER", "$(", "ADV", "PTKNEG", "APPRART", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Zum vernichtenden, l\u00f6st er von Olaf sich los,", "tokens": ["Zum", "ver\u00b7nich\u00b7ten\u00b7den", ",", "l\u00f6st", "er", "von", "O\u00b7laf", "sich", "los", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "$,", "VVFIN", "PPER", "APPR", "NE", "PRF", "PTKVZ", "$,"], "meter": "--+--+--++-+", "measure": "anapaest.tri.plus"}, "line.5": {"text": "\u00bb", "tokens": ["\u00bb"], "token_info": ["punct"], "pos": ["$("]}, "line.6": {"text": "Verrat und durch ", "tokens": ["Ver\u00b7rat", "und", "durch"], "token_info": ["word", "word", "word"], "pos": ["VVFIN", "KON", "APPR"], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "Der D\u00e4ne galt nichts, ", "tokens": ["Der", "D\u00e4\u00b7ne", "galt", "nichts", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PIS", "$,"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.8": {"text": "Norweg gegen Norweg. Erik Jarl, wirf gut,", "tokens": ["Nor\u00b7weg", "ge\u00b7gen", "Nor\u00b7weg.", "E\u00b7rik", "Jarl", ",", "wirf", "gut", ","], "token_info": ["word", "word", "abbreviation", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "APPR", "NE", "NE", "NE", "$,", "VVFIN", "ADJD", "$,"], "meter": "++--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.9": {"text": "La\u00df sehn, wer die besten W\u00fcrfe tut.\u00ab", "tokens": ["La\u00df", "sehn", ",", "wer", "die", "bes\u00b7ten", "W\u00fcr\u00b7fe", "tut", ".", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVIMP", "VVINF", "$,", "PWS", "ART", "ADJA", "NN", "VVFIN", "$.", "$("], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.7": {"line.1": {"text": "Und er nahm den Bogen, als w\u00e4r' es ein Spiel,", "tokens": ["Und", "er", "nahm", "den", "Bo\u00b7gen", ",", "als", "w\u00e4r'", "es", "ein", "Spiel", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ART", "NN", "$,", "KOKOM", "VAFIN", "PPER", "ART", "NN", "$,"], "meter": "--+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Auf seine R\u00fcstung die Sonne fiel,", "tokens": ["Auf", "sei\u00b7ne", "R\u00fcs\u00b7tung", "die", "Son\u00b7ne", "fiel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Er spannte den Bogen mit aller Kraft,", "tokens": ["Er", "spann\u00b7te", "den", "Bo\u00b7gen", "mit", "al\u00b7ler", "Kraft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "PIAT", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Klirrend zerbrach der Eschenschaft,", "tokens": ["Klir\u00b7rend", "zer\u00b7brach", "der", "E\u00b7schen\u00b7schaft", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "ART", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.5": {"text": "Und h\u00fcben und dr\u00fcben klang es zugleich:", "tokens": ["Und", "h\u00fc\u00b7ben", "und", "dr\u00fc\u00b7ben", "klang", "es", "zu\u00b7gleich", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "KON", "ADV", "VVFIN", "PPER", "ADV", "$."], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "\u00bbzerbrochen der Bogen, zerbrochen das Reich.\u00ab", "tokens": ["\u00bb", "zer\u00b7bro\u00b7chen", "der", "Bo\u00b7gen", ",", "zer\u00b7bro\u00b7chen", "das", "Reich", ".", "\u00ab"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VVPP", "ART", "NN", "$,", "VVFIN", "ART", "NN", "$.", "$("], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}}, "stanza.8": {"line.1": {"text": "Olaf Kragebeen aber, des Schiffes Mast", "tokens": ["O\u00b7laf", "Kra\u00b7ge\u00b7been", "a\u00b7ber", ",", "des", "Schif\u00b7fes", "Mast"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["NE", "NN", "ADV", "$,", "ART", "NN", "NN"], "meter": "--+-----+-+", "measure": "anapaest.init"}, "line.2": {"text": "H\u00e4lt sein Arm nicht l\u00e4nger umfa\u00dft,", "tokens": ["H\u00e4lt", "sein", "Arm", "nicht", "l\u00e4n\u00b7ger", "um\u00b7fa\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "PTKNEG", "ADJD", "VVFIN", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Er schreitet bis zu des Schiffes Bug,", "tokens": ["Er", "schrei\u00b7tet", "bis", "zu", "des", "Schif\u00b7fes", "Bug", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "ART", "NN", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Statt der Kr\u00e4hen umschwirrt ihn ein M\u00f6wenzug,", "tokens": ["Statt", "der", "Kr\u00e4\u00b7hen", "um\u00b7schwirrt", "ihn", "ein", "M\u00f6\u00b7wen\u00b7zug", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "+-+--+--+-+", "measure": "trochaic.penta.relaxed"}, "line.5": {"text": "Immer dichter flattert es um ihn her:", "tokens": ["Im\u00b7mer", "dich\u00b7ter", "flat\u00b7tert", "es", "um", "ihn", "her", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "PPER", "APPR", "PPER", "PTKVZ", "$."], "meter": "+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.6": {"text": "\u00bbwei\u00dfe Wogenkinder, euch sendet das ", "tokens": ["\u00bb", "wei\u00b7\u00dfe", "Wo\u00b7gen\u00b7kin\u00b7der", ",", "euch", "sen\u00b7det", "das"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word"], "pos": ["$(", "ADJA", "NN", "$,", "PPER", "VVFIN", "ART"], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.7": {"text": "Es ruft mich \u2013 mein Gl\u00fcck einst, nun mein Grab.\u00ab", "tokens": ["Es", "ruft", "mich", "\u2013", "mein", "Gl\u00fcck", "einst", ",", "nun", "mein", "Grab", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$(", "PPOSAT", "NN", "ADV", "$,", "ADV", "PPOSAT", "NN", "$.", "$("], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Und in goldener R\u00fcstung stieg er hinab.", "tokens": ["Und", "in", "gol\u00b7de\u00b7ner", "R\u00fcs\u00b7tung", "stieg", "er", "hin\u00b7ab", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ADJA", "NN", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "--+--+-+--+", "measure": "anapaest.di.plus"}}, "stanza.9": {"line.1": {"text": "Olaf ", "tokens": ["O\u00b7laf"], "token_info": ["word"], "pos": ["NE"], "meter": "+-", "measure": "trochaic.single"}, "line.2": {"text": "\u00bbstawanger-Fjord liegt noch im Schnee,", "tokens": ["\u00bb", "sta\u00b7wan\u00b7ger\u00b7\u00b7F\u00b7jord", "liegt", "noch", "im", "Schnee", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "NE", "VVFIN", "ADV", "APPRART", "NN", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.3": {"text": "Schnee die Felsen und Schnee die Bucht,", "tokens": ["Schnee", "die", "Fel\u00b7sen", "und", "Schnee", "die", "Bucht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "KON", "NN", "ART", "NN", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.4": {"text": "Und doch ist der Winter schon auf der Flucht,", "tokens": ["Und", "doch", "ist", "der", "Win\u00b7ter", "schon", "auf", "der", "Flucht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "ART", "NN", "ADV", "APPR", "ART", "NN", "$,"], "meter": "--+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Von Westen weht's \u2013 einen Fr\u00fchlingston,", "tokens": ["Von", "Wes\u00b7ten", "weht's", "\u2013", "ei\u00b7nen", "Fr\u00fch\u00b7lings\u00b7ton", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "NN", "NE", "$(", "ART", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Ich f\u00fchl' ihn in Luft und Sonne schon,", "tokens": ["Ich", "f\u00fchl'", "ihn", "in", "Luft", "und", "Son\u00b7ne", "schon", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "NN", "KON", "NN", "ADV", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Und das Meer ein Spiegel ... Steig' ich zu Schiff?", "tokens": ["Und", "das", "Meer", "ein", "Spie\u00b7gel", "...", "Steig'", "ich", "zu", "Schiff", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ART", "NN", "$(", "VVIMP", "PPER", "APPR", "NN", "$."], "meter": "--+-+-+--+", "measure": "iambic.tetra.chol"}, "line.8": {"text": "\u00dcberrasch' ich den Feind auf Kongens-Kliff?", "tokens": ["\u00dc\u00b7ber\u00b7rasch'", "ich", "den", "Feind", "auf", "Kon\u00b7gens\u00b7K\u00b7liff", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "APPR", "NN", "$."], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.9": {"text": "Ihr, meine R\u00e4te zu Land und See,", "tokens": ["Ihr", ",", "mei\u00b7ne", "R\u00e4\u00b7te", "zu", "Land", "und", "See", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PPOSAT", "NN", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "Schreibt euren Rat mir in den Schnee,", "tokens": ["Schreibt", "eu\u00b7ren", "Rat", "mir", "in", "den", "Schnee", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "La\u00dft mich eure Zeichen ersp\u00e4hn,", "tokens": ["La\u00dft", "mich", "eu\u00b7re", "Zei\u00b7chen", "er\u00b7sp\u00e4hn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "PPOSAT", "NN", "VVINF", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.12": {"text": "Ihr, meine Weisen, ihr meine ", "tokens": ["Ihr", ",", "mei\u00b7ne", "Wei\u00b7sen", ",", "ihr", "mei\u00b7ne"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word"], "pos": ["PPER", "$,", "PPOSAT", "NN", "$,", "PPER", "PPOSAT"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.10": {"line.1": {"text": "Und kaum gerufen, so sind sie da,", "tokens": ["Und", "kaum", "ge\u00b7ru\u00b7fen", ",", "so", "sind", "sie", "da", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVPP", "$,", "ADV", "VAFIN", "PPER", "ADV", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Setzen sich um ihn, fern und nah,", "tokens": ["Set\u00b7zen", "sich", "um", "ihn", ",", "fern", "und", "nah", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "APPR", "PPER", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "+----+-+", "measure": "dactylic.init"}, "line.3": {"text": "Aber was er auch lockend tu',", "tokens": ["A\u00b7ber", "was", "er", "auch", "lo\u00b7ckend", "tu'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "ADV", "ADJD", "PTKVZ", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Keine, keine h\u00fcpft auf ihn zu,", "tokens": ["Kei\u00b7ne", ",", "kei\u00b7ne", "h\u00fcpft", "auf", "ihn", "zu", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "$,", "PIAT", "VVFIN", "APPR", "PPER", "PTKVZ", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.5": {"text": "Wenden sich all, ihrer F\u00fc\u00dfe Spur,", "tokens": ["Wen\u00b7den", "sich", "all", ",", "ih\u00b7rer", "F\u00fc\u00b7\u00dfe", "Spur", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIAT", "PRF", "PIAT", "$,", "PPOSAT", "NN", "NN", "$,"], "meter": "+-----+-+", "measure": "dactylic.init"}, "line.6": {"text": "Abgewandt, r\u00fcckw\u00e4rts f\u00fchrt sie nur,", "tokens": ["Ab\u00b7ge\u00b7wandt", ",", "r\u00fcck\u00b7w\u00e4rts", "f\u00fchrt", "sie", "nur", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "ADV", "VVFIN", "PPER", "ADV", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.7": {"text": "R\u00fcckw\u00e4rts h\u00fcpfen sie Schritt um Schritt:", "tokens": ["R\u00fcck\u00b7w\u00e4rts", "h\u00fcp\u00b7fen", "sie", "Schritt", "um", "Schritt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "NN", "APPR", "NN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.8": {"text": "\u00bbkr\u00e4hen, nehmt ihr das Gl\u00fcck mir mit?\u00ab", "tokens": ["\u00bb", "kr\u00e4\u00b7hen", ",", "nehmt", "ihr", "das", "Gl\u00fcck", "mir", "mit", "?", "\u00ab"], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VVINF", "$,", "VVFIN", "PPER", "ART", "NN", "PPER", "PTKVZ", "$.", "$("], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.11": {"line.1": {"text": "Und als er so sprach und als er so sann,", "tokens": ["Und", "als", "er", "so", "sprach", "und", "als", "er", "so", "sann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "VVFIN", "KON", "KOUS", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Erik Jarl, sein Freund, tritt an ihn heran:", "tokens": ["E\u00b7rik", "Jarl", ",", "sein", "Freund", ",", "tritt", "an", "ihn", "he\u00b7ran", ":"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "PPOSAT", "NN", "$,", "VVFIN", "APPR", "PPER", "PTKVZ", "$."], "meter": "--+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "\u00bbk\u00f6nig Olaf, der D\u00e4ne spielt um sein Gl\u00fcck,", "tokens": ["\u00bb", "k\u00f6\u00b7nig", "O\u00b7laf", ",", "der", "D\u00e4\u00b7ne", "spielt", "um", "sein", "Gl\u00fcck", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VMFIN", "NE", "$,", "ART", "NN", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "+--+-+-+--+", "measure": "iambic.penta.invert"}, "line.4": {"text": "Im \u00d6resund hielt's ihn nicht l\u00e4nger zur\u00fcck,", "tokens": ["Im", "\u00d6\u00b7re\u00b7sund", "hielt's", "ihn", "nicht", "l\u00e4n\u00b7ger", "zu\u00b7r\u00fcck", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PPER", "PTKNEG", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.5": {"text": "Aus der Kj\u00f6ge Bucht, aus dem Wassersack,", "tokens": ["Aus", "der", "Kj\u00f6\u00b7ge", "Bucht", ",", "aus", "dem", "Was\u00b7ser\u00b7sack", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "$,", "APPR", "ART", "NN", "$,"], "meter": "--+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Ist er hinaus ins Skager-Rak,", "tokens": ["Ist", "er", "hin\u00b7aus", "ins", "Ska\u00b7ger\u00b7Rak", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Hundert Schiffe f\u00fchrt er, zehnhundert an Bord \u2013", "tokens": ["Hun\u00b7dert", "Schif\u00b7fe", "f\u00fchrt", "er", ",", "zehn\u00b7hun\u00b7dert", "an", "Bord", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "VVFIN", "PPER", "$,", "VVFIN", "APPR", "NN", "$("], "meter": "+-+-+---+-+", "measure": "unknown.measure.penta"}, "line.8": {"text": "Auf, Olaf, auf, aus Stavanger-Fjord!\u00ab", "tokens": ["Auf", ",", "O\u00b7laf", ",", "auf", ",", "aus", "Stavan\u00b7ger\u00b7\u00b7F\u00b7jord", "!", "\u00ab"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "punct", "punct"], "pos": ["APPR", "$,", "NE", "$,", "PTKVZ", "$,", "APPR", "NN", "$.", "$("], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.12": {"line.1": {"text": "Und der K\u00f6nig steigt hinab an das Meer,", "tokens": ["Und", "der", "K\u00f6\u00b7nig", "steigt", "hin\u00b7ab", "an", "das", "Meer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "ADV", "APPR", "ART", "NN", "$,"], "meter": "--+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Seine Kr\u00e4hen kreischen um ihn her,", "tokens": ["Sei\u00b7ne", "Kr\u00e4\u00b7hen", "krei\u00b7schen", "um", "ihn", "her", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "APPR", "PPER", "PTKVZ", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Er h\u00f6rt nicht mehr ihr schrill Geschrei.", "tokens": ["Er", "h\u00f6rt", "nicht", "mehr", "ihr", "schrill", "Ge\u00b7schrei", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "ADV", "PPER", "ADJD", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "\u00bberik Jarl\u00ab, so spricht er, \u00bb", "tokens": ["\u00bb", "e\u00b7rik", "Jarl", "\u00ab", ",", "so", "spricht", "er", ",", "\u00bb"], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VVFIN", "NE", "$(", "$,", "ADV", "VVFIN", "PPER", "$,", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.5": {"text": "Und wankt der D\u00e4ne, so brichst du los,", "tokens": ["Und", "wankt", "der", "D\u00e4\u00b7ne", ",", "so", "brichst", "du", "los", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "$,", "ADV", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Ihr letztes Schiff, es mu\u00df in den Grund,", "tokens": ["Ihr", "letz\u00b7tes", "Schiff", ",", "es", "mu\u00df", "in", "den", "Grund", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,", "PPER", "VMFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.7": {"text": "Nichts darf heim in den \u00d6resund.\u00ab", "tokens": ["Nichts", "darf", "heim", "in", "den", "\u00d6\u00b7re\u00b7sund", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PIS", "VMFIN", "PTKVZ", "APPR", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Sprach es. Und als den Feind er sah,", "tokens": ["Sprach", "es", ".", "Und", "als", "den", "Feind", "er", "sah", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "$.", "KON", "KOUS", "ART", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "In goldener R\u00fcstung stand er da;", "tokens": ["In", "gol\u00b7de\u00b7ner", "R\u00fcs\u00b7tung", "stand", "er", "da", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "PPER", "ADV", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Zu F\u00fc\u00dfen ihm, des Reiches Stolz,", "tokens": ["Zu", "F\u00fc\u00b7\u00dfen", "ihm", ",", "des", "Rei\u00b7ches", "Stolz", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PPER", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Lag der Runenbogen aus Eschenholz,", "tokens": ["Lag", "der", "Ru\u00b7nen\u00b7bo\u00b7gen", "aus", "E\u00b7schen\u00b7holz", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "APPR", "NN", "$,"], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.5": {"text": "Der st\u00e4rkste Bogen in Norderland,", "tokens": ["Der", "st\u00e4rks\u00b7te", "Bo\u00b7gen", "in", "Nor\u00b7der\u00b7land", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "NE", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Keiner spannt ihn, nur Olafs Hand.", "tokens": ["Kei\u00b7ner", "spannt", "ihn", ",", "nur", "O\u00b7lafs", "Hand", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "$,", "ADV", "NE", "NN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.14": {"line.1": {"text": "Und in des Feindes gedoppelte Reihn", "tokens": ["Und", "in", "des", "Fein\u00b7des", "ge\u00b7dop\u00b7pel\u00b7te", "Reihn"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "ADJA", "NN"], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.2": {"text": "Olaf Kragebeen f\u00e4hrt jetzt mitten hinein,", "tokens": ["O\u00b7laf", "Kra\u00b7ge\u00b7been", "f\u00e4hrt", "jetzt", "mit\u00b7ten", "hin\u00b7ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "VVFIN", "ADV", "ADV", "PTKVZ", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.3": {"text": "Erik Jarl, wohl folgt er \u2013 doch nicht zum Sto\u00df,", "tokens": ["E\u00b7rik", "Jarl", ",", "wohl", "folgt", "er", "\u2013", "doch", "nicht", "zum", "Sto\u00df", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "ADV", "VVFIN", "PPER", "$(", "ADV", "PTKNEG", "APPRART", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Zum vernichtenden, l\u00f6st er von Olaf sich los,", "tokens": ["Zum", "ver\u00b7nich\u00b7ten\u00b7den", ",", "l\u00f6st", "er", "von", "O\u00b7laf", "sich", "los", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "$,", "VVFIN", "PPER", "APPR", "NE", "PRF", "PTKVZ", "$,"], "meter": "--+--+--++-+", "measure": "anapaest.tri.plus"}, "line.5": {"text": "\u00bb", "tokens": ["\u00bb"], "token_info": ["punct"], "pos": ["$("]}, "line.6": {"text": "Verrat und durch ", "tokens": ["Ver\u00b7rat", "und", "durch"], "token_info": ["word", "word", "word"], "pos": ["VVFIN", "KON", "APPR"], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "Der D\u00e4ne galt nichts, ", "tokens": ["Der", "D\u00e4\u00b7ne", "galt", "nichts", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PIS", "$,"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.8": {"text": "Norweg gegen Norweg. Erik Jarl, wirf gut,", "tokens": ["Nor\u00b7weg", "ge\u00b7gen", "Nor\u00b7weg.", "E\u00b7rik", "Jarl", ",", "wirf", "gut", ","], "token_info": ["word", "word", "abbreviation", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "APPR", "NE", "NE", "NE", "$,", "VVFIN", "ADJD", "$,"], "meter": "++--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.9": {"text": "La\u00df sehn, wer die besten W\u00fcrfe tut.\u00ab", "tokens": ["La\u00df", "sehn", ",", "wer", "die", "bes\u00b7ten", "W\u00fcr\u00b7fe", "tut", ".", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVIMP", "VVINF", "$,", "PWS", "ART", "ADJA", "NN", "VVFIN", "$.", "$("], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.15": {"line.1": {"text": "Und er nahm den Bogen, als w\u00e4r' es ein Spiel,", "tokens": ["Und", "er", "nahm", "den", "Bo\u00b7gen", ",", "als", "w\u00e4r'", "es", "ein", "Spiel", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ART", "NN", "$,", "KOKOM", "VAFIN", "PPER", "ART", "NN", "$,"], "meter": "--+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Auf seine R\u00fcstung die Sonne fiel,", "tokens": ["Auf", "sei\u00b7ne", "R\u00fcs\u00b7tung", "die", "Son\u00b7ne", "fiel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Er spannte den Bogen mit aller Kraft,", "tokens": ["Er", "spann\u00b7te", "den", "Bo\u00b7gen", "mit", "al\u00b7ler", "Kraft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "PIAT", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Klirrend zerbrach der Eschenschaft,", "tokens": ["Klir\u00b7rend", "zer\u00b7brach", "der", "E\u00b7schen\u00b7schaft", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "ART", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.5": {"text": "Und h\u00fcben und dr\u00fcben klang es zugleich:", "tokens": ["Und", "h\u00fc\u00b7ben", "und", "dr\u00fc\u00b7ben", "klang", "es", "zu\u00b7gleich", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "KON", "ADV", "VVFIN", "PPER", "ADV", "$."], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "\u00bbzerbrochen der Bogen, zerbrochen das Reich.\u00ab", "tokens": ["\u00bb", "zer\u00b7bro\u00b7chen", "der", "Bo\u00b7gen", ",", "zer\u00b7bro\u00b7chen", "das", "Reich", ".", "\u00ab"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VVPP", "ART", "NN", "$,", "VVFIN", "ART", "NN", "$.", "$("], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}}, "stanza.16": {"line.1": {"text": "Olaf Kragebeen aber, des Schiffes Mast", "tokens": ["O\u00b7laf", "Kra\u00b7ge\u00b7been", "a\u00b7ber", ",", "des", "Schif\u00b7fes", "Mast"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["NE", "NN", "ADV", "$,", "ART", "NN", "NN"], "meter": "--+-----+-+", "measure": "anapaest.init"}, "line.2": {"text": "H\u00e4lt sein Arm nicht l\u00e4nger umfa\u00dft,", "tokens": ["H\u00e4lt", "sein", "Arm", "nicht", "l\u00e4n\u00b7ger", "um\u00b7fa\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "PTKNEG", "ADJD", "VVFIN", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Er schreitet bis zu des Schiffes Bug,", "tokens": ["Er", "schrei\u00b7tet", "bis", "zu", "des", "Schif\u00b7fes", "Bug", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "ART", "NN", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Statt der Kr\u00e4hen umschwirrt ihn ein M\u00f6wenzug,", "tokens": ["Statt", "der", "Kr\u00e4\u00b7hen", "um\u00b7schwirrt", "ihn", "ein", "M\u00f6\u00b7wen\u00b7zug", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "+-+--+--+-+", "measure": "trochaic.penta.relaxed"}, "line.5": {"text": "Immer dichter flattert es um ihn her:", "tokens": ["Im\u00b7mer", "dich\u00b7ter", "flat\u00b7tert", "es", "um", "ihn", "her", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "PPER", "APPR", "PPER", "PTKVZ", "$."], "meter": "+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.6": {"text": "\u00bbwei\u00dfe Wogenkinder, euch sendet das ", "tokens": ["\u00bb", "wei\u00b7\u00dfe", "Wo\u00b7gen\u00b7kin\u00b7der", ",", "euch", "sen\u00b7det", "das"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word"], "pos": ["$(", "ADJA", "NN", "$,", "PPER", "VVFIN", "ART"], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.7": {"text": "Es ruft mich \u2013 mein Gl\u00fcck einst, nun mein Grab.\u00ab", "tokens": ["Es", "ruft", "mich", "\u2013", "mein", "Gl\u00fcck", "einst", ",", "nun", "mein", "Grab", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$(", "PPOSAT", "NN", "ADV", "$,", "ADV", "PPOSAT", "NN", "$.", "$("], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Und in goldener R\u00fcstung stieg er hinab.", "tokens": ["Und", "in", "gol\u00b7de\u00b7ner", "R\u00fcs\u00b7tung", "stieg", "er", "hin\u00b7ab", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ADJA", "NN", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "--+--+-+--+", "measure": "anapaest.di.plus"}}}}}