{"textgrid.poem.36881": {"metadata": {"author": {"name": "Gellert, Christian F\u00fcrchtegott", "birth": "N.A.", "death": "N.A."}, "title": "Die Liebe des N\u00e4chsten", "genre": "verse", "period": "N.A.", "pub_year": 1742, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "So jemand spricht: Ich liebe Gott!", "tokens": ["So", "je\u00b7mand", "spricht", ":", "Ich", "lie\u00b7be", "Gott", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "VVFIN", "$.", "PPER", "VVFIN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und ha\u00dft doch seine Br\u00fcder,", "tokens": ["Und", "ha\u00dft", "doch", "sei\u00b7ne", "Br\u00fc\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Der treibt mit Gottes Wahrheit Spott,", "tokens": ["Der", "treibt", "mit", "Got\u00b7tes", "Wahr\u00b7heit", "Spott", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPR", "NN", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und rei\u00dft sie ganz darnieder.", "tokens": ["Und", "rei\u00dft", "sie", "ganz", "dar\u00b7nie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "PAV", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Gott ist die Lieb, und will, da\u00df ich", "tokens": ["Gott", "ist", "die", "Lieb", ",", "und", "will", ",", "da\u00df", "ich"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["NN", "VAFIN", "ART", "NN", "$,", "KON", "VMFIN", "$,", "KOUS", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Den N\u00e4chsten liebe, gleich als mich.", "tokens": ["Den", "N\u00e4chs\u00b7ten", "lie\u00b7be", ",", "gleich", "als", "mich", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "ADV", "KOUS", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Wer dieser Erden G\u00fcter hat,", "tokens": ["Wer", "die\u00b7ser", "Er\u00b7den", "G\u00fc\u00b7ter", "hat", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PDAT", "NN", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und sieht die Br\u00fcder leiden,", "tokens": ["Und", "sieht", "die", "Br\u00fc\u00b7der", "lei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und macht den Hungrigen nicht satt,", "tokens": ["Und", "macht", "den", "Hung\u00b7ri\u00b7gen", "nicht", "satt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "PTKNEG", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "L\u00e4\u00dft Nackende nicht kleiden;", "tokens": ["L\u00e4\u00dft", "Na\u00b7cken\u00b7de", "nicht", "klei\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "PTKNEG", "VVINF", "$."], "meter": "-+---+-", "measure": "dactylic.init"}, "line.5": {"text": "Der ist ein Feind der ersten Pflicht,", "tokens": ["Der", "ist", "ein", "Feind", "der", "ers\u00b7ten", "Pflicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und hat die Liebe Gottes nicht.", "tokens": ["Und", "hat", "die", "Lie\u00b7be", "Got\u00b7tes", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ART", "NN", "NN", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Wer seines N\u00e4chsten Ehre schm\u00e4ht,", "tokens": ["Wer", "sei\u00b7nes", "N\u00e4chs\u00b7ten", "Eh\u00b7re", "schm\u00e4ht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPOSAT", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und gern sie schm\u00e4hen h\u00f6ret;", "tokens": ["Und", "gern", "sie", "schm\u00e4\u00b7hen", "h\u00f6\u00b7ret", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PPER", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Sich freut, wenn sich sein Feind vergeht,", "tokens": ["Sich", "freut", ",", "wenn", "sich", "sein", "Feind", "ver\u00b7geht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "VVFIN", "$,", "KOUS", "PRF", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und nichts zum Besten kehret;", "tokens": ["Und", "nichts", "zum", "Bes\u00b7ten", "keh\u00b7ret", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Nicht dem Verleumder widerspricht;", "tokens": ["Nicht", "dem", "Ver\u00b7leum\u00b7der", "wi\u00b7der\u00b7spricht", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ART", "NN", "VVFIN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.6": {"text": "Der liebt auch seinen Bruder nicht.", "tokens": ["Der", "liebt", "auch", "sei\u00b7nen", "Bru\u00b7der", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "PPOSAT", "NN", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Wer zwar mit Rat, mit Trost und Schutz", "tokens": ["Wer", "zwar", "mit", "Rat", ",", "mit", "Trost", "und", "Schutz"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWS", "ADV", "APPR", "NN", "$,", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Den N\u00e4chsten unterst\u00fctzet,", "tokens": ["Den", "N\u00e4chs\u00b7ten", "un\u00b7ter\u00b7st\u00fct\u00b7zet", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Doch nur aus Stolz, aus Eigennutz,", "tokens": ["Doch", "nur", "aus", "Stolz", ",", "aus", "Ei\u00b7gen\u00b7nutz", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "NN", "$,", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Aus Weichlichkeit ihm n\u00fctzet;", "tokens": ["Aus", "Weich\u00b7lich\u00b7keit", "ihm", "n\u00fct\u00b7zet", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Nicht aus Gehorsam, nicht aus Pflicht;", "tokens": ["Nicht", "aus", "Ge\u00b7hor\u00b7sam", ",", "nicht", "aus", "Pflicht", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "NN", "$,", "PTKNEG", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Der liebt auch seinen N\u00e4chsten nicht.", "tokens": ["Der", "liebt", "auch", "sei\u00b7nen", "N\u00e4chs\u00b7ten", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "PPOSAT", "NN", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Wer harret, bis ihn anzuflehn,", "tokens": ["Wer", "har\u00b7ret", ",", "bis", "ihn", "an\u00b7zu\u00b7flehn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "$,", "KOUS", "PPER", "VVIZU", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein D\u00fcrftger erst erscheinet,", "tokens": ["Ein", "D\u00fcrft\u00b7ger", "erst", "er\u00b7schei\u00b7net", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Nicht eilt, dem Frommen beizustehn,", "tokens": ["Nicht", "eilt", ",", "dem", "From\u00b7men", "bei\u00b7zu\u00b7stehn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "VVFIN", "$,", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der im Verborgnen weinet;", "tokens": ["Der", "im", "Ver\u00b7borg\u00b7nen", "wei\u00b7net", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Nicht g\u00fctig forscht, ob's ihm gebricht;", "tokens": ["Nicht", "g\u00fc\u00b7tig", "forscht", ",", "ob's", "ihm", "ge\u00b7bricht", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADJD", "VVPP", "$,", "KOUS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Der liebt auch seinen N\u00e4chsten nicht.", "tokens": ["Der", "liebt", "auch", "sei\u00b7nen", "N\u00e4chs\u00b7ten", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "PPOSAT", "NN", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Wer andre, wenn er sie beschirmt,", "tokens": ["Wer", "and\u00b7re", ",", "wenn", "er", "sie", "be\u00b7schirmt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PIS", "$,", "KOUS", "PPER", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mit H\u00e4rt und Vorwurf qu\u00e4let,", "tokens": ["Mit", "H\u00e4rt", "und", "Vor\u00b7wurf", "qu\u00e4\u00b7let", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und ohne Nachsicht straft und st\u00fcrmt,", "tokens": ["Und", "oh\u00b7ne", "Nach\u00b7sicht", "straft", "und", "st\u00fcrmt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "ADJD", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So bald sein N\u00e4chster fehlet;", "tokens": ["So", "bald", "sein", "N\u00e4chs\u00b7ter", "feh\u00b7let", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Wie bleibt bei seinem Ungest\u00fcm", "tokens": ["Wie", "bleibt", "bei", "sei\u00b7nem", "Un\u00b7ge\u00b7st\u00fcm"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Die Liebe Gottes wohl in ihm?", "tokens": ["Die", "Lie\u00b7be", "Got\u00b7tes", "wohl", "in", "ihm", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "ADV", "APPR", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Wer f\u00fcr der Armen Heil und Zucht", "tokens": ["Wer", "f\u00fcr", "der", "Ar\u00b7men", "Heil", "und", "Zucht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWS", "APPR", "ART", "NN", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mit Rat und Tat nicht wachet,", "tokens": ["Mit", "Rat", "und", "Tat", "nicht", "wa\u00b7chet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Dem \u00dcbel nicht zu wehren sucht,", "tokens": ["Dem", "\u00dc\u00b7bel", "nicht", "zu", "weh\u00b7ren", "sucht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKNEG", "PTKZU", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Das oft sie d\u00fcrftig machet;", "tokens": ["Das", "oft", "sie", "d\u00fcrf\u00b7tig", "ma\u00b7chet", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "PPER", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Nur sorglos ihnen Gaben gibt;", "tokens": ["Nur", "sorg\u00b7los", "ih\u00b7nen", "Ga\u00b7ben", "gibt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Der hat sie wenig noch geliebt.", "tokens": ["Der", "hat", "sie", "we\u00b7nig", "noch", "ge\u00b7liebt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "ADV", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Wahr ist es, du vermagst es nicht,", "tokens": ["Wahr", "ist", "es", ",", "du", "ver\u00b7magst", "es", "nicht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "PPER", "$,", "PPER", "VVFIN", "PPER", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Stets durch die Tat zu lieben.", "tokens": ["Stets", "durch", "die", "Tat", "zu", "lie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Doch bist du nur geneigt, die Pflicht", "tokens": ["Doch", "bist", "du", "nur", "ge\u00b7neigt", ",", "die", "Pflicht"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "VAFIN", "PPER", "ADV", "VVPP", "$,", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Getreulich auszu\u00fcben,", "tokens": ["Ge\u00b7treu\u00b7lich", "aus\u00b7zu\u00b7\u00fc\u00b7ben", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJD", "VVIZU", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Und w\u00fcnschest dir die Kraft dazu,", "tokens": ["Und", "w\u00fcn\u00b7schest", "dir", "die", "Kraft", "da\u00b7zu", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ART", "NN", "PAV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und sorgst daf\u00fcr: so liebest du.", "tokens": ["Und", "sorgst", "da\u00b7f\u00fcr", ":", "so", "lie\u00b7best", "du", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PAV", "$.", "ADV", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Ermattet dieser Trieb in dir:", "tokens": ["Er\u00b7mat\u00b7tet", "die\u00b7ser", "Trieb", "in", "dir", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PDAT", "NN", "APPR", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So such ihn zu beleben.", "tokens": ["So", "such", "ihn", "zu", "be\u00b7le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Sprich oft: Gott ist die Lieb, und mir", "tokens": ["Sprich", "oft", ":", "Gott", "ist", "die", "Lieb", ",", "und", "mir"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["VVIMP", "ADV", "$.", "NN", "VAFIN", "ART", "NN", "$,", "KON", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Hat er sein Bild gegeben.", "tokens": ["Hat", "er", "sein", "Bild", "ge\u00b7ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Denk oft: Gott, was ich bin, ist dein;", "tokens": ["Denk", "oft", ":", "Gott", ",", "was", "ich", "bin", ",", "ist", "dein", ";"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVIMP", "ADV", "$.", "NN", "$,", "PWS", "PPER", "VAFIN", "$,", "VAFIN", "PPOSAT", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.6": {"text": "Sollt ich, gleich dir, nicht g\u00fctig sein?", "tokens": ["Sollt", "ich", ",", "gleich", "dir", ",", "nicht", "g\u00fc\u00b7tig", "sein", "?"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "$,", "ADV", "PPER", "$,", "PTKNEG", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Wir haben ", "tokens": ["Wir", "ha\u00b7ben"], "token_info": ["word", "word"], "pos": ["PPER", "VAFIN"], "meter": "-+-", "measure": "amphibrach.single"}, "line.2": {"text": "Sind ", "tokens": ["Sind"], "token_info": ["word"], "pos": ["VAFIN"], "meter": "-", "measure": "single.down"}, "line.3": {"text": "Drum diene deinem N\u00e4chsten gern;", "tokens": ["Drum", "die\u00b7ne", "dei\u00b7nem", "N\u00e4chs\u00b7ten", "gern", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPOSAT", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Denn wir sind alle Br\u00fcder.", "tokens": ["Denn", "wir", "sind", "al\u00b7le", "Br\u00fc\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "PIAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Gott schuf die Welt nicht blo\u00df f\u00fcr mich;", "tokens": ["Gott", "schuf", "die", "Welt", "nicht", "blo\u00df", "f\u00fcr", "mich", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ART", "NN", "PTKNEG", "ADV", "APPR", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Mein N\u00e4chster ist sein Kind, wie ich.", "tokens": ["Mein", "N\u00e4chs\u00b7ter", "ist", "sein", "Kind", ",", "wie", "ich", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "PPOSAT", "NN", "$,", "PWAV", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Ich sollte Br\u00fcder hassen,", "tokens": ["Ich", "soll\u00b7te", "Br\u00fc\u00b7der", "has\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Die Gott durch seines Sohnes Blut", "tokens": ["Die", "Gott", "durch", "sei\u00b7nes", "Soh\u00b7nes", "Blut"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So hoch erkaufen lassen?", "tokens": ["So", "hoch", "er\u00b7kau\u00b7fen", "las\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVINF", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Da\u00df Gott mich schuf, und mich vers\u00fchnt,", "tokens": ["Da\u00df", "Gott", "mich", "schuf", ",", "und", "mich", "ver\u00b7s\u00fchnt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "PPER", "VVFIN", "$,", "KON", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Hab ich dies mehr, als sie, verdient?", "tokens": ["Hab", "ich", "dies", "mehr", ",", "als", "sie", ",", "ver\u00b7dient", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["NN", "PPER", "PDS", "ADV", "$,", "KOUS", "PPER", "$,", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Du schenkst mir t\u00e4glich so viel Schuld,", "tokens": ["Du", "schenkst", "mir", "t\u00e4g\u00b7lich", "so", "viel", "Schuld", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADJD", "ADV", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Du Herr von meinen Tagen!", "tokens": ["Du", "Herr", "von", "mei\u00b7nen", "Ta\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Ich aber sollte nicht Geduld", "tokens": ["Ich", "a\u00b7ber", "soll\u00b7te", "nicht", "Ge\u00b7duld"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "VMFIN", "PTKNEG", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mit meinen Br\u00fcdern tragen?", "tokens": ["Mit", "mei\u00b7nen", "Br\u00fc\u00b7dern", "tra\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Dem nicht verzeihn, dem du vergibst,", "tokens": ["Dem", "nicht", "ver\u00b7zeihn", ",", "dem", "du", "ver\u00b7gibst", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "PTKNEG", "VVINF", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und den nicht lieben, den du liebst?", "tokens": ["Und", "den", "nicht", "lie\u00b7ben", ",", "den", "du", "liebst", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ART", "PTKNEG", "VVINF", "$,", "PRELS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Was ich den Frommen hier getan,", "tokens": ["Was", "ich", "den", "From\u00b7men", "hier", "ge\u00b7tan", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ART", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dem Kleinsten auch von diesen,", "tokens": ["Dem", "Kleins\u00b7ten", "auch", "von", "die\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "APPR", "PDAT", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Das sieht Er, mein Erl\u00f6ser, an,", "tokens": ["Das", "sieht", "Er", ",", "mein", "Er\u00b7l\u00f6\u00b7ser", ",", "an", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "$,", "PPOSAT", "NN", "$,", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Als h\u00e4tt ich's ihm erwiesen.", "tokens": ["Als", "h\u00e4tt", "ich's", "ihm", "er\u00b7wie\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VAFIN", "PIS", "PPER", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Und ich, ich sollt ein Mensch noch sein,", "tokens": ["Und", "ich", ",", "ich", "sollt", "ein", "Mensch", "noch", "sein", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "$,", "PPER", "VMFIN", "ART", "NN", "ADV", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und Gott in Br\u00fcdern nicht erfreun?", "tokens": ["Und", "Gott", "in", "Br\u00fc\u00b7dern", "nicht", "er\u00b7freun", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "APPR", "NN", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Ein unbarmherziges Gericht", "tokens": ["Ein", "un\u00b7barm\u00b7her\u00b7zi\u00b7ges", "Ge\u00b7richt"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wird \u00fcber den ergehen,", "tokens": ["Wird", "\u00fc\u00b7ber", "den", "er\u00b7ge\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "ART", "ADJA", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Der nicht barmherzig ist, der nicht", "tokens": ["Der", "nicht", "barm\u00b7her\u00b7zig", "ist", ",", "der", "nicht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "PTKNEG", "ADJD", "VAFIN", "$,", "PRELS", "PTKNEG"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die rettet, die ihn flehen.", "tokens": ["Die", "ret\u00b7tet", ",", "die", "ihn", "fle\u00b7hen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "$,", "PRELS", "PPER", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Drum gib mir, Gott! durch deinen Geist", "tokens": ["Drum", "gib", "mir", ",", "Gott", "!", "durch", "dei\u00b7nen", "Geist"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["PAV", "VVIMP", "PPER", "$,", "NN", "$.", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ein Herz, das dich durch Liebe preist.", "tokens": ["Ein", "Herz", ",", "das", "dich", "durch", "Lie\u00b7be", "preist", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PRF", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "So jemand spricht: Ich liebe Gott!", "tokens": ["So", "je\u00b7mand", "spricht", ":", "Ich", "lie\u00b7be", "Gott", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "VVFIN", "$.", "PPER", "VVFIN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und ha\u00dft doch seine Br\u00fcder,", "tokens": ["Und", "ha\u00dft", "doch", "sei\u00b7ne", "Br\u00fc\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Der treibt mit Gottes Wahrheit Spott,", "tokens": ["Der", "treibt", "mit", "Got\u00b7tes", "Wahr\u00b7heit", "Spott", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPR", "NN", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und rei\u00dft sie ganz darnieder.", "tokens": ["Und", "rei\u00dft", "sie", "ganz", "dar\u00b7nie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "PAV", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Gott ist die Lieb, und will, da\u00df ich", "tokens": ["Gott", "ist", "die", "Lieb", ",", "und", "will", ",", "da\u00df", "ich"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["NN", "VAFIN", "ART", "NN", "$,", "KON", "VMFIN", "$,", "KOUS", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Den N\u00e4chsten liebe, gleich als mich.", "tokens": ["Den", "N\u00e4chs\u00b7ten", "lie\u00b7be", ",", "gleich", "als", "mich", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "ADV", "KOUS", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "Wer dieser Erden G\u00fcter hat,", "tokens": ["Wer", "die\u00b7ser", "Er\u00b7den", "G\u00fc\u00b7ter", "hat", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PDAT", "NN", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und sieht die Br\u00fcder leiden,", "tokens": ["Und", "sieht", "die", "Br\u00fc\u00b7der", "lei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und macht den Hungrigen nicht satt,", "tokens": ["Und", "macht", "den", "Hung\u00b7ri\u00b7gen", "nicht", "satt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "PTKNEG", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "L\u00e4\u00dft Nackende nicht kleiden;", "tokens": ["L\u00e4\u00dft", "Na\u00b7cken\u00b7de", "nicht", "klei\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "PTKNEG", "VVINF", "$."], "meter": "-+---+-", "measure": "dactylic.init"}, "line.5": {"text": "Der ist ein Feind der ersten Pflicht,", "tokens": ["Der", "ist", "ein", "Feind", "der", "ers\u00b7ten", "Pflicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und hat die Liebe Gottes nicht.", "tokens": ["Und", "hat", "die", "Lie\u00b7be", "Got\u00b7tes", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ART", "NN", "NN", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.17": {"line.1": {"text": "Wer seines N\u00e4chsten Ehre schm\u00e4ht,", "tokens": ["Wer", "sei\u00b7nes", "N\u00e4chs\u00b7ten", "Eh\u00b7re", "schm\u00e4ht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPOSAT", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und gern sie schm\u00e4hen h\u00f6ret;", "tokens": ["Und", "gern", "sie", "schm\u00e4\u00b7hen", "h\u00f6\u00b7ret", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PPER", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Sich freut, wenn sich sein Feind vergeht,", "tokens": ["Sich", "freut", ",", "wenn", "sich", "sein", "Feind", "ver\u00b7geht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "VVFIN", "$,", "KOUS", "PRF", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und nichts zum Besten kehret;", "tokens": ["Und", "nichts", "zum", "Bes\u00b7ten", "keh\u00b7ret", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Nicht dem Verleumder widerspricht;", "tokens": ["Nicht", "dem", "Ver\u00b7leum\u00b7der", "wi\u00b7der\u00b7spricht", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ART", "NN", "VVFIN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.6": {"text": "Der liebt auch seinen Bruder nicht.", "tokens": ["Der", "liebt", "auch", "sei\u00b7nen", "Bru\u00b7der", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "PPOSAT", "NN", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.18": {"line.1": {"text": "Wer zwar mit Rat, mit Trost und Schutz", "tokens": ["Wer", "zwar", "mit", "Rat", ",", "mit", "Trost", "und", "Schutz"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWS", "ADV", "APPR", "NN", "$,", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Den N\u00e4chsten unterst\u00fctzet,", "tokens": ["Den", "N\u00e4chs\u00b7ten", "un\u00b7ter\u00b7st\u00fct\u00b7zet", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Doch nur aus Stolz, aus Eigennutz,", "tokens": ["Doch", "nur", "aus", "Stolz", ",", "aus", "Ei\u00b7gen\u00b7nutz", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "NN", "$,", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Aus Weichlichkeit ihm n\u00fctzet;", "tokens": ["Aus", "Weich\u00b7lich\u00b7keit", "ihm", "n\u00fct\u00b7zet", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Nicht aus Gehorsam, nicht aus Pflicht;", "tokens": ["Nicht", "aus", "Ge\u00b7hor\u00b7sam", ",", "nicht", "aus", "Pflicht", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "NN", "$,", "PTKNEG", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Der liebt auch seinen N\u00e4chsten nicht.", "tokens": ["Der", "liebt", "auch", "sei\u00b7nen", "N\u00e4chs\u00b7ten", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "PPOSAT", "NN", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.19": {"line.1": {"text": "Wer harret, bis ihn anzuflehn,", "tokens": ["Wer", "har\u00b7ret", ",", "bis", "ihn", "an\u00b7zu\u00b7flehn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "$,", "KOUS", "PPER", "VVIZU", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein D\u00fcrftger erst erscheinet,", "tokens": ["Ein", "D\u00fcrft\u00b7ger", "erst", "er\u00b7schei\u00b7net", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Nicht eilt, dem Frommen beizustehn,", "tokens": ["Nicht", "eilt", ",", "dem", "From\u00b7men", "bei\u00b7zu\u00b7stehn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "VVFIN", "$,", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der im Verborgnen weinet;", "tokens": ["Der", "im", "Ver\u00b7borg\u00b7nen", "wei\u00b7net", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Nicht g\u00fctig forscht, ob's ihm gebricht;", "tokens": ["Nicht", "g\u00fc\u00b7tig", "forscht", ",", "ob's", "ihm", "ge\u00b7bricht", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADJD", "VVPP", "$,", "KOUS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Der liebt auch seinen N\u00e4chsten nicht.", "tokens": ["Der", "liebt", "auch", "sei\u00b7nen", "N\u00e4chs\u00b7ten", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "PPOSAT", "NN", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.20": {"line.1": {"text": "Wer andre, wenn er sie beschirmt,", "tokens": ["Wer", "and\u00b7re", ",", "wenn", "er", "sie", "be\u00b7schirmt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PIS", "$,", "KOUS", "PPER", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mit H\u00e4rt und Vorwurf qu\u00e4let,", "tokens": ["Mit", "H\u00e4rt", "und", "Vor\u00b7wurf", "qu\u00e4\u00b7let", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und ohne Nachsicht straft und st\u00fcrmt,", "tokens": ["Und", "oh\u00b7ne", "Nach\u00b7sicht", "straft", "und", "st\u00fcrmt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "ADJD", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So bald sein N\u00e4chster fehlet;", "tokens": ["So", "bald", "sein", "N\u00e4chs\u00b7ter", "feh\u00b7let", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Wie bleibt bei seinem Ungest\u00fcm", "tokens": ["Wie", "bleibt", "bei", "sei\u00b7nem", "Un\u00b7ge\u00b7st\u00fcm"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Die Liebe Gottes wohl in ihm?", "tokens": ["Die", "Lie\u00b7be", "Got\u00b7tes", "wohl", "in", "ihm", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "ADV", "APPR", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.21": {"line.1": {"text": "Wer f\u00fcr der Armen Heil und Zucht", "tokens": ["Wer", "f\u00fcr", "der", "Ar\u00b7men", "Heil", "und", "Zucht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWS", "APPR", "ART", "NN", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mit Rat und Tat nicht wachet,", "tokens": ["Mit", "Rat", "und", "Tat", "nicht", "wa\u00b7chet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Dem \u00dcbel nicht zu wehren sucht,", "tokens": ["Dem", "\u00dc\u00b7bel", "nicht", "zu", "weh\u00b7ren", "sucht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKNEG", "PTKZU", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Das oft sie d\u00fcrftig machet;", "tokens": ["Das", "oft", "sie", "d\u00fcrf\u00b7tig", "ma\u00b7chet", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "PPER", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Nur sorglos ihnen Gaben gibt;", "tokens": ["Nur", "sorg\u00b7los", "ih\u00b7nen", "Ga\u00b7ben", "gibt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Der hat sie wenig noch geliebt.", "tokens": ["Der", "hat", "sie", "we\u00b7nig", "noch", "ge\u00b7liebt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "ADV", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.22": {"line.1": {"text": "Wahr ist es, du vermagst es nicht,", "tokens": ["Wahr", "ist", "es", ",", "du", "ver\u00b7magst", "es", "nicht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "PPER", "$,", "PPER", "VVFIN", "PPER", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Stets durch die Tat zu lieben.", "tokens": ["Stets", "durch", "die", "Tat", "zu", "lie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Doch bist du nur geneigt, die Pflicht", "tokens": ["Doch", "bist", "du", "nur", "ge\u00b7neigt", ",", "die", "Pflicht"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "VAFIN", "PPER", "ADV", "VVPP", "$,", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Getreulich auszu\u00fcben,", "tokens": ["Ge\u00b7treu\u00b7lich", "aus\u00b7zu\u00b7\u00fc\u00b7ben", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJD", "VVIZU", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Und w\u00fcnschest dir die Kraft dazu,", "tokens": ["Und", "w\u00fcn\u00b7schest", "dir", "die", "Kraft", "da\u00b7zu", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ART", "NN", "PAV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und sorgst daf\u00fcr: so liebest du.", "tokens": ["Und", "sorgst", "da\u00b7f\u00fcr", ":", "so", "lie\u00b7best", "du", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PAV", "$.", "ADV", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.23": {"line.1": {"text": "Ermattet dieser Trieb in dir:", "tokens": ["Er\u00b7mat\u00b7tet", "die\u00b7ser", "Trieb", "in", "dir", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PDAT", "NN", "APPR", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So such ihn zu beleben.", "tokens": ["So", "such", "ihn", "zu", "be\u00b7le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Sprich oft: Gott ist die Lieb, und mir", "tokens": ["Sprich", "oft", ":", "Gott", "ist", "die", "Lieb", ",", "und", "mir"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["VVIMP", "ADV", "$.", "NN", "VAFIN", "ART", "NN", "$,", "KON", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Hat er sein Bild gegeben.", "tokens": ["Hat", "er", "sein", "Bild", "ge\u00b7ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Denk oft: Gott, was ich bin, ist dein;", "tokens": ["Denk", "oft", ":", "Gott", ",", "was", "ich", "bin", ",", "ist", "dein", ";"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVIMP", "ADV", "$.", "NN", "$,", "PWS", "PPER", "VAFIN", "$,", "VAFIN", "PPOSAT", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.6": {"text": "Sollt ich, gleich dir, nicht g\u00fctig sein?", "tokens": ["Sollt", "ich", ",", "gleich", "dir", ",", "nicht", "g\u00fc\u00b7tig", "sein", "?"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "$,", "ADV", "PPER", "$,", "PTKNEG", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.24": {"line.1": {"text": "Wir haben ", "tokens": ["Wir", "ha\u00b7ben"], "token_info": ["word", "word"], "pos": ["PPER", "VAFIN"], "meter": "-+-", "measure": "amphibrach.single"}, "line.2": {"text": "Sind ", "tokens": ["Sind"], "token_info": ["word"], "pos": ["VAFIN"], "meter": "-", "measure": "single.down"}, "line.3": {"text": "Drum diene deinem N\u00e4chsten gern;", "tokens": ["Drum", "die\u00b7ne", "dei\u00b7nem", "N\u00e4chs\u00b7ten", "gern", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPOSAT", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Denn wir sind alle Br\u00fcder.", "tokens": ["Denn", "wir", "sind", "al\u00b7le", "Br\u00fc\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "PIAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Gott schuf die Welt nicht blo\u00df f\u00fcr mich;", "tokens": ["Gott", "schuf", "die", "Welt", "nicht", "blo\u00df", "f\u00fcr", "mich", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ART", "NN", "PTKNEG", "ADV", "APPR", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Mein N\u00e4chster ist sein Kind, wie ich.", "tokens": ["Mein", "N\u00e4chs\u00b7ter", "ist", "sein", "Kind", ",", "wie", "ich", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "PPOSAT", "NN", "$,", "PWAV", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.25": {"line.1": {"text": "Ich sollte Br\u00fcder hassen,", "tokens": ["Ich", "soll\u00b7te", "Br\u00fc\u00b7der", "has\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Die Gott durch seines Sohnes Blut", "tokens": ["Die", "Gott", "durch", "sei\u00b7nes", "Soh\u00b7nes", "Blut"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So hoch erkaufen lassen?", "tokens": ["So", "hoch", "er\u00b7kau\u00b7fen", "las\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVINF", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Da\u00df Gott mich schuf, und mich vers\u00fchnt,", "tokens": ["Da\u00df", "Gott", "mich", "schuf", ",", "und", "mich", "ver\u00b7s\u00fchnt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "PPER", "VVFIN", "$,", "KON", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Hab ich dies mehr, als sie, verdient?", "tokens": ["Hab", "ich", "dies", "mehr", ",", "als", "sie", ",", "ver\u00b7dient", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["NN", "PPER", "PDS", "ADV", "$,", "KOUS", "PPER", "$,", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.26": {"line.1": {"text": "Du schenkst mir t\u00e4glich so viel Schuld,", "tokens": ["Du", "schenkst", "mir", "t\u00e4g\u00b7lich", "so", "viel", "Schuld", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADJD", "ADV", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Du Herr von meinen Tagen!", "tokens": ["Du", "Herr", "von", "mei\u00b7nen", "Ta\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Ich aber sollte nicht Geduld", "tokens": ["Ich", "a\u00b7ber", "soll\u00b7te", "nicht", "Ge\u00b7duld"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "VMFIN", "PTKNEG", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mit meinen Br\u00fcdern tragen?", "tokens": ["Mit", "mei\u00b7nen", "Br\u00fc\u00b7dern", "tra\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Dem nicht verzeihn, dem du vergibst,", "tokens": ["Dem", "nicht", "ver\u00b7zeihn", ",", "dem", "du", "ver\u00b7gibst", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "PTKNEG", "VVINF", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und den nicht lieben, den du liebst?", "tokens": ["Und", "den", "nicht", "lie\u00b7ben", ",", "den", "du", "liebst", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ART", "PTKNEG", "VVINF", "$,", "PRELS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.27": {"line.1": {"text": "Was ich den Frommen hier getan,", "tokens": ["Was", "ich", "den", "From\u00b7men", "hier", "ge\u00b7tan", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ART", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dem Kleinsten auch von diesen,", "tokens": ["Dem", "Kleins\u00b7ten", "auch", "von", "die\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "APPR", "PDAT", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Das sieht Er, mein Erl\u00f6ser, an,", "tokens": ["Das", "sieht", "Er", ",", "mein", "Er\u00b7l\u00f6\u00b7ser", ",", "an", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "$,", "PPOSAT", "NN", "$,", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Als h\u00e4tt ich's ihm erwiesen.", "tokens": ["Als", "h\u00e4tt", "ich's", "ihm", "er\u00b7wie\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VAFIN", "PIS", "PPER", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Und ich, ich sollt ein Mensch noch sein,", "tokens": ["Und", "ich", ",", "ich", "sollt", "ein", "Mensch", "noch", "sein", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "$,", "PPER", "VMFIN", "ART", "NN", "ADV", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und Gott in Br\u00fcdern nicht erfreun?", "tokens": ["Und", "Gott", "in", "Br\u00fc\u00b7dern", "nicht", "er\u00b7freun", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "APPR", "NN", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.28": {"line.1": {"text": "Ein unbarmherziges Gericht", "tokens": ["Ein", "un\u00b7barm\u00b7her\u00b7zi\u00b7ges", "Ge\u00b7richt"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wird \u00fcber den ergehen,", "tokens": ["Wird", "\u00fc\u00b7ber", "den", "er\u00b7ge\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "ART", "ADJA", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Der nicht barmherzig ist, der nicht", "tokens": ["Der", "nicht", "barm\u00b7her\u00b7zig", "ist", ",", "der", "nicht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "PTKNEG", "ADJD", "VAFIN", "$,", "PRELS", "PTKNEG"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die rettet, die ihn flehen.", "tokens": ["Die", "ret\u00b7tet", ",", "die", "ihn", "fle\u00b7hen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "$,", "PRELS", "PPER", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Drum gib mir, Gott! durch deinen Geist", "tokens": ["Drum", "gib", "mir", ",", "Gott", "!", "durch", "dei\u00b7nen", "Geist"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["PAV", "VVIMP", "PPER", "$,", "NN", "$.", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ein Herz, das dich durch Liebe preist.", "tokens": ["Ein", "Herz", ",", "das", "dich", "durch", "Lie\u00b7be", "preist", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PRF", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}