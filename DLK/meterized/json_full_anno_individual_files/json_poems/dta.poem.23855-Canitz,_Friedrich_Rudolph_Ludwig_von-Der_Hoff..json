{"dta.poem.23855": {"metadata": {"author": {"name": "Canitz, Friedrich Rudolph Ludwig von", "birth": "N.A.", "death": "N.A."}, "title": "Der Hoff.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1700", "urn": "urn:nbn:de:kobv:b4-200905197532", "language": ["de:0.99"], "booktitle": "[Canitz, Friedrich Rudolph Ludwig von]: Neben-Stunden Unterschiedener Gedichte. [Hrsg. v. Joachim Lange]. Berlin, 1700."}, "poem": {"stanza.1": {"line.1": {"text": "Ein Schlo\u00df da Circe schertzt mit ihren Gauckel-Pos-\nsen/", "tokens": ["Ein", "Schlo\u00df", "da", "Cir\u00b7ce", "schertzt", "mit", "ih\u00b7ren", "Gau\u00b7ckel\u00b7Pos", "sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "NE", "VVFIN", "APPR", "PPOSAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ein Kercker da das Gl\u00fcck die Sclaven h\u00e4lt verschlossen/", "tokens": ["Ein", "Ker\u00b7cker", "da", "das", "Gl\u00fcck", "die", "Scla\u00b7ven", "h\u00e4lt", "ver\u00b7schlos\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ART", "NN", "ART", "NN", "VVFIN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ein Dollhau\u00df da man sich durch manche Narren drengt/", "tokens": ["Ein", "Doll\u00b7hau\u00df", "da", "man", "sich", "durch", "man\u00b7che", "Nar\u00b7ren", "drengt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KOUS", "PIS", "PRF", "APPR", "PIAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Von denen einer singt/ der ander Grillen f\u00e4ngt/", "tokens": ["Von", "de\u00b7nen", "ei\u00b7ner", "singt", "/", "der", "an\u00b7der", "Gril\u00b7len", "f\u00e4ngt", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PIS", "VVFIN", "$(", "ART", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ein Kloster da man sieht die reichste Br\u00fcder betteln/", "tokens": ["Ein", "Klos\u00b7ter", "da", "man", "sieht", "die", "reichs\u00b7te", "Br\u00fc\u00b7der", "bet\u00b7teln", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KOUS", "PIS", "VVFIN", "ART", "ADJA", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Ein Gl\u00fcckstopff welcher meist besteht in leeren Zetteln/", "tokens": ["Ein", "Gl\u00fccks\u00b7topff", "wel\u00b7cher", "meist", "be\u00b7steht", "in", "lee\u00b7ren", "Zet\u00b7teln", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PRELS", "ADV", "VVFIN", "APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Ein Marck da Wind und Rauch die besten Wahren sind/", "tokens": ["Ein", "Marck", "da", "Wind", "und", "Rauch", "die", "bes\u00b7ten", "Wah\u00b7ren", "sind", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "NN", "KON", "NN", "ART", "ADJA", "NN", "VAFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und wer ein Gauckel-Dieb/ das meiste Geld gewinnt/", "tokens": ["Und", "wer", "ein", "Gau\u00b7ckel\u00b7Dieb", "/", "das", "meis\u00b7te", "Geld", "ge\u00b7winnt", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ART", "NN", "$(", "ART", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Ein angef\u00fcllt Spital/ in welches einzutreten/", "tokens": ["Ein", "an\u00b7ge\u00b7f\u00fcllt", "Spi\u00b7tal", "/", "in", "wel\u00b7ches", "ein\u00b7zu\u00b7tre\u00b7ten", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "VVPP", "NN", "$(", "APPR", "PRELS", "VVIZU", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Ein kranck er sich bem\u00fcht den andern todt zu beten/", "tokens": ["Ein", "kranck", "er", "sich", "be\u00b7m\u00fcht", "den", "an\u00b7dern", "todt", "zu", "be\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPER", "PRF", "VVFIN", "ART", "ADJA", "ADJD", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Hier ist ein Fastnachtspiel da Tugend wird verh\u00f6nt/", "tokens": ["Hier", "ist", "ein", "Fast\u00b7nacht\u00b7spiel", "da", "Tu\u00b7gend", "wird", "ver\u00b7h\u00f6nt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "ADV", "NN", "VAFIN", "VVPP", "$("], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.12": {"text": "Ob gleich das Laster selbst von ihr die Ma\u00dfque lehnt.", "tokens": ["Ob", "gleich", "das", "Las\u00b7ter", "selbst", "von", "ihr", "die", "Ma\u00df\u00b7que", "lehnt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "ADV", "APPR", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Den\u0303 schmeicheln hei\u00dft man hier sich in die Zeit bequemen/", "tokens": ["De\u00f1", "schmei\u00b7cheln", "hei\u00dft", "man", "hier", "sich", "in", "die", "Zeit", "be\u00b7que\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVINF", "VVFIN", "PIS", "ADV", "PRF", "APPR", "ART", "NN", "ADJA", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Verleumden/ ohn vermerckt der Schlangen Gifft beneh-", "tokens": ["Ver\u00b7leum\u00b7den", "/", "ohn", "ver\u00b7merckt", "der", "Schlan\u00b7gen", "Gifft", "be\u00b7neh"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "$(", "APPR", "VVFIN", "ART", "NN", "NN", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Den Hochmuht/ Freund und Feind frey unter Augen", "tokens": ["Den", "Hoch\u00b7muht", "/", "Freund", "und", "Feind", "frey", "un\u00b7ter", "Au\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$(", "NN", "KON", "NN", "ADJD", "APPR", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.16": {"text": "Den Geitz/ mit Wolbedacht auf seine Wirthschafft sehn/", "tokens": ["Den", "Geitz", "/", "mit", "Wol\u00b7be\u00b7dacht", "auf", "sei\u00b7ne", "Wirth\u00b7schafft", "sehn", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "APPR", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Die Pracht/ den Purpur nicht mit Niedrigkeit beflecken/", "tokens": ["Die", "Pracht", "/", "den", "Pur\u00b7pur", "nicht", "mit", "Nied\u00b7rig\u00b7keit", "be\u00b7fle\u00b7cken", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "ART", "NN", "PTKNEG", "APPR", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Und Falschheit/ mit Verstand des andern Sin\u0303 entdecken/", "tokens": ["Und", "Falschheit", "/", "mit", "Ver\u00b7stand", "des", "an\u00b7dern", "Si\u00f1", "ent\u00b7de\u00b7cken", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "$(", "APPR", "NN", "ART", "ADJA", "NN", "VVINF", "$("], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.19": {"text": "Eins wisse welcher denckt/ - - - - - zu handeln/", "tokens": ["Eins", "wis\u00b7se", "wel\u00b7cher", "denckt", "/", "zu", "han\u00b7deln", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PWAT", "VVFIN", "$(", "$(", "$(", "$(", "$(", "$(", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.20": {"text": "Mu\u00df mit Gefahr und Streit auf dieser Strassen wan-", "tokens": ["Mu\u00df", "mit", "Ge\u00b7fahr", "und", "Streit", "auf", "die\u00b7ser", "Stras\u00b7sen", "wan"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "APPR", "NN", "KON", "NN", "APPR", "PDAT", "NN", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Die uns in einem Tag mehr Ungeheuer zeigt.", "tokens": ["Die", "uns", "in", "ei\u00b7nem", "Tag", "mehr", "Un\u00b7ge\u00b7heu\u00b7er", "zeigt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "ART", "NN", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Als uns der \u00f6de Strich in Africa gezeugt.", "tokens": ["Als", "uns", "der", "\u00f6\u00b7de", "Strich", "in", "A\u00b7fri\u00b7ca", "ge\u00b7zeugt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "APPR", "NE", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}