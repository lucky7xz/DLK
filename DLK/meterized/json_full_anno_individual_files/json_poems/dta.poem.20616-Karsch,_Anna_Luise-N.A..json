{"dta.poem.20616": {"metadata": {"author": {"name": "Karsch, Anna Luise", "birth": "N.A.", "death": "N.A."}, "title": "N.A.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1792", "urn": "urn:nbn:de:kobv:b4-200905193016", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Herrscherin des gro\u00dfen Wasserreiches!               ", "tokens": ["Herr\u00b7sche\u00b7rin", "des", "gro\u00b7\u00dfen", "Was\u00b7ser\u00b7rei\u00b7ches", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Tausend Schiffe bringen Edelstein,", "tokens": ["Tau\u00b7send", "Schif\u00b7fe", "brin\u00b7gen", "E\u00b7del\u00b7stein", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "VVINF", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Gold und Perlen, nur keins lud ein gleiches", "tokens": ["Gold", "und", "Per\u00b7len", ",", "nur", "keins", "lud", "ein", "glei\u00b7ches"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "KON", "NN", "$,", "ADV", "PIAT", "VVFIN", "ART", "ADJA"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "Unsch\u00e4tzbares Kleinod ein.", "tokens": ["Un\u00b7sch\u00e4tz\u00b7ba\u00b7res", "Klei\u00b7nod", "ein", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Friedrich Wilhelms allererste Blume", "tokens": ["Fried\u00b7rich", "Wil\u00b7helms", "al\u00b7le\u00b7rers\u00b7te", "Blu\u00b7me"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "NE", "ADJA", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Seiner Liebe s\u00fc\u00dfes erstes Pfand,", "tokens": ["Sei\u00b7ner", "Lie\u00b7be", "s\u00fc\u00b7\u00dfes", "ers\u00b7tes", "Pfand", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADJA", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Bringt Dein York zum Ewigeigenthume", "tokens": ["Bringt", "Dein", "Y\u00b7ork", "zum", "E\u00b7wi\u00b7gei\u00b7gen\u00b7thu\u00b7me"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPOSAT", "NE", "APPRART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "An der holden Liebe Band.", "tokens": ["An", "der", "hol\u00b7den", "Lie\u00b7be", "Band", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Zart gebaut, und sch\u00f6n, und geistbeflammet,", "tokens": ["Zart", "ge\u00b7baut", ",", "und", "sch\u00f6n", ",", "und", "geist\u00b7be\u00b7flam\u00b7met", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADJD", "VVPP", "$,", "KON", "ADJD", "$,", "KON", "VVFIN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Siehest du mit feinem Kennerblick,", "tokens": ["Sie\u00b7hest", "du", "mit", "fei\u00b7nem", "Ken\u00b7ner\u00b7blick", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Wer Sie ist, von wem Sie abgestammet:", "tokens": ["Wer", "Sie", "ist", ",", "von", "wem", "Sie", "ab\u00b7ge\u00b7stam\u00b7met", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VAFIN", "$,", "APPR", "PWS", "PPER", "VVPP", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "Sie wird zweier Staaten Gl\u00fcck!", "tokens": ["Sie", "wird", "zwei\u00b7er", "Staa\u00b7ten", "Gl\u00fcck", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJA", "NN", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.4": {"line.1": {"text": "Dieser Bund, mit Ihrem York geschlossen,", "tokens": ["Die\u00b7ser", "Bund", ",", "mit", "Ih\u00b7rem", "Y\u00b7ork", "ge\u00b7schlos\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "$,", "APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "+-+-+-+--+-", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Kn\u00fcpft den Brennus- und den Brittenthron", "tokens": ["Kn\u00fcpft", "den", "Bren\u00b7nus", "und", "den", "Brit\u00b7ten\u00b7thron"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "ART", "TRUNC", "KON", "ART", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "So zusammen, da\u00df ihm die Genossen", "tokens": ["So", "zu\u00b7sam\u00b7men", ",", "da\u00df", "ihm", "die", "Ge\u00b7nos\u00b7sen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "PTKVZ", "$,", "KOUS", "PPER", "ART", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "Lucifers vergebens drohn.", "tokens": ["Lu\u00b7ci\u00b7fers", "ver\u00b7ge\u00b7bens", "drohn", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "ADV", "VVFIN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.5": {"line.1": {"text": "Wer beschreibt die Wonne der betagten", "tokens": ["Wer", "be\u00b7schreibt", "die", "Won\u00b7ne", "der", "be\u00b7tag\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "ART", "NN", "ART", "ADJA"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Wittwe Braunschweigs, deren Muttergram", "tokens": ["Witt\u00b7we", "Braun\u00b7schweigs", ",", "de\u00b7ren", "Mut\u00b7ter\u00b7gram"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["NN", "NE", "$,", "PRELAT", "NN"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.3": {"text": "Oft die Engel Gottes mit beklagten,", "tokens": ["Oft", "die", "En\u00b7gel", "Got\u00b7tes", "mit", "be\u00b7klag\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "NN", "APPR", "ADJA", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "Wenn er Kind auf Kind ihr nahm?", "tokens": ["Wenn", "er", "Kind", "auf", "Kind", "ihr", "nahm", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NN", "APPR", "NN", "PPER", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Wer vermag die Freude ganz zu sagen", "tokens": ["Wer", "ver\u00b7mag", "die", "Freu\u00b7de", "ganz", "zu", "sa\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "ART", "NN", "ADV", "PTKZU", "VVINF"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Deines alten Feldherrn Ferdinands,", "tokens": ["Dei\u00b7nes", "al\u00b7ten", "Feld\u00b7herrn", "Fer\u00b7di\u00b7nands", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "NE", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Den Bourbon zu Boden wollte schlagen,", "tokens": ["Den", "Bour\u00b7bon", "zu", "Bo\u00b7den", "woll\u00b7te", "schla\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "VMFIN", "VVINF", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Und Er schlugs und \u00fcberwands.", "tokens": ["Und", "Er", "schlugs", "und", "\u00fc\u00b7ber\u00b7wands", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ADV", "KON", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Und wer hats ermessen und erwogen,", "tokens": ["Und", "wer", "hats", "er\u00b7mes\u00b7sen", "und", "er\u00b7wo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VAFIN", "VVPP", "KON", "VVPP", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Was der K\u00f6niginnen Fr\u00f6mmste ", "tokens": ["Was", "der", "K\u00f6\u00b7ni\u00b7gin\u00b7nen", "Fr\u00f6mms\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["PWS", "ART", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Welche hier die Blume hat erzogen,", "tokens": ["Wel\u00b7che", "hier", "die", "Blu\u00b7me", "hat", "er\u00b7zo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "ART", "NN", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "Die den h\u00f6chsten Prei\u00df erhielt?", "tokens": ["Die", "den", "h\u00f6chs\u00b7ten", "Prei\u00df", "er\u00b7hielt", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Wie vermag ich\u2019s selbst zu offenbaren,", "tokens": ["Wie", "ver\u00b7mag", "ich's", "selbst", "zu", "of\u00b7fen\u00b7ba\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PIS", "ADV", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Was mein altes mattes Herz belebt,", "tokens": ["Was", "mein", "al\u00b7tes", "mat\u00b7tes", "Herz", "be\u00b7lebt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPOSAT", "ADJA", "ADJA", "NN", "VVPP", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Welches jezt vor drei\u00dfig goldnen Jahren", "tokens": ["Wel\u00b7ches", "jezt", "vor", "drei\u00b7\u00dfig", "gold\u00b7nen", "Jah\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "ADV", "APPR", "CARD", "ADJA", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "Um Charlottens*) Schiff geschwebt?", "tokens": ["Um", "Char\u00b7lot\u00b7tens", "*", ")", "Schiff", "ge\u00b7schwebt", "?"], "token_info": ["word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["KOUI", "NE", "XY", "$(", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Also wird\u2019s auf Lieb\u2019- und Ehrfurchtschwingen", "tokens": ["Al\u00b7so", "wird's", "auf", "Lie\u00b7b'", "und", "Ehr\u00b7furcht\u00b7schwin\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "APPR", "TRUNC", "KON", "NN"], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.2": {"text": "Schweben um das sanfte Seegelwehn", "tokens": ["Schwe\u00b7ben", "um", "das", "sanf\u00b7te", "See\u00b7gel\u00b7wehn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Dieses Schiffs, das nicht mehr wiederhringen", "tokens": ["Die\u00b7ses", "Schiffs", ",", "das", "nicht", "mehr", "wie\u00b7der\u00b7hrin\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PDAT", "NN", "$,", "PRELS", "PTKNEG", "ADV", "VVINF"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "Mir dies Kleinod wird zum sehn.", "tokens": ["Mir", "dies", "Klei\u00b7nod", "wird", "zum", "sehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PDS", "NN", "VAFIN", "APPRART", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Hier, ", "tokens": ["Hier", ","], "token_info": ["word", "punct"], "pos": ["ADV", "$,"], "meter": "+", "measure": "single.up"}, "line.2": {"text": "Die S\u00e4ngerin die ist nicht mehr \u2014", "tokens": ["Die", "S\u00e4n\u00b7ge\u00b7rin", "die", "ist", "nicht", "mehr"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "VAFIN", "PTKNEG", "ADV", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}