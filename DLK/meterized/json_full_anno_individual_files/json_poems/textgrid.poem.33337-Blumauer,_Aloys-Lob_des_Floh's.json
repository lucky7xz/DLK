{"textgrid.poem.33337": {"metadata": {"author": {"name": "Blumauer, Aloys", "birth": "N.A.", "death": "N.A."}, "title": "Lob des Floh's", "genre": "verse", "period": "N.A.", "pub_year": 1776, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Du kleiner Nero, Compagnon der L\u00e4use,", "tokens": ["Du", "klei\u00b7ner", "Ne\u00b7ro", ",", "Com\u00b7pag\u00b7non", "der", "L\u00e4u\u00b7se", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NE", "$,", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Blutgieriger Tyrann!", "tokens": ["Blut\u00b7gie\u00b7ri\u00b7ger", "Ty\u00b7rann", "!"], "token_info": ["word", "word", "punct"], "pos": ["NN", "NE", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "F\u00fcr dich stimm' ich, nach Meister Linguets Weise", "tokens": ["F\u00fcr", "dich", "stimm'", "ich", ",", "nach", "Meis\u00b7ter", "Lin\u00b7guets", "Wei\u00b7se"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "PPER", "VVFIN", "PPER", "$,", "APPR", "NE", "NE", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Nun auch ein Loblied an.", "tokens": ["Nun", "auch", "ein", "Lob\u00b7lied", "an", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Dein ganz br\u00fcnetter Teint, so sehr verschieden", "tokens": ["Dein", "ganz", "br\u00fc\u00b7net\u00b7ter", "Teint", ",", "so", "sehr", "ver\u00b7schie\u00b7den"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPOSAT", "ADV", "ADJA", "NN", "$,", "ADV", "ADV", "ADJA"], "meter": "-++--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Vom Teint der blonden Laus,", "tokens": ["Vom", "Teint", "der", "blon\u00b7den", "Laus", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Erkohr gleich Anfangs dein Geschlecht hienieden", "tokens": ["Er\u00b7kohr", "gleich", "An\u00b7fangs", "dein", "Ge\u00b7schlecht", "hien\u00b7ie\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "ADV", "ADV", "PPOSAT", "NN", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Zu grossen Thaten aus.", "tokens": ["Zu", "gros\u00b7sen", "Tha\u00b7ten", "aus", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Nur deinen Stamm, der stets in ganzen Schaaren", "tokens": ["Nur", "dei\u00b7nen", "Stamm", ",", "der", "stets", "in", "gan\u00b7zen", "Schaa\u00b7ren"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "PPOSAT", "NN", "$,", "PRELS", "ADV", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Bei M\u00e4dchen Wache h\u00e4lt,", "tokens": ["Bei", "M\u00e4d\u00b7chen", "Wa\u00b7che", "h\u00e4lt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "NN", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Hat die Natur zu tapfern Leibhusaren", "tokens": ["Hat", "die", "Na\u00b7tur", "zu", "tap\u00b7fern", "Leib\u00b7hu\u00b7sa\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ART", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Der Jungfrauschaft erw\u00e4hlt.", "tokens": ["Der", "Jung\u00b7frausc\u00b7haft", "er\u00b7w\u00e4hlt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Und darum patroulliren auch Schwadronen", "tokens": ["Und", "da\u00b7rum", "pat\u00b7ro\u00b7ul\u00b7li\u00b7ren", "auch", "Schwad\u00b7ro\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PAV", "VVFIN", "ADV", "NN"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.2": {"text": "Von diesem leichten Heer", "tokens": ["Von", "die\u00b7sem", "leich\u00b7ten", "Heer"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PDAT", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Best\u00e4ndig in den dunklen Regionen", "tokens": ["Be\u00b7st\u00e4n\u00b7dig", "in", "den", "dunk\u00b7len", "Re\u00b7gi\u00b7o\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADJD", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Des Unterrock's umher.", "tokens": ["Des", "Un\u00b7ter\u00b7rock's", "um\u00b7her", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Nichts sch\u00fctzt die M\u00e4dchen, die sich dir verschliessen,", "tokens": ["Nichts", "sch\u00fctzt", "die", "M\u00e4d\u00b7chen", ",", "die", "sich", "dir", "ver\u00b7schlies\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ART", "NN", "$,", "PRELS", "PRF", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Vor deiner Blutbegier:", "tokens": ["Vor", "dei\u00b7ner", "Blut\u00b7be\u00b7gier", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Die Erstlinge von ihrem Blute fliessen", "tokens": ["Die", "Erst\u00b7lin\u00b7ge", "von", "ih\u00b7rem", "Blu\u00b7te", "flies\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "PPOSAT", "NN", "VVINF"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "O Gl\u00fccklicher, nur dir!", "tokens": ["O", "Gl\u00fcck\u00b7li\u00b7cher", ",", "nur", "dir", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "ADV", "PPER", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Du Springinsfeld bist \u00fcberall gelitten,", "tokens": ["Du", "Sprin\u00b7gins\u00b7feld", "bist", "\u00fc\u00b7be\u00b7rall", "ge\u00b7lit\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "VAFIN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Wo nie ein Mann hin soll,", "tokens": ["Wo", "nie", "ein", "Mann", "hin", "soll", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "ART", "NN", "ADV", "VMFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und schwelgst dich, gleich der Biene, an den Bl\u00fcthen", "tokens": ["Und", "schwelgst", "dich", ",", "gleich", "der", "Bie\u00b7ne", ",", "an", "den", "Bl\u00fc\u00b7then"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "$,", "ADV", "ART", "NN", "$,", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Geheimer Sch\u00f6nheit voll.", "tokens": ["Ge\u00b7hei\u00b7mer", "Sch\u00f6n\u00b7heit", "voll", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Kein Fleck im ganzen weiblichen Gebiete,", "tokens": ["Kein", "Fleck", "im", "gan\u00b7zen", "weib\u00b7li\u00b7chen", "Ge\u00b7bie\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "APPRART", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Auch noch so heilig, ist,", "tokens": ["Auch", "noch", "so", "hei\u00b7lig", ",", "ist", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "ADJD", "$,", "VAFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Auf dem du nicht schon mit verweg'nem Tritte", "tokens": ["Auf", "dem", "du", "nicht", "schon", "mit", "ver\u00b7weg'\u00b7nem", "Trit\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PRELS", "PPER", "PTKNEG", "ADV", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Herumspazieret bist.", "tokens": ["Her\u00b7um\u00b7spa\u00b7zie\u00b7ret", "bist", "."], "token_info": ["word", "word", "punct"], "pos": ["VVFIN", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Da ist kein Strauch, wo du dich nicht verstecktest", "tokens": ["Da", "ist", "kein", "Strauch", ",", "wo", "du", "dich", "nicht", "ver\u00b7steck\u00b7test"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PIAT", "NN", "$,", "PWAV", "PPER", "PRF", "PTKNEG", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Kein Plan, wo du nicht liefst,", "tokens": ["Kein", "Plan", ",", "wo", "du", "nicht", "liefst", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "$,", "PWAV", "PPER", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Kein H\u00fcgelchen, wohin du dich nicht legtest,", "tokens": ["Kein", "H\u00fc\u00b7gel\u00b7chen", ",", "wo\u00b7hin", "du", "dich", "nicht", "leg\u00b7test", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "$,", "PWAV", "PPER", "PRF", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Kein Thal, wo du nicht schliefst.", "tokens": ["Kein", "Thal", ",", "wo", "du", "nicht", "schliefst", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "$,", "PWAV", "PPER", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Ja, wollte man einst auch rektificiren", "tokens": ["Ja", ",", "woll\u00b7te", "man", "einst", "auch", "rek\u00b7ti\u00b7fi\u00b7ci\u00b7ren"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "$,", "VMFIN", "PIS", "ADV", "ADV", "VVINF"], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Der Sch\u00f6nheit Lustrevier,", "tokens": ["Der", "Sch\u00f6n\u00b7heit", "Lus\u00b7tre\u00b7vier", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "NE", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "So brauchte man, um recht es zu mappiren,", "tokens": ["So", "brauch\u00b7te", "man", ",", "um", "recht", "es", "zu", "map\u00b7pi\u00b7ren", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "$,", "KOUI", "ADV", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Nur dich zum Ingenier.", "tokens": ["Nur", "dich", "zum", "In\u00b7ge\u00b7nier", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "APPRART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "Nur dies verzeihen dir die Sch\u00f6nen nimmer,", "tokens": ["Nur", "dies", "ver\u00b7zei\u00b7hen", "dir", "die", "Sch\u00f6\u00b7nen", "nim\u00b7mer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PDS", "VVFIN", "PPER", "ART", "NN", "ADV", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Da\u00df stets von jedem Ku\u00df,", "tokens": ["Da\u00df", "stets", "von", "je\u00b7dem", "Ku\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Den im Geheim du ihnen aufdr\u00fcckst, immer", "tokens": ["Den", "im", "Ge\u00b7heim", "du", "ih\u00b7nen", "auf\u00b7dr\u00fcckst", ",", "im\u00b7mer"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["ART", "APPRART", "NN", "PPER", "PPER", "VVFIN", "$,", "ADV"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Ein Fleckchen zeugen mu\u00df.", "tokens": ["Ein", "Fleck\u00b7chen", "zeu\u00b7gen", "mu\u00df", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "VMFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "D'rum lauren auch stets auf dich losen N\u00e4scher,", "tokens": ["D'\u00b7rum", "lau\u00b7ren", "auch", "stets", "auf", "dich", "lo\u00b7sen", "N\u00e4\u00b7scher", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "ADV", "ADV", "APPR", "PPER", "VVFIN", "NN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.2": {"text": "Enth\u00fcpfst du nicht geschwind,", "tokens": ["Ent\u00b7h\u00fcpfst", "du", "nicht", "ge\u00b7schwind", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKNEG", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Bei Tag und Nacht so viele hundert H\u00e4scher", "tokens": ["Bei", "Tag", "und", "Nacht", "so", "vie\u00b7le", "hun\u00b7dert", "H\u00e4\u00b7scher"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN", "ADV", "PIAT", "CARD", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Als M\u00e4dchenfinger sind.", "tokens": ["Als", "M\u00e4d\u00b7chen\u00b7fin\u00b7ger", "sind", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KOUS", "NN", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "Doch hascht ein M\u00e4dchen auch dich kleinen Springer", "tokens": ["Doch", "hascht", "ein", "M\u00e4d\u00b7chen", "auch", "dich", "klei\u00b7nen", "Sprin\u00b7ger"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ART", "NN", "ADV", "PPER", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Zuletzt in ihrem Schoo\u00df,", "tokens": ["Zu\u00b7letzt", "in", "ih\u00b7rem", "Schoo\u00df", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "So ist doch unter einem sch\u00f6nen Finger", "tokens": ["So", "ist", "doch", "un\u00b7ter", "ei\u00b7nem", "sch\u00f6\u00b7nen", "Fin\u00b7ger"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ADV", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Noch neidenswerth dein Loos.", "tokens": ["Noch", "nei\u00b7dens\u00b7werth", "dein", "Loos", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.13": {"line.1": {"text": "Du kleiner Nero, Compagnon der L\u00e4use,", "tokens": ["Du", "klei\u00b7ner", "Ne\u00b7ro", ",", "Com\u00b7pag\u00b7non", "der", "L\u00e4u\u00b7se", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NE", "$,", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Blutgieriger Tyrann!", "tokens": ["Blut\u00b7gie\u00b7ri\u00b7ger", "Ty\u00b7rann", "!"], "token_info": ["word", "word", "punct"], "pos": ["NN", "NE", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "F\u00fcr dich stimm' ich, nach Meister Linguets Weise", "tokens": ["F\u00fcr", "dich", "stimm'", "ich", ",", "nach", "Meis\u00b7ter", "Lin\u00b7guets", "Wei\u00b7se"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "PPER", "VVFIN", "PPER", "$,", "APPR", "NE", "NE", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Nun auch ein Loblied an.", "tokens": ["Nun", "auch", "ein", "Lob\u00b7lied", "an", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.14": {"line.1": {"text": "Dein ganz br\u00fcnetter Teint, so sehr verschieden", "tokens": ["Dein", "ganz", "br\u00fc\u00b7net\u00b7ter", "Teint", ",", "so", "sehr", "ver\u00b7schie\u00b7den"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPOSAT", "ADV", "ADJA", "NN", "$,", "ADV", "ADV", "ADJA"], "meter": "-++--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Vom Teint der blonden Laus,", "tokens": ["Vom", "Teint", "der", "blon\u00b7den", "Laus", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Erkohr gleich Anfangs dein Geschlecht hienieden", "tokens": ["Er\u00b7kohr", "gleich", "An\u00b7fangs", "dein", "Ge\u00b7schlecht", "hien\u00b7ie\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "ADV", "ADV", "PPOSAT", "NN", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Zu grossen Thaten aus.", "tokens": ["Zu", "gros\u00b7sen", "Tha\u00b7ten", "aus", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.15": {"line.1": {"text": "Nur deinen Stamm, der stets in ganzen Schaaren", "tokens": ["Nur", "dei\u00b7nen", "Stamm", ",", "der", "stets", "in", "gan\u00b7zen", "Schaa\u00b7ren"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "PPOSAT", "NN", "$,", "PRELS", "ADV", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Bei M\u00e4dchen Wache h\u00e4lt,", "tokens": ["Bei", "M\u00e4d\u00b7chen", "Wa\u00b7che", "h\u00e4lt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "NN", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Hat die Natur zu tapfern Leibhusaren", "tokens": ["Hat", "die", "Na\u00b7tur", "zu", "tap\u00b7fern", "Leib\u00b7hu\u00b7sa\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ART", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Der Jungfrauschaft erw\u00e4hlt.", "tokens": ["Der", "Jung\u00b7frausc\u00b7haft", "er\u00b7w\u00e4hlt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.16": {"line.1": {"text": "Und darum patroulliren auch Schwadronen", "tokens": ["Und", "da\u00b7rum", "pat\u00b7ro\u00b7ul\u00b7li\u00b7ren", "auch", "Schwad\u00b7ro\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PAV", "VVFIN", "ADV", "NN"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.2": {"text": "Von diesem leichten Heer", "tokens": ["Von", "die\u00b7sem", "leich\u00b7ten", "Heer"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PDAT", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Best\u00e4ndig in den dunklen Regionen", "tokens": ["Be\u00b7st\u00e4n\u00b7dig", "in", "den", "dunk\u00b7len", "Re\u00b7gi\u00b7o\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADJD", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Des Unterrock's umher.", "tokens": ["Des", "Un\u00b7ter\u00b7rock's", "um\u00b7her", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.17": {"line.1": {"text": "Nichts sch\u00fctzt die M\u00e4dchen, die sich dir verschliessen,", "tokens": ["Nichts", "sch\u00fctzt", "die", "M\u00e4d\u00b7chen", ",", "die", "sich", "dir", "ver\u00b7schlies\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ART", "NN", "$,", "PRELS", "PRF", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Vor deiner Blutbegier:", "tokens": ["Vor", "dei\u00b7ner", "Blut\u00b7be\u00b7gier", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Die Erstlinge von ihrem Blute fliessen", "tokens": ["Die", "Erst\u00b7lin\u00b7ge", "von", "ih\u00b7rem", "Blu\u00b7te", "flies\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "PPOSAT", "NN", "VVINF"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "O Gl\u00fccklicher, nur dir!", "tokens": ["O", "Gl\u00fcck\u00b7li\u00b7cher", ",", "nur", "dir", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "ADV", "PPER", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.18": {"line.1": {"text": "Du Springinsfeld bist \u00fcberall gelitten,", "tokens": ["Du", "Sprin\u00b7gins\u00b7feld", "bist", "\u00fc\u00b7be\u00b7rall", "ge\u00b7lit\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "VAFIN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Wo nie ein Mann hin soll,", "tokens": ["Wo", "nie", "ein", "Mann", "hin", "soll", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "ART", "NN", "ADV", "VMFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und schwelgst dich, gleich der Biene, an den Bl\u00fcthen", "tokens": ["Und", "schwelgst", "dich", ",", "gleich", "der", "Bie\u00b7ne", ",", "an", "den", "Bl\u00fc\u00b7then"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "$,", "ADV", "ART", "NN", "$,", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Geheimer Sch\u00f6nheit voll.", "tokens": ["Ge\u00b7hei\u00b7mer", "Sch\u00f6n\u00b7heit", "voll", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.19": {"line.1": {"text": "Kein Fleck im ganzen weiblichen Gebiete,", "tokens": ["Kein", "Fleck", "im", "gan\u00b7zen", "weib\u00b7li\u00b7chen", "Ge\u00b7bie\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "APPRART", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Auch noch so heilig, ist,", "tokens": ["Auch", "noch", "so", "hei\u00b7lig", ",", "ist", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "ADJD", "$,", "VAFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Auf dem du nicht schon mit verweg'nem Tritte", "tokens": ["Auf", "dem", "du", "nicht", "schon", "mit", "ver\u00b7weg'\u00b7nem", "Trit\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PRELS", "PPER", "PTKNEG", "ADV", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Herumspazieret bist.", "tokens": ["Her\u00b7um\u00b7spa\u00b7zie\u00b7ret", "bist", "."], "token_info": ["word", "word", "punct"], "pos": ["VVFIN", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.20": {"line.1": {"text": "Da ist kein Strauch, wo du dich nicht verstecktest", "tokens": ["Da", "ist", "kein", "Strauch", ",", "wo", "du", "dich", "nicht", "ver\u00b7steck\u00b7test"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PIAT", "NN", "$,", "PWAV", "PPER", "PRF", "PTKNEG", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Kein Plan, wo du nicht liefst,", "tokens": ["Kein", "Plan", ",", "wo", "du", "nicht", "liefst", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "$,", "PWAV", "PPER", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Kein H\u00fcgelchen, wohin du dich nicht legtest,", "tokens": ["Kein", "H\u00fc\u00b7gel\u00b7chen", ",", "wo\u00b7hin", "du", "dich", "nicht", "leg\u00b7test", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "$,", "PWAV", "PPER", "PRF", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Kein Thal, wo du nicht schliefst.", "tokens": ["Kein", "Thal", ",", "wo", "du", "nicht", "schliefst", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "$,", "PWAV", "PPER", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.21": {"line.1": {"text": "Ja, wollte man einst auch rektificiren", "tokens": ["Ja", ",", "woll\u00b7te", "man", "einst", "auch", "rek\u00b7ti\u00b7fi\u00b7ci\u00b7ren"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "$,", "VMFIN", "PIS", "ADV", "ADV", "VVINF"], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Der Sch\u00f6nheit Lustrevier,", "tokens": ["Der", "Sch\u00f6n\u00b7heit", "Lus\u00b7tre\u00b7vier", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "NE", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "So brauchte man, um recht es zu mappiren,", "tokens": ["So", "brauch\u00b7te", "man", ",", "um", "recht", "es", "zu", "map\u00b7pi\u00b7ren", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "$,", "KOUI", "ADV", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Nur dich zum Ingenier.", "tokens": ["Nur", "dich", "zum", "In\u00b7ge\u00b7nier", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "APPRART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.22": {"line.1": {"text": "Nur dies verzeihen dir die Sch\u00f6nen nimmer,", "tokens": ["Nur", "dies", "ver\u00b7zei\u00b7hen", "dir", "die", "Sch\u00f6\u00b7nen", "nim\u00b7mer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PDS", "VVFIN", "PPER", "ART", "NN", "ADV", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Da\u00df stets von jedem Ku\u00df,", "tokens": ["Da\u00df", "stets", "von", "je\u00b7dem", "Ku\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Den im Geheim du ihnen aufdr\u00fcckst, immer", "tokens": ["Den", "im", "Ge\u00b7heim", "du", "ih\u00b7nen", "auf\u00b7dr\u00fcckst", ",", "im\u00b7mer"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["ART", "APPRART", "NN", "PPER", "PPER", "VVFIN", "$,", "ADV"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Ein Fleckchen zeugen mu\u00df.", "tokens": ["Ein", "Fleck\u00b7chen", "zeu\u00b7gen", "mu\u00df", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "VMFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.23": {"line.1": {"text": "D'rum lauren auch stets auf dich losen N\u00e4scher,", "tokens": ["D'\u00b7rum", "lau\u00b7ren", "auch", "stets", "auf", "dich", "lo\u00b7sen", "N\u00e4\u00b7scher", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "ADV", "ADV", "APPR", "PPER", "VVFIN", "NN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.2": {"text": "Enth\u00fcpfst du nicht geschwind,", "tokens": ["Ent\u00b7h\u00fcpfst", "du", "nicht", "ge\u00b7schwind", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKNEG", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Bei Tag und Nacht so viele hundert H\u00e4scher", "tokens": ["Bei", "Tag", "und", "Nacht", "so", "vie\u00b7le", "hun\u00b7dert", "H\u00e4\u00b7scher"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN", "ADV", "PIAT", "CARD", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Als M\u00e4dchenfinger sind.", "tokens": ["Als", "M\u00e4d\u00b7chen\u00b7fin\u00b7ger", "sind", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KOUS", "NN", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.24": {"line.1": {"text": "Doch hascht ein M\u00e4dchen auch dich kleinen Springer", "tokens": ["Doch", "hascht", "ein", "M\u00e4d\u00b7chen", "auch", "dich", "klei\u00b7nen", "Sprin\u00b7ger"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ART", "NN", "ADV", "PPER", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Zuletzt in ihrem Schoo\u00df,", "tokens": ["Zu\u00b7letzt", "in", "ih\u00b7rem", "Schoo\u00df", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "So ist doch unter einem sch\u00f6nen Finger", "tokens": ["So", "ist", "doch", "un\u00b7ter", "ei\u00b7nem", "sch\u00f6\u00b7nen", "Fin\u00b7ger"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ADV", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Noch neidenswerth dein Loos.", "tokens": ["Noch", "nei\u00b7dens\u00b7werth", "dein", "Loos", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}}}}