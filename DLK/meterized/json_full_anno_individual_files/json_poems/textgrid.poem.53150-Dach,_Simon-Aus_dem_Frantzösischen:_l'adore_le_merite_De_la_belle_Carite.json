{"textgrid.poem.53150": {"metadata": {"author": {"name": "Dach, Simon", "birth": "N.A.", "death": "N.A."}, "title": "Aus dem Frantz\u00f6sischen: l'adore le merite De la belle Carite", "genre": "verse", "period": "N.A.", "pub_year": 1632, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "So heb' ich hoch Carithen", "tokens": ["So", "heb'", "ich", "hoch", "Ca\u00b7ri\u00b7then"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Verdienst, Sie zu beg\u00fcten,", "tokens": ["Ver\u00b7dienst", ",", "Sie", "zu", "be\u00b7g\u00fc\u00b7ten", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Himmlisch gantz", "tokens": ["Himm\u00b7lisch", "gantz"], "token_info": ["word", "word"], "pos": ["NN", "ADV"], "meter": "+-+", "measure": "trochaic.di"}, "line.4": {"text": "Ist jhr Glantz,", "tokens": ["Ist", "jhr", "Glantz", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.5": {"text": "Ihre Brust", "tokens": ["Ih\u00b7re", "Brust"], "token_info": ["word", "word"], "pos": ["PPOSAT", "NN"], "meter": "+-+", "measure": "trochaic.di"}, "line.6": {"text": "Meine Lust,", "tokens": ["Mei\u00b7ne", "Lust", ","], "token_info": ["word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.7": {"text": "Ob ich es gleich verheele,", "tokens": ["Ob", "ich", "es", "gleich", "ver\u00b7hee\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Da\u00df ich umb Sie mich quehle.", "tokens": ["Da\u00df", "ich", "umb", "Sie", "mich", "queh\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PPER", "PRF", "VVFIN", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}}, "stanza.2": {"line.1": {"text": "O harter Spruch, wenn lieben", "tokens": ["O", "har\u00b7ter", "Spruch", ",", "wenn", "lie\u00b7ben"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["NE", "ADJA", "NN", "$,", "KOUS", "ADJA"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "W\u00e4hr' etwas B\u00f6ses \u00fcben!", "tokens": ["W\u00e4hr'", "et\u00b7was", "B\u00f6\u00b7ses", "\u00fc\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Trag' ich doch", "tokens": ["Trag'", "ich", "doch"], "token_info": ["word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV"], "meter": "+-+", "measure": "trochaic.di"}, "line.4": {"text": "L\u00e4nger noch", "tokens": ["L\u00e4n\u00b7ger", "noch"], "token_info": ["word", "word"], "pos": ["NN", "ADV"], "meter": "+-+", "measure": "trochaic.di"}, "line.5": {"text": "Nicht ohn Todt", "tokens": ["Nicht", "ohn", "Todt"], "token_info": ["word", "word", "word"], "pos": ["PTKNEG", "APPR", "NN"], "meter": "+-+", "measure": "trochaic.di"}, "line.6": {"text": "Diese Noht,", "tokens": ["Die\u00b7se", "Noht", ","], "token_info": ["word", "word", "punct"], "pos": ["PDAT", "NN", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.7": {"text": "Nichts \u00e4rgers kan geschehen,", "tokens": ["Nichts", "\u00e4r\u00b7gers", "kan", "ge\u00b7sche\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "ADV", "VMFIN", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Als, was man liebt, nicht sehen.", "tokens": ["Als", ",", "was", "man", "liebt", ",", "nicht", "se\u00b7hen", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "$,", "PRELS", "PIS", "VVFIN", "$,", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Mein weg-seyn, meint' ich, w\u00fcrde", "tokens": ["Mein", "weg\u00b7seyn", ",", "meint'", "ich", ",", "w\u00fcr\u00b7de"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word"], "pos": ["PPOSAT", "NN", "$,", "VVFIN", "PPER", "$,", "VAFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Entladen mich der B\u00fcrde,", "tokens": ["Ent\u00b7la\u00b7den", "mich", "der", "B\u00fcr\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Keine List,", "tokens": ["Kei\u00b7ne", "List", ","], "token_info": ["word", "word", "punct"], "pos": ["PIAT", "NN", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.4": {"text": "Wie sie ist,", "tokens": ["Wie", "sie", "ist", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VAFIN", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.5": {"text": "Noch kein Fall", "tokens": ["Noch", "kein", "Fall"], "token_info": ["word", "word", "word"], "pos": ["ADV", "PIAT", "NN"], "meter": "+-+", "measure": "trochaic.di"}, "line.6": {"text": "\u00fcberall", "tokens": ["\u00fc\u00b7be\u00b7rall"], "token_info": ["word"], "pos": ["ADV"], "meter": "+-+", "measure": "trochaic.di"}, "line.7": {"text": "Kan mich der Lieb' entheben,", "tokens": ["Kan", "mich", "der", "Lieb'", "ent\u00b7he\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PRF", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "So bin ich Ihr ergeben.", "tokens": ["So", "bin", "ich", "Ihr", "er\u00b7ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PPER", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Wie denn? zum Vngehewer!", "tokens": ["Wie", "denn", "?", "zum", "Vn\u00b7ge\u00b7he\u00b7wer", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "ADV", "$.", "APPRART", "NN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Lescht nichts mir dieses Fewer?", "tokens": ["Lescht", "nichts", "mir", "die\u00b7ses", "Fe\u00b7wer", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PIS", "PPER", "PDAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Sie, mein Liecht,", "tokens": ["Sie", ",", "mein", "Liecht", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["PPER", "$,", "PPOSAT", "NN", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.4": {"text": "Scheint mir nicht,", "tokens": ["Scheint", "mir", "nicht", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKNEG", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.5": {"text": "Ihre Zier", "tokens": ["Ih\u00b7re", "Zier"], "token_info": ["word", "word"], "pos": ["PPOSAT", "NN"], "meter": "+-+", "measure": "trochaic.di"}, "line.6": {"text": "Fleucht f\u00fcr mir,", "tokens": ["Fleucht", "f\u00fcr", "mir", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPER", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.7": {"text": "Sol dann die Fluth der Augen", "tokens": ["Sol", "dann", "die", "Fluth", "der", "Au\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "ADV", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Es nicht zu leschen taugen?", "tokens": ["Es", "nicht", "zu", "le\u00b7schen", "tau\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKNEG", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Nein. Denn ich trag' im Hertzen", "tokens": ["Nein", ".", "Denn", "ich", "trag'", "im", "Hert\u00b7zen"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "$.", "KON", "PPER", "VVFIN", "APPRART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Ihr Bild vnd helle Kertzen,", "tokens": ["Ihr", "Bild", "vnd", "hel\u00b7le", "Kert\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Amor macht", "tokens": ["A\u00b7mor", "macht"], "token_info": ["word", "word"], "pos": ["NE", "VVFIN"], "meter": "+-+", "measure": "trochaic.di"}, "line.4": {"text": "Tag vnd Nacht,", "tokens": ["Tag", "vnd", "Nacht", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.5": {"text": "Da\u00df mein Sinn", "tokens": ["Da\u00df", "mein", "Sinn"], "token_info": ["word", "word", "word"], "pos": ["KOUS", "PPOSAT", "NN"], "meter": "+-+", "measure": "trochaic.di"}, "line.6": {"text": "Stets sieht hin", "tokens": ["Stets", "sieht", "hin"], "token_info": ["word", "word", "word"], "pos": ["ADV", "VVFIN", "PTKVZ"], "meter": "-+-", "measure": "amphibrach.single"}, "line.7": {"text": "Auff das Verdienst Carihten,", "tokens": ["Auff", "das", "Ver\u00b7dienst", "Ca\u00b7rih\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "$,"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.8": {"text": "Die ich gern wil beg\u00fcten.", "tokens": ["Die", "ich", "gern", "wil", "be\u00b7g\u00fc\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "So heb' ich hoch Carithen", "tokens": ["So", "heb'", "ich", "hoch", "Ca\u00b7ri\u00b7then"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Verdienst, Sie zu beg\u00fcten,", "tokens": ["Ver\u00b7dienst", ",", "Sie", "zu", "be\u00b7g\u00fc\u00b7ten", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Himmlisch gantz", "tokens": ["Himm\u00b7lisch", "gantz"], "token_info": ["word", "word"], "pos": ["NN", "ADV"], "meter": "+-+", "measure": "trochaic.di"}, "line.4": {"text": "Ist jhr Glantz,", "tokens": ["Ist", "jhr", "Glantz", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.5": {"text": "Ihre Brust", "tokens": ["Ih\u00b7re", "Brust"], "token_info": ["word", "word"], "pos": ["PPOSAT", "NN"], "meter": "+-+", "measure": "trochaic.di"}, "line.6": {"text": "Meine Lust,", "tokens": ["Mei\u00b7ne", "Lust", ","], "token_info": ["word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.7": {"text": "Ob ich es gleich verheele,", "tokens": ["Ob", "ich", "es", "gleich", "ver\u00b7hee\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Da\u00df ich umb Sie mich quehle.", "tokens": ["Da\u00df", "ich", "umb", "Sie", "mich", "queh\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PPER", "PRF", "VVFIN", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}}, "stanza.7": {"line.1": {"text": "O harter Spruch, wenn lieben", "tokens": ["O", "har\u00b7ter", "Spruch", ",", "wenn", "lie\u00b7ben"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["NE", "ADJA", "NN", "$,", "KOUS", "ADJA"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "W\u00e4hr' etwas B\u00f6ses \u00fcben!", "tokens": ["W\u00e4hr'", "et\u00b7was", "B\u00f6\u00b7ses", "\u00fc\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Trag' ich doch", "tokens": ["Trag'", "ich", "doch"], "token_info": ["word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV"], "meter": "+-+", "measure": "trochaic.di"}, "line.4": {"text": "L\u00e4nger noch", "tokens": ["L\u00e4n\u00b7ger", "noch"], "token_info": ["word", "word"], "pos": ["NN", "ADV"], "meter": "+-+", "measure": "trochaic.di"}, "line.5": {"text": "Nicht ohn Todt", "tokens": ["Nicht", "ohn", "Todt"], "token_info": ["word", "word", "word"], "pos": ["PTKNEG", "APPR", "NN"], "meter": "+-+", "measure": "trochaic.di"}, "line.6": {"text": "Diese Noht,", "tokens": ["Die\u00b7se", "Noht", ","], "token_info": ["word", "word", "punct"], "pos": ["PDAT", "NN", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.7": {"text": "Nichts \u00e4rgers kan geschehen,", "tokens": ["Nichts", "\u00e4r\u00b7gers", "kan", "ge\u00b7sche\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "ADV", "VMFIN", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Als, was man liebt, nicht sehen.", "tokens": ["Als", ",", "was", "man", "liebt", ",", "nicht", "se\u00b7hen", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "$,", "PRELS", "PIS", "VVFIN", "$,", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Mein weg-seyn, meint' ich, w\u00fcrde", "tokens": ["Mein", "weg\u00b7seyn", ",", "meint'", "ich", ",", "w\u00fcr\u00b7de"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word"], "pos": ["PPOSAT", "NN", "$,", "VVFIN", "PPER", "$,", "VAFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Entladen mich der B\u00fcrde,", "tokens": ["Ent\u00b7la\u00b7den", "mich", "der", "B\u00fcr\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Keine List,", "tokens": ["Kei\u00b7ne", "List", ","], "token_info": ["word", "word", "punct"], "pos": ["PIAT", "NN", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.4": {"text": "Wie sie ist,", "tokens": ["Wie", "sie", "ist", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VAFIN", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.5": {"text": "Noch kein Fall", "tokens": ["Noch", "kein", "Fall"], "token_info": ["word", "word", "word"], "pos": ["ADV", "PIAT", "NN"], "meter": "+-+", "measure": "trochaic.di"}, "line.6": {"text": "\u00fcberall", "tokens": ["\u00fc\u00b7be\u00b7rall"], "token_info": ["word"], "pos": ["ADV"], "meter": "+-+", "measure": "trochaic.di"}, "line.7": {"text": "Kan mich der Lieb' entheben,", "tokens": ["Kan", "mich", "der", "Lieb'", "ent\u00b7he\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PRF", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "So bin ich Ihr ergeben.", "tokens": ["So", "bin", "ich", "Ihr", "er\u00b7ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PPER", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Wie denn? zum Vngehewer!", "tokens": ["Wie", "denn", "?", "zum", "Vn\u00b7ge\u00b7he\u00b7wer", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "ADV", "$.", "APPRART", "NN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Lescht nichts mir dieses Fewer?", "tokens": ["Lescht", "nichts", "mir", "die\u00b7ses", "Fe\u00b7wer", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PIS", "PPER", "PDAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Sie, mein Liecht,", "tokens": ["Sie", ",", "mein", "Liecht", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["PPER", "$,", "PPOSAT", "NN", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.4": {"text": "Scheint mir nicht,", "tokens": ["Scheint", "mir", "nicht", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKNEG", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.5": {"text": "Ihre Zier", "tokens": ["Ih\u00b7re", "Zier"], "token_info": ["word", "word"], "pos": ["PPOSAT", "NN"], "meter": "+-+", "measure": "trochaic.di"}, "line.6": {"text": "Fleucht f\u00fcr mir,", "tokens": ["Fleucht", "f\u00fcr", "mir", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPER", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.7": {"text": "Sol dann die Fluth der Augen", "tokens": ["Sol", "dann", "die", "Fluth", "der", "Au\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "ADV", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Es nicht zu leschen taugen?", "tokens": ["Es", "nicht", "zu", "le\u00b7schen", "tau\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKNEG", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "Nein. Denn ich trag' im Hertzen", "tokens": ["Nein", ".", "Denn", "ich", "trag'", "im", "Hert\u00b7zen"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "$.", "KON", "PPER", "VVFIN", "APPRART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Ihr Bild vnd helle Kertzen,", "tokens": ["Ihr", "Bild", "vnd", "hel\u00b7le", "Kert\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Amor macht", "tokens": ["A\u00b7mor", "macht"], "token_info": ["word", "word"], "pos": ["NE", "VVFIN"], "meter": "+-+", "measure": "trochaic.di"}, "line.4": {"text": "Tag vnd Nacht,", "tokens": ["Tag", "vnd", "Nacht", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.5": {"text": "Da\u00df mein Sinn", "tokens": ["Da\u00df", "mein", "Sinn"], "token_info": ["word", "word", "word"], "pos": ["KOUS", "PPOSAT", "NN"], "meter": "+-+", "measure": "trochaic.di"}, "line.6": {"text": "Stets sieht hin", "tokens": ["Stets", "sieht", "hin"], "token_info": ["word", "word", "word"], "pos": ["ADV", "VVFIN", "PTKVZ"], "meter": "-+-", "measure": "amphibrach.single"}, "line.7": {"text": "Auff das Verdienst Carihten,", "tokens": ["Auff", "das", "Ver\u00b7dienst", "Ca\u00b7rih\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "$,"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.8": {"text": "Die ich gern wil beg\u00fcten.", "tokens": ["Die", "ich", "gern", "wil", "be\u00b7g\u00fc\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}}}}