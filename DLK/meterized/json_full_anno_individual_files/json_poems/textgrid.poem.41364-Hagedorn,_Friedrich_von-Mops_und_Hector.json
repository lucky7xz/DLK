{"textgrid.poem.41364": {"metadata": {"author": {"name": "Hagedorn, Friedrich von", "birth": "N.A.", "death": "N.A."}, "title": "Mops und Hector", "genre": "verse", "period": "N.A.", "pub_year": 1731, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Der beste Freund in unsrer Welt,", "tokens": ["Der", "bes\u00b7te", "Freund", "in", "uns\u00b7rer", "Welt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mops, war mit Hector auferzogen,", "tokens": ["Mops", ",", "war", "mit", "Hec\u00b7tor", "auf\u00b7er\u00b7zo\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VAFIN", "APPR", "NE", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und blieb ihm immer unverstellt,", "tokens": ["Und", "blieb", "ihm", "im\u00b7mer", "un\u00b7ver\u00b7stellt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mit wahrer Hundetreu gewogen.", "tokens": ["Mit", "wah\u00b7rer", "Hun\u00b7de\u00b7treu", "ge\u00b7wo\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Ihm ging es recht nach seinem Sinn:", "tokens": ["Ihm", "ging", "es", "recht", "nach", "sei\u00b7nem", "Sinn", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADJD", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wo M\u00f6pschen war, da gab es Freude;", "tokens": ["Wo", "M\u00f6p\u00b7schen", "war", ",", "da", "gab", "es", "Freu\u00b7de", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "VAFIN", "$,", "ADV", "VVFIN", "PPER", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Doch Hector zog nach Norden hin,", "tokens": ["Doch", "Hec\u00b7tor", "zog", "nach", "Nor\u00b7den", "hin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "VVFIN", "APPR", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und fand Verfolgung, Frost und R\u00e4ude.", "tokens": ["Und", "fand", "Ver\u00b7fol\u00b7gung", ",", "Frost", "und", "R\u00e4u\u00b7de", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Wahr ist es: Hectors Unverstand", "tokens": ["Wahr", "ist", "es", ":", "Hec\u00b7tors", "Un\u00b7ver\u00b7stand"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["ADJD", "VAFIN", "PPER", "$.", "NE", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Gibt Anla\u00df oft ihn zu verl\u00e4stern:", "tokens": ["Gibt", "An\u00b7la\u00df", "oft", "ihn", "zu", "ver\u00b7l\u00e4s\u00b7tern", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "ADV", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Er ist zu munter, zu galant,", "tokens": ["Er", "ist", "zu", "mun\u00b7ter", ",", "zu", "ga\u00b7lant", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKA", "ADJD", "$,", "PTKA", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und lebte dort bei keuschen Schwestern.", "tokens": ["Und", "leb\u00b7te", "dort", "bei", "keu\u00b7schen", "Schwes\u00b7tern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Kaum finden sich die Br\u00fcder ein,", "tokens": ["Kaum", "fin\u00b7den", "sich", "die", "Br\u00fc\u00b7der", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und seufzen br\u00fcnstig an der Schwelle,", "tokens": ["Und", "seuf\u00b7zen", "br\u00fcns\u00b7tig", "an", "der", "Schwel\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "(vom Nachbar recht geh\u00f6rt zu sein)", "tokens": ["(", "vom", "Nach\u00b7bar", "recht", "ge\u00b7h\u00f6rt", "zu", "sein", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPRART", "NN", "ADJD", "VVPP", "PTKZU", "VAINF", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So \u00fcbert\u00e4ubt sie sein Gebelle.", "tokens": ["So", "\u00fc\u00b7bert\u00b7\u00e4ubt", "sie", "sein", "Ge\u00b7bel\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Er wedelt, wenn den Andachtbund", "tokens": ["Er", "we\u00b7delt", ",", "wenn", "den", "An\u00b7dacht\u00b7bund"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Gebet und Wink und Ku\u00df beleben!", "tokens": ["Ge\u00b7bet", "und", "Wink", "und", "Ku\u00df", "be\u00b7le\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Er wedelt! O der H\u00f6llenhund,", "tokens": ["Er", "we\u00b7delt", "!", "O", "der", "H\u00f6l\u00b7len\u00b7hund", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "NE", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der Unschuld Aergerni\u00df zu geben!", "tokens": ["Der", "Un\u00b7schuld", "A\u00b7er\u00b7ger\u00b7ni\u00df", "zu", "ge\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.6": {"line.1": {"text": "Er nimmt sich endlich mehr in Acht,", "tokens": ["Er", "nimmt", "sich", "end\u00b7lich", "mehr", "in", "Acht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "ADV", "ADV", "APPR", "CARD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Damit sein Thun unstr\u00e4flich scheine.", "tokens": ["Da\u00b7mit", "sein", "Thun", "uns\u00b7tr\u00e4f\u00b7lich", "schei\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PPOSAT", "NN", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Doch Hectorn dr\u00fcckt schon der Verdacht;", "tokens": ["Doch", "Hec\u00b7torn", "dr\u00fcckt", "schon", "der", "Ver\u00b7dacht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Er ist kein Thier f\u00fcr die Gemeine.", "tokens": ["Er", "ist", "kein", "Thier", "f\u00fcr", "die", "Ge\u00b7mei\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIAT", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Bald soll ein wohlgew\u00e4hlter Stein", "tokens": ["Bald", "soll", "ein", "wohl\u00b7ge\u00b7w\u00e4hl\u00b7ter", "Stein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Den ungezognen Hund ertr\u00e4nken;", "tokens": ["Den", "un\u00b7ge\u00b7zog\u00b7nen", "Hund", "er\u00b7tr\u00e4n\u00b7ken", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Nur ist die Strafe fast zu klein;", "tokens": ["Nur", "ist", "die", "Stra\u00b7fe", "fast", "zu", "klein", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "ADV", "PTKA", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der Hunger kann noch l\u00e4nger kr\u00e4nken.", "tokens": ["Der", "Hun\u00b7ger", "kann", "noch", "l\u00e4n\u00b7ger", "kr\u00e4n\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "ADV", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Man st\u00f6\u00dft, und schl\u00e4gt, und nennt ihn toll,", "tokens": ["Man", "st\u00f6\u00dft", ",", "und", "schl\u00e4gt", ",", "und", "nennt", "ihn", "toll", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "$,", "KON", "VVFIN", "$,", "KON", "VVFIN", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Zum Vorschmack h\u00e4rtrer Z\u00fcchtigungen:", "tokens": ["Zum", "Vor\u00b7schmack", "h\u00e4r\u00b7trer", "Z\u00fcch\u00b7ti\u00b7gun\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Doch alles dient zu seinem Wohl,", "tokens": ["Doch", "al\u00b7les", "dient", "zu", "sei\u00b7nem", "Wohl", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und zielt auf nichts, als Besserungen.", "tokens": ["Und", "zielt", "auf", "nichts", ",", "als", "Bes\u00b7se\u00b7run\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PIS", "$,", "KOUS", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Der Br\u00fcderschaft ergrimmte Zucht", "tokens": ["Der", "Br\u00fc\u00b7der\u00b7schaft", "er\u00b7grimm\u00b7te", "Zucht"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "H\u00e4uft t\u00e4glich die gewohnten T\u00fccke.", "tokens": ["H\u00e4uft", "t\u00e4g\u00b7lich", "die", "ge\u00b7wohn\u00b7ten", "T\u00fc\u00b7cke", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Zuletzt dringt ihn die Noth zur Flucht,", "tokens": ["Zu\u00b7letzt", "dringt", "ihn", "die", "Noth", "zur", "Flucht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und halberstarrt kehrt er zur\u00fccke.", "tokens": ["Und", "hal\u00b7ber\u00b7starrt", "kehrt", "er", "zu\u00b7r\u00fc\u00b7cke", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Von Mopsen wird er kaum erkannt;", "tokens": ["Von", "Mop\u00b7sen", "wird", "er", "kaum", "er\u00b7kannt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VAFIN", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So d\u00fcrftig k\u00f6mmt er angekrochen.", "tokens": ["So", "d\u00fcrf\u00b7tig", "k\u00f6mmt", "er", "an\u00b7ge\u00b7kro\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Allein, sobald er sich genannt,", "tokens": ["Al\u00b7lein", ",", "so\u00b7bald", "er", "sich", "ge\u00b7nannt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "PPER", "PRF", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wird er aufs z\u00e4rtlichste berochen.", "tokens": ["Wird", "er", "aufs", "z\u00e4rt\u00b7lichs\u00b7te", "be\u00b7ro\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPRART", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Mops spricht: mein Freund, du jammerst mich,", "tokens": ["Mops", "spricht", ":", "mein", "Freund", ",", "du", "jam\u00b7merst", "mich", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "$.", "PPOSAT", "NN", "$,", "PPER", "VVFIN", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ich werde dich zu tr\u00f6sten wissen,", "tokens": ["Ich", "wer\u00b7de", "dich", "zu", "tr\u00f6s\u00b7ten", "wis\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "PTKZU", "VVINF", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Ich lebe hier fast k\u00f6niglich,", "tokens": ["Ich", "le\u00b7be", "hier", "fast", "k\u00f6\u00b7nig\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mich m\u00e4sten lauter Leckerbissen.", "tokens": ["Mich", "m\u00e4s\u00b7ten", "lau\u00b7ter", "Le\u00b7cker\u00b7bis\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Madame gibt mir manchen Ku\u00df,", "tokens": ["Ma\u00b7da\u00b7me", "gibt", "mir", "man\u00b7chen", "Ku\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["FM", "VVFIN", "PPER", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Manch Schm\u00e4tzchen, dem kein Nachdruck fehlet.", "tokens": ["Manch", "Schm\u00e4tz\u00b7chen", ",", "dem", "kein", "Nach\u00b7druck", "feh\u00b7let", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "$,", "PRELS", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Mir kommen sie in Ueberflu\u00df,", "tokens": ["Mir", "kom\u00b7men", "sie", "in", "Ue\u00b7berf\u00b7lu\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Dem Manne werden sie gez\u00e4hlet.", "tokens": ["Dem", "Man\u00b7ne", "wer\u00b7den", "sie", "ge\u00b7z\u00e4h\u00b7let", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Wer will, was H\u00f6here gewollt,", "tokens": ["Wer", "will", ",", "was", "H\u00f6\u00b7he\u00b7re", "ge\u00b7wollt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "$,", "PWS", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dem wird die Ehrfurcht zum Erg\u00f6tzen,", "tokens": ["Dem", "wird", "die", "Ehr\u00b7furcht", "zum", "Er\u00b7g\u00f6t\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Mir sind die meisten Sch\u00f6nen hold,", "tokens": ["Mir", "sind", "die", "meis\u00b7ten", "Sch\u00f6\u00b7nen", "hold", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "PIAT", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mich lieben zwanzig junge Betzen.", "tokens": ["Mich", "lie\u00b7ben", "zwan\u00b7zig", "jun\u00b7ge", "Bet\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "CARD", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Mich lobt das ganze Haus; warum?", "tokens": ["Mich", "lobt", "das", "gan\u00b7ze", "Haus", ";", "wa\u00b7rum", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "$.", "PWAV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ich kann die Treue kl\u00fcglich \u00fcben;", "tokens": ["Ich", "kann", "die", "Treu\u00b7e", "kl\u00fcg\u00b7lich", "\u00fc\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "NN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Ich bleibe dem Geliebten stumm,", "tokens": ["Ich", "blei\u00b7be", "dem", "Ge\u00b7lieb\u00b7ten", "stumm", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und belle Bettlern oder Dieben.", "tokens": ["Und", "bel\u00b7le", "Bett\u00b7lern", "o\u00b7der", "Die\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "KON", "PDAT", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "Der beste Freund in unsrer Welt,", "tokens": ["Der", "bes\u00b7te", "Freund", "in", "uns\u00b7rer", "Welt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mops, war mit Hector auferzogen,", "tokens": ["Mops", ",", "war", "mit", "Hec\u00b7tor", "auf\u00b7er\u00b7zo\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VAFIN", "APPR", "NE", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und blieb ihm immer unverstellt,", "tokens": ["Und", "blieb", "ihm", "im\u00b7mer", "un\u00b7ver\u00b7stellt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mit wahrer Hundetreu gewogen.", "tokens": ["Mit", "wah\u00b7rer", "Hun\u00b7de\u00b7treu", "ge\u00b7wo\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "Ihm ging es recht nach seinem Sinn:", "tokens": ["Ihm", "ging", "es", "recht", "nach", "sei\u00b7nem", "Sinn", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADJD", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wo M\u00f6pschen war, da gab es Freude;", "tokens": ["Wo", "M\u00f6p\u00b7schen", "war", ",", "da", "gab", "es", "Freu\u00b7de", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "VAFIN", "$,", "ADV", "VVFIN", "PPER", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Doch Hector zog nach Norden hin,", "tokens": ["Doch", "Hec\u00b7tor", "zog", "nach", "Nor\u00b7den", "hin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "VVFIN", "APPR", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und fand Verfolgung, Frost und R\u00e4ude.", "tokens": ["Und", "fand", "Ver\u00b7fol\u00b7gung", ",", "Frost", "und", "R\u00e4u\u00b7de", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.17": {"line.1": {"text": "Wahr ist es: Hectors Unverstand", "tokens": ["Wahr", "ist", "es", ":", "Hec\u00b7tors", "Un\u00b7ver\u00b7stand"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["ADJD", "VAFIN", "PPER", "$.", "NE", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Gibt Anla\u00df oft ihn zu verl\u00e4stern:", "tokens": ["Gibt", "An\u00b7la\u00df", "oft", "ihn", "zu", "ver\u00b7l\u00e4s\u00b7tern", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "ADV", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Er ist zu munter, zu galant,", "tokens": ["Er", "ist", "zu", "mun\u00b7ter", ",", "zu", "ga\u00b7lant", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKA", "ADJD", "$,", "PTKA", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und lebte dort bei keuschen Schwestern.", "tokens": ["Und", "leb\u00b7te", "dort", "bei", "keu\u00b7schen", "Schwes\u00b7tern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.18": {"line.1": {"text": "Kaum finden sich die Br\u00fcder ein,", "tokens": ["Kaum", "fin\u00b7den", "sich", "die", "Br\u00fc\u00b7der", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und seufzen br\u00fcnstig an der Schwelle,", "tokens": ["Und", "seuf\u00b7zen", "br\u00fcns\u00b7tig", "an", "der", "Schwel\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "(vom Nachbar recht geh\u00f6rt zu sein)", "tokens": ["(", "vom", "Nach\u00b7bar", "recht", "ge\u00b7h\u00f6rt", "zu", "sein", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPRART", "NN", "ADJD", "VVPP", "PTKZU", "VAINF", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So \u00fcbert\u00e4ubt sie sein Gebelle.", "tokens": ["So", "\u00fc\u00b7bert\u00b7\u00e4ubt", "sie", "sein", "Ge\u00b7bel\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.19": {"line.1": {"text": "Er wedelt, wenn den Andachtbund", "tokens": ["Er", "we\u00b7delt", ",", "wenn", "den", "An\u00b7dacht\u00b7bund"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Gebet und Wink und Ku\u00df beleben!", "tokens": ["Ge\u00b7bet", "und", "Wink", "und", "Ku\u00df", "be\u00b7le\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Er wedelt! O der H\u00f6llenhund,", "tokens": ["Er", "we\u00b7delt", "!", "O", "der", "H\u00f6l\u00b7len\u00b7hund", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "NE", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der Unschuld Aergerni\u00df zu geben!", "tokens": ["Der", "Un\u00b7schuld", "A\u00b7er\u00b7ger\u00b7ni\u00df", "zu", "ge\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.20": {"line.1": {"text": "Er nimmt sich endlich mehr in Acht,", "tokens": ["Er", "nimmt", "sich", "end\u00b7lich", "mehr", "in", "Acht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "ADV", "ADV", "APPR", "CARD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Damit sein Thun unstr\u00e4flich scheine.", "tokens": ["Da\u00b7mit", "sein", "Thun", "uns\u00b7tr\u00e4f\u00b7lich", "schei\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PPOSAT", "NN", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Doch Hectorn dr\u00fcckt schon der Verdacht;", "tokens": ["Doch", "Hec\u00b7torn", "dr\u00fcckt", "schon", "der", "Ver\u00b7dacht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Er ist kein Thier f\u00fcr die Gemeine.", "tokens": ["Er", "ist", "kein", "Thier", "f\u00fcr", "die", "Ge\u00b7mei\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIAT", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.21": {"line.1": {"text": "Bald soll ein wohlgew\u00e4hlter Stein", "tokens": ["Bald", "soll", "ein", "wohl\u00b7ge\u00b7w\u00e4hl\u00b7ter", "Stein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Den ungezognen Hund ertr\u00e4nken;", "tokens": ["Den", "un\u00b7ge\u00b7zog\u00b7nen", "Hund", "er\u00b7tr\u00e4n\u00b7ken", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Nur ist die Strafe fast zu klein;", "tokens": ["Nur", "ist", "die", "Stra\u00b7fe", "fast", "zu", "klein", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "ADV", "PTKA", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der Hunger kann noch l\u00e4nger kr\u00e4nken.", "tokens": ["Der", "Hun\u00b7ger", "kann", "noch", "l\u00e4n\u00b7ger", "kr\u00e4n\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "ADV", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.22": {"line.1": {"text": "Man st\u00f6\u00dft, und schl\u00e4gt, und nennt ihn toll,", "tokens": ["Man", "st\u00f6\u00dft", ",", "und", "schl\u00e4gt", ",", "und", "nennt", "ihn", "toll", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "$,", "KON", "VVFIN", "$,", "KON", "VVFIN", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Zum Vorschmack h\u00e4rtrer Z\u00fcchtigungen:", "tokens": ["Zum", "Vor\u00b7schmack", "h\u00e4r\u00b7trer", "Z\u00fcch\u00b7ti\u00b7gun\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Doch alles dient zu seinem Wohl,", "tokens": ["Doch", "al\u00b7les", "dient", "zu", "sei\u00b7nem", "Wohl", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und zielt auf nichts, als Besserungen.", "tokens": ["Und", "zielt", "auf", "nichts", ",", "als", "Bes\u00b7se\u00b7run\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PIS", "$,", "KOUS", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.23": {"line.1": {"text": "Der Br\u00fcderschaft ergrimmte Zucht", "tokens": ["Der", "Br\u00fc\u00b7der\u00b7schaft", "er\u00b7grimm\u00b7te", "Zucht"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "H\u00e4uft t\u00e4glich die gewohnten T\u00fccke.", "tokens": ["H\u00e4uft", "t\u00e4g\u00b7lich", "die", "ge\u00b7wohn\u00b7ten", "T\u00fc\u00b7cke", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Zuletzt dringt ihn die Noth zur Flucht,", "tokens": ["Zu\u00b7letzt", "dringt", "ihn", "die", "Noth", "zur", "Flucht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und halberstarrt kehrt er zur\u00fccke.", "tokens": ["Und", "hal\u00b7ber\u00b7starrt", "kehrt", "er", "zu\u00b7r\u00fc\u00b7cke", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.24": {"line.1": {"text": "Von Mopsen wird er kaum erkannt;", "tokens": ["Von", "Mop\u00b7sen", "wird", "er", "kaum", "er\u00b7kannt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VAFIN", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So d\u00fcrftig k\u00f6mmt er angekrochen.", "tokens": ["So", "d\u00fcrf\u00b7tig", "k\u00f6mmt", "er", "an\u00b7ge\u00b7kro\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Allein, sobald er sich genannt,", "tokens": ["Al\u00b7lein", ",", "so\u00b7bald", "er", "sich", "ge\u00b7nannt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "PPER", "PRF", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wird er aufs z\u00e4rtlichste berochen.", "tokens": ["Wird", "er", "aufs", "z\u00e4rt\u00b7lichs\u00b7te", "be\u00b7ro\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPRART", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.25": {"line.1": {"text": "Mops spricht: mein Freund, du jammerst mich,", "tokens": ["Mops", "spricht", ":", "mein", "Freund", ",", "du", "jam\u00b7merst", "mich", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "$.", "PPOSAT", "NN", "$,", "PPER", "VVFIN", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ich werde dich zu tr\u00f6sten wissen,", "tokens": ["Ich", "wer\u00b7de", "dich", "zu", "tr\u00f6s\u00b7ten", "wis\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "PTKZU", "VVINF", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Ich lebe hier fast k\u00f6niglich,", "tokens": ["Ich", "le\u00b7be", "hier", "fast", "k\u00f6\u00b7nig\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mich m\u00e4sten lauter Leckerbissen.", "tokens": ["Mich", "m\u00e4s\u00b7ten", "lau\u00b7ter", "Le\u00b7cker\u00b7bis\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.26": {"line.1": {"text": "Madame gibt mir manchen Ku\u00df,", "tokens": ["Ma\u00b7da\u00b7me", "gibt", "mir", "man\u00b7chen", "Ku\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["FM", "VVFIN", "PPER", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Manch Schm\u00e4tzchen, dem kein Nachdruck fehlet.", "tokens": ["Manch", "Schm\u00e4tz\u00b7chen", ",", "dem", "kein", "Nach\u00b7druck", "feh\u00b7let", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "$,", "PRELS", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Mir kommen sie in Ueberflu\u00df,", "tokens": ["Mir", "kom\u00b7men", "sie", "in", "Ue\u00b7berf\u00b7lu\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Dem Manne werden sie gez\u00e4hlet.", "tokens": ["Dem", "Man\u00b7ne", "wer\u00b7den", "sie", "ge\u00b7z\u00e4h\u00b7let", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.27": {"line.1": {"text": "Wer will, was H\u00f6here gewollt,", "tokens": ["Wer", "will", ",", "was", "H\u00f6\u00b7he\u00b7re", "ge\u00b7wollt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "$,", "PWS", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dem wird die Ehrfurcht zum Erg\u00f6tzen,", "tokens": ["Dem", "wird", "die", "Ehr\u00b7furcht", "zum", "Er\u00b7g\u00f6t\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Mir sind die meisten Sch\u00f6nen hold,", "tokens": ["Mir", "sind", "die", "meis\u00b7ten", "Sch\u00f6\u00b7nen", "hold", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "PIAT", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mich lieben zwanzig junge Betzen.", "tokens": ["Mich", "lie\u00b7ben", "zwan\u00b7zig", "jun\u00b7ge", "Bet\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "CARD", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.28": {"line.1": {"text": "Mich lobt das ganze Haus; warum?", "tokens": ["Mich", "lobt", "das", "gan\u00b7ze", "Haus", ";", "wa\u00b7rum", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "$.", "PWAV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ich kann die Treue kl\u00fcglich \u00fcben;", "tokens": ["Ich", "kann", "die", "Treu\u00b7e", "kl\u00fcg\u00b7lich", "\u00fc\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "NN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Ich bleibe dem Geliebten stumm,", "tokens": ["Ich", "blei\u00b7be", "dem", "Ge\u00b7lieb\u00b7ten", "stumm", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und belle Bettlern oder Dieben.", "tokens": ["Und", "bel\u00b7le", "Bett\u00b7lern", "o\u00b7der", "Die\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "KON", "PDAT", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}