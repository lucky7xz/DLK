{"dta.poem.10113": {"metadata": {"author": {"name": "Brockes, Barthold Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "Der Lammes-Kopf.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1735", "urn": "urn:nbn:de:kobv:b4-20086-0", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Man hatte j\u00fcngst, zum Mittags-Mahl, mir einen Lam\u0303s-\nKopf aufgetischet:\nWie ich nun die zerlegte Knochen von ungefehr recht ange-\nsehn,", "tokens": ["Man", "hat\u00b7te", "j\u00fcngst", ",", "zum", "Mit\u00b7tags\u00b7Mahl", ",", "mir", "ei\u00b7nen", "Lam\u0303s", "Kopf", "auf\u00b7ge\u00b7ti\u00b7schet", ":", "Wie", "ich", "nun", "die", "zer\u00b7leg\u00b7te", "Kno\u00b7chen", "von", "un\u00b7ge\u00b7fehr", "recht", "an\u00b7ge", "sehn", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "ADV", "$,", "APPRART", "NN", "$,", "PPER", "ART", "TRUNC", "NN", "VVFIN", "$.", "PWAV", "PPER", "ADV", "ART", "ADJA", "NN", "APPR", "ADV", "ADJD", "TRUNC", "VVINF", "$,"], "meter": "-+-+-+-+-+--+-+-+-+-+-+-+--+-+-+-+", "measure": "iambic.octa.plus.relaxed"}, "line.2": {"text": "Befand ich sie gantz sonderbar, ja wunderns-wehrt gebildet", "tokens": ["Be\u00b7fand", "ich", "sie", "gantz", "son\u00b7der\u00b7bar", ",", "ja", "wun\u00b7derns\u00b7wehrt", "ge\u00b7bil\u00b7det"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "PPER", "PPER", "ADV", "ADJD", "$,", "ADV", "ADJD", "VVPP"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.3": {"text": "Und ward zu fernerer Betrachtung dadurch, wie billig, an-", "tokens": ["Und", "ward", "zu", "fer\u00b7ne\u00b7rer", "Be\u00b7trach\u00b7tung", "da\u00b7durch", ",", "wie", "bil\u00b7lig", ",", "an"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word"], "pos": ["KON", "VAFIN", "APPR", "ADJA", "NN", "PAV", "$,", "PWAV", "ADJD", "$,", "TRUNC"], "meter": "-+-+-+-+--+-+-+", "measure": "iambic.septa.relaxed"}}, "stanza.2": {"line.1": {"text": "Ich ward Bewundrungs-voll gewahr, da\u00df gantz ver-", "tokens": ["Ich", "ward", "Be\u00b7wun\u00b7drungs\u00b7voll", "ge\u00b7wahr", ",", "da\u00df", "gantz", "ver"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VAFIN", "NN", "ADJD", "$,", "KOUS", "ADV", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Den nett formirten Kopf formiren; da mancher hart, als", "tokens": ["Den", "nett", "for\u00b7mir\u00b7ten", "Kopf", "for\u00b7mi\u00b7ren", ";", "da", "man\u00b7cher", "hart", ",", "als"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["ART", "ADJD", "ADJA", "NN", "VVFIN", "$.", "KOUS", "PIS", "ADJD", "$,", "KOUS"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Ein ander weich; der knorpelhaft; der voller L\u00f6cher, und", "tokens": ["Ein", "an\u00b7der", "weich", ";", "der", "knor\u00b7pel\u00b7haft", ";", "der", "vol\u00b7ler", "L\u00f6\u00b7cher", ",", "und"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["ART", "ADJD", "ADJD", "$.", "ART", "NN", "$.", "ART", "ADJA", "NN", "$,", "KON"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.4": {"text": "Der recht wie Schiefer; dieser rund; da viele lang und", "tokens": ["Der", "recht", "wie", "Schie\u00b7fer", ";", "die\u00b7ser", "rund", ";", "da", "vie\u00b7le", "lang", "und"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJD", "KOKOM", "NN", "$.", "PDAT", "ADJD", "$.", "KOUS", "PIS", "ADJD", "KON"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Verschiedne schienen eingedr\u00fcckt; mit Strichen sind viel\u2019", "tokens": ["Ver\u00b7schied\u00b7ne", "schie\u00b7nen", "ein\u00b7ge\u00b7dr\u00fcckt", ";", "mit", "Stri\u00b7chen", "sind", "viel'"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "VVPP", "$.", "APPR", "NN", "VAFIN", "ADV"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.6": {"text": "Der ist gerade wie ein Stock; der, wie ein Hake, krumm", "tokens": ["Der", "ist", "ge\u00b7ra\u00b7de", "wie", "ein", "Stock", ";", "der", ",", "wie", "ein", "Ha\u00b7ke", ",", "krumm"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["PDS", "VAFIN", "ADV", "KOKOM", "ART", "NN", "$.", "ART", "$,", "PWAV", "ART", "NN", "$,", "ADJD"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.7": {"text": "In diesem sind gew\u00f6lbte H\u00f6len, der Augen Schirm-Dach;", "tokens": ["In", "die\u00b7sem", "sind", "ge\u00b7w\u00f6lb\u00b7te", "H\u00f6\u00b7len", ",", "der", "Au\u00b7gen", "Schir\u00b7mDach", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "VAFIN", "ADJA", "NN", "$,", "ART", "NN", "NN", "$."], "meter": "--+--+-+--+--+", "measure": "anapaest.di.plus"}, "line.8": {"text": "Besondre Oeffnungen der Ohren, und noch an einem andern", "tokens": ["Be\u00b7sond\u00b7re", "Oeff\u00b7nun\u00b7gen", "der", "Oh\u00b7ren", ",", "und", "noch", "an", "ei\u00b7nem", "an\u00b7dern"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADJA", "NN", "ART", "NN", "$,", "KON", "ADV", "APPR", "ART", "ADJA"], "meter": "-+-+-+-+--+-+-+-", "measure": "iambic.septa.relaxed"}, "line.9": {"text": "Von noch gantz unterschiedner Gattung, am fordern Kno-", "tokens": ["Von", "noch", "gantz", "un\u00b7ter\u00b7schied\u00b7ner", "Gat\u00b7tung", ",", "am", "for\u00b7dern", "Kno"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "ADV", "ADV", "ADJA", "NN", "$,", "APPRART", "ADJA", "TRUNC"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.10": {"text": "Zu des Geruchs Canal und Gang, noch andere sich schmahl", "tokens": ["Zu", "des", "Ge\u00b7ruchs", "Ca\u00b7nal", "und", "Gang", ",", "noch", "an\u00b7de\u00b7re", "sich", "schmahl"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "NE", "KON", "NN", "$,", "ADV", "PIS", "PRF", "ADV"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.11": {"text": "Die forn beweg-und weichlich werden. Verschiedene sind", "tokens": ["Die", "forn", "be\u00b7weg\u00b7\u00b7und", "weich\u00b7lich", "wer\u00b7den", ".", "Ver\u00b7schie\u00b7de\u00b7ne", "sind"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "ADJD", "ADJD", "VAINF", "$.", "NN", "VAFIN"], "meter": "-+-+-+-+--+--+", "measure": "iambic.hexa.relaxed"}, "line.12": {"text": "Da\u00df zarte Nerven durch sie gehen; es endigen sich viel\u2019 in", "tokens": ["Da\u00df", "zar\u00b7te", "Ner\u00b7ven", "durch", "sie", "ge\u00b7hen", ";", "es", "en\u00b7di\u00b7gen", "sich", "viel'", "in"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADJA", "NN", "APPR", "PPER", "VVINF", "$.", "PPER", "VVFIN", "PRF", "ADV", "APPR"], "meter": "-+-+-+-+--++-+--", "measure": "iambic.septa.relaxed"}, "line.13": {"text": "Die Kiefern sieht man eingetheilt in viele F\u00e4cherchen mit", "tokens": ["Die", "Kie\u00b7fern", "sieht", "man", "ein\u00b7ge\u00b7theilt", "in", "vie\u00b7le", "F\u00e4\u00b7cher\u00b7chen", "mit"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PIS", "VVPP", "APPR", "PIAT", "NN", "APPR"], "meter": "-+-+-+-+-+-+--+", "measure": "iambic.septa.chol"}, "line.14": {"text": "Noch wird ein wirckliches Gew\u00f6lbe von gr\u00f6ssern Umfang,", "tokens": ["Noch", "wird", "ein", "wir\u00b7ck\u00b7li\u00b7ches", "Ge\u00b7w\u00f6l\u00b7be", "von", "gr\u00f6s\u00b7sern", "Um\u00b7fang", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "ADJA", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-++-+--+-+-", "measure": "iambic.septa.relaxed"}, "line.15": {"text": "Bis hinten durch den gantzen Kopf, als ein Beh\u00e4lter zum", "tokens": ["Bis", "hin\u00b7ten", "durch", "den", "gant\u00b7zen", "Kopf", ",", "als", "ein", "Be\u00b7h\u00e4l\u00b7ter", "zum"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "ADV", "APPR", "ART", "ADJA", "NN", "$,", "KOUS", "ART", "NN", "APPRART"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.16": {"text": "Jm harten Knochen angetroffen. Ich stutzt\u2019, als ich die\u00df", "tokens": ["Jm", "har\u00b7ten", "Kno\u00b7chen", "an\u00b7ge\u00b7trof\u00b7fen", ".", "Ich", "stutzt'", ",", "als", "ich", "die\u00df"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["APPRART", "ADJA", "NN", "VVPP", "$.", "PPER", "VVFIN", "$,", "KOUS", "PPER", "PDS"], "meter": "-+-+-+-+--+--+", "measure": "iambic.hexa.relaxed"}, "line.17": {"text": "Und dachte mit ger\u00fchrter Seele: Wie ward die\u00df alles?", "tokens": ["Und", "dach\u00b7te", "mit", "ge\u00b7r\u00fchr\u00b7ter", "See\u00b7le", ":", "Wie", "ward", "die\u00df", "al\u00b7les", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ADJA", "NN", "$.", "PWAV", "VAFIN", "PDS", "PIS", "$."], "meter": "-+-+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.18": {"text": "Hat dieses k\u00fcnstliche Geb\u00e4ude formirt, errichtet, ausge-", "tokens": ["Hat", "die\u00b7ses", "k\u00fcnst\u00b7li\u00b7che", "Ge\u00b7b\u00e4u\u00b7de", "for\u00b7mirt", ",", "er\u00b7rich\u00b7tet", ",", "aus\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word"], "pos": ["VAFIN", "PDAT", "ADJA", "NN", "VVPP", "$,", "VVPP", "$,", "TRUNC"], "meter": "-+-+-+-+-+--+-+-", "measure": "iambic.septa.relaxed"}, "line.19": {"text": "Nach welcher Richtschnur legt sies an?", "tokens": ["Nach", "wel\u00b7cher", "Richt\u00b7schnur", "legt", "sies", "an", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PWAT", "NN", "VVFIN", "PIS", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.20": {"text": "Was f\u00fcr ein Werck-Zeug brauchte sie,", "tokens": ["Was", "f\u00fcr", "ein", "Wer\u00b7ck\u00b7Zeug", "brauch\u00b7te", "sie", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "ART", "NN", "VVFIN", "PPER", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.21": {"text": "Es auszuh\u00f6len, es zu bilden? woher nahm sie die Symmetrie,", "tokens": ["Es", "aus\u00b7zu\u00b7h\u00f6\u00b7len", ",", "es", "zu", "bil\u00b7den", "?", "wo\u00b7her", "nahm", "sie", "die", "Sym\u00b7me\u00b7trie", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVINF", "$,", "PPER", "PTKZU", "VVINF", "$.", "PWAV", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+--++--+-+", "measure": "iambic.octa.plus.relaxed"}, "line.22": {"text": "Da\u00df alles so gar Negel-recht, da\u00df alles gleich auf beiden", "tokens": ["Da\u00df", "al\u00b7les", "so", "gar", "Ne\u00b7gel\u00b7recht", ",", "da\u00df", "al\u00b7les", "gleich", "auf", "bei\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "ADV", "ADV", "NN", "$,", "KOUS", "PIS", "ADV", "APPR", "PIAT"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.23": {"text": "Woher ein so gesch\u00e4rfft Gesicht? da so viel kleine Kleinigkeiten", "tokens": ["Wo\u00b7her", "ein", "so", "ge\u00b7sch\u00e4rfft", "Ge\u00b7sicht", "?", "da", "so", "viel", "klei\u00b7ne", "Klei\u00b7nig\u00b7kei\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ART", "ADV", "VVPP", "NN", "$.", "ADV", "ADV", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-+-+-", "measure": "iambic.octa.plus"}, "line.24": {"text": "Mit Flei\u00df allhier zu bilden waren: Ich find\u2019 hier weder", "tokens": ["Mit", "Flei\u00df", "all\u00b7hier", "zu", "bil\u00b7den", "wa\u00b7ren", ":", "Ich", "find'", "hier", "we\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "NN", "ADV", "PTKZU", "VVINF", "VAFIN", "$.", "PPER", "VVFIN", "ADV", "KON"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.25": {"text": "Die solch ein \u00fcberk\u00fcnstlich Werck zu sehn und zu formiren", "tokens": ["Die", "solch", "ein", "\u00fc\u00b7ber\u00b7k\u00fcnst\u00b7lich", "Werck", "zu", "sehn", "und", "zu", "for\u00b7mi\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "PIAT", "ART", "ADJD", "NN", "PTKZU", "VVINF", "KON", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.26": {"text": "Ich finde nicht einmahl ein Licht, wobey solch Kunst-reich", "tokens": ["Ich", "fin\u00b7de", "nicht", "ein\u00b7mahl", "ein", "Licht", ",", "wo\u00b7bey", "solch", "Kunst\u00b7reich"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PTKNEG", "ADV", "ART", "NN", "$,", "PWAV", "PIAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Indem es, wie bekannt, im dunckeln gewirckt wird und her-", "tokens": ["In\u00b7dem", "es", ",", "wie", "be\u00b7kannt", ",", "im", "dun\u00b7ckeln", "ge\u00b7wirckt", "wird", "und", "her"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "$,", "PWAV", "ADJD", "$,", "APPRART", "ADJA", "VVPP", "VAFIN", "KON", "TRUNC"], "meter": "-+-+-+-+---+-+", "measure": "unknown.measure.hexa"}}, "stanza.3": {"line.1": {"text": "Hier stehet all mein dencken still. Ich seh\u2019 allhier gantz", "tokens": ["Hier", "ste\u00b7het", "all", "mein", "den\u00b7cken", "still", ".", "Ich", "seh'", "all\u00b7hier", "gantz"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PIAT", "PPOSAT", "NN", "PTKVZ", "$.", "PPER", "VVFIN", "ADV", "ADV"], "meter": "-+--+--+-+--+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Als alle Kr\u00e4ffte, die die Menschheit, trotz ihrem D\u00fcnckel, ie", "tokens": ["Als", "al\u00b7le", "Kr\u00e4ff\u00b7te", ",", "die", "die", "Menschheit", ",", "trotz", "ih\u00b7rem", "D\u00fcn\u00b7ckel", ",", "ie"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["KOUS", "PIAT", "NN", "$,", "PRELS", "ART", "NN", "$,", "APPR", "PPOSAT", "NN", "$,", "ADV"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.3": {"text": "Ob sie bisher gleich mehrentheils, nach ihrem Ma\u00df-Stab,", "tokens": ["Ob", "sie", "bis\u00b7her", "gleich", "meh\u00b7ren\u00b7theils", ",", "nach", "ih\u00b7rem", "Ma\u00df\u00b7Stab", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "ADV", "$,", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.4": {"text": "Es m\u00fcssen eigne Kr\u00e4ffte seyn, die zu so k\u00fcnstlichem Gesch\u00e4ffte,", "tokens": ["Es", "m\u00fcs\u00b7sen", "eig\u00b7ne", "Kr\u00e4ff\u00b7te", "seyn", ",", "die", "zu", "so", "k\u00fcnst\u00b7li\u00b7chem", "Ge\u00b7sch\u00e4ff\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADJA", "NN", "VAINF", "$,", "PRELS", "APPR", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-+-+-", "measure": "iambic.octa.plus"}, "line.5": {"text": "Mehr F\u00e4higkeit, mehr Wissenschaft, mehr Kunst, Geschick-", "tokens": ["Mehr", "F\u00e4\u00b7hig\u00b7keit", ",", "mehr", "Wis\u00b7sen\u00b7schaft", ",", "mehr", "Kunst", ",", "Ge\u00b7schick"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word"], "pos": ["PIAT", "NN", "$,", "PIAT", "NN", "$,", "PIAT", "NN", "$,", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Vom grossen Sch\u00f6pfer aller Dinge vermuthlich \u00fcberkom-", "tokens": ["Vom", "gros\u00b7sen", "Sch\u00f6p\u00b7fer", "al\u00b7ler", "Din\u00b7ge", "ver\u00b7muth\u00b7lich", "\u00fc\u00b7ber\u00b7kom"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "ADJA", "NN", "PIAT", "NN", "ADV", "TRUNC"], "meter": "-+-+-+-+--+-+-+", "measure": "iambic.septa.relaxed"}}, "stanza.4": {"line.1": {"text": "Denn da\u00df man spricht: es ist gewachsen; und anders", "tokens": ["Denn", "da\u00df", "man", "spricht", ":", "es", "ist", "ge\u00b7wach\u00b7sen", ";", "und", "an\u00b7ders"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "KOUS", "PIS", "VVFIN", "$.", "PPER", "VAFIN", "VVPP", "$.", "KON", "ADV"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Fast eben vor, als wenn man spricht: es k\u00f6mmt von unge-", "tokens": ["Fast", "e\u00b7ben", "vor", ",", "als", "wenn", "man", "spricht", ":", "es", "k\u00f6mmt", "von", "un\u00b7ge"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "PTKVZ", "$,", "KOKOM", "KOUS", "PIS", "VVFIN", "$.", "PPER", "VVFIN", "APPR", "TRUNC"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ich kann, wenn ich es recht erwege, vom W\u00f6rtchen ", "tokens": ["Ich", "kann", ",", "wenn", "ich", "es", "recht", "er\u00b7we\u00b7ge", ",", "vom", "W\u00f6rt\u00b7chen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VMFIN", "$,", "KOUS", "PPER", "PPER", "ADJD", "VVFIN", "$,", "APPRART", "NN"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Als da\u00df von einem C\u00f6rper sich desselben Theile mehren,", "tokens": ["Als", "da\u00df", "von", "ei\u00b7nem", "C\u00f6r\u00b7per", "sich", "des\u00b7sel\u00b7ben", "Thei\u00b7le", "meh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "APPR", "ART", "NN", "PRF", "PDAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.5": {"text": "Sich dehnen, f\u00fcllen, gr\u00f6sser werden, sich in die Breit\u2019 und", "tokens": ["Sich", "deh\u00b7nen", ",", "f\u00fcl\u00b7len", ",", "gr\u00f6s\u00b7ser", "wer\u00b7den", ",", "sich", "in", "die", "Breit'", "und"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PRF", "PDS", "$,", "VVFIN", "$,", "ADJD", "VAINF", "$,", "PRF", "APPR", "ART", "NN", "KON"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "Die\u00df heisset ", "tokens": ["Die\u00df", "heis\u00b7set"], "token_info": ["word", "word"], "pos": ["PDS", "VVFIN"], "meter": "-+-", "measure": "amphibrach.single"}, "line.7": {"text": "Die Urstands-Theil\u2019, indem ein iedes solch eine Krafft zu", "tokens": ["Die", "Ur\u00b7stands\u00b7T\u00b7heil'", ",", "in\u00b7dem", "ein", "ie\u00b7des", "solch", "ei\u00b7ne", "Krafft", "zu"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "KOUS", "ART", "PIAT", "PIAT", "ART", "NN", "PTKZU"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.8": {"text": "Die alles so, nicht anders wirckt; die\u00df kann mir ", "tokens": ["Die", "al\u00b7les", "so", ",", "nicht", "an\u00b7ders", "wirckt", ";", "die\u00df", "kann", "mir"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "PIS", "ADV", "$,", "PTKNEG", "ADV", "VVFIN", "$.", "PDS", "VMFIN", "PPER"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "Du sprichst: im Samen steckt die\u00df alles. Gar wol!", "tokens": ["Du", "sprichst", ":", "im", "Sa\u00b7men", "steckt", "die\u00df", "al\u00b7les", ".", "Gar", "wol", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "APPRART", "NN", "VVFIN", "PDS", "PIS", "$.", "ADV", "ADV", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ein Wort, das mich nicht kl\u00fcger macht, ein unverst\u00e4ndlich", "tokens": ["Ein", "Wort", ",", "das", "mich", "nicht", "kl\u00fc\u00b7ger", "macht", ",", "ein", "un\u00b7ver\u00b7st\u00e4nd\u00b7lich"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "PTKNEG", "ADJD", "VVFIN", "$,", "ART", "ADJD"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Sie treffen beid\u2019 an Dunckelheit, wie mich bed\u00fcnckt, wol", "tokens": ["Sie", "tref\u00b7fen", "beid'", "an", "Dun\u00b7ckel\u00b7heit", ",", "wie", "mich", "be\u00b7d\u00fcnckt", ",", "wol"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["PPER", "VVFIN", "PIS", "APPR", "NN", "$,", "PWAV", "PPER", "VVFIN", "$,", "ADV"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So weit wir unser dencken sch\u00e4rffen, so tieff auch unsre Sin-", "tokens": ["So", "weit", "wir", "un\u00b7ser", "den\u00b7cken", "sch\u00e4rf\u00b7fen", ",", "so", "tieff", "auch", "uns\u00b7re", "Sin"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "PPER", "PPOSAT", "NN", "VVINF", "$,", "ADV", "ADJD", "ADV", "PPOSAT", "TRUNC"], "meter": "-+-+-+-+--+-+-+", "measure": "iambic.septa.relaxed"}, "line.5": {"text": "So k\u00f6nnen wir vom wahren Ursprung des Samen-Wesens", "tokens": ["So", "k\u00f6n\u00b7nen", "wir", "vom", "wah\u00b7ren", "Ur\u00b7sprung", "des", "Sa\u00b7men\u00b7We\u00b7sens"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PPER", "APPRART", "ADJA", "NN", "ART", "NN"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "Wie aber wir, ohn Witz, nichts k\u00fcnstlichs von Menschen ie", "tokens": ["Wie", "a\u00b7ber", "wir", ",", "ohn", "Witz", ",", "nichts", "k\u00fcnst\u00b7lichs", "von", "Men\u00b7schen", "ie"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADV", "PPER", "$,", "KOUI", "NN", "$,", "PIS", "VVFIN", "APPR", "NN", "ADV"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.7": {"text": "So scheint es billig, auch zu glauben, da\u00df das, so die Natur", "tokens": ["So", "scheint", "es", "bil\u00b7lig", ",", "auch", "zu", "glau\u00b7ben", ",", "da\u00df", "das", ",", "so", "die", "Na\u00b7tur"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "$,", "ADV", "PTKZU", "VVINF", "$,", "KOUS", "PDS", "$,", "ADV", "ART", "NN"], "meter": "-+-+-+-+--+-+-+", "measure": "iambic.septa.relaxed"}, "line.8": {"text": "So k\u00fcnstlich webt, so flei\u00dfig f\u00fcget, so nett verschr\u00e4nckt, so", "tokens": ["So", "k\u00fcnst\u00b7lich", "webt", ",", "so", "flei\u00b7\u00dfig", "f\u00fc\u00b7get", ",", "so", "nett", "ver\u00b7schr\u00e4nckt", ",", "so"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["ADV", "ADJD", "VVFIN", "$,", "ADV", "ADJD", "VVFIN", "$,", "ADV", "ADJD", "VVPP", "$,", "ADV"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.9": {"text": "Nicht sonder Witz, Verstand und dencken, ohn\u2019 Arbeit, Flei\u00df", "tokens": ["Nicht", "son\u00b7der", "Witz", ",", "Ver\u00b7stand", "und", "den\u00b7cken", ",", "ohn'", "Ar\u00b7beit", ",", "Flei\u00df"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word"], "pos": ["PTKNEG", "ADJA", "NN", "$,", "NN", "KON", "VVINF", "$,", "KOUI", "NN", "$,", "NN"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.10": {"text": "Nur blo\u00df von ungefehr geschehe. Ach nein! Die Vollen-", "tokens": ["Nur", "blo\u00df", "von", "un\u00b7ge\u00b7fehr", "ge\u00b7sche\u00b7he", ".", "Ach", "nein", "!", "Die", "Vol\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["ADV", "ADV", "APPR", "ADJD", "VVFIN", "$.", "NN", "PTKANT", "$.", "ART", "TRUNC"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.11": {"text": "Der C\u00f6rper die der Menschen Arbeit, an Ordnung, Masse,", "tokens": ["Der", "C\u00f6r\u00b7per", "die", "der", "Men\u00b7schen", "Ar\u00b7beit", ",", "an", "Ord\u00b7nung", ",", "Mas\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "ART", "ART", "NN", "NN", "$,", "APPR", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.12": {"text": "Und Kunst, bey weitem \u00fcbersteigt, erweiset, wenn wirs wol", "tokens": ["Und", "Kunst", ",", "bey", "wei\u00b7tem", "\u00fc\u00b7bers\u00b7teigt", ",", "er\u00b7wei\u00b7set", ",", "wenn", "wirs", "wol"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["KON", "NN", "$,", "APPR", "PIS", "VVPP", "$,", "VVFIN", "$,", "KOUS", "PIS", "ADV"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.13": {"text": "Da\u00df es nicht ungereimt zu dencken: Der Sch\u00f6pfer hab\u2019 aus", "tokens": ["Da\u00df", "es", "nicht", "un\u00b7ge\u00b7reimt", "zu", "den\u00b7cken", ":", "Der", "Sch\u00f6p\u00b7fer", "hab'", "aus"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PTKNEG", "ADJD", "PTKZU", "VVINF", "$.", "ART", "NN", "VAFIN", "APPR"], "meter": "-+-+-+-+--+--+", "measure": "iambic.hexa.relaxed"}, "line.14": {"text": "Die er in solcher Meng\u2019 erschaffen, verschiedene zu Bildungs-", "tokens": ["Die", "er", "in", "sol\u00b7cher", "Meng'", "er\u00b7schaf\u00b7fen", ",", "ver\u00b7schie\u00b7de\u00b7ne", "zu", "Bil\u00b7dungs"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "PPER", "APPR", "PIAT", "NN", "VVPP", "$,", "ADJA", "APPR", "TRUNC"], "meter": "-+-+-+-+--+-+-+-", "measure": "iambic.septa.relaxed"}, "line.15": {"text": "Allein erschaffen und geordnet; als da\u00df man wollt\u2019 ein Un-", "tokens": ["Al\u00b7lein", "er\u00b7schaf\u00b7fen", "und", "ge\u00b7ord\u00b7net", ";", "als", "da\u00df", "man", "wollt'", "ein", "Un"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVPP", "KON", "VVPP", "$.", "KOKOM", "KOUS", "PIS", "VMFIN", "ART", "TRUNC"], "meter": "-+-+-+-+--+-+-+", "measure": "iambic.septa.relaxed"}, "line.16": {"text": "Das blind im Samen wircket, glauben, und nicht was wei-", "tokens": ["Das", "blind", "im", "Sa\u00b7men", "wir\u00b7cket", ",", "glau\u00b7ben", ",", "und", "nicht", "was", "wei"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["PDS", "ADJD", "APPRART", "NN", "VVFIN", "$,", "VVFIN", "$,", "KON", "PTKNEG", "PWS", "TRUNC"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.6": {"line.1": {"text": "Mir kommt es wenigstens so vor, es stimme mit des", "tokens": ["Mir", "kommt", "es", "we\u00b7nigs\u00b7tens", "so", "vor", ",", "es", "stim\u00b7me", "mit", "des"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ADV", "PTKVZ", "$,", "PPER", "VVFIN", "APPR", "ART"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Am allerbesten \u00fcberein, wenn alles, was wir k\u00fcnstlichs sehn,", "tokens": ["Am", "al\u00b7ler\u00b7bes\u00b7ten", "\u00fc\u00b7be\u00b7re\u00b7in", ",", "wenn", "al\u00b7les", ",", "was", "wir", "k\u00fcnst\u00b7lichs", "sehn", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "PTKVZ", "$,", "KOUS", "PIS", "$,", "PRELS", "PPER", "PIS", "VVINF", "$,"], "meter": "-+-+-+--+-+-+-+-+", "measure": "iambic.octa.plus.relaxed"}, "line.3": {"text": "Auch durch vern\u00fcnftige Gesch\u00f6pfe vern\u00fcnftig zugerichtet", "tokens": ["Auch", "durch", "ver\u00b7n\u00fcnf\u00b7ti\u00b7ge", "Ge\u00b7sch\u00f6p\u00b7fe", "ver\u00b7n\u00fcnf\u00b7tig", "zu\u00b7ge\u00b7rich\u00b7tet"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "ADJA", "NN", "ADJD", "VVPP"], "meter": "-+-+-+-+--+-+-+-", "measure": "iambic.septa.relaxed"}, "line.4": {"text": "Denn sollt\u2019 ein sch\u00f6nes Marmor-Bild, das lange doch so", "tokens": ["Denn", "sollt'", "ein", "sch\u00f6\u00b7nes", "Mar\u00b7mor\u00b7Bild", ",", "das", "lan\u00b7ge", "doch", "so"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VMFIN", "ART", "ADJA", "NN", "$,", "PRELS", "ADV", "ADV", "ADV"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wol von sich selbst entstehen k\u00f6nnen, wofern es nicht durch", "tokens": ["Wol", "von", "sich", "selbst", "ent\u00b7ste\u00b7hen", "k\u00f6n\u00b7nen", ",", "wo\u00b7fern", "es", "nicht", "durch"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "PRF", "ADV", "VVINF", "VMINF", "$,", "KOUS", "PPER", "PTKNEG", "APPR"], "meter": "+--+-+-+--+--+", "measure": "iambic.hexa.invert"}, "line.6": {"text": "Und, \u00fcm noch deutlicher zu reden, durch Menschen Kunst und", "tokens": ["Und", ",", "\u00fcm", "noch", "deut\u00b7li\u00b7cher", "zu", "re\u00b7den", ",", "durch", "Men\u00b7schen", "Kunst", "und"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "$,", "ADV", "ADV", "ADJD", "PTKZU", "VVINF", "$,", "APPR", "NN", "NN", "KON"], "meter": "-+-+---+--+-+-", "measure": "iambic.penta.relaxed"}, "line.7": {"text": "Nach Mass\u2019 und Schnur gehauen w\u00e4re, und nach der Regel", "tokens": ["Nach", "Mass'", "und", "Schnur", "ge\u00b7hau\u00b7en", "w\u00e4\u00b7re", ",", "und", "nach", "der", "Re\u00b7gel"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN", "VVPP", "VAFIN", "$,", "KON", "APPR", "ART", "NN"], "meter": "-+-+-+-++-+-+-", "measure": "unknown.measure.septa"}, "line.8": {"text": "Ich meine, nein! denn ob wir gleich an GOTTES Macht", "tokens": ["Ich", "mei\u00b7ne", ",", "nein", "!", "denn", "ob", "wir", "gleich", "an", "GoT\u00b7TES", "Macht"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "PTKANT", "$.", "KON", "KOUS", "PPER", "ADV", "APPR", "NE", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "So scheint es doch aus der Natur, GOtt habe so nicht wollen", "tokens": ["So", "scheint", "es", "doch", "aus", "der", "Na\u00b7tur", ",", "Gott", "ha\u00b7be", "so", "nicht", "wol\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPR", "ART", "NN", "$,", "NN", "VAFIN", "ADV", "PTKNEG", "VMFIN"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}}, "stanza.7": {"line.1": {"text": "Will einer noch hingegen sagen, da\u00df es der Finger", "tokens": ["Will", "ei\u00b7ner", "noch", "hin\u00b7ge\u00b7gen", "sa\u00b7gen", ",", "da\u00df", "es", "der", "Fin\u00b7ger"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VMFIN", "ART", "ADV", "ADV", "VVINF", "$,", "KOUS", "PPER", "ART", "NN"], "meter": "-+--+--+-+--+-", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Der alles das unmittelbar verrichte; so gesteh\u2019 ich frey,", "tokens": ["Der", "al\u00b7les", "das", "un\u00b7mit\u00b7tel\u00b7bar", "ver\u00b7rich\u00b7te", ";", "so", "ge\u00b7steh'", "ich", "frey", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "ART", "ADJD", "VVFIN", "$.", "ADV", "VVFIN", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+-+-+-+-+", "measure": "iambic.octa.plus"}, "line.3": {"text": "Es scheine mir die erste Meinung von GOTTES Weisheit,", "tokens": ["Es", "schei\u00b7ne", "mir", "die", "ers\u00b7te", "Mei\u00b7nung", "von", "GoT\u00b7TES", "Weis\u00b7heit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ART", "ADJA", "NN", "APPR", "NE", "NN", "$,"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Geschickter, w\u00fcrdiger, erhabner, und ", "tokens": ["Ge\u00b7schick\u00b7ter", ",", "w\u00fcr\u00b7di\u00b7ger", ",", "er\u00b7hab\u00b7ner", ",", "und"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word"], "pos": ["NN", "$,", "ADJD", "$,", "ADJA", "$,", "KON"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Denn, ausser, da\u00df ich in den Worten, und in der wircklichen", "tokens": ["Denn", ",", "aus\u00b7ser", ",", "da\u00df", "ich", "in", "den", "Wor\u00b7ten", ",", "und", "in", "der", "wir\u00b7ck\u00b7li\u00b7chen"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "$,", "ADJD", "$,", "KOUS", "PPER", "APPR", "ART", "NN", "$,", "KON", "APPR", "ART", "ADJA"], "meter": "-+-+++-+--+-++--", "measure": "iambic.octa.plus.relaxed"}, "line.6": {"text": "Vom Finger GOttes, was verbl\u00fchmtes, und nicht was ei-", "tokens": ["Vom", "Fin\u00b7ger", "Got\u00b7tes", ",", "was", "ver\u00b7bl\u00fchm\u00b7tes", ",", "und", "nicht", "was", "ei"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "NN", "$,", "PWS", "ADJA", "$,", "KON", "PTKNEG", "PWS", "TRUNC"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.7": {"text": "So deucht mich, da\u00df dergleichen Wercke durch Seine Die-", "tokens": ["So", "deucht", "mich", ",", "da\u00df", "derg\u00b7lei\u00b7chen", "Wer\u00b7cke", "durch", "Sei\u00b7ne", "Die"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "$,", "KOUS", "PIS", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.8": {"text": "Sey einer Gottheit w\u00fcrdiger, als Selbst damit sich zu be-", "tokens": ["Sey", "ei\u00b7ner", "Got\u00b7theit", "w\u00fcr\u00b7di\u00b7ger", ",", "als", "Selbst", "da\u00b7mit", "sich", "zu", "be"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ART", "NN", "ADJD", "$,", "KOUS", "ADV", "KOUS", "PRF", "APPR", "TRUNC"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}}, "stanza.8": {"line.1": {"text": "Vermindert es ja doch die Ehre des Sch\u00f6pfers im ge-", "tokens": ["Ver\u00b7min\u00b7dert", "es", "ja", "doch", "die", "Eh\u00b7re", "des", "Sch\u00f6p\u00b7fers", "im", "ge"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "ART", "NN", "ART", "NN", "APPRART", "TRUNC"], "meter": "-+--+--+--+--+", "measure": "amphibrach.penta.plus"}, "line.2": {"text": "Wenn so viel k\u00fcnstliches auf Erden durch Menschen-Witz", "tokens": ["Wenn", "so", "viel", "k\u00fcnst\u00b7li\u00b7ches", "auf", "Er\u00b7den", "durch", "Men\u00b7schen\u00b7Witz"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "PIAT", "ADJA", "APPR", "NN", "APPR", "NN"], "meter": "+--+-+-+--+-+", "measure": "iambic.hexa.invert"}, "line.3": {"text": "Sonst k\u00f6n\u0303te ja der Sch\u00f6pfer auch, als Dem es nicht an Macht", "tokens": ["Sonst", "k\u00f6\u00f1te", "ja", "der", "Sch\u00f6p\u00b7fer", "auch", ",", "als", "Dem", "es", "nicht", "an", "Macht"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ADV", "ART", "NN", "ADV", "$,", "KOUS", "ART", "PPER", "PTKNEG", "APPR", "NN"], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Aus Holtz und Stein formirte Bilder, Geb\u00e4ude, G\u00e4rten,", "tokens": ["Aus", "Holtz", "und", "Stein", "for\u00b7mir\u00b7te", "Bil\u00b7der", ",", "Ge\u00b7b\u00e4u\u00b7de", ",", "G\u00e4r\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "ADJA", "NN", "$,", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "Auch Gl\u00e4ser, Haus-Ger\u00e4the, Schr\u00e4ncke, Gem\u00e4hlde, Fenster-", "tokens": ["Auch", "Gl\u00e4\u00b7ser", ",", "Haus\u00b7Ge\u00b7r\u00e4\u00b7the", ",", "Schr\u00e4n\u00b7cke", ",", "Ge\u00b7m\u00e4hl\u00b7de", ",", "Fens\u00b7ter"], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word"], "pos": ["ADV", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,", "TRUNC"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "Ohn unsern Beytritt, wachsen lassen. Wir sehen aber auf", "tokens": ["Ohn", "un\u00b7sern", "Bey\u00b7tritt", ",", "wach\u00b7sen", "las\u00b7sen", ".", "Wir", "se\u00b7hen", "a\u00b7ber", "auf"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "$,", "VVINF", "VVINF", "$.", "PPER", "VVFIN", "ADV", "APPR"], "meter": "-+-+-+-+--+-+-+", "measure": "iambic.septa.relaxed"}, "line.7": {"text": "Da\u00df es Jhm, unser sich dabey auch zu gebrauchen, nicht mi\u00df-", "tokens": ["Da\u00df", "es", "Jhm", ",", "un\u00b7ser", "sich", "da\u00b7bey", "auch", "zu", "ge\u00b7brau\u00b7chen", ",", "nicht", "mi\u00df"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KOUS", "PPER", "PPER", "$,", "PPOSAT", "PRF", "PAV", "ADV", "PTKZU", "VVINF", "$,", "PTKNEG", "TRUNC"], "meter": "-+-+-+-+-+-+--+", "measure": "iambic.septa.chol"}}, "stanza.9": {"line.1": {"text": "Und wie so sehr w\u00fcrd\u2019 einer nicht in seiner Meinung", "tokens": ["Und", "wie", "so", "sehr", "w\u00fcrd'", "ei\u00b7ner", "nicht", "in", "sei\u00b7ner", "Mei\u00b7nung"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "ADV", "ADV", "VAFIN", "ART", "PTKNEG", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der, weil er etwan solche Dinge von Menschen niemahls", "tokens": ["Der", ",", "weil", "er", "et\u00b7wan", "sol\u00b7che", "Din\u00b7ge", "von", "Men\u00b7schen", "nie\u00b7mahls"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "$,", "KOUS", "PPER", "ADV", "PIAT", "NN", "APPR", "NN", "ADV"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Da\u00df sie gewachsen w\u00e4ren, glaubte? dar\u00fcm ist dieses auch", "tokens": ["Da\u00df", "sie", "ge\u00b7wach\u00b7sen", "w\u00e4\u00b7ren", ",", "glaub\u00b7te", "?", "da\u00b7r\u00fcm", "ist", "die\u00b7ses", "auch"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "VVPP", "VAFIN", "$,", "VVFIN", "$.", "PAV", "VAFIN", "PDS", "ADV"], "meter": "-+-+-+-+--+-+-+", "measure": "iambic.septa.relaxed"}, "line.4": {"text": "Noch lange nicht so ungereimt, als wie es etwa manchem", "tokens": ["Noch", "lan\u00b7ge", "nicht", "so", "un\u00b7ge\u00b7reimt", ",", "als", "wie", "es", "et\u00b7wa", "man\u00b7chem"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "PTKNEG", "ADV", "ADJD", "$,", "KOUS", "PWAV", "PPER", "ADV", "PIAT"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}}, "stanza.10": {"line.1": {"text": "Jedoch, da unser Wissen hier nur St\u00fcck-Werck; soll", "tokens": ["Je\u00b7doch", ",", "da", "un\u00b7ser", "Wis\u00b7sen", "hier", "nur", "St\u00fc\u00b7ck\u00b7\u00b7Werck", ";", "soll"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["ADV", "$,", "KOUS", "PPOSAT", "NN", "ADV", "ADV", "NN", "$.", "VMFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Dem, der mir bessre Gr\u00fcnde bringt, nicht widersinnig wie-", "tokens": ["Dem", ",", "der", "mir", "bess\u00b7re", "Gr\u00fcn\u00b7de", "bringt", ",", "nicht", "wi\u00b7der\u00b7sin\u00b7nig", "wie"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PDS", "$,", "PRELS", "PPER", "ADJA", "NN", "VVFIN", "$,", "PTKNEG", "ADJD", "TRUNC"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.3": {"text": "La\u00df dir zugleich, geliebter Leser, was wir von solchen Gei-", "tokens": ["La\u00df", "dir", "zu\u00b7gleich", ",", "ge\u00b7lieb\u00b7ter", "Le\u00b7ser", ",", "was", "wir", "von", "sol\u00b7chen", "Gei"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVIMP", "PPER", "ADV", "$,", "ADJA", "NN", "$,", "PRELS", "PPER", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+--+-+-+", "measure": "iambic.septa.relaxed"}, "line.4": {"text": "Nicht eine neuerliche Lehre, nicht fremd und nicht gef\u00e4hrlich", "tokens": ["Nicht", "ei\u00b7ne", "neu\u00b7er\u00b7li\u00b7che", "Leh\u00b7re", ",", "nicht", "fremd", "und", "nicht", "ge\u00b7f\u00e4hr\u00b7lich"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PTKNEG", "ART", "ADJA", "NN", "$,", "PTKNEG", "ADJD", "KON", "PTKNEG", "ADJD"], "meter": "-+-+-+-+--+-+-+-", "measure": "iambic.septa.relaxed"}, "line.5": {"text": "Vielleicht sind wir nicht unterschieden, vielleicht ist es fast", "tokens": ["Viel\u00b7leicht", "sind", "wir", "nicht", "un\u00b7ter\u00b7schie\u00b7den", ",", "viel\u00b7leicht", "ist", "es", "fast"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "PTKNEG", "VVINF", "$,", "ADV", "VAFIN", "PPER", "ADV"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.6": {"text": "Ob, was ich Geister nenne, kr\u00e4fftig; ob, was du Krafft heist,", "tokens": ["Ob", ",", "was", "ich", "Geis\u00b7ter", "nen\u00b7ne", ",", "kr\u00e4ff\u00b7tig", ";", "ob", ",", "was", "du", "Krafft", "heist", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$,", "PWS", "PPER", "NN", "VVFIN", "$,", "ADJD", "$.", "KOUS", "$,", "PWS", "PPER", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.7": {"text": "Denn wir begreiffen ja so wenig, was eigentlich dergleichen", "tokens": ["Denn", "wir", "be\u00b7greif\u00b7fen", "ja", "so", "we\u00b7nig", ",", "was", "ei\u00b7gent\u00b7lich", "derg\u00b7lei\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "ADV", "ADV", "PIS", "$,", "PRELS", "ADV", "PIS"], "meter": "-+-+-+-+--+-+-+-", "measure": "iambic.septa.relaxed"}, "line.8": {"text": "Als was von Geistern, welche bilden, recht eigentlich die Ei-", "tokens": ["Als", "was", "von", "Geis\u00b7tern", ",", "wel\u00b7che", "bil\u00b7den", ",", "recht", "ei\u00b7gent\u00b7lich", "die", "Ei"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "APPR", "NN", "$,", "PRELS", "VVINF", "$,", "ADV", "ADV", "ART", "TRUNC"], "meter": "-+-+-+-+---+--+", "measure": "iambic.hexa.chol"}}, "stanza.11": {"line.1": {"text": "Genug iedoch, wenn wir hiedurch von der Gewohnheit", "tokens": ["Ge\u00b7nug", "ie\u00b7doch", ",", "wenn", "wir", "hie\u00b7durch", "von", "der", "Ge\u00b7wohn\u00b7heit"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "$,", "KOUS", "PPER", "PAV", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und GOttes k\u00fcnstliche Gesch\u00f6pfe mehr achten und bewun-", "tokens": ["Und", "Got\u00b7tes", "k\u00fcnst\u00b7li\u00b7che", "Ge\u00b7sch\u00f6p\u00b7fe", "mehr", "ach\u00b7ten", "und", "be\u00b7wun"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "NN", "ADJA", "NN", "ADV", "VVINF", "KON", "TRUNC"], "meter": "-+-+-+-+--+-+-+", "measure": "iambic.septa.relaxed"}, "line.3": {"text": "Die\u00df ist mein Endzweck hier gewesen, erbaue dich nebst mir", "tokens": ["Die\u00df", "ist", "mein", "End\u00b7zweck", "hier", "ge\u00b7we\u00b7sen", ",", "er\u00b7bau\u00b7e", "dich", "nebst", "mir"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "PPOSAT", "NN", "ADV", "VAPP", "$,", "VVFIN", "PRF", "APPR", "PPER"], "meter": "-+-+-+-+--+-+-+", "measure": "iambic.septa.relaxed"}, "line.4": {"text": "Da\u00df uns zur Demuth und zur Andacht so gar ein Lamms-", "tokens": ["Da\u00df", "uns", "zur", "De\u00b7muth", "und", "zur", "An\u00b7dacht", "so", "gar", "ein", "Lamms"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPRART", "NN", "KON", "APPRART", "NN", "ADV", "ADV", "ART", "TRUNC"], "meter": "-+--+--+--+-+", "measure": "amphibrach.tetra.plus"}}}}}