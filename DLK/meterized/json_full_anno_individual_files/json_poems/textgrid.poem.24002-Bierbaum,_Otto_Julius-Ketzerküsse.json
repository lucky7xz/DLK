{"textgrid.poem.24002": {"metadata": {"author": {"name": "Bierbaum, Otto Julius", "birth": "N.A.", "death": "N.A."}, "title": "Ketzerk\u00fcsse", "genre": "verse", "period": "N.A.", "pub_year": 1887, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Gr\u00fcn deine Federn am Hut, mein Kind,", "tokens": ["Gr\u00fcn", "dei\u00b7ne", "Fe\u00b7dern", "am", "Hut", ",", "mein", "Kind", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "APPRART", "NN", "$,", "PPOSAT", "NN", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.2": {"text": "Blau deine Augen im Kopfe sind:", "tokens": ["Blau", "dei\u00b7ne", "Au\u00b7gen", "im", "Kop\u00b7fe", "sind", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "APPRART", "NN", "VAFIN", "$."], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.3": {"text": "Wie kannst du so was wagen!?", "tokens": ["Wie", "kannst", "du", "so", "was", "wa\u00b7gen", "!?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "PPER", "ADV", "PIS", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Gr\u00fcn pa\u00dft nicht zu blau,", "tokens": ["Gr\u00fcn", "pa\u00dft", "nicht", "zu", "blau", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PTKNEG", "PTKA", "ADJD", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.5": {"text": "Wird dir prompt und genau", "tokens": ["Wird", "dir", "prompt", "und", "ge\u00b7nau"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "VVFIN", "KON", "ADJD"], "meter": "--+--+", "measure": "anapaest.di.plus"}, "line.6": {"text": "Ein jeder Professor sagen.", "tokens": ["Ein", "je\u00b7der", "Pro\u00b7fes\u00b7sor", "sa\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VVINF", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.2": {"line.1": {"text": "Was? Dir ist das ganz einerlei?", "tokens": ["Was", "?", "Dir", "ist", "das", "ganz", "ei\u00b7ner\u00b7lei", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "$.", "PPER", "VAFIN", "ART", "ADV", "PIS", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Du sagst, da\u00df es dir \u2013 schnuppe sei,", "tokens": ["Du", "sagst", ",", "da\u00df", "es", "dir", "\u2013", "schnup\u00b7pe", "sei", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "PPER", "PPER", "$(", "VVFIN", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Was Professoren sagen?", "tokens": ["Was", "Pro\u00b7fes\u00b7so\u00b7ren", "sa\u00b7gen", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["PWS", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Mein Kind, mein Kind, dein Sinn ist schlimm", "tokens": ["Mein", "Kind", ",", "mein", "Kind", ",", "dein", "Sinn", "ist", "schlimm"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "$,", "PPOSAT", "NN", "$,", "PPOSAT", "NN", "VAFIN", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ich aber will ad interim", "tokens": ["Ich", "a\u00b7ber", "will", "ad", "in\u00b7te\u00b7rim"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "VMFIN", "FM", "FM"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Es dennoch mit dir wagen.", "tokens": ["Es", "den\u00b7noch", "mit", "dir", "wa\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "APPR", "PPER", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Verwegen zwar, ich f\u00fchl es, ist", "tokens": ["Ver\u00b7we\u00b7gen", "zwar", ",", "ich", "f\u00fchl", "es", ",", "ist"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["NN", "ADV", "$,", "PPER", "VVFIN", "PPER", "$,", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mein Thun, doch wenn du gn\u00e4dig bist,", "tokens": ["Mein", "Thun", ",", "doch", "wenn", "du", "gn\u00e4\u00b7dig", "bist", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "ADV", "KOUS", "PPER", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wird mirs zum Heil ausschlagen.", "tokens": ["Wird", "mirs", "zum", "Heil", "aus\u00b7schla\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NE", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Komm, gieb mir deinen roten Mund", "tokens": ["Komm", ",", "gieb", "mir", "dei\u00b7nen", "ro\u00b7ten", "Mund"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "$,", "VVIMP", "PPER", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und la\u00df uns k\u00fcssen und lachen und", "tokens": ["Und", "la\u00df", "uns", "k\u00fcs\u00b7sen", "und", "la\u00b7chen", "und"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVIMP", "PPER", "VVINF", "KON", "VVINF", "KON"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Kein' Menschen darum fragen.", "tokens": ["Kein'", "Men\u00b7schen", "da\u00b7rum", "fra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "PAV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Gr\u00fcn deine Federn am Hut, mein Kind,", "tokens": ["Gr\u00fcn", "dei\u00b7ne", "Fe\u00b7dern", "am", "Hut", ",", "mein", "Kind", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "APPRART", "NN", "$,", "PPOSAT", "NN", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.2": {"text": "Blau deine Augen im Kopfe sind:", "tokens": ["Blau", "dei\u00b7ne", "Au\u00b7gen", "im", "Kop\u00b7fe", "sind", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "APPRART", "NN", "VAFIN", "$."], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.3": {"text": "Wie kannst du so was wagen!?", "tokens": ["Wie", "kannst", "du", "so", "was", "wa\u00b7gen", "!?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "PPER", "ADV", "PIS", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Gr\u00fcn pa\u00dft nicht zu blau,", "tokens": ["Gr\u00fcn", "pa\u00dft", "nicht", "zu", "blau", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PTKNEG", "PTKA", "ADJD", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.5": {"text": "Wird dir prompt und genau", "tokens": ["Wird", "dir", "prompt", "und", "ge\u00b7nau"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "VVFIN", "KON", "ADJD"], "meter": "--+--+", "measure": "anapaest.di.plus"}, "line.6": {"text": "Ein jeder Professor sagen.", "tokens": ["Ein", "je\u00b7der", "Pro\u00b7fes\u00b7sor", "sa\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VVINF", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.6": {"line.1": {"text": "Was? Dir ist das ganz einerlei?", "tokens": ["Was", "?", "Dir", "ist", "das", "ganz", "ei\u00b7ner\u00b7lei", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "$.", "PPER", "VAFIN", "ART", "ADV", "PIS", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Du sagst, da\u00df es dir \u2013 schnuppe sei,", "tokens": ["Du", "sagst", ",", "da\u00df", "es", "dir", "\u2013", "schnup\u00b7pe", "sei", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "PPER", "PPER", "$(", "VVFIN", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Was Professoren sagen?", "tokens": ["Was", "Pro\u00b7fes\u00b7so\u00b7ren", "sa\u00b7gen", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["PWS", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Mein Kind, mein Kind, dein Sinn ist schlimm", "tokens": ["Mein", "Kind", ",", "mein", "Kind", ",", "dein", "Sinn", "ist", "schlimm"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "$,", "PPOSAT", "NN", "$,", "PPOSAT", "NN", "VAFIN", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ich aber will ad interim", "tokens": ["Ich", "a\u00b7ber", "will", "ad", "in\u00b7te\u00b7rim"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "VMFIN", "FM", "FM"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Es dennoch mit dir wagen.", "tokens": ["Es", "den\u00b7noch", "mit", "dir", "wa\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "APPR", "PPER", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Verwegen zwar, ich f\u00fchl es, ist", "tokens": ["Ver\u00b7we\u00b7gen", "zwar", ",", "ich", "f\u00fchl", "es", ",", "ist"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["NN", "ADV", "$,", "PPER", "VVFIN", "PPER", "$,", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mein Thun, doch wenn du gn\u00e4dig bist,", "tokens": ["Mein", "Thun", ",", "doch", "wenn", "du", "gn\u00e4\u00b7dig", "bist", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "ADV", "KOUS", "PPER", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wird mirs zum Heil ausschlagen.", "tokens": ["Wird", "mirs", "zum", "Heil", "aus\u00b7schla\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NE", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Komm, gieb mir deinen roten Mund", "tokens": ["Komm", ",", "gieb", "mir", "dei\u00b7nen", "ro\u00b7ten", "Mund"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "$,", "VVIMP", "PPER", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und la\u00df uns k\u00fcssen und lachen und", "tokens": ["Und", "la\u00df", "uns", "k\u00fcs\u00b7sen", "und", "la\u00b7chen", "und"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVIMP", "PPER", "VVINF", "KON", "VVINF", "KON"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Kein' Menschen darum fragen.", "tokens": ["Kein'", "Men\u00b7schen", "da\u00b7rum", "fra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "PAV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}}}}