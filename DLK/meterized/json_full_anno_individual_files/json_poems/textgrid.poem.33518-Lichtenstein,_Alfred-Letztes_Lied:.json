{"textgrid.poem.33518": {"metadata": {"author": {"name": "Lichtenstein, Alfred", "birth": "N.A.", "death": "N.A."}, "title": "Letztes Lied:", "genre": "verse", "period": "N.A.", "pub_year": 1902, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Komm nur, mein Regen ... fall mir ins Gesicht \u2013", "tokens": ["Komm", "nur", ",", "mein", "Re\u00b7gen", "...", "fall", "mir", "ins", "Ge\u00b7sicht", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "$,", "PPOSAT", "NN", "$(", "NN", "PPER", "APPRART", "NN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Gelbe Laternen ... werft die H\u00e4user um \u2013", "tokens": ["Gel\u00b7be", "La\u00b7ter\u00b7nen", "...", "werft", "die", "H\u00e4u\u00b7ser", "um", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$(", "VVFIN", "ART", "NN", "APPR", "$("], "meter": "+----+-+-+", "measure": "dactylic.init"}, "line.3": {"text": "Heile und glatte Wege will ich nicht.", "tokens": ["Hei\u00b7le", "und", "glat\u00b7te", "We\u00b7ge", "will", "ich", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "ADJA", "NN", "VMFIN", "PPER", "PTKNEG", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}}, "stanza.2": {"line.1": {"text": "So ist es sch\u00f6n ... nur im Laternenschein ...", "tokens": ["So", "ist", "es", "sch\u00f6n", "...", "nur", "im", "La\u00b7ter\u00b7nen\u00b7schein", "..."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "$(", "ADV", "APPRART", "NN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Maria ... dunkler Regen ringsherum \u2013", "tokens": ["Ma\u00b7ria", "...", "dunk\u00b7ler", "Re\u00b7gen", "rings\u00b7he\u00b7rum", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$(", "ADJA", "NN", "ADV", "$("], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "So geht sichs gut. Ich m\u00f6chte bei dir sein.", "tokens": ["So", "geht", "sichs", "gut", ".", "Ich", "m\u00f6ch\u00b7te", "bei", "dir", "sein", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "ADJD", "$.", "PPER", "VMFIN", "APPR", "PPER", "VAINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Was sind mir Berge und das flache Land \u2013", "tokens": ["Was", "sind", "mir", "Ber\u00b7ge", "und", "das", "fla\u00b7che", "Land", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "NN", "KON", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Was St\u00e4dte mir und bunter Nacht Hypnose \u2013", "tokens": ["Was", "St\u00e4d\u00b7te", "mir", "und", "bun\u00b7ter", "Nacht", "Hyp\u00b7no\u00b7se", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "PPER", "KON", "ADJD", "NN", "NE", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Zur\u00fcck zum Meer ... Zur\u00fcck zum Sternenstrand.", "tokens": ["Zu\u00b7r\u00fcck", "zum", "Meer", "...", "Zu\u00b7r\u00fcck", "zum", "Ster\u00b7nen\u00b7strand", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "$(", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Du bist nicht ganz Maria, die ich suchte.", "tokens": ["Du", "bist", "nicht", "ganz", "Ma\u00b7ria", ",", "die", "ich", "such\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKNEG", "ADV", "NE", "$,", "PRELS", "PPER", "VVFIN", "$."], "meter": "+---+-+-+-", "measure": "dactylic.init"}, "line.2": {"text": "Doch bist auch du Maria \u2013 Grenzenlose ...", "tokens": ["Doch", "bist", "auch", "du", "Ma\u00b7ria", "\u2013", "Gren\u00b7zen\u00b7lo\u00b7se", "..."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "NE", "NE", "$(", "NE", "$("], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Geliebte ... T\u00f6rin ... sehns\u00fcchtig Verfluchte ...", "tokens": ["Ge\u00b7lieb\u00b7te", "...", "T\u00f6\u00b7rin", "...", "sehn\u00b7s\u00fcch\u00b7tig", "Ver\u00b7fluch\u00b7te", "..."], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$(", "NN", "$(", "ADJD", "NN", "$("], "meter": "-+-+-+---+-", "measure": "unknown.measure.tetra"}}, "stanza.5": {"line.1": {"text": "Komm nur, mein Regen ... fall mir ins Gesicht \u2013", "tokens": ["Komm", "nur", ",", "mein", "Re\u00b7gen", "...", "fall", "mir", "ins", "Ge\u00b7sicht", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "$,", "PPOSAT", "NN", "$(", "NN", "PPER", "APPRART", "NN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Gelbe Laternen ... werft die H\u00e4user um \u2013", "tokens": ["Gel\u00b7be", "La\u00b7ter\u00b7nen", "...", "werft", "die", "H\u00e4u\u00b7ser", "um", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$(", "VVFIN", "ART", "NN", "APPR", "$("], "meter": "+----+-+-+", "measure": "dactylic.init"}, "line.3": {"text": "Heile und glatte Wege will ich nicht.", "tokens": ["Hei\u00b7le", "und", "glat\u00b7te", "We\u00b7ge", "will", "ich", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "ADJA", "NN", "VMFIN", "PPER", "PTKNEG", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}}, "stanza.6": {"line.1": {"text": "So ist es sch\u00f6n ... nur im Laternenschein ...", "tokens": ["So", "ist", "es", "sch\u00f6n", "...", "nur", "im", "La\u00b7ter\u00b7nen\u00b7schein", "..."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "$(", "ADV", "APPRART", "NN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Maria ... dunkler Regen ringsherum \u2013", "tokens": ["Ma\u00b7ria", "...", "dunk\u00b7ler", "Re\u00b7gen", "rings\u00b7he\u00b7rum", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$(", "ADJA", "NN", "ADV", "$("], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "So geht sichs gut. Ich m\u00f6chte bei dir sein.", "tokens": ["So", "geht", "sichs", "gut", ".", "Ich", "m\u00f6ch\u00b7te", "bei", "dir", "sein", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "ADJD", "$.", "PPER", "VMFIN", "APPR", "PPER", "VAINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.7": {"line.1": {"text": "Was sind mir Berge und das flache Land \u2013", "tokens": ["Was", "sind", "mir", "Ber\u00b7ge", "und", "das", "fla\u00b7che", "Land", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "NN", "KON", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Was St\u00e4dte mir und bunter Nacht Hypnose \u2013", "tokens": ["Was", "St\u00e4d\u00b7te", "mir", "und", "bun\u00b7ter", "Nacht", "Hyp\u00b7no\u00b7se", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "PPER", "KON", "ADJD", "NN", "NE", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Zur\u00fcck zum Meer ... Zur\u00fcck zum Sternenstrand.", "tokens": ["Zu\u00b7r\u00fcck", "zum", "Meer", "...", "Zu\u00b7r\u00fcck", "zum", "Ster\u00b7nen\u00b7strand", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "$(", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.8": {"line.1": {"text": "Du bist nicht ganz Maria, die ich suchte.", "tokens": ["Du", "bist", "nicht", "ganz", "Ma\u00b7ria", ",", "die", "ich", "such\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKNEG", "ADV", "NE", "$,", "PRELS", "PPER", "VVFIN", "$."], "meter": "+---+-+-+-", "measure": "dactylic.init"}, "line.2": {"text": "Doch bist auch du Maria \u2013 Grenzenlose ...", "tokens": ["Doch", "bist", "auch", "du", "Ma\u00b7ria", "\u2013", "Gren\u00b7zen\u00b7lo\u00b7se", "..."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "NE", "NE", "$(", "NE", "$("], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Geliebte ... T\u00f6rin ... sehns\u00fcchtig Verfluchte ...", "tokens": ["Ge\u00b7lieb\u00b7te", "...", "T\u00f6\u00b7rin", "...", "sehn\u00b7s\u00fcch\u00b7tig", "Ver\u00b7fluch\u00b7te", "..."], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$(", "NN", "$(", "ADJD", "NN", "$("], "meter": "-+-+-+---+-", "measure": "unknown.measure.tetra"}}}}}