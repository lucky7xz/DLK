{"textgrid.poem.48550": {"metadata": {"author": {"name": "Fleming, Paul", "birth": "N.A.", "death": "N.A."}, "title": "8. Tugend ist mein Leben", "genre": "verse", "period": "N.A.", "pub_year": 1624, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Tugend ist mein Leben,", "tokens": ["Tu\u00b7gend", "ist", "mein", "Le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "der hab' ich ergeben", "tokens": ["der", "hab'", "ich", "er\u00b7ge\u00b7ben"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "VAFIN", "PPER", "VVPP"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "den ganzen Mich.", "tokens": ["den", "gan\u00b7zen", "Mich", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "PPER", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.4": {"text": "Tugend will ich ehren,", "tokens": ["Tu\u00b7gend", "will", "ich", "eh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "PPER", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.5": {"text": "Tugend wird mich lehren,", "tokens": ["Tu\u00b7gend", "wird", "mich", "leh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.6": {"text": "was sie selbst kan mehren:", "tokens": ["was", "sie", "selbst", "kan", "meh\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "VMFIN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.7": {"text": "sie w\u00e4chst durch sich.", "tokens": ["sie", "w\u00e4chst", "durch", "sich", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PRF", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.2": {"line.1": {"text": "Nicht des Weges L\u00e4nge,", "tokens": ["Nicht", "des", "We\u00b7ges", "L\u00e4n\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ART", "NN", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "noch des Pfades Enge", "tokens": ["noch", "des", "Pfa\u00b7des", "En\u00b7ge"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "schreckt mich davon.", "tokens": ["schreckt", "mich", "da\u00b7von", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "PAV", "$."], "meter": "+--+", "measure": "iambic.di.chol"}, "line.4": {"text": "La\u00df die Dornen stechen,", "tokens": ["La\u00df", "die", "Dor\u00b7nen", "ste\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.5": {"text": "F\u00fc\u00df' und Kleider brechen,", "tokens": ["F\u00fc\u00df'", "und", "Klei\u00b7der", "bre\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.6": {"text": "sie wird Alles r\u00e4chen", "tokens": ["sie", "wird", "Al\u00b7les", "r\u00e4\u00b7chen"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PIS", "VVINF"], "meter": "--+-+-", "measure": "anapaest.init"}, "line.7": {"text": "durch ihren Lohn.", "tokens": ["durch", "ih\u00b7ren", "Lohn", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.3": {"line.1": {"text": "Weil die Andern karten,", "tokens": ["Weil", "die", "An\u00b7dern", "kar\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Lust und Schlafes warten,", "tokens": ["Lust", "und", "Schla\u00b7fes", "war\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "so s\u00e4um' ich nicht.", "tokens": ["so", "s\u00e4um'", "ich", "nicht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.4": {"text": "Itzt ist Zeit zu eilen;", "tokens": ["Itzt", "ist", "Zeit", "zu", "ei\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "NN", "PTKZU", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.5": {"text": "dem wird alles feilen,", "tokens": ["dem", "wird", "al\u00b7les", "fei\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PIS", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.6": {"text": "der sich wird verweilen", "tokens": ["der", "sich", "wird", "ver\u00b7wei\u00b7len"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "PRF", "VAFIN", "VVINF"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.7": {"text": "und itzt verbricht.", "tokens": ["und", "itzt", "ver\u00b7bricht", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVPP", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.4": {"line.1": {"text": "Alles Ander', alles", "tokens": ["Al\u00b7les", "An\u00b7der'", ",", "al\u00b7les"], "token_info": ["word", "word", "punct", "word"], "pos": ["PIAT", "NN", "$,", "PIS"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "hat die Art des Palles,", "tokens": ["hat", "die", "Art", "des", "Pal\u00b7les", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "der steigt und f\u00e4llt.", "tokens": ["der", "steigt", "und", "f\u00e4llt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.4": {"text": "Sch\u00e4tze haben Fl\u00fcgel,", "tokens": ["Sch\u00e4t\u00b7ze", "ha\u00b7ben", "Fl\u00fc\u00b7gel", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.5": {"text": "Ehre l\u00e4\u00dft den Z\u00fcgel,", "tokens": ["Eh\u00b7re", "l\u00e4\u00dft", "den", "Z\u00fc\u00b7gel", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.6": {"text": "Lust kommt aus dem B\u00fcgel:", "tokens": ["Lust", "kommt", "aus", "dem", "B\u00fc\u00b7gel", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.7": {"text": "die Tugend h\u00e4lt.", "tokens": ["die", "Tu\u00b7gend", "h\u00e4lt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.5": {"line.1": {"text": "Hab' ich Gott und Tugend,", "tokens": ["Hab'", "ich", "Gott", "und", "Tu\u00b7gend", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "NN", "KON", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "so hat meine Jugend,", "tokens": ["so", "hat", "mei\u00b7ne", "Ju\u00b7gend", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "was sie macht wert.", "tokens": ["was", "sie", "macht", "wert", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVFIN", "ADJD", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.4": {"text": "Diese sch\u00f6nen Beide", "tokens": ["Die\u00b7se", "sch\u00f6\u00b7nen", "Bei\u00b7de"], "token_info": ["word", "word", "word"], "pos": ["PDAT", "ADJA", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.5": {"text": "wehren allem Leide,", "tokens": ["weh\u00b7ren", "al\u00b7lem", "Lei\u00b7de", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.6": {"text": "lieben alle Freude,", "tokens": ["lie\u00b7ben", "al\u00b7le", "Freu\u00b7de", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.7": {"text": "so man begehrt.", "tokens": ["so", "man", "be\u00b7gehrt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "PIS", "VVPP", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.6": {"line.1": {"text": "Tugend ist mein Leben,", "tokens": ["Tu\u00b7gend", "ist", "mein", "Le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "der hab' ich ergeben", "tokens": ["der", "hab'", "ich", "er\u00b7ge\u00b7ben"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "VAFIN", "PPER", "VVPP"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "den ganzen Mich.", "tokens": ["den", "gan\u00b7zen", "Mich", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "PPER", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.4": {"text": "Tugend will ich ehren,", "tokens": ["Tu\u00b7gend", "will", "ich", "eh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "PPER", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.5": {"text": "Tugend wird mich lehren,", "tokens": ["Tu\u00b7gend", "wird", "mich", "leh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.6": {"text": "was sie selbst kan mehren:", "tokens": ["was", "sie", "selbst", "kan", "meh\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "VMFIN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.7": {"text": "sie w\u00e4chst durch sich.", "tokens": ["sie", "w\u00e4chst", "durch", "sich", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PRF", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.7": {"line.1": {"text": "Nicht des Weges L\u00e4nge,", "tokens": ["Nicht", "des", "We\u00b7ges", "L\u00e4n\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ART", "NN", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "noch des Pfades Enge", "tokens": ["noch", "des", "Pfa\u00b7des", "En\u00b7ge"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "schreckt mich davon.", "tokens": ["schreckt", "mich", "da\u00b7von", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "PAV", "$."], "meter": "+--+", "measure": "iambic.di.chol"}, "line.4": {"text": "La\u00df die Dornen stechen,", "tokens": ["La\u00df", "die", "Dor\u00b7nen", "ste\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.5": {"text": "F\u00fc\u00df' und Kleider brechen,", "tokens": ["F\u00fc\u00df'", "und", "Klei\u00b7der", "bre\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.6": {"text": "sie wird Alles r\u00e4chen", "tokens": ["sie", "wird", "Al\u00b7les", "r\u00e4\u00b7chen"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PIS", "VVINF"], "meter": "--+-+-", "measure": "anapaest.init"}, "line.7": {"text": "durch ihren Lohn.", "tokens": ["durch", "ih\u00b7ren", "Lohn", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.8": {"line.1": {"text": "Weil die Andern karten,", "tokens": ["Weil", "die", "An\u00b7dern", "kar\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Lust und Schlafes warten,", "tokens": ["Lust", "und", "Schla\u00b7fes", "war\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "so s\u00e4um' ich nicht.", "tokens": ["so", "s\u00e4um'", "ich", "nicht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.4": {"text": "Itzt ist Zeit zu eilen;", "tokens": ["Itzt", "ist", "Zeit", "zu", "ei\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "NN", "PTKZU", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.5": {"text": "dem wird alles feilen,", "tokens": ["dem", "wird", "al\u00b7les", "fei\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PIS", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.6": {"text": "der sich wird verweilen", "tokens": ["der", "sich", "wird", "ver\u00b7wei\u00b7len"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "PRF", "VAFIN", "VVINF"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.7": {"text": "und itzt verbricht.", "tokens": ["und", "itzt", "ver\u00b7bricht", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVPP", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.9": {"line.1": {"text": "Alles Ander', alles", "tokens": ["Al\u00b7les", "An\u00b7der'", ",", "al\u00b7les"], "token_info": ["word", "word", "punct", "word"], "pos": ["PIAT", "NN", "$,", "PIS"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "hat die Art des Palles,", "tokens": ["hat", "die", "Art", "des", "Pal\u00b7les", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "der steigt und f\u00e4llt.", "tokens": ["der", "steigt", "und", "f\u00e4llt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.4": {"text": "Sch\u00e4tze haben Fl\u00fcgel,", "tokens": ["Sch\u00e4t\u00b7ze", "ha\u00b7ben", "Fl\u00fc\u00b7gel", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.5": {"text": "Ehre l\u00e4\u00dft den Z\u00fcgel,", "tokens": ["Eh\u00b7re", "l\u00e4\u00dft", "den", "Z\u00fc\u00b7gel", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.6": {"text": "Lust kommt aus dem B\u00fcgel:", "tokens": ["Lust", "kommt", "aus", "dem", "B\u00fc\u00b7gel", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.7": {"text": "die Tugend h\u00e4lt.", "tokens": ["die", "Tu\u00b7gend", "h\u00e4lt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.10": {"line.1": {"text": "Hab' ich Gott und Tugend,", "tokens": ["Hab'", "ich", "Gott", "und", "Tu\u00b7gend", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "NN", "KON", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "so hat meine Jugend,", "tokens": ["so", "hat", "mei\u00b7ne", "Ju\u00b7gend", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "was sie macht wert.", "tokens": ["was", "sie", "macht", "wert", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVFIN", "ADJD", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.4": {"text": "Diese sch\u00f6nen Beide", "tokens": ["Die\u00b7se", "sch\u00f6\u00b7nen", "Bei\u00b7de"], "token_info": ["word", "word", "word"], "pos": ["PDAT", "ADJA", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.5": {"text": "wehren allem Leide,", "tokens": ["weh\u00b7ren", "al\u00b7lem", "Lei\u00b7de", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.6": {"text": "lieben alle Freude,", "tokens": ["lie\u00b7ben", "al\u00b7le", "Freu\u00b7de", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.7": {"text": "so man begehrt.", "tokens": ["so", "man", "be\u00b7gehrt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "PIS", "VVPP", "$."], "meter": "-+-+", "measure": "iambic.di"}}}}}