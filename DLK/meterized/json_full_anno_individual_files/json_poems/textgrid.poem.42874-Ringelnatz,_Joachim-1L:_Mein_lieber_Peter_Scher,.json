{"textgrid.poem.42874": {"metadata": {"author": {"name": "Ringelnatz, Joachim", "birth": "N.A.", "death": "N.A."}, "title": "1L: Mein lieber Peter Scher,", "genre": "verse", "period": "N.A.", "pub_year": 1908, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Mein lieber Peter Scher,", "tokens": ["Mein", "lie\u00b7ber", "Pe\u00b7ter", "Scher", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADV", "NE", "NE", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Horch her:", "tokens": ["Horch", "her", ":"], "token_info": ["word", "word", "punct"], "pos": ["NE", "PTKVZ", "$."], "meter": "+-", "measure": "trochaic.single"}}, "stanza.2": {"line.1": {"text": "Ich h\u00e4tte dich manchmal hassen", "tokens": ["Ich", "h\u00e4t\u00b7te", "dich", "manch\u00b7mal", "has\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "VVINF"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Und an der Gurgel fassen", "tokens": ["Und", "an", "der", "Gur\u00b7gel", "fas\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Wollen, dich, den der Ringelnatz liebt.", "tokens": ["Wol\u00b7len", ",", "dich", ",", "den", "der", "Rin\u00b7gel\u00b7natz", "liebt", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PPER", "$,", "PRELS", "ART", "NN", "VVFIN", "$."], "meter": "+-+--+--+", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Weil du nicht lernst, da\u00df es Etwasse gibt,", "tokens": ["Weil", "du", "nicht", "lernst", ",", "da\u00df", "es", "Et\u00b7was\u00b7se", "gibt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "VVFIN", "$,", "KOUS", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Die gar nichts mit sich anfangen lassen.", "tokens": ["Die", "gar", "nichts", "mit", "sich", "an\u00b7fan\u00b7gen", "las\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "PIS", "APPR", "PRF", "VVINF", "VVINF", "$."], "meter": "+-++--+-+-", "measure": "trochaic.penta.relaxed"}, "line.6": {"text": "Oder weil du, der auch du mich liebst,", "tokens": ["O\u00b7der", "weil", "du", ",", "der", "auch", "du", "mich", "liebst", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "$,", "PRELS", "ADV", "PPER", "PRF", "VVFIN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.7": {"text": "Das nicht zugibst.", "tokens": ["Das", "nicht", "zu\u00b7gibst", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PDS", "PTKNEG", "VVPP", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.8": {"text": "Und gerade auf das Zugeben", "tokens": ["Und", "ge\u00b7ra\u00b7de", "auf", "das", "Zu\u00b7ge\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "APPR", "ART", "NN"], "meter": "+-+-+-+--", "measure": "unknown.measure.tetra"}, "line.9": {"text": "Kommt's an im Leben.", "tokens": ["Kommt's", "an", "im", "Le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "APPRART", "NN", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.3": {"line.1": {"text": "Du bist oft an falscher Stelle zu dick.", "tokens": ["Du", "bist", "oft", "an", "fal\u00b7scher", "Stel\u00b7le", "zu", "dick", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "APPR", "ADJA", "NN", "PTKA", "ADJD", "$."], "meter": "----+-+--+", "measure": "iambic.tri.chol"}}, "stanza.4": {"line.1": {"text": "Wir sind Freunde auf Lebenszeit.", "tokens": ["Wir", "sind", "Freun\u00b7de", "auf", "Le\u00b7bens\u00b7zeit", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NN", "APPR", "NN", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.2": {"text": "Ich kenne deine Vergangenheit.", "tokens": ["Ich", "ken\u00b7ne", "dei\u00b7ne", "Ver\u00b7gan\u00b7gen\u00b7heit", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Und ich wei\u00df: Im wichtigen Augenblick", "tokens": ["Und", "ich", "wei\u00df", ":", "Im", "wich\u00b7ti\u00b7gen", "Au\u00b7gen\u00b7blick"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "$.", "APPRART", "ADJA", "NN"], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Bist du ganz und gro\u00df und hilfsbereit.", "tokens": ["Bist", "du", "ganz", "und", "gro\u00df", "und", "hilfs\u00b7be\u00b7reit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "KON", "ADJD", "KON", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.5": {"line.1": {"text": "Mein lieber Peter Scher,", "tokens": ["Mein", "lie\u00b7ber", "Pe\u00b7ter", "Scher", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADV", "NE", "NE", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Horch her:", "tokens": ["Horch", "her", ":"], "token_info": ["word", "word", "punct"], "pos": ["NE", "PTKVZ", "$."], "meter": "+-", "measure": "trochaic.single"}}, "stanza.6": {"line.1": {"text": "Ich h\u00e4tte dich manchmal hassen", "tokens": ["Ich", "h\u00e4t\u00b7te", "dich", "manch\u00b7mal", "has\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "VVINF"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Und an der Gurgel fassen", "tokens": ["Und", "an", "der", "Gur\u00b7gel", "fas\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Wollen, dich, den der Ringelnatz liebt.", "tokens": ["Wol\u00b7len", ",", "dich", ",", "den", "der", "Rin\u00b7gel\u00b7natz", "liebt", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PPER", "$,", "PRELS", "ART", "NN", "VVFIN", "$."], "meter": "+-+--+--+", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Weil du nicht lernst, da\u00df es Etwasse gibt,", "tokens": ["Weil", "du", "nicht", "lernst", ",", "da\u00df", "es", "Et\u00b7was\u00b7se", "gibt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "VVFIN", "$,", "KOUS", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Die gar nichts mit sich anfangen lassen.", "tokens": ["Die", "gar", "nichts", "mit", "sich", "an\u00b7fan\u00b7gen", "las\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "PIS", "APPR", "PRF", "VVINF", "VVINF", "$."], "meter": "+-++--+-+-", "measure": "trochaic.penta.relaxed"}, "line.6": {"text": "Oder weil du, der auch du mich liebst,", "tokens": ["O\u00b7der", "weil", "du", ",", "der", "auch", "du", "mich", "liebst", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "$,", "PRELS", "ADV", "PPER", "PRF", "VVFIN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.7": {"text": "Das nicht zugibst.", "tokens": ["Das", "nicht", "zu\u00b7gibst", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PDS", "PTKNEG", "VVPP", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.8": {"text": "Und gerade auf das Zugeben", "tokens": ["Und", "ge\u00b7ra\u00b7de", "auf", "das", "Zu\u00b7ge\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "APPR", "ART", "NN"], "meter": "+-+-+-+--", "measure": "unknown.measure.tetra"}, "line.9": {"text": "Kommt's an im Leben.", "tokens": ["Kommt's", "an", "im", "Le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "APPRART", "NN", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.7": {"line.1": {"text": "Du bist oft an falscher Stelle zu dick.", "tokens": ["Du", "bist", "oft", "an", "fal\u00b7scher", "Stel\u00b7le", "zu", "dick", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "APPR", "ADJA", "NN", "PTKA", "ADJD", "$."], "meter": "----+-+--+", "measure": "iambic.tri.chol"}}, "stanza.8": {"line.1": {"text": "Wir sind Freunde auf Lebenszeit.", "tokens": ["Wir", "sind", "Freun\u00b7de", "auf", "Le\u00b7bens\u00b7zeit", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NN", "APPR", "NN", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.2": {"text": "Ich kenne deine Vergangenheit.", "tokens": ["Ich", "ken\u00b7ne", "dei\u00b7ne", "Ver\u00b7gan\u00b7gen\u00b7heit", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Und ich wei\u00df: Im wichtigen Augenblick", "tokens": ["Und", "ich", "wei\u00df", ":", "Im", "wich\u00b7ti\u00b7gen", "Au\u00b7gen\u00b7blick"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "$.", "APPRART", "ADJA", "NN"], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Bist du ganz und gro\u00df und hilfsbereit.", "tokens": ["Bist", "du", "ganz", "und", "gro\u00df", "und", "hilfs\u00b7be\u00b7reit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "KON", "ADJD", "KON", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}}}}