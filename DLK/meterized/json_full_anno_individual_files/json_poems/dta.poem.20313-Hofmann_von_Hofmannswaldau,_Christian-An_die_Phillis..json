{"dta.poem.20313": {"metadata": {"author": {"name": "Hofmann von Hofmannswaldau, Christian", "birth": "N.A.", "death": "N.A."}, "title": "An die Phillis.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1695", "urn": "urn:nbn:de:kobv:b4-200905197751", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Cupido hatte sich aus kurtzweil f\u00fcrgenommen", "tokens": ["Cu\u00b7pi\u00b7do", "hat\u00b7te", "sich", "aus", "kurt\u00b7zweil", "f\u00fcr\u00b7ge\u00b7nom\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "VAFIN", "PRF", "APPR", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Auff einen sonntag j\u00fcngst zur Phillis hin zu kommen/", "tokens": ["Auff", "ei\u00b7nen", "sonn\u00b7tag", "j\u00fcngst", "zur", "Phil\u00b7lis", "hin", "zu", "kom\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADV", "APPRART", "NE", "ADV", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Er schlich auch unvermerckt in die gesellschafft ein/", "tokens": ["Er", "schlich", "auch", "un\u00b7ver\u00b7merckt", "in", "die", "ge\u00b7sell\u00b7schafft", "ein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADJD", "APPR", "ART", "NN", "ART", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Als man noch emsig war/ durch lachen/ spiel und k\u00fcssen", "tokens": ["Als", "man", "noch", "em\u00b7sig", "war", "/", "durch", "la\u00b7chen", "/", "spiel", "und", "k\u00fcs\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "PIS", "ADV", "ADJD", "VAFIN", "$(", "APPR", "VVINF", "$(", "VVFIN", "KON", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Den kurtzen rest der zeit erfreulich zu geniessen/", "tokens": ["Den", "kurt\u00b7zen", "rest", "der", "zeit", "er\u00b7freu\u00b7lich", "zu", "ge\u00b7nies\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "ART", "NN", "ADJD", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und wolte bey der lust selbst koch und kellner seyn.", "tokens": ["Und", "wol\u00b7te", "bey", "der", "lust", "selbst", "koch", "und", "kell\u00b7ner", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "APPR", "ART", "NN", "ADV", "ADJD", "KON", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Itzt sah man allererst/ wie sich die hertzen regten/", "tokens": ["Itzt", "sah", "man", "al\u00b7le\u00b7rerst", "/", "wie", "sich", "die", "hert\u00b7zen", "reg\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "ADV", "$(", "PWAV", "PRF", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "So bald der kleine schalck in die versammlung trat/", "tokens": ["So", "bald", "der", "klei\u00b7ne", "schalck", "in", "die", "ver\u00b7samm\u00b7lung", "trat", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "ADJA", "NN", "APPR", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Wie man die Phillis hier um ihre liebe bat/", "tokens": ["Wie", "man", "die", "Phil\u00b7lis", "hier", "um", "ih\u00b7re", "lie\u00b7be", "bat", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "ART", "NE", "ADV", "APPR", "PPOSAT", "ADJA", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Die augen aber dort sich gantz erhitzt bewegten/", "tokens": ["Die", "au\u00b7gen", "a\u00b7ber", "dort", "sich", "gantz", "er\u00b7hitzt", "be\u00b7weg\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ADV", "PRF", "ADV", "VVFIN", "ADJA", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Und wie dem einem blieb die zunge stille stehn/", "tokens": ["Und", "wie", "dem", "ei\u00b7nem", "blieb", "die", "zun\u00b7ge", "stil\u00b7le", "stehn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ART", "ART", "VVFIN", "ART", "NN", "VVFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Beym andern seuffzer lie\u00df an statt der worte gehn.", "tokens": ["Beym", "an\u00b7dern", "seuff\u00b7zer", "lie\u00df", "an", "statt", "der", "wor\u00b7te", "gehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "VVFIN", "APPR", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Man sagt: Er h\u00e4tte sich den abend fest verschworen:", "tokens": ["Man", "sagt", ":", "Er", "h\u00e4t\u00b7te", "sich", "den", "a\u00b7bend", "fest", "ver\u00b7schwo\u00b7ren", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "$.", "PPER", "VAFIN", "PRF", "ART", "ADV", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Es solte keiner nicht von liebe seyn befreyt;", "tokens": ["Es", "sol\u00b7te", "kei\u00b7ner", "nicht", "von", "lie\u00b7be", "seyn", "be\u00b7freyt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PIS", "PTKNEG", "APPR", "VVFIN", "PPOSAT", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Dem krocher in den mund durch k\u00fc\u00df und s\u00fc\u00dfigkeit/", "tokens": ["Dem", "kro\u00b7cher", "in", "den", "mund", "durch", "k\u00fc\u00df", "und", "s\u00fc\u00b7\u00dfig\u00b7keit", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "APPR", "ADJD", "KON", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Ein andrer fieng ihn auff mit auffgespitzten ohren;", "tokens": ["Ein", "an\u00b7drer", "fi\u00b7eng", "ihn", "auff", "mit", "auff\u00b7ge\u00b7spitz\u00b7ten", "oh\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "PPER", "APPR", "APPR", "ADJA", "NN", "$."], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.17": {"text": "Dem kam er in den fu\u00df/ und jenem in die hand/", "tokens": ["Dem", "kam", "er", "in", "den", "fu\u00df", "/", "und", "je\u00b7nem", "in", "die", "hand", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "APPR", "ART", "PTKVZ", "$(", "KON", "PDAT", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Und vielen ward er auch durchs auge nur bekandt.", "tokens": ["Und", "vie\u00b7len", "ward", "er", "auch", "durchs", "au\u00b7ge", "nur", "be\u00b7kandt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VAFIN", "PPER", "ADV", "APPRART", "NN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "So ward das strenge feur der liebe nun gebohren/", "tokens": ["So", "ward", "das", "stren\u00b7ge", "feur", "der", "lie\u00b7be", "nun", "ge\u00b7boh\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "ADJA", "NN", "ART", "VVFIN", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Und machte/ da\u00df mein hertz auch stille flammen fing;", "tokens": ["Und", "mach\u00b7te", "/", "da\u00df", "mein", "hertz", "auch", "stil\u00b7le", "flam\u00b7men", "fing", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$(", "KOUS", "PPOSAT", "NN", "ADV", "ADJA", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Doch/ als man wiederum nun von einander gieng/", "tokens": ["Doch", "/", "als", "man", "wie\u00b7de\u00b7rum", "nun", "von", "ein\u00b7an\u00b7der", "gieng", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$(", "KOUS", "PIS", "ADV", "ADV", "APPR", "PRF", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Schien es/ als h\u00e4tte sich Cupido gar verlohren/", "tokens": ["Schien", "es", "/", "als", "h\u00e4t\u00b7te", "sich", "Cu\u00b7pi\u00b7do", "gar", "ver\u00b7loh\u00b7ren", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$(", "KOKOM", "VAFIN", "PRF", "NE", "ADV", "VVPP", "$("], "meter": "---+-+-+-+-+-", "measure": "unknown.measure.penta"}, "line.23": {"text": "Cupido/ welcher doch beym scheiden gerne bleibt/", "tokens": ["Cu\u00b7pi\u00b7do", "/", "wel\u00b7cher", "doch", "beym", "schei\u00b7den", "ger\u00b7ne", "bleibt", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$(", "PRELS", "ADV", "APPRART", "VVFIN", "ADV", "VVFIN", "$("], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.24": {"text": "Und sonderlich zuletzt noch seine possen treibt.", "tokens": ["Und", "son\u00b7der\u00b7lich", "zu\u00b7letzt", "noch", "sei\u00b7ne", "pos\u00b7sen", "treibt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "ADV", "ADV", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "So bald ich aber drauff nach hause wieder kommen/", "tokens": ["So", "bald", "ich", "a\u00b7ber", "drauff", "nach", "hau\u00b7se", "wie\u00b7der", "kom\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "ADV", "PAV", "APPR", "NN", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Da f\u00fchlt ich allererst/ wie wider die natur", "tokens": ["Da", "f\u00fchlt", "ich", "al\u00b7le\u00b7rerst", "/", "wie", "wi\u00b7der", "die", "na\u00b7tur"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "$(", "KOKOM", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Mir ein erhitztes feur durch alle glieder fuhr/", "tokens": ["Mir", "ein", "er\u00b7hitz\u00b7tes", "feur", "durch", "al\u00b7le", "glie\u00b7der", "fuhr", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "ADJA", "NN", "APPR", "PIAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Und da\u00df ich unvermerckt den vogel mitgenommen.", "tokens": ["Und", "da\u00df", "ich", "un\u00b7ver\u00b7merckt", "den", "vo\u00b7gel", "mit\u00b7ge\u00b7nom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADJD", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Hier klagt ich/ doch zu sp\u00e4t/ da\u00df freude sonder pein", "tokens": ["Hier", "klagt", "ich", "/", "doch", "zu", "sp\u00e4t", "/", "da\u00df", "freu\u00b7de", "son\u00b7der", "pein"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "$(", "ADV", "PTKA", "ADJD", "$(", "KOUS", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "So wenig als ein stern kan ohne flecken seyn.", "tokens": ["So", "we\u00b7nig", "als", "ein", "stern", "kan", "oh\u00b7ne", "fle\u00b7cken", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "KOKOM", "ART", "VVINF", "VMFIN", "APPR", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Nun f\u00fcrcht ich/ Phillis/ sehr/ er m\u00f6chte beym studieren/", "tokens": ["Nun", "f\u00fcrcht", "ich", "/", "Phil\u00b7lis", "/", "sehr", "/", "er", "m\u00f6ch\u00b7te", "beym", "stu\u00b7die\u00b7ren", "/"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$(", "NE", "$(", "ADV", "$(", "PPER", "VMFIN", "APPRART", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "(man wei\u00df doch allzuwohl/ was dieser bube kan/)", "tokens": ["(", "man", "wei\u00df", "doch", "all\u00b7zu\u00b7wohl", "/", "was", "die\u00b7ser", "bu\u00b7be", "kan", "/", ")"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PIS", "VVFIN", "ADV", "ADV", "$(", "PWS", "PDAT", "NN", "VMFIN", "$(", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "Bald meinen federkiel von der gelehrten bahn/", "tokens": ["Bald", "mei\u00b7nen", "fe\u00b7der\u00b7kiel", "von", "der", "ge\u00b7lehr\u00b7ten", "bahn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "APPR", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "Bald/ wie ein kind gewohnt/ die b\u00fccher mir entf\u00fchren.", "tokens": ["Bald", "/", "wie", "ein", "kind", "ge\u00b7wohnt", "/", "die", "b\u00fc\u00b7cher", "mir", "ent\u00b7f\u00fch\u00b7ren", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$(", "KOKOM", "ART", "NN", "VVPP", "$(", "ART", "ADJA", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "Und dieses d\u00fcrffte leicht nebst andern ursach seyn/", "tokens": ["Und", "die\u00b7ses", "d\u00fcrff\u00b7te", "leicht", "nebst", "an\u00b7dern", "ur\u00b7sach", "seyn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VMFIN", "ADJD", "APPR", "ADJA", "NN", "VAINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "Da\u00df ich ihm st\u00fcndlich nur mit ruthen m\u00fcste dr\u00e4uen.", "tokens": ["Da\u00df", "ich", "ihm", "st\u00fcnd\u00b7lich", "nur", "mit", "ru\u00b7then", "m\u00fcs\u00b7te", "dr\u00e4u\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "ADJD", "ADV", "APPR", "VVINF", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "Drum mu\u00df ich endlich wohl ein ander mittel fassen:", "tokens": ["Drum", "mu\u00df", "ich", "end\u00b7lich", "wohl", "ein", "an\u00b7der", "mit\u00b7tel", "fas\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VMFIN", "PPER", "ADV", "ADV", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.38": {"text": "Denn Musen schicken sich zu keiner liebes-pein.", "tokens": ["Denn", "Mu\u00b7sen", "schi\u00b7cken", "sich", "zu", "kei\u00b7ner", "lie\u00b7bes\u00b7pein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "PRF", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.39": {"text": "Was aber ist hier rath? bey dir nahm ich ihn ein/", "tokens": ["Was", "a\u00b7ber", "ist", "hier", "rath", "?", "bey", "dir", "nahm", "ich", "ihn", "ein", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "VAFIN", "ADV", "NN", "$.", "APPR", "PPER", "VVFIN", "PPER", "PPER", "ART", "$("], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.40": {"text": "Bey dir will ich ihn auch nun wieder sitzen lassen/", "tokens": ["Bey", "dir", "will", "ich", "ihn", "auch", "nun", "wie\u00b7der", "sit\u00b7zen", "las\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VMFIN", "PPER", "PPER", "ADV", "ADV", "ADV", "VVINF", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.41": {"text": "Ich habe nichts wie du/ das ihn vergn\u00fcgen kan/", "tokens": ["Ich", "ha\u00b7be", "nichts", "wie", "du", "/", "das", "ihn", "ver\u00b7gn\u00fc\u00b7gen", "kan", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIS", "KOKOM", "PPER", "$(", "PRELS", "PPER", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.42": {"text": "Denn g\u00f6ttern stehen doch nur sch\u00f6ne lager an.", "tokens": ["Denn", "g\u00f6t\u00b7tern", "ste\u00b7hen", "doch", "nur", "sch\u00f6\u00b7ne", "la\u00b7ger", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVINF", "VVFIN", "ADV", "ADV", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}