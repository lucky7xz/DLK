{"textgrid.poem.53451": {"metadata": {"author": {"name": "Tucholsky, Kurt", "birth": "N.A.", "death": "N.A."}, "title": "Saisonbeschlu\u00df", "genre": "verse", "period": "N.A.", "pub_year": 1912, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Nun reibt der Heldenvater sich mit Margarine", "tokens": ["Nun", "reibt", "der", "Hel\u00b7den\u00b7va\u00b7ter", "sich", "mit", "Mar\u00b7ga\u00b7ri\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "PRF", "APPR", "NE"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "die Schminke aus dem fetten Doppelkinn,", "tokens": ["die", "Schmin\u00b7ke", "aus", "dem", "fet\u00b7ten", "Dop\u00b7pel\u00b7kinn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "und auch im Silberhaar die Heroine", "tokens": ["und", "auch", "im", "Sil\u00b7ber\u00b7haar", "die", "He\u00b7ro\u00b7i\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "APPRART", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "legt alles ab und hin.", "tokens": ["legt", "al\u00b7les", "ab", "und", "hin", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PTKVZ", "KON", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Verstaubt und leer steht nun der Kassenschalter;", "tokens": ["Ver\u00b7staubt", "und", "leer", "steht", "nun", "der", "Kas\u00b7sen\u00b7schal\u00b7ter", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "KON", "ADJD", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "sie schieben alle nacheinander ab:", "tokens": ["sie", "schie\u00b7ben", "al\u00b7le", "na\u00b7ch\u00b7ein\u00b7an\u00b7der", "ab", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "ADV", "PTKVZ", "$."], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "das Personal und der Konkursverwalter", "tokens": ["das", "Per\u00b7so\u00b7nal", "und", "der", "Kon\u00b7kurs\u00b7ver\u00b7wal\u00b7ter"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "KON", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "und Herr von Glasenapp.", "tokens": ["und", "Herr", "von", "Gla\u00b7sen\u00b7app", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "APPR", "NE", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Und es erheben sich so manche Fragen:", "tokens": ["Und", "es", "er\u00b7he\u00b7ben", "sich", "so", "man\u00b7che", "Fra\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PRF", "ADV", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Da Hollaender nicht immer schweigen kann,", "tokens": ["Da", "Hol\u00b7la\u00b7en\u00b7der", "nicht", "im\u00b7mer", "schwei\u00b7gen", "kann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "PTKNEG", "ADV", "VVINF", "VMFIN", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "\u2013 der Speichel rinnt auch in den warmen Tagen \u2013", "tokens": ["\u2013", "der", "Spei\u00b7chel", "rinnt", "auch", "in", "den", "war\u00b7men", "Ta\u00b7gen", "\u2013"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "VVFIN", "ADV", "APPR", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "wo l\u00e4\u00dft es dieser Mann?", "tokens": ["wo", "l\u00e4\u00dft", "es", "die\u00b7ser", "Mann", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "PDAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Wovon soll der Gerichtsvollzieher leben?", "tokens": ["Wo\u00b7von", "soll", "der", "Ge\u00b7richts\u00b7voll\u00b7zie\u00b7her", "le\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "ART", "NN", "VVINF", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.2": {"text": "Es bleibt nicht immer, wie es einstens war . . .", "tokens": ["Es", "bleibt", "nicht", "im\u00b7mer", ",", "wie", "es", "eins\u00b7tens", "war", ".", ".", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "ADV", "$,", "PWAV", "PPER", "ADV", "VAFIN", "$.", "$.", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "und wohin soll er nun den Kuckuck kleben?", "tokens": ["und", "wo\u00b7hin", "soll", "er", "nun", "den", "Ku\u00b7ckuck", "kle\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "VMFIN", "PPER", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "O einziger Lothar!", "tokens": ["O", "ein\u00b7zi\u00b7ger", "Lo\u00b7thar", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}}, "stanza.5": {"line.1": {"text": "Und kurz und gut: Nicht immer gings dem s\u00fc\u00dfen Kinde", "tokens": ["Und", "kurz", "und", "gut", ":", "Nicht", "im\u00b7mer", "gings", "dem", "s\u00fc\u00b7\u00dfen", "Kin\u00b7de"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "KON", "ADJD", "$.", "PTKNEG", "ADV", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Thaliens gut, und meistens nur so so . . .", "tokens": ["Tha\u00b7li\u00b7ens", "gut", ",", "und", "meis\u00b7tens", "nur", "so", "so", ".", ".", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["NN", "ADJD", "$,", "KON", "ADV", "ADV", "ADV", "ADV", "$.", "$.", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.3": {"text": "Nun aber kommen Wiesen und die Sommerwinde \u2013", "tokens": ["Nun", "a\u00b7ber", "kom\u00b7men", "Wie\u00b7sen", "und", "die", "Som\u00b7mer\u00b7win\u00b7de", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "NN", "KON", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Rideau!", "tokens": ["Ri\u00b7de\u00b7au", "!"], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.5": {"text": "Rideau!", "tokens": ["Ri\u00b7de\u00b7au", "!"], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.6": {"line.1": {"text": "Nun reibt der Heldenvater sich mit Margarine", "tokens": ["Nun", "reibt", "der", "Hel\u00b7den\u00b7va\u00b7ter", "sich", "mit", "Mar\u00b7ga\u00b7ri\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "PRF", "APPR", "NE"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "die Schminke aus dem fetten Doppelkinn,", "tokens": ["die", "Schmin\u00b7ke", "aus", "dem", "fet\u00b7ten", "Dop\u00b7pel\u00b7kinn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "und auch im Silberhaar die Heroine", "tokens": ["und", "auch", "im", "Sil\u00b7ber\u00b7haar", "die", "He\u00b7ro\u00b7i\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "APPRART", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "legt alles ab und hin.", "tokens": ["legt", "al\u00b7les", "ab", "und", "hin", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PTKVZ", "KON", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Verstaubt und leer steht nun der Kassenschalter;", "tokens": ["Ver\u00b7staubt", "und", "leer", "steht", "nun", "der", "Kas\u00b7sen\u00b7schal\u00b7ter", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "KON", "ADJD", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "sie schieben alle nacheinander ab:", "tokens": ["sie", "schie\u00b7ben", "al\u00b7le", "na\u00b7ch\u00b7ein\u00b7an\u00b7der", "ab", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "ADV", "PTKVZ", "$."], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "das Personal und der Konkursverwalter", "tokens": ["das", "Per\u00b7so\u00b7nal", "und", "der", "Kon\u00b7kurs\u00b7ver\u00b7wal\u00b7ter"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "KON", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "und Herr von Glasenapp.", "tokens": ["und", "Herr", "von", "Gla\u00b7sen\u00b7app", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "APPR", "NE", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Und es erheben sich so manche Fragen:", "tokens": ["Und", "es", "er\u00b7he\u00b7ben", "sich", "so", "man\u00b7che", "Fra\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PRF", "ADV", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Da Hollaender nicht immer schweigen kann,", "tokens": ["Da", "Hol\u00b7la\u00b7en\u00b7der", "nicht", "im\u00b7mer", "schwei\u00b7gen", "kann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "PTKNEG", "ADV", "VVINF", "VMFIN", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "\u2013 der Speichel rinnt auch in den warmen Tagen \u2013", "tokens": ["\u2013", "der", "Spei\u00b7chel", "rinnt", "auch", "in", "den", "war\u00b7men", "Ta\u00b7gen", "\u2013"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "VVFIN", "ADV", "APPR", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "wo l\u00e4\u00dft es dieser Mann?", "tokens": ["wo", "l\u00e4\u00dft", "es", "die\u00b7ser", "Mann", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "PDAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Wovon soll der Gerichtsvollzieher leben?", "tokens": ["Wo\u00b7von", "soll", "der", "Ge\u00b7richts\u00b7voll\u00b7zie\u00b7her", "le\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "ART", "NN", "VVINF", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.2": {"text": "Es bleibt nicht immer, wie es einstens war . . .", "tokens": ["Es", "bleibt", "nicht", "im\u00b7mer", ",", "wie", "es", "eins\u00b7tens", "war", ".", ".", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "ADV", "$,", "PWAV", "PPER", "ADV", "VAFIN", "$.", "$.", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "und wohin soll er nun den Kuckuck kleben?", "tokens": ["und", "wo\u00b7hin", "soll", "er", "nun", "den", "Ku\u00b7ckuck", "kle\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "VMFIN", "PPER", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "O einziger Lothar!", "tokens": ["O", "ein\u00b7zi\u00b7ger", "Lo\u00b7thar", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}}, "stanza.10": {"line.1": {"text": "Und kurz und gut: Nicht immer gings dem s\u00fc\u00dfen Kinde", "tokens": ["Und", "kurz", "und", "gut", ":", "Nicht", "im\u00b7mer", "gings", "dem", "s\u00fc\u00b7\u00dfen", "Kin\u00b7de"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "KON", "ADJD", "$.", "PTKNEG", "ADV", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Thaliens gut, und meistens nur so so . . .", "tokens": ["Tha\u00b7li\u00b7ens", "gut", ",", "und", "meis\u00b7tens", "nur", "so", "so", ".", ".", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["NN", "ADJD", "$,", "KON", "ADV", "ADV", "ADV", "ADV", "$.", "$.", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.3": {"text": "Nun aber kommen Wiesen und die Sommerwinde \u2013", "tokens": ["Nun", "a\u00b7ber", "kom\u00b7men", "Wie\u00b7sen", "und", "die", "Som\u00b7mer\u00b7win\u00b7de", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "NN", "KON", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Rideau!", "tokens": ["Ri\u00b7de\u00b7au", "!"], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.5": {"text": "Rideau!", "tokens": ["Ri\u00b7de\u00b7au", "!"], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "+-+", "measure": "trochaic.di"}}}}}