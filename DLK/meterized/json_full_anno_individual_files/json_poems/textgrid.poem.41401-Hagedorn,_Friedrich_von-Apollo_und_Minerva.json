{"textgrid.poem.41401": {"metadata": {"author": {"name": "Hagedorn, Friedrich von", "birth": "N.A.", "death": "N.A."}, "title": "Apollo und Minerva", "genre": "verse", "period": "N.A.", "pub_year": 1731, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Mein Behrmann, den Geschmack und Witz und Redlichkeit", "tokens": ["Mein", "Behr\u00b7mann", ",", "den", "Ge\u00b7schmack", "und", "Witz", "und", "Red\u00b7lich\u00b7keit"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "$,", "ART", "NN", "KON", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Von niedertr\u00e4cht'gem Wahn entfernet,", "tokens": ["Von", "nie\u00b7der\u00b7tr\u00e4cht'\u00b7gem", "Wahn", "ent\u00b7fer\u00b7net", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Den auch ein innrer Reichthum k\u00f6rnet,", "tokens": ["Den", "auch", "ein", "inn\u00b7rer", "Reicht\u00b7hum", "k\u00f6r\u00b7net", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Der weder Wind noch Fluten scheut,", "tokens": ["Der", "we\u00b7der", "Wind", "noch", "Flu\u00b7ten", "scheut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "KON", "NN", "ADV", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Erm\u00fcde nicht, in lehrenden Gedichten", "tokens": ["Er\u00b7m\u00fc\u00b7de", "nicht", ",", "in", "leh\u00b7ren\u00b7den", "Ge\u00b7dich\u00b7ten"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["NN", "PTKNEG", "$,", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Die deutschen Musen zu erfreun.", "tokens": ["Die", "deut\u00b7schen", "Mu\u00b7sen", "zu", "er\u00b7freun", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Der D\u00fcnkel meistre dich; es mag die Thorheit richten;", "tokens": ["Der", "D\u00fcn\u00b7kel", "meist\u00b7re", "dich", ";", "es", "mag", "die", "Thor\u00b7heit", "rich\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "$.", "PPER", "VMFIN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Nicht aber dich mit Witz und Kunst entzwein.", "tokens": ["Nicht", "a\u00b7ber", "dich", "mit", "Witz", "und", "Kunst", "ent\u00b7zwein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "PPER", "APPR", "NN", "KON", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Der Einfalt l\u00e4cherliches Lachen", "tokens": ["Der", "Ein\u00b7falt", "l\u00e4\u00b7cher\u00b7li\u00b7ches", "La\u00b7chen"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Mu\u00df deine Seele nicht klein, tr\u00e4g' und irdisch machen.", "tokens": ["Mu\u00df", "dei\u00b7ne", "See\u00b7le", "nicht", "klein", ",", "tr\u00e4g'", "und", "ir\u00b7disch", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPOSAT", "NN", "PTKNEG", "ADJD", "$,", "VVFIN", "KON", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Sei stets der Wahrheit hold, (sie nutzt vor tausend Sachen)", "tokens": ["Sei", "stets", "der", "Wahr\u00b7heit", "hold", ",", "(", "sie", "nutzt", "vor", "tau\u00b7send", "Sa\u00b7chen", ")"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "ADJD", "$,", "$(", "PPER", "ADV", "APPR", "CARD", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Und sch\u00e4me dich nicht, klug zu sein.", "tokens": ["Und", "sch\u00e4\u00b7me", "dich", "nicht", ",", "klug", "zu", "sein", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PTKNEG", "$,", "ADJD", "PTKZU", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Die Fabel, die ich dich jetzt lehre,", "tokens": ["Die", "Fa\u00b7bel", ",", "die", "ich", "dich", "jetzt", "leh\u00b7re", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "PRF", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Zeigt unsers P\u00f6bels Ekel an;", "tokens": ["Zeigt", "un\u00b7sers", "P\u00f6\u00b7bels", "E\u00b7kel", "an", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und dennoch bleibt es wahr: Ein reicher, weiser Mann", "tokens": ["Und", "den\u00b7noch", "bleibt", "es", "wahr", ":", "Ein", "rei\u00b7cher", ",", "wei\u00b7ser", "Mann"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "PPER", "PTKVZ", "$.", "ART", "ADJD", "$,", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ist zwiefach seiner Eltern Ehre.", "tokens": ["Ist", "zwie\u00b7fach", "sei\u00b7ner", "El\u00b7tern", "Eh\u00b7re", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Der Gott der Aerzt' und der Poeten", "tokens": ["Der", "Gott", "der", "A\u00b7e\u00b7rzt'", "und", "der", "Po\u00b7et\u00b7en"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "NN", "KON", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und Pallas wurden einst vom Himmel weggebannt,", "tokens": ["Und", "Pal\u00b7las", "wur\u00b7den", "einst", "vom", "Him\u00b7mel", "weg\u00b7ge\u00b7bannt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "VAFIN", "ADV", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die Ursach' ist noch unbekannt,", "tokens": ["Die", "Ur\u00b7sach'", "ist", "noch", "un\u00b7be\u00b7kannt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und scheint zu wissen nicht vonn\u00f6then.", "tokens": ["Und", "scheint", "zu", "wis\u00b7sen", "nicht", "von\u00b7n\u00f6\u00b7then", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKZU", "VVINF", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Als dieses Paar die Welt betrat,", "tokens": ["Als", "die\u00b7ses", "Paar", "die", "Welt", "be\u00b7trat", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDAT", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Beriethen beide sich, was bestens anzufangen?", "tokens": ["Be\u00b7rie\u00b7then", "bei\u00b7de", "sich", ",", "was", "bes\u00b7tens", "an\u00b7zu\u00b7fan\u00b7gen", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PRF", "$,", "PRELS", "ADV", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Apollo sprach: Ich schaffe Rath,", "tokens": ["A\u00b7pol\u00b7lo", "sprach", ":", "Ich", "schaf\u00b7fe", "Rath", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "$.", "PPER", "VVFIN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mein Lebens\u00f6l mu\u00df Brod erlangen.", "tokens": ["Mein", "Le\u00b7bens\u00b7\u00f6l", "mu\u00df", "Brod", "er\u00b7lan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VMFIN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Minerva rief frohlockend aus:", "tokens": ["Mi\u00b7ner\u00b7va", "rief", "froh\u00b7lo\u00b7ckend", "aus", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADJD", "PTKVZ", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.6": {"text": "Auch meiner Kunst bedarf ein jedes Haus.", "tokens": ["Auch", "mei\u00b7ner", "Kunst", "be\u00b7darf", "ein", "je\u00b7des", "Haus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "VVFIN", "ART", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "Man waget den Versuch, und baut im n\u00e4chsten Orte", "tokens": ["Man", "wa\u00b7get", "den", "Ver\u00b7such", ",", "und", "baut", "im", "n\u00e4chs\u00b7ten", "Or\u00b7te"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "ART", "NN", "$,", "KON", "VVFIN", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Zwo gro\u00dfe Storgerb\u00fchnen auf.", "tokens": ["Zwo", "gro\u00b7\u00dfe", "Stor\u00b7ger\u00b7b\u00fch\u00b7nen", "auf", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["CARD", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Apollo hat, als Arzt, viel Herrliches zu Kauf,", "tokens": ["A\u00b7pol\u00b7lo", "hat", ",", "als", "Arzt", ",", "viel", "Herr\u00b7li\u00b7ches", "zu", "Kauf", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "$,", "KOUS", "NN", "$,", "PIAT", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und r\u00fchmet, was er hat, durch ausgesuchte Worte.", "tokens": ["Und", "r\u00fch\u00b7met", ",", "was", "er", "hat", ",", "durch", "aus\u00b7ge\u00b7such\u00b7te", "Wor\u00b7te", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "PWS", "PPER", "VAFIN", "$,", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Sein Wunderelixir, das alte Haut verj\u00fcngt,", "tokens": ["Sein", "Wun\u00b7de\u00b7re\u00b7li\u00b7xir", ",", "das", "al\u00b7te", "Haut", "ver\u00b7j\u00fcngt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Den \u00e4chten Theriac, die besten Augensalben,", "tokens": ["Den", "\u00e4ch\u00b7ten", "The\u00b7riac", ",", "die", "bes\u00b7ten", "Au\u00b7gen\u00b7sal\u00b7ben", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.7": {"text": "Ein Oel, das jede Krankheit zwingt,", "tokens": ["Ein", "O\u00b7el", ",", "das", "je\u00b7de", "Krank\u00b7heit", "zwingt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PIAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.8": {"text": "Und Apotheken g'nug, zu ganzen und zu halben.", "tokens": ["Und", "A\u00b7pot\u00b7he\u00b7ken", "g'\u00b7nug", ",", "zu", "gan\u00b7zen", "und", "zu", "hal\u00b7ben", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ADV", "$,", "APPR", "ADJA", "KON", "PTKZU", "VVINF", "$."], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}}, "stanza.6": {"line.1": {"text": "Die Tochter Jupiters nahm Seelen in die Cur,", "tokens": ["Die", "Toch\u00b7ter", "Ju\u00b7pi\u00b7ters", "nahm", "See\u00b7len", "in", "die", "Cur", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NE", "VVFIN", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Sie sprach: Mein Gegengift wehrt allen Vorurtheilen,", "tokens": ["Sie", "sprach", ":", "Mein", "Ge\u00b7gen\u00b7gift", "wehrt", "al\u00b7len", "Vor\u00b7urt\u00b7hei\u00b7len", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "PPOSAT", "NN", "VVFIN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Mein Weisheitbalsam ist die St\u00e4rkung der Natur;", "tokens": ["Mein", "Weis\u00b7heit\u00b7bal\u00b7sam", "ist", "die", "St\u00e4r\u00b7kung", "der", "Na\u00b7tur", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Er kann den schlimmsten Schaden heilen:", "tokens": ["Er", "kann", "den", "schlimms\u00b7ten", "Scha\u00b7den", "hei\u00b7len", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Des Aberglaubens Krebs, der viele Lehrer plagt,", "tokens": ["Des", "A\u00b7berg\u00b7lau\u00b7bens", "Krebs", ",", "der", "vie\u00b7le", "Leh\u00b7rer", "plagt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$,", "PRELS", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Die Ueppigkeit, die Zehrung ganzer Reiche,", "tokens": ["Die", "Uep\u00b7pig\u00b7keit", ",", "die", "Zeh\u00b7rung", "gan\u00b7zer", "Rei\u00b7che", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "ADJA", "NE", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Den Wurm des Widerspruchs, der Haubt und Zunge nagt,", "tokens": ["Den", "Wurm", "des", "Wi\u00b7der\u00b7spruchs", ",", "der", "Haubt", "und", "Zun\u00b7ge", "nagt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$,", "ART", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Den Neid, der kleinen Geister Seuche.", "tokens": ["Den", "Neid", ",", "der", "klei\u00b7nen", "Geis\u00b7ter", "Seu\u00b7che", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Die Mittel, die ich zubereite,", "tokens": ["Die", "Mit\u00b7tel", ",", "die", "ich", "zu\u00b7be\u00b7rei\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Vertreiben unges\u00e4umt der Schw\u00e4tzer L\u00fcgensucht,", "tokens": ["Ver\u00b7trei\u00b7ben", "un\u00b7ge\u00b7s\u00e4umt", "der", "Schw\u00e4t\u00b7zer", "L\u00fc\u00b7gen\u00b7sucht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und die Vergessenheit, des rohen Undanks Frucht,", "tokens": ["Und", "die", "Ver\u00b7ges\u00b7sen\u00b7heit", ",", "des", "ro\u00b7hen", "Un\u00b7danks", "Frucht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "ART", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die Taubheit und den Kropf, die Krankheit gro\u00dfer Leute,", "tokens": ["Die", "Taub\u00b7heit", "und", "den", "Kropf", ",", "die", "Krank\u00b7heit", "gro\u00b7\u00dfer", "Leu\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "$,", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Des Geizes H\u00f6llendurst, der Einfalt Eigensinn,", "tokens": ["Des", "Gei\u00b7zes", "H\u00f6l\u00b7len\u00b7durst", ",", "der", "Ein\u00b7falt", "Ei\u00b7gen\u00b7sinn", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$,", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Den tilg' ich wundersam; so wahr ich Pallas bin!", "tokens": ["Den", "til\u00b7g'", "ich", "wun\u00b7der\u00b7sam", ";", "so", "wahr", "ich", "Pal\u00b7las", "bin", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPER", "ADJD", "$.", "ADV", "ADJD", "PPER", "NN", "VAFIN", "$."], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}, "line.7": {"text": "Auch nehm' ich die Bezahlung nur", "tokens": ["Auch", "nehm'", "ich", "die", "Be\u00b7zah\u00b7lung", "nur"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Nach gl\u00fccklich angeschlagner Cur.", "tokens": ["Nach", "gl\u00fcck\u00b7lich", "an\u00b7ge\u00b7schlag\u00b7ner", "Cur", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJD", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Apollo machte flei\u00dfig Kunden,", "tokens": ["A\u00b7pol\u00b7lo", "mach\u00b7te", "flei\u00b7\u00dfig", "Kun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADJD", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die arme Pallas hatte Ruh'.", "tokens": ["Die", "ar\u00b7me", "Pal\u00b7las", "hat\u00b7te", "Ruh'", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Nur ihm warf man das Schnupftuch zu,", "tokens": ["Nur", "ihm", "warf", "man", "das", "Schnupf\u00b7tuch", "zu", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VVFIN", "PIS", "ART", "NN", "PTKVZ", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.4": {"text": "Er rieth den Kranken und Gesunden.", "tokens": ["Er", "rieth", "den", "Kran\u00b7ken", "und", "Ge\u00b7sun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Wo wird die Weisheit Kranke finden?", "tokens": ["Wo", "wird", "die", "Weis\u00b7heit", "Kran\u00b7ke", "fin\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "ART", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ein jeder h\u00e4lt sich schon f\u00fcr klug,", "tokens": ["Ein", "je\u00b7der", "h\u00e4lt", "sich", "schon", "f\u00fcr", "klug", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VVFIN", "PRF", "ADV", "APPR", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Bescheiden, liebreich, fromm genug.", "tokens": ["Be\u00b7schei\u00b7den", ",", "lieb\u00b7reich", ",", "fromm", "ge\u00b7nug", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "ADJD", "$,", "ADJD", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der Hochmuth hilft ihm schon zu Gr\u00fcnden.", "tokens": ["Der", "Hoch\u00b7muth", "hilft", "ihm", "schon", "zu", "Gr\u00fcn\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADV", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Mein Behrmann, den Geschmack und Witz und Redlichkeit", "tokens": ["Mein", "Behr\u00b7mann", ",", "den", "Ge\u00b7schmack", "und", "Witz", "und", "Red\u00b7lich\u00b7keit"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "$,", "ART", "NN", "KON", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Von niedertr\u00e4cht'gem Wahn entfernet,", "tokens": ["Von", "nie\u00b7der\u00b7tr\u00e4cht'\u00b7gem", "Wahn", "ent\u00b7fer\u00b7net", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Den auch ein innrer Reichthum k\u00f6rnet,", "tokens": ["Den", "auch", "ein", "inn\u00b7rer", "Reicht\u00b7hum", "k\u00f6r\u00b7net", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Der weder Wind noch Fluten scheut,", "tokens": ["Der", "we\u00b7der", "Wind", "noch", "Flu\u00b7ten", "scheut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "KON", "NN", "ADV", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Erm\u00fcde nicht, in lehrenden Gedichten", "tokens": ["Er\u00b7m\u00fc\u00b7de", "nicht", ",", "in", "leh\u00b7ren\u00b7den", "Ge\u00b7dich\u00b7ten"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["NN", "PTKNEG", "$,", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Die deutschen Musen zu erfreun.", "tokens": ["Die", "deut\u00b7schen", "Mu\u00b7sen", "zu", "er\u00b7freun", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Der D\u00fcnkel meistre dich; es mag die Thorheit richten;", "tokens": ["Der", "D\u00fcn\u00b7kel", "meist\u00b7re", "dich", ";", "es", "mag", "die", "Thor\u00b7heit", "rich\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "$.", "PPER", "VMFIN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Nicht aber dich mit Witz und Kunst entzwein.", "tokens": ["Nicht", "a\u00b7ber", "dich", "mit", "Witz", "und", "Kunst", "ent\u00b7zwein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "PPER", "APPR", "NN", "KON", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Der Einfalt l\u00e4cherliches Lachen", "tokens": ["Der", "Ein\u00b7falt", "l\u00e4\u00b7cher\u00b7li\u00b7ches", "La\u00b7chen"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Mu\u00df deine Seele nicht klein, tr\u00e4g' und irdisch machen.", "tokens": ["Mu\u00df", "dei\u00b7ne", "See\u00b7le", "nicht", "klein", ",", "tr\u00e4g'", "und", "ir\u00b7disch", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPOSAT", "NN", "PTKNEG", "ADJD", "$,", "VVFIN", "KON", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Sei stets der Wahrheit hold, (sie nutzt vor tausend Sachen)", "tokens": ["Sei", "stets", "der", "Wahr\u00b7heit", "hold", ",", "(", "sie", "nutzt", "vor", "tau\u00b7send", "Sa\u00b7chen", ")"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "ADJD", "$,", "$(", "PPER", "ADV", "APPR", "CARD", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Und sch\u00e4me dich nicht, klug zu sein.", "tokens": ["Und", "sch\u00e4\u00b7me", "dich", "nicht", ",", "klug", "zu", "sein", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PTKNEG", "$,", "ADJD", "PTKZU", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Die Fabel, die ich dich jetzt lehre,", "tokens": ["Die", "Fa\u00b7bel", ",", "die", "ich", "dich", "jetzt", "leh\u00b7re", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "PRF", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Zeigt unsers P\u00f6bels Ekel an;", "tokens": ["Zeigt", "un\u00b7sers", "P\u00f6\u00b7bels", "E\u00b7kel", "an", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und dennoch bleibt es wahr: Ein reicher, weiser Mann", "tokens": ["Und", "den\u00b7noch", "bleibt", "es", "wahr", ":", "Ein", "rei\u00b7cher", ",", "wei\u00b7ser", "Mann"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "PPER", "PTKVZ", "$.", "ART", "ADJD", "$,", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ist zwiefach seiner Eltern Ehre.", "tokens": ["Ist", "zwie\u00b7fach", "sei\u00b7ner", "El\u00b7tern", "Eh\u00b7re", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Der Gott der Aerzt' und der Poeten", "tokens": ["Der", "Gott", "der", "A\u00b7e\u00b7rzt'", "und", "der", "Po\u00b7et\u00b7en"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "NN", "KON", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und Pallas wurden einst vom Himmel weggebannt,", "tokens": ["Und", "Pal\u00b7las", "wur\u00b7den", "einst", "vom", "Him\u00b7mel", "weg\u00b7ge\u00b7bannt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "VAFIN", "ADV", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die Ursach' ist noch unbekannt,", "tokens": ["Die", "Ur\u00b7sach'", "ist", "noch", "un\u00b7be\u00b7kannt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und scheint zu wissen nicht vonn\u00f6then.", "tokens": ["Und", "scheint", "zu", "wis\u00b7sen", "nicht", "von\u00b7n\u00f6\u00b7then", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKZU", "VVINF", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Als dieses Paar die Welt betrat,", "tokens": ["Als", "die\u00b7ses", "Paar", "die", "Welt", "be\u00b7trat", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDAT", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Beriethen beide sich, was bestens anzufangen?", "tokens": ["Be\u00b7rie\u00b7then", "bei\u00b7de", "sich", ",", "was", "bes\u00b7tens", "an\u00b7zu\u00b7fan\u00b7gen", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PRF", "$,", "PRELS", "ADV", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Apollo sprach: Ich schaffe Rath,", "tokens": ["A\u00b7pol\u00b7lo", "sprach", ":", "Ich", "schaf\u00b7fe", "Rath", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "$.", "PPER", "VVFIN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mein Lebens\u00f6l mu\u00df Brod erlangen.", "tokens": ["Mein", "Le\u00b7bens\u00b7\u00f6l", "mu\u00df", "Brod", "er\u00b7lan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VMFIN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Minerva rief frohlockend aus:", "tokens": ["Mi\u00b7ner\u00b7va", "rief", "froh\u00b7lo\u00b7ckend", "aus", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADJD", "PTKVZ", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.6": {"text": "Auch meiner Kunst bedarf ein jedes Haus.", "tokens": ["Auch", "mei\u00b7ner", "Kunst", "be\u00b7darf", "ein", "je\u00b7des", "Haus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "VVFIN", "ART", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.14": {"line.1": {"text": "Man waget den Versuch, und baut im n\u00e4chsten Orte", "tokens": ["Man", "wa\u00b7get", "den", "Ver\u00b7such", ",", "und", "baut", "im", "n\u00e4chs\u00b7ten", "Or\u00b7te"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "ART", "NN", "$,", "KON", "VVFIN", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Zwo gro\u00dfe Storgerb\u00fchnen auf.", "tokens": ["Zwo", "gro\u00b7\u00dfe", "Stor\u00b7ger\u00b7b\u00fch\u00b7nen", "auf", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["CARD", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Apollo hat, als Arzt, viel Herrliches zu Kauf,", "tokens": ["A\u00b7pol\u00b7lo", "hat", ",", "als", "Arzt", ",", "viel", "Herr\u00b7li\u00b7ches", "zu", "Kauf", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "$,", "KOUS", "NN", "$,", "PIAT", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und r\u00fchmet, was er hat, durch ausgesuchte Worte.", "tokens": ["Und", "r\u00fch\u00b7met", ",", "was", "er", "hat", ",", "durch", "aus\u00b7ge\u00b7such\u00b7te", "Wor\u00b7te", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "PWS", "PPER", "VAFIN", "$,", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Sein Wunderelixir, das alte Haut verj\u00fcngt,", "tokens": ["Sein", "Wun\u00b7de\u00b7re\u00b7li\u00b7xir", ",", "das", "al\u00b7te", "Haut", "ver\u00b7j\u00fcngt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Den \u00e4chten Theriac, die besten Augensalben,", "tokens": ["Den", "\u00e4ch\u00b7ten", "The\u00b7riac", ",", "die", "bes\u00b7ten", "Au\u00b7gen\u00b7sal\u00b7ben", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.7": {"text": "Ein Oel, das jede Krankheit zwingt,", "tokens": ["Ein", "O\u00b7el", ",", "das", "je\u00b7de", "Krank\u00b7heit", "zwingt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PIAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.8": {"text": "Und Apotheken g'nug, zu ganzen und zu halben.", "tokens": ["Und", "A\u00b7pot\u00b7he\u00b7ken", "g'\u00b7nug", ",", "zu", "gan\u00b7zen", "und", "zu", "hal\u00b7ben", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ADV", "$,", "APPR", "ADJA", "KON", "PTKZU", "VVINF", "$."], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}}, "stanza.15": {"line.1": {"text": "Die Tochter Jupiters nahm Seelen in die Cur,", "tokens": ["Die", "Toch\u00b7ter", "Ju\u00b7pi\u00b7ters", "nahm", "See\u00b7len", "in", "die", "Cur", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NE", "VVFIN", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Sie sprach: Mein Gegengift wehrt allen Vorurtheilen,", "tokens": ["Sie", "sprach", ":", "Mein", "Ge\u00b7gen\u00b7gift", "wehrt", "al\u00b7len", "Vor\u00b7urt\u00b7hei\u00b7len", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "PPOSAT", "NN", "VVFIN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Mein Weisheitbalsam ist die St\u00e4rkung der Natur;", "tokens": ["Mein", "Weis\u00b7heit\u00b7bal\u00b7sam", "ist", "die", "St\u00e4r\u00b7kung", "der", "Na\u00b7tur", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Er kann den schlimmsten Schaden heilen:", "tokens": ["Er", "kann", "den", "schlimms\u00b7ten", "Scha\u00b7den", "hei\u00b7len", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Des Aberglaubens Krebs, der viele Lehrer plagt,", "tokens": ["Des", "A\u00b7berg\u00b7lau\u00b7bens", "Krebs", ",", "der", "vie\u00b7le", "Leh\u00b7rer", "plagt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$,", "PRELS", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Die Ueppigkeit, die Zehrung ganzer Reiche,", "tokens": ["Die", "Uep\u00b7pig\u00b7keit", ",", "die", "Zeh\u00b7rung", "gan\u00b7zer", "Rei\u00b7che", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "ADJA", "NE", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Den Wurm des Widerspruchs, der Haubt und Zunge nagt,", "tokens": ["Den", "Wurm", "des", "Wi\u00b7der\u00b7spruchs", ",", "der", "Haubt", "und", "Zun\u00b7ge", "nagt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$,", "ART", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Den Neid, der kleinen Geister Seuche.", "tokens": ["Den", "Neid", ",", "der", "klei\u00b7nen", "Geis\u00b7ter", "Seu\u00b7che", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "Die Mittel, die ich zubereite,", "tokens": ["Die", "Mit\u00b7tel", ",", "die", "ich", "zu\u00b7be\u00b7rei\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Vertreiben unges\u00e4umt der Schw\u00e4tzer L\u00fcgensucht,", "tokens": ["Ver\u00b7trei\u00b7ben", "un\u00b7ge\u00b7s\u00e4umt", "der", "Schw\u00e4t\u00b7zer", "L\u00fc\u00b7gen\u00b7sucht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und die Vergessenheit, des rohen Undanks Frucht,", "tokens": ["Und", "die", "Ver\u00b7ges\u00b7sen\u00b7heit", ",", "des", "ro\u00b7hen", "Un\u00b7danks", "Frucht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "ART", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die Taubheit und den Kropf, die Krankheit gro\u00dfer Leute,", "tokens": ["Die", "Taub\u00b7heit", "und", "den", "Kropf", ",", "die", "Krank\u00b7heit", "gro\u00b7\u00dfer", "Leu\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "$,", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Des Geizes H\u00f6llendurst, der Einfalt Eigensinn,", "tokens": ["Des", "Gei\u00b7zes", "H\u00f6l\u00b7len\u00b7durst", ",", "der", "Ein\u00b7falt", "Ei\u00b7gen\u00b7sinn", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$,", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Den tilg' ich wundersam; so wahr ich Pallas bin!", "tokens": ["Den", "til\u00b7g'", "ich", "wun\u00b7der\u00b7sam", ";", "so", "wahr", "ich", "Pal\u00b7las", "bin", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPER", "ADJD", "$.", "ADV", "ADJD", "PPER", "NN", "VAFIN", "$."], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}, "line.7": {"text": "Auch nehm' ich die Bezahlung nur", "tokens": ["Auch", "nehm'", "ich", "die", "Be\u00b7zah\u00b7lung", "nur"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Nach gl\u00fccklich angeschlagner Cur.", "tokens": ["Nach", "gl\u00fcck\u00b7lich", "an\u00b7ge\u00b7schlag\u00b7ner", "Cur", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJD", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.17": {"line.1": {"text": "Apollo machte flei\u00dfig Kunden,", "tokens": ["A\u00b7pol\u00b7lo", "mach\u00b7te", "flei\u00b7\u00dfig", "Kun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADJD", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die arme Pallas hatte Ruh'.", "tokens": ["Die", "ar\u00b7me", "Pal\u00b7las", "hat\u00b7te", "Ruh'", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Nur ihm warf man das Schnupftuch zu,", "tokens": ["Nur", "ihm", "warf", "man", "das", "Schnupf\u00b7tuch", "zu", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VVFIN", "PIS", "ART", "NN", "PTKVZ", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.4": {"text": "Er rieth den Kranken und Gesunden.", "tokens": ["Er", "rieth", "den", "Kran\u00b7ken", "und", "Ge\u00b7sun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.18": {"line.1": {"text": "Wo wird die Weisheit Kranke finden?", "tokens": ["Wo", "wird", "die", "Weis\u00b7heit", "Kran\u00b7ke", "fin\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "ART", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ein jeder h\u00e4lt sich schon f\u00fcr klug,", "tokens": ["Ein", "je\u00b7der", "h\u00e4lt", "sich", "schon", "f\u00fcr", "klug", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VVFIN", "PRF", "ADV", "APPR", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Bescheiden, liebreich, fromm genug.", "tokens": ["Be\u00b7schei\u00b7den", ",", "lieb\u00b7reich", ",", "fromm", "ge\u00b7nug", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "ADJD", "$,", "ADJD", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der Hochmuth hilft ihm schon zu Gr\u00fcnden.", "tokens": ["Der", "Hoch\u00b7muth", "hilft", "ihm", "schon", "zu", "Gr\u00fcn\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADV", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}