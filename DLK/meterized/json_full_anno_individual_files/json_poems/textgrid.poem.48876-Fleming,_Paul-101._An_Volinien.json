{"textgrid.poem.48876": {"metadata": {"author": {"name": "Fleming, Paul", "birth": "N.A.", "death": "N.A."}, "title": "101. An Volinien", "genre": "verse", "period": "N.A.", "pub_year": 1624, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wenn ich, ", "tokens": ["Wenn", "ich", ","], "token_info": ["word", "word", "punct"], "pos": ["KOUS", "PPER", "$,"], "meter": "++", "measure": "spondeus"}, "line.2": {"text": "besinne deine Gunst und reiche Freundlichkeit,", "tokens": ["be\u00b7sin\u00b7ne", "dei\u00b7ne", "Gunst", "und", "rei\u00b7che", "Freund\u00b7lich\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "die du mir hast bezeigt so eine lange Zeit,", "tokens": ["die", "du", "mir", "hast", "be\u00b7zeigt", "so", "ei\u00b7ne", "lan\u00b7ge", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PPER", "VAFIN", "VVPP", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "und gegen dessen Wert mein armes Tun erw\u00e4ge,", "tokens": ["und", "ge\u00b7gen", "des\u00b7sen", "Wert", "mein", "ar\u00b7mes", "Tun", "er\u00b7w\u00e4\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PDS", "VAFIN", "PPOSAT", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "darmit ich dankbar bin, was Wunder, werd ich tr\u00e4ge,", "tokens": ["dar\u00b7mit", "ich", "dank\u00b7bar", "bin", ",", "was", "Wun\u00b7der", ",", "werd", "ich", "tr\u00e4\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "VAFIN", "$,", "PWS", "NN", "$,", "VAFIN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "zu treten vor das Licht? Es ist mir mehr als leid,", "tokens": ["zu", "tre\u00b7ten", "vor", "das", "Licht", "?", "Es", "ist", "mir", "mehr", "als", "leid", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "APPR", "ART", "NN", "$.", "PPER", "VAFIN", "PPER", "PIAT", "KOKOM", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "da\u00df ihr so ungeneigt, ihr harten G\u00f6tter, seid,", "tokens": ["da\u00df", "ihr", "so", "un\u00b7ge\u00b7neigt", ",", "ihr", "har\u00b7ten", "G\u00f6t\u00b7ter", ",", "seid", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "$,", "PPOSAT", "ADJA", "NN", "$,", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "der ich doch vor euch geh' auf einem reinen Stege.", "tokens": ["der", "ich", "doch", "vor", "euch", "geh'", "auf", "ei\u00b7nem", "rei\u00b7nen", "Ste\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "APPR", "PPER", "VVFIN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Nim dieses mein Sonnet zur Handschrift und zum Pfande,", "tokens": ["Nim", "die\u00b7ses", "mein", "Son\u00b7net", "zur", "Hand\u00b7schrift", "und", "zum", "Pfan\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PDAT", "PPOSAT", "NN", "APPRART", "NN", "KON", "APPRART", "NN", "$,"], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "da\u00df ich dein Schuldner bin, aus meinem Vaterlande,", "tokens": ["da\u00df", "ich", "dein", "Schuld\u00b7ner", "bin", ",", "aus", "mei\u00b7nem", "Va\u00b7ter\u00b7lan\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "VAFIN", "$,", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "von dem ich nun so weit und ach! wie lange! bin.", "tokens": ["von", "dem", "ich", "nun", "so", "weit", "und", "ach", "!", "wie", "lan\u00b7ge", "!", "bin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "ADV", "ADV", "ADJD", "KON", "XY", "$.", "PWAV", "ADV", "$.", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "und \u00fcber das Gestirn' in reinem Glanze gehen,", "tokens": ["und", "\u00fc\u00b7ber", "das", "Ge\u00b7stirn'", "in", "rei\u00b7nem", "Glan\u00b7ze", "ge\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "APPR", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "nach dem so mancher w\u00fcndscht und ich nur komme hin.", "tokens": ["nach", "dem", "so", "man\u00b7cher", "w\u00fcnd\u00b7scht", "und", "ich", "nur", "kom\u00b7me", "hin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADV", "PIS", "VVFIN", "KON", "PPER", "ADV", "VVFIN", "PTKVZ", "$."], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.5": {"line.1": {"text": "Wenn ich, ", "tokens": ["Wenn", "ich", ","], "token_info": ["word", "word", "punct"], "pos": ["KOUS", "PPER", "$,"], "meter": "++", "measure": "spondeus"}, "line.2": {"text": "besinne deine Gunst und reiche Freundlichkeit,", "tokens": ["be\u00b7sin\u00b7ne", "dei\u00b7ne", "Gunst", "und", "rei\u00b7che", "Freund\u00b7lich\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "die du mir hast bezeigt so eine lange Zeit,", "tokens": ["die", "du", "mir", "hast", "be\u00b7zeigt", "so", "ei\u00b7ne", "lan\u00b7ge", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PPER", "VAFIN", "VVPP", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "und gegen dessen Wert mein armes Tun erw\u00e4ge,", "tokens": ["und", "ge\u00b7gen", "des\u00b7sen", "Wert", "mein", "ar\u00b7mes", "Tun", "er\u00b7w\u00e4\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PDS", "VAFIN", "PPOSAT", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "darmit ich dankbar bin, was Wunder, werd ich tr\u00e4ge,", "tokens": ["dar\u00b7mit", "ich", "dank\u00b7bar", "bin", ",", "was", "Wun\u00b7der", ",", "werd", "ich", "tr\u00e4\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "VAFIN", "$,", "PWS", "NN", "$,", "VAFIN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "zu treten vor das Licht? Es ist mir mehr als leid,", "tokens": ["zu", "tre\u00b7ten", "vor", "das", "Licht", "?", "Es", "ist", "mir", "mehr", "als", "leid", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "APPR", "ART", "NN", "$.", "PPER", "VAFIN", "PPER", "PIAT", "KOKOM", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "da\u00df ihr so ungeneigt, ihr harten G\u00f6tter, seid,", "tokens": ["da\u00df", "ihr", "so", "un\u00b7ge\u00b7neigt", ",", "ihr", "har\u00b7ten", "G\u00f6t\u00b7ter", ",", "seid", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "$,", "PPOSAT", "ADJA", "NN", "$,", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "der ich doch vor euch geh' auf einem reinen Stege.", "tokens": ["der", "ich", "doch", "vor", "euch", "geh'", "auf", "ei\u00b7nem", "rei\u00b7nen", "Ste\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "APPR", "PPER", "VVFIN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Nim dieses mein Sonnet zur Handschrift und zum Pfande,", "tokens": ["Nim", "die\u00b7ses", "mein", "Son\u00b7net", "zur", "Hand\u00b7schrift", "und", "zum", "Pfan\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PDAT", "PPOSAT", "NN", "APPRART", "NN", "KON", "APPRART", "NN", "$,"], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "da\u00df ich dein Schuldner bin, aus meinem Vaterlande,", "tokens": ["da\u00df", "ich", "dein", "Schuld\u00b7ner", "bin", ",", "aus", "mei\u00b7nem", "Va\u00b7ter\u00b7lan\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "VAFIN", "$,", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "von dem ich nun so weit und ach! wie lange! bin.", "tokens": ["von", "dem", "ich", "nun", "so", "weit", "und", "ach", "!", "wie", "lan\u00b7ge", "!", "bin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "ADV", "ADV", "ADJD", "KON", "XY", "$.", "PWAV", "ADV", "$.", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "und \u00fcber das Gestirn' in reinem Glanze gehen,", "tokens": ["und", "\u00fc\u00b7ber", "das", "Ge\u00b7stirn'", "in", "rei\u00b7nem", "Glan\u00b7ze", "ge\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "APPR", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "nach dem so mancher w\u00fcndscht und ich nur komme hin.", "tokens": ["nach", "dem", "so", "man\u00b7cher", "w\u00fcnd\u00b7scht", "und", "ich", "nur", "kom\u00b7me", "hin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADV", "PIS", "VVFIN", "KON", "PPER", "ADV", "VVFIN", "PTKVZ", "$."], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}}}}}