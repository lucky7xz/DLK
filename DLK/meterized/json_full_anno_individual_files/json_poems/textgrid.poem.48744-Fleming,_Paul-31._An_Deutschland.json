{"textgrid.poem.48744": {"metadata": {"author": {"name": "Fleming, Paul", "birth": "N.A.", "death": "N.A."}, "title": "31. An Deutschland", "genre": "verse", "period": "N.A.", "pub_year": 1624, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ja Mutter, es ist wahr. Ich habe diese Zeit,", "tokens": ["Ja", "Mut\u00b7ter", ",", "es", "ist", "wahr", ".", "Ich", "ha\u00b7be", "die\u00b7se", "Zeit", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "NN", "$,", "PPER", "VAFIN", "ADJD", "$.", "PPER", "VAFIN", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "die Jugend mehr als faul und \u00fcbel angewendet.", "tokens": ["die", "Ju\u00b7gend", "mehr", "als", "faul", "und", "\u00fc\u00b7bel", "an\u00b7ge\u00b7wen\u00b7det", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PIAT", "KOKOM", "ADJD", "KON", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ich hab' es nicht getan, wie ich mich dir verpf\u00e4ndet.", "tokens": ["Ich", "hab'", "es", "nicht", "ge\u00b7tan", ",", "wie", "ich", "mich", "dir", "ver\u00b7pf\u00e4n\u00b7det", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "PTKNEG", "VVPP", "$,", "PWAV", "PPER", "PPER", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So lange bin ich aus und denke noch so weit.", "tokens": ["So", "lan\u00b7ge", "bin", "ich", "aus", "und", "den\u00b7ke", "noch", "so", "weit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VAFIN", "PPER", "PTKVZ", "KON", "VVFIN", "ADV", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Ach Mutter, z\u00fcrne nicht! Es ist mir mehr als leid,", "tokens": ["Ach", "Mut\u00b7ter", ",", "z\u00fcr\u00b7ne", "nicht", "!", "Es", "ist", "mir", "mehr", "als", "leid", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "NN", "$,", "VVFIN", "PTKNEG", "$.", "PPER", "VAFIN", "PPER", "PIAT", "KOKOM", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "der Vorwitz, dieser Mut hat mich zu sehr verblendet,", "tokens": ["der", "Vor\u00b7witz", ",", "die\u00b7ser", "Mut", "hat", "mich", "zu", "sehr", "ver\u00b7blen\u00b7det", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PDAT", "NN", "VAFIN", "PPER", "PTKA", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "nun hab' ich allzuweit von dir, Trost, abgel\u00e4ndet,", "tokens": ["nun", "hab'", "ich", "all\u00b7zu\u00b7weit", "von", "dir", ",", "Trost", ",", "ab\u00b7ge\u00b7l\u00e4n\u00b7det", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "APPR", "PPER", "$,", "NN", "$,", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "und kan es \u00e4ndern nicht, wie hoch es mich auch reut.", "tokens": ["und", "kan", "es", "\u00e4n\u00b7dern", "nicht", ",", "wie", "hoch", "es", "mich", "auch", "reut", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "VVINF", "PTKNEG", "$,", "PWAV", "ADJD", "PPER", "PRF", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Ich bin ein schwaches Boot ans gro\u00dfe Schiff gehangen,", "tokens": ["Ich", "bin", "ein", "schwa\u00b7ches", "Boot", "ans", "gro\u00b7\u00dfe", "Schiff", "ge\u00b7han\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "APPRART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "mu\u00df folgen, wie und wenn und wo man denkt hinaus,", "tokens": ["mu\u00df", "fol\u00b7gen", ",", "wie", "und", "wenn", "und", "wo", "man", "denkt", "hin\u00b7aus", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "VVINF", "$,", "PWAV", "KON", "KOUS", "KON", "PWAV", "PIS", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "ich wil gleich oder nicht. Es wird nichts anders draus.", "tokens": ["ich", "wil", "gleich", "o\u00b7der", "nicht", ".", "Es", "wird", "nichts", "an\u00b7ders", "draus", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "KON", "PTKNEG", "$.", "PPER", "VAFIN", "PIS", "ADV", "PAV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Indessen meine nicht, o du mein schwer Verlangen,", "tokens": ["In\u00b7des\u00b7sen", "mei\u00b7ne", "nicht", ",", "o", "du", "mein", "schwer", "Ver\u00b7lan\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PTKNEG", "$,", "FM", "PPER", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "ich denke nicht auf dich und was mir Frommen bringt.", "tokens": ["ich", "den\u00b7ke", "nicht", "auf", "dich", "und", "was", "mir", "From\u00b7men", "bringt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "APPR", "PPER", "KON", "PWS", "PPER", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der wonet \u00fcberall, der nach der Tugend ringt!", "tokens": ["Der", "wo\u00b7net", "\u00fc\u00b7be\u00b7rall", ",", "der", "nach", "der", "Tu\u00b7gend", "ringt", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "$,", "PRELS", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Ja Mutter, es ist wahr. Ich habe diese Zeit,", "tokens": ["Ja", "Mut\u00b7ter", ",", "es", "ist", "wahr", ".", "Ich", "ha\u00b7be", "die\u00b7se", "Zeit", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "NN", "$,", "PPER", "VAFIN", "ADJD", "$.", "PPER", "VAFIN", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "die Jugend mehr als faul und \u00fcbel angewendet.", "tokens": ["die", "Ju\u00b7gend", "mehr", "als", "faul", "und", "\u00fc\u00b7bel", "an\u00b7ge\u00b7wen\u00b7det", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PIAT", "KOKOM", "ADJD", "KON", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ich hab' es nicht getan, wie ich mich dir verpf\u00e4ndet.", "tokens": ["Ich", "hab'", "es", "nicht", "ge\u00b7tan", ",", "wie", "ich", "mich", "dir", "ver\u00b7pf\u00e4n\u00b7det", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "PTKNEG", "VVPP", "$,", "PWAV", "PPER", "PPER", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So lange bin ich aus und denke noch so weit.", "tokens": ["So", "lan\u00b7ge", "bin", "ich", "aus", "und", "den\u00b7ke", "noch", "so", "weit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VAFIN", "PPER", "PTKVZ", "KON", "VVFIN", "ADV", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Ach Mutter, z\u00fcrne nicht! Es ist mir mehr als leid,", "tokens": ["Ach", "Mut\u00b7ter", ",", "z\u00fcr\u00b7ne", "nicht", "!", "Es", "ist", "mir", "mehr", "als", "leid", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "NN", "$,", "VVFIN", "PTKNEG", "$.", "PPER", "VAFIN", "PPER", "PIAT", "KOKOM", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "der Vorwitz, dieser Mut hat mich zu sehr verblendet,", "tokens": ["der", "Vor\u00b7witz", ",", "die\u00b7ser", "Mut", "hat", "mich", "zu", "sehr", "ver\u00b7blen\u00b7det", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PDAT", "NN", "VAFIN", "PPER", "PTKA", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "nun hab' ich allzuweit von dir, Trost, abgel\u00e4ndet,", "tokens": ["nun", "hab'", "ich", "all\u00b7zu\u00b7weit", "von", "dir", ",", "Trost", ",", "ab\u00b7ge\u00b7l\u00e4n\u00b7det", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "APPR", "PPER", "$,", "NN", "$,", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "und kan es \u00e4ndern nicht, wie hoch es mich auch reut.", "tokens": ["und", "kan", "es", "\u00e4n\u00b7dern", "nicht", ",", "wie", "hoch", "es", "mich", "auch", "reut", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "VVINF", "PTKNEG", "$,", "PWAV", "ADJD", "PPER", "PRF", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Ich bin ein schwaches Boot ans gro\u00dfe Schiff gehangen,", "tokens": ["Ich", "bin", "ein", "schwa\u00b7ches", "Boot", "ans", "gro\u00b7\u00dfe", "Schiff", "ge\u00b7han\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "APPRART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "mu\u00df folgen, wie und wenn und wo man denkt hinaus,", "tokens": ["mu\u00df", "fol\u00b7gen", ",", "wie", "und", "wenn", "und", "wo", "man", "denkt", "hin\u00b7aus", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "VVINF", "$,", "PWAV", "KON", "KOUS", "KON", "PWAV", "PIS", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "ich wil gleich oder nicht. Es wird nichts anders draus.", "tokens": ["ich", "wil", "gleich", "o\u00b7der", "nicht", ".", "Es", "wird", "nichts", "an\u00b7ders", "draus", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "KON", "PTKNEG", "$.", "PPER", "VAFIN", "PIS", "ADV", "PAV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "Indessen meine nicht, o du mein schwer Verlangen,", "tokens": ["In\u00b7des\u00b7sen", "mei\u00b7ne", "nicht", ",", "o", "du", "mein", "schwer", "Ver\u00b7lan\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PTKNEG", "$,", "FM", "PPER", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "ich denke nicht auf dich und was mir Frommen bringt.", "tokens": ["ich", "den\u00b7ke", "nicht", "auf", "dich", "und", "was", "mir", "From\u00b7men", "bringt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "APPR", "PPER", "KON", "PWS", "PPER", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der wonet \u00fcberall, der nach der Tugend ringt!", "tokens": ["Der", "wo\u00b7net", "\u00fc\u00b7be\u00b7rall", ",", "der", "nach", "der", "Tu\u00b7gend", "ringt", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "$,", "PRELS", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}