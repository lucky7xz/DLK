{"textgrid.poem.36952": {"metadata": {"author": {"name": "Gla\u00dfbrenner, Adolf", "birth": "N.A.", "death": "N.A."}, "title": "1L: Es zog ein L\u00fcderjan \u00fcber das Feld;", "genre": "verse", "period": "N.A.", "pub_year": 1843, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Es zog ein L\u00fcderjan \u00fcber das Feld;", "tokens": ["Es", "zog", "ein", "L\u00fc\u00b7der\u00b7jan", "\u00fc\u00b7ber", "das", "Feld", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Der hatt' einen Beutel und hatte kein Geld,", "tokens": ["Der", "hatt'", "ei\u00b7nen", "Beu\u00b7tel", "und", "hat\u00b7te", "kein", "Geld", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "KON", "VAFIN", "PIAT", "NN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.3": {"text": "Er wird es wohl bekommen!", "tokens": ["Er", "wird", "es", "wohl", "be\u00b7kom\u00b7men", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Und als er kam in die gro\u00dfe Stadt,", "tokens": ["Und", "als", "er", "kam", "in", "die", "gro\u00b7\u00dfe", "Stadt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "VVFIN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Er weder Speise noch Obdach hatt'.", "tokens": ["Er", "we\u00b7der", "Spei\u00b7se", "noch", "Ob\u00b7dach", "hatt'", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "KON", "NN", "ADV", "NN", "VAFIN", "$."], "meter": "-+-+--++-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Es wird sich Alles finden!", "tokens": ["Es", "wird", "sich", "Al\u00b7les", "fin\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PRF", "PIS", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "\u00bbwas treibst Du umher dich als L\u00fcderjan?", "tokens": ["\u00bb", "was", "treibst", "Du", "um\u00b7her", "dich", "als", "L\u00fc\u00b7der\u00b7jan", "?"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "VVFIN", "PPER", "PTKVZ", "PPER", "KOUS", "NE", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Sollst j\u00e4hrlich Dreihundert Thaler ha'n,", "tokens": ["Sollst", "j\u00e4hr\u00b7lich", "Drei\u00b7hun\u00b7dert", "Tha\u00b7ler", "ha'n", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADJD", "CARD", "NN", "NE", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Wenn du willst Censor werden.\u00ab", "tokens": ["Wenn", "du", "willst", "Cen\u00b7sor", "wer\u00b7den", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PPER", "VMFIN", "NN", "VAINF", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Nein, f\u00fcr Dreihundert Thaler das Jahr,", "tokens": ["Nein", ",", "f\u00fcr", "Drei\u00b7hun\u00b7dert", "Tha\u00b7ler", "das", "Jahr", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "APPR", "CARD", "NN", "ART", "NN", "$,"], "meter": "+-+--+--+", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Da werd' ich nicht aller Ehren bar,", "tokens": ["Da", "werd'", "ich", "nicht", "al\u00b7ler", "Eh\u00b7ren", "bar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PTKNEG", "PIAT", "NN", "ADJD", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Will ich mich nicht beschimpfen.", "tokens": ["Will", "ich", "mich", "nicht", "be\u00b7schimp\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PRF", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "\u00bbwas treibst Du umher dich als L\u00fcderjan?", "tokens": ["\u00bb", "was", "treibst", "Du", "um\u00b7her", "dich", "als", "L\u00fc\u00b7der\u00b7jan", "?"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "VVFIN", "PPER", "PTKVZ", "PPER", "KOUS", "NE", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Sollst j\u00e4hrlich Sechshundert Thaler ha'n,", "tokens": ["Sollst", "j\u00e4hr\u00b7lich", "Sechs\u00b7hun\u00b7dert", "Tha\u00b7ler", "ha'n", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADJD", "CARD", "NN", "NE", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Wenn du willst Censor werden.\u00ab", "tokens": ["Wenn", "du", "willst", "Cen\u00b7sor", "wer\u00b7den", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PPER", "VMFIN", "NN", "VAINF", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "F\u00fcr Sechshundert Thaler thu' ich es Euch,", "tokens": ["F\u00fcr", "Sechs\u00b7hun\u00b7dert", "Tha\u00b7ler", "thu'", "ich", "es", "Euch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "CARD", "NN", "VVFIN", "PPER", "PPER", "PPER", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Da ist mir Ehre und Schande gleich,", "tokens": ["Da", "ist", "mir", "Eh\u00b7re", "und", "Schan\u00b7de", "gleich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "NN", "KON", "NN", "ADV", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Da will ich Censor werden.", "tokens": ["Da", "will", "ich", "Cen\u00b7sor", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "NN", "VAINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Du Censor, du Henker, du M\u00f6rder, du Dieb!", "tokens": ["Du", "Cen\u00b7sor", ",", "du", "Hen\u00b7ker", ",", "du", "M\u00f6r\u00b7der", ",", "du", "Dieb", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "NN", "$,", "PPER", "NN", "$,", "PPER", "NN", "$,", "PPER", "NN", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "Kein Mensch mag dich achten, kein Mensch hat dich lieb,", "tokens": ["Kein", "Mensch", "mag", "dich", "ach\u00b7ten", ",", "kein", "Mensch", "hat", "dich", "lieb", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VMFIN", "PRF", "VVINF", "$,", "PIAT", "NN", "VAFIN", "PPER", "ADJD", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.3": {"text": "F\u00fcr die Sechshundert Thaler!", "tokens": ["F\u00fcr", "die", "Sechs\u00b7hun\u00b7dert", "Tha\u00b7ler", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "CARD", "NN", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}}, "stanza.8": {"line.1": {"text": "Es zog ein L\u00fcderjan \u00fcber das Feld;", "tokens": ["Es", "zog", "ein", "L\u00fc\u00b7der\u00b7jan", "\u00fc\u00b7ber", "das", "Feld", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Der hatt' einen Beutel und hatte kein Geld,", "tokens": ["Der", "hatt'", "ei\u00b7nen", "Beu\u00b7tel", "und", "hat\u00b7te", "kein", "Geld", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "KON", "VAFIN", "PIAT", "NN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.3": {"text": "Er wird es wohl bekommen!", "tokens": ["Er", "wird", "es", "wohl", "be\u00b7kom\u00b7men", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Und als er kam in die gro\u00dfe Stadt,", "tokens": ["Und", "als", "er", "kam", "in", "die", "gro\u00b7\u00dfe", "Stadt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "VVFIN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Er weder Speise noch Obdach hatt'.", "tokens": ["Er", "we\u00b7der", "Spei\u00b7se", "noch", "Ob\u00b7dach", "hatt'", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "KON", "NN", "ADV", "NN", "VAFIN", "$."], "meter": "-+-+--++-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Es wird sich Alles finden!", "tokens": ["Es", "wird", "sich", "Al\u00b7les", "fin\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PRF", "PIS", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "\u00bbwas treibst Du umher dich als L\u00fcderjan?", "tokens": ["\u00bb", "was", "treibst", "Du", "um\u00b7her", "dich", "als", "L\u00fc\u00b7der\u00b7jan", "?"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "VVFIN", "PPER", "PTKVZ", "PPER", "KOUS", "NE", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Sollst j\u00e4hrlich Dreihundert Thaler ha'n,", "tokens": ["Sollst", "j\u00e4hr\u00b7lich", "Drei\u00b7hun\u00b7dert", "Tha\u00b7ler", "ha'n", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADJD", "CARD", "NN", "NE", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Wenn du willst Censor werden.\u00ab", "tokens": ["Wenn", "du", "willst", "Cen\u00b7sor", "wer\u00b7den", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PPER", "VMFIN", "NN", "VAINF", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "Nein, f\u00fcr Dreihundert Thaler das Jahr,", "tokens": ["Nein", ",", "f\u00fcr", "Drei\u00b7hun\u00b7dert", "Tha\u00b7ler", "das", "Jahr", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "APPR", "CARD", "NN", "ART", "NN", "$,"], "meter": "+-+--+--+", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Da werd' ich nicht aller Ehren bar,", "tokens": ["Da", "werd'", "ich", "nicht", "al\u00b7ler", "Eh\u00b7ren", "bar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PTKNEG", "PIAT", "NN", "ADJD", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Will ich mich nicht beschimpfen.", "tokens": ["Will", "ich", "mich", "nicht", "be\u00b7schimp\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PRF", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "\u00bbwas treibst Du umher dich als L\u00fcderjan?", "tokens": ["\u00bb", "was", "treibst", "Du", "um\u00b7her", "dich", "als", "L\u00fc\u00b7der\u00b7jan", "?"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "VVFIN", "PPER", "PTKVZ", "PPER", "KOUS", "NE", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Sollst j\u00e4hrlich Sechshundert Thaler ha'n,", "tokens": ["Sollst", "j\u00e4hr\u00b7lich", "Sechs\u00b7hun\u00b7dert", "Tha\u00b7ler", "ha'n", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADJD", "CARD", "NN", "NE", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Wenn du willst Censor werden.\u00ab", "tokens": ["Wenn", "du", "willst", "Cen\u00b7sor", "wer\u00b7den", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PPER", "VMFIN", "NN", "VAINF", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.13": {"line.1": {"text": "F\u00fcr Sechshundert Thaler thu' ich es Euch,", "tokens": ["F\u00fcr", "Sechs\u00b7hun\u00b7dert", "Tha\u00b7ler", "thu'", "ich", "es", "Euch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "CARD", "NN", "VVFIN", "PPER", "PPER", "PPER", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Da ist mir Ehre und Schande gleich,", "tokens": ["Da", "ist", "mir", "Eh\u00b7re", "und", "Schan\u00b7de", "gleich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "NN", "KON", "NN", "ADV", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Da will ich Censor werden.", "tokens": ["Da", "will", "ich", "Cen\u00b7sor", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "NN", "VAINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.14": {"line.1": {"text": "Du Censor, du Henker, du M\u00f6rder, du Dieb!", "tokens": ["Du", "Cen\u00b7sor", ",", "du", "Hen\u00b7ker", ",", "du", "M\u00f6r\u00b7der", ",", "du", "Dieb", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "NN", "$,", "PPER", "NN", "$,", "PPER", "NN", "$,", "PPER", "NN", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "Kein Mensch mag dich achten, kein Mensch hat dich lieb,", "tokens": ["Kein", "Mensch", "mag", "dich", "ach\u00b7ten", ",", "kein", "Mensch", "hat", "dich", "lieb", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VMFIN", "PRF", "VVINF", "$,", "PIAT", "NN", "VAFIN", "PPER", "ADJD", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.3": {"text": "F\u00fcr die Sechshundert Thaler!", "tokens": ["F\u00fcr", "die", "Sechs\u00b7hun\u00b7dert", "Tha\u00b7ler", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "CARD", "NN", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}}}}}