{"textgrid.poem.57497": {"metadata": {"author": {"name": "Gottsched, Johann Christoph", "birth": "N.A.", "death": "N.A."}, "title": "1L: Mein Freund! dein Jahrfest k\u00f6mmt, und lehrt mich meine Pflicht;", "genre": "verse", "period": "N.A.", "pub_year": 1733, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Mein Freund! dein Jahrfest k\u00f6mmt, und lehrt mich meine Pflicht;", "tokens": ["Mein", "Freund", "!", "dein", "Jahr\u00b7fest", "k\u00f6mmt", ",", "und", "lehrt", "mich", "mei\u00b7ne", "Pflicht", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$.", "PPOSAT", "NN", "VVFIN", "$,", "KON", "VVFIN", "PPER", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ich opfre dir dabey kein gro\u00dfes Lobgedicht:", "tokens": ["Ich", "opf\u00b7re", "dir", "da\u00b7bey", "kein", "gro\u00b7\u00dfes", "Lob\u00b7ge\u00b7dicht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PAV", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Du hast dergleichen schon von meinem Kiel vernommen,", "tokens": ["Du", "hast", "derg\u00b7lei\u00b7chen", "schon", "von", "mei\u00b7nem", "Kiel", "ver\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIS", "ADV", "APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und manches wird vielleicht bis auf die Nachwelt kommen.", "tokens": ["Und", "man\u00b7ches", "wird", "viel\u00b7leicht", "bis", "auf", "die", "Nach\u00b7welt", "kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VAFIN", "ADV", "ADV", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ich liefre dir voritzt was Uebersetztes ein,", "tokens": ["Ich", "lief\u00b7re", "dir", "vo\u00b7ritzt", "was", "Ue\u00b7ber\u00b7setz\u00b7tes", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "VVFIN", "PIS", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Das soll ein Ehrenmaal von deinem Tage seyn;", "tokens": ["Das", "soll", "ein", "Eh\u00b7ren\u00b7maal", "von", "dei\u00b7nem", "Ta\u00b7ge", "seyn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "ART", "NN", "APPR", "PPOSAT", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Ein ewiger Beweis von unsern Freundschaftstrieben,", "tokens": ["Ein", "e\u00b7wi\u00b7ger", "Be\u00b7weis", "von", "un\u00b7sern", "Freund\u00b7schaft\u00b7strie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Dadurch wir uns bisher aus reiner Absicht lieben.", "tokens": ["Da\u00b7durch", "wir", "uns", "bis\u00b7her", "aus", "rei\u00b7ner", "Ab\u00b7sicht", "lie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PPER", "PRF", "ADV", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Hier wiederhohl ich nur den l\u00e4ngstgeschlo\u00dfnen Bund,", "tokens": ["Hier", "wie\u00b7der\u00b7hohl", "ich", "nur", "den", "l\u00e4ngst\u00b7ge\u00b7schlo\u00df\u00b7nen", "Bund", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PPER", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und mache durch die\u00df Blatt vor hundert Zeugen kund:", "tokens": ["Und", "ma\u00b7che", "durch", "die\u00df", "Blatt", "vor", "hun\u00b7dert", "Zeu\u00b7gen", "kund", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PDS", "NN", "APPR", "CARD", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Da\u00df Weisheit und Vernunft, durch dein unstr\u00e4flich Leben,", "tokens": ["Da\u00df", "Weis\u00b7heit", "und", "Ver\u00b7nunft", ",", "durch", "dein", "uns\u00b7tr\u00e4f\u00b7lich", "Le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "NN", "$,", "APPR", "PPOSAT", "ADJD", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Dem Haufen, der sie schm\u00e4ht, ein Tugendmuster geben,", "tokens": ["Dem", "Hau\u00b7fen", ",", "der", "sie", "schm\u00e4ht", ",", "ein", "Tu\u00b7gend\u00b7mus\u00b7ter", "ge\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Dabey er schamroth wird. Du legest Proben ab,", "tokens": ["Da\u00b7bey", "er", "scham\u00b7roth", "wird", ".", "Du", "le\u00b7gest", "Pro\u00b7ben", "ab", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "VAFIN", "$.", "PPER", "VVFIN", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Da\u00df Gott uns nicht umsonst Verstand und Willen gab;", "tokens": ["Da\u00df", "Gott", "uns", "nicht", "um\u00b7sonst", "Ver\u00b7stand", "und", "Wil\u00b7len", "gab", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "PPER", "PTKNEG", "ADV", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und da\u00df ein heitrer Geist, durch ein gegr\u00fcndet Wissen,", "tokens": ["Und", "da\u00df", "ein", "hei\u00b7trer", "Geist", ",", "durch", "ein", "ge\u00b7gr\u00fcn\u00b7det", "Wis\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "ADJA", "NN", "$,", "APPR", "ART", "VVPP", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Nachdem er sich beherzt des P\u00f6bels Wahn entrissen,", "tokens": ["Nach\u00b7dem", "er", "sich", "be\u00b7herzt", "des", "P\u00f6\u00b7bels", "Wahn", "ent\u00b7ris\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ADJD", "ART", "NN", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Auch Thaten \u00fcben kann, die sonder Tadel sind.", "tokens": ["Auch", "Tha\u00b7ten", "\u00fc\u00b7ben", "kann", ",", "die", "son\u00b7der", "Ta\u00b7del", "sind", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "VVINF", "VMFIN", "$,", "ART", "ADJA", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Denn ist schon die Vernunft in Glaubenssachen blind;", "tokens": ["Denn", "ist", "schon", "die", "Ver\u00b7nunft", "in", "Glau\u00b7bens\u00b7sa\u00b7chen", "blind", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "ART", "NN", "APPR", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "So lehrt sie doch sehr wohl, der Menschen Thun und Lassen,", "tokens": ["So", "lehrt", "sie", "doch", "sehr", "wohl", ",", "der", "Men\u00b7schen", "Thun", "und", "Las\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ADV", "ADV", "$,", "ART", "NN", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Wenn man nur selber will, nach Tugendregeln fassen.", "tokens": ["Wenn", "man", "nur", "sel\u00b7ber", "will", ",", "nach", "Tu\u00b7gend\u00b7re\u00b7geln", "fas\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ADV", "ADV", "VMFIN", "$,", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Dein stiller Wandel zwar erscheint nicht \u00f6ffentlich;", "tokens": ["Dein", "stil\u00b7ler", "Wan\u00b7del", "zwar", "er\u00b7scheint", "nicht", "\u00f6f\u00b7fent\u00b7lich", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "ADV", "VVFIN", "PTKNEG", "ADJD", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.14": {"text": "Du hast kein gro\u00dfes Amt: denn wer gedenkt an dich?", "tokens": ["Du", "hast", "kein", "gro\u00b7\u00dfes", "Amt", ":", "denn", "wer", "ge\u00b7denkt", "an", "dich", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIAT", "ADJA", "NN", "$.", "KON", "PWS", "VVFIN", "APPR", "PPER", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Da du die Kunst nicht kannst, durch Betteln, Flehn und H\u00e4ucheln,", "tokens": ["Da", "du", "die", "Kunst", "nicht", "kannst", ",", "durch", "Bet\u00b7teln", ",", "Flehn", "und", "H\u00e4u\u00b7cheln", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "PTKNEG", "VMFIN", "$,", "APPR", "NN", "$,", "VVFIN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Den Gro\u00dfen in der Welt den Beystand abzuschm\u00e4ucheln.", "tokens": ["Den", "Gro\u00b7\u00dfen", "in", "der", "Welt", "den", "Beys\u00b7tand", "ab\u00b7zu\u00b7schm\u00e4u\u00b7cheln", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "ART", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Allein, du n\u00fctzest viel; indem du dich bem\u00fchst,", "tokens": ["Al\u00b7lein", ",", "du", "n\u00fct\u00b7zest", "viel", ";", "in\u00b7dem", "du", "dich", "be\u00b7m\u00fchst", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PPER", "VVFIN", "ADV", "$.", "KOUS", "PPER", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Der Zeit, die nach uns k\u00f6mmt, geschickte B\u00fcrger ziehst,", "tokens": ["Der", "Zeit", ",", "die", "nach", "uns", "k\u00f6mmt", ",", "ge\u00b7schick\u00b7te", "B\u00fcr\u00b7ger", "ziehst", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "APPR", "PPER", "VVFIN", "$,", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Die Jugend K\u00fcnste lehrst; und tausend Lust empfindest,", "tokens": ["Die", "Ju\u00b7gend", "K\u00fcns\u00b7te", "lehrst", ";", "und", "tau\u00b7send", "Lust", "emp\u00b7fin\u00b7dest", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "$.", "KON", "CARD", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Wenn du in einer Brust der Tugend Trieb entz\u00fcndest.", "tokens": ["Wenn", "du", "in", "ei\u00b7ner", "Brust", "der", "Tu\u00b7gend", "Trieb", "ent\u00b7z\u00fcn\u00b7dest", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ART", "NN", "ART", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Genug zu deinem Ruhm! Nun lies einmal die\u00df Blatt!", "tokens": ["Ge\u00b7nug", "zu", "dei\u00b7nem", "Ruhm", "!", "Nun", "lies", "ein\u00b7mal", "die\u00df", "Blatt", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPOSAT", "NN", "$.", "ADV", "VVFIN", "ADV", "PDS", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Das dir mein Kiel geweiht und zugeschrieben hat.", "tokens": ["Das", "dir", "mein", "Kiel", "ge\u00b7weiht", "und", "zu\u00b7ge\u00b7schrie\u00b7ben", "hat", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "PPOSAT", "NE", "VVPP", "KON", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Du pflegst die Redekunst und Weisheit zu verbinden,", "tokens": ["Du", "pflegst", "die", "Re\u00b7de\u00b7kunst", "und", "Weis\u00b7heit", "zu", "ver\u00b7bin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "KON", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und wirst auch hier die Spur der alten Redner finden,", "tokens": ["Und", "wirst", "auch", "hier", "die", "Spur", "der", "al\u00b7ten", "Red\u00b7ner", "fin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "ADV", "ART", "NN", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die ", "tokens": ["Die"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}, "line.6": {"text": "Und wenn er sp\u00f6ttisch schrieb, so ists doch sonnenklar,", "tokens": ["Und", "wenn", "er", "sp\u00f6t\u00b7tisch", "schrieb", ",", "so", "ists", "doch", "son\u00b7nen\u00b7klar", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADJD", "VVFIN", "$,", "ADV", "VAFIN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und jede Schrift von ihm l\u00e4\u00dft gar zu deutlich lesen;", "tokens": ["Und", "je\u00b7de", "Schrift", "von", "ihm", "l\u00e4\u00dft", "gar", "zu", "deut\u00b7lich", "le\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "APPR", "PPER", "VVFIN", "ADV", "PTKA", "ADJD", "VVINF", "$."], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.8": {"text": "Da\u00df er der Weisheit hold, der Thorheit feind gewesen.", "tokens": ["Da\u00df", "er", "der", "Weis\u00b7heit", "hold", ",", "der", "Thor\u00b7heit", "feind", "ge\u00b7we\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "ADJD", "$,", "ART", "NN", "NN", "VAPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Mein Freund! dein Jahrfest k\u00f6mmt, und lehrt mich meine Pflicht;", "tokens": ["Mein", "Freund", "!", "dein", "Jahr\u00b7fest", "k\u00f6mmt", ",", "und", "lehrt", "mich", "mei\u00b7ne", "Pflicht", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$.", "PPOSAT", "NN", "VVFIN", "$,", "KON", "VVFIN", "PPER", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ich opfre dir dabey kein gro\u00dfes Lobgedicht:", "tokens": ["Ich", "opf\u00b7re", "dir", "da\u00b7bey", "kein", "gro\u00b7\u00dfes", "Lob\u00b7ge\u00b7dicht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PAV", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Du hast dergleichen schon von meinem Kiel vernommen,", "tokens": ["Du", "hast", "derg\u00b7lei\u00b7chen", "schon", "von", "mei\u00b7nem", "Kiel", "ver\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIS", "ADV", "APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und manches wird vielleicht bis auf die Nachwelt kommen.", "tokens": ["Und", "man\u00b7ches", "wird", "viel\u00b7leicht", "bis", "auf", "die", "Nach\u00b7welt", "kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VAFIN", "ADV", "ADV", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ich liefre dir voritzt was Uebersetztes ein,", "tokens": ["Ich", "lief\u00b7re", "dir", "vo\u00b7ritzt", "was", "Ue\u00b7ber\u00b7setz\u00b7tes", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "VVFIN", "PIS", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Das soll ein Ehrenmaal von deinem Tage seyn;", "tokens": ["Das", "soll", "ein", "Eh\u00b7ren\u00b7maal", "von", "dei\u00b7nem", "Ta\u00b7ge", "seyn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "ART", "NN", "APPR", "PPOSAT", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Ein ewiger Beweis von unsern Freundschaftstrieben,", "tokens": ["Ein", "e\u00b7wi\u00b7ger", "Be\u00b7weis", "von", "un\u00b7sern", "Freund\u00b7schaft\u00b7strie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Dadurch wir uns bisher aus reiner Absicht lieben.", "tokens": ["Da\u00b7durch", "wir", "uns", "bis\u00b7her", "aus", "rei\u00b7ner", "Ab\u00b7sicht", "lie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PPER", "PRF", "ADV", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Hier wiederhohl ich nur den l\u00e4ngstgeschlo\u00dfnen Bund,", "tokens": ["Hier", "wie\u00b7der\u00b7hohl", "ich", "nur", "den", "l\u00e4ngst\u00b7ge\u00b7schlo\u00df\u00b7nen", "Bund", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PPER", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und mache durch die\u00df Blatt vor hundert Zeugen kund:", "tokens": ["Und", "ma\u00b7che", "durch", "die\u00df", "Blatt", "vor", "hun\u00b7dert", "Zeu\u00b7gen", "kund", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PDS", "NN", "APPR", "CARD", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Da\u00df Weisheit und Vernunft, durch dein unstr\u00e4flich Leben,", "tokens": ["Da\u00df", "Weis\u00b7heit", "und", "Ver\u00b7nunft", ",", "durch", "dein", "uns\u00b7tr\u00e4f\u00b7lich", "Le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "NN", "$,", "APPR", "PPOSAT", "ADJD", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Dem Haufen, der sie schm\u00e4ht, ein Tugendmuster geben,", "tokens": ["Dem", "Hau\u00b7fen", ",", "der", "sie", "schm\u00e4ht", ",", "ein", "Tu\u00b7gend\u00b7mus\u00b7ter", "ge\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Dabey er schamroth wird. Du legest Proben ab,", "tokens": ["Da\u00b7bey", "er", "scham\u00b7roth", "wird", ".", "Du", "le\u00b7gest", "Pro\u00b7ben", "ab", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "VAFIN", "$.", "PPER", "VVFIN", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Da\u00df Gott uns nicht umsonst Verstand und Willen gab;", "tokens": ["Da\u00df", "Gott", "uns", "nicht", "um\u00b7sonst", "Ver\u00b7stand", "und", "Wil\u00b7len", "gab", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "PPER", "PTKNEG", "ADV", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und da\u00df ein heitrer Geist, durch ein gegr\u00fcndet Wissen,", "tokens": ["Und", "da\u00df", "ein", "hei\u00b7trer", "Geist", ",", "durch", "ein", "ge\u00b7gr\u00fcn\u00b7det", "Wis\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "ADJA", "NN", "$,", "APPR", "ART", "VVPP", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Nachdem er sich beherzt des P\u00f6bels Wahn entrissen,", "tokens": ["Nach\u00b7dem", "er", "sich", "be\u00b7herzt", "des", "P\u00f6\u00b7bels", "Wahn", "ent\u00b7ris\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ADJD", "ART", "NN", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Auch Thaten \u00fcben kann, die sonder Tadel sind.", "tokens": ["Auch", "Tha\u00b7ten", "\u00fc\u00b7ben", "kann", ",", "die", "son\u00b7der", "Ta\u00b7del", "sind", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "VVINF", "VMFIN", "$,", "ART", "ADJA", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Denn ist schon die Vernunft in Glaubenssachen blind;", "tokens": ["Denn", "ist", "schon", "die", "Ver\u00b7nunft", "in", "Glau\u00b7bens\u00b7sa\u00b7chen", "blind", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "ART", "NN", "APPR", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "So lehrt sie doch sehr wohl, der Menschen Thun und Lassen,", "tokens": ["So", "lehrt", "sie", "doch", "sehr", "wohl", ",", "der", "Men\u00b7schen", "Thun", "und", "Las\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ADV", "ADV", "$,", "ART", "NN", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Wenn man nur selber will, nach Tugendregeln fassen.", "tokens": ["Wenn", "man", "nur", "sel\u00b7ber", "will", ",", "nach", "Tu\u00b7gend\u00b7re\u00b7geln", "fas\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ADV", "ADV", "VMFIN", "$,", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Dein stiller Wandel zwar erscheint nicht \u00f6ffentlich;", "tokens": ["Dein", "stil\u00b7ler", "Wan\u00b7del", "zwar", "er\u00b7scheint", "nicht", "\u00f6f\u00b7fent\u00b7lich", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "ADV", "VVFIN", "PTKNEG", "ADJD", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.14": {"text": "Du hast kein gro\u00dfes Amt: denn wer gedenkt an dich?", "tokens": ["Du", "hast", "kein", "gro\u00b7\u00dfes", "Amt", ":", "denn", "wer", "ge\u00b7denkt", "an", "dich", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIAT", "ADJA", "NN", "$.", "KON", "PWS", "VVFIN", "APPR", "PPER", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Da du die Kunst nicht kannst, durch Betteln, Flehn und H\u00e4ucheln,", "tokens": ["Da", "du", "die", "Kunst", "nicht", "kannst", ",", "durch", "Bet\u00b7teln", ",", "Flehn", "und", "H\u00e4u\u00b7cheln", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "PTKNEG", "VMFIN", "$,", "APPR", "NN", "$,", "VVFIN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Den Gro\u00dfen in der Welt den Beystand abzuschm\u00e4ucheln.", "tokens": ["Den", "Gro\u00b7\u00dfen", "in", "der", "Welt", "den", "Beys\u00b7tand", "ab\u00b7zu\u00b7schm\u00e4u\u00b7cheln", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "ART", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Allein, du n\u00fctzest viel; indem du dich bem\u00fchst,", "tokens": ["Al\u00b7lein", ",", "du", "n\u00fct\u00b7zest", "viel", ";", "in\u00b7dem", "du", "dich", "be\u00b7m\u00fchst", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PPER", "VVFIN", "ADV", "$.", "KOUS", "PPER", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Der Zeit, die nach uns k\u00f6mmt, geschickte B\u00fcrger ziehst,", "tokens": ["Der", "Zeit", ",", "die", "nach", "uns", "k\u00f6mmt", ",", "ge\u00b7schick\u00b7te", "B\u00fcr\u00b7ger", "ziehst", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "APPR", "PPER", "VVFIN", "$,", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Die Jugend K\u00fcnste lehrst; und tausend Lust empfindest,", "tokens": ["Die", "Ju\u00b7gend", "K\u00fcns\u00b7te", "lehrst", ";", "und", "tau\u00b7send", "Lust", "emp\u00b7fin\u00b7dest", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "$.", "KON", "CARD", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Wenn du in einer Brust der Tugend Trieb entz\u00fcndest.", "tokens": ["Wenn", "du", "in", "ei\u00b7ner", "Brust", "der", "Tu\u00b7gend", "Trieb", "ent\u00b7z\u00fcn\u00b7dest", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ART", "NN", "ART", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Genug zu deinem Ruhm! Nun lies einmal die\u00df Blatt!", "tokens": ["Ge\u00b7nug", "zu", "dei\u00b7nem", "Ruhm", "!", "Nun", "lies", "ein\u00b7mal", "die\u00df", "Blatt", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPOSAT", "NN", "$.", "ADV", "VVFIN", "ADV", "PDS", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Das dir mein Kiel geweiht und zugeschrieben hat.", "tokens": ["Das", "dir", "mein", "Kiel", "ge\u00b7weiht", "und", "zu\u00b7ge\u00b7schrie\u00b7ben", "hat", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "PPOSAT", "NE", "VVPP", "KON", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Du pflegst die Redekunst und Weisheit zu verbinden,", "tokens": ["Du", "pflegst", "die", "Re\u00b7de\u00b7kunst", "und", "Weis\u00b7heit", "zu", "ver\u00b7bin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "KON", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und wirst auch hier die Spur der alten Redner finden,", "tokens": ["Und", "wirst", "auch", "hier", "die", "Spur", "der", "al\u00b7ten", "Red\u00b7ner", "fin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "ADV", "ART", "NN", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die ", "tokens": ["Die"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}, "line.6": {"text": "Und wenn er sp\u00f6ttisch schrieb, so ists doch sonnenklar,", "tokens": ["Und", "wenn", "er", "sp\u00f6t\u00b7tisch", "schrieb", ",", "so", "ists", "doch", "son\u00b7nen\u00b7klar", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADJD", "VVFIN", "$,", "ADV", "VAFIN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und jede Schrift von ihm l\u00e4\u00dft gar zu deutlich lesen;", "tokens": ["Und", "je\u00b7de", "Schrift", "von", "ihm", "l\u00e4\u00dft", "gar", "zu", "deut\u00b7lich", "le\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "APPR", "PPER", "VVFIN", "ADV", "PTKA", "ADJD", "VVINF", "$."], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.8": {"text": "Da\u00df er der Weisheit hold, der Thorheit feind gewesen.", "tokens": ["Da\u00df", "er", "der", "Weis\u00b7heit", "hold", ",", "der", "Thor\u00b7heit", "feind", "ge\u00b7we\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "ADJD", "$,", "ART", "NN", "NN", "VAPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}