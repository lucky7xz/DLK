{"textgrid.poem.38134": {"metadata": {"author": {"name": "Arnim, Ludwig Achim von", "birth": "N.A.", "death": "N.A."}, "title": "St. Jakobs Pilgerlied", "genre": "verse", "period": "N.A.", "pub_year": 1806, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wer das Elend bauen w\u00f6ll,", "tokens": ["Wer", "das", "E\u00b7lend", "bau\u00b7en", "w\u00f6ll", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "NN", "VVINF", "VMFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Der heb' sich auf und sey mein G'sell,", "tokens": ["Der", "heb'", "sich", "auf", "und", "sey", "mein", "G'\u00b7sell", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PRF", "PTKVZ", "KON", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Wol auf Sankt Jakobs Strassen.", "tokens": ["Wol", "auf", "Sankt", "Ja\u00b7kobs", "Stras\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "VVFIN", "NE", "NE", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.4": {"text": "Zwei Paar Schuh, der darf er wol,", "tokens": ["Zwei", "Paar", "Schuh", ",", "der", "darf", "er", "wol", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "NN", "$,", "PRELS", "VMFIN", "PPER", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Ein Sch\u00fcssel bey der Flaschen.", "tokens": ["Ein", "Sch\u00fcs\u00b7sel", "bey", "der", "Fla\u00b7schen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Ein breiten Huth, den soll er han,", "tokens": ["Ein", "brei\u00b7ten", "Huth", ",", "den", "soll", "er", "han", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "VMFIN", "PPER", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und ohne Mantel soll er nit gahn", "tokens": ["Und", "oh\u00b7ne", "Man\u00b7tel", "soll", "er", "nit", "gahn"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "NN", "VMFIN", "PPER", "PTKNEG", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Mit Leder wol besezet,", "tokens": ["Mit", "Le\u00b7der", "wol", "be\u00b7se\u00b7zet", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Es schnei' oder regen' oder wehe der Wind", "tokens": ["Es", "schnei'", "o\u00b7der", "re\u00b7gen'", "o\u00b7der", "we\u00b7he", "der", "Wind"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "KON", "ADJD", "ART", "NN"], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Da\u00df ihn die Luft nicht nezet.", "tokens": ["Da\u00df", "ihn", "die", "Luft", "nicht", "ne\u00b7zet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "PTKNEG", "VVFIN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.3": {"line.1": {"text": "Sack und Stab ist auch dabey,", "tokens": ["Sack", "und", "Stab", "ist", "auch", "da\u00b7bey", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VAFIN", "ADV", "PAV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Er lug, da\u00df er gebeichtet sey,", "tokens": ["Er", "lug", ",", "da\u00df", "er", "ge\u00b7beich\u00b7tet", "sey", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "PPER", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Gebeichtet und geb\u00fcsset,", "tokens": ["Ge\u00b7beich\u00b7tet", "und", "ge\u00b7b\u00fcs\u00b7set", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVPP", "KON", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Kommt er in die welsche Land,", "tokens": ["Kommt", "er", "in", "die", "wel\u00b7sche", "Land", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Er findt keinen deutschen Priester.", "tokens": ["Er", "findt", "kei\u00b7nen", "deut\u00b7schen", "Pries\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIAT", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Ein deutschen Priester findt er wol,", "tokens": ["Ein", "deut\u00b7schen", "Pries\u00b7ter", "findt", "er", "wol", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PPER", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Er wei\u00df nit wo er sterben soll,", "tokens": ["Er", "wei\u00df", "nit", "wo", "er", "ster\u00b7ben", "soll", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "PWAV", "PPER", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Oder sein Leben lassen.", "tokens": ["O\u00b7der", "sein", "Le\u00b7ben", "las\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Stirbt er in dem welschen Land,", "tokens": ["Stirbt", "er", "in", "dem", "wel\u00b7schen", "Land", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Man gr\u00e4bt ihn bei der Strassen.", "tokens": ["Man", "gr\u00e4bt", "ihn", "bei", "der", "Stras\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "So ziehen wir durch Schweizerland hin,", "tokens": ["So", "zie\u00b7hen", "wir", "durch", "Schwei\u00b7zer\u00b7land", "hin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "NN", "PTKVZ", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Sie heissen uns Gott wellkumm! sin,", "tokens": ["Sie", "heis\u00b7sen", "uns", "Gott", "well\u00b7kumm", "!", "sin", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "NN", "ADJD", "$.", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und geben uns ihr Speise.", "tokens": ["Und", "ge\u00b7ben", "uns", "ihr", "Spei\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Sie legen uns wol und decken uns warm,", "tokens": ["Sie", "le\u00b7gen", "uns", "wol", "und", "de\u00b7cken", "uns", "warm", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "KON", "VVFIN", "PPER", "ADJD", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Die Strassen thun sie uns weisen.", "tokens": ["Die", "Stras\u00b7sen", "thun", "sie", "uns", "wei\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "PRF", "VVINF", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.6": {"line.1": {"text": "So ziehen wir durch die welsche Land,", "tokens": ["So", "zie\u00b7hen", "wir", "durch", "die", "wel\u00b7sche", "Land", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Die sind uns Br\u00fcdern unbekannt,", "tokens": ["Die", "sind", "uns", "Br\u00fc\u00b7dern", "un\u00b7be\u00b7kannt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Das Elend m\u00fcssen wir bauen,", "tokens": ["Das", "E\u00b7lend", "m\u00fcs\u00b7sen", "wir", "bau\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PPER", "VVINF", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Wir ruffen Gott und St. Jakob an,", "tokens": ["Wir", "ruf\u00b7fen", "Gott", "und", "St.", "Ja\u00b7kob", "an", ","], "token_info": ["word", "word", "word", "word", "abbreviation", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "KON", "NE", "NE", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und unsre liebe Frauen.", "tokens": ["Und", "uns\u00b7re", "lie\u00b7be", "Frau\u00b7en", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "So ziehen wir durch der armen Gecken Land.", "tokens": ["So", "zie\u00b7hen", "wir", "durch", "der", "ar\u00b7men", "Ge\u00b7cken", "Land", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "ADJA", "NN", "NN", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Man giebt uns nichts denn Aepfeltrank,", "tokens": ["Man", "giebt", "uns", "nichts", "denn", "A\u00b7e\u00b7pfel\u00b7trank", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "PIS", "KON", "NN", "$,"], "meter": "-+-+----+", "measure": "unknown.measure.tri"}, "line.3": {"text": "Die Berge m\u00fcssen wir steigen.", "tokens": ["Die", "Ber\u00b7ge", "m\u00fcs\u00b7sen", "wir", "stei\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "G\u00e4b man uns Aepfel und Birn genug,", "tokens": ["G\u00e4b", "man", "uns", "A\u00b7e\u00b7pfel", "und", "Birn", "ge\u00b7nug", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PIS", "PPER", "NN", "KON", "NN", "ADV", "$,"], "meter": "+---+--+-+", "measure": "trochaic.tetra.relaxed"}, "line.5": {"text": "Wir essens f\u00fcr die Feigen.", "tokens": ["Wir", "es\u00b7sens", "f\u00fcr", "die", "Fei\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "So ziehen wir durch Sofei hinein", "tokens": ["So", "zie\u00b7hen", "wir", "durch", "So\u00b7fei", "hin\u00b7ein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "NN", "APZR"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Man giebt uns weder Brod noch Wein;", "tokens": ["Man", "giebt", "uns", "we\u00b7der", "Brod", "noch", "Wein", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "KON", "NN", "ADV", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die S\u00e4ck stehn uns gar leere;", "tokens": ["Die", "S\u00e4ck", "stehn", "uns", "gar", "lee\u00b7re", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADV", "ADJA", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Wo ein Bruder zu dem andern kommt,", "tokens": ["Wo", "ein", "Bru\u00b7der", "zu", "dem", "an\u00b7dern", "kommt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "APPR", "ART", "ADJA", "VVFIN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.5": {"text": "Der sagt ihm b\u00f6se M\u00e4hre.", "tokens": ["Der", "sagt", "ihm", "b\u00f6\u00b7se", "M\u00e4h\u00b7re", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "So ziehen wir zu St. Spiritus ein,", "tokens": ["So", "zie\u00b7hen", "wir", "zu", "St.", "Spi\u00b7ri\u00b7tus", "ein", ","], "token_info": ["word", "word", "word", "word", "abbreviation", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "NE", "NE", "PTKVZ", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Man giebt uns Brod und guten Wein,", "tokens": ["Man", "giebt", "uns", "Brod", "und", "gu\u00b7ten", "Wein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "NN", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wir leben in rechten Schallen,", "tokens": ["Wir", "le\u00b7ben", "in", "rech\u00b7ten", "Schal\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Langedocken und Hispanien,", "tokens": ["Lan\u00b7ge\u00b7do\u00b7cken", "und", "His\u00b7pa\u00b7ni\u00b7en", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "NE", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.5": {"text": "Das loben wir Br\u00fcder allen.", "tokens": ["Das", "lo\u00b7ben", "wir", "Br\u00fc\u00b7der", "al\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "NN", "PIAT", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.10": {"line.1": {"text": "Es liegen f\u00fcnf Berg im welschen Land,", "tokens": ["Es", "lie\u00b7gen", "f\u00fcnf", "Berg", "im", "wel\u00b7schen", "Land", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "CARD", "NN", "APPRART", "ADJA", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Die sind uns Pilgram wol bekandt,", "tokens": ["Die", "sind", "uns", "Pilg\u00b7ram", "wol", "be\u00b7kandt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "NE", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der erst' hei\u00dft Runzevale,", "tokens": ["Der", "er\u00b7st'", "hei\u00dft", "Run\u00b7ze\u00b7va\u00b7le", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VVFIN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und welcher Bruder dar\u00fcber geht", "tokens": ["Und", "wel\u00b7cher", "Bru\u00b7der", "da\u00b7r\u00fc\u00b7ber", "geht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PWAT", "NN", "PAV", "VVFIN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Sein Backen werden ihm schmale.", "tokens": ["Sein", "Ba\u00b7cken", "wer\u00b7den", "ihm", "schma\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "PPER", "VVFIN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.11": {"line.1": {"text": "Der eine hei\u00dft de Monte Castein,", "tokens": ["Der", "ei\u00b7ne", "hei\u00dft", "de", "Mon\u00b7te", "Cas\u00b7tein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VVFIN", "NE", "NE", "NE", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Der Pfortenberg mag wol sein Bruder sein,", "tokens": ["Der", "Pfor\u00b7ten\u00b7berg", "mag", "wol", "sein", "Bru\u00b7der", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "ADV", "PPOSAT", "NN", "VAINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Sie sind einander fast gleiche.", "tokens": ["Sie", "sind", "ein\u00b7an\u00b7der", "fast", "glei\u00b7che", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PRF", "ADV", "ADJA", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Und welcher Bruder dar\u00fcber geht,", "tokens": ["Und", "wel\u00b7cher", "Bru\u00b7der", "da\u00b7r\u00fc\u00b7ber", "geht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAT", "NN", "PAV", "VVFIN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Verdient das Himmelreiche.", "tokens": ["Ver\u00b7di\u00b7ent", "das", "Him\u00b7mel\u00b7rei\u00b7che", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVPP", "ART", "NN", "$."], "meter": "+---+-+-", "measure": "dactylic.init"}}, "stanza.12": {"line.1": {"text": "Der vierte hei\u00dft der Rabanel,", "tokens": ["Der", "vier\u00b7te", "hei\u00dft", "der", "Ra\u00b7ba\u00b7nel", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dar\u00fcber lauffen die Br\u00fcder und Schwestern gar schnell,", "tokens": ["Da\u00b7r\u00fc\u00b7ber", "lauf\u00b7fen", "die", "Br\u00fc\u00b7der", "und", "Schwes\u00b7tern", "gar", "schnell", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "ART", "NN", "KON", "NN", "ADV", "ADJD", "$,"], "meter": "-+-+--+--+--+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Der f\u00fcnft hei\u00dft in Alle Fabe,", "tokens": ["Der", "f\u00fcnft", "hei\u00dft", "in", "Al\u00b7le", "Fa\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "PIAT", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Do leit viel manches Biedermanns Kind,", "tokens": ["Do", "leit", "viel", "man\u00b7ches", "Bie\u00b7der\u00b7manns", "Kind", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ADV", "PIAT", "NN", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.5": {"text": "Aus deutschem Land begraben.", "tokens": ["Aus", "deut\u00b7schem", "Land", "be\u00b7gra\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.13": {"line.1": {"text": "Der K\u00f6nig von Hispanien der f\u00fchrt ein Kron,", "tokens": ["Der", "K\u00f6\u00b7nig", "von", "His\u00b7pa\u00b7ni\u00b7en", "der", "f\u00fchrt", "ein", "Kron", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NE", "ART", "VVFIN", "ART", "NN", "$,"], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Er hat gebaut drei Spital gar schon,", "tokens": ["Er", "hat", "ge\u00b7baut", "drei", "Spi\u00b7tal", "gar", "schon", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVPP", "CARD", "NN", "ADV", "ADV", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "In St. Jakobs Ehren,", "tokens": ["In", "St.", "Ja\u00b7kobs", "Eh\u00b7ren", ","], "token_info": ["word", "abbreviation", "word", "word", "punct"], "pos": ["APPR", "NE", "NE", "NN", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.4": {"text": "Und welcher Bruder darein kommt,", "tokens": ["Und", "wel\u00b7cher", "Bru\u00b7der", "da\u00b7rein", "kommt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAT", "NN", "PAV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Man beweist ihm Zucht und Ehre.", "tokens": ["Man", "be\u00b7weist", "ihm", "Zucht", "und", "Eh\u00b7re", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "NN", "KON", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "Es war dem Spitalmeister nit eben,", "tokens": ["Es", "war", "dem", "Spi\u00b7tal\u00b7meis\u00b7ter", "nit", "e\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "PTKNEG", "ADV", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Vierthalbhundert Br\u00fcder hat er vergeben,", "tokens": ["Vier\u00b7thal\u00b7bhun\u00b7dert", "Br\u00fc\u00b7der", "hat", "er", "ver\u00b7ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "VAFIN", "PPER", "VVPP", "$,"], "meter": "--+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Gott lie\u00df nicht ungerochen.", "tokens": ["Gott", "lie\u00df", "nicht", "un\u00b7ge\u00b7ro\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PTKNEG", "ADJD", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Zu Burges ward er an ein Kreuz geheft,", "tokens": ["Zu", "Bur\u00b7ges", "ward", "er", "an", "ein", "Kreuz", "ge\u00b7heft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VAFIN", "PPER", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Mit scharfen Pfeilen durchstochen.", "tokens": ["Mit", "schar\u00b7fen", "Pfei\u00b7len", "durch\u00b7sto\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.15": {"line.1": {"text": "Der K\u00f6nig der war ein Biedermann,", "tokens": ["Der", "K\u00f6\u00b7nig", "der", "war", "ein", "Bie\u00b7der\u00b7mann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "VAFIN", "ART", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "In Pilgramkleider legt er sich an,", "tokens": ["In", "Pil\u00b7gram\u00b7klei\u00b7der", "legt", "er", "sich", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PPER", "PRF", "PTKVZ", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Sein Spital wollt er beschauen,", "tokens": ["Sein", "Spi\u00b7tal", "wollt", "er", "be\u00b7schau\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VMFIN", "PPER", "VVINF", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Was ihm die deutschen Br\u00fcder sagten,", "tokens": ["Was", "ihm", "die", "deut\u00b7schen", "Br\u00fc\u00b7der", "sag\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Das wollt er nit glauben.", "tokens": ["Das", "wollt", "er", "nit", "glau\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PPER", "PTKNEG", "VVINF", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.16": {"line.1": {"text": "Da ging er in das Spital ein,", "tokens": ["Da", "ging", "er", "in", "das", "Spi\u00b7tal", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Er hies ihm bringen Brod und Wein,", "tokens": ["Er", "hies", "ihm", "brin\u00b7gen", "Brod", "und", "Wein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "VVINF", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die Suppe die war nit reine;", "tokens": ["Die", "Sup\u00b7pe", "die", "war", "nit", "rei\u00b7ne", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "VAFIN", "PTKNEG", "ADJA", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Spitalmeister, lieber Spitalmeister mein!", "tokens": ["Spi\u00b7tal\u00b7meis\u00b7ter", ",", "lie\u00b7ber", "Spi\u00b7tal\u00b7meis\u00b7ter", "mein", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADV", "NN", "PPOSAT", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.5": {"text": "Die Brod sind viel zu kleine.", "tokens": ["Die", "Brod", "sind", "viel", "zu", "klei\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "APPR", "ADJA", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.17": {"line.1": {"text": "Der Spitalmeister war ein zornig Mann:", "tokens": ["Der", "Spi\u00b7tal\u00b7meis\u00b7ter", "war", "ein", "zor\u00b7nig", "Mann", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ART", "ADJD", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Der Greulich hat dich herein gethan,", "tokens": ["Der", "Greu\u00b7lich", "hat", "dich", "her\u00b7ein", "ge\u00b7than", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "VAFIN", "PPER", "PTKVZ", "VVPP", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Das nimmt mich nimmer Wunder!", "tokens": ["Das", "nimmt", "mich", "nim\u00b7mer", "Wun\u00b7der", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADV", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und w\u00e4rst du nit ein welscher Mann,", "tokens": ["Und", "w\u00e4rst", "du", "nit", "ein", "wel\u00b7scher", "Mann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "PTKNEG", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ich verg\u00e4b dir, wie die deutschen Hunde!", "tokens": ["Ich", "ver\u00b7g\u00e4b", "dir", ",", "wie", "die", "deut\u00b7schen", "Hun\u00b7de", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$,", "PWAV", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.18": {"line.1": {"text": "Und da es an den Abend kam,", "tokens": ["Und", "da", "es", "an", "den", "A\u00b7bend", "kam", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Br\u00fcder wollten schlafen gahn,", "tokens": ["Die", "Br\u00fc\u00b7der", "woll\u00b7ten", "schla\u00b7fen", "gahn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der Pilgram wollt schlafen alleine:", "tokens": ["Der", "Pilg\u00b7ram", "wollt", "schla\u00b7fen", "al\u00b7lei\u00b7ne", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "VVINF", "ADV", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Spitalmeister, lieber Spitalmeister mein", "tokens": ["Spi\u00b7tal\u00b7meis\u00b7ter", ",", "lie\u00b7ber", "Spi\u00b7tal\u00b7meis\u00b7ter", "mein"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "ADV", "NN", "PPOSAT"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.5": {"text": "Die Bett sind gar nicht reine.", "tokens": ["Die", "Bett", "sind", "gar", "nicht", "rei\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.19": {"line.1": {"text": "Er gab dem Pilgram ein' Schlag,", "tokens": ["Er", "gab", "dem", "Pilg\u00b7ram", "ein'", "Schlag", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Da\u00df er von Herzen sehr erschrack,", "tokens": ["Da\u00df", "er", "von", "Her\u00b7zen", "sehr", "er\u00b7schrack", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NN", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Er th\u00e4t zu dem Spital auslaufen,", "tokens": ["Er", "th\u00e4t", "zu", "dem", "Spi\u00b7tal", "aus\u00b7lau\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die andern Br\u00fcder th\u00e4ten", "tokens": ["Die", "an\u00b7dern", "Br\u00fc\u00b7der", "th\u00e4\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Den Spitalmeister sehr raufen.", "tokens": ["Den", "Spi\u00b7tal\u00b7meis\u00b7ter", "sehr", "rau\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.20": {"line.1": {"text": "Do es an den Morgen kam,", "tokens": ["Do", "es", "an", "den", "Mor\u00b7gen", "kam", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Man sah viel gewapneter Mann,", "tokens": ["Man", "sah", "viel", "ge\u00b7wap\u00b7ne\u00b7ter", "Mann", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PIAT", "ADJA", "NN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "Zu dem Spital eindringen,", "tokens": ["Zu", "dem", "Spi\u00b7tal", "ein\u00b7drin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVPP", "$,"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.4": {"text": "Man fing den Spitalmeister", "tokens": ["Man", "fing", "den", "Spi\u00b7tal\u00b7meis\u00b7ter"], "token_info": ["word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Und all sein Hausgesinde.", "tokens": ["Und", "all", "sein", "Haus\u00b7ge\u00b7sin\u00b7de", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.21": {"line.1": {"text": "Man band ihn auf ein hohes Ro\u00df,", "tokens": ["Man", "band", "ihn", "auf", "ein", "ho\u00b7hes", "Ro\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Man f\u00fchrt ihn gen Burges auf das Schlo\u00df,", "tokens": ["Man", "f\u00fchrt", "ihn", "gen", "Bur\u00b7ges", "auf", "das", "Schlo\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "APPR", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Man th\u00e4t ihn in Eisen einschlie\u00dfen,", "tokens": ["Man", "th\u00e4t", "ihn", "in", "Ei\u00b7sen", "ein\u00b7schlie\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "APPR", "NN", "VVINF", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Es th\u00e4t den Spitalmeister", "tokens": ["Es", "th\u00e4t", "den", "Spi\u00b7tal\u00b7meis\u00b7ter"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Gar sehr und hart verdriessen.", "tokens": ["Gar", "sehr", "und", "hart", "ver\u00b7dries\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "KON", "ADJD", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.22": {"line.1": {"text": "Der Spitalmeister h\u00e4tt ein T\u00f6chterlein,", "tokens": ["Der", "Spi\u00b7tal\u00b7meis\u00b7ter", "h\u00e4tt", "ein", "T\u00f6ch\u00b7ter\u00b7lein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Es mocht recht wol ein Sch\u00e4lkin sein.", "tokens": ["Es", "mocht", "recht", "wol", "ein", "Sch\u00e4l\u00b7kin", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "ART", "NN", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Es nimmt mich immer Wunder,", "tokens": ["Es", "nimmt", "mich", "im\u00b7mer", "Wun\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Da\u00df der liebste Vater mein,", "tokens": ["Da\u00df", "der", "liebs\u00b7te", "Va\u00b7ter", "mein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "PPOSAT", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Soll sterben wegen der deutschen Hunde.", "tokens": ["Soll", "ster\u00b7ben", "we\u00b7gen", "der", "deut\u00b7schen", "Hun\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "VVINF", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.23": {"line.1": {"text": "Es stund ein Bruder nahe dabey,", "tokens": ["Es", "stund", "ein", "Bru\u00b7der", "na\u00b7he", "da\u00b7bey", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADJD", "PAV", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Nun soll es nit verschwiegen sein,", "tokens": ["Nun", "soll", "es", "nit", "ver\u00b7schwie\u00b7gen", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PTKNEG", "VVPP", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ich will es selber klagen!", "tokens": ["Ich", "will", "es", "sel\u00b7ber", "kla\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Da ward da\u00dfelbig T\u00f6chterlein", "tokens": ["Da", "ward", "da\u00b7\u00dfel\u00b7big", "T\u00f6ch\u00b7ter\u00b7lein"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ADJD", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Unterm Galgen begraben.", "tokens": ["Un\u00b7term", "Gal\u00b7gen", "be\u00b7gra\u00b7ben", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVPP", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}}, "stanza.24": {"line.1": {"text": "Sieh Bruder, du sollst nit stille stahn,", "tokens": ["Sieh", "Bru\u00b7der", ",", "du", "sollst", "nit", "stil\u00b7le", "stahn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "PPER", "VMFIN", "PTKNEG", "ADJA", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Vierzig Meil hast du noch zu gahn;", "tokens": ["Vier\u00b7zig", "Meil", "hast", "du", "noch", "zu", "gahn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "VAFIN", "PPER", "ADV", "PTKZU", "VVINF", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.3": {"text": "Wol in St. Jakobs M\u00fcnster.", "tokens": ["Wol", "in", "St.", "Ja\u00b7kobs", "M\u00fcns\u00b7ter", "."], "token_info": ["word", "word", "abbreviation", "word", "word", "punct"], "pos": ["ADV", "APPR", "NE", "NE", "NE", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Vierzehn Meil hinunter ba\u00df", "tokens": ["Vier\u00b7zehn", "Meil", "hin\u00b7un\u00b7ter", "ba\u00df"], "token_info": ["word", "word", "word", "word"], "pos": ["CARD", "NN", "ADV", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Zu einem Stern, hei\u00dft Finster.", "tokens": ["Zu", "ei\u00b7nem", "Stern", ",", "hei\u00dft", "Fins\u00b7ter", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "VVFIN", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.25": {"line.1": {"text": "Den finstern Stern wollen wir lan stahn,", "tokens": ["Den", "fins\u00b7tern", "Stern", "wol\u00b7len", "wir", "lan", "stahn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VMFIN", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Und wollen zu Salvator eingahn,", "tokens": ["Und", "wol\u00b7len", "zu", "Sal\u00b7va\u00b7tor", "ein\u00b7gahn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "APPR", "NN", "VVIZU", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Gro\u00df Wunderzeichen anschauen.", "tokens": ["Gro\u00df", "Wun\u00b7der\u00b7zei\u00b7chen", "an\u00b7schau\u00b7en", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "NN", "VVINF", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "So rufen wir Gott und St. Jakob an,", "tokens": ["So", "ru\u00b7fen", "wir", "Gott", "und", "St.", "Ja\u00b7kob", "an", ","], "token_info": ["word", "word", "word", "word", "word", "abbreviation", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "NN", "KON", "NE", "NE", "PTKVZ", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Und unsre liebe Frauen.", "tokens": ["Und", "uns\u00b7re", "lie\u00b7be", "Frau\u00b7en", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.26": {"line.1": {"text": "Bei St. Jakob vergiebt man Pein und Schuld,", "tokens": ["Bei", "St.", "Ja\u00b7kob", "ver\u00b7giebt", "man", "Pein", "und", "Schuld", ","], "token_info": ["word", "abbreviation", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "NE", "VVFIN", "PIS", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Der liebe Gott sei uns allen hold,", "tokens": ["Der", "lie\u00b7be", "Gott", "sei", "uns", "al\u00b7len", "hold", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "PPER", "PIAT", "ADJD", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "In seinem h\u00f6chsten Throne,", "tokens": ["In", "sei\u00b7nem", "h\u00f6chs\u00b7ten", "Thro\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Der St. Jakob dienen thut,", "tokens": ["Der", "St.", "Ja\u00b7kob", "die\u00b7nen", "thut", ","], "token_info": ["word", "abbreviation", "word", "word", "word", "punct"], "pos": ["ART", "NE", "NE", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Der lieb Gott soll ihm lohnen.", "tokens": ["Der", "lieb", "Gott", "soll", "ihm", "loh\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.27": {"line.1": {"text": "Wer das Elend bauen w\u00f6ll,", "tokens": ["Wer", "das", "E\u00b7lend", "bau\u00b7en", "w\u00f6ll", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "NN", "VVINF", "VMFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Der heb' sich auf und sey mein G'sell,", "tokens": ["Der", "heb'", "sich", "auf", "und", "sey", "mein", "G'\u00b7sell", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PRF", "PTKVZ", "KON", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Wol auf Sankt Jakobs Strassen.", "tokens": ["Wol", "auf", "Sankt", "Ja\u00b7kobs", "Stras\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "VVFIN", "NE", "NE", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.4": {"text": "Zwei Paar Schuh, der darf er wol,", "tokens": ["Zwei", "Paar", "Schuh", ",", "der", "darf", "er", "wol", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "NN", "$,", "PRELS", "VMFIN", "PPER", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Ein Sch\u00fcssel bey der Flaschen.", "tokens": ["Ein", "Sch\u00fcs\u00b7sel", "bey", "der", "Fla\u00b7schen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.28": {"line.1": {"text": "Ein breiten Huth, den soll er han,", "tokens": ["Ein", "brei\u00b7ten", "Huth", ",", "den", "soll", "er", "han", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "VMFIN", "PPER", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und ohne Mantel soll er nit gahn", "tokens": ["Und", "oh\u00b7ne", "Man\u00b7tel", "soll", "er", "nit", "gahn"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "NN", "VMFIN", "PPER", "PTKNEG", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Mit Leder wol besezet,", "tokens": ["Mit", "Le\u00b7der", "wol", "be\u00b7se\u00b7zet", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Es schnei' oder regen' oder wehe der Wind", "tokens": ["Es", "schnei'", "o\u00b7der", "re\u00b7gen'", "o\u00b7der", "we\u00b7he", "der", "Wind"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "KON", "ADJD", "ART", "NN"], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Da\u00df ihn die Luft nicht nezet.", "tokens": ["Da\u00df", "ihn", "die", "Luft", "nicht", "ne\u00b7zet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "PTKNEG", "VVFIN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.29": {"line.1": {"text": "Sack und Stab ist auch dabey,", "tokens": ["Sack", "und", "Stab", "ist", "auch", "da\u00b7bey", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VAFIN", "ADV", "PAV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Er lug, da\u00df er gebeichtet sey,", "tokens": ["Er", "lug", ",", "da\u00df", "er", "ge\u00b7beich\u00b7tet", "sey", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "PPER", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Gebeichtet und geb\u00fcsset,", "tokens": ["Ge\u00b7beich\u00b7tet", "und", "ge\u00b7b\u00fcs\u00b7set", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVPP", "KON", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Kommt er in die welsche Land,", "tokens": ["Kommt", "er", "in", "die", "wel\u00b7sche", "Land", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Er findt keinen deutschen Priester.", "tokens": ["Er", "findt", "kei\u00b7nen", "deut\u00b7schen", "Pries\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIAT", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.30": {"line.1": {"text": "Ein deutschen Priester findt er wol,", "tokens": ["Ein", "deut\u00b7schen", "Pries\u00b7ter", "findt", "er", "wol", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PPER", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Er wei\u00df nit wo er sterben soll,", "tokens": ["Er", "wei\u00df", "nit", "wo", "er", "ster\u00b7ben", "soll", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "PWAV", "PPER", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Oder sein Leben lassen.", "tokens": ["O\u00b7der", "sein", "Le\u00b7ben", "las\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Stirbt er in dem welschen Land,", "tokens": ["Stirbt", "er", "in", "dem", "wel\u00b7schen", "Land", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Man gr\u00e4bt ihn bei der Strassen.", "tokens": ["Man", "gr\u00e4bt", "ihn", "bei", "der", "Stras\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.31": {"line.1": {"text": "So ziehen wir durch Schweizerland hin,", "tokens": ["So", "zie\u00b7hen", "wir", "durch", "Schwei\u00b7zer\u00b7land", "hin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "NN", "PTKVZ", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Sie heissen uns Gott wellkumm! sin,", "tokens": ["Sie", "heis\u00b7sen", "uns", "Gott", "well\u00b7kumm", "!", "sin", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "NN", "ADJD", "$.", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und geben uns ihr Speise.", "tokens": ["Und", "ge\u00b7ben", "uns", "ihr", "Spei\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Sie legen uns wol und decken uns warm,", "tokens": ["Sie", "le\u00b7gen", "uns", "wol", "und", "de\u00b7cken", "uns", "warm", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "KON", "VVFIN", "PPER", "ADJD", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Die Strassen thun sie uns weisen.", "tokens": ["Die", "Stras\u00b7sen", "thun", "sie", "uns", "wei\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "PRF", "VVINF", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.32": {"line.1": {"text": "So ziehen wir durch die welsche Land,", "tokens": ["So", "zie\u00b7hen", "wir", "durch", "die", "wel\u00b7sche", "Land", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Die sind uns Br\u00fcdern unbekannt,", "tokens": ["Die", "sind", "uns", "Br\u00fc\u00b7dern", "un\u00b7be\u00b7kannt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Das Elend m\u00fcssen wir bauen,", "tokens": ["Das", "E\u00b7lend", "m\u00fcs\u00b7sen", "wir", "bau\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PPER", "VVINF", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Wir ruffen Gott und St. Jakob an,", "tokens": ["Wir", "ruf\u00b7fen", "Gott", "und", "St.", "Ja\u00b7kob", "an", ","], "token_info": ["word", "word", "word", "word", "abbreviation", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "KON", "NE", "NE", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und unsre liebe Frauen.", "tokens": ["Und", "uns\u00b7re", "lie\u00b7be", "Frau\u00b7en", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.33": {"line.1": {"text": "So ziehen wir durch der armen Gecken Land.", "tokens": ["So", "zie\u00b7hen", "wir", "durch", "der", "ar\u00b7men", "Ge\u00b7cken", "Land", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "ADJA", "NN", "NN", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Man giebt uns nichts denn Aepfeltrank,", "tokens": ["Man", "giebt", "uns", "nichts", "denn", "A\u00b7e\u00b7pfel\u00b7trank", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "PIS", "KON", "NN", "$,"], "meter": "-+-+----+", "measure": "unknown.measure.tri"}, "line.3": {"text": "Die Berge m\u00fcssen wir steigen.", "tokens": ["Die", "Ber\u00b7ge", "m\u00fcs\u00b7sen", "wir", "stei\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "G\u00e4b man uns Aepfel und Birn genug,", "tokens": ["G\u00e4b", "man", "uns", "A\u00b7e\u00b7pfel", "und", "Birn", "ge\u00b7nug", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PIS", "PPER", "NN", "KON", "NN", "ADV", "$,"], "meter": "+---+--+-+", "measure": "trochaic.tetra.relaxed"}, "line.5": {"text": "Wir essens f\u00fcr die Feigen.", "tokens": ["Wir", "es\u00b7sens", "f\u00fcr", "die", "Fei\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.34": {"line.1": {"text": "So ziehen wir durch Sofei hinein", "tokens": ["So", "zie\u00b7hen", "wir", "durch", "So\u00b7fei", "hin\u00b7ein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "NN", "APZR"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Man giebt uns weder Brod noch Wein;", "tokens": ["Man", "giebt", "uns", "we\u00b7der", "Brod", "noch", "Wein", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "KON", "NN", "ADV", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die S\u00e4ck stehn uns gar leere;", "tokens": ["Die", "S\u00e4ck", "stehn", "uns", "gar", "lee\u00b7re", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADV", "ADJA", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Wo ein Bruder zu dem andern kommt,", "tokens": ["Wo", "ein", "Bru\u00b7der", "zu", "dem", "an\u00b7dern", "kommt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "APPR", "ART", "ADJA", "VVFIN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.5": {"text": "Der sagt ihm b\u00f6se M\u00e4hre.", "tokens": ["Der", "sagt", "ihm", "b\u00f6\u00b7se", "M\u00e4h\u00b7re", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.35": {"line.1": {"text": "So ziehen wir zu St. Spiritus ein,", "tokens": ["So", "zie\u00b7hen", "wir", "zu", "St.", "Spi\u00b7ri\u00b7tus", "ein", ","], "token_info": ["word", "word", "word", "word", "abbreviation", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "NE", "NE", "PTKVZ", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Man giebt uns Brod und guten Wein,", "tokens": ["Man", "giebt", "uns", "Brod", "und", "gu\u00b7ten", "Wein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "NN", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wir leben in rechten Schallen,", "tokens": ["Wir", "le\u00b7ben", "in", "rech\u00b7ten", "Schal\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Langedocken und Hispanien,", "tokens": ["Lan\u00b7ge\u00b7do\u00b7cken", "und", "His\u00b7pa\u00b7ni\u00b7en", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "NE", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.5": {"text": "Das loben wir Br\u00fcder allen.", "tokens": ["Das", "lo\u00b7ben", "wir", "Br\u00fc\u00b7der", "al\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "NN", "PIAT", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.36": {"line.1": {"text": "Es liegen f\u00fcnf Berg im welschen Land,", "tokens": ["Es", "lie\u00b7gen", "f\u00fcnf", "Berg", "im", "wel\u00b7schen", "Land", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "CARD", "NN", "APPRART", "ADJA", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Die sind uns Pilgram wol bekandt,", "tokens": ["Die", "sind", "uns", "Pilg\u00b7ram", "wol", "be\u00b7kandt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "NE", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der erst' hei\u00dft Runzevale,", "tokens": ["Der", "er\u00b7st'", "hei\u00dft", "Run\u00b7ze\u00b7va\u00b7le", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VVFIN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und welcher Bruder dar\u00fcber geht", "tokens": ["Und", "wel\u00b7cher", "Bru\u00b7der", "da\u00b7r\u00fc\u00b7ber", "geht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PWAT", "NN", "PAV", "VVFIN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Sein Backen werden ihm schmale.", "tokens": ["Sein", "Ba\u00b7cken", "wer\u00b7den", "ihm", "schma\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "PPER", "VVFIN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.37": {"line.1": {"text": "Der eine hei\u00dft de Monte Castein,", "tokens": ["Der", "ei\u00b7ne", "hei\u00dft", "de", "Mon\u00b7te", "Cas\u00b7tein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VVFIN", "NE", "NE", "NE", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Der Pfortenberg mag wol sein Bruder sein,", "tokens": ["Der", "Pfor\u00b7ten\u00b7berg", "mag", "wol", "sein", "Bru\u00b7der", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "ADV", "PPOSAT", "NN", "VAINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Sie sind einander fast gleiche.", "tokens": ["Sie", "sind", "ein\u00b7an\u00b7der", "fast", "glei\u00b7che", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PRF", "ADV", "ADJA", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Und welcher Bruder dar\u00fcber geht,", "tokens": ["Und", "wel\u00b7cher", "Bru\u00b7der", "da\u00b7r\u00fc\u00b7ber", "geht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAT", "NN", "PAV", "VVFIN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Verdient das Himmelreiche.", "tokens": ["Ver\u00b7di\u00b7ent", "das", "Him\u00b7mel\u00b7rei\u00b7che", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVPP", "ART", "NN", "$."], "meter": "+---+-+-", "measure": "dactylic.init"}}, "stanza.38": {"line.1": {"text": "Der vierte hei\u00dft der Rabanel,", "tokens": ["Der", "vier\u00b7te", "hei\u00dft", "der", "Ra\u00b7ba\u00b7nel", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dar\u00fcber lauffen die Br\u00fcder und Schwestern gar schnell,", "tokens": ["Da\u00b7r\u00fc\u00b7ber", "lauf\u00b7fen", "die", "Br\u00fc\u00b7der", "und", "Schwes\u00b7tern", "gar", "schnell", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "ART", "NN", "KON", "NN", "ADV", "ADJD", "$,"], "meter": "-+-+--+--+--+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Der f\u00fcnft hei\u00dft in Alle Fabe,", "tokens": ["Der", "f\u00fcnft", "hei\u00dft", "in", "Al\u00b7le", "Fa\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "PIAT", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Do leit viel manches Biedermanns Kind,", "tokens": ["Do", "leit", "viel", "man\u00b7ches", "Bie\u00b7der\u00b7manns", "Kind", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ADV", "PIAT", "NN", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.5": {"text": "Aus deutschem Land begraben.", "tokens": ["Aus", "deut\u00b7schem", "Land", "be\u00b7gra\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.39": {"line.1": {"text": "Der K\u00f6nig von Hispanien der f\u00fchrt ein Kron,", "tokens": ["Der", "K\u00f6\u00b7nig", "von", "His\u00b7pa\u00b7ni\u00b7en", "der", "f\u00fchrt", "ein", "Kron", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NE", "ART", "VVFIN", "ART", "NN", "$,"], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Er hat gebaut drei Spital gar schon,", "tokens": ["Er", "hat", "ge\u00b7baut", "drei", "Spi\u00b7tal", "gar", "schon", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVPP", "CARD", "NN", "ADV", "ADV", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "In St. Jakobs Ehren,", "tokens": ["In", "St.", "Ja\u00b7kobs", "Eh\u00b7ren", ","], "token_info": ["word", "abbreviation", "word", "word", "punct"], "pos": ["APPR", "NE", "NE", "NN", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.4": {"text": "Und welcher Bruder darein kommt,", "tokens": ["Und", "wel\u00b7cher", "Bru\u00b7der", "da\u00b7rein", "kommt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAT", "NN", "PAV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Man beweist ihm Zucht und Ehre.", "tokens": ["Man", "be\u00b7weist", "ihm", "Zucht", "und", "Eh\u00b7re", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "NN", "KON", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.40": {"line.1": {"text": "Es war dem Spitalmeister nit eben,", "tokens": ["Es", "war", "dem", "Spi\u00b7tal\u00b7meis\u00b7ter", "nit", "e\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "PTKNEG", "ADV", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Vierthalbhundert Br\u00fcder hat er vergeben,", "tokens": ["Vier\u00b7thal\u00b7bhun\u00b7dert", "Br\u00fc\u00b7der", "hat", "er", "ver\u00b7ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "VAFIN", "PPER", "VVPP", "$,"], "meter": "--+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Gott lie\u00df nicht ungerochen.", "tokens": ["Gott", "lie\u00df", "nicht", "un\u00b7ge\u00b7ro\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PTKNEG", "ADJD", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Zu Burges ward er an ein Kreuz geheft,", "tokens": ["Zu", "Bur\u00b7ges", "ward", "er", "an", "ein", "Kreuz", "ge\u00b7heft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VAFIN", "PPER", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Mit scharfen Pfeilen durchstochen.", "tokens": ["Mit", "schar\u00b7fen", "Pfei\u00b7len", "durch\u00b7sto\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.41": {"line.1": {"text": "Der K\u00f6nig der war ein Biedermann,", "tokens": ["Der", "K\u00f6\u00b7nig", "der", "war", "ein", "Bie\u00b7der\u00b7mann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "VAFIN", "ART", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "In Pilgramkleider legt er sich an,", "tokens": ["In", "Pil\u00b7gram\u00b7klei\u00b7der", "legt", "er", "sich", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PPER", "PRF", "PTKVZ", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Sein Spital wollt er beschauen,", "tokens": ["Sein", "Spi\u00b7tal", "wollt", "er", "be\u00b7schau\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VMFIN", "PPER", "VVINF", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Was ihm die deutschen Br\u00fcder sagten,", "tokens": ["Was", "ihm", "die", "deut\u00b7schen", "Br\u00fc\u00b7der", "sag\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Das wollt er nit glauben.", "tokens": ["Das", "wollt", "er", "nit", "glau\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PPER", "PTKNEG", "VVINF", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.42": {"line.1": {"text": "Da ging er in das Spital ein,", "tokens": ["Da", "ging", "er", "in", "das", "Spi\u00b7tal", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Er hies ihm bringen Brod und Wein,", "tokens": ["Er", "hies", "ihm", "brin\u00b7gen", "Brod", "und", "Wein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "VVINF", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die Suppe die war nit reine;", "tokens": ["Die", "Sup\u00b7pe", "die", "war", "nit", "rei\u00b7ne", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "VAFIN", "PTKNEG", "ADJA", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Spitalmeister, lieber Spitalmeister mein!", "tokens": ["Spi\u00b7tal\u00b7meis\u00b7ter", ",", "lie\u00b7ber", "Spi\u00b7tal\u00b7meis\u00b7ter", "mein", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADV", "NN", "PPOSAT", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.5": {"text": "Die Brod sind viel zu kleine.", "tokens": ["Die", "Brod", "sind", "viel", "zu", "klei\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "APPR", "ADJA", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.43": {"line.1": {"text": "Der Spitalmeister war ein zornig Mann:", "tokens": ["Der", "Spi\u00b7tal\u00b7meis\u00b7ter", "war", "ein", "zor\u00b7nig", "Mann", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ART", "ADJD", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Der Greulich hat dich herein gethan,", "tokens": ["Der", "Greu\u00b7lich", "hat", "dich", "her\u00b7ein", "ge\u00b7than", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "VAFIN", "PPER", "PTKVZ", "VVPP", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Das nimmt mich nimmer Wunder!", "tokens": ["Das", "nimmt", "mich", "nim\u00b7mer", "Wun\u00b7der", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADV", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und w\u00e4rst du nit ein welscher Mann,", "tokens": ["Und", "w\u00e4rst", "du", "nit", "ein", "wel\u00b7scher", "Mann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "PTKNEG", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ich verg\u00e4b dir, wie die deutschen Hunde!", "tokens": ["Ich", "ver\u00b7g\u00e4b", "dir", ",", "wie", "die", "deut\u00b7schen", "Hun\u00b7de", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$,", "PWAV", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.44": {"line.1": {"text": "Und da es an den Abend kam,", "tokens": ["Und", "da", "es", "an", "den", "A\u00b7bend", "kam", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Br\u00fcder wollten schlafen gahn,", "tokens": ["Die", "Br\u00fc\u00b7der", "woll\u00b7ten", "schla\u00b7fen", "gahn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der Pilgram wollt schlafen alleine:", "tokens": ["Der", "Pilg\u00b7ram", "wollt", "schla\u00b7fen", "al\u00b7lei\u00b7ne", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "VVINF", "ADV", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Spitalmeister, lieber Spitalmeister mein", "tokens": ["Spi\u00b7tal\u00b7meis\u00b7ter", ",", "lie\u00b7ber", "Spi\u00b7tal\u00b7meis\u00b7ter", "mein"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "ADV", "NN", "PPOSAT"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.5": {"text": "Die Bett sind gar nicht reine.", "tokens": ["Die", "Bett", "sind", "gar", "nicht", "rei\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.45": {"line.1": {"text": "Er gab dem Pilgram ein' Schlag,", "tokens": ["Er", "gab", "dem", "Pilg\u00b7ram", "ein'", "Schlag", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Da\u00df er von Herzen sehr erschrack,", "tokens": ["Da\u00df", "er", "von", "Her\u00b7zen", "sehr", "er\u00b7schrack", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NN", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Er th\u00e4t zu dem Spital auslaufen,", "tokens": ["Er", "th\u00e4t", "zu", "dem", "Spi\u00b7tal", "aus\u00b7lau\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die andern Br\u00fcder th\u00e4ten", "tokens": ["Die", "an\u00b7dern", "Br\u00fc\u00b7der", "th\u00e4\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Den Spitalmeister sehr raufen.", "tokens": ["Den", "Spi\u00b7tal\u00b7meis\u00b7ter", "sehr", "rau\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.46": {"line.1": {"text": "Do es an den Morgen kam,", "tokens": ["Do", "es", "an", "den", "Mor\u00b7gen", "kam", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Man sah viel gewapneter Mann,", "tokens": ["Man", "sah", "viel", "ge\u00b7wap\u00b7ne\u00b7ter", "Mann", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PIAT", "ADJA", "NN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "Zu dem Spital eindringen,", "tokens": ["Zu", "dem", "Spi\u00b7tal", "ein\u00b7drin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVPP", "$,"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.4": {"text": "Man fing den Spitalmeister", "tokens": ["Man", "fing", "den", "Spi\u00b7tal\u00b7meis\u00b7ter"], "token_info": ["word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Und all sein Hausgesinde.", "tokens": ["Und", "all", "sein", "Haus\u00b7ge\u00b7sin\u00b7de", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.47": {"line.1": {"text": "Man band ihn auf ein hohes Ro\u00df,", "tokens": ["Man", "band", "ihn", "auf", "ein", "ho\u00b7hes", "Ro\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Man f\u00fchrt ihn gen Burges auf das Schlo\u00df,", "tokens": ["Man", "f\u00fchrt", "ihn", "gen", "Bur\u00b7ges", "auf", "das", "Schlo\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "APPR", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Man th\u00e4t ihn in Eisen einschlie\u00dfen,", "tokens": ["Man", "th\u00e4t", "ihn", "in", "Ei\u00b7sen", "ein\u00b7schlie\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "APPR", "NN", "VVINF", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Es th\u00e4t den Spitalmeister", "tokens": ["Es", "th\u00e4t", "den", "Spi\u00b7tal\u00b7meis\u00b7ter"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Gar sehr und hart verdriessen.", "tokens": ["Gar", "sehr", "und", "hart", "ver\u00b7dries\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "KON", "ADJD", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.48": {"line.1": {"text": "Der Spitalmeister h\u00e4tt ein T\u00f6chterlein,", "tokens": ["Der", "Spi\u00b7tal\u00b7meis\u00b7ter", "h\u00e4tt", "ein", "T\u00f6ch\u00b7ter\u00b7lein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Es mocht recht wol ein Sch\u00e4lkin sein.", "tokens": ["Es", "mocht", "recht", "wol", "ein", "Sch\u00e4l\u00b7kin", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "ART", "NN", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Es nimmt mich immer Wunder,", "tokens": ["Es", "nimmt", "mich", "im\u00b7mer", "Wun\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Da\u00df der liebste Vater mein,", "tokens": ["Da\u00df", "der", "liebs\u00b7te", "Va\u00b7ter", "mein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "PPOSAT", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Soll sterben wegen der deutschen Hunde.", "tokens": ["Soll", "ster\u00b7ben", "we\u00b7gen", "der", "deut\u00b7schen", "Hun\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "VVINF", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.49": {"line.1": {"text": "Es stund ein Bruder nahe dabey,", "tokens": ["Es", "stund", "ein", "Bru\u00b7der", "na\u00b7he", "da\u00b7bey", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADJD", "PAV", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Nun soll es nit verschwiegen sein,", "tokens": ["Nun", "soll", "es", "nit", "ver\u00b7schwie\u00b7gen", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PTKNEG", "VVPP", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ich will es selber klagen!", "tokens": ["Ich", "will", "es", "sel\u00b7ber", "kla\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Da ward da\u00dfelbig T\u00f6chterlein", "tokens": ["Da", "ward", "da\u00b7\u00dfel\u00b7big", "T\u00f6ch\u00b7ter\u00b7lein"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ADJD", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Unterm Galgen begraben.", "tokens": ["Un\u00b7term", "Gal\u00b7gen", "be\u00b7gra\u00b7ben", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVPP", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}}, "stanza.50": {"line.1": {"text": "Sieh Bruder, du sollst nit stille stahn,", "tokens": ["Sieh", "Bru\u00b7der", ",", "du", "sollst", "nit", "stil\u00b7le", "stahn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "PPER", "VMFIN", "PTKNEG", "ADJA", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Vierzig Meil hast du noch zu gahn;", "tokens": ["Vier\u00b7zig", "Meil", "hast", "du", "noch", "zu", "gahn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "VAFIN", "PPER", "ADV", "PTKZU", "VVINF", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.3": {"text": "Wol in St. Jakobs M\u00fcnster.", "tokens": ["Wol", "in", "St.", "Ja\u00b7kobs", "M\u00fcns\u00b7ter", "."], "token_info": ["word", "word", "abbreviation", "word", "word", "punct"], "pos": ["ADV", "APPR", "NE", "NE", "NE", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Vierzehn Meil hinunter ba\u00df", "tokens": ["Vier\u00b7zehn", "Meil", "hin\u00b7un\u00b7ter", "ba\u00df"], "token_info": ["word", "word", "word", "word"], "pos": ["CARD", "NN", "ADV", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Zu einem Stern, hei\u00dft Finster.", "tokens": ["Zu", "ei\u00b7nem", "Stern", ",", "hei\u00dft", "Fins\u00b7ter", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "VVFIN", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.51": {"line.1": {"text": "Den finstern Stern wollen wir lan stahn,", "tokens": ["Den", "fins\u00b7tern", "Stern", "wol\u00b7len", "wir", "lan", "stahn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VMFIN", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Und wollen zu Salvator eingahn,", "tokens": ["Und", "wol\u00b7len", "zu", "Sal\u00b7va\u00b7tor", "ein\u00b7gahn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "APPR", "NN", "VVIZU", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Gro\u00df Wunderzeichen anschauen.", "tokens": ["Gro\u00df", "Wun\u00b7der\u00b7zei\u00b7chen", "an\u00b7schau\u00b7en", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "NN", "VVINF", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "So rufen wir Gott und St. Jakob an,", "tokens": ["So", "ru\u00b7fen", "wir", "Gott", "und", "St.", "Ja\u00b7kob", "an", ","], "token_info": ["word", "word", "word", "word", "word", "abbreviation", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "NN", "KON", "NE", "NE", "PTKVZ", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Und unsre liebe Frauen.", "tokens": ["Und", "uns\u00b7re", "lie\u00b7be", "Frau\u00b7en", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.52": {"line.1": {"text": "Bei St. Jakob vergiebt man Pein und Schuld,", "tokens": ["Bei", "St.", "Ja\u00b7kob", "ver\u00b7giebt", "man", "Pein", "und", "Schuld", ","], "token_info": ["word", "abbreviation", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "NE", "VVFIN", "PIS", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Der liebe Gott sei uns allen hold,", "tokens": ["Der", "lie\u00b7be", "Gott", "sei", "uns", "al\u00b7len", "hold", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "PPER", "PIAT", "ADJD", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "In seinem h\u00f6chsten Throne,", "tokens": ["In", "sei\u00b7nem", "h\u00f6chs\u00b7ten", "Thro\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Der St. Jakob dienen thut,", "tokens": ["Der", "St.", "Ja\u00b7kob", "die\u00b7nen", "thut", ","], "token_info": ["word", "abbreviation", "word", "word", "word", "punct"], "pos": ["ART", "NE", "NE", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Der lieb Gott soll ihm lohnen.", "tokens": ["Der", "lieb", "Gott", "soll", "ihm", "loh\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}}}}