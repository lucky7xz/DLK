{"textgrid.poem.65024": {"metadata": {"author": {"name": "Paoli, Betty", "birth": "N.A.", "death": "N.A."}, "title": "1L: Was wir gelitten und erduldet", "genre": "verse", "period": "N.A.", "pub_year": 1854, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Was wir gelitten und erduldet", "tokens": ["Was", "wir", "ge\u00b7lit\u00b7ten", "und", "er\u00b7dul\u00b7det"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "PPER", "VVPP", "KON", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Durch meine Fehler, deine Schw\u00e4chen,", "tokens": ["Durch", "mei\u00b7ne", "Feh\u00b7ler", ",", "dei\u00b7ne", "Schw\u00e4\u00b7chen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Was du geirrt, was ich verschuldet \u2013", "tokens": ["Was", "du", "ge\u00b7irrt", ",", "was", "ich", "ver\u00b7schul\u00b7det", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVPP", "$,", "PWS", "PPER", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wir wollen nicht dar\u00fcber sprechen.", "tokens": ["Wir", "wol\u00b7len", "nicht", "da\u00b7r\u00fc\u00b7ber", "spre\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PTKNEG", "PAV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Wer an dem Zwiespalt unsrer Tage \u2013", "tokens": ["Wer", "an", "dem", "Zwies\u00b7palt", "uns\u00b7rer", "Ta\u00b7ge", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "ART", "NN", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Zu l\u00f6sen nicht und nicht zu schlichten, \u2013", "tokens": ["Zu", "l\u00f6\u00b7sen", "nicht", "und", "nicht", "zu", "schlich\u00b7ten", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PTKZU", "VVINF", "PTKNEG", "KON", "PTKNEG", "PTKZU", "VVINF", "$,", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Die gr\u00f6\u00df're Schuld, die klein're trage,", "tokens": ["Die", "gr\u00f6\u00df'\u00b7re", "Schuld", ",", "die", "klein'\u00b7re", "tra\u00b7ge", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wir wollen nicht dar\u00fcber richten.", "tokens": ["Wir", "wol\u00b7len", "nicht", "da\u00b7r\u00fc\u00b7ber", "rich\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PTKNEG", "PAV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Ich wei\u00df nur Ein's! nur Eines f\u00fchle", "tokens": ["Ich", "wei\u00df", "nur", "Ein's", "!", "nur", "Ei\u00b7nes", "f\u00fch\u00b7le"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "NN", "$.", "ADV", "PIS", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Im Herzen ich, dem trauervollen:", "tokens": ["Im", "Her\u00b7zen", "ich", ",", "dem", "trau\u00b7er\u00b7vol\u00b7len", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPRART", "NN", "PPER", "$,", "PRELS", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Wir h\u00e4tten in dem Weltgew\u00fchle", "tokens": ["Wir", "h\u00e4t\u00b7ten", "in", "dem", "Welt\u00b7ge\u00b7w\u00fch\u00b7le"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Uns nun und nimmer finden sollen.", "tokens": ["Uns", "nun", "und", "nim\u00b7mer", "fin\u00b7den", "sol\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "KON", "ADV", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Und da wir dennoch uns gefunden,", "tokens": ["Und", "da", "wir", "den\u00b7noch", "uns", "ge\u00b7fun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "So la\u00df uns z\u00fcrnen nicht und klagen", "tokens": ["So", "la\u00df", "uns", "z\u00fcr\u00b7nen", "nicht", "und", "kla\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVIMP", "PPER", "VVFIN", "PTKNEG", "KON", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Ob all den Schmerzen und den Wunden,", "tokens": ["Ob", "all", "den", "Schmer\u00b7zen", "und", "den", "Wun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "ART", "NN", "KON", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die Ein's dem Andern wir geschlagen.", "tokens": ["Die", "Ein's", "dem", "An\u00b7dern", "wir", "ge\u00b7schla\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "ADJA", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Nicht b\u00f6ser Wille ist's gewesen,", "tokens": ["Nicht", "b\u00f6\u00b7ser", "Wil\u00b7le", "ist's", "ge\u00b7we\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADJA", "NN", "VAFIN", "VAPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Der uns gebracht so herbe Leiden;", "tokens": ["Der", "uns", "ge\u00b7bracht", "so", "her\u00b7be", "Lei\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVPP", "ADV", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Uns trennet unser tiefstes Wesen,", "tokens": ["Uns", "tren\u00b7net", "un\u00b7ser", "tiefs\u00b7tes", "We\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Der Gott im Innern hei\u00dft uns scheiden.", "tokens": ["Der", "Gott", "im", "In\u00b7nern", "hei\u00dft", "uns", "schei\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "VVFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Ein Frevel war, was einst wir schwuren", "tokens": ["Ein", "Fre\u00b7vel", "war", ",", "was", "einst", "wir", "schwu\u00b7ren"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "$,", "PRELS", "ADV", "PPER", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und Thorheit unser K\u00e4mpfen, Weinen!", "tokens": ["Und", "Thor\u00b7heit", "un\u00b7ser", "K\u00e4mp\u00b7fen", ",", "Wei\u00b7nen", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "NN", "PPOSAT", "NN", "$,", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Sich widerstrebende Naturen", "tokens": ["Sich", "wi\u00b7der\u00b7stre\u00b7ben\u00b7de", "Na\u00b7tu\u00b7ren"], "token_info": ["word", "word", "word"], "pos": ["PRF", "ADJA", "NN"], "meter": "-+-+---+-", "measure": "unknown.measure.tri"}, "line.4": {"text": "Die kann die Liebe nicht vereinen.", "tokens": ["Die", "kann", "die", "Lie\u00b7be", "nicht", "ver\u00b7ei\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "ART", "NN", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Je hei\u00dfer, sehnender sie ringen", "tokens": ["Je", "hei\u00b7\u00dfer", ",", "seh\u00b7nen\u00b7der", "sie", "rin\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "ADJD", "$,", "PRELS", "PPER", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Nach sel'gen Einklangs sanften Frieden,", "tokens": ["Nach", "sel'\u00b7gen", "Ein\u00b7klangs", "sanf\u00b7ten", "Frie\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "So tiefer wird es sie durchdringen,", "tokens": ["So", "tie\u00b7fer", "wird", "es", "sie", "durch\u00b7drin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VAFIN", "PPER", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Durch welche Kl\u00fcfte sie geschieden. \u2013", "tokens": ["Durch", "wel\u00b7che", "Kl\u00fcf\u00b7te", "sie", "ge\u00b7schie\u00b7den", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "PWAT", "NN", "PPER", "VVPP", "$.", "$("], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}}, "stanza.8": {"line.1": {"text": "Und so ist es auch uns ergangen,", "tokens": ["Und", "so", "ist", "es", "auch", "uns", "er\u00b7gan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "PPER", "ADV", "PPER", "VVPP", "$,"], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.2": {"text": "Gott wei\u00df allein, mit welchen Qualen", "tokens": ["Gott", "wei\u00df", "al\u00b7lein", ",", "mit", "wel\u00b7chen", "Qua\u00b7len"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "VVFIN", "ADV", "$,", "APPR", "PWAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Mit wie verzweiflungsvollem Bangen", "tokens": ["Mit", "wie", "ver\u00b7zwei\u00b7flungs\u00b7vol\u00b7lem", "Ban\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "KOKOM", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wir f\u00fcr den Irrthum mu\u00dften zahlen.", "tokens": ["Wir", "f\u00fcr", "den", "Irr\u00b7thum", "mu\u00df\u00b7ten", "zah\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "ART", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Jetzt ist der Klarheit Tag erschienen \u2013", "tokens": ["Jetzt", "ist", "der", "Klar\u00b7heit", "Tag", "er\u00b7schie\u00b7nen", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "NN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "La\u00df uns ihn ohne Groll begr\u00fc\u00dfen", "tokens": ["La\u00df", "uns", "ihn", "oh\u00b7ne", "Groll", "be\u00b7gr\u00fc\u00b7\u00dfen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVIMP", "PPER", "PPER", "APPR", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und, klaglos, auf des Gl\u00fccks Ruinen", "tokens": ["Und", ",", "klag\u00b7los", ",", "auf", "des", "Gl\u00fccks", "Ru\u00b7i\u00b7nen"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "$,", "ADJD", "$,", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "F\u00fcr Schuld, die nicht die unsre, b\u00fc\u00dfen.", "tokens": ["F\u00fcr", "Schuld", ",", "die", "nicht", "die", "uns\u00b7re", ",", "b\u00fc\u00b7\u00dfen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "NN", "$,", "PRELS", "PTKNEG", "ART", "NN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Was wir gelitten und erduldet", "tokens": ["Was", "wir", "ge\u00b7lit\u00b7ten", "und", "er\u00b7dul\u00b7det"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "PPER", "VVPP", "KON", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Durch meine Fehler, deine Schw\u00e4chen,", "tokens": ["Durch", "mei\u00b7ne", "Feh\u00b7ler", ",", "dei\u00b7ne", "Schw\u00e4\u00b7chen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Was du geirrt, was ich verschuldet \u2013", "tokens": ["Was", "du", "ge\u00b7irrt", ",", "was", "ich", "ver\u00b7schul\u00b7det", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVPP", "$,", "PWS", "PPER", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wir wollen nicht dar\u00fcber sprechen.", "tokens": ["Wir", "wol\u00b7len", "nicht", "da\u00b7r\u00fc\u00b7ber", "spre\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PTKNEG", "PAV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Wer an dem Zwiespalt unsrer Tage \u2013", "tokens": ["Wer", "an", "dem", "Zwies\u00b7palt", "uns\u00b7rer", "Ta\u00b7ge", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "ART", "NN", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Zu l\u00f6sen nicht und nicht zu schlichten, \u2013", "tokens": ["Zu", "l\u00f6\u00b7sen", "nicht", "und", "nicht", "zu", "schlich\u00b7ten", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PTKZU", "VVINF", "PTKNEG", "KON", "PTKNEG", "PTKZU", "VVINF", "$,", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Die gr\u00f6\u00df're Schuld, die klein're trage,", "tokens": ["Die", "gr\u00f6\u00df'\u00b7re", "Schuld", ",", "die", "klein'\u00b7re", "tra\u00b7ge", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wir wollen nicht dar\u00fcber richten.", "tokens": ["Wir", "wol\u00b7len", "nicht", "da\u00b7r\u00fc\u00b7ber", "rich\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PTKNEG", "PAV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Ich wei\u00df nur Ein's! nur Eines f\u00fchle", "tokens": ["Ich", "wei\u00df", "nur", "Ein's", "!", "nur", "Ei\u00b7nes", "f\u00fch\u00b7le"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "NN", "$.", "ADV", "PIS", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Im Herzen ich, dem trauervollen:", "tokens": ["Im", "Her\u00b7zen", "ich", ",", "dem", "trau\u00b7er\u00b7vol\u00b7len", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPRART", "NN", "PPER", "$,", "PRELS", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Wir h\u00e4tten in dem Weltgew\u00fchle", "tokens": ["Wir", "h\u00e4t\u00b7ten", "in", "dem", "Welt\u00b7ge\u00b7w\u00fch\u00b7le"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Uns nun und nimmer finden sollen.", "tokens": ["Uns", "nun", "und", "nim\u00b7mer", "fin\u00b7den", "sol\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "KON", "ADV", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Und da wir dennoch uns gefunden,", "tokens": ["Und", "da", "wir", "den\u00b7noch", "uns", "ge\u00b7fun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "So la\u00df uns z\u00fcrnen nicht und klagen", "tokens": ["So", "la\u00df", "uns", "z\u00fcr\u00b7nen", "nicht", "und", "kla\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVIMP", "PPER", "VVFIN", "PTKNEG", "KON", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Ob all den Schmerzen und den Wunden,", "tokens": ["Ob", "all", "den", "Schmer\u00b7zen", "und", "den", "Wun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "ART", "NN", "KON", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die Ein's dem Andern wir geschlagen.", "tokens": ["Die", "Ein's", "dem", "An\u00b7dern", "wir", "ge\u00b7schla\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "ADJA", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Nicht b\u00f6ser Wille ist's gewesen,", "tokens": ["Nicht", "b\u00f6\u00b7ser", "Wil\u00b7le", "ist's", "ge\u00b7we\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADJA", "NN", "VAFIN", "VAPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Der uns gebracht so herbe Leiden;", "tokens": ["Der", "uns", "ge\u00b7bracht", "so", "her\u00b7be", "Lei\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVPP", "ADV", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Uns trennet unser tiefstes Wesen,", "tokens": ["Uns", "tren\u00b7net", "un\u00b7ser", "tiefs\u00b7tes", "We\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Der Gott im Innern hei\u00dft uns scheiden.", "tokens": ["Der", "Gott", "im", "In\u00b7nern", "hei\u00dft", "uns", "schei\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "VVFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "Ein Frevel war, was einst wir schwuren", "tokens": ["Ein", "Fre\u00b7vel", "war", ",", "was", "einst", "wir", "schwu\u00b7ren"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "$,", "PRELS", "ADV", "PPER", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und Thorheit unser K\u00e4mpfen, Weinen!", "tokens": ["Und", "Thor\u00b7heit", "un\u00b7ser", "K\u00e4mp\u00b7fen", ",", "Wei\u00b7nen", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "NN", "PPOSAT", "NN", "$,", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Sich widerstrebende Naturen", "tokens": ["Sich", "wi\u00b7der\u00b7stre\u00b7ben\u00b7de", "Na\u00b7tu\u00b7ren"], "token_info": ["word", "word", "word"], "pos": ["PRF", "ADJA", "NN"], "meter": "-+-+---+-", "measure": "unknown.measure.tri"}, "line.4": {"text": "Die kann die Liebe nicht vereinen.", "tokens": ["Die", "kann", "die", "Lie\u00b7be", "nicht", "ver\u00b7ei\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "ART", "NN", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "Je hei\u00dfer, sehnender sie ringen", "tokens": ["Je", "hei\u00b7\u00dfer", ",", "seh\u00b7nen\u00b7der", "sie", "rin\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "ADJD", "$,", "PRELS", "PPER", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Nach sel'gen Einklangs sanften Frieden,", "tokens": ["Nach", "sel'\u00b7gen", "Ein\u00b7klangs", "sanf\u00b7ten", "Frie\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "So tiefer wird es sie durchdringen,", "tokens": ["So", "tie\u00b7fer", "wird", "es", "sie", "durch\u00b7drin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VAFIN", "PPER", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Durch welche Kl\u00fcfte sie geschieden. \u2013", "tokens": ["Durch", "wel\u00b7che", "Kl\u00fcf\u00b7te", "sie", "ge\u00b7schie\u00b7den", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "PWAT", "NN", "PPER", "VVPP", "$.", "$("], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}}, "stanza.17": {"line.1": {"text": "Und so ist es auch uns ergangen,", "tokens": ["Und", "so", "ist", "es", "auch", "uns", "er\u00b7gan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "PPER", "ADV", "PPER", "VVPP", "$,"], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.2": {"text": "Gott wei\u00df allein, mit welchen Qualen", "tokens": ["Gott", "wei\u00df", "al\u00b7lein", ",", "mit", "wel\u00b7chen", "Qua\u00b7len"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "VVFIN", "ADV", "$,", "APPR", "PWAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Mit wie verzweiflungsvollem Bangen", "tokens": ["Mit", "wie", "ver\u00b7zwei\u00b7flungs\u00b7vol\u00b7lem", "Ban\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "KOKOM", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wir f\u00fcr den Irrthum mu\u00dften zahlen.", "tokens": ["Wir", "f\u00fcr", "den", "Irr\u00b7thum", "mu\u00df\u00b7ten", "zah\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "ART", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.18": {"line.1": {"text": "Jetzt ist der Klarheit Tag erschienen \u2013", "tokens": ["Jetzt", "ist", "der", "Klar\u00b7heit", "Tag", "er\u00b7schie\u00b7nen", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "NN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "La\u00df uns ihn ohne Groll begr\u00fc\u00dfen", "tokens": ["La\u00df", "uns", "ihn", "oh\u00b7ne", "Groll", "be\u00b7gr\u00fc\u00b7\u00dfen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVIMP", "PPER", "PPER", "APPR", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und, klaglos, auf des Gl\u00fccks Ruinen", "tokens": ["Und", ",", "klag\u00b7los", ",", "auf", "des", "Gl\u00fccks", "Ru\u00b7i\u00b7nen"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "$,", "ADJD", "$,", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "F\u00fcr Schuld, die nicht die unsre, b\u00fc\u00dfen.", "tokens": ["F\u00fcr", "Schuld", ",", "die", "nicht", "die", "uns\u00b7re", ",", "b\u00fc\u00b7\u00dfen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "NN", "$,", "PRELS", "PTKNEG", "ART", "NN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}