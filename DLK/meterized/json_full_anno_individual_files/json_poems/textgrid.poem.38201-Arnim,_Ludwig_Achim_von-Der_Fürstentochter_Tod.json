{"textgrid.poem.38201": {"metadata": {"author": {"name": "Arnim, Ludwig Achim von", "birth": "N.A.", "death": "N.A."}, "title": "Der F\u00fcrstentochter Tod", "genre": "verse", "period": "N.A.", "pub_year": 1806, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Es fuhr gen Acker ein grober Baur,", "tokens": ["Es", "fuhr", "gen", "A\u00b7cker", "ein", "gro\u00b7ber", "Baur", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Arbeitet wacker im Schweis so sau'r,", "tokens": ["Ar\u00b7bei\u00b7tet", "wa\u00b7cker", "im", "Schweis", "so", "sau'r", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "APPRART", "NN", "ADV", "ADJD", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Im Fr\u00fchling, M\u00e4rzen, May, April,", "tokens": ["Im", "Fr\u00fch\u00b7ling", ",", "M\u00e4r\u00b7zen", ",", "May", ",", "Ap\u00b7ril", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["APPRART", "NN", "$,", "NN", "$,", "NE", "$,", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Im Feld standen der Bl\u00fcmlein viel,", "tokens": ["Im", "Feld", "stan\u00b7den", "der", "Bl\u00fcm\u00b7lein", "viel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "ART", "NN", "ADV", "$,"], "meter": "-+---+-+", "measure": "dactylic.init"}, "line.5": {"text": "Die ihn anlachten in der Still.", "tokens": ["Die", "ihn", "an\u00b7lach\u00b7ten", "in", "der", "Still", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Er lie\u00df sich solches bewegen nicht,", "tokens": ["Er", "lie\u00df", "sich", "sol\u00b7ches", "be\u00b7we\u00b7gen", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "PIAT", "ADJA", "PTKNEG", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Mit seinem Pflug er sich dr\u00fcber richt,", "tokens": ["Mit", "sei\u00b7nem", "Pflug", "er", "sich", "dr\u00fc\u00b7ber", "richt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PPER", "PRF", "PAV", "VVFIN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Er ", "tokens": ["Er"], "token_info": ["word"], "pos": ["PPER"], "meter": "-", "measure": "single.down"}, "line.4": {"text": "Und griff an ihren Wurzeln an", "tokens": ["Und", "griff", "an", "ih\u00b7ren", "Wur\u00b7zeln", "an"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "PPOSAT", "NN", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die sch\u00f6nen Blumen lobesan.", "tokens": ["Die", "sch\u00f6\u00b7nen", "Blu\u00b7men", "lo\u00b7be\u00b7san", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Die Bl\u00fcmlein neigten die K\u00f6pfe zart,", "tokens": ["Die", "Bl\u00fcm\u00b7lein", "neig\u00b7ten", "die", "K\u00f6p\u00b7fe", "zart", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "ADJD", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Sanken darnieder zu Boden hart,", "tokens": ["San\u00b7ken", "dar\u00b7nie\u00b7der", "zu", "Bo\u00b7den", "hart", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PAV", "APPR", "NN", "ADJD", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.3": {"text": "Ich sie anschaute sinniglich,", "tokens": ["Ich", "sie", "an\u00b7schau\u00b7te", "sin\u00b7nig\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "PPER", "VVFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Von Herzen sie erbarmten mich,", "tokens": ["Von", "Her\u00b7zen", "sie", "er\u00b7barm\u00b7ten", "mich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PPER", "VVFIN", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "H\u00e4tt sie wohl gern errettet ich.", "tokens": ["H\u00e4tt", "sie", "wohl", "gern", "er\u00b7ret\u00b7tet", "ich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Auf unsres F\u00fcrsten sein Wiesen gr\u00fcn", "tokens": ["Auf", "uns\u00b7res", "F\u00fcrs\u00b7ten", "sein", "Wie\u00b7sen", "gr\u00fcn"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "PPOSAT", "NN", "ADJD"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.2": {"text": "Da that ein holdselig Bl\u00fcmlein bl\u00fchn,", "tokens": ["Da", "that", "ein", "hold\u00b7se\u00b7lig", "Bl\u00fcm\u00b7lein", "bl\u00fchn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJD", "NN", "VVINF", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Das war sein liebstes T\u00f6chterlein,", "tokens": ["Das", "war", "sein", "liebs\u00b7tes", "T\u00f6ch\u00b7ter\u00b7lein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Zw\u00f6lfj\u00e4hrig, edel, h\u00fcbsch und fein,", "tokens": ["Zw\u00f6lf\u00b7j\u00e4h\u00b7rig", ",", "e\u00b7del", ",", "h\u00fcbsch", "und", "fein", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "ADJD", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ein Herzentrost den Aeltern sein.", "tokens": ["Ein", "Her\u00b7zent\u00b7rost", "den", "A\u00b7el\u00b7tern", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VAINF", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.5": {"line.1": {"text": "Da kam der grimmige Tod daher,", "tokens": ["Da", "kam", "der", "grim\u00b7mi\u00b7ge", "Tod", "da\u00b7her", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "PAV", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Trabanten, Garden, nichts achtet er,", "tokens": ["Tra\u00b7ban\u00b7ten", ",", "Gar\u00b7den", ",", "nichts", "ach\u00b7tet", "er", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "PIS", "VVFIN", "PPER", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Frey trat er in die Burg hinein,", "tokens": ["Frey", "trat", "er", "in", "die", "Burg", "hin\u00b7ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "APPR", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Schlug grausam ins Frauenzimmer drein,", "tokens": ["Schlug", "grau\u00b7sam", "ins", "Frau\u00b7en\u00b7zim\u00b7mer", "drein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "APPRART", "NN", "PTKVZ", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Und traf das F\u00fcrstliche Fr\u00e4ulein allein.", "tokens": ["Und", "traf", "das", "F\u00fcrst\u00b7li\u00b7che", "Fr\u00e4u\u00b7lein", "al\u00b7lein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "ADJA", "NN", "ADV", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}}, "stanza.6": {"line.1": {"text": "Nun kommt zum Saale ihr Christenleut,", "tokens": ["Nun", "kommt", "zum", "Saa\u00b7le", "ihr", "Chris\u00b7ten\u00b7leut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPRART", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Nun gehet ins Feld mit bitterem Leid,", "tokens": ["Nun", "ge\u00b7het", "ins", "Feld", "mit", "bit\u00b7te\u00b7rem", "Leid", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPRART", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Zwey Blumen stehn auf einem Feld,", "tokens": ["Zwey", "Blu\u00b7men", "stehn", "auf", "ei\u00b7nem", "Feld", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die eine frisch, die andre welk,", "tokens": ["Die", "ei\u00b7ne", "frisch", ",", "die", "and\u00b7re", "welk", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ART", "ADJD", "$,", "PRELS", "PIS", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Rath, welche l\u00e4nger sich erh\u00e4lt.", "tokens": ["Rath", ",", "wel\u00b7che", "l\u00e4n\u00b7ger", "sich", "er\u00b7h\u00e4lt", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PRELS", "ADJD", "PRF", "VVFIN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.7": {"line.1": {"text": "Da kommt gegangen ein Wandersmann,", "tokens": ["Da", "kommt", "ge\u00b7gan\u00b7gen", "ein", "Wan\u00b7ders\u00b7mann", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "VVPP", "ART", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Der tr\u00e4gt Verlangen zu greifen an,", "tokens": ["Der", "tr\u00e4gt", "Ver\u00b7lan\u00b7gen", "zu", "grei\u00b7fen", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "NN", "PTKZU", "VVINF", "PTKVZ", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Der Blumen eine mit Gewalt,", "tokens": ["Der", "Blu\u00b7men", "ei\u00b7ne", "mit", "Ge\u00b7walt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Hand darnach er ausstreckt bald,", "tokens": ["Die", "Hand", "dar\u00b7nach", "er", "aus\u00b7streckt", "bald", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PAV", "PPER", "VVFIN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Nimmt die am besten ihm gefallt.", "tokens": ["Nimmt", "die", "am", "bes\u00b7ten", "ihm", "ge\u00b7fallt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "APPRART", "ADJA", "PPER", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Die halbverwelkte will er nicht,", "tokens": ["Die", "halb\u00b7ver\u00b7welk\u00b7te", "will", "er", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "VMFIN", "PPER", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die frische ihm in die Augen sticht,", "tokens": ["Die", "fri\u00b7sche", "ihm", "in", "die", "Au\u00b7gen", "sticht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "PPER", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Er l\u00e4\u00dft die alt und nimmt die neu,", "tokens": ["Er", "l\u00e4\u00dft", "die", "alt", "und", "nimmt", "die", "neu", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJD", "KON", "VVFIN", "ART", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Thut dran gar recht bey meiner Treu,", "tokens": ["Thut", "dran", "gar", "recht", "bey", "mei\u00b7ner", "Treu", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PAV", "ADV", "ADJD", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ich machets auch so ohne Scheu.", "tokens": ["Ich", "ma\u00b7chets", "auch", "so", "oh\u00b7ne", "Scheu", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Es fuhr gen Acker ein grober Baur,", "tokens": ["Es", "fuhr", "gen", "A\u00b7cker", "ein", "gro\u00b7ber", "Baur", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Arbeitet wacker im Schweis so sau'r,", "tokens": ["Ar\u00b7bei\u00b7tet", "wa\u00b7cker", "im", "Schweis", "so", "sau'r", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "APPRART", "NN", "ADV", "ADJD", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Im Fr\u00fchling, M\u00e4rzen, May, April,", "tokens": ["Im", "Fr\u00fch\u00b7ling", ",", "M\u00e4r\u00b7zen", ",", "May", ",", "Ap\u00b7ril", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["APPRART", "NN", "$,", "NN", "$,", "NE", "$,", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Im Feld standen der Bl\u00fcmlein viel,", "tokens": ["Im", "Feld", "stan\u00b7den", "der", "Bl\u00fcm\u00b7lein", "viel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "ART", "NN", "ADV", "$,"], "meter": "-+---+-+", "measure": "dactylic.init"}, "line.5": {"text": "Die ihn anlachten in der Still.", "tokens": ["Die", "ihn", "an\u00b7lach\u00b7ten", "in", "der", "Still", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Er lie\u00df sich solches bewegen nicht,", "tokens": ["Er", "lie\u00df", "sich", "sol\u00b7ches", "be\u00b7we\u00b7gen", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "PIAT", "ADJA", "PTKNEG", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Mit seinem Pflug er sich dr\u00fcber richt,", "tokens": ["Mit", "sei\u00b7nem", "Pflug", "er", "sich", "dr\u00fc\u00b7ber", "richt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PPER", "PRF", "PAV", "VVFIN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Er ", "tokens": ["Er"], "token_info": ["word"], "pos": ["PPER"], "meter": "-", "measure": "single.down"}, "line.4": {"text": "Und griff an ihren Wurzeln an", "tokens": ["Und", "griff", "an", "ih\u00b7ren", "Wur\u00b7zeln", "an"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "PPOSAT", "NN", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die sch\u00f6nen Blumen lobesan.", "tokens": ["Die", "sch\u00f6\u00b7nen", "Blu\u00b7men", "lo\u00b7be\u00b7san", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Die Bl\u00fcmlein neigten die K\u00f6pfe zart,", "tokens": ["Die", "Bl\u00fcm\u00b7lein", "neig\u00b7ten", "die", "K\u00f6p\u00b7fe", "zart", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "ADJD", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Sanken darnieder zu Boden hart,", "tokens": ["San\u00b7ken", "dar\u00b7nie\u00b7der", "zu", "Bo\u00b7den", "hart", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PAV", "APPR", "NN", "ADJD", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.3": {"text": "Ich sie anschaute sinniglich,", "tokens": ["Ich", "sie", "an\u00b7schau\u00b7te", "sin\u00b7nig\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "PPER", "VVFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Von Herzen sie erbarmten mich,", "tokens": ["Von", "Her\u00b7zen", "sie", "er\u00b7barm\u00b7ten", "mich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PPER", "VVFIN", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "H\u00e4tt sie wohl gern errettet ich.", "tokens": ["H\u00e4tt", "sie", "wohl", "gern", "er\u00b7ret\u00b7tet", "ich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Auf unsres F\u00fcrsten sein Wiesen gr\u00fcn", "tokens": ["Auf", "uns\u00b7res", "F\u00fcrs\u00b7ten", "sein", "Wie\u00b7sen", "gr\u00fcn"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "PPOSAT", "NN", "ADJD"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.2": {"text": "Da that ein holdselig Bl\u00fcmlein bl\u00fchn,", "tokens": ["Da", "that", "ein", "hold\u00b7se\u00b7lig", "Bl\u00fcm\u00b7lein", "bl\u00fchn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJD", "NN", "VVINF", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Das war sein liebstes T\u00f6chterlein,", "tokens": ["Das", "war", "sein", "liebs\u00b7tes", "T\u00f6ch\u00b7ter\u00b7lein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Zw\u00f6lfj\u00e4hrig, edel, h\u00fcbsch und fein,", "tokens": ["Zw\u00f6lf\u00b7j\u00e4h\u00b7rig", ",", "e\u00b7del", ",", "h\u00fcbsch", "und", "fein", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "ADJD", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ein Herzentrost den Aeltern sein.", "tokens": ["Ein", "Her\u00b7zent\u00b7rost", "den", "A\u00b7el\u00b7tern", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VAINF", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.13": {"line.1": {"text": "Da kam der grimmige Tod daher,", "tokens": ["Da", "kam", "der", "grim\u00b7mi\u00b7ge", "Tod", "da\u00b7her", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "PAV", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Trabanten, Garden, nichts achtet er,", "tokens": ["Tra\u00b7ban\u00b7ten", ",", "Gar\u00b7den", ",", "nichts", "ach\u00b7tet", "er", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "PIS", "VVFIN", "PPER", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Frey trat er in die Burg hinein,", "tokens": ["Frey", "trat", "er", "in", "die", "Burg", "hin\u00b7ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "APPR", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Schlug grausam ins Frauenzimmer drein,", "tokens": ["Schlug", "grau\u00b7sam", "ins", "Frau\u00b7en\u00b7zim\u00b7mer", "drein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "APPRART", "NN", "PTKVZ", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Und traf das F\u00fcrstliche Fr\u00e4ulein allein.", "tokens": ["Und", "traf", "das", "F\u00fcrst\u00b7li\u00b7che", "Fr\u00e4u\u00b7lein", "al\u00b7lein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "ADJA", "NN", "ADV", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}}, "stanza.14": {"line.1": {"text": "Nun kommt zum Saale ihr Christenleut,", "tokens": ["Nun", "kommt", "zum", "Saa\u00b7le", "ihr", "Chris\u00b7ten\u00b7leut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPRART", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Nun gehet ins Feld mit bitterem Leid,", "tokens": ["Nun", "ge\u00b7het", "ins", "Feld", "mit", "bit\u00b7te\u00b7rem", "Leid", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPRART", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Zwey Blumen stehn auf einem Feld,", "tokens": ["Zwey", "Blu\u00b7men", "stehn", "auf", "ei\u00b7nem", "Feld", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die eine frisch, die andre welk,", "tokens": ["Die", "ei\u00b7ne", "frisch", ",", "die", "and\u00b7re", "welk", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ART", "ADJD", "$,", "PRELS", "PIS", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Rath, welche l\u00e4nger sich erh\u00e4lt.", "tokens": ["Rath", ",", "wel\u00b7che", "l\u00e4n\u00b7ger", "sich", "er\u00b7h\u00e4lt", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PRELS", "ADJD", "PRF", "VVFIN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.15": {"line.1": {"text": "Da kommt gegangen ein Wandersmann,", "tokens": ["Da", "kommt", "ge\u00b7gan\u00b7gen", "ein", "Wan\u00b7ders\u00b7mann", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "VVPP", "ART", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Der tr\u00e4gt Verlangen zu greifen an,", "tokens": ["Der", "tr\u00e4gt", "Ver\u00b7lan\u00b7gen", "zu", "grei\u00b7fen", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "NN", "PTKZU", "VVINF", "PTKVZ", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Der Blumen eine mit Gewalt,", "tokens": ["Der", "Blu\u00b7men", "ei\u00b7ne", "mit", "Ge\u00b7walt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Hand darnach er ausstreckt bald,", "tokens": ["Die", "Hand", "dar\u00b7nach", "er", "aus\u00b7streckt", "bald", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PAV", "PPER", "VVFIN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Nimmt die am besten ihm gefallt.", "tokens": ["Nimmt", "die", "am", "bes\u00b7ten", "ihm", "ge\u00b7fallt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "APPRART", "ADJA", "PPER", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "Die halbverwelkte will er nicht,", "tokens": ["Die", "halb\u00b7ver\u00b7welk\u00b7te", "will", "er", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "VMFIN", "PPER", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die frische ihm in die Augen sticht,", "tokens": ["Die", "fri\u00b7sche", "ihm", "in", "die", "Au\u00b7gen", "sticht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "PPER", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Er l\u00e4\u00dft die alt und nimmt die neu,", "tokens": ["Er", "l\u00e4\u00dft", "die", "alt", "und", "nimmt", "die", "neu", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJD", "KON", "VVFIN", "ART", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Thut dran gar recht bey meiner Treu,", "tokens": ["Thut", "dran", "gar", "recht", "bey", "mei\u00b7ner", "Treu", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PAV", "ADV", "ADJD", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ich machets auch so ohne Scheu.", "tokens": ["Ich", "ma\u00b7chets", "auch", "so", "oh\u00b7ne", "Scheu", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}