{"textgrid.poem.44117": {"metadata": {"author": {"name": "G\u00fcnther, Johann Christian", "birth": "N.A.", "death": "N.A."}, "title": "1L: Vergebliche Gedult! Die Hofnung be\u00dfrer Zeiten", "genre": "verse", "period": "N.A.", "pub_year": 1709, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Vergebliche Gedult! Die Hofnung be\u00dfrer Zeiten", "tokens": ["Ver\u00b7geb\u00b7li\u00b7che", "Ge\u00b7dult", "!", "Die", "Hof\u00b7nung", "be\u00df\u00b7rer", "Zei\u00b7ten"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADJA", "NN", "$.", "ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Speist mein Verlangen nur mit faulen Fischen ab.", "tokens": ["Speist", "mein", "Ver\u00b7lan\u00b7gen", "nur", "mit", "fau\u00b7len", "Fi\u00b7schen", "ab", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "ADV", "APPR", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Man log vom Juppiter, in Creta sey sein Grab,", "tokens": ["Man", "log", "vom", "Jup\u00b7pi\u00b7ter", ",", "in", "Cre\u00b7ta", "sey", "sein", "Grab", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "APPRART", "NN", "$,", "APPR", "NE", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Mir wird man's in der That in Deutschland zubereiten.", "tokens": ["Mir", "wird", "man's", "in", "der", "That", "in", "Deutschland", "zu\u00b7be\u00b7rei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIS", "APPR", "ART", "NN", "APPR", "NE", "VVINF", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Kein G\u00f6nner liebt mein Volck, kein Prinz zieht wie August", "tokens": ["Kein", "G\u00f6n\u00b7ner", "liebt", "mein", "Volck", ",", "kein", "Prinz", "zieht", "wie", "Au\u00b7gust"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "VVFIN", "PPOSAT", "NN", "$,", "PIAT", "NN", "VVFIN", "KOKOM", "NN"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Der Dichter Lorbeerkranz aus dem Verachtungsstaube.", "tokens": ["Der", "Dich\u00b7ter", "Lor\u00b7beer\u00b7kranz", "aus", "dem", "Ver\u00b7ach\u00b7tungs\u00b7stau\u00b7be", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Der Neid quetscht ihren Ruhm mit seiner L\u00e4sterschraube", "tokens": ["Der", "Neid", "quetscht", "ih\u00b7ren", "Ruhm", "mit", "sei\u00b7ner", "L\u00e4s\u00b7ter\u00b7schrau\u00b7be"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PPOSAT", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und sezt der Poesie das Mordheft auf die Brust.", "tokens": ["Und", "sezt", "der", "Poe\u00b7sie", "das", "Mord\u00b7heft", "auf", "die", "Brust", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+----+-+-+", "measure": "dactylic.init"}}, "stanza.2": {"line.1": {"text": "Vor dem lebt' eine Welt, die meine Diener ehrte,", "tokens": ["Vor", "dem", "lebt'", "ei\u00b7ne", "Welt", ",", "die", "mei\u00b7ne", "Die\u00b7ner", "ehr\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "VVFIN", "ART", "NN", "$,", "PRELS", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Da Delphus noch nicht schwieg, Rom in der Bl\u00fcthe stand,", "tokens": ["Da", "Del\u00b7phus", "noch", "nicht", "schwieg", ",", "Rom", "in", "der", "Bl\u00fc\u00b7the", "stand", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "ADV", "PTKNEG", "VVFIN", "$,", "NE", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Mir bothen K\u00f6nige die gnadenreiche Hand,", "tokens": ["Mir", "bo\u00b7then", "K\u00f6\u00b7ni\u00b7ge", "die", "gna\u00b7den\u00b7rei\u00b7che", "Hand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wenn ihr ge\u00fcbtes Ohr gebundne Sprachen h\u00f6rte.", "tokens": ["Wenn", "ihr", "ge\u00b7\u00fcb\u00b7tes", "Ohr", "ge\u00b7bund\u00b7ne", "Spra\u00b7chen", "h\u00f6r\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "ADJA", "NN", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Jezt, seit der Bober-Schwan mein deutsches Kleid gemacht,", "tokens": ["Jezt", ",", "seit", "der", "Bo\u00b7ber\u00b7Schwan", "mein", "deut\u00b7sches", "Kleid", "ge\u00b7macht", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "APPR", "ART", "NN", "PPOSAT", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Th\u00e4t es warhaftig noth, den Magen zu bedencken,", "tokens": ["Th\u00e4t", "es", "war\u00b7haf\u00b7tig", "noth", ",", "den", "Ma\u00b7gen", "zu", "be\u00b7den\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "NN", "$,", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.7": {"text": "Ich lief um Fastnachtszeit in alle Kr\u00fcg und Schencken", "tokens": ["Ich", "lief", "um", "Fast\u00b7nachts\u00b7zeit", "in", "al\u00b7le", "Kr\u00fcg", "und", "Schen\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "NN", "APPR", "PIAT", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und leyrte vor ein Brodt vom Mittag in die Nacht.", "tokens": ["Und", "leyr\u00b7te", "vor", "ein", "Brodt", "vom", "Mit\u00b7tag", "in", "die", "Nacht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "APPRART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Mein wohlgestimmtes Spiel, das manchen Held besungen,", "tokens": ["Mein", "wohl\u00b7ge\u00b7stimm\u00b7tes", "Spiel", ",", "das", "man\u00b7chen", "Held", "be\u00b7sun\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,", "PRELS", "PIAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Steht kaum noch diesem an, der nach dem Bocke springt.", "tokens": ["Steht", "kaum", "noch", "die\u00b7sem", "an", ",", "der", "nach", "dem", "Bo\u00b7cke", "springt", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADV", "PDAT", "PTKVZ", "$,", "PRELS", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wenn die von Wachs und Rohr gemachte Pfeife klingt,", "tokens": ["Wenn", "die", "von", "Wachs", "und", "Rohr", "ge\u00b7mach\u00b7te", "Pfei\u00b7fe", "klingt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "APPR", "NN", "KON", "NN", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So wird mein Fl\u00f6thenschall durch ihren Thon verdrungen.", "tokens": ["So", "wird", "mein", "Fl\u00f6\u00b7then\u00b7schall", "durch", "ih\u00b7ren", "Thon", "ver\u00b7drun\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPOSAT", "NN", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Warum? Die Thorheit schl\u00e4gt dem groben Midas nach,", "tokens": ["Wa\u00b7rum", "?", "Die", "Thor\u00b7heit", "schl\u00e4gt", "dem", "gro\u00b7ben", "Mi\u00b7das", "nach", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$.", "ART", "NN", "VVFIN", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Der von der Pfuscherey des Pans aus Unverstande,", "tokens": ["Der", "von", "der", "Pfu\u00b7sche\u00b7rey", "des", "Pans", "aus", "Un\u00b7ver\u00b7stan\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "ART", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Zum Nachtheil meiner Kunst, sich selbst zur Straf und Schande,", "tokens": ["Zum", "Nacht\u00b7heil", "mei\u00b7ner", "Kunst", ",", "sich", "selbst", "zur", "Straf", "und", "Schan\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PPOSAT", "NN", "$,", "PRF", "ADV", "APPRART", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Ein seiner Unvernunft gem\u00e4\u00dfes Urtheil sprach.", "tokens": ["Ein", "sei\u00b7ner", "Un\u00b7ver\u00b7nunft", "ge\u00b7m\u00e4\u00b7\u00dfes", "Ur\u00b7theil", "sprach", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Mit solchen Worten schmi\u00df der F\u00fcrst der Pierinnen", "tokens": ["Mit", "sol\u00b7chen", "Wor\u00b7ten", "schmi\u00df", "der", "F\u00fcrst", "der", "Pie\u00b7rin\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PIAT", "NN", "VVFIN", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Den Unmuth aus der Brust, die Glieder auf die Banck", "tokens": ["Den", "Un\u00b7muth", "aus", "der", "Brust", ",", "die", "Glie\u00b7der", "auf", "die", "Banck"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$,", "ART", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und ward vor \u00c4rgern\u00fc\u00df nicht so geschwinde kranck", "tokens": ["Und", "ward", "vor", "\u00c4r\u00b7ger\u00b7n\u00fc\u00df", "nicht", "so", "ge\u00b7schwin\u00b7de", "kranck"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "APPR", "NN", "PTKNEG", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Als die Calliope nicht seiner Ohnmacht innen.", "tokens": ["Als", "die", "Cal\u00b7li\u00b7o\u00b7pe", "nicht", "sei\u00b7ner", "Ohn\u00b7macht", "in\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "PTKNEG", "PPOSAT", "NN", "ADV", "$."], "meter": "--+--+-+-+-+-", "measure": "anapaest.di.plus"}, "line.5": {"text": "Sie stuzte, schwieg und schrie, die Schwestern liefen zu,", "tokens": ["Sie", "stuz\u00b7te", ",", "schwieg", "und", "schrie", ",", "die", "Schwes\u00b7tern", "lie\u00b7fen", "zu", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "VVFIN", "KON", "VVFIN", "$,", "ART", "NN", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Doch nein, sie liefen nicht, sie flogen mit den F\u00fc\u00dfen:", "tokens": ["Doch", "nein", ",", "sie", "lie\u00b7fen", "nicht", ",", "sie", "flo\u00b7gen", "mit", "den", "F\u00fc\u00b7\u00dfen", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKANT", "$,", "PPER", "VVFIN", "PTKNEG", "$,", "PPER", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "So lernt ein leichtes Reh, wenn es das Nez durchri\u00dfen,", "tokens": ["So", "lernt", "ein", "leich\u00b7tes", "Reh", ",", "wenn", "es", "das", "Nez", "durch\u00b7ri\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "$,", "KOUS", "PPER", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Was Schr\u00f6cken und Gefahr vor weite Spr\u00fcnge thu.", "tokens": ["Was", "Schr\u00f6\u00b7cken", "und", "Ge\u00b7fahr", "vor", "wei\u00b7te", "Spr\u00fcn\u00b7ge", "thu", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "KON", "NN", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Euterpe kam zuerst und strich die kalten Schl\u00e4fe", "tokens": ["Eu\u00b7ter\u00b7pe", "kam", "zu\u00b7erst", "und", "strich", "die", "kal\u00b7ten", "Schl\u00e4\u00b7fe"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "ADV", "KON", "ADJD", "ART", "ADJA", "NN"], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.2": {"text": "Mit einer Kostbarkeit von Nardenwa\u00dfer an.", "tokens": ["Mit", "ei\u00b7ner", "Kost\u00b7bar\u00b7keit", "von", "Nar\u00b7den\u00b7wa\u00b7\u00dfer", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die andern h\u00e4tten gern ein laut Geschrey gethan,", "tokens": ["Die", "an\u00b7dern", "h\u00e4t\u00b7ten", "gern", "ein", "laut", "Ge\u00b7schrey", "ge\u00b7than", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VAFIN", "ADV", "ART", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wenn nur der Schlag nicht auch die Zungennerven tr\u00e4fe.", "tokens": ["Wenn", "nur", "der", "Schlag", "nicht", "auch", "die", "Zun\u00b7gen\u00b7ner\u00b7ven", "tr\u00e4\u00b7fe", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "PTKNEG", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+---+-", "measure": "unknown.measure.penta"}, "line.5": {"text": "Nur eine faste sich und sprang zum Aesculap,", "tokens": ["Nur", "ei\u00b7ne", "fas\u00b7te", "sich", "und", "sprang", "zum", "A\u00b7e\u00b7scu\u00b7lap", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "PRF", "KON", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.6": {"text": "Der durch ein kr\u00e4ftges Salz die Schlafsucht fl\u00fcchtig machte", "tokens": ["Der", "durch", "ein", "kr\u00e4ft\u00b7ges", "Salz", "die", "Schlaf\u00b7sucht", "fl\u00fcch\u00b7tig", "mach\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "ART", "ADJA", "NN", "ART", "NN", "ADJD", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und den ger\u00fchrten Gott so weit zurechte brachte,", "tokens": ["Und", "den", "ge\u00b7r\u00fchr\u00b7ten", "Gott", "so", "weit", "zu\u00b7rech\u00b7te", "brach\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "ADV", "ADJD", "VVFIN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Da\u00df er mit welcker Hand ein Lebenszeichen gab.", "tokens": ["Da\u00df", "er", "mit", "wel\u00b7cker", "Hand", "ein", "Le\u00b7bens\u00b7zei\u00b7chen", "gab", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PWAT", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Dies war der Musen Trost. Doch weil in lezten Z\u00fcgen", "tokens": ["Dies", "war", "der", "Mu\u00b7sen", "Trost", ".", "Doch", "weil", "in", "lez\u00b7ten", "Z\u00fc\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "ART", "NN", "NN", "$.", "KON", "KOUS", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ein jezt Verscheidender gar oft ges\u00fcnder scheint,", "tokens": ["Ein", "jezt", "Ver\u00b7schei\u00b7den\u00b7der", "gar", "oft", "ge\u00b7s\u00fcn\u00b7der", "scheint", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "NN", "ADV", "ADV", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Sich starck und munter macht, bis, eh man es vermeint,", "tokens": ["Sich", "starck", "und", "mun\u00b7ter", "macht", ",", "bis", ",", "eh", "man", "es", "ver\u00b7meint", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADJD", "KON", "ADJD", "VVFIN", "$,", "KOUS", "$,", "KOUS", "PIS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die Geister des Gebl\u00fcts aus ihrer Wohnung fliegen,", "tokens": ["Die", "Geis\u00b7ter", "des", "Ge\u00b7bl\u00fcts", "aus", "ih\u00b7rer", "Woh\u00b7nung", "flie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "So blieb die Schaar dabey halb furcht-, halb hofnungsvoll", "tokens": ["So", "blieb", "die", "Schaar", "da\u00b7bey", "halb", "furcht", ",", "halb", "hof\u00b7nungs\u00b7voll"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "PAV", "ADJD", "TRUNC", "$,", "ADJD", "ADJD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und wanckte wie ein Stamm, der manchen Hieb gef\u00fchlet", "tokens": ["Und", "wanck\u00b7te", "wie", "ein", "Stamm", ",", "der", "man\u00b7chen", "Hieb", "ge\u00b7f\u00fch\u00b7let"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "KOKOM", "ART", "NN", "$,", "PRELS", "PIAT", "NN", "VVPP"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und, eh der lezte Schlag das Garaus mit ihm spielet,", "tokens": ["Und", ",", "eh", "der", "lez\u00b7te", "Schlag", "das", "Ga\u00b7raus", "mit", "ihm", "spie\u00b7let", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "ART", "ADJA", "NN", "ART", "NN", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Mit sich nicht einig ist, worauf er fallen soll.", "tokens": ["Mit", "sich", "nicht", "ei\u00b7nig", "ist", ",", "wo\u00b7rauf", "er", "fal\u00b7len", "soll", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRF", "PTKNEG", "ADJD", "VAFIN", "$,", "PWAV", "PPER", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Des Zweifels Traurigkeit must endlich Abschied nehmen,", "tokens": ["Des", "Zwei\u00b7fels", "Trau\u00b7rig\u00b7keit", "must", "end\u00b7lich", "Ab\u00b7schied", "neh\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VMFIN", "ADV", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Als Athem, Farb und Geist dem Krancken wiederkam,", "tokens": ["Als", "A\u00b7them", ",", "Farb", "und", "Geist", "dem", "Kran\u00b7cken", "wie\u00b7der\u00b7kam", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "$,", "NN", "KON", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der, da er neben sich den Arzt ins Auge nahm,", "tokens": ["Der", ",", "da", "er", "ne\u00b7ben", "sich", "den", "Arzt", "ins", "Au\u00b7ge", "nahm", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "KOUS", "PPER", "APPR", "PRF", "ART", "NN", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Sich also h\u00f6ren lie\u00df: So starck ist Leid und Gr\u00e4men,", "tokens": ["Sich", "al\u00b7so", "h\u00f6\u00b7ren", "lie\u00df", ":", "So", "starck", "ist", "Leid", "und", "Gr\u00e4\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADV", "VVINF", "VVFIN", "$.", "ADV", "ADJD", "VAFIN", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Da\u00df G\u00f6tter selbst dadurch dem Tod entgegengehn.", "tokens": ["Da\u00df", "G\u00f6t\u00b7ter", "selbst", "da\u00b7durch", "dem", "Tod", "ent\u00b7ge\u00b7gen\u00b7gehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "ADV", "PAV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Doch weil nun, wie es scheint, die Noth fast halb verschwunden,", "tokens": ["Doch", "weil", "nun", ",", "wie", "es", "scheint", ",", "die", "Noth", "fast", "halb", "ver\u00b7schwun\u00b7den", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ADV", "$,", "PWAV", "PPER", "VVFIN", "$,", "ART", "NN", "ADV", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "So bin ich dir, mein Sohn, vor diesen Flei\u00df verbunden", "tokens": ["So", "bin", "ich", "dir", ",", "mein", "Sohn", ",", "vor", "die\u00b7sen", "Flei\u00df", "ver\u00b7bun\u00b7den"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "PPER", "$,", "PPOSAT", "NN", "$,", "APPR", "PDAT", "NN", "VVPP"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und finde mich geschickt, mir selber vorzustehn.", "tokens": ["Und", "fin\u00b7de", "mich", "ge\u00b7schickt", ",", "mir", "sel\u00b7ber", "vor\u00b7zu\u00b7stehn", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "VVPP", "$,", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "Ich krancke, wie man sieht, am Leib und am Gem\u00fcthe,", "tokens": ["Ich", "kran\u00b7cke", ",", "wie", "man", "sieht", ",", "am", "Leib", "und", "am", "Ge\u00b7m\u00fc\u00b7the", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PWAV", "PIS", "VVFIN", "$,", "APPRART", "NN", "KON", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Weil ich die Nordenluft nicht recht gewohnen kan.", "tokens": ["Weil", "ich", "die", "Nor\u00b7den\u00b7luft", "nicht", "recht", "ge\u00b7woh\u00b7nen", "kan", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "PTKNEG", "ADJD", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der Ansto\u00df wandelt mich mit einem Fr\u00f6steln an", "tokens": ["Der", "An\u00b7sto\u00df", "wan\u00b7delt", "mich", "mit", "ei\u00b7nem", "Fr\u00f6s\u00b7teln", "an"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PRF", "APPR", "ART", "NN", "APPR"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und zeiget ein von Gall und Gift verderbt Gebl\u00fcte.", "tokens": ["Und", "zei\u00b7get", "ein", "von", "Gall", "und", "Gift", "ver\u00b7derbt", "Ge\u00b7bl\u00fc\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "APPR", "NE", "KON", "NN", "ADJD", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Des Magens erster Weg ist gleichfalls sehr verstopft,", "tokens": ["Des", "Ma\u00b7gens", "ers\u00b7ter", "Weg", "ist", "gleich\u00b7falls", "sehr", "ver\u00b7stopft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "VAFIN", "ADV", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Daher empfind ich oft ein eckelhaftges Grauen.", "tokens": ["Da\u00b7her", "emp\u00b7find", "ich", "oft", "ein", "ec\u00b7kel\u00b7haft\u00b7ges", "Grau\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Wie kan es anders seyn? Ich mu\u00df so viel verdauen,", "tokens": ["Wie", "kan", "es", "an\u00b7ders", "seyn", "?", "Ich", "mu\u00df", "so", "viel", "ver\u00b7dau\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "PPER", "ADV", "VAINF", "$.", "PPER", "VMFIN", "ADV", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Wenn mich die Tadelsucht auf Mund und Finger klopft.", "tokens": ["Wenn", "mich", "die", "Ta\u00b7del\u00b7sucht", "auf", "Mund", "und", "Fin\u00b7ger", "klopft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "APPR", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Durch eine Reinigung den Schleim hinwegzuf\u00fchren,", "tokens": ["Durch", "ei\u00b7ne", "Rei\u00b7ni\u00b7gung", "den", "Schleim", "hin\u00b7weg\u00b7zu\u00b7f\u00fch\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wird also folglich wohl das beste Mittel seyn.", "tokens": ["Wird", "al\u00b7so", "folg\u00b7lich", "wohl", "das", "bes\u00b7te", "Mit\u00b7tel", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "ADV", "ART", "ADJA", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Doch brauch ich, solchen Wust und Unrath wegzuspeyn,", "tokens": ["Doch", "brauch", "ich", ",", "sol\u00b7chen", "Wust", "und", "Un\u00b7rath", "weg\u00b7zus\u00b7peyn", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "$,", "PIAT", "NN", "KON", "NN", "VAINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Nicht ein Galappenharz noch Weinstein anzur\u00fchren,", "tokens": ["Nicht", "ein", "Ga\u00b7lap\u00b7pen\u00b7harz", "noch", "Wein\u00b7stein", "an\u00b7zu\u00b7r\u00fch\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ART", "NN", "ADV", "NN", "VVIZU", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Der Finger in den Hals ist eben noch zu schwach.", "tokens": ["Der", "Fin\u00b7ger", "in", "den", "Hals", "ist", "e\u00b7ben", "noch", "zu", "schwach", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "VAFIN", "ADV", "ADV", "PTKA", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Halt! Jezt besinn ich mich, was ich j\u00fcngsthin gefunden,", "tokens": ["Halt", "!", "Jezt", "be\u00b7sinn", "ich", "mich", ",", "was", "ich", "j\u00fcng\u00b7sthin", "ge\u00b7fun\u00b7den", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "$.", "ADV", "VVFIN", "PPER", "PRF", "$,", "PWS", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Es heist dies Vomitiv: Vergn\u00fcgung m\u00fc\u00dfger Stunden", "tokens": ["Es", "heist", "dies", "Vo\u00b7mi\u00b7tiv", ":", "Ver\u00b7gn\u00fc\u00b7gung", "m\u00fc\u00df\u00b7ger", "Stun\u00b7den"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PDS", "NN", "$.", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und giebt an W\u00fcrckung kaum dem st\u00e4rcksten Pulver nach.", "tokens": ["Und", "giebt", "an", "W\u00fcr\u00b7ckung", "kaum", "dem", "st\u00e4rcks\u00b7ten", "Pul\u00b7ver", "nach", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "NN", "ADV", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.10": {"line.1": {"text": "Die Tugend dieses Buchs ist nicht genug zu preisen,", "tokens": ["Die", "Tu\u00b7gend", "die\u00b7ses", "Buchs", "ist", "nicht", "ge\u00b7nug", "zu", "prei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PDAT", "NN", "VAFIN", "PTKNEG", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ich weis, wie dienlich es zu solchen Curen sey.", "tokens": ["Ich", "weis", ",", "wie", "dien\u00b7lich", "es", "zu", "sol\u00b7chen", "Cu\u00b7ren", "sey", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKVZ", "$,", "PWAV", "ADJD", "PPER", "APPR", "PIAT", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wer einen Mund voll list, dem wird so wohl darbey", "tokens": ["Wer", "ei\u00b7nen", "Mund", "voll", "list", ",", "dem", "wird", "so", "wohl", "dar\u00b7bey"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PWS", "ART", "NN", "ADJD", "VVFIN", "$,", "PDS", "VAFIN", "ADV", "ADV", "PAV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Als Jungfern kaum nicht wird, wenn sie ins Bad verreisen.", "tokens": ["Als", "Jung\u00b7fern", "kaum", "nicht", "wird", ",", "wenn", "sie", "ins", "Bad", "ver\u00b7rei\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "ADV", "PTKNEG", "VAFIN", "$,", "KOUS", "PPER", "APPRART", "NE", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Dies kan ich wohl gestehn: Als ich von ohngefehr", "tokens": ["Dies", "kan", "ich", "wohl", "ge\u00b7stehn", ":", "Als", "ich", "von", "ohn\u00b7ge\u00b7fehr"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PDS", "VMFIN", "PPER", "ADV", "VVPP", "$.", "KOUS", "PPER", "APPR", "ADJD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Es auf dem Tr\u00f6del sah, wohin man's neulich schickte,", "tokens": ["Es", "auf", "dem", "Tr\u00f6\u00b7del", "sah", ",", "wo\u00b7hin", "man's", "neu\u00b7lich", "schick\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "ART", "NN", "VVFIN", "$,", "PWAV", "PIS", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Schien es, als wenn die Gicht mir jeden Darm verr\u00fcckte", "tokens": ["Schien", "es", ",", "als", "wenn", "die", "Gicht", "mir", "je\u00b7den", "Darm", "ver\u00b7r\u00fcck\u00b7te"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "$,", "KOKOM", "KOUS", "ART", "NN", "PPER", "PIAT", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und Juppiters Gesch\u00fcz in meinem Leibe w\u00e4r.", "tokens": ["Und", "Jup\u00b7pi\u00b7ters", "Ge\u00b7sch\u00fcz", "in", "mei\u00b7nem", "Lei\u00b7be", "w\u00e4r", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "NN", "APPR", "PPOSAT", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.11": {"line.1": {"text": "Die Musen wurden roth, sie fingen an zu lachen", "tokens": ["Die", "Mu\u00b7sen", "wur\u00b7den", "roth", ",", "sie", "fin\u00b7gen", "an", "zu", "la\u00b7chen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ADJD", "$,", "PPER", "VVFIN", "PTKVZ", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und fielen ungescheut dem Phoebus in das Wort:", "tokens": ["Und", "fie\u00b7len", "un\u00b7ge\u00b7scheut", "dem", "Phoe\u00b7bus", "in", "das", "Wort", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NE", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ach Vater, nenn uns doch den grundgelehrten Ort", "tokens": ["Ach", "Va\u00b7ter", ",", "nenn", "uns", "doch", "den", "grund\u00b7ge\u00b7lehr\u00b7ten", "Ort"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ITJ", "NN", "$,", "VVFIN", "PPER", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und die verschlagne Faust, die solche Schriften machen,", "tokens": ["Und", "die", "ver\u00b7schlag\u00b7ne", "Faust", ",", "die", "sol\u00b7che", "Schrif\u00b7ten", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "$,", "PRELS", "PIAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ein Schif voll Niesewurz kommt von Anticyra,", "tokens": ["Ein", "Schif", "voll", "Nie\u00b7se\u00b7wurz", "kommt", "von", "An\u00b7ti\u00b7cy\u00b7ra", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "NN", "VVFIN", "APPR", "NE", "$,"], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Den L\u00e4strern unsrer Kunst die Nasen vollzureiben.", "tokens": ["Den", "L\u00e4st\u00b7rern", "uns\u00b7rer", "Kunst", "die", "Na\u00b7sen", "voll\u00b7zu\u00b7rei\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Wir wollen einen Rie\u00df des sch\u00f6nen Buchs verschreiben;", "tokens": ["Wir", "wol\u00b7len", "ei\u00b7nen", "Rie\u00df", "des", "sch\u00f6\u00b7nen", "Buchs", "ver\u00b7schrei\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "NN", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Denn an den T\u00fctten ist ein gro\u00dfer Mangel da.", "tokens": ["Denn", "an", "den", "T\u00fct\u00b7ten", "ist", "ein", "gro\u00b7\u00dfer", "Man\u00b7gel", "da", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VAFIN", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.12": {"line.1": {"text": "Die Antwort gab Bericht: Dort unter den Sudeten,", "tokens": ["Die", "Ant\u00b7wort", "gab", "Be\u00b7richt", ":", "Dort", "un\u00b7ter", "den", "Su\u00b7de\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "NN", "$.", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wo Aganippens Quell sich in die Weistriz geu\u00dft,", "tokens": ["Wo", "A\u00b7gan\u00b7ip\u00b7pens", "Quell", "sich", "in", "die", "Wei\u00b7striz", "geu\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NE", "NN", "PRF", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Liegt ein Hyopolis, das sich gar sehr beflei\u00dft,", "tokens": ["Liegt", "ein", "Hyo\u00b7po\u00b7lis", ",", "das", "sich", "gar", "sehr", "be\u00b7flei\u00dft", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NE", "$,", "PRELS", "PRF", "ADV", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.4": {"text": "Durch manch gelehrtes Kind den bleichen Neid zu t\u00f6dten.", "tokens": ["Durch", "manch", "ge\u00b7lehr\u00b7tes", "Kind", "den", "blei\u00b7chen", "Neid", "zu", "t\u00f6d\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "ADJA", "NN", "ART", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Hier scheint die Wi\u00dfenschaft auf ewig einzubaun,", "tokens": ["Hier", "scheint", "die", "Wi\u00b7\u00dfen\u00b7schaft", "auf", "e\u00b7wig", "ein\u00b7zu\u00b7baun", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPR", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Hier zeigt so mancher Kopf die Kr\u00e4fte des Verstandes;", "tokens": ["Hier", "zeigt", "so", "man\u00b7cher", "Kopf", "die", "Kr\u00e4f\u00b7te", "des", "Ver\u00b7stan\u00b7des", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "PIAT", "NN", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Das herrschende Latein, die Anmuth Griechenlandes", "tokens": ["Das", "herr\u00b7schen\u00b7de", "La\u00b7tein", ",", "die", "An\u00b7muth", "Grie\u00b7chen\u00b7lan\u00b7des"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "NN", "NN"], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.8": {"text": "Kan hier von ihrer Zunft nicht wenig Meister schaun.", "tokens": ["Kan", "hier", "von", "ih\u00b7rer", "Zunft", "nicht", "we\u00b7nig", "Meis\u00b7ter", "schaun", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "APPR", "PPOSAT", "NN", "PTKNEG", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.13": {"line.1": {"text": "Der Weizen tr\u00e4gt auch Spreu, kein Gold ist sonder Schlacken.", "tokens": ["Der", "Wei\u00b7zen", "tr\u00e4gt", "auch", "Spreu", ",", "kein", "Gold", "ist", "son\u00b7der", "Schla\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "NN", "$,", "PIAT", "NN", "VAFIN", "ADV", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Sagt mir ein Handwerck her, das keine St\u00fcmper f\u00fchrt.", "tokens": ["Sagt", "mir", "ein", "Hand\u00b7werck", "her", ",", "das", "kei\u00b7ne", "St\u00fcm\u00b7per", "f\u00fchrt", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "PTKVZ", "$,", "PRELS", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Drum lebt auch hier ein Kiel, der minder schreibt als schmiert", "tokens": ["Drum", "lebt", "auch", "hier", "ein", "Kiel", ",", "der", "min\u00b7der", "schreibt", "als", "schmiert"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "ADV", "ADV", "ART", "NE", "$,", "PRELS", "ADV", "VVFIN", "KOKOM", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und geile Bo\u00dfheit hegt. Die Unschuld anzuzwacken,", "tokens": ["Und", "gei\u00b7le", "Bo\u00df\u00b7heit", "hegt", ".", "Die", "Un\u00b7schuld", "an\u00b7zu\u00b7zwa\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "VVFIN", "$.", "ART", "NN", "VVIZU", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Den Lehrern Leides thun, das Priesteramt beschreyn,", "tokens": ["Den", "Leh\u00b7rern", "Lei\u00b7des", "thun", ",", "das", "Pries\u00b7ter\u00b7amt", "be\u00b7schreyn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVINF", "$,", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Des Nechsten Ehrenkleid mit fremder Scheere kr\u00e4ncken,", "tokens": ["Des", "Nechs\u00b7ten", "Eh\u00b7ren\u00b7kleid", "mit", "frem\u00b7der", "Schee\u00b7re", "kr\u00e4n\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "APPR", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Viel wi\u00dfen, nichts verstehn, erzehlen und erdencken", "tokens": ["Viel", "wi\u00b7\u00dfen", ",", "nichts", "ver\u00b7stehn", ",", "er\u00b7zeh\u00b7len", "und", "er\u00b7den\u00b7cken"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVINF", "$,", "PIS", "VVINF", "$,", "VVINF", "KON", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Ist seine ganze Kunst und m\u00fc\u00dfges Flei\u00dfigseyn.", "tokens": ["Ist", "sei\u00b7ne", "gan\u00b7ze", "Kunst", "und", "m\u00fc\u00df\u00b7ges", "Flei\u00b7\u00dfig\u00b7seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "ADJA", "NN", "KON", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.14": {"line.1": {"text": "Vor nennt ich euch das Buch, jezt kennt ihr den Verfa\u00dfer,", "tokens": ["Vor", "nennt", "ich", "euch", "das", "Buch", ",", "jezt", "kennt", "ihr", "den", "Ver\u00b7fa\u00b7\u00dfer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "VVFIN", "PPER", "PRF", "ART", "NN", "$,", "ADV", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Erwegt nunmehr, ob nicht der Vater und das Kind,", "tokens": ["Er\u00b7wegt", "nun\u00b7mehr", ",", "ob", "nicht", "der", "Va\u00b7ter", "und", "das", "Kind", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "$,", "KOUS", "PTKNEG", "ART", "NN", "KON", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wie eins des andern werth, einander \u00e4hnlich sind.", "tokens": ["Wie", "eins", "des", "an\u00b7dern", "werth", ",", "ein\u00b7an\u00b7der", "\u00e4hn\u00b7lich", "sind", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "ART", "ADJA", "ADJD", "$,", "PRF", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Kein wohlgeschmackter Fisch kommt doch aus faulem Wa\u00dfer.", "tokens": ["Kein", "wohl\u00b7ge\u00b7schmack\u00b7ter", "Fisch", "kommt", "doch", "aus", "fau\u00b7lem", "Wa\u00b7\u00dfer", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "VVFIN", "ADV", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Es ist kein Ding so schlimm, es ist zu etwas gut;", "tokens": ["Es", "ist", "kein", "Ding", "so", "schlimm", ",", "es", "ist", "zu", "et\u00b7was", "gut", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIAT", "NN", "ADV", "ADJD", "$,", "PPER", "VAFIN", "PTKA", "PIS", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Mir dient die saubre Schrift, da\u00df ich mich \u00fcbergebe.", "tokens": ["Mir", "dient", "die", "saub\u00b7re", "Schrift", ",", "da\u00df", "ich", "mich", "\u00fc\u00b7ber\u00b7ge\u00b7be", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "$,", "KOUS", "PPER", "PRF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Dies aber schieb ich auf, weil ich das \u00dcbel hebe,", "tokens": ["Dies", "a\u00b7ber", "schieb", "ich", "auf", ",", "weil", "ich", "das", "\u00dc\u00b7bel", "he\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "VVFIN", "PPER", "PTKVZ", "$,", "KOUS", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Wenn mir nur jezt jemand vergn\u00fcgte Posten thut.", "tokens": ["Wenn", "mir", "nur", "jezt", "je\u00b7mand", "ver\u00b7gn\u00fcg\u00b7te", "Pos\u00b7ten", "thut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "PIS", "VVFIN", "NN", "VVFIN", "$."], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}}, "stanza.15": {"line.1": {"text": "Gleich war ich im Begrif, die Zunge loszudr\u00fccken,", "tokens": ["Gleich", "war", "ich", "im", "Be\u00b7grif", ",", "die", "Zun\u00b7ge", "los\u00b7zu\u00b7dr\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "APPRART", "NN", "$,", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Brach Aesculap heraus, weil mich das Schweigen qu\u00e4lt.", "tokens": ["Brach", "A\u00b7e\u00b7scu\u00b7lap", "he\u00b7raus", ",", "weil", "mich", "das", "Schwei\u00b7gen", "qu\u00e4lt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "PTKVZ", "$,", "KOUS", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Gieb Achtung auf den Trost, den dir mein Mund erzehlt,", "tokens": ["Gieb", "Ach\u00b7tung", "auf", "den", "Trost", ",", "den", "dir", "mein", "Mund", "er\u00b7zehlt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "NN", "APPR", "ART", "NN", "$,", "PRELS", "PPER", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Es wird kein Perlentranck dein Herz so starck erquicken.", "tokens": ["Es", "wird", "kein", "Per\u00b7len\u00b7tranck", "dein", "Herz", "so", "starck", "er\u00b7qui\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIAT", "NN", "PPOSAT", "NN", "ADV", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Minerva zog bisher in angef\u00fchrter Stadt", "tokens": ["Mi\u00b7ner\u00b7va", "zog", "bis\u00b7her", "in", "an\u00b7ge\u00b7f\u00fchr\u00b7ter", "Stadt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "ADV", "APPR", "ADJA", "NN"], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.6": {"text": "Von gut- und edler Zucht vier ungemeine H\u00e4hne,", "tokens": ["Von", "gut", "und", "ed\u00b7ler", "Zucht", "vier", "un\u00b7ge\u00b7mei\u00b7ne", "H\u00e4h\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "TRUNC", "KON", "ADJA", "NN", "CARD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Vor die ihr Cypris oft zwey Tauben und zwey Schw\u00e4ne", "tokens": ["Vor", "die", "ihr", "Cyp\u00b7ris", "oft", "zwey", "Tau\u00b7ben", "und", "zwey", "Schw\u00e4\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PRELS", "PPER", "NE", "ADV", "CARD", "NN", "KON", "CARD", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und Juno gar den Pfau umsonst gebothen hat.", "tokens": ["Und", "Ju\u00b7no", "gar", "den", "Pfau", "um\u00b7sonst", "ge\u00b7bo\u00b7then", "hat", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ADV", "ART", "NN", "ADV", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.16": {"line.1": {"text": "Der J\u00fcngst' ist noch gar zart und spielt in ihrem Schoo\u00dfe;", "tokens": ["Der", "J\u00fcngst'", "ist", "noch", "gar", "zart", "und", "spielt", "in", "ih\u00b7rem", "Schoo\u00b7\u00dfe", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "ADV", "ADJD", "KON", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die Themis, kommt mir vor, verspizt sich schon auf ihn.", "tokens": ["Die", "The\u00b7mis", ",", "kommt", "mir", "vor", ",", "ver\u00b7spizt", "sich", "schon", "auf", "ihn", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "$,", "VVFIN", "PPER", "PTKVZ", "$,", "VVFIN", "PRF", "ADV", "APPR", "PPER", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Den einen lies sie mir mit Sorgfalt auferziehn,", "tokens": ["Den", "ei\u00b7nen", "lies", "sie", "mir", "mit", "Sorg\u00b7falt", "auf\u00b7er\u00b7ziehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VVFIN", "PPER", "PPER", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der ist ohn Ursach nicht nach der Geburth der Gro\u00dfe.", "tokens": ["Der", "ist", "ohn", "Ur\u00b7sach", "nicht", "nach", "der", "Ge\u00b7burth", "der", "Gro\u00b7\u00dfe", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "APPR", "NN", "PTKNEG", "APPR", "ART", "NN", "ART", "ADJA", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Mercur, der insgemein gar lange Finger braucht,", "tokens": ["Mer\u00b7cur", ",", "der", "ins\u00b7ge\u00b7mein", "gar", "lan\u00b7ge", "Fin\u00b7ger", "braucht", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PRELS", "ADV", "ADV", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Stahl ihr den dritten weg und flog mit dieser Beute", "tokens": ["Stahl", "ihr", "den", "drit\u00b7ten", "weg", "und", "flog", "mit", "die\u00b7ser", "Beu\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "PPER", "ART", "ADJA", "PTKVZ", "KON", "VVFIN", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Nach jenem Tyrus zu, wo auf der Abendseite", "tokens": ["Nach", "je\u00b7nem", "Ty\u00b7rus", "zu", ",", "wo", "auf", "der", "A\u00b7ben\u00b7dsei\u00b7te"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "PDAT", "NN", "PTKVZ", "$,", "PWAV", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Des fetten Schlesiens der Strand der Oder raucht.", "tokens": ["Des", "fet\u00b7ten", "Schle\u00b7si\u00b7ens", "der", "Strand", "der", "O\u00b7der", "raucht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.17": {"line.1": {"text": "Heut aber, als mein Fu\u00df, den Kriegsgott zu besuchen,", "tokens": ["Heut", "a\u00b7ber", ",", "als", "mein", "Fu\u00df", ",", "den", "Kriegs\u00b7gott", "zu", "be\u00b7su\u00b7chen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$,", "KOUS", "PPOSAT", "NN", "$,", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der nechst bey Temeswar den T\u00fcrckschen Hieb empfing,", "tokens": ["Der", "nechst", "bey", "Te\u00b7mes\u00b7war", "den", "T\u00fcrck\u00b7schen", "Hieb", "emp\u00b7fing", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "NN", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Aus meinem Hause trat und zu verbinden gieng,", "tokens": ["Aus", "mei\u00b7nem", "Hau\u00b7se", "trat", "und", "zu", "ver\u00b7bin\u00b7den", "gieng", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "KON", "PTKZU", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "H\u00f6rt ich ein Weibermaul hart und entsezlich fluchen.", "tokens": ["H\u00f6rt", "ich", "ein", "Wei\u00b7ber\u00b7maul", "hart", "und", "ent\u00b7sez\u00b7lich", "flu\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ART", "NN", "ADJD", "KON", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Mein Aug erfuhr es bald, da\u00df es die Misgunst war,", "tokens": ["Mein", "Aug", "er\u00b7fuhr", "es", "bald", ",", "da\u00df", "es", "die", "Mis\u00b7gunst", "war", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "ADV", "$,", "KOUS", "PPER", "ART", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Die scheusliche Gestalt schien ein verdorrt Gerippe,", "tokens": ["Die", "scheus\u00b7li\u00b7che", "Ge\u00b7stalt", "schien", "ein", "ver\u00b7dorrt", "Ge\u00b7rip\u00b7pe", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ART", "ADJD", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Ein gelb- und halber Zahn bi\u00df in die blutge Lippe", "tokens": ["Ein", "gelb", "und", "hal\u00b7ber", "Zahn", "bi\u00df", "in", "die", "blut\u00b7ge", "Lip\u00b7pe"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "TRUNC", "KON", "ADJA", "NN", "APPR", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und ihre Schm\u00e4hsucht warf die Klauen in das Haar.", "tokens": ["Und", "ih\u00b7re", "Schm\u00e4h\u00b7sucht", "warf", "die", "Klau\u00b7en", "in", "das", "Haar", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.18": {"line.1": {"text": "Was, was! so klafte sie, da\u00df mir das Ohr noch klinget,", "tokens": ["Was", ",", "was", "!", "so", "klaf\u00b7te", "sie", ",", "da\u00df", "mir", "das", "Ohr", "noch", "klin\u00b7get", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "$,", "PWS", "$.", "ADV", "VVFIN", "PPER", "$,", "KOUS", "PPER", "ART", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Was, steigt der J\u00fcngling schon die Ehrenstufen auf?", "tokens": ["Was", ",", "steigt", "der", "J\u00fcng\u00b7ling", "schon", "die", "Eh\u00b7ren\u00b7stu\u00b7fen", "auf", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "$,", "VVFIN", "ART", "NN", "ADV", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Was, cr\u00f6nt man einen Mensch, der seinen Lebenslauf,", "tokens": ["Was", ",", "cr\u00f6nt", "man", "ei\u00b7nen", "Mensch", ",", "der", "sei\u00b7nen", "Le\u00b7bens\u00b7lauf", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "$,", "VVFIN", "PIS", "ART", "NN", "$,", "PRELS", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wie ehmahls br\u00e4uchlich war, noch nicht auf drey\u00dfig bringet?", "tokens": ["Wie", "eh\u00b7mahls", "br\u00e4uch\u00b7lich", "war", ",", "noch", "nicht", "auf", "drey\u00b7\u00dfig", "brin\u00b7get", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "ADJD", "VAFIN", "$,", "ADV", "PTKNEG", "APPR", "CARD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ich merckte kurz darauf, wen dieses Luder schalt,", "tokens": ["Ich", "merck\u00b7te", "kurz", "da\u00b7rauf", ",", "wen", "die\u00b7ses", "Lu\u00b7der", "schalt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "PAV", "$,", "PWS", "PDAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Da man den vierten Hahn zu einem Tempel f\u00fchrte", "tokens": ["Da", "man", "den", "vier\u00b7ten", "Hahn", "zu", "ei\u00b7nem", "Tem\u00b7pel", "f\u00fchr\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "ART", "ADJA", "NN", "APPR", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und mit Kleinodien, doch nicht so reichlich, zierte,", "tokens": ["Und", "mit", "Klein\u00b7o\u00b7di\u00b7en", ",", "doch", "nicht", "so", "reich\u00b7lich", ",", "zier\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "APPR", "NN", "$,", "ADV", "PTKNEG", "ADV", "ADJD", "$,", "VVFIN", "$,"], "meter": "--+--+-+-+-+-", "measure": "anapaest.di.plus"}, "line.8": {"text": "Da\u00df sein Verdienst nicht mehr und weit dar\u00fcber galt.", "tokens": ["Da\u00df", "sein", "Ver\u00b7dienst", "nicht", "mehr", "und", "weit", "da\u00b7r\u00fc\u00b7ber", "galt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "PTKNEG", "ADV", "KON", "ADJD", "PAV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.19": {"line.1": {"text": "Ich schlich dem Jubel nach, trat furchtsam auf die Schwelle", "tokens": ["Ich", "schlich", "dem", "Ju\u00b7bel", "nach", ",", "trat", "furcht\u00b7sam", "auf", "die", "Schwel\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "PTKVZ", "$,", "VVFIN", "ADJD", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Des gro\u00dfen Heiligthums, in dem Sophia sizt.", "tokens": ["Des", "gro\u00b7\u00dfen", "Hei\u00b7lig\u00b7thums", ",", "in", "dem", "So\u00b7phia", "sizt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Die Pracht strahlt \u00fcberall, wie wenn es n\u00e4chtlich blizt,", "tokens": ["Die", "Pracht", "strahlt", "\u00fc\u00b7be\u00b7rall", ",", "wie", "wenn", "es", "n\u00e4cht\u00b7lich", "blizt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "$,", "KOKOM", "KOUS", "PPER", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die Ampeln machten es in jedem Winckel helle,", "tokens": ["Die", "Am\u00b7peln", "mach\u00b7ten", "es", "in", "je\u00b7dem", "Win\u00b7ckel", "hel\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "APPR", "PIAT", "NN", "ADJA", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die S\u00e4nger stritten sch\u00f6n, der Weihrauch dampfte scharf,", "tokens": ["Die", "S\u00e4n\u00b7ger", "strit\u00b7ten", "sch\u00f6n", ",", "der", "Weih\u00b7rauch", "dampf\u00b7te", "scharf", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJD", "$,", "ART", "NN", "VVFIN", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Die Decke war Saphir, der Jaspis lies sich treten,", "tokens": ["Die", "De\u00b7cke", "war", "Sa\u00b7phir", ",", "der", "Jas\u00b7pis", "lies", "sich", "tre\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "NE", "$,", "ART", "NE", "VVFIN", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und mitten prahlt' ein Tisch mit k\u00f6stlichen Ger\u00e4then,", "tokens": ["Und", "mit\u00b7ten", "prahlt'", "ein", "Tisch", "mit", "k\u00f6st\u00b7li\u00b7chen", "Ge\u00b7r\u00e4\u00b7then", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "ART", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Worzu die Wei\u00dfheit kam und ihren Mantel warf.", "tokens": ["Wor\u00b7zu", "die", "Wei\u00df\u00b7heit", "kam", "und", "ih\u00b7ren", "Man\u00b7tel", "warf", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "VVFIN", "KON", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.20": {"line.1": {"text": "Sie nahm der Pallas flugs den Vogel aus den H\u00e4nden,", "tokens": ["Sie", "nahm", "der", "Pal\u00b7las", "flugs", "den", "Vo\u00b7gel", "aus", "den", "H\u00e4n\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADV", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die ihn mit Folgendem ihr als ein Opfer gab:", "tokens": ["Die", "ihn", "mit", "Fol\u00b7gen\u00b7dem", "ihr", "als", "ein", "Op\u00b7fer", "gab", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "NN", "PPER", "KOUS", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Nimm hier mein Schooskind hin und richt es weiter ab,", "tokens": ["Nimm", "hier", "mein", "Scho\u00b7os\u00b7kind", "hin", "und", "richt", "es", "wei\u00b7ter", "ab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "PPOSAT", "NN", "PTKVZ", "KON", "VVFIN", "PPER", "ADV", "PTKVZ", "$,"], "meter": "+--+--+-+-+-+", "measure": "dactylic.di.plus"}, "line.4": {"text": "Ich kan dir meine Gunst nicht herrlicher verpf\u00e4nden.", "tokens": ["Ich", "kan", "dir", "mei\u00b7ne", "Gunst", "nicht", "herr\u00b7li\u00b7cher", "ver\u00b7pf\u00e4n\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "PPOSAT", "NN", "PTKNEG", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ihn hat Apollo l\u00e4ngst die Singekunst gelehrt", "tokens": ["Ihn", "hat", "A\u00b7pol\u00b7lo", "l\u00e4ngst", "die", "Sin\u00b7ge\u00b7kunst", "ge\u00b7lehrt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "NE", "ADV", "ART", "NN", "VVPP"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und seiner Stimme Schall vor Tausenden gepriesen,", "tokens": ["Und", "sei\u00b7ner", "Stim\u00b7me", "Schall", "vor", "Tau\u00b7sen\u00b7den", "ge\u00b7prie\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "NN", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Er ist nicht obenhin in allem unterwiesen,", "tokens": ["Er", "ist", "nicht", "o\u00b7ben\u00b7hin", "in", "al\u00b7lem", "un\u00b7ter\u00b7wie\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKNEG", "ADV", "APPR", "PIS", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Was zu der Gr\u00fcndligkeit der Wi\u00dfenschaft geh\u00f6rt.", "tokens": ["Was", "zu", "der", "Gr\u00fcnd\u00b7lig\u00b7keit", "der", "Wi\u00b7\u00dfen\u00b7schaft", "ge\u00b7h\u00f6rt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "ART", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.21": {"line.1": {"text": "Sie schwieg; und sieh, ein Bild des sch\u00f6nsten Frauenzimmers,", "tokens": ["Sie", "schwieg", ";", "und", "sieh", ",", "ein", "Bild", "des", "sch\u00f6ns\u00b7ten", "Frau\u00b7en\u00b7zim\u00b7mers", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "KON", "VVFIN", "$,", "ART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Es schien den G\u00f6ttern gleich, doch nicht von unsrer Art,", "tokens": ["Es", "schien", "den", "G\u00f6t\u00b7tern", "gleich", ",", "doch", "nicht", "von", "uns\u00b7rer", "Art", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADV", "$,", "ADV", "PTKNEG", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Fuhr durch den Tempel hin, der fast zum Himmel ward", "tokens": ["Fuhr", "durch", "den", "Tem\u00b7pel", "hin", ",", "der", "fast", "zum", "Him\u00b7mel", "ward"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "ART", "NN", "PTKVZ", "$,", "PRELS", "ADV", "APPRART", "NN", "VAFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Von wegen des von ihr geworfnen Sonnenschimmers.", "tokens": ["Von", "we\u00b7gen", "des", "von", "ihr", "ge\u00b7worf\u00b7nen", "Son\u00b7nen\u00b7schim\u00b7mers", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "APPR", "ART", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ihr Mund, der mehr ins Ohr als zum Gesichte drang,", "tokens": ["Ihr", "Mund", ",", "der", "mehr", "ins", "Ohr", "als", "zum", "Ge\u00b7sich\u00b7te", "drang", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PRELS", "ADV", "APPRART", "NN", "KOKOM", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Erhob der Stimme Kraft: Wer Ohren hat, der h\u00f6re", "tokens": ["Er\u00b7hob", "der", "Stim\u00b7me", "Kraft", ":", "Wer", "Oh\u00b7ren", "hat", ",", "der", "h\u00f6\u00b7re"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["VVFIN", "ART", "NN", "NN", "$.", "PWS", "NN", "VAFIN", "$,", "PRELS", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Den Spruch Eusebiens! Der Hahn soll mir zur Ehre", "tokens": ["Den", "Spruch", "Eu\u00b7se\u00b7bi\u00b7ens", "!", "Der", "Hahn", "soll", "mir", "zur", "Eh\u00b7re"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "NE", "$.", "ART", "NN", "VMFIN", "PPER", "APPRART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Ein W\u00e4chter Zions seyn, womit sie sich verschwang.", "tokens": ["Ein", "W\u00e4ch\u00b7ter", "Zi\u00b7ons", "seyn", ",", "wo\u00b7mit", "sie", "sich", "ver\u00b7schwang", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "NE", "VAINF", "$,", "PWAV", "PPER", "PRF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.22": {"line.1": {"text": "Hier schlo\u00df der Aesculap. Sein Vater sang vor Freuden", "tokens": ["Hier", "schlo\u00df", "der", "A\u00b7e\u00b7scu\u00b7lap", ".", "Sein", "Va\u00b7ter", "sang", "vor", "Freu\u00b7den"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "$.", "PPOSAT", "NN", "VVFIN", "APPR", "NN"], "meter": "-+-+--+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Und rief: Die Leyer her! Ich bin bereits gesund.", "tokens": ["Und", "rief", ":", "Die", "Le\u00b7yer", "her", "!", "Ich", "bin", "be\u00b7reits", "ge\u00b7sund", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "ART", "NN", "PTKVZ", "$.", "PPER", "VAFIN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Schl\u00e4gt mich bisweilen gleich das Schwerd der Neider wund,", "tokens": ["Schl\u00e4gt", "mich", "bis\u00b7wei\u00b7len", "gleich", "das", "Schwerd", "der", "Nei\u00b7der", "wund", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "ART", "NN", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Mu\u00df ich schon als ein Gott mehr als die Menschen leiden,", "tokens": ["Mu\u00df", "ich", "schon", "als", "ein", "Gott", "mehr", "als", "die", "Men\u00b7schen", "lei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "KOUS", "ART", "NN", "PIAT", "KOKOM", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Vielleicht kommt einst die Zeit, da mich ein F\u00fcrst erhebt,", "tokens": ["Viel\u00b7leicht", "kommt", "einst", "die", "Zeit", ",", "da", "mich", "ein", "F\u00fcrst", "er\u00b7hebt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "ART", "NN", "$,", "KOUS", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Damit der blinde Schwarm mein Volck nicht mehr verh\u00f6hne;", "tokens": ["Da\u00b7mit", "der", "blin\u00b7de", "Schwarm", "mein", "Volck", "nicht", "mehr", "ver\u00b7h\u00f6h\u00b7ne", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "ADJA", "NN", "PPOSAT", "NN", "PTKNEG", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Vorjezt bin ich vergn\u00fcgt, da einer meiner S\u00f6hne", "tokens": ["Vor\u00b7jezt", "bin", "ich", "ver\u00b7gn\u00fcgt", ",", "da", "ei\u00b7ner", "mei\u00b7ner", "S\u00f6h\u00b7ne"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "VVPP", "$,", "KOUS", "ART", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Im edlen Plei\u00df-Athen der Ehren n\u00e4herstrebt.", "tokens": ["Im", "ed\u00b7len", "Plei\u00df\u00b7A\u00b7then", "der", "Eh\u00b7ren", "n\u00e4\u00b7her\u00b7strebt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}}, "stanza.23": {"line.1": {"text": "Gelehrt- und kluger Freund, er\u00f6fne dies Gedichte.", "tokens": ["Ge\u00b7lehr\u00b7t", "und", "klu\u00b7ger", "Freund", ",", "er\u00b7\u00f6f\u00b7ne", "dies", "Ge\u00b7dich\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["TRUNC", "KON", "ADJA", "NN", "$,", "VVFIN", "PDS", "NN", "$."], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Den Schl\u00fc\u00dfel reichet dir die wahre Redligkeit,", "tokens": ["Den", "Schl\u00fc\u00b7\u00dfel", "rei\u00b7chet", "dir", "die", "wah\u00b7re", "Red\u00b7lig\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die dir dies Unterpfand getreuer Sinnen weiht", "tokens": ["Die", "dir", "dies", "Un\u00b7ter\u00b7pfand", "ge\u00b7treu\u00b7er", "Sin\u00b7nen", "weiht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "PDS", "NN", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und sich daran nichts kehrt, da\u00df man sie splitterrichte.", "tokens": ["Und", "sich", "da\u00b7ran", "nichts", "kehrt", ",", "da\u00df", "man", "sie", "split\u00b7ter\u00b7rich\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "PAV", "PIS", "VVFIN", "$,", "KOUS", "PIS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die Thorheit wird sich zwar hiermit beleidigt sehn,", "tokens": ["Die", "Thor\u00b7heit", "wird", "sich", "zwar", "hier\u00b7mit", "be\u00b7lei\u00b7digt", "sehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PRF", "ADV", "PAV", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Allein man f\u00fcrchtet nicht den Bliz von ihrem Dr\u00e4uen.", "tokens": ["Al\u00b7lein", "man", "f\u00fcrch\u00b7tet", "nicht", "den", "Bliz", "von", "ih\u00b7rem", "Dr\u00e4u\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "VVFIN", "PTKNEG", "ART", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Wer Hecheln schmieden will, mu\u00df keine Funcken scheuen.", "tokens": ["Wer", "He\u00b7cheln", "schmie\u00b7den", "will", ",", "mu\u00df", "kei\u00b7ne", "Fun\u00b7cken", "scheu\u00b7en", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "VVINF", "VMFIN", "$,", "VMFIN", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Was sie an mir ersucht, mag ihr zum Schimpf geschehn.", "tokens": ["Was", "sie", "an", "mir", "er\u00b7sucht", ",", "mag", "ihr", "zum", "Schimpf", "ge\u00b7schehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "APPR", "PPER", "VVPP", "$,", "VMFIN", "PPER", "APPRART", "NN", "VVPP", "$."], "meter": "--+--+-+-+-+", "measure": "anapaest.di.plus"}}, "stanza.24": {"line.1": {"text": "Wie manchmahl denck ich nicht an die verstrichnen Wochen!", "tokens": ["Wie", "manch\u00b7mahl", "denck", "ich", "nicht", "an", "die", "ver\u00b7strich\u00b7nen", "Wo\u00b7chen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "VVIMP", "PPER", "PTKNEG", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der andre Winter schneit den Bergen auf das Haupt,", "tokens": ["Der", "and\u00b7re", "Win\u00b7ter", "schneit", "den", "Ber\u00b7gen", "auf", "das", "Haupt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Seit das Verh\u00e4ngn\u00fc\u00df uns dem s\u00fc\u00dfen Lande raubt,", "tokens": ["Seit", "das", "Ver\u00b7h\u00e4ng\u00b7n\u00fc\u00df", "uns", "dem", "s\u00fc\u00b7\u00dfen", "Lan\u00b7de", "raubt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PPER", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "In welchem wir der Welt am ersten zugesprochen.", "tokens": ["In", "wel\u00b7chem", "wir", "der", "Welt", "am", "ers\u00b7ten", "zu\u00b7ge\u00b7spro\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "ART", "NN", "APPRART", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Dort schlo\u00dfen du und ich den festen Freundschaftsbund,", "tokens": ["Dort", "schlo\u00b7\u00dfen", "du", "und", "ich", "den", "fes\u00b7ten", "Freund\u00b7schafts\u00b7bund", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "KON", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Dort war Vertraulichseyn der Drittmann unsrer Herzen", "tokens": ["Dort", "war", "Ver\u00b7trau\u00b7lich\u00b7seyn", "der", "Dritt\u00b7mann", "uns\u00b7rer", "Her\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "NN", "ART", "NN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und lies die Einsamkeit auf dem Parna\u00dfus scherzen,", "tokens": ["Und", "lies", "die", "Ein\u00b7sam\u00b7keit", "auf", "dem", "Par\u00b7na\u00b7\u00dfus", "scher\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+---+-+-", "measure": "unknown.measure.penta"}, "line.8": {"text": "Wenn seine Castalis uns zu Gebothe stund.", "tokens": ["Wenn", "sei\u00b7ne", "Cas\u00b7ta\u00b7lis", "uns", "zu", "Ge\u00b7bo\u00b7the", "stund", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NE", "PPER", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.25": {"line.1": {"text": "Du flogst nicht vor der Zeit, wie mancher, aus dem Neste,", "tokens": ["Du", "flogst", "nicht", "vor", "der", "Zeit", ",", "wie", "man\u00b7cher", ",", "aus", "dem", "Nes\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "APPR", "ART", "NN", "$,", "PWAV", "PIS", "$,", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der, wenn die Schul ihn brennt, nach hohen Schulen lauft", "tokens": ["Der", ",", "wenn", "die", "Schul", "ihn", "brennt", ",", "nach", "ho\u00b7hen", "Schu\u00b7len", "lauft"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "$,", "KOUS", "ART", "NN", "PPER", "VVFIN", "$,", "APPR", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und eher wiederkommt, als er den Bart gekauft;", "tokens": ["Und", "e\u00b7her", "wie\u00b7der\u00b7kommt", ",", "als", "er", "den", "Bart", "ge\u00b7kauft", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "$,", "KOUS", "PPER", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Du legtest starcken Grund und baust daher auch feste.", "tokens": ["Du", "leg\u00b7test", "star\u00b7cken", "Grund", "und", "baust", "da\u00b7her", "auch", "fes\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJA", "NN", "KON", "VVFIN", "PAV", "ADV", "ADJA", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Der Hundertste bekommt der Wei\u00dfheit Meisterrecht", "tokens": ["Der", "Hun\u00b7derts\u00b7te", "be\u00b7kommt", "der", "Wei\u00df\u00b7heit", "Meis\u00b7ter\u00b7recht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und weis von ihr wohl nichts als nur den blo\u00dfen Nahmen,", "tokens": ["Und", "weis", "von", "ihr", "wohl", "nichts", "als", "nur", "den", "blo\u00b7\u00dfen", "Nah\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKVZ", "APPR", "PPER", "ADV", "PIS", "KOKOM", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Weil der in seiner Brust bekliebne Hochmuthssaamen,", "tokens": ["Weil", "der", "in", "sei\u00b7ner", "Brust", "be\u00b7klieb\u00b7ne", "Hoch\u00b7muths\u00b7saa\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "APPR", "PPOSAT", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Wie etwan Bilsenkraut, der Sinnen Kr\u00e4fte schw\u00e4cht.", "tokens": ["Wie", "et\u00b7wan", "Bil\u00b7sen\u00b7kraut", ",", "der", "Sin\u00b7nen", "Kr\u00e4f\u00b7te", "schw\u00e4cht", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "NN", "$,", "ART", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.26": {"line.1": {"text": "Er zwingt sich, die Vernunft mit Macht zu unterdr\u00fccken,", "tokens": ["Er", "zwingt", "sich", ",", "die", "Ver\u00b7nunft", "mit", "Macht", "zu", "un\u00b7ter\u00b7dr\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "$,", "ART", "NN", "APPR", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "H\u00e4lt ihren Rath vor toll, verh\u00fcllt ihr helles Licht,", "tokens": ["H\u00e4lt", "ih\u00b7ren", "Rath", "vor", "toll", ",", "ver\u00b7h\u00fcllt", "ihr", "hel\u00b7les", "Licht", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "APPR", "ADJD", "$,", "VVFIN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Sich selbst h\u00f6rt er nicht an, gl\u00e4ubt, was ein Heuchler spricht,", "tokens": ["Sich", "selbst", "h\u00f6rt", "er", "nicht", "an", ",", "gl\u00e4ubt", ",", "was", "ein", "Heuch\u00b7ler", "spricht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADV", "VVFIN", "PPER", "PTKNEG", "PTKVZ", "$,", "VVFIN", "$,", "PRELS", "ART", "NN", "VVFIN", "$,"], "meter": "--+--+-+-+-+", "measure": "anapaest.di.plus"}, "line.4": {"text": "Dem Schein und Schwanenschnee der Seelen Schw\u00e4rze", "tokens": ["Dem", "Schein", "und", "Schwa\u00b7nen\u00b7schnee", "der", "See\u00b7len", "Schw\u00e4r\u00b7ze"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "KON", "NN", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Denn \u00fcbereilt er sich, greift, eh es ihm geh\u00f6rt, [schm\u00fccken.", "tokens": ["Denn", "\u00fc\u00b7be\u00b7reilt", "er", "sich", ",", "greift", ",", "eh", "es", "ihm", "ge\u00b7h\u00f6rt", ",", "schm\u00fc\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct", "punct", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PRF", "$,", "VVFIN", "$,", "KOUS", "PPER", "PPER", "VVFIN", "$,", "$(", "VVINF", "$."], "meter": "-+-+-++--+-+-", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "Mit ungewaschner Hand an die so heilge Biebel,", "tokens": ["Mit", "un\u00b7ge\u00b7waschner", "Hand", "an", "die", "so", "heil\u00b7ge", "Bie\u00b7bel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "APPR", "ART", "ADV", "ADJA", "NN", "$,"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.7": {"text": "Er eifert ohn Verstand, nimmt es nicht wenig \u00fcbel,", "tokens": ["Er", "ei\u00b7fert", "ohn", "Ver\u00b7stand", ",", "nimmt", "es", "nicht", "we\u00b7nig", "\u00fc\u00b7bel", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "$,", "VVFIN", "PPER", "PTKNEG", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Wenn ihn sein Schwager nicht als Schriftgelehrten ehrt.", "tokens": ["Wenn", "ihn", "sein", "Schwa\u00b7ger", "nicht", "als", "Schrift\u00b7ge\u00b7lehr\u00b7ten", "ehrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "PTKNEG", "KOUS", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.27": {"line.1": {"text": "N\u00e4hm er dein Beyspiel wahr, so w\u00fcrd er be\u00dfer lernen,", "tokens": ["N\u00e4hm", "er", "dein", "Bey\u00b7spiel", "wahr", ",", "so", "w\u00fcrd", "er", "be\u00b7\u00dfer", "ler\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "PTKVZ", "$,", "ADV", "VAFIN", "PPER", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wie uns die Creatur den Sch\u00f6pfer ofenbahrt,", "tokens": ["Wie", "uns", "die", "Crea\u00b7tur", "den", "Sch\u00f6p\u00b7fer", "o\u00b7fen\u00b7bahrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.3": {"text": "Wie manches Wunderwerck Meer, Erd und Luft verwahrt;", "tokens": ["Wie", "man\u00b7ches", "Wun\u00b7der\u00b7werck", "Meer", ",", "Erd", "und", "Luft", "ver\u00b7wahrt", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIAT", "NN", "NN", "$,", "NN", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Durch dies begehrstu dich dem P\u00f6bel zu entfernen:", "tokens": ["Durch", "dies", "be\u00b7gehrs\u00b7tu", "dich", "dem", "P\u00f6\u00b7bel", "zu", "ent\u00b7fer\u00b7nen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDS", "VVFIN", "PRF", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Was dieses Ganze fast, wie richtig alles geh,", "tokens": ["Was", "die\u00b7ses", "Gan\u00b7ze", "fast", ",", "wie", "rich\u00b7tig", "al\u00b7les", "geh", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PDAT", "NN", "ADV", "$,", "PWAV", "ADJD", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wie aller F\u00e4ll Erfolg an einer Kette h\u00e4nge", "tokens": ["Wie", "al\u00b7ler", "F\u00e4ll", "Er\u00b7folg", "an", "ei\u00b7ner", "Ket\u00b7te", "h\u00e4n\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PIAT", "NN", "NN", "APPR", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und wie sich ihr Geschehn so ordentlich vermenge,", "tokens": ["Und", "wie", "sich", "ihr", "Ge\u00b7schehn", "so", "or\u00b7dent\u00b7lich", "ver\u00b7men\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PRF", "PPOSAT", "NN", "ADV", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Ja wie, was noch nicht ist, schon im Vergangnen steh,", "tokens": ["Ja", "wie", ",", "was", "noch", "nicht", "ist", ",", "schon", "im", "Ver\u00b7gang\u00b7nen", "steh", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "PWAV", "$,", "PRELS", "ADV", "PTKNEG", "VAFIN", "$,", "ADV", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.28": {"line.1": {"text": "Das mu\u00df, gelehrter Hahn, dein reifer Flei\u00df begreifen.", "tokens": ["Das", "mu\u00df", ",", "ge\u00b7lehr\u00b7ter", "Hahn", ",", "dein", "rei\u00b7fer", "Flei\u00df", "be\u00b7grei\u00b7fen", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "$,", "ADJA", "NN", "$,", "PPOSAT", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Erwege, was hieraus vor Lohn und Wollust springt.", "tokens": ["Er\u00b7we\u00b7ge", ",", "was", "hier\u00b7aus", "vor", "Lohn", "und", "Wol\u00b7lust", "springt", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PRELS", "PAV", "APPR", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Man wird sich selbst bekand, man ruht, man lacht, man singt,", "tokens": ["Man", "wird", "sich", "selbst", "be\u00b7kand", ",", "man", "ruht", ",", "man", "lacht", ",", "man", "singt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "PRF", "ADV", "VVFIN", "$,", "PIS", "VVFIN", "$,", "PIS", "VVFIN", "$,", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wenn Ungl\u00fcck und Gefahr der Leute Thr\u00e4nen h\u00e4ufen.", "tokens": ["Wenn", "Un\u00b7gl\u00fcck", "und", "Ge\u00b7fahr", "der", "Leu\u00b7te", "Thr\u00e4\u00b7nen", "h\u00e4u\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "NN", "ART", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Man sieht mit Frieden an, was Krieg und Eintracht thun,", "tokens": ["Man", "sieht", "mit", "Frie\u00b7den", "an", ",", "was", "Krieg", "und", "Ein\u00b7tracht", "thun", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "APPR", "NN", "PTKVZ", "$,", "PWS", "NN", "KON", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Fragt todte Lehrer aus, spricht mit den kl\u00fcgsten Seelen,", "tokens": ["Fragt", "tod\u00b7te", "Leh\u00b7rer", "aus", ",", "spricht", "mit", "den", "kl\u00fcgs\u00b7ten", "See\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJA", "NN", "PTKVZ", "$,", "VVFIN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Die nun dem Leibe nach in ihren Grabesh\u00f6hlen", "tokens": ["Die", "nun", "dem", "Lei\u00b7be", "nach", "in", "ih\u00b7ren", "Gra\u00b7bes\u00b7h\u00f6h\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "ART", "NN", "APPR", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Mehr als zweytausend Jahr so west- als ostw\u00e4rts ruhn.", "tokens": ["Mehr", "als", "zweyt\u00b7au\u00b7send", "Jahr", "so", "west", "als", "ost\u00b7w\u00e4rts", "ruhn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "KOKOM", "CARD", "NN", "ADV", "TRUNC", "KOKOM", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.29": {"line.1": {"text": "Forthin erwarthet auch der Leibrock deine Lenden,", "tokens": ["For\u00b7thin", "er\u00b7wart\u00b7het", "auch", "der", "Lei\u00b7brock", "dei\u00b7ne", "Len\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADV", "ART", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die Gottes Vorsichtszug de\u00dfelben w\u00fcrdig preist.", "tokens": ["Die", "Got\u00b7tes", "Vor\u00b7sichts\u00b7zug", "de\u00b7\u00dfel\u00b7ben", "w\u00fcr\u00b7dig", "preist", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "PAV", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Dein innerster Beruf, der sich so fr\u00fch erweist,", "tokens": ["Dein", "in\u00b7ners\u00b7ter", "Be\u00b7ruf", ",", "der", "sich", "so", "fr\u00fch", "er\u00b7weist", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,", "PRELS", "PRF", "ADV", "ADJD", "VVFIN", "$,"], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.4": {"text": "Wird dir bald eu\u00dferlich die Wahl der Kirchen senden.", "tokens": ["Wird", "dir", "bald", "eu\u00b7\u00dfer\u00b7lich", "die", "Wahl", "der", "Kir\u00b7chen", "sen\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ADJD", "ART", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Sieht ihm ein G\u00e4rtner Lust, der einen Baum erzielt,", "tokens": ["Sieht", "ihm", "ein", "G\u00e4rt\u00b7ner", "Lust", ",", "der", "ei\u00b7nen", "Baum", "er\u00b7zielt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "NN", "$,", "PRELS", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Der die geno\u00dfne M\u00fch mit reicher Frucht bezahlet,", "tokens": ["Der", "die", "ge\u00b7no\u00df\u00b7ne", "M\u00fch", "mit", "rei\u00b7cher", "Frucht", "be\u00b7zah\u00b7let", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "ADJA", "NN", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "So w\u00fcntscht ich mir vorjezt die Regung abgemahlet,", "tokens": ["So", "w\u00fcnt\u00b7scht", "ich", "mir", "vor\u00b7jezt", "die", "Re\u00b7gung", "ab\u00b7ge\u00b7mah\u00b7let", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "ADV", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}, "line.8": {"text": "Die \u00fcber dir das Herz hochwerther Eltern f\u00fchlt.", "tokens": ["Die", "\u00fc\u00b7ber", "dir", "das", "Herz", "hoch\u00b7wert\u00b7her", "El\u00b7tern", "f\u00fchlt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "PPER", "ART", "NN", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.30": {"line.1": {"text": "Inde\u00dfen blick ich dir aus des Parna\u00dfus Auen", "tokens": ["In\u00b7de\u00b7\u00dfen", "blick", "ich", "dir", "aus", "des", "Par\u00b7na\u00b7\u00dfus", "Au\u00b7en"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der Sonnenstra\u00dfe nach, worauf dein Eifer rennt", "tokens": ["Der", "Son\u00b7nen\u00b7stra\u00b7\u00dfe", "nach", ",", "wo\u00b7rauf", "dein", "Ei\u00b7fer", "rennt"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "PTKVZ", "$,", "PWAV", "PPOSAT", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und durch den Sternenflug die blauen L\u00fcfte trennt,", "tokens": ["Und", "durch", "den", "Ster\u00b7nen\u00b7flug", "die", "blau\u00b7en", "L\u00fcf\u00b7te", "trennt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Darf aber nachzugehn den Federn noch nicht trauen.", "tokens": ["Darf", "a\u00b7ber", "nach\u00b7zu\u00b7gehn", "den", "Fe\u00b7dern", "noch", "nicht", "trau\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "APPR", "ART", "NN", "ADV", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Sollt einmahl Delius mich h\u00f6her aufw\u00e4rts ziehn", "tokens": ["Sollt", "ein\u00b7mahl", "De\u00b7lius", "mich", "h\u00f6\u00b7her", "auf\u00b7w\u00e4rts", "ziehn"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "ADV", "NE", "PPER", "ADJD", "ADV", "VVINF"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.6": {"text": "So wird mein Pegasus sich aus den Th\u00e4lern wagen", "tokens": ["So", "wird", "mein", "Pe\u00b7ga\u00b7sus", "sich", "aus", "den", "Th\u00e4\u00b7lern", "wa\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPOSAT", "NN", "PRF", "APPR", "ART", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und deinen Freundschaftsruhm bis an die H\u00fcgel tragen,", "tokens": ["Und", "dei\u00b7nen", "Freund\u00b7schafts\u00b7ruhm", "bis", "an", "die", "H\u00fc\u00b7gel", "tra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "APPR", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Wo der Acarnan blizt und beide Hunde gl\u00fchn.", "tokens": ["Wo", "der", "A\u00b7car\u00b7nan", "blizt", "und", "bei\u00b7de", "Hun\u00b7de", "gl\u00fchn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "VVFIN", "KON", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.31": {"line.1": {"text": "Las einen frechen Kerl die Musenpriester schimpfen!", "tokens": ["Las", "ei\u00b7nen", "fre\u00b7chen", "Kerl", "die", "Mu\u00b7sen\u00b7pries\u00b7ter", "schimp\u00b7fen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ART", "ADJA", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Sein Zahn rei\u00dft uns vorwahr nicht eine Sayth entzwey.", "tokens": ["Sein", "Zahn", "rei\u00dft", "uns", "vor\u00b7wahr", "nicht", "ei\u00b7ne", "Say\u00b7th", "ent\u00b7zwey", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "ADV", "PTKNEG", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.3": {"text": "Apollo zwingt so gut des Pythons Raserey", "tokens": ["A\u00b7pol\u00b7lo", "zwingt", "so", "gut", "des", "Py\u00b7thons", "Ra\u00b7se\u00b7rey"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "ADV", "ADJD", "ART", "NE", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Als ehmahls Hercules das Thier in Lernens S\u00fcmpfen.", "tokens": ["Als", "eh\u00b7mahls", "Her\u00b7cu\u00b7les", "das", "Thier", "in", "Ler\u00b7nens", "S\u00fcmp\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "NN", "ART", "NN", "APPR", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "So redlich wir vordem einander wohlgewollt,", "tokens": ["So", "red\u00b7lich", "wir", "vor\u00b7dem", "ein\u00b7an\u00b7der", "wohl\u00b7ge\u00b7wollt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "ADV", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "So leicht kan, glaub es nur, in den auch k\u00fcnftgen Jahren", "tokens": ["So", "leicht", "kan", ",", "glaub", "es", "nur", ",", "in", "den", "auch", "k\u00fcnft\u00b7gen", "Jah\u00b7ren"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "VMFIN", "$,", "VVFIN", "PPER", "ADV", "$,", "APPR", "ART", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Dein sch\u00f6nes Violet sich mit dem Lorbeer paaren,", "tokens": ["Dein", "sch\u00f6\u00b7nes", "Vi\u00b7o\u00b7let", "sich", "mit", "dem", "Lor\u00b7beer", "paa\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "PRF", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Um den die Poesie mein junges Haar gerollt.", "tokens": ["Um", "den", "die", "Poe\u00b7sie", "mein", "jun\u00b7ges", "Haar", "ge\u00b7rollt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "ART", "ART", "NN", "PPOSAT", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}}, "stanza.32": {"line.1": {"text": "Vergebliche Gedult! Die Hofnung be\u00dfrer Zeiten", "tokens": ["Ver\u00b7geb\u00b7li\u00b7che", "Ge\u00b7dult", "!", "Die", "Hof\u00b7nung", "be\u00df\u00b7rer", "Zei\u00b7ten"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADJA", "NN", "$.", "ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Speist mein Verlangen nur mit faulen Fischen ab.", "tokens": ["Speist", "mein", "Ver\u00b7lan\u00b7gen", "nur", "mit", "fau\u00b7len", "Fi\u00b7schen", "ab", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "ADV", "APPR", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Man log vom Juppiter, in Creta sey sein Grab,", "tokens": ["Man", "log", "vom", "Jup\u00b7pi\u00b7ter", ",", "in", "Cre\u00b7ta", "sey", "sein", "Grab", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "APPRART", "NN", "$,", "APPR", "NE", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Mir wird man's in der That in Deutschland zubereiten.", "tokens": ["Mir", "wird", "man's", "in", "der", "That", "in", "Deutschland", "zu\u00b7be\u00b7rei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIS", "APPR", "ART", "NN", "APPR", "NE", "VVINF", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Kein G\u00f6nner liebt mein Volck, kein Prinz zieht wie August", "tokens": ["Kein", "G\u00f6n\u00b7ner", "liebt", "mein", "Volck", ",", "kein", "Prinz", "zieht", "wie", "Au\u00b7gust"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "VVFIN", "PPOSAT", "NN", "$,", "PIAT", "NN", "VVFIN", "KOKOM", "NN"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Der Dichter Lorbeerkranz aus dem Verachtungsstaube.", "tokens": ["Der", "Dich\u00b7ter", "Lor\u00b7beer\u00b7kranz", "aus", "dem", "Ver\u00b7ach\u00b7tungs\u00b7stau\u00b7be", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Der Neid quetscht ihren Ruhm mit seiner L\u00e4sterschraube", "tokens": ["Der", "Neid", "quetscht", "ih\u00b7ren", "Ruhm", "mit", "sei\u00b7ner", "L\u00e4s\u00b7ter\u00b7schrau\u00b7be"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PPOSAT", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und sezt der Poesie das Mordheft auf die Brust.", "tokens": ["Und", "sezt", "der", "Poe\u00b7sie", "das", "Mord\u00b7heft", "auf", "die", "Brust", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+----+-+-+", "measure": "dactylic.init"}}, "stanza.33": {"line.1": {"text": "Vor dem lebt' eine Welt, die meine Diener ehrte,", "tokens": ["Vor", "dem", "lebt'", "ei\u00b7ne", "Welt", ",", "die", "mei\u00b7ne", "Die\u00b7ner", "ehr\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "VVFIN", "ART", "NN", "$,", "PRELS", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Da Delphus noch nicht schwieg, Rom in der Bl\u00fcthe stand,", "tokens": ["Da", "Del\u00b7phus", "noch", "nicht", "schwieg", ",", "Rom", "in", "der", "Bl\u00fc\u00b7the", "stand", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "ADV", "PTKNEG", "VVFIN", "$,", "NE", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Mir bothen K\u00f6nige die gnadenreiche Hand,", "tokens": ["Mir", "bo\u00b7then", "K\u00f6\u00b7ni\u00b7ge", "die", "gna\u00b7den\u00b7rei\u00b7che", "Hand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wenn ihr ge\u00fcbtes Ohr gebundne Sprachen h\u00f6rte.", "tokens": ["Wenn", "ihr", "ge\u00b7\u00fcb\u00b7tes", "Ohr", "ge\u00b7bund\u00b7ne", "Spra\u00b7chen", "h\u00f6r\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "ADJA", "NN", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Jezt, seit der Bober-Schwan mein deutsches Kleid gemacht,", "tokens": ["Jezt", ",", "seit", "der", "Bo\u00b7ber\u00b7Schwan", "mein", "deut\u00b7sches", "Kleid", "ge\u00b7macht", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "APPR", "ART", "NN", "PPOSAT", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Th\u00e4t es warhaftig noth, den Magen zu bedencken,", "tokens": ["Th\u00e4t", "es", "war\u00b7haf\u00b7tig", "noth", ",", "den", "Ma\u00b7gen", "zu", "be\u00b7den\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "NN", "$,", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.7": {"text": "Ich lief um Fastnachtszeit in alle Kr\u00fcg und Schencken", "tokens": ["Ich", "lief", "um", "Fast\u00b7nachts\u00b7zeit", "in", "al\u00b7le", "Kr\u00fcg", "und", "Schen\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "NN", "APPR", "PIAT", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und leyrte vor ein Brodt vom Mittag in die Nacht.", "tokens": ["Und", "leyr\u00b7te", "vor", "ein", "Brodt", "vom", "Mit\u00b7tag", "in", "die", "Nacht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "APPRART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.34": {"line.1": {"text": "Mein wohlgestimmtes Spiel, das manchen Held besungen,", "tokens": ["Mein", "wohl\u00b7ge\u00b7stimm\u00b7tes", "Spiel", ",", "das", "man\u00b7chen", "Held", "be\u00b7sun\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,", "PRELS", "PIAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Steht kaum noch diesem an, der nach dem Bocke springt.", "tokens": ["Steht", "kaum", "noch", "die\u00b7sem", "an", ",", "der", "nach", "dem", "Bo\u00b7cke", "springt", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADV", "PDAT", "PTKVZ", "$,", "PRELS", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wenn die von Wachs und Rohr gemachte Pfeife klingt,", "tokens": ["Wenn", "die", "von", "Wachs", "und", "Rohr", "ge\u00b7mach\u00b7te", "Pfei\u00b7fe", "klingt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "APPR", "NN", "KON", "NN", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So wird mein Fl\u00f6thenschall durch ihren Thon verdrungen.", "tokens": ["So", "wird", "mein", "Fl\u00f6\u00b7then\u00b7schall", "durch", "ih\u00b7ren", "Thon", "ver\u00b7drun\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPOSAT", "NN", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Warum? Die Thorheit schl\u00e4gt dem groben Midas nach,", "tokens": ["Wa\u00b7rum", "?", "Die", "Thor\u00b7heit", "schl\u00e4gt", "dem", "gro\u00b7ben", "Mi\u00b7das", "nach", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$.", "ART", "NN", "VVFIN", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Der von der Pfuscherey des Pans aus Unverstande,", "tokens": ["Der", "von", "der", "Pfu\u00b7sche\u00b7rey", "des", "Pans", "aus", "Un\u00b7ver\u00b7stan\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "ART", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Zum Nachtheil meiner Kunst, sich selbst zur Straf und Schande,", "tokens": ["Zum", "Nacht\u00b7heil", "mei\u00b7ner", "Kunst", ",", "sich", "selbst", "zur", "Straf", "und", "Schan\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PPOSAT", "NN", "$,", "PRF", "ADV", "APPRART", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Ein seiner Unvernunft gem\u00e4\u00dfes Urtheil sprach.", "tokens": ["Ein", "sei\u00b7ner", "Un\u00b7ver\u00b7nunft", "ge\u00b7m\u00e4\u00b7\u00dfes", "Ur\u00b7theil", "sprach", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.35": {"line.1": {"text": "Mit solchen Worten schmi\u00df der F\u00fcrst der Pierinnen", "tokens": ["Mit", "sol\u00b7chen", "Wor\u00b7ten", "schmi\u00df", "der", "F\u00fcrst", "der", "Pie\u00b7rin\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PIAT", "NN", "VVFIN", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Den Unmuth aus der Brust, die Glieder auf die Banck", "tokens": ["Den", "Un\u00b7muth", "aus", "der", "Brust", ",", "die", "Glie\u00b7der", "auf", "die", "Banck"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$,", "ART", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und ward vor \u00c4rgern\u00fc\u00df nicht so geschwinde kranck", "tokens": ["Und", "ward", "vor", "\u00c4r\u00b7ger\u00b7n\u00fc\u00df", "nicht", "so", "ge\u00b7schwin\u00b7de", "kranck"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "APPR", "NN", "PTKNEG", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Als die Calliope nicht seiner Ohnmacht innen.", "tokens": ["Als", "die", "Cal\u00b7li\u00b7o\u00b7pe", "nicht", "sei\u00b7ner", "Ohn\u00b7macht", "in\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "PTKNEG", "PPOSAT", "NN", "ADV", "$."], "meter": "--+--+-+-+-+-", "measure": "anapaest.di.plus"}, "line.5": {"text": "Sie stuzte, schwieg und schrie, die Schwestern liefen zu,", "tokens": ["Sie", "stuz\u00b7te", ",", "schwieg", "und", "schrie", ",", "die", "Schwes\u00b7tern", "lie\u00b7fen", "zu", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "VVFIN", "KON", "VVFIN", "$,", "ART", "NN", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Doch nein, sie liefen nicht, sie flogen mit den F\u00fc\u00dfen:", "tokens": ["Doch", "nein", ",", "sie", "lie\u00b7fen", "nicht", ",", "sie", "flo\u00b7gen", "mit", "den", "F\u00fc\u00b7\u00dfen", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKANT", "$,", "PPER", "VVFIN", "PTKNEG", "$,", "PPER", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "So lernt ein leichtes Reh, wenn es das Nez durchri\u00dfen,", "tokens": ["So", "lernt", "ein", "leich\u00b7tes", "Reh", ",", "wenn", "es", "das", "Nez", "durch\u00b7ri\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "$,", "KOUS", "PPER", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Was Schr\u00f6cken und Gefahr vor weite Spr\u00fcnge thu.", "tokens": ["Was", "Schr\u00f6\u00b7cken", "und", "Ge\u00b7fahr", "vor", "wei\u00b7te", "Spr\u00fcn\u00b7ge", "thu", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "KON", "NN", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.36": {"line.1": {"text": "Euterpe kam zuerst und strich die kalten Schl\u00e4fe", "tokens": ["Eu\u00b7ter\u00b7pe", "kam", "zu\u00b7erst", "und", "strich", "die", "kal\u00b7ten", "Schl\u00e4\u00b7fe"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "ADV", "KON", "ADJD", "ART", "ADJA", "NN"], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.2": {"text": "Mit einer Kostbarkeit von Nardenwa\u00dfer an.", "tokens": ["Mit", "ei\u00b7ner", "Kost\u00b7bar\u00b7keit", "von", "Nar\u00b7den\u00b7wa\u00b7\u00dfer", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die andern h\u00e4tten gern ein laut Geschrey gethan,", "tokens": ["Die", "an\u00b7dern", "h\u00e4t\u00b7ten", "gern", "ein", "laut", "Ge\u00b7schrey", "ge\u00b7than", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VAFIN", "ADV", "ART", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wenn nur der Schlag nicht auch die Zungennerven tr\u00e4fe.", "tokens": ["Wenn", "nur", "der", "Schlag", "nicht", "auch", "die", "Zun\u00b7gen\u00b7ner\u00b7ven", "tr\u00e4\u00b7fe", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "PTKNEG", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+---+-", "measure": "unknown.measure.penta"}, "line.5": {"text": "Nur eine faste sich und sprang zum Aesculap,", "tokens": ["Nur", "ei\u00b7ne", "fas\u00b7te", "sich", "und", "sprang", "zum", "A\u00b7e\u00b7scu\u00b7lap", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "PRF", "KON", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.6": {"text": "Der durch ein kr\u00e4ftges Salz die Schlafsucht fl\u00fcchtig machte", "tokens": ["Der", "durch", "ein", "kr\u00e4ft\u00b7ges", "Salz", "die", "Schlaf\u00b7sucht", "fl\u00fcch\u00b7tig", "mach\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "ART", "ADJA", "NN", "ART", "NN", "ADJD", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und den ger\u00fchrten Gott so weit zurechte brachte,", "tokens": ["Und", "den", "ge\u00b7r\u00fchr\u00b7ten", "Gott", "so", "weit", "zu\u00b7rech\u00b7te", "brach\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "ADV", "ADJD", "VVFIN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Da\u00df er mit welcker Hand ein Lebenszeichen gab.", "tokens": ["Da\u00df", "er", "mit", "wel\u00b7cker", "Hand", "ein", "Le\u00b7bens\u00b7zei\u00b7chen", "gab", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PWAT", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.37": {"line.1": {"text": "Dies war der Musen Trost. Doch weil in lezten Z\u00fcgen", "tokens": ["Dies", "war", "der", "Mu\u00b7sen", "Trost", ".", "Doch", "weil", "in", "lez\u00b7ten", "Z\u00fc\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "ART", "NN", "NN", "$.", "KON", "KOUS", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ein jezt Verscheidender gar oft ges\u00fcnder scheint,", "tokens": ["Ein", "jezt", "Ver\u00b7schei\u00b7den\u00b7der", "gar", "oft", "ge\u00b7s\u00fcn\u00b7der", "scheint", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "NN", "ADV", "ADV", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Sich starck und munter macht, bis, eh man es vermeint,", "tokens": ["Sich", "starck", "und", "mun\u00b7ter", "macht", ",", "bis", ",", "eh", "man", "es", "ver\u00b7meint", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADJD", "KON", "ADJD", "VVFIN", "$,", "KOUS", "$,", "KOUS", "PIS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die Geister des Gebl\u00fcts aus ihrer Wohnung fliegen,", "tokens": ["Die", "Geis\u00b7ter", "des", "Ge\u00b7bl\u00fcts", "aus", "ih\u00b7rer", "Woh\u00b7nung", "flie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "So blieb die Schaar dabey halb furcht-, halb hofnungsvoll", "tokens": ["So", "blieb", "die", "Schaar", "da\u00b7bey", "halb", "furcht", ",", "halb", "hof\u00b7nungs\u00b7voll"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "PAV", "ADJD", "TRUNC", "$,", "ADJD", "ADJD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und wanckte wie ein Stamm, der manchen Hieb gef\u00fchlet", "tokens": ["Und", "wanck\u00b7te", "wie", "ein", "Stamm", ",", "der", "man\u00b7chen", "Hieb", "ge\u00b7f\u00fch\u00b7let"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "KOKOM", "ART", "NN", "$,", "PRELS", "PIAT", "NN", "VVPP"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und, eh der lezte Schlag das Garaus mit ihm spielet,", "tokens": ["Und", ",", "eh", "der", "lez\u00b7te", "Schlag", "das", "Ga\u00b7raus", "mit", "ihm", "spie\u00b7let", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "ART", "ADJA", "NN", "ART", "NN", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Mit sich nicht einig ist, worauf er fallen soll.", "tokens": ["Mit", "sich", "nicht", "ei\u00b7nig", "ist", ",", "wo\u00b7rauf", "er", "fal\u00b7len", "soll", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRF", "PTKNEG", "ADJD", "VAFIN", "$,", "PWAV", "PPER", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.38": {"line.1": {"text": "Des Zweifels Traurigkeit must endlich Abschied nehmen,", "tokens": ["Des", "Zwei\u00b7fels", "Trau\u00b7rig\u00b7keit", "must", "end\u00b7lich", "Ab\u00b7schied", "neh\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VMFIN", "ADV", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Als Athem, Farb und Geist dem Krancken wiederkam,", "tokens": ["Als", "A\u00b7them", ",", "Farb", "und", "Geist", "dem", "Kran\u00b7cken", "wie\u00b7der\u00b7kam", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "$,", "NN", "KON", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der, da er neben sich den Arzt ins Auge nahm,", "tokens": ["Der", ",", "da", "er", "ne\u00b7ben", "sich", "den", "Arzt", "ins", "Au\u00b7ge", "nahm", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "KOUS", "PPER", "APPR", "PRF", "ART", "NN", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Sich also h\u00f6ren lie\u00df: So starck ist Leid und Gr\u00e4men,", "tokens": ["Sich", "al\u00b7so", "h\u00f6\u00b7ren", "lie\u00df", ":", "So", "starck", "ist", "Leid", "und", "Gr\u00e4\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADV", "VVINF", "VVFIN", "$.", "ADV", "ADJD", "VAFIN", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Da\u00df G\u00f6tter selbst dadurch dem Tod entgegengehn.", "tokens": ["Da\u00df", "G\u00f6t\u00b7ter", "selbst", "da\u00b7durch", "dem", "Tod", "ent\u00b7ge\u00b7gen\u00b7gehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "ADV", "PAV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Doch weil nun, wie es scheint, die Noth fast halb verschwunden,", "tokens": ["Doch", "weil", "nun", ",", "wie", "es", "scheint", ",", "die", "Noth", "fast", "halb", "ver\u00b7schwun\u00b7den", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ADV", "$,", "PWAV", "PPER", "VVFIN", "$,", "ART", "NN", "ADV", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "So bin ich dir, mein Sohn, vor diesen Flei\u00df verbunden", "tokens": ["So", "bin", "ich", "dir", ",", "mein", "Sohn", ",", "vor", "die\u00b7sen", "Flei\u00df", "ver\u00b7bun\u00b7den"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "PPER", "$,", "PPOSAT", "NN", "$,", "APPR", "PDAT", "NN", "VVPP"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und finde mich geschickt, mir selber vorzustehn.", "tokens": ["Und", "fin\u00b7de", "mich", "ge\u00b7schickt", ",", "mir", "sel\u00b7ber", "vor\u00b7zu\u00b7stehn", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "VVPP", "$,", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.39": {"line.1": {"text": "Ich krancke, wie man sieht, am Leib und am Gem\u00fcthe,", "tokens": ["Ich", "kran\u00b7cke", ",", "wie", "man", "sieht", ",", "am", "Leib", "und", "am", "Ge\u00b7m\u00fc\u00b7the", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PWAV", "PIS", "VVFIN", "$,", "APPRART", "NN", "KON", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Weil ich die Nordenluft nicht recht gewohnen kan.", "tokens": ["Weil", "ich", "die", "Nor\u00b7den\u00b7luft", "nicht", "recht", "ge\u00b7woh\u00b7nen", "kan", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "PTKNEG", "ADJD", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der Ansto\u00df wandelt mich mit einem Fr\u00f6steln an", "tokens": ["Der", "An\u00b7sto\u00df", "wan\u00b7delt", "mich", "mit", "ei\u00b7nem", "Fr\u00f6s\u00b7teln", "an"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PRF", "APPR", "ART", "NN", "APPR"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und zeiget ein von Gall und Gift verderbt Gebl\u00fcte.", "tokens": ["Und", "zei\u00b7get", "ein", "von", "Gall", "und", "Gift", "ver\u00b7derbt", "Ge\u00b7bl\u00fc\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "APPR", "NE", "KON", "NN", "ADJD", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Des Magens erster Weg ist gleichfalls sehr verstopft,", "tokens": ["Des", "Ma\u00b7gens", "ers\u00b7ter", "Weg", "ist", "gleich\u00b7falls", "sehr", "ver\u00b7stopft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "VAFIN", "ADV", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Daher empfind ich oft ein eckelhaftges Grauen.", "tokens": ["Da\u00b7her", "emp\u00b7find", "ich", "oft", "ein", "ec\u00b7kel\u00b7haft\u00b7ges", "Grau\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Wie kan es anders seyn? Ich mu\u00df so viel verdauen,", "tokens": ["Wie", "kan", "es", "an\u00b7ders", "seyn", "?", "Ich", "mu\u00df", "so", "viel", "ver\u00b7dau\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "PPER", "ADV", "VAINF", "$.", "PPER", "VMFIN", "ADV", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Wenn mich die Tadelsucht auf Mund und Finger klopft.", "tokens": ["Wenn", "mich", "die", "Ta\u00b7del\u00b7sucht", "auf", "Mund", "und", "Fin\u00b7ger", "klopft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "APPR", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.40": {"line.1": {"text": "Durch eine Reinigung den Schleim hinwegzuf\u00fchren,", "tokens": ["Durch", "ei\u00b7ne", "Rei\u00b7ni\u00b7gung", "den", "Schleim", "hin\u00b7weg\u00b7zu\u00b7f\u00fch\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wird also folglich wohl das beste Mittel seyn.", "tokens": ["Wird", "al\u00b7so", "folg\u00b7lich", "wohl", "das", "bes\u00b7te", "Mit\u00b7tel", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "ADV", "ART", "ADJA", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Doch brauch ich, solchen Wust und Unrath wegzuspeyn,", "tokens": ["Doch", "brauch", "ich", ",", "sol\u00b7chen", "Wust", "und", "Un\u00b7rath", "weg\u00b7zus\u00b7peyn", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "$,", "PIAT", "NN", "KON", "NN", "VAINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Nicht ein Galappenharz noch Weinstein anzur\u00fchren,", "tokens": ["Nicht", "ein", "Ga\u00b7lap\u00b7pen\u00b7harz", "noch", "Wein\u00b7stein", "an\u00b7zu\u00b7r\u00fch\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ART", "NN", "ADV", "NN", "VVIZU", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Der Finger in den Hals ist eben noch zu schwach.", "tokens": ["Der", "Fin\u00b7ger", "in", "den", "Hals", "ist", "e\u00b7ben", "noch", "zu", "schwach", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "VAFIN", "ADV", "ADV", "PTKA", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Halt! Jezt besinn ich mich, was ich j\u00fcngsthin gefunden,", "tokens": ["Halt", "!", "Jezt", "be\u00b7sinn", "ich", "mich", ",", "was", "ich", "j\u00fcng\u00b7sthin", "ge\u00b7fun\u00b7den", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "$.", "ADV", "VVFIN", "PPER", "PRF", "$,", "PWS", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Es heist dies Vomitiv: Vergn\u00fcgung m\u00fc\u00dfger Stunden", "tokens": ["Es", "heist", "dies", "Vo\u00b7mi\u00b7tiv", ":", "Ver\u00b7gn\u00fc\u00b7gung", "m\u00fc\u00df\u00b7ger", "Stun\u00b7den"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PDS", "NN", "$.", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und giebt an W\u00fcrckung kaum dem st\u00e4rcksten Pulver nach.", "tokens": ["Und", "giebt", "an", "W\u00fcr\u00b7ckung", "kaum", "dem", "st\u00e4rcks\u00b7ten", "Pul\u00b7ver", "nach", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "NN", "ADV", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.41": {"line.1": {"text": "Die Tugend dieses Buchs ist nicht genug zu preisen,", "tokens": ["Die", "Tu\u00b7gend", "die\u00b7ses", "Buchs", "ist", "nicht", "ge\u00b7nug", "zu", "prei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PDAT", "NN", "VAFIN", "PTKNEG", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ich weis, wie dienlich es zu solchen Curen sey.", "tokens": ["Ich", "weis", ",", "wie", "dien\u00b7lich", "es", "zu", "sol\u00b7chen", "Cu\u00b7ren", "sey", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKVZ", "$,", "PWAV", "ADJD", "PPER", "APPR", "PIAT", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wer einen Mund voll list, dem wird so wohl darbey", "tokens": ["Wer", "ei\u00b7nen", "Mund", "voll", "list", ",", "dem", "wird", "so", "wohl", "dar\u00b7bey"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PWS", "ART", "NN", "ADJD", "VVFIN", "$,", "PDS", "VAFIN", "ADV", "ADV", "PAV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Als Jungfern kaum nicht wird, wenn sie ins Bad verreisen.", "tokens": ["Als", "Jung\u00b7fern", "kaum", "nicht", "wird", ",", "wenn", "sie", "ins", "Bad", "ver\u00b7rei\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "ADV", "PTKNEG", "VAFIN", "$,", "KOUS", "PPER", "APPRART", "NE", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Dies kan ich wohl gestehn: Als ich von ohngefehr", "tokens": ["Dies", "kan", "ich", "wohl", "ge\u00b7stehn", ":", "Als", "ich", "von", "ohn\u00b7ge\u00b7fehr"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PDS", "VMFIN", "PPER", "ADV", "VVPP", "$.", "KOUS", "PPER", "APPR", "ADJD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Es auf dem Tr\u00f6del sah, wohin man's neulich schickte,", "tokens": ["Es", "auf", "dem", "Tr\u00f6\u00b7del", "sah", ",", "wo\u00b7hin", "man's", "neu\u00b7lich", "schick\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "ART", "NN", "VVFIN", "$,", "PWAV", "PIS", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Schien es, als wenn die Gicht mir jeden Darm verr\u00fcckte", "tokens": ["Schien", "es", ",", "als", "wenn", "die", "Gicht", "mir", "je\u00b7den", "Darm", "ver\u00b7r\u00fcck\u00b7te"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "$,", "KOKOM", "KOUS", "ART", "NN", "PPER", "PIAT", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und Juppiters Gesch\u00fcz in meinem Leibe w\u00e4r.", "tokens": ["Und", "Jup\u00b7pi\u00b7ters", "Ge\u00b7sch\u00fcz", "in", "mei\u00b7nem", "Lei\u00b7be", "w\u00e4r", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "NN", "APPR", "PPOSAT", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.42": {"line.1": {"text": "Die Musen wurden roth, sie fingen an zu lachen", "tokens": ["Die", "Mu\u00b7sen", "wur\u00b7den", "roth", ",", "sie", "fin\u00b7gen", "an", "zu", "la\u00b7chen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ADJD", "$,", "PPER", "VVFIN", "PTKVZ", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und fielen ungescheut dem Phoebus in das Wort:", "tokens": ["Und", "fie\u00b7len", "un\u00b7ge\u00b7scheut", "dem", "Phoe\u00b7bus", "in", "das", "Wort", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NE", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ach Vater, nenn uns doch den grundgelehrten Ort", "tokens": ["Ach", "Va\u00b7ter", ",", "nenn", "uns", "doch", "den", "grund\u00b7ge\u00b7lehr\u00b7ten", "Ort"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ITJ", "NN", "$,", "VVFIN", "PPER", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und die verschlagne Faust, die solche Schriften machen,", "tokens": ["Und", "die", "ver\u00b7schlag\u00b7ne", "Faust", ",", "die", "sol\u00b7che", "Schrif\u00b7ten", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "$,", "PRELS", "PIAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ein Schif voll Niesewurz kommt von Anticyra,", "tokens": ["Ein", "Schif", "voll", "Nie\u00b7se\u00b7wurz", "kommt", "von", "An\u00b7ti\u00b7cy\u00b7ra", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "NN", "VVFIN", "APPR", "NE", "$,"], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Den L\u00e4strern unsrer Kunst die Nasen vollzureiben.", "tokens": ["Den", "L\u00e4st\u00b7rern", "uns\u00b7rer", "Kunst", "die", "Na\u00b7sen", "voll\u00b7zu\u00b7rei\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Wir wollen einen Rie\u00df des sch\u00f6nen Buchs verschreiben;", "tokens": ["Wir", "wol\u00b7len", "ei\u00b7nen", "Rie\u00df", "des", "sch\u00f6\u00b7nen", "Buchs", "ver\u00b7schrei\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "NN", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Denn an den T\u00fctten ist ein gro\u00dfer Mangel da.", "tokens": ["Denn", "an", "den", "T\u00fct\u00b7ten", "ist", "ein", "gro\u00b7\u00dfer", "Man\u00b7gel", "da", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VAFIN", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.43": {"line.1": {"text": "Die Antwort gab Bericht: Dort unter den Sudeten,", "tokens": ["Die", "Ant\u00b7wort", "gab", "Be\u00b7richt", ":", "Dort", "un\u00b7ter", "den", "Su\u00b7de\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "NN", "$.", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wo Aganippens Quell sich in die Weistriz geu\u00dft,", "tokens": ["Wo", "A\u00b7gan\u00b7ip\u00b7pens", "Quell", "sich", "in", "die", "Wei\u00b7striz", "geu\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NE", "NN", "PRF", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Liegt ein Hyopolis, das sich gar sehr beflei\u00dft,", "tokens": ["Liegt", "ein", "Hyo\u00b7po\u00b7lis", ",", "das", "sich", "gar", "sehr", "be\u00b7flei\u00dft", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NE", "$,", "PRELS", "PRF", "ADV", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.4": {"text": "Durch manch gelehrtes Kind den bleichen Neid zu t\u00f6dten.", "tokens": ["Durch", "manch", "ge\u00b7lehr\u00b7tes", "Kind", "den", "blei\u00b7chen", "Neid", "zu", "t\u00f6d\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "ADJA", "NN", "ART", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Hier scheint die Wi\u00dfenschaft auf ewig einzubaun,", "tokens": ["Hier", "scheint", "die", "Wi\u00b7\u00dfen\u00b7schaft", "auf", "e\u00b7wig", "ein\u00b7zu\u00b7baun", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPR", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Hier zeigt so mancher Kopf die Kr\u00e4fte des Verstandes;", "tokens": ["Hier", "zeigt", "so", "man\u00b7cher", "Kopf", "die", "Kr\u00e4f\u00b7te", "des", "Ver\u00b7stan\u00b7des", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "PIAT", "NN", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Das herrschende Latein, die Anmuth Griechenlandes", "tokens": ["Das", "herr\u00b7schen\u00b7de", "La\u00b7tein", ",", "die", "An\u00b7muth", "Grie\u00b7chen\u00b7lan\u00b7des"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "NN", "NN"], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.8": {"text": "Kan hier von ihrer Zunft nicht wenig Meister schaun.", "tokens": ["Kan", "hier", "von", "ih\u00b7rer", "Zunft", "nicht", "we\u00b7nig", "Meis\u00b7ter", "schaun", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "APPR", "PPOSAT", "NN", "PTKNEG", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.44": {"line.1": {"text": "Der Weizen tr\u00e4gt auch Spreu, kein Gold ist sonder Schlacken.", "tokens": ["Der", "Wei\u00b7zen", "tr\u00e4gt", "auch", "Spreu", ",", "kein", "Gold", "ist", "son\u00b7der", "Schla\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "NN", "$,", "PIAT", "NN", "VAFIN", "ADV", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Sagt mir ein Handwerck her, das keine St\u00fcmper f\u00fchrt.", "tokens": ["Sagt", "mir", "ein", "Hand\u00b7werck", "her", ",", "das", "kei\u00b7ne", "St\u00fcm\u00b7per", "f\u00fchrt", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "PTKVZ", "$,", "PRELS", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Drum lebt auch hier ein Kiel, der minder schreibt als schmiert", "tokens": ["Drum", "lebt", "auch", "hier", "ein", "Kiel", ",", "der", "min\u00b7der", "schreibt", "als", "schmiert"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "ADV", "ADV", "ART", "NE", "$,", "PRELS", "ADV", "VVFIN", "KOKOM", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und geile Bo\u00dfheit hegt. Die Unschuld anzuzwacken,", "tokens": ["Und", "gei\u00b7le", "Bo\u00df\u00b7heit", "hegt", ".", "Die", "Un\u00b7schuld", "an\u00b7zu\u00b7zwa\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "VVFIN", "$.", "ART", "NN", "VVIZU", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Den Lehrern Leides thun, das Priesteramt beschreyn,", "tokens": ["Den", "Leh\u00b7rern", "Lei\u00b7des", "thun", ",", "das", "Pries\u00b7ter\u00b7amt", "be\u00b7schreyn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVINF", "$,", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Des Nechsten Ehrenkleid mit fremder Scheere kr\u00e4ncken,", "tokens": ["Des", "Nechs\u00b7ten", "Eh\u00b7ren\u00b7kleid", "mit", "frem\u00b7der", "Schee\u00b7re", "kr\u00e4n\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "APPR", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Viel wi\u00dfen, nichts verstehn, erzehlen und erdencken", "tokens": ["Viel", "wi\u00b7\u00dfen", ",", "nichts", "ver\u00b7stehn", ",", "er\u00b7zeh\u00b7len", "und", "er\u00b7den\u00b7cken"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVINF", "$,", "PIS", "VVINF", "$,", "VVINF", "KON", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Ist seine ganze Kunst und m\u00fc\u00dfges Flei\u00dfigseyn.", "tokens": ["Ist", "sei\u00b7ne", "gan\u00b7ze", "Kunst", "und", "m\u00fc\u00df\u00b7ges", "Flei\u00b7\u00dfig\u00b7seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "ADJA", "NN", "KON", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.45": {"line.1": {"text": "Vor nennt ich euch das Buch, jezt kennt ihr den Verfa\u00dfer,", "tokens": ["Vor", "nennt", "ich", "euch", "das", "Buch", ",", "jezt", "kennt", "ihr", "den", "Ver\u00b7fa\u00b7\u00dfer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "VVFIN", "PPER", "PRF", "ART", "NN", "$,", "ADV", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Erwegt nunmehr, ob nicht der Vater und das Kind,", "tokens": ["Er\u00b7wegt", "nun\u00b7mehr", ",", "ob", "nicht", "der", "Va\u00b7ter", "und", "das", "Kind", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "$,", "KOUS", "PTKNEG", "ART", "NN", "KON", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wie eins des andern werth, einander \u00e4hnlich sind.", "tokens": ["Wie", "eins", "des", "an\u00b7dern", "werth", ",", "ein\u00b7an\u00b7der", "\u00e4hn\u00b7lich", "sind", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "ART", "ADJA", "ADJD", "$,", "PRF", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Kein wohlgeschmackter Fisch kommt doch aus faulem Wa\u00dfer.", "tokens": ["Kein", "wohl\u00b7ge\u00b7schmack\u00b7ter", "Fisch", "kommt", "doch", "aus", "fau\u00b7lem", "Wa\u00b7\u00dfer", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "VVFIN", "ADV", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Es ist kein Ding so schlimm, es ist zu etwas gut;", "tokens": ["Es", "ist", "kein", "Ding", "so", "schlimm", ",", "es", "ist", "zu", "et\u00b7was", "gut", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIAT", "NN", "ADV", "ADJD", "$,", "PPER", "VAFIN", "PTKA", "PIS", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Mir dient die saubre Schrift, da\u00df ich mich \u00fcbergebe.", "tokens": ["Mir", "dient", "die", "saub\u00b7re", "Schrift", ",", "da\u00df", "ich", "mich", "\u00fc\u00b7ber\u00b7ge\u00b7be", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "$,", "KOUS", "PPER", "PRF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Dies aber schieb ich auf, weil ich das \u00dcbel hebe,", "tokens": ["Dies", "a\u00b7ber", "schieb", "ich", "auf", ",", "weil", "ich", "das", "\u00dc\u00b7bel", "he\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "VVFIN", "PPER", "PTKVZ", "$,", "KOUS", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Wenn mir nur jezt jemand vergn\u00fcgte Posten thut.", "tokens": ["Wenn", "mir", "nur", "jezt", "je\u00b7mand", "ver\u00b7gn\u00fcg\u00b7te", "Pos\u00b7ten", "thut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "PIS", "VVFIN", "NN", "VVFIN", "$."], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}}, "stanza.46": {"line.1": {"text": "Gleich war ich im Begrif, die Zunge loszudr\u00fccken,", "tokens": ["Gleich", "war", "ich", "im", "Be\u00b7grif", ",", "die", "Zun\u00b7ge", "los\u00b7zu\u00b7dr\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "APPRART", "NN", "$,", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Brach Aesculap heraus, weil mich das Schweigen qu\u00e4lt.", "tokens": ["Brach", "A\u00b7e\u00b7scu\u00b7lap", "he\u00b7raus", ",", "weil", "mich", "das", "Schwei\u00b7gen", "qu\u00e4lt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "PTKVZ", "$,", "KOUS", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Gieb Achtung auf den Trost, den dir mein Mund erzehlt,", "tokens": ["Gieb", "Ach\u00b7tung", "auf", "den", "Trost", ",", "den", "dir", "mein", "Mund", "er\u00b7zehlt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "NN", "APPR", "ART", "NN", "$,", "PRELS", "PPER", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Es wird kein Perlentranck dein Herz so starck erquicken.", "tokens": ["Es", "wird", "kein", "Per\u00b7len\u00b7tranck", "dein", "Herz", "so", "starck", "er\u00b7qui\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIAT", "NN", "PPOSAT", "NN", "ADV", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Minerva zog bisher in angef\u00fchrter Stadt", "tokens": ["Mi\u00b7ner\u00b7va", "zog", "bis\u00b7her", "in", "an\u00b7ge\u00b7f\u00fchr\u00b7ter", "Stadt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "ADV", "APPR", "ADJA", "NN"], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.6": {"text": "Von gut- und edler Zucht vier ungemeine H\u00e4hne,", "tokens": ["Von", "gut", "und", "ed\u00b7ler", "Zucht", "vier", "un\u00b7ge\u00b7mei\u00b7ne", "H\u00e4h\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "TRUNC", "KON", "ADJA", "NN", "CARD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Vor die ihr Cypris oft zwey Tauben und zwey Schw\u00e4ne", "tokens": ["Vor", "die", "ihr", "Cyp\u00b7ris", "oft", "zwey", "Tau\u00b7ben", "und", "zwey", "Schw\u00e4\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PRELS", "PPER", "NE", "ADV", "CARD", "NN", "KON", "CARD", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und Juno gar den Pfau umsonst gebothen hat.", "tokens": ["Und", "Ju\u00b7no", "gar", "den", "Pfau", "um\u00b7sonst", "ge\u00b7bo\u00b7then", "hat", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ADV", "ART", "NN", "ADV", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.47": {"line.1": {"text": "Der J\u00fcngst' ist noch gar zart und spielt in ihrem Schoo\u00dfe;", "tokens": ["Der", "J\u00fcngst'", "ist", "noch", "gar", "zart", "und", "spielt", "in", "ih\u00b7rem", "Schoo\u00b7\u00dfe", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "ADV", "ADJD", "KON", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die Themis, kommt mir vor, verspizt sich schon auf ihn.", "tokens": ["Die", "The\u00b7mis", ",", "kommt", "mir", "vor", ",", "ver\u00b7spizt", "sich", "schon", "auf", "ihn", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "$,", "VVFIN", "PPER", "PTKVZ", "$,", "VVFIN", "PRF", "ADV", "APPR", "PPER", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Den einen lies sie mir mit Sorgfalt auferziehn,", "tokens": ["Den", "ei\u00b7nen", "lies", "sie", "mir", "mit", "Sorg\u00b7falt", "auf\u00b7er\u00b7ziehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VVFIN", "PPER", "PPER", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der ist ohn Ursach nicht nach der Geburth der Gro\u00dfe.", "tokens": ["Der", "ist", "ohn", "Ur\u00b7sach", "nicht", "nach", "der", "Ge\u00b7burth", "der", "Gro\u00b7\u00dfe", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "APPR", "NN", "PTKNEG", "APPR", "ART", "NN", "ART", "ADJA", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Mercur, der insgemein gar lange Finger braucht,", "tokens": ["Mer\u00b7cur", ",", "der", "ins\u00b7ge\u00b7mein", "gar", "lan\u00b7ge", "Fin\u00b7ger", "braucht", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PRELS", "ADV", "ADV", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Stahl ihr den dritten weg und flog mit dieser Beute", "tokens": ["Stahl", "ihr", "den", "drit\u00b7ten", "weg", "und", "flog", "mit", "die\u00b7ser", "Beu\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "PPER", "ART", "ADJA", "PTKVZ", "KON", "VVFIN", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Nach jenem Tyrus zu, wo auf der Abendseite", "tokens": ["Nach", "je\u00b7nem", "Ty\u00b7rus", "zu", ",", "wo", "auf", "der", "A\u00b7ben\u00b7dsei\u00b7te"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "PDAT", "NN", "PTKVZ", "$,", "PWAV", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Des fetten Schlesiens der Strand der Oder raucht.", "tokens": ["Des", "fet\u00b7ten", "Schle\u00b7si\u00b7ens", "der", "Strand", "der", "O\u00b7der", "raucht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.48": {"line.1": {"text": "Heut aber, als mein Fu\u00df, den Kriegsgott zu besuchen,", "tokens": ["Heut", "a\u00b7ber", ",", "als", "mein", "Fu\u00df", ",", "den", "Kriegs\u00b7gott", "zu", "be\u00b7su\u00b7chen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$,", "KOUS", "PPOSAT", "NN", "$,", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der nechst bey Temeswar den T\u00fcrckschen Hieb empfing,", "tokens": ["Der", "nechst", "bey", "Te\u00b7mes\u00b7war", "den", "T\u00fcrck\u00b7schen", "Hieb", "emp\u00b7fing", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "NN", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Aus meinem Hause trat und zu verbinden gieng,", "tokens": ["Aus", "mei\u00b7nem", "Hau\u00b7se", "trat", "und", "zu", "ver\u00b7bin\u00b7den", "gieng", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "KON", "PTKZU", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "H\u00f6rt ich ein Weibermaul hart und entsezlich fluchen.", "tokens": ["H\u00f6rt", "ich", "ein", "Wei\u00b7ber\u00b7maul", "hart", "und", "ent\u00b7sez\u00b7lich", "flu\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ART", "NN", "ADJD", "KON", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Mein Aug erfuhr es bald, da\u00df es die Misgunst war,", "tokens": ["Mein", "Aug", "er\u00b7fuhr", "es", "bald", ",", "da\u00df", "es", "die", "Mis\u00b7gunst", "war", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "ADV", "$,", "KOUS", "PPER", "ART", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Die scheusliche Gestalt schien ein verdorrt Gerippe,", "tokens": ["Die", "scheus\u00b7li\u00b7che", "Ge\u00b7stalt", "schien", "ein", "ver\u00b7dorrt", "Ge\u00b7rip\u00b7pe", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ART", "ADJD", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Ein gelb- und halber Zahn bi\u00df in die blutge Lippe", "tokens": ["Ein", "gelb", "und", "hal\u00b7ber", "Zahn", "bi\u00df", "in", "die", "blut\u00b7ge", "Lip\u00b7pe"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "TRUNC", "KON", "ADJA", "NN", "APPR", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und ihre Schm\u00e4hsucht warf die Klauen in das Haar.", "tokens": ["Und", "ih\u00b7re", "Schm\u00e4h\u00b7sucht", "warf", "die", "Klau\u00b7en", "in", "das", "Haar", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.49": {"line.1": {"text": "Was, was! so klafte sie, da\u00df mir das Ohr noch klinget,", "tokens": ["Was", ",", "was", "!", "so", "klaf\u00b7te", "sie", ",", "da\u00df", "mir", "das", "Ohr", "noch", "klin\u00b7get", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "$,", "PWS", "$.", "ADV", "VVFIN", "PPER", "$,", "KOUS", "PPER", "ART", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Was, steigt der J\u00fcngling schon die Ehrenstufen auf?", "tokens": ["Was", ",", "steigt", "der", "J\u00fcng\u00b7ling", "schon", "die", "Eh\u00b7ren\u00b7stu\u00b7fen", "auf", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "$,", "VVFIN", "ART", "NN", "ADV", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Was, cr\u00f6nt man einen Mensch, der seinen Lebenslauf,", "tokens": ["Was", ",", "cr\u00f6nt", "man", "ei\u00b7nen", "Mensch", ",", "der", "sei\u00b7nen", "Le\u00b7bens\u00b7lauf", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "$,", "VVFIN", "PIS", "ART", "NN", "$,", "PRELS", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wie ehmahls br\u00e4uchlich war, noch nicht auf drey\u00dfig bringet?", "tokens": ["Wie", "eh\u00b7mahls", "br\u00e4uch\u00b7lich", "war", ",", "noch", "nicht", "auf", "drey\u00b7\u00dfig", "brin\u00b7get", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "ADJD", "VAFIN", "$,", "ADV", "PTKNEG", "APPR", "CARD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ich merckte kurz darauf, wen dieses Luder schalt,", "tokens": ["Ich", "merck\u00b7te", "kurz", "da\u00b7rauf", ",", "wen", "die\u00b7ses", "Lu\u00b7der", "schalt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "PAV", "$,", "PWS", "PDAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Da man den vierten Hahn zu einem Tempel f\u00fchrte", "tokens": ["Da", "man", "den", "vier\u00b7ten", "Hahn", "zu", "ei\u00b7nem", "Tem\u00b7pel", "f\u00fchr\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "ART", "ADJA", "NN", "APPR", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und mit Kleinodien, doch nicht so reichlich, zierte,", "tokens": ["Und", "mit", "Klein\u00b7o\u00b7di\u00b7en", ",", "doch", "nicht", "so", "reich\u00b7lich", ",", "zier\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "APPR", "NN", "$,", "ADV", "PTKNEG", "ADV", "ADJD", "$,", "VVFIN", "$,"], "meter": "--+--+-+-+-+-", "measure": "anapaest.di.plus"}, "line.8": {"text": "Da\u00df sein Verdienst nicht mehr und weit dar\u00fcber galt.", "tokens": ["Da\u00df", "sein", "Ver\u00b7dienst", "nicht", "mehr", "und", "weit", "da\u00b7r\u00fc\u00b7ber", "galt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "PTKNEG", "ADV", "KON", "ADJD", "PAV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.50": {"line.1": {"text": "Ich schlich dem Jubel nach, trat furchtsam auf die Schwelle", "tokens": ["Ich", "schlich", "dem", "Ju\u00b7bel", "nach", ",", "trat", "furcht\u00b7sam", "auf", "die", "Schwel\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "PTKVZ", "$,", "VVFIN", "ADJD", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Des gro\u00dfen Heiligthums, in dem Sophia sizt.", "tokens": ["Des", "gro\u00b7\u00dfen", "Hei\u00b7lig\u00b7thums", ",", "in", "dem", "So\u00b7phia", "sizt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Die Pracht strahlt \u00fcberall, wie wenn es n\u00e4chtlich blizt,", "tokens": ["Die", "Pracht", "strahlt", "\u00fc\u00b7be\u00b7rall", ",", "wie", "wenn", "es", "n\u00e4cht\u00b7lich", "blizt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "$,", "KOKOM", "KOUS", "PPER", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die Ampeln machten es in jedem Winckel helle,", "tokens": ["Die", "Am\u00b7peln", "mach\u00b7ten", "es", "in", "je\u00b7dem", "Win\u00b7ckel", "hel\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "APPR", "PIAT", "NN", "ADJA", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die S\u00e4nger stritten sch\u00f6n, der Weihrauch dampfte scharf,", "tokens": ["Die", "S\u00e4n\u00b7ger", "strit\u00b7ten", "sch\u00f6n", ",", "der", "Weih\u00b7rauch", "dampf\u00b7te", "scharf", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJD", "$,", "ART", "NN", "VVFIN", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Die Decke war Saphir, der Jaspis lies sich treten,", "tokens": ["Die", "De\u00b7cke", "war", "Sa\u00b7phir", ",", "der", "Jas\u00b7pis", "lies", "sich", "tre\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "NE", "$,", "ART", "NE", "VVFIN", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und mitten prahlt' ein Tisch mit k\u00f6stlichen Ger\u00e4then,", "tokens": ["Und", "mit\u00b7ten", "prahlt'", "ein", "Tisch", "mit", "k\u00f6st\u00b7li\u00b7chen", "Ge\u00b7r\u00e4\u00b7then", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "ART", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Worzu die Wei\u00dfheit kam und ihren Mantel warf.", "tokens": ["Wor\u00b7zu", "die", "Wei\u00df\u00b7heit", "kam", "und", "ih\u00b7ren", "Man\u00b7tel", "warf", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "VVFIN", "KON", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.51": {"line.1": {"text": "Sie nahm der Pallas flugs den Vogel aus den H\u00e4nden,", "tokens": ["Sie", "nahm", "der", "Pal\u00b7las", "flugs", "den", "Vo\u00b7gel", "aus", "den", "H\u00e4n\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADV", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die ihn mit Folgendem ihr als ein Opfer gab:", "tokens": ["Die", "ihn", "mit", "Fol\u00b7gen\u00b7dem", "ihr", "als", "ein", "Op\u00b7fer", "gab", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "NN", "PPER", "KOUS", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Nimm hier mein Schooskind hin und richt es weiter ab,", "tokens": ["Nimm", "hier", "mein", "Scho\u00b7os\u00b7kind", "hin", "und", "richt", "es", "wei\u00b7ter", "ab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "PPOSAT", "NN", "PTKVZ", "KON", "VVFIN", "PPER", "ADV", "PTKVZ", "$,"], "meter": "+--+--+-+-+-+", "measure": "dactylic.di.plus"}, "line.4": {"text": "Ich kan dir meine Gunst nicht herrlicher verpf\u00e4nden.", "tokens": ["Ich", "kan", "dir", "mei\u00b7ne", "Gunst", "nicht", "herr\u00b7li\u00b7cher", "ver\u00b7pf\u00e4n\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "PPOSAT", "NN", "PTKNEG", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ihn hat Apollo l\u00e4ngst die Singekunst gelehrt", "tokens": ["Ihn", "hat", "A\u00b7pol\u00b7lo", "l\u00e4ngst", "die", "Sin\u00b7ge\u00b7kunst", "ge\u00b7lehrt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "NE", "ADV", "ART", "NN", "VVPP"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und seiner Stimme Schall vor Tausenden gepriesen,", "tokens": ["Und", "sei\u00b7ner", "Stim\u00b7me", "Schall", "vor", "Tau\u00b7sen\u00b7den", "ge\u00b7prie\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "NN", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Er ist nicht obenhin in allem unterwiesen,", "tokens": ["Er", "ist", "nicht", "o\u00b7ben\u00b7hin", "in", "al\u00b7lem", "un\u00b7ter\u00b7wie\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKNEG", "ADV", "APPR", "PIS", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Was zu der Gr\u00fcndligkeit der Wi\u00dfenschaft geh\u00f6rt.", "tokens": ["Was", "zu", "der", "Gr\u00fcnd\u00b7lig\u00b7keit", "der", "Wi\u00b7\u00dfen\u00b7schaft", "ge\u00b7h\u00f6rt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "ART", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.52": {"line.1": {"text": "Sie schwieg; und sieh, ein Bild des sch\u00f6nsten Frauenzimmers,", "tokens": ["Sie", "schwieg", ";", "und", "sieh", ",", "ein", "Bild", "des", "sch\u00f6ns\u00b7ten", "Frau\u00b7en\u00b7zim\u00b7mers", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "KON", "VVFIN", "$,", "ART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Es schien den G\u00f6ttern gleich, doch nicht von unsrer Art,", "tokens": ["Es", "schien", "den", "G\u00f6t\u00b7tern", "gleich", ",", "doch", "nicht", "von", "uns\u00b7rer", "Art", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADV", "$,", "ADV", "PTKNEG", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Fuhr durch den Tempel hin, der fast zum Himmel ward", "tokens": ["Fuhr", "durch", "den", "Tem\u00b7pel", "hin", ",", "der", "fast", "zum", "Him\u00b7mel", "ward"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "ART", "NN", "PTKVZ", "$,", "PRELS", "ADV", "APPRART", "NN", "VAFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Von wegen des von ihr geworfnen Sonnenschimmers.", "tokens": ["Von", "we\u00b7gen", "des", "von", "ihr", "ge\u00b7worf\u00b7nen", "Son\u00b7nen\u00b7schim\u00b7mers", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "APPR", "ART", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ihr Mund, der mehr ins Ohr als zum Gesichte drang,", "tokens": ["Ihr", "Mund", ",", "der", "mehr", "ins", "Ohr", "als", "zum", "Ge\u00b7sich\u00b7te", "drang", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PRELS", "ADV", "APPRART", "NN", "KOKOM", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Erhob der Stimme Kraft: Wer Ohren hat, der h\u00f6re", "tokens": ["Er\u00b7hob", "der", "Stim\u00b7me", "Kraft", ":", "Wer", "Oh\u00b7ren", "hat", ",", "der", "h\u00f6\u00b7re"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["VVFIN", "ART", "NN", "NN", "$.", "PWS", "NN", "VAFIN", "$,", "PRELS", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Den Spruch Eusebiens! Der Hahn soll mir zur Ehre", "tokens": ["Den", "Spruch", "Eu\u00b7se\u00b7bi\u00b7ens", "!", "Der", "Hahn", "soll", "mir", "zur", "Eh\u00b7re"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "NE", "$.", "ART", "NN", "VMFIN", "PPER", "APPRART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Ein W\u00e4chter Zions seyn, womit sie sich verschwang.", "tokens": ["Ein", "W\u00e4ch\u00b7ter", "Zi\u00b7ons", "seyn", ",", "wo\u00b7mit", "sie", "sich", "ver\u00b7schwang", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "NE", "VAINF", "$,", "PWAV", "PPER", "PRF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.53": {"line.1": {"text": "Hier schlo\u00df der Aesculap. Sein Vater sang vor Freuden", "tokens": ["Hier", "schlo\u00df", "der", "A\u00b7e\u00b7scu\u00b7lap", ".", "Sein", "Va\u00b7ter", "sang", "vor", "Freu\u00b7den"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "$.", "PPOSAT", "NN", "VVFIN", "APPR", "NN"], "meter": "-+-+--+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Und rief: Die Leyer her! Ich bin bereits gesund.", "tokens": ["Und", "rief", ":", "Die", "Le\u00b7yer", "her", "!", "Ich", "bin", "be\u00b7reits", "ge\u00b7sund", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "ART", "NN", "PTKVZ", "$.", "PPER", "VAFIN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Schl\u00e4gt mich bisweilen gleich das Schwerd der Neider wund,", "tokens": ["Schl\u00e4gt", "mich", "bis\u00b7wei\u00b7len", "gleich", "das", "Schwerd", "der", "Nei\u00b7der", "wund", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "ART", "NN", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Mu\u00df ich schon als ein Gott mehr als die Menschen leiden,", "tokens": ["Mu\u00df", "ich", "schon", "als", "ein", "Gott", "mehr", "als", "die", "Men\u00b7schen", "lei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "KOUS", "ART", "NN", "PIAT", "KOKOM", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Vielleicht kommt einst die Zeit, da mich ein F\u00fcrst erhebt,", "tokens": ["Viel\u00b7leicht", "kommt", "einst", "die", "Zeit", ",", "da", "mich", "ein", "F\u00fcrst", "er\u00b7hebt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "ART", "NN", "$,", "KOUS", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Damit der blinde Schwarm mein Volck nicht mehr verh\u00f6hne;", "tokens": ["Da\u00b7mit", "der", "blin\u00b7de", "Schwarm", "mein", "Volck", "nicht", "mehr", "ver\u00b7h\u00f6h\u00b7ne", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "ADJA", "NN", "PPOSAT", "NN", "PTKNEG", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Vorjezt bin ich vergn\u00fcgt, da einer meiner S\u00f6hne", "tokens": ["Vor\u00b7jezt", "bin", "ich", "ver\u00b7gn\u00fcgt", ",", "da", "ei\u00b7ner", "mei\u00b7ner", "S\u00f6h\u00b7ne"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "VVPP", "$,", "KOUS", "ART", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Im edlen Plei\u00df-Athen der Ehren n\u00e4herstrebt.", "tokens": ["Im", "ed\u00b7len", "Plei\u00df\u00b7A\u00b7then", "der", "Eh\u00b7ren", "n\u00e4\u00b7her\u00b7strebt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}}, "stanza.54": {"line.1": {"text": "Gelehrt- und kluger Freund, er\u00f6fne dies Gedichte.", "tokens": ["Ge\u00b7lehr\u00b7t", "und", "klu\u00b7ger", "Freund", ",", "er\u00b7\u00f6f\u00b7ne", "dies", "Ge\u00b7dich\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["TRUNC", "KON", "ADJA", "NN", "$,", "VVFIN", "PDS", "NN", "$."], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Den Schl\u00fc\u00dfel reichet dir die wahre Redligkeit,", "tokens": ["Den", "Schl\u00fc\u00b7\u00dfel", "rei\u00b7chet", "dir", "die", "wah\u00b7re", "Red\u00b7lig\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die dir dies Unterpfand getreuer Sinnen weiht", "tokens": ["Die", "dir", "dies", "Un\u00b7ter\u00b7pfand", "ge\u00b7treu\u00b7er", "Sin\u00b7nen", "weiht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "PDS", "NN", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und sich daran nichts kehrt, da\u00df man sie splitterrichte.", "tokens": ["Und", "sich", "da\u00b7ran", "nichts", "kehrt", ",", "da\u00df", "man", "sie", "split\u00b7ter\u00b7rich\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "PAV", "PIS", "VVFIN", "$,", "KOUS", "PIS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die Thorheit wird sich zwar hiermit beleidigt sehn,", "tokens": ["Die", "Thor\u00b7heit", "wird", "sich", "zwar", "hier\u00b7mit", "be\u00b7lei\u00b7digt", "sehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PRF", "ADV", "PAV", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Allein man f\u00fcrchtet nicht den Bliz von ihrem Dr\u00e4uen.", "tokens": ["Al\u00b7lein", "man", "f\u00fcrch\u00b7tet", "nicht", "den", "Bliz", "von", "ih\u00b7rem", "Dr\u00e4u\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "VVFIN", "PTKNEG", "ART", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Wer Hecheln schmieden will, mu\u00df keine Funcken scheuen.", "tokens": ["Wer", "He\u00b7cheln", "schmie\u00b7den", "will", ",", "mu\u00df", "kei\u00b7ne", "Fun\u00b7cken", "scheu\u00b7en", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "VVINF", "VMFIN", "$,", "VMFIN", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Was sie an mir ersucht, mag ihr zum Schimpf geschehn.", "tokens": ["Was", "sie", "an", "mir", "er\u00b7sucht", ",", "mag", "ihr", "zum", "Schimpf", "ge\u00b7schehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "APPR", "PPER", "VVPP", "$,", "VMFIN", "PPER", "APPRART", "NN", "VVPP", "$."], "meter": "--+--+-+-+-+", "measure": "anapaest.di.plus"}}, "stanza.55": {"line.1": {"text": "Wie manchmahl denck ich nicht an die verstrichnen Wochen!", "tokens": ["Wie", "manch\u00b7mahl", "denck", "ich", "nicht", "an", "die", "ver\u00b7strich\u00b7nen", "Wo\u00b7chen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "VVIMP", "PPER", "PTKNEG", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der andre Winter schneit den Bergen auf das Haupt,", "tokens": ["Der", "and\u00b7re", "Win\u00b7ter", "schneit", "den", "Ber\u00b7gen", "auf", "das", "Haupt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Seit das Verh\u00e4ngn\u00fc\u00df uns dem s\u00fc\u00dfen Lande raubt,", "tokens": ["Seit", "das", "Ver\u00b7h\u00e4ng\u00b7n\u00fc\u00df", "uns", "dem", "s\u00fc\u00b7\u00dfen", "Lan\u00b7de", "raubt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PPER", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "In welchem wir der Welt am ersten zugesprochen.", "tokens": ["In", "wel\u00b7chem", "wir", "der", "Welt", "am", "ers\u00b7ten", "zu\u00b7ge\u00b7spro\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "ART", "NN", "APPRART", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Dort schlo\u00dfen du und ich den festen Freundschaftsbund,", "tokens": ["Dort", "schlo\u00b7\u00dfen", "du", "und", "ich", "den", "fes\u00b7ten", "Freund\u00b7schafts\u00b7bund", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "KON", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Dort war Vertraulichseyn der Drittmann unsrer Herzen", "tokens": ["Dort", "war", "Ver\u00b7trau\u00b7lich\u00b7seyn", "der", "Dritt\u00b7mann", "uns\u00b7rer", "Her\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "NN", "ART", "NN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und lies die Einsamkeit auf dem Parna\u00dfus scherzen,", "tokens": ["Und", "lies", "die", "Ein\u00b7sam\u00b7keit", "auf", "dem", "Par\u00b7na\u00b7\u00dfus", "scher\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+---+-+-", "measure": "unknown.measure.penta"}, "line.8": {"text": "Wenn seine Castalis uns zu Gebothe stund.", "tokens": ["Wenn", "sei\u00b7ne", "Cas\u00b7ta\u00b7lis", "uns", "zu", "Ge\u00b7bo\u00b7the", "stund", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NE", "PPER", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.56": {"line.1": {"text": "Du flogst nicht vor der Zeit, wie mancher, aus dem Neste,", "tokens": ["Du", "flogst", "nicht", "vor", "der", "Zeit", ",", "wie", "man\u00b7cher", ",", "aus", "dem", "Nes\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "APPR", "ART", "NN", "$,", "PWAV", "PIS", "$,", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der, wenn die Schul ihn brennt, nach hohen Schulen lauft", "tokens": ["Der", ",", "wenn", "die", "Schul", "ihn", "brennt", ",", "nach", "ho\u00b7hen", "Schu\u00b7len", "lauft"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "$,", "KOUS", "ART", "NN", "PPER", "VVFIN", "$,", "APPR", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und eher wiederkommt, als er den Bart gekauft;", "tokens": ["Und", "e\u00b7her", "wie\u00b7der\u00b7kommt", ",", "als", "er", "den", "Bart", "ge\u00b7kauft", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "$,", "KOUS", "PPER", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Du legtest starcken Grund und baust daher auch feste.", "tokens": ["Du", "leg\u00b7test", "star\u00b7cken", "Grund", "und", "baust", "da\u00b7her", "auch", "fes\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJA", "NN", "KON", "VVFIN", "PAV", "ADV", "ADJA", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Der Hundertste bekommt der Wei\u00dfheit Meisterrecht", "tokens": ["Der", "Hun\u00b7derts\u00b7te", "be\u00b7kommt", "der", "Wei\u00df\u00b7heit", "Meis\u00b7ter\u00b7recht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und weis von ihr wohl nichts als nur den blo\u00dfen Nahmen,", "tokens": ["Und", "weis", "von", "ihr", "wohl", "nichts", "als", "nur", "den", "blo\u00b7\u00dfen", "Nah\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKVZ", "APPR", "PPER", "ADV", "PIS", "KOKOM", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Weil der in seiner Brust bekliebne Hochmuthssaamen,", "tokens": ["Weil", "der", "in", "sei\u00b7ner", "Brust", "be\u00b7klieb\u00b7ne", "Hoch\u00b7muths\u00b7saa\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "APPR", "PPOSAT", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Wie etwan Bilsenkraut, der Sinnen Kr\u00e4fte schw\u00e4cht.", "tokens": ["Wie", "et\u00b7wan", "Bil\u00b7sen\u00b7kraut", ",", "der", "Sin\u00b7nen", "Kr\u00e4f\u00b7te", "schw\u00e4cht", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "NN", "$,", "ART", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.57": {"line.1": {"text": "Er zwingt sich, die Vernunft mit Macht zu unterdr\u00fccken,", "tokens": ["Er", "zwingt", "sich", ",", "die", "Ver\u00b7nunft", "mit", "Macht", "zu", "un\u00b7ter\u00b7dr\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "$,", "ART", "NN", "APPR", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "H\u00e4lt ihren Rath vor toll, verh\u00fcllt ihr helles Licht,", "tokens": ["H\u00e4lt", "ih\u00b7ren", "Rath", "vor", "toll", ",", "ver\u00b7h\u00fcllt", "ihr", "hel\u00b7les", "Licht", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "APPR", "ADJD", "$,", "VVFIN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Sich selbst h\u00f6rt er nicht an, gl\u00e4ubt, was ein Heuchler spricht,", "tokens": ["Sich", "selbst", "h\u00f6rt", "er", "nicht", "an", ",", "gl\u00e4ubt", ",", "was", "ein", "Heuch\u00b7ler", "spricht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADV", "VVFIN", "PPER", "PTKNEG", "PTKVZ", "$,", "VVFIN", "$,", "PRELS", "ART", "NN", "VVFIN", "$,"], "meter": "--+--+-+-+-+", "measure": "anapaest.di.plus"}, "line.4": {"text": "Dem Schein und Schwanenschnee der Seelen Schw\u00e4rze", "tokens": ["Dem", "Schein", "und", "Schwa\u00b7nen\u00b7schnee", "der", "See\u00b7len", "Schw\u00e4r\u00b7ze"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "KON", "NN", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Denn \u00fcbereilt er sich, greift, eh es ihm geh\u00f6rt, [schm\u00fccken.", "tokens": ["Denn", "\u00fc\u00b7be\u00b7reilt", "er", "sich", ",", "greift", ",", "eh", "es", "ihm", "ge\u00b7h\u00f6rt", ",", "schm\u00fc\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct", "punct", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PRF", "$,", "VVFIN", "$,", "KOUS", "PPER", "PPER", "VVFIN", "$,", "$(", "VVINF", "$."], "meter": "-+-+-++--+-+-", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "Mit ungewaschner Hand an die so heilge Biebel,", "tokens": ["Mit", "un\u00b7ge\u00b7waschner", "Hand", "an", "die", "so", "heil\u00b7ge", "Bie\u00b7bel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "APPR", "ART", "ADV", "ADJA", "NN", "$,"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.7": {"text": "Er eifert ohn Verstand, nimmt es nicht wenig \u00fcbel,", "tokens": ["Er", "ei\u00b7fert", "ohn", "Ver\u00b7stand", ",", "nimmt", "es", "nicht", "we\u00b7nig", "\u00fc\u00b7bel", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "$,", "VVFIN", "PPER", "PTKNEG", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Wenn ihn sein Schwager nicht als Schriftgelehrten ehrt.", "tokens": ["Wenn", "ihn", "sein", "Schwa\u00b7ger", "nicht", "als", "Schrift\u00b7ge\u00b7lehr\u00b7ten", "ehrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "PTKNEG", "KOUS", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.58": {"line.1": {"text": "N\u00e4hm er dein Beyspiel wahr, so w\u00fcrd er be\u00dfer lernen,", "tokens": ["N\u00e4hm", "er", "dein", "Bey\u00b7spiel", "wahr", ",", "so", "w\u00fcrd", "er", "be\u00b7\u00dfer", "ler\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "PTKVZ", "$,", "ADV", "VAFIN", "PPER", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wie uns die Creatur den Sch\u00f6pfer ofenbahrt,", "tokens": ["Wie", "uns", "die", "Crea\u00b7tur", "den", "Sch\u00f6p\u00b7fer", "o\u00b7fen\u00b7bahrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.3": {"text": "Wie manches Wunderwerck Meer, Erd und Luft verwahrt;", "tokens": ["Wie", "man\u00b7ches", "Wun\u00b7der\u00b7werck", "Meer", ",", "Erd", "und", "Luft", "ver\u00b7wahrt", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIAT", "NN", "NN", "$,", "NN", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Durch dies begehrstu dich dem P\u00f6bel zu entfernen:", "tokens": ["Durch", "dies", "be\u00b7gehrs\u00b7tu", "dich", "dem", "P\u00f6\u00b7bel", "zu", "ent\u00b7fer\u00b7nen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDS", "VVFIN", "PRF", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Was dieses Ganze fast, wie richtig alles geh,", "tokens": ["Was", "die\u00b7ses", "Gan\u00b7ze", "fast", ",", "wie", "rich\u00b7tig", "al\u00b7les", "geh", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PDAT", "NN", "ADV", "$,", "PWAV", "ADJD", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wie aller F\u00e4ll Erfolg an einer Kette h\u00e4nge", "tokens": ["Wie", "al\u00b7ler", "F\u00e4ll", "Er\u00b7folg", "an", "ei\u00b7ner", "Ket\u00b7te", "h\u00e4n\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PIAT", "NN", "NN", "APPR", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und wie sich ihr Geschehn so ordentlich vermenge,", "tokens": ["Und", "wie", "sich", "ihr", "Ge\u00b7schehn", "so", "or\u00b7dent\u00b7lich", "ver\u00b7men\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PRF", "PPOSAT", "NN", "ADV", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Ja wie, was noch nicht ist, schon im Vergangnen steh,", "tokens": ["Ja", "wie", ",", "was", "noch", "nicht", "ist", ",", "schon", "im", "Ver\u00b7gang\u00b7nen", "steh", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "PWAV", "$,", "PRELS", "ADV", "PTKNEG", "VAFIN", "$,", "ADV", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.59": {"line.1": {"text": "Das mu\u00df, gelehrter Hahn, dein reifer Flei\u00df begreifen.", "tokens": ["Das", "mu\u00df", ",", "ge\u00b7lehr\u00b7ter", "Hahn", ",", "dein", "rei\u00b7fer", "Flei\u00df", "be\u00b7grei\u00b7fen", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "$,", "ADJA", "NN", "$,", "PPOSAT", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Erwege, was hieraus vor Lohn und Wollust springt.", "tokens": ["Er\u00b7we\u00b7ge", ",", "was", "hier\u00b7aus", "vor", "Lohn", "und", "Wol\u00b7lust", "springt", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PRELS", "PAV", "APPR", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Man wird sich selbst bekand, man ruht, man lacht, man singt,", "tokens": ["Man", "wird", "sich", "selbst", "be\u00b7kand", ",", "man", "ruht", ",", "man", "lacht", ",", "man", "singt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "PRF", "ADV", "VVFIN", "$,", "PIS", "VVFIN", "$,", "PIS", "VVFIN", "$,", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wenn Ungl\u00fcck und Gefahr der Leute Thr\u00e4nen h\u00e4ufen.", "tokens": ["Wenn", "Un\u00b7gl\u00fcck", "und", "Ge\u00b7fahr", "der", "Leu\u00b7te", "Thr\u00e4\u00b7nen", "h\u00e4u\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "NN", "ART", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Man sieht mit Frieden an, was Krieg und Eintracht thun,", "tokens": ["Man", "sieht", "mit", "Frie\u00b7den", "an", ",", "was", "Krieg", "und", "Ein\u00b7tracht", "thun", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "APPR", "NN", "PTKVZ", "$,", "PWS", "NN", "KON", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Fragt todte Lehrer aus, spricht mit den kl\u00fcgsten Seelen,", "tokens": ["Fragt", "tod\u00b7te", "Leh\u00b7rer", "aus", ",", "spricht", "mit", "den", "kl\u00fcgs\u00b7ten", "See\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJA", "NN", "PTKVZ", "$,", "VVFIN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Die nun dem Leibe nach in ihren Grabesh\u00f6hlen", "tokens": ["Die", "nun", "dem", "Lei\u00b7be", "nach", "in", "ih\u00b7ren", "Gra\u00b7bes\u00b7h\u00f6h\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "ART", "NN", "APPR", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Mehr als zweytausend Jahr so west- als ostw\u00e4rts ruhn.", "tokens": ["Mehr", "als", "zweyt\u00b7au\u00b7send", "Jahr", "so", "west", "als", "ost\u00b7w\u00e4rts", "ruhn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "KOKOM", "CARD", "NN", "ADV", "TRUNC", "KOKOM", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.60": {"line.1": {"text": "Forthin erwarthet auch der Leibrock deine Lenden,", "tokens": ["For\u00b7thin", "er\u00b7wart\u00b7het", "auch", "der", "Lei\u00b7brock", "dei\u00b7ne", "Len\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADV", "ART", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die Gottes Vorsichtszug de\u00dfelben w\u00fcrdig preist.", "tokens": ["Die", "Got\u00b7tes", "Vor\u00b7sichts\u00b7zug", "de\u00b7\u00dfel\u00b7ben", "w\u00fcr\u00b7dig", "preist", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "PAV", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Dein innerster Beruf, der sich so fr\u00fch erweist,", "tokens": ["Dein", "in\u00b7ners\u00b7ter", "Be\u00b7ruf", ",", "der", "sich", "so", "fr\u00fch", "er\u00b7weist", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,", "PRELS", "PRF", "ADV", "ADJD", "VVFIN", "$,"], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.4": {"text": "Wird dir bald eu\u00dferlich die Wahl der Kirchen senden.", "tokens": ["Wird", "dir", "bald", "eu\u00b7\u00dfer\u00b7lich", "die", "Wahl", "der", "Kir\u00b7chen", "sen\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ADJD", "ART", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Sieht ihm ein G\u00e4rtner Lust, der einen Baum erzielt,", "tokens": ["Sieht", "ihm", "ein", "G\u00e4rt\u00b7ner", "Lust", ",", "der", "ei\u00b7nen", "Baum", "er\u00b7zielt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "NN", "$,", "PRELS", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Der die geno\u00dfne M\u00fch mit reicher Frucht bezahlet,", "tokens": ["Der", "die", "ge\u00b7no\u00df\u00b7ne", "M\u00fch", "mit", "rei\u00b7cher", "Frucht", "be\u00b7zah\u00b7let", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "ADJA", "NN", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "So w\u00fcntscht ich mir vorjezt die Regung abgemahlet,", "tokens": ["So", "w\u00fcnt\u00b7scht", "ich", "mir", "vor\u00b7jezt", "die", "Re\u00b7gung", "ab\u00b7ge\u00b7mah\u00b7let", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "ADV", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}, "line.8": {"text": "Die \u00fcber dir das Herz hochwerther Eltern f\u00fchlt.", "tokens": ["Die", "\u00fc\u00b7ber", "dir", "das", "Herz", "hoch\u00b7wert\u00b7her", "El\u00b7tern", "f\u00fchlt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "PPER", "ART", "NN", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.61": {"line.1": {"text": "Inde\u00dfen blick ich dir aus des Parna\u00dfus Auen", "tokens": ["In\u00b7de\u00b7\u00dfen", "blick", "ich", "dir", "aus", "des", "Par\u00b7na\u00b7\u00dfus", "Au\u00b7en"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der Sonnenstra\u00dfe nach, worauf dein Eifer rennt", "tokens": ["Der", "Son\u00b7nen\u00b7stra\u00b7\u00dfe", "nach", ",", "wo\u00b7rauf", "dein", "Ei\u00b7fer", "rennt"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "PTKVZ", "$,", "PWAV", "PPOSAT", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und durch den Sternenflug die blauen L\u00fcfte trennt,", "tokens": ["Und", "durch", "den", "Ster\u00b7nen\u00b7flug", "die", "blau\u00b7en", "L\u00fcf\u00b7te", "trennt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Darf aber nachzugehn den Federn noch nicht trauen.", "tokens": ["Darf", "a\u00b7ber", "nach\u00b7zu\u00b7gehn", "den", "Fe\u00b7dern", "noch", "nicht", "trau\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "APPR", "ART", "NN", "ADV", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Sollt einmahl Delius mich h\u00f6her aufw\u00e4rts ziehn", "tokens": ["Sollt", "ein\u00b7mahl", "De\u00b7lius", "mich", "h\u00f6\u00b7her", "auf\u00b7w\u00e4rts", "ziehn"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "ADV", "NE", "PPER", "ADJD", "ADV", "VVINF"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.6": {"text": "So wird mein Pegasus sich aus den Th\u00e4lern wagen", "tokens": ["So", "wird", "mein", "Pe\u00b7ga\u00b7sus", "sich", "aus", "den", "Th\u00e4\u00b7lern", "wa\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPOSAT", "NN", "PRF", "APPR", "ART", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und deinen Freundschaftsruhm bis an die H\u00fcgel tragen,", "tokens": ["Und", "dei\u00b7nen", "Freund\u00b7schafts\u00b7ruhm", "bis", "an", "die", "H\u00fc\u00b7gel", "tra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "APPR", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Wo der Acarnan blizt und beide Hunde gl\u00fchn.", "tokens": ["Wo", "der", "A\u00b7car\u00b7nan", "blizt", "und", "bei\u00b7de", "Hun\u00b7de", "gl\u00fchn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "VVFIN", "KON", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.62": {"line.1": {"text": "Las einen frechen Kerl die Musenpriester schimpfen!", "tokens": ["Las", "ei\u00b7nen", "fre\u00b7chen", "Kerl", "die", "Mu\u00b7sen\u00b7pries\u00b7ter", "schimp\u00b7fen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ART", "ADJA", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Sein Zahn rei\u00dft uns vorwahr nicht eine Sayth entzwey.", "tokens": ["Sein", "Zahn", "rei\u00dft", "uns", "vor\u00b7wahr", "nicht", "ei\u00b7ne", "Say\u00b7th", "ent\u00b7zwey", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "ADV", "PTKNEG", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.3": {"text": "Apollo zwingt so gut des Pythons Raserey", "tokens": ["A\u00b7pol\u00b7lo", "zwingt", "so", "gut", "des", "Py\u00b7thons", "Ra\u00b7se\u00b7rey"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "ADV", "ADJD", "ART", "NE", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Als ehmahls Hercules das Thier in Lernens S\u00fcmpfen.", "tokens": ["Als", "eh\u00b7mahls", "Her\u00b7cu\u00b7les", "das", "Thier", "in", "Ler\u00b7nens", "S\u00fcmp\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "NN", "ART", "NN", "APPR", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "So redlich wir vordem einander wohlgewollt,", "tokens": ["So", "red\u00b7lich", "wir", "vor\u00b7dem", "ein\u00b7an\u00b7der", "wohl\u00b7ge\u00b7wollt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "ADV", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "So leicht kan, glaub es nur, in den auch k\u00fcnftgen Jahren", "tokens": ["So", "leicht", "kan", ",", "glaub", "es", "nur", ",", "in", "den", "auch", "k\u00fcnft\u00b7gen", "Jah\u00b7ren"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "VMFIN", "$,", "VVFIN", "PPER", "ADV", "$,", "APPR", "ART", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Dein sch\u00f6nes Violet sich mit dem Lorbeer paaren,", "tokens": ["Dein", "sch\u00f6\u00b7nes", "Vi\u00b7o\u00b7let", "sich", "mit", "dem", "Lor\u00b7beer", "paa\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "PRF", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Um den die Poesie mein junges Haar gerollt.", "tokens": ["Um", "den", "die", "Poe\u00b7sie", "mein", "jun\u00b7ges", "Haar", "ge\u00b7rollt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "ART", "ART", "NN", "PPOSAT", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}}}}}