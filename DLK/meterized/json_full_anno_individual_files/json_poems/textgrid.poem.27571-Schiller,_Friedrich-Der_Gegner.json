{"textgrid.poem.27571": {"metadata": {"author": {"name": "Schiller, Friedrich", "birth": "N.A.", "death": "N.A."}, "title": "Der Gegner", "genre": "verse", "period": "N.A.", "pub_year": 1782, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Neu ist der Einfall doch nicht, man hat ja selber den h\u00f6chsten,", "tokens": ["Neu", "ist", "der", "Ein\u00b7fall", "doch", "nicht", ",", "man", "hat", "ja", "sel\u00b7ber", "den", "h\u00f6chs\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "ART", "NN", "ADV", "PTKNEG", "$,", "PIS", "VAFIN", "ADV", "ADV", "ART", "ADJA", "$,"], "meter": "+--+--+-+-+--+-", "measure": "hexameter"}, "line.2": {"text": "Einzigsten, reinsten Begriff Gottes in Teile geteilt.", "tokens": ["Ein\u00b7zigs\u00b7ten", ",", "reins\u00b7ten", "Be\u00b7griff", "Got\u00b7tes", "in", "Tei\u00b7le", "ge\u00b7teilt", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADJA", "NN", "NN", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+--+--+", "measure": "iambic.hexa.relaxed"}}, "stanza.2": {"line.1": {"text": "Redet, Lumpen, lumpig von mir, doch saget: \u00bbEs war ihm", "tokens": ["Re\u00b7det", ",", "Lum\u00b7pen", ",", "lum\u00b7pig", "von", "mir", ",", "doch", "sa\u00b7get", ":", "\u00bb", "Es", "war", "ihm"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "punct", "word", "word", "word"], "pos": ["VVFIN", "$,", "NN", "$,", "ADJD", "APPR", "PPER", "$,", "ADV", "VVFIN", "$.", "$(", "PPER", "VAFIN", "PPER"], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}}, "stanza.3": {"line.1": {"text": "\u00bbgeh doch! Sein Leben ist keusch.\u00ab Das m\u00f6chten wir gerne ihm lassen,", "tokens": ["\u00bb", "geh", "doch", "!", "Sein", "Le\u00b7ben", "ist", "keusch", ".", "\u00ab", "Das", "m\u00f6ch\u00b7ten", "wir", "ger\u00b7ne", "ihm", "las\u00b7sen", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "ADV", "$.", "PPOSAT", "NN", "VAFIN", "ADJD", "$.", "$(", "PDS", "VMFIN", "PPER", "ADV", "PPER", "VVINF", "$,"], "meter": "+--+--+-+--+--+-", "measure": "hexameter"}, "line.2": {"text": "Aber die lustigste Kunst ist nur bei ihm nicht jokos.", "tokens": ["A\u00b7ber", "die", "lus\u00b7tigs\u00b7te", "Kunst", "ist", "nur", "bei", "ihm", "nicht", "jo\u00b7kos", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "VAFIN", "ADV", "APPR", "PPER", "PTKNEG", "NE", "$."], "meter": "+--+--++-+-+-+", "measure": "dactylic.di.plus"}}, "stanza.4": {"line.1": {"text": "Giebichensteiner, sei auch pers\u00f6nlich in deinen Satiren,", "tokens": ["Gie\u00b7bi\u00b7chen\u00b7stei\u00b7ner", ",", "sei", "auch", "per\u00b7s\u00f6n\u00b7lich", "in", "dei\u00b7nen", "Sa\u00b7ti\u00b7ren", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VAFIN", "ADV", "ADJD", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+--+--+----", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Deine leid'ge Person tritt doch am st\u00e4rksten hervor.", "tokens": ["Dei\u00b7ne", "lei\u00b7d'\u00b7ge", "Per\u00b7son", "tritt", "doch", "am", "st\u00e4rks\u00b7ten", "her\u00b7vor", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVFIN", "ADV", "APPRART", "ADJA", "PTKVZ", "$."], "meter": "+-+--+--+-+--+", "measure": "trochaic.hexa.relaxed"}}, "stanza.5": {"line.1": {"text": "Als man ihn traf, den Esel, da schlug er aus, doch das macht ihn", "tokens": ["Als", "man", "ihn", "traf", ",", "den", "E\u00b7sel", ",", "da", "schlug", "er", "aus", ",", "doch", "das", "macht", "ihn"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "PPER", "VVFIN", "$,", "ART", "NN", "$,", "ADV", "VVFIN", "PPER", "PTKVZ", "$,", "KON", "PDS", "VVFIN", "PPER"], "meter": "-+-+-+--+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Nicht zum Pferde. Nicht wird, den er auch tr\u00e4fe, ihm gleich.", "tokens": ["Nicht", "zum", "Pfer\u00b7de", ".", "Nicht", "wird", ",", "den", "er", "auch", "tr\u00e4\u00b7fe", ",", "ihm", "gleich", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PTKNEG", "APPRART", "NN", "$.", "PTKNEG", "VAFIN", "$,", "PRELS", "PPER", "ADV", "VVFIN", "$,", "PPER", "ADV", "$."], "meter": "--+--+---+--+", "measure": "anapaest.di.plus"}}, "stanza.6": {"line.1": {"text": "Freilich laufe wer nackt als ungest\u00fcmer Lupercus,", "tokens": ["Frei\u00b7lich", "lau\u00b7fe", "wer", "nackt", "als", "un\u00b7ge\u00b7st\u00fc\u00b7mer", "Lu\u00b7per\u00b7cus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PWS", "ADJD", "KOKOM", "ADJD", "NE", "$,"], "meter": "+-+--+-+-+-+-+", "measure": "trochaic.septa.relaxed"}, "line.2": {"text": "Aber mit falschem Bart prangst in der Kutte du nur.", "tokens": ["A\u00b7ber", "mit", "fal\u00b7schem", "Bart", "prangst", "in", "der", "Kut\u00b7te", "du", "nur", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ADJA", "NN", "VVFIN", "APPR", "ART", "NN", "PPER", "ADV", "$."], "meter": "+--+-+-+-+--+", "measure": "iambic.hexa.invert"}}, "stanza.7": {"line.1": {"text": "Sag mir, wo ist denn die Klicke? \u00bbDa dr\u00fcben ist sie beim Nachbar.\u00ab", "tokens": ["Sag", "mir", ",", "wo", "ist", "denn", "die", "Kli\u00b7cke", "?", "\u00bb", "Da", "dr\u00fc\u00b7ben", "ist", "sie", "beim", "Nach\u00b7bar", ".", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "PPER", "$,", "PWAV", "VAFIN", "ADV", "ART", "NN", "$.", "$(", "ADV", "ADV", "VAFIN", "PPER", "APPRART", "NN", "$.", "$("], "meter": "+--+--+--+-++-+-", "measure": "dactylic.tri.plus"}, "line.2": {"text": "Frag ich den Nachbar, er sagt, h\u00fcben sei sie bei dir.", "tokens": ["Frag", "ich", "den", "Nach\u00b7bar", ",", "er", "sagt", ",", "h\u00fc\u00b7ben", "sei", "sie", "bei", "dir", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ART", "NN", "$,", "PPER", "VVFIN", "$,", "ADJD", "VAFIN", "PPER", "APPR", "PPER", "$."], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}}, "stanza.8": {"line.1": {"text": "Einen Tyrannen zu hassen verm\u00f6gen auch knechtische Seelen,", "tokens": ["Ei\u00b7nen", "Ty\u00b7ran\u00b7nen", "zu", "has\u00b7sen", "ver\u00b7m\u00f6\u00b7gen", "auch", "knech\u00b7ti\u00b7sche", "See\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKZU", "VVINF", "VVFIN", "ADV", "ADJA", "NN", "$,"], "meter": "+--+--+--+--+--+-", "measure": "hexameter"}, "line.2": {"text": "Nur wer die Tyrannei hasset, ist edel und gro\u00df.", "tokens": ["Nur", "wer", "die", "Ty\u00b7ran\u00b7nei", "has\u00b7set", ",", "ist", "e\u00b7del", "und", "gro\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PWS", "ART", "NN", "VVFIN", "$,", "VAFIN", "ADJD", "KON", "ADJD", "$."], "meter": "-+---+-+-+--+", "measure": "iambic.penta.chol"}}, "stanza.9": {"line.1": {"text": "Neu ist der Einfall doch nicht, man hat ja selber den h\u00f6chsten,", "tokens": ["Neu", "ist", "der", "Ein\u00b7fall", "doch", "nicht", ",", "man", "hat", "ja", "sel\u00b7ber", "den", "h\u00f6chs\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "ART", "NN", "ADV", "PTKNEG", "$,", "PIS", "VAFIN", "ADV", "ADV", "ART", "ADJA", "$,"], "meter": "+--+--+-+-+--+-", "measure": "hexameter"}, "line.2": {"text": "Einzigsten, reinsten Begriff Gottes in Teile geteilt.", "tokens": ["Ein\u00b7zigs\u00b7ten", ",", "reins\u00b7ten", "Be\u00b7griff", "Got\u00b7tes", "in", "Tei\u00b7le", "ge\u00b7teilt", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADJA", "NN", "NN", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+--+--+", "measure": "iambic.hexa.relaxed"}}, "stanza.10": {"line.1": {"text": "Redet, Lumpen, lumpig von mir, doch saget: \u00bbEs war ihm", "tokens": ["Re\u00b7det", ",", "Lum\u00b7pen", ",", "lum\u00b7pig", "von", "mir", ",", "doch", "sa\u00b7get", ":", "\u00bb", "Es", "war", "ihm"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "punct", "word", "word", "word"], "pos": ["VVFIN", "$,", "NN", "$,", "ADJD", "APPR", "PPER", "$,", "ADV", "VVFIN", "$.", "$(", "PPER", "VAFIN", "PPER"], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}}, "stanza.11": {"line.1": {"text": "\u00bbgeh doch! Sein Leben ist keusch.\u00ab Das m\u00f6chten wir gerne ihm lassen,", "tokens": ["\u00bb", "geh", "doch", "!", "Sein", "Le\u00b7ben", "ist", "keusch", ".", "\u00ab", "Das", "m\u00f6ch\u00b7ten", "wir", "ger\u00b7ne", "ihm", "las\u00b7sen", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "ADV", "$.", "PPOSAT", "NN", "VAFIN", "ADJD", "$.", "$(", "PDS", "VMFIN", "PPER", "ADV", "PPER", "VVINF", "$,"], "meter": "+--+--+-+--+--+-", "measure": "hexameter"}, "line.2": {"text": "Aber die lustigste Kunst ist nur bei ihm nicht jokos.", "tokens": ["A\u00b7ber", "die", "lus\u00b7tigs\u00b7te", "Kunst", "ist", "nur", "bei", "ihm", "nicht", "jo\u00b7kos", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "VAFIN", "ADV", "APPR", "PPER", "PTKNEG", "NE", "$."], "meter": "+--+--++-+-+-+", "measure": "dactylic.di.plus"}}, "stanza.12": {"line.1": {"text": "Giebichensteiner, sei auch pers\u00f6nlich in deinen Satiren,", "tokens": ["Gie\u00b7bi\u00b7chen\u00b7stei\u00b7ner", ",", "sei", "auch", "per\u00b7s\u00f6n\u00b7lich", "in", "dei\u00b7nen", "Sa\u00b7ti\u00b7ren", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VAFIN", "ADV", "ADJD", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+--+--+----", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Deine leid'ge Person tritt doch am st\u00e4rksten hervor.", "tokens": ["Dei\u00b7ne", "lei\u00b7d'\u00b7ge", "Per\u00b7son", "tritt", "doch", "am", "st\u00e4rks\u00b7ten", "her\u00b7vor", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVFIN", "ADV", "APPRART", "ADJA", "PTKVZ", "$."], "meter": "+-+--+--+-+--+", "measure": "trochaic.hexa.relaxed"}}, "stanza.13": {"line.1": {"text": "Als man ihn traf, den Esel, da schlug er aus, doch das macht ihn", "tokens": ["Als", "man", "ihn", "traf", ",", "den", "E\u00b7sel", ",", "da", "schlug", "er", "aus", ",", "doch", "das", "macht", "ihn"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "PPER", "VVFIN", "$,", "ART", "NN", "$,", "ADV", "VVFIN", "PPER", "PTKVZ", "$,", "KON", "PDS", "VVFIN", "PPER"], "meter": "-+-+-+--+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Nicht zum Pferde. Nicht wird, den er auch tr\u00e4fe, ihm gleich.", "tokens": ["Nicht", "zum", "Pfer\u00b7de", ".", "Nicht", "wird", ",", "den", "er", "auch", "tr\u00e4\u00b7fe", ",", "ihm", "gleich", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PTKNEG", "APPRART", "NN", "$.", "PTKNEG", "VAFIN", "$,", "PRELS", "PPER", "ADV", "VVFIN", "$,", "PPER", "ADV", "$."], "meter": "--+--+---+--+", "measure": "anapaest.di.plus"}}, "stanza.14": {"line.1": {"text": "Freilich laufe wer nackt als ungest\u00fcmer Lupercus,", "tokens": ["Frei\u00b7lich", "lau\u00b7fe", "wer", "nackt", "als", "un\u00b7ge\u00b7st\u00fc\u00b7mer", "Lu\u00b7per\u00b7cus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PWS", "ADJD", "KOKOM", "ADJD", "NE", "$,"], "meter": "+-+--+-+-+-+-+", "measure": "trochaic.septa.relaxed"}, "line.2": {"text": "Aber mit falschem Bart prangst in der Kutte du nur.", "tokens": ["A\u00b7ber", "mit", "fal\u00b7schem", "Bart", "prangst", "in", "der", "Kut\u00b7te", "du", "nur", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ADJA", "NN", "VVFIN", "APPR", "ART", "NN", "PPER", "ADV", "$."], "meter": "+--+-+-+-+--+", "measure": "iambic.hexa.invert"}}, "stanza.15": {"line.1": {"text": "Sag mir, wo ist denn die Klicke? \u00bbDa dr\u00fcben ist sie beim Nachbar.\u00ab", "tokens": ["Sag", "mir", ",", "wo", "ist", "denn", "die", "Kli\u00b7cke", "?", "\u00bb", "Da", "dr\u00fc\u00b7ben", "ist", "sie", "beim", "Nach\u00b7bar", ".", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "PPER", "$,", "PWAV", "VAFIN", "ADV", "ART", "NN", "$.", "$(", "ADV", "ADV", "VAFIN", "PPER", "APPRART", "NN", "$.", "$("], "meter": "+--+--+--+-++-+-", "measure": "dactylic.tri.plus"}, "line.2": {"text": "Frag ich den Nachbar, er sagt, h\u00fcben sei sie bei dir.", "tokens": ["Frag", "ich", "den", "Nach\u00b7bar", ",", "er", "sagt", ",", "h\u00fc\u00b7ben", "sei", "sie", "bei", "dir", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ART", "NN", "$,", "PPER", "VVFIN", "$,", "ADJD", "VAFIN", "PPER", "APPR", "PPER", "$."], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}}, "stanza.16": {"line.1": {"text": "Einen Tyrannen zu hassen verm\u00f6gen auch knechtische Seelen,", "tokens": ["Ei\u00b7nen", "Ty\u00b7ran\u00b7nen", "zu", "has\u00b7sen", "ver\u00b7m\u00f6\u00b7gen", "auch", "knech\u00b7ti\u00b7sche", "See\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKZU", "VVINF", "VVFIN", "ADV", "ADJA", "NN", "$,"], "meter": "+--+--+--+--+--+-", "measure": "hexameter"}, "line.2": {"text": "Nur wer die Tyrannei hasset, ist edel und gro\u00df.", "tokens": ["Nur", "wer", "die", "Ty\u00b7ran\u00b7nei", "has\u00b7set", ",", "ist", "e\u00b7del", "und", "gro\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PWS", "ART", "NN", "VVFIN", "$,", "VAFIN", "ADJD", "KON", "ADJD", "$."], "meter": "-+---+-+-+--+", "measure": "iambic.penta.chol"}}}}}