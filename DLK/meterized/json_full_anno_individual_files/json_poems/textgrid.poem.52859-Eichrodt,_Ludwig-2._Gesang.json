{"textgrid.poem.52859": {"metadata": {"author": {"name": "Eichrodt, Ludwig", "birth": "N.A.", "death": "N.A."}, "title": "2. Gesang", "genre": "verse", "period": "N.A.", "pub_year": 1859, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Grad kehrte Gottvatter beim Schwanenwirth ein,", "tokens": ["Grad", "kehr\u00b7te", "Gott\u00b7vat\u00b7ter", "beim", "Schwa\u00b7nen\u00b7wirth", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "NN", "APPRART", "NN", "PTKVZ", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "Zu trinken ein Sch\u00f6pplein vern\u00fcnftigen Wein,", "tokens": ["Zu", "trin\u00b7ken", "ein", "Sch\u00f6p\u00b7plein", "ver\u00b7n\u00fcnf\u00b7ti\u00b7gen", "Wein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.3": {"text": "Wollt' restauriren den Magen,", "tokens": ["Wollt'", "res\u00b7tau\u00b7ri\u00b7ren", "den", "Ma\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "VVINF", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Darein ihm der Aerger geschlagen.", "tokens": ["Da\u00b7rein", "ihm", "der", "A\u00b7er\u00b7ger", "ge\u00b7schla\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PPER", "ART", "NN", "VVPP", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.2": {"line.1": {"text": "Ihn hatte der Schwanenwirth nie noch geseh'n", "tokens": ["Ihn", "hat\u00b7te", "der", "Schwa\u00b7nen\u00b7wirth", "nie", "noch", "ge\u00b7seh'n"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "NN", "ADV", "ADV", "VVPP"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "So wild und so zornig ins Wirthshaus 'reingehn,", "tokens": ["So", "wild", "und", "so", "zor\u00b7nig", "ins", "Wirths\u00b7haus", "'rein\u00b7gehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KON", "ADV", "ADJD", "APPRART", "NN", "NE", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.3": {"text": "Und ihm f\u00e4hrt in die Glieder der Schrecken,", "tokens": ["Und", "ihm", "f\u00e4hrt", "in", "die", "Glie\u00b7der", "der", "Schre\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "APPR", "ART", "NN", "ART", "NN", "$,"], "meter": "--+--+--+-", "measure": "anapaest.tri.plus"}, "line.4": {"text": "Als der Hergott den Grund thut entdecken.", "tokens": ["Als", "der", "Her\u00b7gott", "den", "Grund", "thut", "ent\u00b7de\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ART", "NN", "VVFIN", "VVINF", "$."], "meter": "--+--+--+-", "measure": "anapaest.tri.plus"}}, "stanza.3": {"line.1": {"text": "\"du kennst mich, ich bin ein langm\u00fcthiger Mann,", "tokens": ["\"", "du", "kennst", "mich", ",", "ich", "bin", "ein", "lang\u00b7m\u00fct\u00b7hi\u00b7ger", "Mann", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "PPER", "$,", "PPER", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Ich dr\u00fccke ein Aug zu, so lang als ich kann,", "tokens": ["Ich", "dr\u00fc\u00b7cke", "ein", "Aug", "zu", ",", "so", "lang", "als", "ich", "kann", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "PTKVZ", "$,", "ADV", "ADJD", "KOKOM", "PPER", "VMFIN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.3": {"text": "Aber ganz kann ich au\u00dfer mich kommen,", "tokens": ["A\u00b7ber", "ganz", "kann", "ich", "au\u00b7\u00dfer", "mich", "kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VMFIN", "PPER", "APPR", "PRF", "VVINF", "$,"], "meter": "+-+--+--+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Wenn Alles und gar nichts will frommen.", "tokens": ["Wenn", "Al\u00b7les", "und", "gar", "nichts", "will", "from\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "KON", "ADV", "PIS", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Fang' ich einmal zu verz\u00fcrnen mich an,", "tokens": ["Fang'", "ich", "ein\u00b7mal", "zu", "ver\u00b7z\u00fcr\u00b7nen", "mich", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "ADV", "PTKZU", "VVINF", "PPER", "PTKVZ", "$,"], "meter": "+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.2": {"text": "So wei\u00dft Du, es hindert kein Mensch mich daran,", "tokens": ["So", "wei\u00dft", "Du", ",", "es", "hin\u00b7dert", "kein", "Mensch", "mich", "da\u00b7ran", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "PPER", "VVFIN", "PIAT", "NN", "PRF", "PAV", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.3": {"text": "Und in meiner verlorenen Ruhe", "tokens": ["Und", "in", "mei\u00b7ner", "ver\u00b7lo\u00b7re\u00b7nen", "Ru\u00b7he"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "--+--+--+-", "measure": "anapaest.tri.plus"}, "line.4": {"text": "Wei\u00df ich selber nicht mehr, was ich thue.", "tokens": ["Wei\u00df", "ich", "sel\u00b7ber", "nicht", "mehr", ",", "was", "ich", "thue", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "PTKNEG", "ADV", "$,", "PWS", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.5": {"line.1": {"text": "Da komm' ich heut Mittag, die Zeit wei\u00df ich nicht,", "tokens": ["Da", "komm'", "ich", "heut", "Mit\u00b7tag", ",", "die", "Zeit", "wei\u00df", "ich", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "NN", "$,", "ART", "NN", "VVFIN", "PPER", "PTKNEG", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Ich hatte gerad an der Sonn' was gericht',", "tokens": ["Ich", "hat\u00b7te", "ge\u00b7rad", "an", "der", "Sonn'", "was", "ge\u00b7richt'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "APPR", "ART", "NN", "PWS", "VVPP", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.3": {"text": "Vom Sinai runter nach Theben -", "tokens": ["Vom", "Si\u00b7nai", "run\u00b7ter", "nach", "The\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "ADJD", "APPR", "NE", "$("], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Die f\u00fchren ein l\u00e4sterlich Leben.", "tokens": ["Die", "f\u00fch\u00b7ren", "ein", "l\u00e4s\u00b7ter\u00b7lich", "Le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ART", "ADJD", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.6": {"line.1": {"text": "Da sitzen sie \u00fcber bei W\u00fcrfel und Spiel,", "tokens": ["Da", "sit\u00b7zen", "sie", "\u00fc\u00b7ber", "bei", "W\u00fcr\u00b7fel", "und", "Spiel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "Polizeistund' die kennen sie gar nicht am Nil,", "tokens": ["Po\u00b7li\u00b7zei\u00b7stund'", "die", "ken\u00b7nen", "sie", "gar", "nicht", "am", "Nil", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "VVFIN", "PPER", "ADV", "PTKNEG", "APPRART", "NN", "$,"], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.3": {"text": "Sie saufen und fressen wie Thiere", "tokens": ["Sie", "sau\u00b7fen", "und", "fres\u00b7sen", "wie", "Thie\u00b7re"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "KOKOM", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Und strecken von ", "tokens": ["Und", "stre\u00b7cken", "von"], "token_info": ["word", "word", "word"], "pos": ["KON", "VVFIN", "APPR"], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.7": {"line.1": {"text": "Wenn so was am heiligen Sonntag geschieht,", "tokens": ["Wenn", "so", "was", "am", "hei\u00b7li\u00b7gen", "Sonn\u00b7tag", "ge\u00b7schieht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PRELS", "APPRART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "Zum Kukuk das geht \u00fcber's Bohnenlied,", "tokens": ["Zum", "Ku\u00b7kuk", "das", "geht", "\u00fc\u00b7ber's", "Boh\u00b7nen\u00b7lied", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PDS", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Besonders die f\u00fcrnehmen Kasten", "tokens": ["Be\u00b7son\u00b7ders", "die", "f\u00fcr\u00b7neh\u00b7men", "Kas\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wo thun sie noch beichten und fasten?", "tokens": ["Wo", "thun", "sie", "noch", "beich\u00b7ten", "und", "fas\u00b7ten", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "ADV", "VVINF", "KON", "VVFIN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.8": {"line.1": {"text": "Wenn Einer einmal sich so recht \u00fcbernimmt,", "tokens": ["Wenn", "Ei\u00b7ner", "ein\u00b7mal", "sich", "so", "recht", "\u00fc\u00b7ber\u00b7nimmt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ADV", "PRF", "ADV", "ADJD", "VVPP", "$,"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Da will ich nichts sagen, doch hat mich's verstimmt,", "tokens": ["Da", "will", "ich", "nichts", "sa\u00b7gen", ",", "doch", "hat", "mich's", "ver\u00b7stimmt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PIS", "VVINF", "$,", "ADV", "VAFIN", "PIS", "VVFIN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.3": {"text": "Da\u00df sie in Neujahrstag 'nein tanzen,", "tokens": ["Da\u00df", "sie", "in", "Neu\u00b7jahr\u00b7stag", "'n\u00b7ein", "tan\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NN", "NN", "VVINF", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Und schelten auf's Pfarrer's sein' Ranzen.", "tokens": ["Und", "schel\u00b7ten", "auf's", "Pfar\u00b7rer's", "sein'", "Ran\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPRART", "NN", "PPOSAT", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.9": {"line.1": {"text": "Das Sch\u00e4ndlichste aber das stellst Dir nicht vor,", "tokens": ["Das", "Sch\u00e4nd\u00b7lichs\u00b7te", "a\u00b7ber", "das", "stellst", "Dir", "nicht", "vor", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "PDS", "VVFIN", "PPER", "PTKNEG", "PTKVZ", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Da komm' ich vor's Memphisser Br\u00fcckenthor,", "tokens": ["Da", "komm'", "ich", "vor's", "Mem\u00b7phis\u00b7ser", "Br\u00fc\u00b7cken\u00b7thor", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Da machen die Heiden, Panduren,", "tokens": ["Da", "ma\u00b7chen", "die", "Hei\u00b7den", ",", "Pan\u00b7du\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$,", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Gott straf mich, auf mich Carrkaturen!", "tokens": ["Gott", "straf", "mich", ",", "auf", "mich", "Carr\u00b7ka\u00b7tu\u00b7ren", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "$,", "APPR", "PPER", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Da stellten sie hin einen Ochsen, ein Viech,", "tokens": ["Da", "stell\u00b7ten", "sie", "hin", "ei\u00b7nen", "Och\u00b7sen", ",", "ein", "Viech", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ART", "NN", "$,", "ART", "NN", "$,"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.2": {"text": "Und sagen: der Ochs, der Ochs, das w\u00e4r Ich!", "tokens": ["Und", "sa\u00b7gen", ":", "der", "Ochs", ",", "der", "Ochs", ",", "das", "w\u00e4r", "Ich", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVINF", "$.", "ART", "NN", "$,", "ART", "NN", "$,", "PDS", "VAFIN", "PPER", "$."], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Ein Ochs vor s\u00e4mmtlichen Leuten", "tokens": ["Ein", "Ochs", "vor", "s\u00e4mmt\u00b7li\u00b7chen", "Leu\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "PIAT", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Soll mich, den Hergott, bedeuten.", "tokens": ["Soll", "mich", ",", "den", "Her\u00b7gott", ",", "be\u00b7deu\u00b7ten", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["VMFIN", "PPER", "$,", "ART", "NN", "$,", "VVINF", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}}, "stanza.11": {"line.1": {"text": "Und weiter, der Unfug geht \u00fcber den Spott,", "tokens": ["Und", "wei\u00b7ter", ",", "der", "Un\u00b7fug", "geht", "\u00fc\u00b7ber", "den", "Spott", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$,", "ART", "NN", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "Da malen sie mich, o du lieber Gott -", "tokens": ["Da", "ma\u00b7len", "sie", "mich", ",", "o", "du", "lie\u00b7ber", "Gott"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "$,", "FM", "PPER", "ADV", "NN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Als Kranich mit krummen Beinen,", "tokens": ["Als", "Kra\u00b7nich", "mit", "krum\u00b7men", "Bei\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Vor Zorn m\u00f6cht ich Blutigel weinen!\"", "tokens": ["Vor", "Zorn", "m\u00f6cht", "ich", "Blu\u00b7ti\u00b7gel", "wei\u00b7nen", "!", "\""], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "NN", "VMFIN", "PPER", "NN", "VVINF", "$.", "$("], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.12": {"line.1": {"text": "Grad kehrte Gottvatter beim Schwanenwirth ein,", "tokens": ["Grad", "kehr\u00b7te", "Gott\u00b7vat\u00b7ter", "beim", "Schwa\u00b7nen\u00b7wirth", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "NN", "APPRART", "NN", "PTKVZ", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "Zu trinken ein Sch\u00f6pplein vern\u00fcnftigen Wein,", "tokens": ["Zu", "trin\u00b7ken", "ein", "Sch\u00f6p\u00b7plein", "ver\u00b7n\u00fcnf\u00b7ti\u00b7gen", "Wein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.3": {"text": "Wollt' restauriren den Magen,", "tokens": ["Wollt'", "res\u00b7tau\u00b7ri\u00b7ren", "den", "Ma\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "VVINF", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Darein ihm der Aerger geschlagen.", "tokens": ["Da\u00b7rein", "ihm", "der", "A\u00b7er\u00b7ger", "ge\u00b7schla\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PPER", "ART", "NN", "VVPP", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.13": {"line.1": {"text": "Ihn hatte der Schwanenwirth nie noch geseh'n", "tokens": ["Ihn", "hat\u00b7te", "der", "Schwa\u00b7nen\u00b7wirth", "nie", "noch", "ge\u00b7seh'n"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "NN", "ADV", "ADV", "VVPP"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "So wild und so zornig ins Wirthshaus 'reingehn,", "tokens": ["So", "wild", "und", "so", "zor\u00b7nig", "ins", "Wirths\u00b7haus", "'rein\u00b7gehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KON", "ADV", "ADJD", "APPRART", "NN", "NE", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.3": {"text": "Und ihm f\u00e4hrt in die Glieder der Schrecken,", "tokens": ["Und", "ihm", "f\u00e4hrt", "in", "die", "Glie\u00b7der", "der", "Schre\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "APPR", "ART", "NN", "ART", "NN", "$,"], "meter": "--+--+--+-", "measure": "anapaest.tri.plus"}, "line.4": {"text": "Als der Hergott den Grund thut entdecken.", "tokens": ["Als", "der", "Her\u00b7gott", "den", "Grund", "thut", "ent\u00b7de\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ART", "NN", "VVFIN", "VVINF", "$."], "meter": "--+--+--+-", "measure": "anapaest.tri.plus"}}, "stanza.14": {"line.1": {"text": "\"du kennst mich, ich bin ein langm\u00fcthiger Mann,", "tokens": ["\"", "du", "kennst", "mich", ",", "ich", "bin", "ein", "lang\u00b7m\u00fct\u00b7hi\u00b7ger", "Mann", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "PPER", "$,", "PPER", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Ich dr\u00fccke ein Aug zu, so lang als ich kann,", "tokens": ["Ich", "dr\u00fc\u00b7cke", "ein", "Aug", "zu", ",", "so", "lang", "als", "ich", "kann", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "PTKVZ", "$,", "ADV", "ADJD", "KOKOM", "PPER", "VMFIN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.3": {"text": "Aber ganz kann ich au\u00dfer mich kommen,", "tokens": ["A\u00b7ber", "ganz", "kann", "ich", "au\u00b7\u00dfer", "mich", "kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VMFIN", "PPER", "APPR", "PRF", "VVINF", "$,"], "meter": "+-+--+--+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Wenn Alles und gar nichts will frommen.", "tokens": ["Wenn", "Al\u00b7les", "und", "gar", "nichts", "will", "from\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "KON", "ADV", "PIS", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "Fang' ich einmal zu verz\u00fcrnen mich an,", "tokens": ["Fang'", "ich", "ein\u00b7mal", "zu", "ver\u00b7z\u00fcr\u00b7nen", "mich", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "ADV", "PTKZU", "VVINF", "PPER", "PTKVZ", "$,"], "meter": "+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.2": {"text": "So wei\u00dft Du, es hindert kein Mensch mich daran,", "tokens": ["So", "wei\u00dft", "Du", ",", "es", "hin\u00b7dert", "kein", "Mensch", "mich", "da\u00b7ran", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "PPER", "VVFIN", "PIAT", "NN", "PRF", "PAV", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.3": {"text": "Und in meiner verlorenen Ruhe", "tokens": ["Und", "in", "mei\u00b7ner", "ver\u00b7lo\u00b7re\u00b7nen", "Ru\u00b7he"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "--+--+--+-", "measure": "anapaest.tri.plus"}, "line.4": {"text": "Wei\u00df ich selber nicht mehr, was ich thue.", "tokens": ["Wei\u00df", "ich", "sel\u00b7ber", "nicht", "mehr", ",", "was", "ich", "thue", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "PTKNEG", "ADV", "$,", "PWS", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.16": {"line.1": {"text": "Da komm' ich heut Mittag, die Zeit wei\u00df ich nicht,", "tokens": ["Da", "komm'", "ich", "heut", "Mit\u00b7tag", ",", "die", "Zeit", "wei\u00df", "ich", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "NN", "$,", "ART", "NN", "VVFIN", "PPER", "PTKNEG", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Ich hatte gerad an der Sonn' was gericht',", "tokens": ["Ich", "hat\u00b7te", "ge\u00b7rad", "an", "der", "Sonn'", "was", "ge\u00b7richt'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "APPR", "ART", "NN", "PWS", "VVPP", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.3": {"text": "Vom Sinai runter nach Theben -", "tokens": ["Vom", "Si\u00b7nai", "run\u00b7ter", "nach", "The\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "ADJD", "APPR", "NE", "$("], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Die f\u00fchren ein l\u00e4sterlich Leben.", "tokens": ["Die", "f\u00fch\u00b7ren", "ein", "l\u00e4s\u00b7ter\u00b7lich", "Le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ART", "ADJD", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.17": {"line.1": {"text": "Da sitzen sie \u00fcber bei W\u00fcrfel und Spiel,", "tokens": ["Da", "sit\u00b7zen", "sie", "\u00fc\u00b7ber", "bei", "W\u00fcr\u00b7fel", "und", "Spiel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "Polizeistund' die kennen sie gar nicht am Nil,", "tokens": ["Po\u00b7li\u00b7zei\u00b7stund'", "die", "ken\u00b7nen", "sie", "gar", "nicht", "am", "Nil", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "VVFIN", "PPER", "ADV", "PTKNEG", "APPRART", "NN", "$,"], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.3": {"text": "Sie saufen und fressen wie Thiere", "tokens": ["Sie", "sau\u00b7fen", "und", "fres\u00b7sen", "wie", "Thie\u00b7re"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "KOKOM", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Und strecken von ", "tokens": ["Und", "stre\u00b7cken", "von"], "token_info": ["word", "word", "word"], "pos": ["KON", "VVFIN", "APPR"], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.18": {"line.1": {"text": "Wenn so was am heiligen Sonntag geschieht,", "tokens": ["Wenn", "so", "was", "am", "hei\u00b7li\u00b7gen", "Sonn\u00b7tag", "ge\u00b7schieht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PRELS", "APPRART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "Zum Kukuk das geht \u00fcber's Bohnenlied,", "tokens": ["Zum", "Ku\u00b7kuk", "das", "geht", "\u00fc\u00b7ber's", "Boh\u00b7nen\u00b7lied", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PDS", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Besonders die f\u00fcrnehmen Kasten", "tokens": ["Be\u00b7son\u00b7ders", "die", "f\u00fcr\u00b7neh\u00b7men", "Kas\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wo thun sie noch beichten und fasten?", "tokens": ["Wo", "thun", "sie", "noch", "beich\u00b7ten", "und", "fas\u00b7ten", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "ADV", "VVINF", "KON", "VVFIN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.19": {"line.1": {"text": "Wenn Einer einmal sich so recht \u00fcbernimmt,", "tokens": ["Wenn", "Ei\u00b7ner", "ein\u00b7mal", "sich", "so", "recht", "\u00fc\u00b7ber\u00b7nimmt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ADV", "PRF", "ADV", "ADJD", "VVPP", "$,"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Da will ich nichts sagen, doch hat mich's verstimmt,", "tokens": ["Da", "will", "ich", "nichts", "sa\u00b7gen", ",", "doch", "hat", "mich's", "ver\u00b7stimmt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PIS", "VVINF", "$,", "ADV", "VAFIN", "PIS", "VVFIN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.3": {"text": "Da\u00df sie in Neujahrstag 'nein tanzen,", "tokens": ["Da\u00df", "sie", "in", "Neu\u00b7jahr\u00b7stag", "'n\u00b7ein", "tan\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NN", "NN", "VVINF", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Und schelten auf's Pfarrer's sein' Ranzen.", "tokens": ["Und", "schel\u00b7ten", "auf's", "Pfar\u00b7rer's", "sein'", "Ran\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPRART", "NN", "PPOSAT", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.20": {"line.1": {"text": "Das Sch\u00e4ndlichste aber das stellst Dir nicht vor,", "tokens": ["Das", "Sch\u00e4nd\u00b7lichs\u00b7te", "a\u00b7ber", "das", "stellst", "Dir", "nicht", "vor", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "PDS", "VVFIN", "PPER", "PTKNEG", "PTKVZ", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Da komm' ich vor's Memphisser Br\u00fcckenthor,", "tokens": ["Da", "komm'", "ich", "vor's", "Mem\u00b7phis\u00b7ser", "Br\u00fc\u00b7cken\u00b7thor", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Da machen die Heiden, Panduren,", "tokens": ["Da", "ma\u00b7chen", "die", "Hei\u00b7den", ",", "Pan\u00b7du\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$,", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Gott straf mich, auf mich Carrkaturen!", "tokens": ["Gott", "straf", "mich", ",", "auf", "mich", "Carr\u00b7ka\u00b7tu\u00b7ren", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "$,", "APPR", "PPER", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.21": {"line.1": {"text": "Da stellten sie hin einen Ochsen, ein Viech,", "tokens": ["Da", "stell\u00b7ten", "sie", "hin", "ei\u00b7nen", "Och\u00b7sen", ",", "ein", "Viech", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ART", "NN", "$,", "ART", "NN", "$,"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.2": {"text": "Und sagen: der Ochs, der Ochs, das w\u00e4r Ich!", "tokens": ["Und", "sa\u00b7gen", ":", "der", "Ochs", ",", "der", "Ochs", ",", "das", "w\u00e4r", "Ich", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVINF", "$.", "ART", "NN", "$,", "ART", "NN", "$,", "PDS", "VAFIN", "PPER", "$."], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Ein Ochs vor s\u00e4mmtlichen Leuten", "tokens": ["Ein", "Ochs", "vor", "s\u00e4mmt\u00b7li\u00b7chen", "Leu\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "PIAT", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Soll mich, den Hergott, bedeuten.", "tokens": ["Soll", "mich", ",", "den", "Her\u00b7gott", ",", "be\u00b7deu\u00b7ten", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["VMFIN", "PPER", "$,", "ART", "NN", "$,", "VVINF", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}}, "stanza.22": {"line.1": {"text": "Und weiter, der Unfug geht \u00fcber den Spott,", "tokens": ["Und", "wei\u00b7ter", ",", "der", "Un\u00b7fug", "geht", "\u00fc\u00b7ber", "den", "Spott", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$,", "ART", "NN", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "Da malen sie mich, o du lieber Gott -", "tokens": ["Da", "ma\u00b7len", "sie", "mich", ",", "o", "du", "lie\u00b7ber", "Gott"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "$,", "FM", "PPER", "ADV", "NN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Als Kranich mit krummen Beinen,", "tokens": ["Als", "Kra\u00b7nich", "mit", "krum\u00b7men", "Bei\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Vor Zorn m\u00f6cht ich Blutigel weinen!\"", "tokens": ["Vor", "Zorn", "m\u00f6cht", "ich", "Blu\u00b7ti\u00b7gel", "wei\u00b7nen", "!", "\""], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "NN", "VMFIN", "PPER", "NN", "VVINF", "$.", "$("], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}}}}