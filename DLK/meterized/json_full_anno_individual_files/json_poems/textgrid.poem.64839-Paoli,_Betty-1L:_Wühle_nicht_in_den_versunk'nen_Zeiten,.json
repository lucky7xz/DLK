{"textgrid.poem.64839": {"metadata": {"author": {"name": "Paoli, Betty", "birth": "N.A.", "death": "N.A."}, "title": "1L: W\u00fchle nicht in den versunk'nen Zeiten,", "genre": "verse", "period": "N.A.", "pub_year": 1854, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "W\u00fchle nicht in den versunk'nen Zeiten,", "tokens": ["W\u00fch\u00b7le", "nicht", "in", "den", "ver\u00b7sunk'\u00b7nen", "Zei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "La\u00df Vergessen schirmend niedergleiten", "tokens": ["La\u00df", "Ver\u00b7ges\u00b7sen", "schir\u00b7mend", "nie\u00b7derg\u00b7lei\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["VVIMP", "NN", "ADJD", "VVINF"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Auf die Gr\u00e4ber der Vergangenheiten.", "tokens": ["Auf", "die", "Gr\u00e4\u00b7ber", "der", "Ver\u00b7gan\u00b7gen\u00b7hei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.2": {"line.1": {"text": "Wohl bed\u00fcrfen sie der dunkeln Decke,", "tokens": ["Wohl", "be\u00b7d\u00fcr\u00b7fen", "sie", "der", "dun\u00b7keln", "De\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Da\u00df ihr Anblick nicht dein Auge schrecke,", "tokens": ["Da\u00df", "ihr", "An\u00b7blick", "nicht", "dein", "Au\u00b7ge", "schre\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "PTKNEG", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "B\u00f6se Ahnung nicht in dir erwecke.", "tokens": ["B\u00f6\u00b7se", "Ah\u00b7nung", "nicht", "in", "dir", "er\u00b7we\u00b7cke", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "PTKNEG", "APPR", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.3": {"line.1": {"text": "H\u00e4lt mein Arm dich fest und lind umschlossen,", "tokens": ["H\u00e4lt", "mein", "Arm", "dich", "fest", "und", "lind", "um\u00b7schlos\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "PPER", "PTKVZ", "KON", "ADJD", "VVINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "O so frag nicht, also ernstumflossen,", "tokens": ["O", "so", "frag", "nicht", ",", "al\u00b7so", "erns\u00b7tum\u00b7flos\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "ADV", "VVFIN", "PTKNEG", "$,", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Welchem Grund mein Lieben sei entsprossen.", "tokens": ["Wel\u00b7chem", "Grund", "mein", "Lie\u00b7ben", "sei", "ent\u00b7spros\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAT", "NN", "PPOSAT", "ADJA", "VAFIN", "VVPP", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.4": {"line.1": {"text": "Wissen Blumen, wissen s\u00fc\u00dfe Reben", "tokens": ["Wis\u00b7sen", "Blu\u00b7men", ",", "wis\u00b7sen", "s\u00fc\u00b7\u00dfe", "Re\u00b7ben"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ADJA", "NN", "$,", "VVFIN", "ADJA", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Wohl die Theilchen Staubes anzugeben,", "tokens": ["Wohl", "die", "Theil\u00b7chen", "Stau\u00b7bes", "an\u00b7zu\u00b7ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "VVIZU", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Draus entsprang ihr farbig, w\u00fcrzig Leben?", "tokens": ["Draus", "ent\u00b7sprang", "ihr", "far\u00b7big", ",", "w\u00fcr\u00b7zig", "Le\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "ADJD", "$,", "ADJD", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.5": {"line.1": {"text": "Sind sie minder duft- und gluthdurchflossen,", "tokens": ["Sind", "sie", "min\u00b7der", "duft", "und", "gluth\u00b7durch\u00b7flos\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "TRUNC", "KON", "VVFIN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Ob im Garten sie bei den Genossen,", "tokens": ["Ob", "im", "Gar\u00b7ten", "sie", "bei", "den", "Ge\u00b7nos\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPRART", "NN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "--+--+--+-", "measure": "anapaest.tri.plus"}, "line.3": {"text": "Oder auf dem Hochgericht entsprossen?", "tokens": ["O\u00b7der", "auf", "dem", "Hoch\u00b7ge\u00b7richt", "ent\u00b7spros\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.6": {"line.1": {"text": "Was ein Selbst, verdient als Selbst Beachtung,", "tokens": ["Was", "ein", "Selbst", ",", "ver\u00b7dient", "als", "Selbst", "Be\u00b7ach\u00b7tung", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "NN", "$,", "VVFIN", "KOKOM", "ADV", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Nur dem Sein, nicht des Entsteh'ns Umnachtung", "tokens": ["Nur", "dem", "Sein", ",", "nicht", "des", "Ent\u00b7steh'ns", "Um\u00b7nach\u00b7tung"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "$,", "PTKNEG", "ART", "NN", "NN"], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}, "line.3": {"text": "Wende zu die forschende Betrachtung.", "tokens": ["Wen\u00b7de", "zu", "die", "for\u00b7schen\u00b7de", "Be\u00b7trach\u00b7tung", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+---+-", "measure": "unknown.measure.tetra"}}, "stanza.7": {"line.1": {"text": "W\u00fchle nicht in den versunk'nen Zeiten,", "tokens": ["W\u00fch\u00b7le", "nicht", "in", "den", "ver\u00b7sunk'\u00b7nen", "Zei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "La\u00df Vergessen schirmend niedergleiten", "tokens": ["La\u00df", "Ver\u00b7ges\u00b7sen", "schir\u00b7mend", "nie\u00b7derg\u00b7lei\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["VVIMP", "NN", "ADJD", "VVINF"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Auf die Gr\u00e4ber der Vergangenheiten.", "tokens": ["Auf", "die", "Gr\u00e4\u00b7ber", "der", "Ver\u00b7gan\u00b7gen\u00b7hei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.8": {"line.1": {"text": "Wohl bed\u00fcrfen sie der dunkeln Decke,", "tokens": ["Wohl", "be\u00b7d\u00fcr\u00b7fen", "sie", "der", "dun\u00b7keln", "De\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Da\u00df ihr Anblick nicht dein Auge schrecke,", "tokens": ["Da\u00df", "ihr", "An\u00b7blick", "nicht", "dein", "Au\u00b7ge", "schre\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "PTKNEG", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "B\u00f6se Ahnung nicht in dir erwecke.", "tokens": ["B\u00f6\u00b7se", "Ah\u00b7nung", "nicht", "in", "dir", "er\u00b7we\u00b7cke", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "PTKNEG", "APPR", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.9": {"line.1": {"text": "H\u00e4lt mein Arm dich fest und lind umschlossen,", "tokens": ["H\u00e4lt", "mein", "Arm", "dich", "fest", "und", "lind", "um\u00b7schlos\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "PPER", "PTKVZ", "KON", "ADJD", "VVINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "O so frag nicht, also ernstumflossen,", "tokens": ["O", "so", "frag", "nicht", ",", "al\u00b7so", "erns\u00b7tum\u00b7flos\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "ADV", "VVFIN", "PTKNEG", "$,", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Welchem Grund mein Lieben sei entsprossen.", "tokens": ["Wel\u00b7chem", "Grund", "mein", "Lie\u00b7ben", "sei", "ent\u00b7spros\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAT", "NN", "PPOSAT", "ADJA", "VAFIN", "VVPP", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.10": {"line.1": {"text": "Wissen Blumen, wissen s\u00fc\u00dfe Reben", "tokens": ["Wis\u00b7sen", "Blu\u00b7men", ",", "wis\u00b7sen", "s\u00fc\u00b7\u00dfe", "Re\u00b7ben"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ADJA", "NN", "$,", "VVFIN", "ADJA", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Wohl die Theilchen Staubes anzugeben,", "tokens": ["Wohl", "die", "Theil\u00b7chen", "Stau\u00b7bes", "an\u00b7zu\u00b7ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "VVIZU", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Draus entsprang ihr farbig, w\u00fcrzig Leben?", "tokens": ["Draus", "ent\u00b7sprang", "ihr", "far\u00b7big", ",", "w\u00fcr\u00b7zig", "Le\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "ADJD", "$,", "ADJD", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.11": {"line.1": {"text": "Sind sie minder duft- und gluthdurchflossen,", "tokens": ["Sind", "sie", "min\u00b7der", "duft", "und", "gluth\u00b7durch\u00b7flos\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "TRUNC", "KON", "VVFIN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Ob im Garten sie bei den Genossen,", "tokens": ["Ob", "im", "Gar\u00b7ten", "sie", "bei", "den", "Ge\u00b7nos\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPRART", "NN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "--+--+--+-", "measure": "anapaest.tri.plus"}, "line.3": {"text": "Oder auf dem Hochgericht entsprossen?", "tokens": ["O\u00b7der", "auf", "dem", "Hoch\u00b7ge\u00b7richt", "ent\u00b7spros\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.12": {"line.1": {"text": "Was ein Selbst, verdient als Selbst Beachtung,", "tokens": ["Was", "ein", "Selbst", ",", "ver\u00b7dient", "als", "Selbst", "Be\u00b7ach\u00b7tung", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "NN", "$,", "VVFIN", "KOKOM", "ADV", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Nur dem Sein, nicht des Entsteh'ns Umnachtung", "tokens": ["Nur", "dem", "Sein", ",", "nicht", "des", "Ent\u00b7steh'ns", "Um\u00b7nach\u00b7tung"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "$,", "PTKNEG", "ART", "NN", "NN"], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}, "line.3": {"text": "Wende zu die forschende Betrachtung.", "tokens": ["Wen\u00b7de", "zu", "die", "for\u00b7schen\u00b7de", "Be\u00b7trach\u00b7tung", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+---+-", "measure": "unknown.measure.tetra"}}}}}