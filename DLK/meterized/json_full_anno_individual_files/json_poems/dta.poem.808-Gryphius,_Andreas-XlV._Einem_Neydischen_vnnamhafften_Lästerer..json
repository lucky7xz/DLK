{"dta.poem.808": {"metadata": {"author": {"name": "Gryphius, Andreas", "birth": "N.A.", "death": "N.A."}, "title": "XlV.  \n Einem Neydischen vnnamhafften L\u00e4sterer.", "genre": "Lyrik, Drama", "period": "N.A.", "pub_year": "1650", "urn": "urn:nbn:de:kobv:b4-20218-7", "language": ["de:0.99"], "booktitle": "Gryphius, Andreas: Teutsche Reim-Gedichte. Frankfurt (Main), 1650."}, "poem": {"stanza.1": {"line.1": {"text": "Schmeh' jm\u0303er weil du kanst/ halt nichts als dich/ f\u00fcr gutt/ ", "tokens": ["Schmeh'", "jm\u0303er", "weil", "du", "kanst", "/", "halt", "nichts", "als", "dich", "/", "f\u00fcr", "gutt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "ADV", "KOUS", "PPER", "VMFIN", "$(", "VVFIN", "PIS", "KOKOM", "PPER", "$(", "APPR", "ADJD", "$("], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.2": {"text": "Vnd bleib nur/ wer du bist! Man wird nach dir nicht", "tokens": ["Vnd", "bleib", "nur", "/", "wer", "du", "bist", "!", "Man", "wird", "nach", "dir", "nicht"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "$(", "PWS", "PPER", "VAFIN", "$.", "PIS", "VAFIN", "APPR", "PPER", "PTKNEG"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "fragen/ ", "tokens": ["fra\u00b7gen", "/"], "token_info": ["word", "punct"], "pos": ["VVINF", "$("], "meter": "+-", "measure": "trochaic.single"}, "line.4": {"text": "Von dem kein Mann erf\u00fchr/ ob dich die welt getragen/", "tokens": ["Von", "dem", "kein", "Mann", "er\u00b7f\u00fchr", "/", "ob", "dich", "die", "welt", "ge\u00b7tra\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "PIAT", "NN", "VVFIN", "$(", "KOUS", "PPER", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Es k\u00fcmmert sich vmb vieh kein hochgesinnter mutt.", "tokens": ["Es", "k\u00fcm\u00b7mert", "sich", "vmb", "vieh", "kein", "hoch\u00b7ge\u00b7sinn\u00b7ter", "mutt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "ADV", "PIAT", "ADJA", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Ein vnerschrocken Hertz das jhm durch Flei\u00df vnd Blutt", "tokens": ["Ein", "vner\u00b7schro\u00b7cken", "Hertz", "das", "jhm", "durch", "Flei\u00df", "vnd", "Blutt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "ART", "PPER", "APPR", "NN", "KON", "NN"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.2": {"text": "Die Ewigkeit verm\u00e4hlt/ das m\u00e4chtig sich zu wagen", "tokens": ["Die", "E\u00b7wig\u00b7keit", "ver\u00b7m\u00e4hlt", "/", "das", "m\u00e4ch\u00b7tig", "sich", "zu", "wa\u00b7gen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVPP", "$(", "ART", "ADJD", "PRF", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wohin kein vnmensch denckt/ sch\u00e4tzt/ was vn\u00df meynt zu nag\u1ebd", "tokens": ["Wo\u00b7hin", "kein", "vn\u00b7mensch", "denckt", "/", "sch\u00e4tzt", "/", "was", "vn\u00df", "meynt", "zu", "nag\u1ebd"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PIAT", "ADJD", "VVFIN", "$(", "VVFIN", "$(", "PWS", "PPER", "VVFIN", "APPR", "NE"], "meter": "--+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Auch nicht de\u00df Anblicks werth! Neyd ist sein eigne Rutt.", "tokens": ["Auch", "nicht", "de\u00df", "An\u00b7blicks", "werth", "!", "Neyd", "ist", "sein", "eig\u00b7ne", "Rutt", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKNEG", "ART", "NN", "ADJD", "$.", "NN", "VAFIN", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}}, "stanza.3": {"line.1": {"text": "Der Hund b\u00e4llt nur vmbsonst de\u00df Mondens Fackel an/", "tokens": ["Der", "Hund", "b\u00e4llt", "nur", "vmbsonst", "de\u00df", "Mon\u00b7dens", "Fa\u00b7ckel", "an", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "ADV", "ART", "NN", "NN", "PTKVZ", "$("], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Ein rasend tolles Haupt/ das nichs denn w\u00fctten kan", "tokens": ["Ein", "ra\u00b7send", "tol\u00b7les", "Haupt", "/", "das", "nichs", "denn", "w\u00fct\u00b7ten", "kan"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJD", "ADJA", "NN", "$(", "ART", "PIS", "ADV", "VVINF", "VMFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Pflegt/ wer vernunfft noch hat/ mitleidend anzuschawen/", "tokens": ["Pflegt", "/", "wer", "ver\u00b7nunfft", "noch", "hat", "/", "mit\u00b7lei\u00b7dend", "an\u00b7zu\u00b7scha\u00b7wen", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVIMP", "$(", "PWS", "VVFIN", "ADV", "VAFIN", "$(", "VVPP", "VVIZU", "$("], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}}, "stanza.4": {"line.1": {"text": "Ach! k\u00f6ntest du dich nur/ du vnmensch recht besehn", "tokens": ["Ach", "!", "k\u00f6n\u00b7test", "du", "dich", "nur", "/", "du", "vn\u00b7mensch", "recht", "be\u00b7sehn"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ITJ", "$.", "VMFIN", "PPER", "PRF", "ADV", "$(", "PPER", "ADJD", "ADJD", "VVINF"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Vnd was du thust verstehn/ v\u00f1 wehn du pflegst zu schmehn.", "tokens": ["Vnd", "was", "du", "thust", "ver\u00b7stehn", "/", "v\u00f1", "wehn", "du", "pflegst", "zu", "schmehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "VVFIN", "VVINF", "$(", "NE", "VVFIN", "PPER", "VVFIN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Dir w\u00fcrde vor dir selbst bi\u00df auff das brechen grawen.", "tokens": ["Dir", "w\u00fcr\u00b7de", "vor", "dir", "selbst", "bi\u00df", "auff", "das", "bre\u00b7chen", "gra\u00b7wen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "PPER", "ADV", "ADV", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}}}}}