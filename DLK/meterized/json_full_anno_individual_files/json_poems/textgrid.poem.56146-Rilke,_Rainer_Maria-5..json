{"textgrid.poem.56146": {"metadata": {"author": {"name": "Rilke, Rainer Maria", "birth": "N.A.", "death": "N.A."}, "title": "5.", "genre": "verse", "period": "N.A.", "pub_year": 1900, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Blumenmuskel, der der Anemone", "tokens": ["Blu\u00b7men\u00b7mus\u00b7kel", ",", "der", "der", "A\u00b7ne\u00b7mo\u00b7ne"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "PRELS", "ART", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Wiesenmorgen nach und nach erschlie\u00dft,", "tokens": ["Wie\u00b7sen\u00b7mor\u00b7gen", "nach", "und", "nach", "er\u00b7schlie\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "KON", "APPR", "VVFIN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "bis in ihren Schoo\u00df das polyphone", "tokens": ["bis", "in", "ih\u00b7ren", "Schoo\u00df", "das", "po\u00b7ly\u00b7pho\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "PPOSAT", "NN", "ART", "ADJA"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "Licht der lauten Himmel sich ergie\u00dft,", "tokens": ["Licht", "der", "lau\u00b7ten", "Him\u00b7mel", "sich", "er\u00b7gie\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "PRF", "VVFIN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.2": {"line.1": {"text": "in den stillen Bl\u00fctenstern gespannter", "tokens": ["in", "den", "stil\u00b7len", "Bl\u00fc\u00b7tens\u00b7tern", "ge\u00b7spann\u00b7ter"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "ADJA"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Muskel des unendlichen Empfangs,", "tokens": ["Mus\u00b7kel", "des", "un\u00b7end\u00b7li\u00b7chen", "Emp\u00b7fangs", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "manchmal so von F\u00fclle \u00fcbermannter,", "tokens": ["manch\u00b7mal", "so", "von", "F\u00fcl\u00b7le", "\u00fc\u00b7berm\u00b7ann\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "NN", "ADJD", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "da\u00df der Ruhewink des Untergangs", "tokens": ["da\u00df", "der", "Ru\u00b7he\u00b7wink", "des", "Un\u00b7ter\u00b7gangs"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "ART", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.3": {"line.1": {"text": "kaum vermag die weitzur\u00fcckgeschnellten", "tokens": ["kaum", "ver\u00b7mag", "die", "weit\u00b7zu\u00b7r\u00fcck\u00b7ge\u00b7schnell\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "ADJA"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Blatterr\u00e4nder dir zur\u00fcckzugeben:", "tokens": ["Blat\u00b7ter\u00b7r\u00e4n\u00b7der", "dir", "zu\u00b7r\u00fcck\u00b7zu\u00b7ge\u00b7ben", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PPER", "VVIZU", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "du, Entschlu\u00df und Kraft von ", "tokens": ["du", ",", "Ent\u00b7schlu\u00df", "und", "Kraft", "von"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "$,", "NN", "KON", "NN", "APPR"], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.4": {"line.1": {"text": "Wir, Gewaltsamen, wir w\u00e4hren l\u00e4nger.", "tokens": ["Wir", ",", "Ge\u00b7walt\u00b7sa\u00b7men", ",", "wir", "w\u00e4h\u00b7ren", "l\u00e4n\u00b7ger", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "NN", "$,", "PPER", "VAFIN", "ADJD", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Aber ", "tokens": ["A\u00b7ber"], "token_info": ["word"], "pos": ["KON"], "meter": "+-", "measure": "trochaic.single"}, "line.3": {"text": "sind wir endlich offen und Empf\u00e4nger?", "tokens": ["sind", "wir", "end\u00b7lich", "of\u00b7fen", "und", "Emp\u00b7f\u00e4n\u00b7ger", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ADJD", "KON", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.5": {"line.1": {"text": "Blumenmuskel, der der Anemone", "tokens": ["Blu\u00b7men\u00b7mus\u00b7kel", ",", "der", "der", "A\u00b7ne\u00b7mo\u00b7ne"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "PRELS", "ART", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Wiesenmorgen nach und nach erschlie\u00dft,", "tokens": ["Wie\u00b7sen\u00b7mor\u00b7gen", "nach", "und", "nach", "er\u00b7schlie\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "KON", "APPR", "VVFIN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "bis in ihren Schoo\u00df das polyphone", "tokens": ["bis", "in", "ih\u00b7ren", "Schoo\u00df", "das", "po\u00b7ly\u00b7pho\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "PPOSAT", "NN", "ART", "ADJA"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "Licht der lauten Himmel sich ergie\u00dft,", "tokens": ["Licht", "der", "lau\u00b7ten", "Him\u00b7mel", "sich", "er\u00b7gie\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "PRF", "VVFIN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.6": {"line.1": {"text": "in den stillen Bl\u00fctenstern gespannter", "tokens": ["in", "den", "stil\u00b7len", "Bl\u00fc\u00b7tens\u00b7tern", "ge\u00b7spann\u00b7ter"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "ADJA"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Muskel des unendlichen Empfangs,", "tokens": ["Mus\u00b7kel", "des", "un\u00b7end\u00b7li\u00b7chen", "Emp\u00b7fangs", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "manchmal so von F\u00fclle \u00fcbermannter,", "tokens": ["manch\u00b7mal", "so", "von", "F\u00fcl\u00b7le", "\u00fc\u00b7berm\u00b7ann\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "NN", "ADJD", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "da\u00df der Ruhewink des Untergangs", "tokens": ["da\u00df", "der", "Ru\u00b7he\u00b7wink", "des", "Un\u00b7ter\u00b7gangs"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "ART", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.7": {"line.1": {"text": "kaum vermag die weitzur\u00fcckgeschnellten", "tokens": ["kaum", "ver\u00b7mag", "die", "weit\u00b7zu\u00b7r\u00fcck\u00b7ge\u00b7schnell\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "ADJA"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Blatterr\u00e4nder dir zur\u00fcckzugeben:", "tokens": ["Blat\u00b7ter\u00b7r\u00e4n\u00b7der", "dir", "zu\u00b7r\u00fcck\u00b7zu\u00b7ge\u00b7ben", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PPER", "VVIZU", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "du, Entschlu\u00df und Kraft von ", "tokens": ["du", ",", "Ent\u00b7schlu\u00df", "und", "Kraft", "von"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "$,", "NN", "KON", "NN", "APPR"], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.8": {"line.1": {"text": "Wir, Gewaltsamen, wir w\u00e4hren l\u00e4nger.", "tokens": ["Wir", ",", "Ge\u00b7walt\u00b7sa\u00b7men", ",", "wir", "w\u00e4h\u00b7ren", "l\u00e4n\u00b7ger", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "NN", "$,", "PPER", "VAFIN", "ADJD", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Aber ", "tokens": ["A\u00b7ber"], "token_info": ["word"], "pos": ["KON"], "meter": "+-", "measure": "trochaic.single"}, "line.3": {"text": "sind wir endlich offen und Empf\u00e4nger?", "tokens": ["sind", "wir", "end\u00b7lich", "of\u00b7fen", "und", "Emp\u00b7f\u00e4n\u00b7ger", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ADJD", "KON", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}}}}