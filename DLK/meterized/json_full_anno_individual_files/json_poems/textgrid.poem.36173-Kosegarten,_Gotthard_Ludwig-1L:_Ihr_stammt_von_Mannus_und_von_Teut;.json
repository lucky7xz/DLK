{"textgrid.poem.36173": {"metadata": {"author": {"name": "Kosegarten, Gotthard Ludwig", "birth": "N.A.", "death": "N.A."}, "title": "1L: Ihr stammt von Mannus und von Teut;", "genre": "verse", "period": "N.A.", "pub_year": 1788, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ihr stammt von Mannus und von Teut;", "tokens": ["Ihr", "stammt", "von", "Man\u00b7nus", "und", "von", "Teut", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NE", "KON", "APPR", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Von Teut und Mannus stammen wir;", "tokens": ["Von", "Teut", "und", "Man\u00b7nus", "stam\u00b7men", "wir", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "KON", "NN", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ihr \u00fcberst\u00fcrmtet Ost und West;", "tokens": ["Ihr", "\u00fc\u00b7bers\u00b7t\u00fcrm\u00b7tet", "Ost", "und", "West", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wir blieben heim im Vaterhaus,", "tokens": ["Wir", "blie\u00b7ben", "heim", "im", "Va\u00b7ter\u00b7haus", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKVZ", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "H\u00fctend den heil'gen Heerd.", "tokens": ["H\u00fc\u00b7tend", "den", "heil'\u00b7gen", "Heerd", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}}, "stanza.2": {"line.1": {"text": "Euch tummelnd unter Galliern", "tokens": ["Euch", "tum\u00b7melnd", "un\u00b7ter", "Gal\u00b7li\u00b7ern"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "ADJD", "APPR", "NN"], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}, "line.2": {"text": "Und R\u00f6mlingen, verlerntet ihr", "tokens": ["Und", "R\u00f6m\u00b7lin\u00b7gen", ",", "ver\u00b7lern\u00b7tet", "ihr"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["KON", "NN", "$,", "VVFIN", "PPER"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.3": {"text": "Der V\u00e4ter Zung' und Zucht.", "tokens": ["Der", "V\u00e4\u00b7ter", "Zung'", "und", "Zucht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "KON", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Wir tragen noch der V\u00e4ter Bild,", "tokens": ["Wir", "tra\u00b7gen", "noch", "der", "V\u00e4\u00b7ter", "Bild", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wir reden noch die Sprache Teuts,", "tokens": ["Wir", "re\u00b7den", "noch", "die", "Spra\u00b7che", "Teuts", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Die jede F\u00e4lschung scheu't.", "tokens": ["Die", "je\u00b7de", "F\u00e4l\u00b7schung", "scheu'", "t."], "token_info": ["word", "word", "word", "word", "abbreviation"], "pos": ["ART", "PIAT", "NN", "VVFIN", "NE"], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Zu Thor und Wodan riefen wir;", "tokens": ["Zu", "Thor", "und", "Wo\u00b7dan", "rie\u00b7fen", "wir", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NE", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ihr zu Sankt Guy und Sankt Denys;", "tokens": ["Ihr", "zu", "Sankt", "Guy", "und", "Sankt", "De\u00b7nys", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKZU", "VVFIN", "NE", "KON", "VVFIN", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Eins war des Andern werth.", "tokens": ["Eins", "war", "des", "An\u00b7dern", "werth", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ART", "ADJA", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Doch ", "tokens": ["Doch"], "token_info": ["word"], "pos": ["KON"], "meter": "+", "measure": "single.up"}, "line.5": {"text": "Sie wurden uns gesandt durch euch,", "tokens": ["Sie", "wur\u00b7den", "uns", "ge\u00b7sandt", "durch", "euch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "VVPP", "APPR", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Das fordert unsern Dank.", "tokens": ["Das", "for\u00b7dert", "un\u00b7sern", "Dank", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "F\u00fcr Christus strittet ihr bei Tours;", "tokens": ["F\u00fcr", "Chris\u00b7tus", "strit\u00b7tet", "ihr", "bei", "Tours", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VVFIN", "PPER", "APPR", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Im Lechfeld stritten wir f\u00fcr Ihn,", "tokens": ["Im", "Lech\u00b7feld", "strit\u00b7ten", "wir", "f\u00fcr", "Ihn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PPER", "APPR", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Das stellt uns gleich mit euch.", "tokens": ["Das", "stellt", "uns", "gleich", "mit", "euch", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADV", "APPR", "PPER", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Doch als zu Clermont Gott gebot,", "tokens": ["Doch", "als", "zu", "Cler\u00b7mont", "Gott", "ge\u00b7bot", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "APPR", "NE", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Habt ihr erk\u00e4mpft das heil'ge Grab;", "tokens": ["Habt", "ihr", "er\u00b7k\u00e4mpft", "das", "heil'\u00b7ge", "Grab", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Das, traun! gabt ihr voraus.", "tokens": ["Das", ",", "traun", "!", "gabt", "ihr", "vo\u00b7raus", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "$,", "VVINF", "$.", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Den Gottesfrieden gabet ihr,", "tokens": ["Den", "Got\u00b7tes\u00b7frie\u00b7den", "ga\u00b7bet", "ihr", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das Ritterthum erfandet ihr;", "tokens": ["Das", "Rit\u00b7ter\u00b7thum", "er\u00b7fan\u00b7det", "ihr", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Das heischt der Menschheit Dank.", "tokens": ["Das", "heischt", "der", "Menschheit", "Dank", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ART", "NN", "NN", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.4": {"text": "Es kam die Sitt', es kam die Kunst,", "tokens": ["Es", "kam", "die", "Sitt'", ",", "es", "kam", "die", "Kunst", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "PPER", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die Bildung kam zu uns von euch;", "tokens": ["Die", "Bil\u00b7dung", "kam", "zu", "uns", "von", "euch", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "PPER", "APPR", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Das heischt auch unsern Dank.", "tokens": ["Das", "heischt", "auch", "un\u00b7sern", "Dank", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Des Liedes Leib erwecktet ihr,", "tokens": ["Des", "Lie\u00b7des", "Leib", "er\u00b7weck\u00b7tet", "ihr", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wir hauchten eine Seel' ihm ein,", "tokens": ["Wir", "hauch\u00b7ten", "ei\u00b7ne", "Seel'", "ihm", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Eins ist des Andern werth.", "tokens": ["Eins", "ist", "des", "An\u00b7dern", "werth", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ART", "ADJA", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Doch wer, der unserm ", "tokens": ["Doch", "wer", ",", "der", "un\u00b7serm"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["KON", "PWS", "$,", "PRELS", "PPOSAT"], "meter": "-+-+-", "measure": "iambic.di"}, "line.5": {"text": "Unserm ", "tokens": ["Un\u00b7serm"], "token_info": ["word"], "pos": ["NN"], "meter": "+-", "measure": "trochaic.single"}, "line.6": {"text": "Lauscht eurem ", "tokens": ["Lauscht", "eu\u00b7rem"], "token_info": ["word", "word"], "pos": ["NN", "PPOSAT"], "meter": "-+-", "measure": "amphibrach.single"}}, "stanza.7": {"line.1": {"text": "Der Sch\u00f6nheit Blume pfl\u00fccktet ihr;", "tokens": ["Der", "Sch\u00f6n\u00b7heit", "Blu\u00b7me", "pfl\u00fcck\u00b7tet", "ihr", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Uns st\u00e4rkt des Wissens n\u00e4hrend Mark,", "tokens": ["Uns", "st\u00e4rkt", "des", "Wis\u00b7sens", "n\u00e4h\u00b7rend", "Mark", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADJD", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wohl dies wiegt jenes auf.", "tokens": ["Wohl", "dies", "wiegt", "je\u00b7nes", "auf", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PDS", "VVFIN", "PDS", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Ihr brachtet ", "tokens": ["Ihr", "brach\u00b7tet"], "token_info": ["word", "word"], "pos": ["PPER", "VVFIN"], "meter": "-+-", "measure": "amphibrach.single"}, "line.5": {"text": "Und unsre Schale sank.", "tokens": ["Und", "uns\u00b7re", "Scha\u00b7le", "sank", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Die Schalen schweben gleich.", "tokens": ["Die", "Scha\u00b7len", "schwe\u00b7ben", "gleich", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Doch wiegt auch ", "tokens": ["Doch", "wiegt", "auch"], "token_info": ["word", "word", "word"], "pos": ["KON", "VVFIN", "ADV"], "meter": "-+-", "measure": "amphibrach.single"}, "line.3": {"text": "Wol den ", "tokens": ["Wol", "den"], "token_info": ["word", "word"], "pos": ["ADV", "ART"], "meter": "+-", "measure": "trochaic.single"}, "line.4": {"text": "Wol ", "tokens": ["Wol"], "token_info": ["word"], "pos": ["ADV"], "meter": "+", "measure": "single.up"}}, "stanza.9": {"line.1": {"text": "Ihr nennet ", "tokens": ["Ihr", "nen\u00b7net"], "token_info": ["word", "word"], "pos": ["PPER", "VVFIN"], "meter": "+--", "measure": "dactylic.init"}, "line.2": {"text": "Wir nennen ", "tokens": ["Wir", "nen\u00b7nen"], "token_info": ["word", "word"], "pos": ["PPER", "VVFIN"], "meter": "-+-", "measure": "amphibrach.single"}, "line.3": {"text": "Und eure Schale steigt.", "tokens": ["Und", "eu\u00b7re", "Scha\u00b7le", "steigt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Und unsre Schale sinkt.", "tokens": ["Und", "uns\u00b7re", "Scha\u00b7le", "sinkt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "Gelt, ihr seyd witzig, glatt und fein;", "tokens": ["Gelt", ",", "ihr", "seyd", "wit\u00b7zig", ",", "glatt", "und", "fein", ";"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PPER", "VAFIN", "ADJD", "$,", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wir sind nicht witzig, fein und glatt,", "tokens": ["Wir", "sind", "nicht", "wit\u00b7zig", ",", "fein", "und", "glatt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKNEG", "ADJD", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wir sind nur schlecht und recht.", "tokens": ["Wir", "sind", "nur", "schlecht", "und", "recht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Ihr trotzt auf hohes Ehrgef\u00fchl;", "tokens": ["Ihr", "trotzt", "auf", "ho\u00b7hes", "Ehr\u00b7ge\u00b7f\u00fchl", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wir trotzen nicht, wir pflegen still", "tokens": ["Wir", "trot\u00b7zen", "nicht", ",", "wir", "pfle\u00b7gen", "still"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PTKNEG", "$,", "PPER", "VVINF", "VMFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Den Sinn f\u00fcr Pflicht und Recht.", "tokens": ["Den", "Sinn", "f\u00fcr", "Pflicht", "und", "Recht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "Wohl Heldenmuth und Rittersinn", "tokens": ["Wohl", "Hel\u00b7den\u00b7muth", "und", "Rit\u00b7ter\u00b7sinn"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Habt ihr erprobt gar oft und viel;", "tokens": ["Habt", "ihr", "er\u00b7probt", "gar", "oft", "und", "viel", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "VVFIN", "ADV", "ADV", "KON", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Nicht minder wir, noch mehr!", "tokens": ["Nicht", "min\u00b7der", "wir", ",", "noch", "mehr", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "PPER", "$,", "ADV", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "F\u00fcr euch zeugt ", "tokens": ["F\u00fcr", "euch", "zeugt"], "token_info": ["word", "word", "word"], "pos": ["APPR", "PPER", "VVFIN"], "meter": "+-+", "measure": "trochaic.di"}, "line.5": {"text": "F\u00fcr uns zeugt ", "tokens": ["F\u00fcr", "uns", "zeugt"], "token_info": ["word", "word", "word"], "pos": ["APPR", "PPER", "VVFIN"], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.12": {"line.1": {"text": "Hart wurdet ihr bedr\u00e4ngt; da stand", "tokens": ["Hart", "wur\u00b7det", "ihr", "be\u00b7dr\u00e4ngt", ";", "da", "stand"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["NE", "VAFIN", "PPER", "VVFIN", "$.", "ADV", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die gotterf\u00fcllte Jungfrau auf,", "tokens": ["Die", "got\u00b7ter\u00b7f\u00fcll\u00b7te", "Jung\u00b7frau", "auf", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Erl\u00f6ste euch und starb.", "tokens": ["Er\u00b7l\u00f6s\u00b7te", "euch", "und", "starb", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "KON", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Hart sind auch wir bedr\u00e4ngt; doch schon", "tokens": ["Hart", "sind", "auch", "wir", "be\u00b7dr\u00e4ngt", ";", "doch", "schon"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["NE", "VAFIN", "ADV", "PPER", "VVFIN", "$.", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Regt m\u00e4chtig sich der Geist des Herrn,", "tokens": ["Regt", "m\u00e4ch\u00b7tig", "sich", "der", "Geist", "des", "Herrn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "PRF", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Der uns, auch uns erl\u00f6st.", "tokens": ["Der", "uns", ",", "auch", "uns", "er\u00b7l\u00f6st", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "$,", "ADV", "PPER", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.13": {"line.1": {"text": "Doch g'nug des Haders! ", "tokens": ["Doch", "g'\u00b7nug", "des", "Ha\u00b7ders", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Entspro\u00dft, getauft auf ", "tokens": ["Ent\u00b7spro\u00dft", ",", "ge\u00b7tauft", "auf"], "token_info": ["word", "punct", "word", "word"], "pos": ["VVFIN", "$,", "VVPP", "APPR"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.3": {"text": "Was hadern wir und ihr?", "tokens": ["Was", "ha\u00b7dern", "wir", "und", "ihr", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "KON", "PPER", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Begabt seyd ihr, begabt sind wir,", "tokens": ["Be\u00b7gabt", "seyd", "ihr", ",", "be\u00b7gabt", "sind", "wir", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "PPER", "$,", "ADJD", "VAFIN", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Nicht minder s\u00fcndig wir wie ihr;", "tokens": ["Nicht", "min\u00b7der", "s\u00fcn\u00b7dig", "wir", "wie", "ihr", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "ADJD", "PPER", "KOKOM", "PPOSAT", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "D'rum la\u00dft uns Freunde seyn!", "tokens": ["D'\u00b7rum", "la\u00dft", "uns", "Freun\u00b7de", "seyn", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "NN", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "Wohl sch\u00f6n und gro\u00df ist euer Land;", "tokens": ["Wohl", "sch\u00f6n", "und", "gro\u00df", "ist", "eu\u00b7er", "Land", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KON", "ADJD", "VAFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Auch unser Land ist weit und sch\u00f6n;", "tokens": ["Auch", "un\u00b7ser", "Land", "ist", "weit", "und", "sch\u00f6n", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "VAFIN", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Raum's g'nug f\u00fcr uns und euch!", "tokens": ["Raum's", "g'\u00b7nug", "f\u00fcr", "uns", "und", "euch", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "APPR", "PPER", "KON", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Gott schied uns durch Geb\u00fcrg und Strom;", "tokens": ["Gott", "schied", "uns", "durch", "Ge\u00b7b\u00fcrg", "und", "Strom", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "APPR", "NN", "KON", "NN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.5": {"text": "Scheu't, wackre Br\u00fcder, scheu't den Gott,", "tokens": ["Scheu't", ",", "wack\u00b7re", "Br\u00fc\u00b7der", ",", "scheu't", "den", "Gott", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ADJA", "NN", "$,", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und Friede sey mit euch!", "tokens": ["Und", "Frie\u00b7de", "sey", "mit", "euch", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VAFIN", "APPR", "PPER", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.15": {"line.1": {"text": "Ihr stammt von Mannus und von Teut;", "tokens": ["Ihr", "stammt", "von", "Man\u00b7nus", "und", "von", "Teut", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NE", "KON", "APPR", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Von Teut und Mannus stammen wir;", "tokens": ["Von", "Teut", "und", "Man\u00b7nus", "stam\u00b7men", "wir", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "KON", "NN", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ihr \u00fcberst\u00fcrmtet Ost und West;", "tokens": ["Ihr", "\u00fc\u00b7bers\u00b7t\u00fcrm\u00b7tet", "Ost", "und", "West", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wir blieben heim im Vaterhaus,", "tokens": ["Wir", "blie\u00b7ben", "heim", "im", "Va\u00b7ter\u00b7haus", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKVZ", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "H\u00fctend den heil'gen Heerd.", "tokens": ["H\u00fc\u00b7tend", "den", "heil'\u00b7gen", "Heerd", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}}, "stanza.16": {"line.1": {"text": "Euch tummelnd unter Galliern", "tokens": ["Euch", "tum\u00b7melnd", "un\u00b7ter", "Gal\u00b7li\u00b7ern"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "ADJD", "APPR", "NN"], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}, "line.2": {"text": "Und R\u00f6mlingen, verlerntet ihr", "tokens": ["Und", "R\u00f6m\u00b7lin\u00b7gen", ",", "ver\u00b7lern\u00b7tet", "ihr"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["KON", "NN", "$,", "VVFIN", "PPER"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.3": {"text": "Der V\u00e4ter Zung' und Zucht.", "tokens": ["Der", "V\u00e4\u00b7ter", "Zung'", "und", "Zucht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "KON", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Wir tragen noch der V\u00e4ter Bild,", "tokens": ["Wir", "tra\u00b7gen", "noch", "der", "V\u00e4\u00b7ter", "Bild", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wir reden noch die Sprache Teuts,", "tokens": ["Wir", "re\u00b7den", "noch", "die", "Spra\u00b7che", "Teuts", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Die jede F\u00e4lschung scheu't.", "tokens": ["Die", "je\u00b7de", "F\u00e4l\u00b7schung", "scheu'", "t."], "token_info": ["word", "word", "word", "word", "abbreviation"], "pos": ["ART", "PIAT", "NN", "VVFIN", "NE"], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.17": {"line.1": {"text": "Zu Thor und Wodan riefen wir;", "tokens": ["Zu", "Thor", "und", "Wo\u00b7dan", "rie\u00b7fen", "wir", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NE", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ihr zu Sankt Guy und Sankt Denys;", "tokens": ["Ihr", "zu", "Sankt", "Guy", "und", "Sankt", "De\u00b7nys", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKZU", "VVFIN", "NE", "KON", "VVFIN", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Eins war des Andern werth.", "tokens": ["Eins", "war", "des", "An\u00b7dern", "werth", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ART", "ADJA", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Doch ", "tokens": ["Doch"], "token_info": ["word"], "pos": ["KON"], "meter": "+", "measure": "single.up"}, "line.5": {"text": "Sie wurden uns gesandt durch euch,", "tokens": ["Sie", "wur\u00b7den", "uns", "ge\u00b7sandt", "durch", "euch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "VVPP", "APPR", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Das fordert unsern Dank.", "tokens": ["Das", "for\u00b7dert", "un\u00b7sern", "Dank", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.18": {"line.1": {"text": "F\u00fcr Christus strittet ihr bei Tours;", "tokens": ["F\u00fcr", "Chris\u00b7tus", "strit\u00b7tet", "ihr", "bei", "Tours", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VVFIN", "PPER", "APPR", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Im Lechfeld stritten wir f\u00fcr Ihn,", "tokens": ["Im", "Lech\u00b7feld", "strit\u00b7ten", "wir", "f\u00fcr", "Ihn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PPER", "APPR", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Das stellt uns gleich mit euch.", "tokens": ["Das", "stellt", "uns", "gleich", "mit", "euch", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADV", "APPR", "PPER", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Doch als zu Clermont Gott gebot,", "tokens": ["Doch", "als", "zu", "Cler\u00b7mont", "Gott", "ge\u00b7bot", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "APPR", "NE", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Habt ihr erk\u00e4mpft das heil'ge Grab;", "tokens": ["Habt", "ihr", "er\u00b7k\u00e4mpft", "das", "heil'\u00b7ge", "Grab", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Das, traun! gabt ihr voraus.", "tokens": ["Das", ",", "traun", "!", "gabt", "ihr", "vo\u00b7raus", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "$,", "VVINF", "$.", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.19": {"line.1": {"text": "Den Gottesfrieden gabet ihr,", "tokens": ["Den", "Got\u00b7tes\u00b7frie\u00b7den", "ga\u00b7bet", "ihr", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das Ritterthum erfandet ihr;", "tokens": ["Das", "Rit\u00b7ter\u00b7thum", "er\u00b7fan\u00b7det", "ihr", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Das heischt der Menschheit Dank.", "tokens": ["Das", "heischt", "der", "Menschheit", "Dank", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ART", "NN", "NN", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.4": {"text": "Es kam die Sitt', es kam die Kunst,", "tokens": ["Es", "kam", "die", "Sitt'", ",", "es", "kam", "die", "Kunst", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "PPER", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die Bildung kam zu uns von euch;", "tokens": ["Die", "Bil\u00b7dung", "kam", "zu", "uns", "von", "euch", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "PPER", "APPR", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Das heischt auch unsern Dank.", "tokens": ["Das", "heischt", "auch", "un\u00b7sern", "Dank", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.20": {"line.1": {"text": "Des Liedes Leib erwecktet ihr,", "tokens": ["Des", "Lie\u00b7des", "Leib", "er\u00b7weck\u00b7tet", "ihr", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wir hauchten eine Seel' ihm ein,", "tokens": ["Wir", "hauch\u00b7ten", "ei\u00b7ne", "Seel'", "ihm", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Eins ist des Andern werth.", "tokens": ["Eins", "ist", "des", "An\u00b7dern", "werth", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ART", "ADJA", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Doch wer, der unserm ", "tokens": ["Doch", "wer", ",", "der", "un\u00b7serm"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["KON", "PWS", "$,", "PRELS", "PPOSAT"], "meter": "-+-+-", "measure": "iambic.di"}, "line.5": {"text": "Unserm ", "tokens": ["Un\u00b7serm"], "token_info": ["word"], "pos": ["NN"], "meter": "+-", "measure": "trochaic.single"}, "line.6": {"text": "Lauscht eurem ", "tokens": ["Lauscht", "eu\u00b7rem"], "token_info": ["word", "word"], "pos": ["NN", "PPOSAT"], "meter": "-+-", "measure": "amphibrach.single"}}, "stanza.21": {"line.1": {"text": "Der Sch\u00f6nheit Blume pfl\u00fccktet ihr;", "tokens": ["Der", "Sch\u00f6n\u00b7heit", "Blu\u00b7me", "pfl\u00fcck\u00b7tet", "ihr", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Uns st\u00e4rkt des Wissens n\u00e4hrend Mark,", "tokens": ["Uns", "st\u00e4rkt", "des", "Wis\u00b7sens", "n\u00e4h\u00b7rend", "Mark", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADJD", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wohl dies wiegt jenes auf.", "tokens": ["Wohl", "dies", "wiegt", "je\u00b7nes", "auf", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PDS", "VVFIN", "PDS", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Ihr brachtet ", "tokens": ["Ihr", "brach\u00b7tet"], "token_info": ["word", "word"], "pos": ["PPER", "VVFIN"], "meter": "-+-", "measure": "amphibrach.single"}, "line.5": {"text": "Und unsre Schale sank.", "tokens": ["Und", "uns\u00b7re", "Scha\u00b7le", "sank", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.22": {"line.1": {"text": "Die Schalen schweben gleich.", "tokens": ["Die", "Scha\u00b7len", "schwe\u00b7ben", "gleich", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Doch wiegt auch ", "tokens": ["Doch", "wiegt", "auch"], "token_info": ["word", "word", "word"], "pos": ["KON", "VVFIN", "ADV"], "meter": "-+-", "measure": "amphibrach.single"}, "line.3": {"text": "Wol den ", "tokens": ["Wol", "den"], "token_info": ["word", "word"], "pos": ["ADV", "ART"], "meter": "+-", "measure": "trochaic.single"}, "line.4": {"text": "Wol ", "tokens": ["Wol"], "token_info": ["word"], "pos": ["ADV"], "meter": "+", "measure": "single.up"}}, "stanza.23": {"line.1": {"text": "Ihr nennet ", "tokens": ["Ihr", "nen\u00b7net"], "token_info": ["word", "word"], "pos": ["PPER", "VVFIN"], "meter": "+--", "measure": "dactylic.init"}, "line.2": {"text": "Wir nennen ", "tokens": ["Wir", "nen\u00b7nen"], "token_info": ["word", "word"], "pos": ["PPER", "VVFIN"], "meter": "-+-", "measure": "amphibrach.single"}, "line.3": {"text": "Und eure Schale steigt.", "tokens": ["Und", "eu\u00b7re", "Scha\u00b7le", "steigt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Und unsre Schale sinkt.", "tokens": ["Und", "uns\u00b7re", "Scha\u00b7le", "sinkt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.24": {"line.1": {"text": "Gelt, ihr seyd witzig, glatt und fein;", "tokens": ["Gelt", ",", "ihr", "seyd", "wit\u00b7zig", ",", "glatt", "und", "fein", ";"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PPER", "VAFIN", "ADJD", "$,", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wir sind nicht witzig, fein und glatt,", "tokens": ["Wir", "sind", "nicht", "wit\u00b7zig", ",", "fein", "und", "glatt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKNEG", "ADJD", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wir sind nur schlecht und recht.", "tokens": ["Wir", "sind", "nur", "schlecht", "und", "recht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Ihr trotzt auf hohes Ehrgef\u00fchl;", "tokens": ["Ihr", "trotzt", "auf", "ho\u00b7hes", "Ehr\u00b7ge\u00b7f\u00fchl", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wir trotzen nicht, wir pflegen still", "tokens": ["Wir", "trot\u00b7zen", "nicht", ",", "wir", "pfle\u00b7gen", "still"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PTKNEG", "$,", "PPER", "VVINF", "VMFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Den Sinn f\u00fcr Pflicht und Recht.", "tokens": ["Den", "Sinn", "f\u00fcr", "Pflicht", "und", "Recht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.25": {"line.1": {"text": "Wohl Heldenmuth und Rittersinn", "tokens": ["Wohl", "Hel\u00b7den\u00b7muth", "und", "Rit\u00b7ter\u00b7sinn"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Habt ihr erprobt gar oft und viel;", "tokens": ["Habt", "ihr", "er\u00b7probt", "gar", "oft", "und", "viel", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "VVFIN", "ADV", "ADV", "KON", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Nicht minder wir, noch mehr!", "tokens": ["Nicht", "min\u00b7der", "wir", ",", "noch", "mehr", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "PPER", "$,", "ADV", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "F\u00fcr euch zeugt ", "tokens": ["F\u00fcr", "euch", "zeugt"], "token_info": ["word", "word", "word"], "pos": ["APPR", "PPER", "VVFIN"], "meter": "+-+", "measure": "trochaic.di"}, "line.5": {"text": "F\u00fcr uns zeugt ", "tokens": ["F\u00fcr", "uns", "zeugt"], "token_info": ["word", "word", "word"], "pos": ["APPR", "PPER", "VVFIN"], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.26": {"line.1": {"text": "Hart wurdet ihr bedr\u00e4ngt; da stand", "tokens": ["Hart", "wur\u00b7det", "ihr", "be\u00b7dr\u00e4ngt", ";", "da", "stand"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["NE", "VAFIN", "PPER", "VVFIN", "$.", "ADV", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die gotterf\u00fcllte Jungfrau auf,", "tokens": ["Die", "got\u00b7ter\u00b7f\u00fcll\u00b7te", "Jung\u00b7frau", "auf", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Erl\u00f6ste euch und starb.", "tokens": ["Er\u00b7l\u00f6s\u00b7te", "euch", "und", "starb", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "KON", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Hart sind auch wir bedr\u00e4ngt; doch schon", "tokens": ["Hart", "sind", "auch", "wir", "be\u00b7dr\u00e4ngt", ";", "doch", "schon"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["NE", "VAFIN", "ADV", "PPER", "VVFIN", "$.", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Regt m\u00e4chtig sich der Geist des Herrn,", "tokens": ["Regt", "m\u00e4ch\u00b7tig", "sich", "der", "Geist", "des", "Herrn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "PRF", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Der uns, auch uns erl\u00f6st.", "tokens": ["Der", "uns", ",", "auch", "uns", "er\u00b7l\u00f6st", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "$,", "ADV", "PPER", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.27": {"line.1": {"text": "Doch g'nug des Haders! ", "tokens": ["Doch", "g'\u00b7nug", "des", "Ha\u00b7ders", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Entspro\u00dft, getauft auf ", "tokens": ["Ent\u00b7spro\u00dft", ",", "ge\u00b7tauft", "auf"], "token_info": ["word", "punct", "word", "word"], "pos": ["VVFIN", "$,", "VVPP", "APPR"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.3": {"text": "Was hadern wir und ihr?", "tokens": ["Was", "ha\u00b7dern", "wir", "und", "ihr", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "KON", "PPER", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Begabt seyd ihr, begabt sind wir,", "tokens": ["Be\u00b7gabt", "seyd", "ihr", ",", "be\u00b7gabt", "sind", "wir", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "PPER", "$,", "ADJD", "VAFIN", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Nicht minder s\u00fcndig wir wie ihr;", "tokens": ["Nicht", "min\u00b7der", "s\u00fcn\u00b7dig", "wir", "wie", "ihr", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "ADJD", "PPER", "KOKOM", "PPOSAT", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "D'rum la\u00dft uns Freunde seyn!", "tokens": ["D'\u00b7rum", "la\u00dft", "uns", "Freun\u00b7de", "seyn", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "NN", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.28": {"line.1": {"text": "Wohl sch\u00f6n und gro\u00df ist euer Land;", "tokens": ["Wohl", "sch\u00f6n", "und", "gro\u00df", "ist", "eu\u00b7er", "Land", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KON", "ADJD", "VAFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Auch unser Land ist weit und sch\u00f6n;", "tokens": ["Auch", "un\u00b7ser", "Land", "ist", "weit", "und", "sch\u00f6n", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "VAFIN", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Raum's g'nug f\u00fcr uns und euch!", "tokens": ["Raum's", "g'\u00b7nug", "f\u00fcr", "uns", "und", "euch", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "APPR", "PPER", "KON", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Gott schied uns durch Geb\u00fcrg und Strom;", "tokens": ["Gott", "schied", "uns", "durch", "Ge\u00b7b\u00fcrg", "und", "Strom", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "APPR", "NN", "KON", "NN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.5": {"text": "Scheu't, wackre Br\u00fcder, scheu't den Gott,", "tokens": ["Scheu't", ",", "wack\u00b7re", "Br\u00fc\u00b7der", ",", "scheu't", "den", "Gott", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ADJA", "NN", "$,", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und Friede sey mit euch!", "tokens": ["Und", "Frie\u00b7de", "sey", "mit", "euch", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VAFIN", "APPR", "PPER", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}}}}