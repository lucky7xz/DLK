{"dta.poem.4383": {"metadata": {"author": {"name": "Brockes, Barthold Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "Ein andrer Hochmuhts-Z\u00fcgel.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1743", "urn": "urn:nbn:de:kobv:b4-20083-6", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Es k\u00f6nnen Leute, die nicht schreiben, noch auf der Laute", "tokens": ["Es", "k\u00f6n\u00b7nen", "Leu\u00b7te", ",", "die", "nicht", "schrei\u00b7ben", ",", "noch", "auf", "der", "Lau\u00b7te"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "NN", "$,", "PRELS", "PTKNEG", "VVINF", "$,", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+-++-+-", "measure": "unknown.measure.septa"}, "line.2": {"text": "spielen k\u00f6nnen,", "tokens": ["spie\u00b7len", "k\u00f6n\u00b7nen", ","], "token_info": ["word", "word", "punct"], "pos": ["VVINF", "VMINF", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "Nicht, ohn\u2019 ein Wunder, beydes thun, so denen doch so", "tokens": ["Nicht", ",", "ohn'", "ein", "Wun\u00b7der", ",", "bey\u00b7des", "thun", ",", "so", "de\u00b7nen", "doch", "so"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PTKNEG", "$,", "KOUI", "ART", "NN", "$,", "PIS", "VVINF", "$,", "ADV", "PRELS", "ADV", "ADV"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.4": {"text": "leichte f\u00e4llt,", "tokens": ["leich\u00b7te", "f\u00e4llt", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "VVFIN", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.5": {"text": "Die schreiben k\u00f6nnen und auch spielen. Wenn die Natur", "tokens": ["Die", "schrei\u00b7ben", "k\u00f6n\u00b7nen", "und", "auch", "spie\u00b7len", ".", "Wenn", "die", "Na\u00b7tur"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "VVINF", "VMINF", "KON", "ADV", "VVINF", "$.", "KOUS", "ART", "NN"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.6": {"text": "nun auf der Welt", "tokens": ["nun", "auf", "der", "Welt"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "APPR", "ART", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "So viele sonderbare Dinge, und die wir, weil wir sie nicht", "tokens": ["So", "vie\u00b7le", "son\u00b7der\u00b7ba\u00b7re", "Din\u00b7ge", ",", "und", "die", "wir", ",", "weil", "wir", "sie", "nicht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "PIAT", "ADJA", "NN", "$,", "KON", "PRELS", "PPER", "$,", "KOUS", "PPER", "PPER", "PTKNEG"], "meter": "-+-+-+-+-+-+-+-+", "measure": "iambic.octa.plus"}, "line.8": {"text": "kennen,", "tokens": ["ken\u00b7nen", ","], "token_info": ["word", "punct"], "pos": ["VVFIN", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.9": {"text": "Wofern nicht Wunder in der That, doch wunderbar mit", "tokens": ["Wo\u00b7fern", "nicht", "Wun\u00b7der", "in", "der", "That", ",", "doch", "wun\u00b7der\u00b7bar", "mit"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "PTKNEG", "NN", "APPR", "ART", "NN", "$,", "ADV", "ADJD", "APPR"], "meter": "-+-+-+-+-+---", "measure": "unknown.measure.penta"}, "line.10": {"text": "Rechte nennen,", "tokens": ["Rech\u00b7te", "nen\u00b7nen", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVINF", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.11": {"text": "Hervorgebracht und t\u00e4glich bringet; wenn sie, zum Beyspiel,", "tokens": ["Her\u00b7vor\u00b7ge\u00b7bracht", "und", "t\u00e4g\u00b7lich", "brin\u00b7get", ";", "wenn", "sie", ",", "zum", "Bey\u00b7spiel", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "KON", "ADJD", "VVFIN", "$.", "KOUS", "PPER", "$,", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-++-+-", "measure": "unknown.measure.septa"}, "line.12": {"text": "eine Biene", "tokens": ["ei\u00b7ne", "Bie\u00b7ne"], "token_info": ["word", "word"], "pos": ["ART", "NN"], "meter": "+-+-", "measure": "trochaic.di"}, "line.13": {"text": "Aus ungeformten Stoff formiert; so scheinet es fast einer-", "tokens": ["Aus", "un\u00b7ge\u00b7form\u00b7ten", "Stoff", "for\u00b7miert", ";", "so", "schei\u00b7net", "es", "fast", "ei\u00b7ner"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "VVPP", "$.", "ADV", "VVFIN", "PPER", "ADV", "TRUNC"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.14": {"text": "ley,", "tokens": ["ley", ","], "token_info": ["word", "punct"], "pos": ["ADV", "$,"], "meter": "+", "measure": "single.up"}, "line.15": {"text": "Und da\u00df, ob es gleich uns unm\u00f6glich, es ihr dennoch ein", "tokens": ["Und", "da\u00df", ",", "ob", "es", "gleich", "uns", "un\u00b7m\u00f6g\u00b7lich", ",", "es", "ihr", "den\u00b7noch", "ein"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "$,", "KOUS", "PPER", "ADV", "PPER", "ADJD", "$,", "PPER", "PPER", "ADV", "ART"], "meter": "-+--+--+--+--+", "measure": "amphibrach.penta.plus"}, "line.16": {"text": "leichtes sey.", "tokens": ["leich\u00b7tes", "sey", "."], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "VAFIN", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.17": {"text": "Mir kommt es vor, da\u00df die\u00df Exempel uns wenigstens", "tokens": ["Mir", "kommt", "es", "vor", ",", "da\u00df", "die\u00df", "Ex\u00b7em\u00b7pel", "uns", "we\u00b7nigs\u00b7tens"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "PTKVZ", "$,", "KOUS", "PDS", "NN", "PPER", "ADV"], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.18": {"text": "zum Beyspiel diene,", "tokens": ["zum", "Bey\u00b7spiel", "die\u00b7ne", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.19": {"text": "Da\u00df, ob wir gleich nicht, wie sie wirke, und die geheime", "tokens": ["Da\u00df", ",", "ob", "wir", "gleich", "nicht", ",", "wie", "sie", "wir\u00b7ke", ",", "und", "die", "ge\u00b7hei\u00b7me"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "$,", "KOUS", "PPER", "ADV", "PTKNEG", "$,", "PWAV", "PPER", "VVFIN", "$,", "KON", "ART", "ADJA"], "meter": "-+------+-+-+-", "measure": "dactylic.init"}, "line.20": {"text": "Art verstehn;", "tokens": ["Art", "ver\u00b7stehn", ";"], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVINF", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.21": {"text": "Wir doch, da\u00df die gewirkten Dinge darum durch Wunder", "tokens": ["Wir", "doch", ",", "da\u00df", "die", "ge\u00b7wirk\u00b7ten", "Din\u00b7ge", "da\u00b7rum", "durch", "Wun\u00b7der"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "$,", "KOUS", "ART", "ADJA", "NN", "PAV", "APPR", "NN"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.22": {"text": "nicht geschehn,", "tokens": ["nicht", "ge\u00b7schehn", ","], "token_info": ["word", "word", "punct"], "pos": ["PTKNEG", "VVPP", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.23": {"text": "Nein, da\u00df der ewige Verstand", "tokens": ["Nein", ",", "da\u00df", "der", "e\u00b7wi\u00b7ge", "Ver\u00b7stand"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["PTKANT", "$,", "KOUS", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.24": {"text": "Jhr F\u00e4higkeiten zugetheilet, da\u00df, wie wir Menschen mit", "tokens": ["Ihr", "F\u00e4\u00b7hig\u00b7kei\u00b7ten", "zu\u00b7ge\u00b7thei\u00b7let", ",", "da\u00df", ",", "wie", "wir", "Men\u00b7schen", "mit"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VVPP", "$,", "KOUS", "$,", "PWAV", "PPER", "NN", "APPR"], "meter": "-+-+-+-+--+-+-+", "measure": "iambic.septa.relaxed"}, "line.25": {"text": "der Hand,", "tokens": ["der", "Hand", ","], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$,"], "meter": "-+", "measure": "iambic.single"}, "line.26": {"text": "Sie, sonder H\u00e4nde, wirken k\u00f6nne, wie wir aus der Er-", "tokens": ["Sie", ",", "son\u00b7der", "H\u00e4n\u00b7de", ",", "wir\u00b7ken", "k\u00f6n\u00b7ne", ",", "wie", "wir", "aus", "der", "Er"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "$,", "KON", "NN", "$,", "VVINF", "VMFIN", "$,", "PWAV", "PPER", "APPR", "ART", "TRUNC"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.27": {"text": "fahrung sehn,", "tokens": ["fah\u00b7rung", "sehn", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVINF", "$,"], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.2": {"line.1": {"text": "Ob wir die Art gleich nicht begreifen. Wir wirken durch", "tokens": ["Ob", "wir", "die", "Art", "gleich", "nicht", "be\u00b7grei\u00b7fen", ".", "Wir", "wir\u00b7ken", "durch"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "NN", "ADV", "PTKNEG", "VVINF", "$.", "PPER", "VVFIN", "APPR"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "die H\u00e4nde nur,", "tokens": ["die", "H\u00e4n\u00b7de", "nur", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "Und k\u00f6nnen, sonder Hand, nicht wirken. Folgt denn", "tokens": ["Und", "k\u00f6n\u00b7nen", ",", "son\u00b7der", "Hand", ",", "nicht", "wir\u00b7ken", ".", "Folgt", "denn"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["KON", "VMFIN", "$,", "KON", "NN", "$,", "PTKNEG", "VVINF", "$.", "VVFIN", "ADV"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "daraus, da\u00df die Natur", "tokens": ["da\u00b7raus", ",", "da\u00df", "die", "Na\u00b7tur"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["PAV", "$,", "KOUS", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Nicht k\u00f6nn\u2019 auf andre Weise handeln? Es scheinet, da\u00df", "tokens": ["Nicht", "k\u00f6nn'", "auf", "and\u00b7re", "Wei\u00b7se", "han\u00b7deln", "?", "Es", "schei\u00b7net", ",", "da\u00df"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word"], "pos": ["PTKNEG", "VMFIN", "APPR", "ADJA", "NN", "VVINF", "$.", "PPER", "VVFIN", "$,", "KOUS"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "wir uns vergessen,", "tokens": ["wir", "uns", "ver\u00b7ges\u00b7sen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "PPER", "VVPP", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.7": {"text": "Und selbst die Ordnungen des Sch\u00f6pfers nur blo\u00df nach", "tokens": ["Und", "selbst", "die", "Ord\u00b7nun\u00b7gen", "des", "Sch\u00f6p\u00b7fers", "nur", "blo\u00df", "nach"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "ART", "NN", "ART", "NN", "ADV", "ADV", "APPR"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "unserm Leisten messen.", "tokens": ["un\u00b7serm", "Leis\u00b7ten", "mes\u00b7sen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.3": {"line.1": {"text": "Dient die Betrachtung sonst zu nichts, und n\u00fctzt uns", "tokens": ["Dient", "die", "Be\u00b7trach\u00b7tung", "sonst", "zu", "nichts", ",", "und", "n\u00fctzt", "uns"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "ART", "NN", "ADV", "PTKA", "PIS", "$,", "KON", "VVFIN", "PPER"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "nicht in andern Dingen;", "tokens": ["nicht", "in", "an\u00b7dern", "Din\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "ADJA", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "So kann sie uns doch \u00fcberzeuglich vom Stolz zur wahren", "tokens": ["So", "kann", "sie", "uns", "doch", "\u00fc\u00b7berz\u00b7eug\u00b7lich", "vom", "Stolz", "zur", "wah\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PPER", "PPER", "ADV", "ADJD", "APPRART", "NN", "APPRART", "ADJA"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Demuht bringen.", "tokens": ["De\u00b7muht", "brin\u00b7gen", "."], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVINF", "$."], "meter": "+-+-", "measure": "trochaic.di"}}}}}