{"textgrid.poem.35892": {"metadata": {"author": {"name": "Hensel, Luise", "birth": "N.A.", "death": "N.A."}, "title": "1L: Es weidet dort im gr\u00fcnen Thal", "genre": "verse", "period": "N.A.", "pub_year": 1830, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Es weidet dort im gr\u00fcnen Thal", "tokens": ["Es", "wei\u00b7det", "dort", "im", "gr\u00fc\u00b7nen", "Thal"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein Hirt von hoher Art.", "tokens": ["Ein", "Hirt", "von", "ho\u00b7her", "Art", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Die Sch\u00e4flein, die er weidet, all'", "tokens": ["Die", "Sch\u00e4f\u00b7lein", ",", "die", "er", "wei\u00b7det", ",", "all'"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,", "PIAT"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sind wei\u00df und fromm und zart.", "tokens": ["Sind", "wei\u00df", "und", "fromm", "und", "zart", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "VVFIN", "KON", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "J\u00fcngst that nach einem irren Lamm", "tokens": ["J\u00fcngst", "that", "nach", "ei\u00b7nem", "ir\u00b7ren", "Lamm"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Er \u00e4ngstlich suchen gehn", "tokens": ["Er", "\u00e4ngst\u00b7lich", "su\u00b7chen", "gehn"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "ADJD", "VVINF", "VVINF"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und stieg auf hohen Baumes Stamm,", "tokens": ["Und", "stieg", "auf", "ho\u00b7hen", "Bau\u00b7mes", "Stamm", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sich weit herum zu sehn.", "tokens": ["Sich", "weit", "he\u00b7rum", "zu", "sehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADJD", "PTKVZ", "PTKZU", "VVINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Er ist dem L\u00e4mmlein gar so gut,", "tokens": ["Er", "ist", "dem", "L\u00e4mm\u00b7lein", "gar", "so", "gut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "ADV", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Drum ruft und klagt er laut;", "tokens": ["Drum", "ruft", "und", "klagt", "er", "laut", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "KON", "VVFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Denn \u2013 ach! \u2013 er kennt des Wolfes Wuth,", "tokens": ["Denn", "\u2013", "ach", "!", "\u2013", "er", "kennt", "des", "Wol\u00b7fes", "Wuth", ","], "token_info": ["word", "punct", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$(", "ITJ", "$.", "$(", "PPER", "VVFIN", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der gierig l\u00e4ngst geschaut.", "tokens": ["Der", "gie\u00b7rig", "l\u00e4ngst", "ge\u00b7schaut", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "ADV", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "\u00bbund kommst du nicht, geliebtes Lamm,", "tokens": ["\u00bb", "und", "kommst", "du", "nicht", ",", "ge\u00b7lieb\u00b7tes", "Lamm", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "KON", "VVFIN", "PPER", "PTKNEG", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und f\u00fchlst nicht meine Noth,", "tokens": ["Und", "f\u00fchlst", "nicht", "mei\u00b7ne", "Noth", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKNEG", "PPOSAT", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "So steig' ich nicht von diesem Stamm", "tokens": ["So", "steig'", "ich", "nicht", "von", "die\u00b7sem", "Stamm"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PTKNEG", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und h\u00e4rme mich zu Tod.\u00ab", "tokens": ["Und", "h\u00e4r\u00b7me", "mich", "zu", "Tod", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "NN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Dann bricht er Rosen von dem Baum", "tokens": ["Dann", "bricht", "er", "Ro\u00b7sen", "von", "dem", "Baum"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und wirft sie, krank und matt,", "tokens": ["Und", "wirft", "sie", ",", "krank", "und", "matt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Hernieder auf den gr\u00fcnen Raum,", "tokens": ["Her\u00b7nie\u00b7der", "auf", "den", "gr\u00fc\u00b7nen", "Raum", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Dem Lamm zur Lagerstatt:", "tokens": ["Dem", "Lamm", "zur", "La\u00b7ger\u00b7statt", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "\u00bbund bin ich nun im Tode bleich,", "tokens": ["\u00bb", "und", "bin", "ich", "nun", "im", "To\u00b7de", "bleich", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KON", "VAFIN", "PPER", "ADV", "APPRART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und kommt mein L\u00e4mmlein sp\u00e4t,", "tokens": ["Und", "kommt", "mein", "L\u00e4mm\u00b7lein", "sp\u00e4t", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "So ruht es doch auf Rosen weich,", "tokens": ["So", "ruht", "es", "doch", "auf", "Ro\u00b7sen", "weich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPR", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die meine Hand ges\u00e4't. \u2013", "tokens": ["Die", "mei\u00b7ne", "Hand", "ge\u00b7s\u00e4'", "t.", "\u2013"], "token_info": ["word", "word", "word", "word", "abbreviation", "punct"], "pos": ["ART", "PPOSAT", "NN", "NE", "NE", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Ich habe dich so treu geliebt,", "tokens": ["Ich", "ha\u00b7be", "dich", "so", "treu", "ge\u00b7liebt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So milde f\u00fchrt' ich dich;", "tokens": ["So", "mil\u00b7de", "f\u00fchrt'", "ich", "dich", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "PPER", "PRF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Du hast mich in den Tod betr\u00fcbt:", "tokens": ["Du", "hast", "mich", "in", "den", "Tod", "be\u00b7tr\u00fcbt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Liebe t\u00f6dtet mich.", "tokens": ["Die", "Lie\u00b7be", "t\u00f6d\u00b7tet", "mich", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Fahr' wohl, du undankbares Lamm!", "tokens": ["Fahr'", "wohl", ",", "du", "un\u00b7dank\u00b7ba\u00b7res", "Lamm", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "$,", "PPER", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Fahr' wohl, du treulos Herz!", "tokens": ["Fahr'", "wohl", ",", "du", "treu\u00b7los", "Herz", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "$,", "PPER", "ADJD", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und kommst du einst zu diesem Stamm,", "tokens": ["Und", "kommst", "du", "einst", "zu", "die\u00b7sem", "Stamm", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So denk' an meinen Schmerz.\u00ab \u2013", "tokens": ["So", "denk'", "an", "mei\u00b7nen", "Schmerz", ".", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["ADV", "VVFIN", "APPR", "PPOSAT", "NN", "$.", "$(", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Nun brach so tr\u00fcb und lebenssatt", "tokens": ["Nun", "brach", "so", "tr\u00fcb", "und", "le\u00b7bens\u00b7satt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ADV", "ADJD", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Des treusten Hirten Blick;", "tokens": ["Des", "treus\u00b7ten", "Hir\u00b7ten", "Blick", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Da kam aus ferner W\u00fcste matt", "tokens": ["Da", "kam", "aus", "fer\u00b7ner", "W\u00fcs\u00b7te", "matt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "APPR", "ADJA", "NN", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Das irre Lamm zur\u00fcck.", "tokens": ["Das", "ir\u00b7re", "Lamm", "zu\u00b7r\u00fcck", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "Und als es seinen Hirten sah,", "tokens": ["Und", "als", "es", "sei\u00b7nen", "Hir\u00b7ten", "sah", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Bereut' es seine Flucht,", "tokens": ["Be\u00b7reut'", "es", "sei\u00b7ne", "Flucht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPOSAT", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und nimmer hat es fern noch nah", "tokens": ["Und", "nim\u00b7mer", "hat", "es", "fern", "noch", "nah"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VAFIN", "PPER", "ADJD", "ADV", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mehr Weid' und Trank gesucht.", "tokens": ["Mehr", "Weid'", "und", "Trank", "ge\u00b7sucht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "Es n\u00e4hrt sich von des Baumes Laub,", "tokens": ["Es", "n\u00e4hrt", "sich", "von", "des", "Bau\u00b7mes", "Laub", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Daran sein Hirt erblich;", "tokens": ["Da\u00b7ran", "sein", "Hirt", "er\u00b7blich", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PAV", "PPOSAT", "NN", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Es w\u00e4hlt gewelkter Rosen Staub", "tokens": ["Es", "w\u00e4hlt", "ge\u00b7welk\u00b7ter", "Ro\u00b7sen", "Staub"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADJA", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Zum sanften Lager sich.", "tokens": ["Zum", "sanf\u00b7ten", "La\u00b7ger", "sich", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "PRF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "Es scheut nicht Dorn, nicht Stein noch Kluft,", "tokens": ["Es", "scheut", "nicht", "Dorn", ",", "nicht", "Stein", "noch", "Kluft", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "NN", "$,", "PTKNEG", "NN", "ADV", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Nicht Gluth noch rauhes Wehn,", "tokens": ["Nicht", "Gluth", "noch", "rau\u00b7hes", "Wehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "NN", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Bis einst der Hirt zur Weide ruft,", "tokens": ["Bis", "einst", "der", "Hirt", "zur", "Wei\u00b7de", "ruft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "ART", "NN", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wo treue L\u00e4mmlein gehn.", "tokens": ["Wo", "treu\u00b7e", "L\u00e4mm\u00b7lein", "gehn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.13": {"line.1": {"text": "Es weidet dort im gr\u00fcnen Thal", "tokens": ["Es", "wei\u00b7det", "dort", "im", "gr\u00fc\u00b7nen", "Thal"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein Hirt von hoher Art.", "tokens": ["Ein", "Hirt", "von", "ho\u00b7her", "Art", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Die Sch\u00e4flein, die er weidet, all'", "tokens": ["Die", "Sch\u00e4f\u00b7lein", ",", "die", "er", "wei\u00b7det", ",", "all'"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,", "PIAT"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sind wei\u00df und fromm und zart.", "tokens": ["Sind", "wei\u00df", "und", "fromm", "und", "zart", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "VVFIN", "KON", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.14": {"line.1": {"text": "J\u00fcngst that nach einem irren Lamm", "tokens": ["J\u00fcngst", "that", "nach", "ei\u00b7nem", "ir\u00b7ren", "Lamm"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Er \u00e4ngstlich suchen gehn", "tokens": ["Er", "\u00e4ngst\u00b7lich", "su\u00b7chen", "gehn"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "ADJD", "VVINF", "VVINF"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und stieg auf hohen Baumes Stamm,", "tokens": ["Und", "stieg", "auf", "ho\u00b7hen", "Bau\u00b7mes", "Stamm", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sich weit herum zu sehn.", "tokens": ["Sich", "weit", "he\u00b7rum", "zu", "sehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADJD", "PTKVZ", "PTKZU", "VVINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.15": {"line.1": {"text": "Er ist dem L\u00e4mmlein gar so gut,", "tokens": ["Er", "ist", "dem", "L\u00e4mm\u00b7lein", "gar", "so", "gut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "ADV", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Drum ruft und klagt er laut;", "tokens": ["Drum", "ruft", "und", "klagt", "er", "laut", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "KON", "VVFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Denn \u2013 ach! \u2013 er kennt des Wolfes Wuth,", "tokens": ["Denn", "\u2013", "ach", "!", "\u2013", "er", "kennt", "des", "Wol\u00b7fes", "Wuth", ","], "token_info": ["word", "punct", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$(", "ITJ", "$.", "$(", "PPER", "VVFIN", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der gierig l\u00e4ngst geschaut.", "tokens": ["Der", "gie\u00b7rig", "l\u00e4ngst", "ge\u00b7schaut", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "ADV", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.16": {"line.1": {"text": "\u00bbund kommst du nicht, geliebtes Lamm,", "tokens": ["\u00bb", "und", "kommst", "du", "nicht", ",", "ge\u00b7lieb\u00b7tes", "Lamm", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "KON", "VVFIN", "PPER", "PTKNEG", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und f\u00fchlst nicht meine Noth,", "tokens": ["Und", "f\u00fchlst", "nicht", "mei\u00b7ne", "Noth", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKNEG", "PPOSAT", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "So steig' ich nicht von diesem Stamm", "tokens": ["So", "steig'", "ich", "nicht", "von", "die\u00b7sem", "Stamm"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PTKNEG", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und h\u00e4rme mich zu Tod.\u00ab", "tokens": ["Und", "h\u00e4r\u00b7me", "mich", "zu", "Tod", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "NN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.17": {"line.1": {"text": "Dann bricht er Rosen von dem Baum", "tokens": ["Dann", "bricht", "er", "Ro\u00b7sen", "von", "dem", "Baum"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und wirft sie, krank und matt,", "tokens": ["Und", "wirft", "sie", ",", "krank", "und", "matt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Hernieder auf den gr\u00fcnen Raum,", "tokens": ["Her\u00b7nie\u00b7der", "auf", "den", "gr\u00fc\u00b7nen", "Raum", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Dem Lamm zur Lagerstatt:", "tokens": ["Dem", "Lamm", "zur", "La\u00b7ger\u00b7statt", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.18": {"line.1": {"text": "\u00bbund bin ich nun im Tode bleich,", "tokens": ["\u00bb", "und", "bin", "ich", "nun", "im", "To\u00b7de", "bleich", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KON", "VAFIN", "PPER", "ADV", "APPRART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und kommt mein L\u00e4mmlein sp\u00e4t,", "tokens": ["Und", "kommt", "mein", "L\u00e4mm\u00b7lein", "sp\u00e4t", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "So ruht es doch auf Rosen weich,", "tokens": ["So", "ruht", "es", "doch", "auf", "Ro\u00b7sen", "weich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPR", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die meine Hand ges\u00e4't. \u2013", "tokens": ["Die", "mei\u00b7ne", "Hand", "ge\u00b7s\u00e4'", "t.", "\u2013"], "token_info": ["word", "word", "word", "word", "abbreviation", "punct"], "pos": ["ART", "PPOSAT", "NN", "NE", "NE", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.19": {"line.1": {"text": "Ich habe dich so treu geliebt,", "tokens": ["Ich", "ha\u00b7be", "dich", "so", "treu", "ge\u00b7liebt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So milde f\u00fchrt' ich dich;", "tokens": ["So", "mil\u00b7de", "f\u00fchrt'", "ich", "dich", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "PPER", "PRF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Du hast mich in den Tod betr\u00fcbt:", "tokens": ["Du", "hast", "mich", "in", "den", "Tod", "be\u00b7tr\u00fcbt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Liebe t\u00f6dtet mich.", "tokens": ["Die", "Lie\u00b7be", "t\u00f6d\u00b7tet", "mich", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.20": {"line.1": {"text": "Fahr' wohl, du undankbares Lamm!", "tokens": ["Fahr'", "wohl", ",", "du", "un\u00b7dank\u00b7ba\u00b7res", "Lamm", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "$,", "PPER", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Fahr' wohl, du treulos Herz!", "tokens": ["Fahr'", "wohl", ",", "du", "treu\u00b7los", "Herz", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "$,", "PPER", "ADJD", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und kommst du einst zu diesem Stamm,", "tokens": ["Und", "kommst", "du", "einst", "zu", "die\u00b7sem", "Stamm", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So denk' an meinen Schmerz.\u00ab \u2013", "tokens": ["So", "denk'", "an", "mei\u00b7nen", "Schmerz", ".", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["ADV", "VVFIN", "APPR", "PPOSAT", "NN", "$.", "$(", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.21": {"line.1": {"text": "Nun brach so tr\u00fcb und lebenssatt", "tokens": ["Nun", "brach", "so", "tr\u00fcb", "und", "le\u00b7bens\u00b7satt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ADV", "ADJD", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Des treusten Hirten Blick;", "tokens": ["Des", "treus\u00b7ten", "Hir\u00b7ten", "Blick", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Da kam aus ferner W\u00fcste matt", "tokens": ["Da", "kam", "aus", "fer\u00b7ner", "W\u00fcs\u00b7te", "matt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "APPR", "ADJA", "NN", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Das irre Lamm zur\u00fcck.", "tokens": ["Das", "ir\u00b7re", "Lamm", "zu\u00b7r\u00fcck", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.22": {"line.1": {"text": "Und als es seinen Hirten sah,", "tokens": ["Und", "als", "es", "sei\u00b7nen", "Hir\u00b7ten", "sah", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Bereut' es seine Flucht,", "tokens": ["Be\u00b7reut'", "es", "sei\u00b7ne", "Flucht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPOSAT", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und nimmer hat es fern noch nah", "tokens": ["Und", "nim\u00b7mer", "hat", "es", "fern", "noch", "nah"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VAFIN", "PPER", "ADJD", "ADV", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mehr Weid' und Trank gesucht.", "tokens": ["Mehr", "Weid'", "und", "Trank", "ge\u00b7sucht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.23": {"line.1": {"text": "Es n\u00e4hrt sich von des Baumes Laub,", "tokens": ["Es", "n\u00e4hrt", "sich", "von", "des", "Bau\u00b7mes", "Laub", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Daran sein Hirt erblich;", "tokens": ["Da\u00b7ran", "sein", "Hirt", "er\u00b7blich", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PAV", "PPOSAT", "NN", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Es w\u00e4hlt gewelkter Rosen Staub", "tokens": ["Es", "w\u00e4hlt", "ge\u00b7welk\u00b7ter", "Ro\u00b7sen", "Staub"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADJA", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Zum sanften Lager sich.", "tokens": ["Zum", "sanf\u00b7ten", "La\u00b7ger", "sich", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "PRF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.24": {"line.1": {"text": "Es scheut nicht Dorn, nicht Stein noch Kluft,", "tokens": ["Es", "scheut", "nicht", "Dorn", ",", "nicht", "Stein", "noch", "Kluft", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "NN", "$,", "PTKNEG", "NN", "ADV", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Nicht Gluth noch rauhes Wehn,", "tokens": ["Nicht", "Gluth", "noch", "rau\u00b7hes", "Wehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "NN", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Bis einst der Hirt zur Weide ruft,", "tokens": ["Bis", "einst", "der", "Hirt", "zur", "Wei\u00b7de", "ruft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "ART", "NN", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wo treue L\u00e4mmlein gehn.", "tokens": ["Wo", "treu\u00b7e", "L\u00e4mm\u00b7lein", "gehn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}}}}