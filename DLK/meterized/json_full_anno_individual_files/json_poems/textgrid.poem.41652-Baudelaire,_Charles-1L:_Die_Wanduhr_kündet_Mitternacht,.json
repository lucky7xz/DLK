{"textgrid.poem.41652": {"metadata": {"author": {"name": "Baudelaire, Charles", "birth": "N.A.", "death": "N.A."}, "title": "1L: Die Wanduhr k\u00fcndet Mitternacht,", "genre": "verse", "period": "N.A.", "pub_year": 1844, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Die Wanduhr k\u00fcndet Mitternacht,", "tokens": ["Die", "Wan\u00b7duhr", "k\u00fcn\u00b7det", "Mit\u00b7ter\u00b7nacht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Als ob sie h\u00f6hnend uns frage,", "tokens": ["Als", "ob", "sie", "h\u00f6h\u00b7nend", "uns", "fra\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "PPER", "ADJD", "PPER", "VVFIN", "$,"], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}, "line.3": {"text": "Welch einen Gebrauch vom Tage,", "tokens": ["Welch", "ei\u00b7nen", "Ge\u00b7brauch", "vom", "Ta\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ART", "NN", "APPRART", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Der nun entschwunden, wir gemacht:", "tokens": ["Der", "nun", "ent\u00b7schwun\u00b7den", ",", "wir", "ge\u00b7macht", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADV", "VVPP", "$,", "PPER", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Diesen Freitag, den schicksalsschweren,", "tokens": ["Die\u00b7sen", "Frei\u00b7tag", ",", "den", "schick\u00b7sals\u00b7schwe\u00b7ren", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PDAT", "NN", "$,", "ART", "ADJA", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.6": {"text": "Den dreizehnten, haben mit Lust", "tokens": ["Den", "drei\u00b7zehn\u00b7ten", ",", "ha\u00b7ben", "mit", "Lust"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "$,", "VAFIN", "APPR", "NN"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.7": {"text": "Wir trotz allem, was wir gewu\u00dft,", "tokens": ["Wir", "trotz", "al\u00b7lem", ",", "was", "wir", "ge\u00b7wu\u00dft", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "PIS", "$,", "PRELS", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Gelebt, als ob Ketzer wir w\u00e4ren.", "tokens": ["Ge\u00b7lebt", ",", "als", "ob", "Ket\u00b7zer", "wir", "w\u00e4\u00b7ren", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "KOKOM", "KOUS", "NN", "PPER", "VAFIN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.2": {"line.1": {"text": "Wir l\u00e4sterten Jesum Christ,", "tokens": ["Wir", "l\u00e4s\u00b7ter\u00b7ten", "Je\u00b7sum", "Christ", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NE", "NE", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Den g\u00f6ttlichsten aller G\u00f6tter!", "tokens": ["Den", "g\u00f6tt\u00b7lichs\u00b7ten", "al\u00b7ler", "G\u00f6t\u00b7ter", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "PIAT", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Wie ein Schmarotzer und Sp\u00f6tter,", "tokens": ["Wie", "ein", "Schma\u00b7rot\u00b7zer", "und", "Sp\u00f6t\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "KON", "NN", "$,"], "meter": "---+--+-", "measure": "iambic.di.relaxed"}, "line.4": {"text": "Der bei verruchtem Kr\u00f6sus i\u00dft,", "tokens": ["Der", "bei", "ver\u00b7ruch\u00b7tem", "Kr\u00f6\u00b7sus", "i\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wir haben, dem Tier zu behagen,", "tokens": ["Wir", "ha\u00b7ben", ",", "dem", "Tier", "zu", "be\u00b7ha\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.6": {"text": "Der D\u00e4monen Sklavenschar,", "tokens": ["Der", "D\u00e4\u00b7mo\u00b7nen", "Skla\u00b7ven\u00b7schar", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Umschmeichelt, was feind uns war,", "tokens": ["Um\u00b7schmei\u00b7chelt", ",", "was", "feind", "uns", "war", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PWS", "NN", "PPER", "VAFIN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "Und was uns lieb war, geschlagen.", "tokens": ["Und", "was", "uns", "lieb", "war", ",", "ge\u00b7schla\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "PWS", "PPER", "ADJD", "VAFIN", "$,", "VVPP", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.3": {"line.1": {"text": "Gleich Henkern haben am Schwachen wir,", "tokens": ["Gleich", "Hen\u00b7kern", "ha\u00b7ben", "am", "Schwa\u00b7chen", "wir", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "VAFIN", "APPRART", "NN", "PPER", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Den man unrecht h\u00f6hnt, uns verschuldigt,", "tokens": ["Den", "man", "un\u00b7recht", "h\u00f6hnt", ",", "uns", "ver\u00b7schul\u00b7digt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "PIS", "NN", "VVFIN", "$,", "PPER", "VVPP", "$,"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "Der Macht der Dummheit gehuldigt,", "tokens": ["Der", "Macht", "der", "Dumm\u00b7heit", "ge\u00b7hul\u00b7digt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Die ehrner Stirn ist, wie ein Stier;", "tokens": ["Die", "ehr\u00b7ner", "Stirn", "ist", ",", "wie", "ein", "Stier", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "$,", "PWAV", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wir k\u00fc\u00dften des Staubes Dumpfheit", "tokens": ["Wir", "k\u00fc\u00df\u00b7ten", "des", "Stau\u00b7bes", "Dum\u00b7pf\u00b7heit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.6": {"text": "Und gingen ihm ehrfurchtsvoll nach,", "tokens": ["Und", "gin\u00b7gen", "ihm", "ehr\u00b7furchts\u00b7voll", "nach", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADJD", "PTKVZ", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.7": {"text": "Wir priesen der F\u00e4ulnis Schmach", "tokens": ["Wir", "prie\u00b7sen", "der", "F\u00e4ul\u00b7nis", "Schmach"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "In all ihrer bleiernen Stumpfheit.", "tokens": ["In", "all", "ih\u00b7rer", "blei\u00b7er\u00b7nen", "Stumpf\u00b7heit", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.4": {"line.1": {"text": "Dann sa\u00dfen, um des Schwindels Qual", "tokens": ["Dann", "sa\u00b7\u00dfen", ",", "um", "des", "Schwin\u00b7dels", "Qual"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "$,", "KOUI", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Zu ertr\u00e4nken in wilder Feier,", "tokens": ["Zu", "er\u00b7tr\u00e4n\u00b7ken", "in", "wil\u00b7der", "Fei\u00b7er", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "APPR", "ADJA", "NN", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "Wir stolzen Priester der Leier,", "tokens": ["Wir", "stol\u00b7zen", "Pries\u00b7ter", "der", "Lei\u00b7er", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "ART", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Denen ihr ruhmvoll Amt befahl", "tokens": ["De\u00b7nen", "ihr", "ruhm\u00b7voll", "Amt", "be\u00b7fahl"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "PPOSAT", "ADJD", "NN", "VVFIN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.5": {"text": "Des Dunkels Rausch zu entdecken,", "tokens": ["Des", "Dun\u00b7kels", "Rausch", "zu", "ent\u00b7de\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Ohne Hunger genie\u00dfend beim Schmaus! ...", "tokens": ["Oh\u00b7ne", "Hun\u00b7ger", "ge\u00b7nie\u00b7\u00dfend", "beim", "Schmaus", "!", "..."], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "NN", "VVPP", "APPRART", "NN", "$.", "$("], "meter": "+-+--+--+", "measure": "trochaic.tetra.relaxed"}, "line.7": {"text": "Rasch, l\u00f6schen die Lampe wir aus,", "tokens": ["Rasch", ",", "l\u00f6\u00b7schen", "die", "Lam\u00b7pe", "wir", "aus", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "VVFIN", "ART", "NN", "PPER", "PTKVZ", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.8": {"text": "In der Finsternis uns zu verstecken!", "tokens": ["In", "der", "Fins\u00b7ter\u00b7nis", "uns", "zu", "ver\u00b7ste\u00b7cken", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PPER", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.5": {"line.1": {"text": "Die Wanduhr k\u00fcndet Mitternacht,", "tokens": ["Die", "Wan\u00b7duhr", "k\u00fcn\u00b7det", "Mit\u00b7ter\u00b7nacht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Als ob sie h\u00f6hnend uns frage,", "tokens": ["Als", "ob", "sie", "h\u00f6h\u00b7nend", "uns", "fra\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "PPER", "ADJD", "PPER", "VVFIN", "$,"], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}, "line.3": {"text": "Welch einen Gebrauch vom Tage,", "tokens": ["Welch", "ei\u00b7nen", "Ge\u00b7brauch", "vom", "Ta\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ART", "NN", "APPRART", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Der nun entschwunden, wir gemacht:", "tokens": ["Der", "nun", "ent\u00b7schwun\u00b7den", ",", "wir", "ge\u00b7macht", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADV", "VVPP", "$,", "PPER", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Diesen Freitag, den schicksalsschweren,", "tokens": ["Die\u00b7sen", "Frei\u00b7tag", ",", "den", "schick\u00b7sals\u00b7schwe\u00b7ren", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PDAT", "NN", "$,", "ART", "ADJA", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.6": {"text": "Den dreizehnten, haben mit Lust", "tokens": ["Den", "drei\u00b7zehn\u00b7ten", ",", "ha\u00b7ben", "mit", "Lust"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "$,", "VAFIN", "APPR", "NN"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.7": {"text": "Wir trotz allem, was wir gewu\u00dft,", "tokens": ["Wir", "trotz", "al\u00b7lem", ",", "was", "wir", "ge\u00b7wu\u00dft", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "PIS", "$,", "PRELS", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Gelebt, als ob Ketzer wir w\u00e4ren.", "tokens": ["Ge\u00b7lebt", ",", "als", "ob", "Ket\u00b7zer", "wir", "w\u00e4\u00b7ren", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "KOKOM", "KOUS", "NN", "PPER", "VAFIN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.6": {"line.1": {"text": "Wir l\u00e4sterten Jesum Christ,", "tokens": ["Wir", "l\u00e4s\u00b7ter\u00b7ten", "Je\u00b7sum", "Christ", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NE", "NE", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Den g\u00f6ttlichsten aller G\u00f6tter!", "tokens": ["Den", "g\u00f6tt\u00b7lichs\u00b7ten", "al\u00b7ler", "G\u00f6t\u00b7ter", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "PIAT", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Wie ein Schmarotzer und Sp\u00f6tter,", "tokens": ["Wie", "ein", "Schma\u00b7rot\u00b7zer", "und", "Sp\u00f6t\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "KON", "NN", "$,"], "meter": "---+--+-", "measure": "iambic.di.relaxed"}, "line.4": {"text": "Der bei verruchtem Kr\u00f6sus i\u00dft,", "tokens": ["Der", "bei", "ver\u00b7ruch\u00b7tem", "Kr\u00f6\u00b7sus", "i\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wir haben, dem Tier zu behagen,", "tokens": ["Wir", "ha\u00b7ben", ",", "dem", "Tier", "zu", "be\u00b7ha\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.6": {"text": "Der D\u00e4monen Sklavenschar,", "tokens": ["Der", "D\u00e4\u00b7mo\u00b7nen", "Skla\u00b7ven\u00b7schar", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Umschmeichelt, was feind uns war,", "tokens": ["Um\u00b7schmei\u00b7chelt", ",", "was", "feind", "uns", "war", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PWS", "NN", "PPER", "VAFIN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "Und was uns lieb war, geschlagen.", "tokens": ["Und", "was", "uns", "lieb", "war", ",", "ge\u00b7schla\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "PWS", "PPER", "ADJD", "VAFIN", "$,", "VVPP", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.7": {"line.1": {"text": "Gleich Henkern haben am Schwachen wir,", "tokens": ["Gleich", "Hen\u00b7kern", "ha\u00b7ben", "am", "Schwa\u00b7chen", "wir", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "VAFIN", "APPRART", "NN", "PPER", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Den man unrecht h\u00f6hnt, uns verschuldigt,", "tokens": ["Den", "man", "un\u00b7recht", "h\u00f6hnt", ",", "uns", "ver\u00b7schul\u00b7digt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "PIS", "NN", "VVFIN", "$,", "PPER", "VVPP", "$,"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "Der Macht der Dummheit gehuldigt,", "tokens": ["Der", "Macht", "der", "Dumm\u00b7heit", "ge\u00b7hul\u00b7digt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Die ehrner Stirn ist, wie ein Stier;", "tokens": ["Die", "ehr\u00b7ner", "Stirn", "ist", ",", "wie", "ein", "Stier", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "$,", "PWAV", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wir k\u00fc\u00dften des Staubes Dumpfheit", "tokens": ["Wir", "k\u00fc\u00df\u00b7ten", "des", "Stau\u00b7bes", "Dum\u00b7pf\u00b7heit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.6": {"text": "Und gingen ihm ehrfurchtsvoll nach,", "tokens": ["Und", "gin\u00b7gen", "ihm", "ehr\u00b7furchts\u00b7voll", "nach", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADJD", "PTKVZ", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.7": {"text": "Wir priesen der F\u00e4ulnis Schmach", "tokens": ["Wir", "prie\u00b7sen", "der", "F\u00e4ul\u00b7nis", "Schmach"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "In all ihrer bleiernen Stumpfheit.", "tokens": ["In", "all", "ih\u00b7rer", "blei\u00b7er\u00b7nen", "Stumpf\u00b7heit", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.8": {"line.1": {"text": "Dann sa\u00dfen, um des Schwindels Qual", "tokens": ["Dann", "sa\u00b7\u00dfen", ",", "um", "des", "Schwin\u00b7dels", "Qual"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "$,", "KOUI", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Zu ertr\u00e4nken in wilder Feier,", "tokens": ["Zu", "er\u00b7tr\u00e4n\u00b7ken", "in", "wil\u00b7der", "Fei\u00b7er", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "APPR", "ADJA", "NN", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "Wir stolzen Priester der Leier,", "tokens": ["Wir", "stol\u00b7zen", "Pries\u00b7ter", "der", "Lei\u00b7er", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "ART", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Denen ihr ruhmvoll Amt befahl", "tokens": ["De\u00b7nen", "ihr", "ruhm\u00b7voll", "Amt", "be\u00b7fahl"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "PPOSAT", "ADJD", "NN", "VVFIN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.5": {"text": "Des Dunkels Rausch zu entdecken,", "tokens": ["Des", "Dun\u00b7kels", "Rausch", "zu", "ent\u00b7de\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Ohne Hunger genie\u00dfend beim Schmaus! ...", "tokens": ["Oh\u00b7ne", "Hun\u00b7ger", "ge\u00b7nie\u00b7\u00dfend", "beim", "Schmaus", "!", "..."], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "NN", "VVPP", "APPRART", "NN", "$.", "$("], "meter": "+-+--+--+", "measure": "trochaic.tetra.relaxed"}, "line.7": {"text": "Rasch, l\u00f6schen die Lampe wir aus,", "tokens": ["Rasch", ",", "l\u00f6\u00b7schen", "die", "Lam\u00b7pe", "wir", "aus", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "VVFIN", "ART", "NN", "PPER", "PTKVZ", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.8": {"text": "In der Finsternis uns zu verstecken!", "tokens": ["In", "der", "Fins\u00b7ter\u00b7nis", "uns", "zu", "ver\u00b7ste\u00b7cken", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PPER", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}}}}