{"textgrid.poem.53457": {"metadata": {"author": {"name": "Tucholsky, Kurt", "birth": "N.A.", "death": "N.A."}, "title": "Parkett", "genre": "verse", "period": "N.A.", "pub_year": 1912, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Das St\u00fcck hat Weltanschauung. Neben mir Ottilchen", "tokens": ["Das", "St\u00fcck", "hat", "Welt\u00b7an\u00b7schau\u00b7ung", ".", "Ne\u00b7ben", "mir", "Ot\u00b7til\u00b7chen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "NN", "$.", "APPR", "PPER", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "hat weit die grauen Augen aufgemacht:", "tokens": ["hat", "weit", "die", "grau\u00b7en", "Au\u00b7gen", "auf\u00b7ge\u00b7macht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Der, nach dem Spiel, erhofft ein Kartenspielchen,", "tokens": ["Der", ",", "nach", "dem", "Spiel", ",", "er\u00b7hofft", "ein", "Kar\u00b7ten\u00b7spiel\u00b7chen", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "$,", "APPR", "ART", "NN", "$,", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "der eine Nacht . . .", "tokens": ["der", "ei\u00b7ne", "Nacht", ".", ".", "."], "token_info": ["word", "word", "word", "punct", "punct", "punct"], "pos": ["ART", "ART", "NN", "$.", "$.", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.2": {"line.1": {"text": "Der Diener meldet die Kommerzienr\u00e4te,", "tokens": ["Der", "Die\u00b7ner", "mel\u00b7det", "die", "Kom\u00b7mer\u00b7zi\u00b7en\u00b7r\u00e4\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "die Gn\u00e4dige empf\u00e4ngt, ein Sektglas klirrt.", "tokens": ["die", "Gn\u00e4\u00b7di\u00b7ge", "emp\u00b7f\u00e4ngt", ",", "ein", "Sekt\u00b7glas", "klirrt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Ich streichle ihre Hand, die sonst die H\u00fcte n\u00e4hte . . .", "tokens": ["Ich", "streich\u00b7le", "ih\u00b7re", "Hand", ",", "die", "sonst", "die", "H\u00fc\u00b7te", "n\u00e4h\u00b7te", ".", ".", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "$,", "PRELS", "ADV", "ART", "NN", "VVFIN", "$.", "$.", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ob das was wird?", "tokens": ["Ob", "das", "was", "wird", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDS", "PIS", "VAFIN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.3": {"line.1": {"text": "Da oben gibt es Liebe und Entsetzen,", "tokens": ["Da", "o\u00b7ben", "gibt", "es", "Lie\u00b7be", "und", "Ent\u00b7set\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "doch so gem\u00e4\u00dfigt, wie sichs eben schickt.", "tokens": ["doch", "so", "ge\u00b7m\u00e4\u00b7\u00dfigt", ",", "wie", "sichs", "e\u00b7ben", "schickt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVPP", "$,", "PWAV", "PIS", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "\u00bbottilie\u00ab, fl\u00fcstre ich, \u00bbvermagst du mich zu sch\u00e4tzen?!\u00ab", "tokens": ["\u00bb", "ot\u00b7ti\u00b7lie", "\u00ab", ",", "fl\u00fcst\u00b7re", "ich", ",", "\u00bb", "ver\u00b7magst", "du", "mich", "zu", "sch\u00e4t\u00b7zen", "?!", "\u00ab"], "token_info": ["punct", "word", "punct", "punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "FM.la", "$(", "$,", "VVFIN", "PPER", "$,", "$(", "VVFIN", "PPER", "PRF", "PTKZU", "VVINF", "$.", "$("], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.4": {"text": "Sieh da: sie nickt.", "tokens": ["Sieh", "da", ":", "sie", "nickt", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "PTKVZ", "$.", "PPER", "VVFIN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.4": {"line.1": {"text": "Nun l\u00e4\u00dft mich alles kalt: die ganze Tragik", "tokens": ["Nun", "l\u00e4\u00dft", "mich", "al\u00b7les", "kalt", ":", "die", "gan\u00b7ze", "Tra\u00b7gik"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PIS", "ADJD", "$.", "ART", "ADJA", "NN"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.2": {"text": "ist jetzt f\u00fcr mich verh\u00e4ltnism\u00e4\u00dfig gleich.", "tokens": ["ist", "jetzt", "f\u00fcr", "mich", "ver\u00b7h\u00e4lt\u00b7nis\u00b7m\u00e4\u00b7\u00dfig", "gleich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "APPR", "PPER", "ADJD", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Und nimmt Madameken ihr Gift, dann sag ick:", "tokens": ["Und", "nimmt", "Ma\u00b7da\u00b7me\u00b7ken", "ihr", "Gift", ",", "dann", "sag", "ick", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "NN", "PPOSAT", "NN", "$,", "ADV", "VVFIN", "PPER", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "\u00bbich bin so reich . . . \u00ab", "tokens": ["\u00bb", "ich", "bin", "so", "reich", ".", ".", ".", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct", "punct", "punct"], "pos": ["$(", "PPER", "VAFIN", "ADV", "ADJD", "$.", "$.", "$.", "$("], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.5": {"line.1": {"text": "Was k\u00fcmmern mich die bl\u00f6den B\u00fchnenr\u00e4nke!", "tokens": ["Was", "k\u00fcm\u00b7mern", "mich", "die", "bl\u00f6\u00b7den", "B\u00fch\u00b7nen\u00b7r\u00e4n\u00b7ke", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Nu sieh mal, wie sie um die Leiche stehn!", "tokens": ["Nu", "sieh", "mal", ",", "wie", "sie", "um", "die", "Lei\u00b7che", "stehn", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVIMP", "ADV", "$,", "PWAV", "PPER", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Genug \u2013", "tokens": ["Ge\u00b7nug", "\u2013"], "token_info": ["word", "punct"], "pos": ["ADV", "$("], "meter": "-+", "measure": "iambic.single"}, "line.4": {"text": " . . . \u00bbOttilie\u00ab, spreche ich, \u00bbich denke \u2013", "tokens": [".", ".", ".", "\u00bb", "Ot\u00b7ti\u00b7lie", "\u00ab", ",", "spre\u00b7che", "ich", ",", "\u00bb", "ich", "den\u00b7ke", "\u2013"], "token_info": ["punct", "punct", "punct", "punct", "word", "punct", "punct", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["$.", "$.", "$.", "$(", "NE", "$(", "$,", "VVFIN", "PPER", "$,", "$(", "PPER", "VVFIN", "$("], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.5": {"text": "wir wollen gehn . . . \u00ab", "tokens": ["wir", "wol\u00b7len", "gehn", ".", ".", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct", "punct", "punct"], "pos": ["PPER", "VMFIN", "VVINF", "$.", "$.", "$.", "$("], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.6": {"line.1": {"text": "Das St\u00fcck hat Weltanschauung. Neben mir Ottilchen", "tokens": ["Das", "St\u00fcck", "hat", "Welt\u00b7an\u00b7schau\u00b7ung", ".", "Ne\u00b7ben", "mir", "Ot\u00b7til\u00b7chen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "NN", "$.", "APPR", "PPER", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "hat weit die grauen Augen aufgemacht:", "tokens": ["hat", "weit", "die", "grau\u00b7en", "Au\u00b7gen", "auf\u00b7ge\u00b7macht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Der, nach dem Spiel, erhofft ein Kartenspielchen,", "tokens": ["Der", ",", "nach", "dem", "Spiel", ",", "er\u00b7hofft", "ein", "Kar\u00b7ten\u00b7spiel\u00b7chen", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "$,", "APPR", "ART", "NN", "$,", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "der eine Nacht . . .", "tokens": ["der", "ei\u00b7ne", "Nacht", ".", ".", "."], "token_info": ["word", "word", "word", "punct", "punct", "punct"], "pos": ["ART", "ART", "NN", "$.", "$.", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.7": {"line.1": {"text": "Der Diener meldet die Kommerzienr\u00e4te,", "tokens": ["Der", "Die\u00b7ner", "mel\u00b7det", "die", "Kom\u00b7mer\u00b7zi\u00b7en\u00b7r\u00e4\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "die Gn\u00e4dige empf\u00e4ngt, ein Sektglas klirrt.", "tokens": ["die", "Gn\u00e4\u00b7di\u00b7ge", "emp\u00b7f\u00e4ngt", ",", "ein", "Sekt\u00b7glas", "klirrt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Ich streichle ihre Hand, die sonst die H\u00fcte n\u00e4hte . . .", "tokens": ["Ich", "streich\u00b7le", "ih\u00b7re", "Hand", ",", "die", "sonst", "die", "H\u00fc\u00b7te", "n\u00e4h\u00b7te", ".", ".", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "$,", "PRELS", "ADV", "ART", "NN", "VVFIN", "$.", "$.", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ob das was wird?", "tokens": ["Ob", "das", "was", "wird", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDS", "PIS", "VAFIN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.8": {"line.1": {"text": "Da oben gibt es Liebe und Entsetzen,", "tokens": ["Da", "o\u00b7ben", "gibt", "es", "Lie\u00b7be", "und", "Ent\u00b7set\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "doch so gem\u00e4\u00dfigt, wie sichs eben schickt.", "tokens": ["doch", "so", "ge\u00b7m\u00e4\u00b7\u00dfigt", ",", "wie", "sichs", "e\u00b7ben", "schickt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVPP", "$,", "PWAV", "PIS", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "\u00bbottilie\u00ab, fl\u00fcstre ich, \u00bbvermagst du mich zu sch\u00e4tzen?!\u00ab", "tokens": ["\u00bb", "ot\u00b7ti\u00b7lie", "\u00ab", ",", "fl\u00fcst\u00b7re", "ich", ",", "\u00bb", "ver\u00b7magst", "du", "mich", "zu", "sch\u00e4t\u00b7zen", "?!", "\u00ab"], "token_info": ["punct", "word", "punct", "punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "FM.la", "$(", "$,", "VVFIN", "PPER", "$,", "$(", "VVFIN", "PPER", "PRF", "PTKZU", "VVINF", "$.", "$("], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.4": {"text": "Sieh da: sie nickt.", "tokens": ["Sieh", "da", ":", "sie", "nickt", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "PTKVZ", "$.", "PPER", "VVFIN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.9": {"line.1": {"text": "Nun l\u00e4\u00dft mich alles kalt: die ganze Tragik", "tokens": ["Nun", "l\u00e4\u00dft", "mich", "al\u00b7les", "kalt", ":", "die", "gan\u00b7ze", "Tra\u00b7gik"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PIS", "ADJD", "$.", "ART", "ADJA", "NN"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.2": {"text": "ist jetzt f\u00fcr mich verh\u00e4ltnism\u00e4\u00dfig gleich.", "tokens": ["ist", "jetzt", "f\u00fcr", "mich", "ver\u00b7h\u00e4lt\u00b7nis\u00b7m\u00e4\u00b7\u00dfig", "gleich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "APPR", "PPER", "ADJD", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Und nimmt Madameken ihr Gift, dann sag ick:", "tokens": ["Und", "nimmt", "Ma\u00b7da\u00b7me\u00b7ken", "ihr", "Gift", ",", "dann", "sag", "ick", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "NN", "PPOSAT", "NN", "$,", "ADV", "VVFIN", "PPER", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "\u00bbich bin so reich . . . \u00ab", "tokens": ["\u00bb", "ich", "bin", "so", "reich", ".", ".", ".", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct", "punct", "punct"], "pos": ["$(", "PPER", "VAFIN", "ADV", "ADJD", "$.", "$.", "$.", "$("], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.10": {"line.1": {"text": "Was k\u00fcmmern mich die bl\u00f6den B\u00fchnenr\u00e4nke!", "tokens": ["Was", "k\u00fcm\u00b7mern", "mich", "die", "bl\u00f6\u00b7den", "B\u00fch\u00b7nen\u00b7r\u00e4n\u00b7ke", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Nu sieh mal, wie sie um die Leiche stehn!", "tokens": ["Nu", "sieh", "mal", ",", "wie", "sie", "um", "die", "Lei\u00b7che", "stehn", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVIMP", "ADV", "$,", "PWAV", "PPER", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Genug \u2013", "tokens": ["Ge\u00b7nug", "\u2013"], "token_info": ["word", "punct"], "pos": ["ADV", "$("], "meter": "-+", "measure": "iambic.single"}, "line.4": {"text": " . . . \u00bbOttilie\u00ab, spreche ich, \u00bbich denke \u2013", "tokens": [".", ".", ".", "\u00bb", "Ot\u00b7ti\u00b7lie", "\u00ab", ",", "spre\u00b7che", "ich", ",", "\u00bb", "ich", "den\u00b7ke", "\u2013"], "token_info": ["punct", "punct", "punct", "punct", "word", "punct", "punct", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["$.", "$.", "$.", "$(", "NE", "$(", "$,", "VVFIN", "PPER", "$,", "$(", "PPER", "VVFIN", "$("], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.5": {"text": "wir wollen gehn . . . \u00ab", "tokens": ["wir", "wol\u00b7len", "gehn", ".", ".", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct", "punct", "punct"], "pos": ["PPER", "VMFIN", "VVINF", "$.", "$.", "$.", "$("], "meter": "-+-+", "measure": "iambic.di"}}}}}