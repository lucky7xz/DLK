{"dta.poem.9850": {"metadata": {"author": {"name": "Hofmannswaldau, Christian Hofmann von", "birth": "N.A.", "death": "N.A."}, "title": "Dasselbe gedichte in eine ode  \n verfasset.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1697", "urn": "urn:nbn:de:kobv:b4-200905199377", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Soll itzt der erden krei\u00df nicht zittern/", "tokens": ["Soll", "itzt", "der", "er\u00b7den", "krei\u00df", "nicht", "zit\u00b7tern", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "ART", "NN", "VVFIN", "PTKNEG", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Da sich mit allen ungewittern", "tokens": ["Da", "sich", "mit", "al\u00b7len", "un\u00b7ge\u00b7wit\u00b7tern"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PRF", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Der himmel wider uns entr\u00fcst/", "tokens": ["Der", "him\u00b7mel", "wi\u00b7der", "uns", "ent\u00b7r\u00fcst", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPER", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Da T\u00fcrck und Tartern rasend wachen/", "tokens": ["Da", "T\u00fcrck", "und", "Tar\u00b7tern", "ra\u00b7send", "wa\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "NN", "VVPP", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Und Ungarn gantz zur leiche machen/", "tokens": ["Und", "Un\u00b7garn", "gantz", "zur", "lei\u00b7che", "ma\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "ADV", "APPRART", "ADJA", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Das nunmehr seiner gantz vergist?", "tokens": ["Das", "nun\u00b7mehr", "sei\u00b7ner", "gantz", "ver\u00b7gist", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "PPOSAT", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Der Ister/ so gekr\u00f6nt von siegen/", "tokens": ["Der", "Is\u00b7ter", "/", "so", "ge\u00b7kr\u00f6nt", "von", "sie\u00b7gen", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "ADV", "ADJD", "APPR", "NE", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Mu\u00df blutig itzt an fesseln liegen/", "tokens": ["Mu\u00df", "blu\u00b7tig", "itzt", "an", "fes\u00b7seln", "lie\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADJD", "ADV", "APPR", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und lebt nicht frey mehr wie zuvor.", "tokens": ["Und", "lebt", "nicht", "frey", "mehr", "wie", "zu\u00b7vor", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKNEG", "ADJD", "ADV", "KOKOM", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sein lorber-crantz der wird gantz eitel/", "tokens": ["Sein", "lor\u00b7ber\u00b7crantz", "der", "wird", "gantz", "ei\u00b7tel", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ART", "VAFIN", "ADV", "ADJD", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Weil nun die hocherhabne scheitel", "tokens": ["Weil", "nun", "die", "ho\u00b7cher\u00b7hab\u00b7ne", "schei\u00b7tel"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Verh\u00f6hnt zerbrechlich schilf und rohr.", "tokens": ["Ver\u00b7h\u00f6hnt", "zer\u00b7brech\u00b7lich", "schilf", "und", "rohr", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Ja selbst das ufer klingt von klage/", "tokens": ["Ja", "selbst", "das", "u\u00b7fer", "klingt", "von", "kla\u00b7ge", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "ADV", "ART", "NN", "VVFIN", "APPR", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und jenseits starrt die schnelle wage/", "tokens": ["Und", "jen\u00b7seits", "starrt", "die", "schnel\u00b7le", "wa\u00b7ge", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VVFIN", "ART", "ADJA", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Gef\u00fcllt mit schon erkaltem blut/", "tokens": ["Ge\u00b7f\u00fcllt", "mit", "schon", "er\u00b7kal\u00b7tem", "blut", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "APPR", "ADV", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Indem den freyheits-purpur tr\u00e4get/", "tokens": ["In\u00b7dem", "den", "frey\u00b7heits\u00b7pur\u00b7pur", "tr\u00e4\u00b7get", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Den unser kriegsmann abgeleget/", "tokens": ["Den", "un\u00b7ser", "kriegs\u00b7mann", "ab\u00b7ge\u00b7le\u00b7get", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Nunmehr des Neutra gelbe fluth.", "tokens": ["Nun\u00b7mehr", "des", "Neut\u00b7ra", "gel\u00b7be", "fluth", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Als Ottomannus nach gefallen", "tokens": ["Als", "Ot\u00b7to\u00b7man\u00b7nus", "nach", "ge\u00b7fal\u00b7len"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "NE", "APPR", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Das ", "tokens": ["Das"], "token_info": ["word"], "pos": ["PDS"], "meter": "-", "measure": "single.down"}, "line.3": {"text": "Und hagel nach Neuh\u00e4usel blie\u00df/", "tokens": ["Und", "ha\u00b7gel", "nach", "Neu\u00b7h\u00e4u\u00b7sel", "blie\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "APPR", "NN", "VVFIN", "$("], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.4": {"text": "Daselbst erschrack des himmels anger/", "tokens": ["Da\u00b7selbst", "er\u00b7schrack", "des", "him\u00b7mels", "an\u00b7ger", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "ART", "NN", "ADJD", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Wie er stets gieng mit blitzen schwanger/", "tokens": ["Wie", "er", "stets", "gieng", "mit", "blit\u00b7zen", "schwan\u00b7ger", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "VVFIN", "APPR", "VVFIN", "ADJD", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Um sich unendlich feuer schmi\u00df.", "tokens": ["Um", "sich", "un\u00b7end\u00b7lich", "feu\u00b7er", "schmi\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PRF", "ADJD", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "O schauplatz aller grausamkeiten!", "tokens": ["O", "schau\u00b7platz", "al\u00b7ler", "grau\u00b7sam\u00b7kei\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Dort sah man wenig Christen streiten/", "tokens": ["Dort", "sah", "man", "we\u00b7nig", "Chris\u00b7ten", "strei\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "PIAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Die kaum ein enger wall umschlo\u00df.", "tokens": ["Die", "kaum", "ein", "en\u00b7ger", "wall", "um\u00b7schlo\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Hier liessen des Hircanus s\u00f6hne", "tokens": ["Hier", "lies\u00b7sen", "des", "Hir\u00b7ca\u00b7nus", "s\u00f6h\u00b7ne"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Mit zitternd-bebendem geth\u00f6ne", "tokens": ["Mit", "zit\u00b7tern\u00b7dbe\u00b7ben\u00b7dem", "ge\u00b7th\u00f6\u00b7ne"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Abscheulich h\u00f6ren ihr gescho\u00df.", "tokens": ["Ab\u00b7scheu\u00b7lich", "h\u00f6\u00b7ren", "ihr", "ge\u00b7scho\u00df", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "VVFIN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.6": {"line.1": {"text": "Die blancken spie\u00df und schwerdter klungen/", "tokens": ["Die", "blan\u00b7cken", "spie\u00df", "und", "schwerd\u00b7ter", "klun\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "KON", "ADJD", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Das runde bley die kugeln sprungen", "tokens": ["Das", "run\u00b7de", "bley", "die", "ku\u00b7geln", "sprun\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Mit lichtem schwefel \u00fcberall/", "tokens": ["Mit", "lich\u00b7tem", "schwe\u00b7fel", "\u00fc\u00b7be\u00b7rall", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ADV", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und die ge\u00e4ngsten anger stunden/", "tokens": ["Und", "die", "ge\u00b7\u00e4ngs\u00b7ten", "an\u00b7ger", "stun\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "ADJA", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Sich gleichsam wie beschw\u00e4rtzt befunden/", "tokens": ["Sich", "gleich\u00b7sam", "wie", "be\u00b7schw\u00e4rtzt", "be\u00b7fun\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADJD", "KOKOM", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Von der zerfleischten c\u00f6rper zahl.", "tokens": ["Von", "der", "zer\u00b7fleischten", "c\u00f6r\u00b7per", "zahl", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "ADJA", "NN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.7": {"line.1": {"text": "Uns reitzte tapfrer muth zu sterben", "tokens": ["Uns", "reitz\u00b7te", "tapf\u00b7rer", "muth", "zu", "ster\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADJA", "NN", "PTKZU", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Vors vaterland/ das zu verderben", "tokens": ["Vors", "va\u00b7ter\u00b7land", "/", "das", "zu", "ver\u00b7der\u00b7ben"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["APPRART", "NN", "$(", "PDS", "PTKZU", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Der bluthund emsig war bereit;", "tokens": ["Der", "blut\u00b7hund", "em\u00b7sig", "war", "be\u00b7reit", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "VAFIN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Er hat die leichen so gest\u00fcrtzet/", "tokens": ["Er", "hat", "die", "lei\u00b7chen", "so", "ge\u00b7st\u00fcrt\u00b7zet", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Gleichwie der m\u00e4der abgek\u00fcrtzet", "tokens": ["Gleich\u00b7wie", "der", "m\u00e4\u00b7der", "ab\u00b7ge\u00b7k\u00fcrt\u00b7zet"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Die gr\u00e4ser in der sommer-zeit.", "tokens": ["Die", "gr\u00e4\u00b7ser", "in", "der", "som\u00b7mer\u00b7zeit", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Viel tausend hat sein schwerdt gefressen/", "tokens": ["Viel", "tau\u00b7send", "hat", "sein", "schwerdt", "ge\u00b7fres\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVPP", "VAFIN", "PPOSAT", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wiewol so gar nicht zu vergessen", "tokens": ["Wie\u00b7wol", "so", "gar", "nicht", "zu", "ver\u00b7ges\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "ADV", "PTKNEG", "PTKZU", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Neuh\u00e4usels tapfrer helden-muth.", "tokens": ["Neu\u00b7h\u00e4u\u00b7sels", "tapf\u00b7rer", "hel\u00b7den\u00b7muth", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Es stritt/ und must es selber bl\u00fcten/", "tokens": ["Es", "stritt", "/", "und", "must", "es", "sel\u00b7ber", "bl\u00fc\u00b7ten", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$(", "KON", "VMFIN", "PPER", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "So wie\u00df es doch weit gr\u00f6\u00dfre fluthen", "tokens": ["So", "wie\u00df", "es", "doch", "weit", "gr\u00f6\u00df\u00b7re", "flut\u00b7hen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ADJD", "ADJA", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Gepre\u00dft aus der verfluchten brut.", "tokens": ["Ge\u00b7pre\u00dft", "aus", "der", "ver\u00b7fluch\u00b7ten", "brut", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Und ist es gleich schon \u00fcberwunden/", "tokens": ["Und", "ist", "es", "gleich", "schon", "\u00fc\u00b7berw\u00b7un\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ADV", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Hat doch auch da den sarg gefunden", "tokens": ["Hat", "doch", "auch", "da", "den", "sarg", "ge\u00b7fun\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "ADV", "ADV", "ART", "NN", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "So wohl das Scythische geschlecht:", "tokens": ["So", "wohl", "das", "Scyt\u00b7hi\u00b7sche", "ge\u00b7schlecht", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Das feld mit grasse vor bedecket/", "tokens": ["Das", "feld", "mit", "gras\u00b7se", "vor", "be\u00b7de\u00b7cket", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "APPR", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Ein grauen aber nun erwecket/", "tokens": ["Ein", "grau\u00b7en", "a\u00b7ber", "nun", "er\u00b7we\u00b7cket", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADV", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Ist zu des feindes kirchhof recht.", "tokens": ["Ist", "zu", "des", "fein\u00b7des", "kirch\u00b7hof", "recht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "ART", "ADJA", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Die abgefleischten bein und sch\u00e4del", "tokens": ["Die", "ab\u00b7ge\u00b7fleischten", "bein", "und", "sch\u00e4\u00b7del"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "KON", "ADJD"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Bezeugen mit der that/ wie edel", "tokens": ["Be\u00b7zeu\u00b7gen", "mit", "der", "that", "/", "wie", "e\u00b7del"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["NN", "APPR", "ART", "VVFIN", "$(", "PWAV", "ADJD"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Sich iederzeit der christ gestalt/", "tokens": ["Sich", "ie\u00b7der\u00b7zeit", "der", "christ", "ge\u00b7stalt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADV", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wie hurtig er im streit gewesen/", "tokens": ["Wie", "hur\u00b7tig", "er", "im", "streit", "ge\u00b7we\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "PPER", "APPRART", "NN", "VAPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Drumb wird man wenig von ihm lesen/", "tokens": ["Drumb", "wird", "man", "we\u00b7nig", "von", "ihm", "le\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "PIS", "ADV", "APPR", "PPER", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Sein ruhm sey nicht im blut erkalt.", "tokens": ["Sein", "ruhm", "sey", "nicht", "im", "blut", "er\u00b7kalt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "PTKNEG", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Erschr\u00f6ckter mensch von deinem feinde/", "tokens": ["Er\u00b7schr\u00f6ck\u00b7ter", "mensch", "von", "dei\u00b7nem", "fein\u00b7de", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "APPR", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Steh\u2019 auf und kiese den zum freunde/", "tokens": ["Steh'", "auf", "und", "kie\u00b7se", "den", "zum", "freun\u00b7de", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "KON", "VVFIN", "ART", "APPRART", "ADJA", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Den kein T\u00fcrck aus dem himmel treibt/", "tokens": ["Den", "kein", "T\u00fcrck", "aus", "dem", "him\u00b7mel", "treibt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "APPR", "ART", "NN", "VVFIN", "$("], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.4": {"text": "Und dencke nur getrost zu dulden/", "tokens": ["Und", "den\u00b7cke", "nur", "ge\u00b7trost", "zu", "dul\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ADJD", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Was du verdient mit deinen schulden/", "tokens": ["Was", "du", "ver\u00b7dient", "mit", "dei\u00b7nen", "schul\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVFIN", "APPR", "PPOSAT", "ADJA", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Die ruthe/ die dich itzund st\u00e4upt.", "tokens": ["Die", "ru\u00b7the", "/", "die", "dich", "it\u00b7zund", "st\u00e4upt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "$(", "PRELS", "PPER", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "La\u00df andachts-opfer GOtt erweichen/", "tokens": ["La\u00df", "an\u00b7dachts\u00b7op\u00b7fer", "Gott", "er\u00b7wei\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ADJA", "NN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "So wirst du wol f\u00fcr krieg und seuchen", "tokens": ["So", "wirst", "du", "wol", "f\u00fcr", "krieg", "und", "seu\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "APPR", "NN", "KON", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Befreyt und unversehret stehn;", "tokens": ["Be\u00b7freyt", "und", "un\u00b7ver\u00b7seh\u00b7ret", "stehn", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wil aber er ein ende machen/", "tokens": ["Wil", "a\u00b7ber", "er", "ein", "en\u00b7de", "ma\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "PPER", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "So kanst du/ wann die welt wird krachen/", "tokens": ["So", "kanst", "du", "/", "wann", "die", "welt", "wird", "kra\u00b7chen", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "$(", "PWAV", "ART", "NN", "VAFIN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Zugleich mit ihr zu grabe gehn.", "tokens": ["Zu\u00b7gleich", "mit", "ihr", "zu", "gra\u00b7be", "gehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPER", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}