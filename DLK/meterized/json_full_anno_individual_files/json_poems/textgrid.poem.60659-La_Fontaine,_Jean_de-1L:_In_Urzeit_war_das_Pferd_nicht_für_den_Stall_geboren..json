{"textgrid.poem.60659": {"metadata": {"author": {"name": "La Fontaine, Jean de", "birth": "N.A.", "death": "N.A."}, "title": "1L: In Urzeit war das Pferd nicht f\u00fcr den Stall geboren.", "genre": "verse", "period": "N.A.", "pub_year": 1658, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "In Urzeit war das Pferd nicht f\u00fcr den Stall geboren.", "tokens": ["In", "Ur\u00b7zeit", "war", "das", "Pferd", "nicht", "f\u00fcr", "den", "Stall", "ge\u00b7bo\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VAFIN", "ART", "NN", "PTKNEG", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Als sich die Menschheit noch von Eicheln n\u00e4hrte,", "tokens": ["Als", "sich", "die", "Menschheit", "noch", "von", "Ei\u00b7cheln", "n\u00e4hr\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "ART", "NN", "ADV", "APPR", "NN", "VVFIN", "$,"], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}, "line.3": {"text": "Vergn\u00fcgten sich im Wald die Esel und die Pferde.", "tokens": ["Ver\u00b7gn\u00fcg\u00b7ten", "sich", "im", "Wald", "die", "E\u00b7sel", "und", "die", "Pfer\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "APPRART", "NN", "ART", "NN", "KON", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Man wu\u00dfte nichts von S\u00e4tteln und von Sporen,", "tokens": ["Man", "wu\u00df\u00b7te", "nichts", "von", "S\u00e4t\u00b7teln", "und", "von", "Spo\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PIS", "APPR", "NN", "KON", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Von R\u00fcstzeug nichts f\u00fcr Streit und Schlacht,", "tokens": ["Von", "R\u00fcst\u00b7zeug", "nichts", "f\u00fcr", "Streit", "und", "Schlacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PIS", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und hat an Z\u00fcgel, Zaum und Wagen nicht gedacht;", "tokens": ["Und", "hat", "an", "Z\u00fc\u00b7gel", ",", "Zaum", "und", "Wa\u00b7gen", "nicht", "ge\u00b7dacht", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "APPR", "NN", "$,", "NN", "KON", "NN", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und wurden Heiraten geschlossen,", "tokens": ["Und", "wur\u00b7den", "Hei\u00b7ra\u00b7ten", "ge\u00b7schlos\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Bedurfte es dazu nicht pr\u00e4chtiger Karossen.", "tokens": ["Be\u00b7durf\u00b7te", "es", "da\u00b7zu", "nicht", "pr\u00e4ch\u00b7ti\u00b7ger", "Ka\u00b7ros\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PAV", "PTKNEG", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Nun lag zu jener Zeit", "tokens": ["Nun", "lag", "zu", "je\u00b7ner", "Zeit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "APPR", "PDAT", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.10": {"text": "Einmal ein Pferd mit einem schnellen Hirsch in Streit,", "tokens": ["Ein\u00b7mal", "ein", "Pferd", "mit", "ei\u00b7nem", "schnel\u00b7len", "Hirsch", "in", "Streit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "APPR", "ART", "ADJA", "NN", "APPR", "NN", "$,"], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.11": {"text": "Und da es laufend ihn nicht zu erreichen", "tokens": ["Und", "da", "es", "lau\u00b7fend", "ihn", "nicht", "zu", "er\u00b7rei\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "ADJD", "PPER", "PTKNEG", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Vermochte, flehte es den Menschen an,", "tokens": ["Ver\u00b7moch\u00b7te", ",", "fleh\u00b7te", "es", "den", "Men\u00b7schen", "an", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "VVFIN", "PPER", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "Ihm beizustehn mit listigen Streichen.", "tokens": ["Ihm", "bei\u00b7zu\u00b7stehn", "mit", "lis\u00b7ti\u00b7gen", "Strei\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.14": {"text": "Der Mensch war willig und ersann", "tokens": ["Der", "Mensch", "war", "wil\u00b7lig", "und", "er\u00b7sann"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ADJD", "KON", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Den Z\u00fcgel, sprang dem Pferde auf den R\u00fccken", "tokens": ["Den", "Z\u00fc\u00b7gel", ",", "sprang", "dem", "Pfer\u00b7de", "auf", "den", "R\u00fc\u00b7cken"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "VVFIN", "ART", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.16": {"text": "Und trieb es, bis der Hirsch erjagt war und erschlagen.", "tokens": ["Und", "trieb", "es", ",", "bis", "der", "Hirsch", "er\u00b7jagt", "war", "und", "er\u00b7schla\u00b7gen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "$,", "APPR", "ART", "NN", "VVPP", "VAFIN", "KON", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Das Pferd sprach voll Entz\u00fccken", "tokens": ["Das", "Pferd", "sprach", "voll", "Ent\u00b7z\u00fc\u00b7cken"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ADJD", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.18": {"text": "Dem Menschen Dank. Dann wollte Lebewohl es sagen", "tokens": ["Dem", "Men\u00b7schen", "Dank", ".", "Dann", "woll\u00b7te", "Le\u00b7be\u00b7wohl", "es", "sa\u00b7gen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "NN", "$.", "ADV", "VMFIN", "NN", "PPER", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Und w\u00e4re gern zum Wald zur\u00fcckgekehrt.", "tokens": ["Und", "w\u00e4\u00b7re", "gern", "zum", "Wald", "zu\u00b7r\u00fcck\u00b7ge\u00b7kehrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.20": {"text": "\u00bbnicht so!\u00ab sprach da der Mensch zum Pferd;", "tokens": ["\u00bb", "nicht", "so", "!", "\u00ab", "sprach", "da", "der", "Mensch", "zum", "Pferd", ";"], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PTKNEG", "ADV", "$.", "$(", "VVFIN", "ADV", "ART", "NN", "APPRART", "NN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.21": {"text": "\u00bbwozu du brauchbar bist und wert,", "tokens": ["\u00bb", "wo\u00b7zu", "du", "brauch\u00b7bar", "bist", "und", "wert", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWAV", "PPER", "ADJD", "VAFIN", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.22": {"text": "Das hast du selbst mich gut gelehrt.", "tokens": ["Das", "hast", "du", "selbst", "mich", "gut", "ge\u00b7lehrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "ADV", "PPER", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.23": {"text": "Du bleibst bei mir! Ich will dich pflegen,", "tokens": ["Du", "bleibst", "bei", "mir", "!", "Ich", "will", "dich", "pfle\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPER", "$.", "PPER", "VMFIN", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.24": {"text": "Will bis zum Bauch in Stroh und Heu dich legen.\u00ab", "tokens": ["Will", "bis", "zum", "Bauch", "in", "Stroh", "und", "Heu", "dich", "le\u00b7gen", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VMFIN", "ADV", "APPRART", "NN", "APPR", "NN", "KON", "NN", "PPER", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.25": {"text": "Ach, ist der reichste Nahrungssegen", "tokens": ["Ach", ",", "ist", "der", "reichs\u00b7te", "Nah\u00b7rungs\u00b7se\u00b7gen"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["ITJ", "$,", "VAFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.26": {"text": "F\u00fcr Freiheit jemals ein Ersatz?", "tokens": ["F\u00fcr", "Frei\u00b7heit", "je\u00b7mals", "ein", "Er\u00b7satz", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.27": {"text": "Dem Pferde wurde seine Torheit klar.", "tokens": ["Dem", "Pfer\u00b7de", "wur\u00b7de", "sei\u00b7ne", "Tor\u00b7heit", "klar", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPOSAT", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.28": {"text": "Bereits der Stall als sein zuk\u00fcnftiger Platz.", "tokens": ["Be\u00b7reits", "der", "Stall", "als", "sein", "zu\u00b7k\u00fcnf\u00b7ti\u00b7ger", "Platz", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "KOKOM", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.29": {"text": "In Fesseln sah sein Leben es entfliehen.", "tokens": ["In", "Fes\u00b7seln", "sah", "sein", "Le\u00b7ben", "es", "ent\u00b7flie\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PPOSAT", "NN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.30": {"text": "Oh h\u00e4tt es damals weise jenem Hirsch verziehen!", "tokens": ["Oh", "h\u00e4tt", "es", "da\u00b7mals", "wei\u00b7se", "je\u00b7nem", "Hirsch", "ver\u00b7zie\u00b7hen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["XY", "VAFIN", "PPER", "ADV", "VVFIN", "PDAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Wie gro\u00df auch immer mag Befriedigung sein", "tokens": ["Wie", "gro\u00df", "auch", "im\u00b7mer", "mag", "Be\u00b7frie\u00b7di\u00b7gung", "sein"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADJD", "ADV", "ADV", "VMFIN", "NN", "PPOSAT"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.2": {"text": "Gestillten Rachedurstes, ist sie klein", "tokens": ["Ge\u00b7still\u00b7ten", "Ra\u00b7che\u00b7durs\u00b7tes", ",", "ist", "sie", "klein"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ADJA", "NN", "$,", "VAFIN", "PPER", "ADJD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Doch gegen Freiheit: jenes Gut,", "tokens": ["Doch", "ge\u00b7gen", "Frei\u00b7heit", ":", "je\u00b7nes", "Gut", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "$.", "PDAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Darin der h\u00f6chste Wert des Lebens ruht.", "tokens": ["Da\u00b7rin", "der", "h\u00f6chs\u00b7te", "Wert", "des", "Le\u00b7bens", "ruht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "ADJA", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "In Urzeit war das Pferd nicht f\u00fcr den Stall geboren.", "tokens": ["In", "Ur\u00b7zeit", "war", "das", "Pferd", "nicht", "f\u00fcr", "den", "Stall", "ge\u00b7bo\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VAFIN", "ART", "NN", "PTKNEG", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Als sich die Menschheit noch von Eicheln n\u00e4hrte,", "tokens": ["Als", "sich", "die", "Menschheit", "noch", "von", "Ei\u00b7cheln", "n\u00e4hr\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "ART", "NN", "ADV", "APPR", "NN", "VVFIN", "$,"], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}, "line.3": {"text": "Vergn\u00fcgten sich im Wald die Esel und die Pferde.", "tokens": ["Ver\u00b7gn\u00fcg\u00b7ten", "sich", "im", "Wald", "die", "E\u00b7sel", "und", "die", "Pfer\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "APPRART", "NN", "ART", "NN", "KON", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Man wu\u00dfte nichts von S\u00e4tteln und von Sporen,", "tokens": ["Man", "wu\u00df\u00b7te", "nichts", "von", "S\u00e4t\u00b7teln", "und", "von", "Spo\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PIS", "APPR", "NN", "KON", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Von R\u00fcstzeug nichts f\u00fcr Streit und Schlacht,", "tokens": ["Von", "R\u00fcst\u00b7zeug", "nichts", "f\u00fcr", "Streit", "und", "Schlacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PIS", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und hat an Z\u00fcgel, Zaum und Wagen nicht gedacht;", "tokens": ["Und", "hat", "an", "Z\u00fc\u00b7gel", ",", "Zaum", "und", "Wa\u00b7gen", "nicht", "ge\u00b7dacht", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "APPR", "NN", "$,", "NN", "KON", "NN", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und wurden Heiraten geschlossen,", "tokens": ["Und", "wur\u00b7den", "Hei\u00b7ra\u00b7ten", "ge\u00b7schlos\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Bedurfte es dazu nicht pr\u00e4chtiger Karossen.", "tokens": ["Be\u00b7durf\u00b7te", "es", "da\u00b7zu", "nicht", "pr\u00e4ch\u00b7ti\u00b7ger", "Ka\u00b7ros\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PAV", "PTKNEG", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Nun lag zu jener Zeit", "tokens": ["Nun", "lag", "zu", "je\u00b7ner", "Zeit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "APPR", "PDAT", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.10": {"text": "Einmal ein Pferd mit einem schnellen Hirsch in Streit,", "tokens": ["Ein\u00b7mal", "ein", "Pferd", "mit", "ei\u00b7nem", "schnel\u00b7len", "Hirsch", "in", "Streit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "APPR", "ART", "ADJA", "NN", "APPR", "NN", "$,"], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.11": {"text": "Und da es laufend ihn nicht zu erreichen", "tokens": ["Und", "da", "es", "lau\u00b7fend", "ihn", "nicht", "zu", "er\u00b7rei\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "ADJD", "PPER", "PTKNEG", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Vermochte, flehte es den Menschen an,", "tokens": ["Ver\u00b7moch\u00b7te", ",", "fleh\u00b7te", "es", "den", "Men\u00b7schen", "an", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "VVFIN", "PPER", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "Ihm beizustehn mit listigen Streichen.", "tokens": ["Ihm", "bei\u00b7zu\u00b7stehn", "mit", "lis\u00b7ti\u00b7gen", "Strei\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.14": {"text": "Der Mensch war willig und ersann", "tokens": ["Der", "Mensch", "war", "wil\u00b7lig", "und", "er\u00b7sann"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ADJD", "KON", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Den Z\u00fcgel, sprang dem Pferde auf den R\u00fccken", "tokens": ["Den", "Z\u00fc\u00b7gel", ",", "sprang", "dem", "Pfer\u00b7de", "auf", "den", "R\u00fc\u00b7cken"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "VVFIN", "ART", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.16": {"text": "Und trieb es, bis der Hirsch erjagt war und erschlagen.", "tokens": ["Und", "trieb", "es", ",", "bis", "der", "Hirsch", "er\u00b7jagt", "war", "und", "er\u00b7schla\u00b7gen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "$,", "APPR", "ART", "NN", "VVPP", "VAFIN", "KON", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Das Pferd sprach voll Entz\u00fccken", "tokens": ["Das", "Pferd", "sprach", "voll", "Ent\u00b7z\u00fc\u00b7cken"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ADJD", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.18": {"text": "Dem Menschen Dank. Dann wollte Lebewohl es sagen", "tokens": ["Dem", "Men\u00b7schen", "Dank", ".", "Dann", "woll\u00b7te", "Le\u00b7be\u00b7wohl", "es", "sa\u00b7gen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "NN", "$.", "ADV", "VMFIN", "NN", "PPER", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Und w\u00e4re gern zum Wald zur\u00fcckgekehrt.", "tokens": ["Und", "w\u00e4\u00b7re", "gern", "zum", "Wald", "zu\u00b7r\u00fcck\u00b7ge\u00b7kehrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.20": {"text": "\u00bbnicht so!\u00ab sprach da der Mensch zum Pferd;", "tokens": ["\u00bb", "nicht", "so", "!", "\u00ab", "sprach", "da", "der", "Mensch", "zum", "Pferd", ";"], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PTKNEG", "ADV", "$.", "$(", "VVFIN", "ADV", "ART", "NN", "APPRART", "NN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.21": {"text": "\u00bbwozu du brauchbar bist und wert,", "tokens": ["\u00bb", "wo\u00b7zu", "du", "brauch\u00b7bar", "bist", "und", "wert", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWAV", "PPER", "ADJD", "VAFIN", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.22": {"text": "Das hast du selbst mich gut gelehrt.", "tokens": ["Das", "hast", "du", "selbst", "mich", "gut", "ge\u00b7lehrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "ADV", "PPER", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.23": {"text": "Du bleibst bei mir! Ich will dich pflegen,", "tokens": ["Du", "bleibst", "bei", "mir", "!", "Ich", "will", "dich", "pfle\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPER", "$.", "PPER", "VMFIN", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.24": {"text": "Will bis zum Bauch in Stroh und Heu dich legen.\u00ab", "tokens": ["Will", "bis", "zum", "Bauch", "in", "Stroh", "und", "Heu", "dich", "le\u00b7gen", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VMFIN", "ADV", "APPRART", "NN", "APPR", "NN", "KON", "NN", "PPER", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.25": {"text": "Ach, ist der reichste Nahrungssegen", "tokens": ["Ach", ",", "ist", "der", "reichs\u00b7te", "Nah\u00b7rungs\u00b7se\u00b7gen"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["ITJ", "$,", "VAFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.26": {"text": "F\u00fcr Freiheit jemals ein Ersatz?", "tokens": ["F\u00fcr", "Frei\u00b7heit", "je\u00b7mals", "ein", "Er\u00b7satz", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.27": {"text": "Dem Pferde wurde seine Torheit klar.", "tokens": ["Dem", "Pfer\u00b7de", "wur\u00b7de", "sei\u00b7ne", "Tor\u00b7heit", "klar", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPOSAT", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.28": {"text": "Bereits der Stall als sein zuk\u00fcnftiger Platz.", "tokens": ["Be\u00b7reits", "der", "Stall", "als", "sein", "zu\u00b7k\u00fcnf\u00b7ti\u00b7ger", "Platz", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "KOKOM", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.29": {"text": "In Fesseln sah sein Leben es entfliehen.", "tokens": ["In", "Fes\u00b7seln", "sah", "sein", "Le\u00b7ben", "es", "ent\u00b7flie\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PPOSAT", "NN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.30": {"text": "Oh h\u00e4tt es damals weise jenem Hirsch verziehen!", "tokens": ["Oh", "h\u00e4tt", "es", "da\u00b7mals", "wei\u00b7se", "je\u00b7nem", "Hirsch", "ver\u00b7zie\u00b7hen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["XY", "VAFIN", "PPER", "ADV", "VVFIN", "PDAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Wie gro\u00df auch immer mag Befriedigung sein", "tokens": ["Wie", "gro\u00df", "auch", "im\u00b7mer", "mag", "Be\u00b7frie\u00b7di\u00b7gung", "sein"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADJD", "ADV", "ADV", "VMFIN", "NN", "PPOSAT"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.2": {"text": "Gestillten Rachedurstes, ist sie klein", "tokens": ["Ge\u00b7still\u00b7ten", "Ra\u00b7che\u00b7durs\u00b7tes", ",", "ist", "sie", "klein"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ADJA", "NN", "$,", "VAFIN", "PPER", "ADJD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Doch gegen Freiheit: jenes Gut,", "tokens": ["Doch", "ge\u00b7gen", "Frei\u00b7heit", ":", "je\u00b7nes", "Gut", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "$.", "PDAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Darin der h\u00f6chste Wert des Lebens ruht.", "tokens": ["Da\u00b7rin", "der", "h\u00f6chs\u00b7te", "Wert", "des", "Le\u00b7bens", "ruht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "ADJA", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}}}}