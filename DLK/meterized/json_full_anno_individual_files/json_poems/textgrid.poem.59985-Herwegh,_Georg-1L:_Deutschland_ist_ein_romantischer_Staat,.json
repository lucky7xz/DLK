{"textgrid.poem.59985": {"metadata": {"author": {"name": "Herwegh, Georg", "birth": "N.A.", "death": "N.A."}, "title": "1L: Deutschland ist ein romantischer Staat,", "genre": "verse", "period": "N.A.", "pub_year": 1846, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Deutschland ist ein romantischer Staat,", "tokens": ["Deutschland", "ist", "ein", "ro\u00b7man\u00b7ti\u00b7scher", "Staat", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "+--+---+", "measure": "dactylic.di.plus"}, "line.2": {"text": "Der des Gedankens Mondschein", "tokens": ["Der", "des", "Ge\u00b7dan\u00b7kens", "Mond\u00b7schein"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ART", "NN", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Vorzieht der klassischen Sonne der Tat \u2013", "tokens": ["Vor\u00b7zieht", "der", "klas\u00b7si\u00b7schen", "Son\u00b7ne", "der", "Tat", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "ART", "NN", "$("], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Man mu\u00df halt alles gewohnt sein.", "tokens": ["Man", "mu\u00df", "halt", "al\u00b7les", "ge\u00b7wohnt", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "VVFIN", "PIS", "VVPP", "VAINF", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.2": {"line.1": {"text": "Den italienischen Stiefel nimmt", "tokens": ["Den", "i\u00b7ta\u00b7li\u00b7e\u00b7ni\u00b7schen", "Stie\u00b7fel", "nimmt"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN"], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Und wird gestiefelter Kater", "tokens": ["Und", "wird", "ge\u00b7stie\u00b7fel\u00b7ter", "Ka\u00b7ter"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VAFIN", "ADJA", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Herr Viktor \u2013 so was t\u00e4te bestimmt", "tokens": ["Herr", "Vik\u00b7tor", "\u2013", "so", "was", "t\u00e4\u00b7te", "be\u00b7stimmt"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "NE", "$(", "ADV", "PWS", "VVFIN", "VVPP"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Kein deutscher Landesvater.", "tokens": ["Kein", "deut\u00b7scher", "Lan\u00b7des\u00b7va\u00b7ter", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Die Strippen des Stiefels beh\u00e4lt sich vor", "tokens": ["Die", "Strip\u00b7pen", "des", "Stie\u00b7fels", "be\u00b7h\u00e4lt", "sich", "vor"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "NN", "VVFIN", "PRF", "APPR"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Der kleine S\u00fcnder Hannes \u2013", "tokens": ["Der", "klei\u00b7ne", "S\u00fcn\u00b7der", "Han\u00b7nes", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NE", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Was Karl nicht konnte, kann Franz Moor;", "tokens": ["Was", "Karl", "nicht", "konn\u00b7te", ",", "kann", "Franz", "Moor", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "NE", "PTKNEG", "VMFIN", "$,", "VMFIN", "NE", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Doch Deutschland \u2013 sag, was kann es?", "tokens": ["Doch", "Deutschland", "\u2013", "sag", ",", "was", "kann", "es", "?"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "NE", "$(", "VVIMP", "$,", "PWS", "VMFIN", "PPER", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.4": {"line.1": {"text": "Kann lesen und schreiben, das ist wahr,", "tokens": ["Kann", "le\u00b7sen", "und", "schrei\u00b7ben", ",", "das", "ist", "wahr", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VMFIN", "VVINF", "KON", "VVINF", "$,", "PDS", "VAFIN", "ADJD", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Auch sehr viel Tinte vergie\u00dft es.", "tokens": ["Auch", "sehr", "viel", "Tin\u00b7te", "ver\u00b7gie\u00dft", "es", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PIAT", "NN", "VVFIN", "PPER", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Das Pulver hat's erfunden sogar;", "tokens": ["Das", "Pul\u00b7ver", "hat's", "er\u00b7fun\u00b7den", "so\u00b7gar", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVPP", "ADV", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Doch Deutschland \u2013 sag, wo schie\u00dft es?", "tokens": ["Doch", "Deutschland", "\u2013", "sag", ",", "wo", "schie\u00dft", "es", "?"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "NE", "$(", "VVIMP", "$,", "PWAV", "VVFIN", "PPER", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.5": {"line.1": {"text": "Es blitzt des Krieges Wetterstrahl,", "tokens": ["Es", "blitzt", "des", "Krie\u00b7ges", "Wet\u00b7ter\u00b7strahl", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Doch Deutschland \u2013 sag, wo blitzt es?", "tokens": ["Doch", "Deutschland", "\u2013", "sag", ",", "wo", "blitzt", "es", "?"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "NE", "$(", "VVIMP", "$,", "PWAV", "VVFIN", "PPER", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Die V\u00f6lker sitzen beim Friedensmahl,", "tokens": ["Die", "V\u00f6l\u00b7ker", "sit\u00b7zen", "beim", "Frie\u00b7dens\u00b7mahl", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Doch Deutschland \u2013 sag, wo sitzt es?", "tokens": ["Doch", "Deutschland", "\u2013", "sag", ",", "wo", "sitzt", "es", "?"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "NE", "$(", "VVIMP", "$,", "PWAV", "VVFIN", "PPER", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.6": {"line.1": {"text": "Zu sitzen wieder wie Anno acht", "tokens": ["Zu", "sit\u00b7zen", "wie\u00b7der", "wie", "An\u00b7no", "acht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PTKZU", "VVINF", "ADV", "KOKOM", "NN", "CARD"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Und vierzig in Frankfurt dacht es;", "tokens": ["Und", "vier\u00b7zig", "in", "Frank\u00b7furt", "dacht", "es", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "CARD", "APPR", "NE", "VVFIN", "PPER", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Doch wenn es ein Parlament gemacht:", "tokens": ["Doch", "wenn", "es", "ein", "Par\u00b7la\u00b7ment", "ge\u00b7macht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ART", "NN", "VVPP", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Das Parlament, was macht es?", "tokens": ["Das", "Par\u00b7la\u00b7ment", ",", "was", "macht", "es", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PWS", "VVFIN", "PPER", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Deutschland ist ein romantischer Staat,", "tokens": ["Deutschland", "ist", "ein", "ro\u00b7man\u00b7ti\u00b7scher", "Staat", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "+--+---+", "measure": "dactylic.di.plus"}, "line.2": {"text": "Der des Gedankens Mondschein", "tokens": ["Der", "des", "Ge\u00b7dan\u00b7kens", "Mond\u00b7schein"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ART", "NN", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Vorzieht der klassischen Sonne der Tat \u2013", "tokens": ["Vor\u00b7zieht", "der", "klas\u00b7si\u00b7schen", "Son\u00b7ne", "der", "Tat", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "ART", "NN", "$("], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Man mu\u00df halt alles gewohnt sein.", "tokens": ["Man", "mu\u00df", "halt", "al\u00b7les", "ge\u00b7wohnt", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "VVFIN", "PIS", "VVPP", "VAINF", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.8": {"line.1": {"text": "Den italienischen Stiefel nimmt", "tokens": ["Den", "i\u00b7ta\u00b7li\u00b7e\u00b7ni\u00b7schen", "Stie\u00b7fel", "nimmt"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN"], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Und wird gestiefelter Kater", "tokens": ["Und", "wird", "ge\u00b7stie\u00b7fel\u00b7ter", "Ka\u00b7ter"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VAFIN", "ADJA", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Herr Viktor \u2013 so was t\u00e4te bestimmt", "tokens": ["Herr", "Vik\u00b7tor", "\u2013", "so", "was", "t\u00e4\u00b7te", "be\u00b7stimmt"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "NE", "$(", "ADV", "PWS", "VVFIN", "VVPP"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Kein deutscher Landesvater.", "tokens": ["Kein", "deut\u00b7scher", "Lan\u00b7des\u00b7va\u00b7ter", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Die Strippen des Stiefels beh\u00e4lt sich vor", "tokens": ["Die", "Strip\u00b7pen", "des", "Stie\u00b7fels", "be\u00b7h\u00e4lt", "sich", "vor"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "NN", "VVFIN", "PRF", "APPR"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Der kleine S\u00fcnder Hannes \u2013", "tokens": ["Der", "klei\u00b7ne", "S\u00fcn\u00b7der", "Han\u00b7nes", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NE", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Was Karl nicht konnte, kann Franz Moor;", "tokens": ["Was", "Karl", "nicht", "konn\u00b7te", ",", "kann", "Franz", "Moor", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "NE", "PTKNEG", "VMFIN", "$,", "VMFIN", "NE", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Doch Deutschland \u2013 sag, was kann es?", "tokens": ["Doch", "Deutschland", "\u2013", "sag", ",", "was", "kann", "es", "?"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "NE", "$(", "VVIMP", "$,", "PWS", "VMFIN", "PPER", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.10": {"line.1": {"text": "Kann lesen und schreiben, das ist wahr,", "tokens": ["Kann", "le\u00b7sen", "und", "schrei\u00b7ben", ",", "das", "ist", "wahr", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VMFIN", "VVINF", "KON", "VVINF", "$,", "PDS", "VAFIN", "ADJD", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Auch sehr viel Tinte vergie\u00dft es.", "tokens": ["Auch", "sehr", "viel", "Tin\u00b7te", "ver\u00b7gie\u00dft", "es", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PIAT", "NN", "VVFIN", "PPER", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Das Pulver hat's erfunden sogar;", "tokens": ["Das", "Pul\u00b7ver", "hat's", "er\u00b7fun\u00b7den", "so\u00b7gar", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVPP", "ADV", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Doch Deutschland \u2013 sag, wo schie\u00dft es?", "tokens": ["Doch", "Deutschland", "\u2013", "sag", ",", "wo", "schie\u00dft", "es", "?"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "NE", "$(", "VVIMP", "$,", "PWAV", "VVFIN", "PPER", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.11": {"line.1": {"text": "Es blitzt des Krieges Wetterstrahl,", "tokens": ["Es", "blitzt", "des", "Krie\u00b7ges", "Wet\u00b7ter\u00b7strahl", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Doch Deutschland \u2013 sag, wo blitzt es?", "tokens": ["Doch", "Deutschland", "\u2013", "sag", ",", "wo", "blitzt", "es", "?"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "NE", "$(", "VVIMP", "$,", "PWAV", "VVFIN", "PPER", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Die V\u00f6lker sitzen beim Friedensmahl,", "tokens": ["Die", "V\u00f6l\u00b7ker", "sit\u00b7zen", "beim", "Frie\u00b7dens\u00b7mahl", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Doch Deutschland \u2013 sag, wo sitzt es?", "tokens": ["Doch", "Deutschland", "\u2013", "sag", ",", "wo", "sitzt", "es", "?"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "NE", "$(", "VVIMP", "$,", "PWAV", "VVFIN", "PPER", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.12": {"line.1": {"text": "Zu sitzen wieder wie Anno acht", "tokens": ["Zu", "sit\u00b7zen", "wie\u00b7der", "wie", "An\u00b7no", "acht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PTKZU", "VVINF", "ADV", "KOKOM", "NN", "CARD"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Und vierzig in Frankfurt dacht es;", "tokens": ["Und", "vier\u00b7zig", "in", "Frank\u00b7furt", "dacht", "es", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "CARD", "APPR", "NE", "VVFIN", "PPER", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Doch wenn es ein Parlament gemacht:", "tokens": ["Doch", "wenn", "es", "ein", "Par\u00b7la\u00b7ment", "ge\u00b7macht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ART", "NN", "VVPP", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Das Parlament, was macht es?", "tokens": ["Das", "Par\u00b7la\u00b7ment", ",", "was", "macht", "es", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PWS", "VVFIN", "PPER", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}}}}