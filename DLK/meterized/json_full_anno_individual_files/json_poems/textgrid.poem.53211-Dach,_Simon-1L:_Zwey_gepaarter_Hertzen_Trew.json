{"textgrid.poem.53211": {"metadata": {"author": {"name": "Dach, Simon", "birth": "N.A.", "death": "N.A."}, "title": "1L: Zwey gepaarter Hertzen Trew", "genre": "verse", "period": "N.A.", "pub_year": 1632, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Zwey gepaarter Hertzen Trew", "tokens": ["Zwey", "ge\u00b7paar\u00b7ter", "Hert\u00b7zen", "Trew"], "token_info": ["word", "word", "word", "word"], "pos": ["CARD", "ADJA", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Hat f\u00fcr keinem Wetter schew,", "tokens": ["Hat", "f\u00fcr", "kei\u00b7nem", "Wet\u00b7ter", "schew", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "PIAT", "NN", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Geht mit unbewegtem Sinn", "tokens": ["Geht", "mit", "un\u00b7be\u00b7weg\u00b7tem", "Sinn"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Durch Gefahr und Grauen hin,", "tokens": ["Durch", "Ge\u00b7fahr", "und", "Grau\u00b7en", "hin", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Die Lieb' ist ihr Gewinn.", "tokens": ["Die", "Lieb'", "ist", "ihr", "Ge\u00b7winn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Dringen auff sie Hell und Tod", "tokens": ["Drin\u00b7gen", "auff", "sie", "Hell", "und", "Tod"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "PPER", "NE", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Vnd was irgends ist f\u00fcr Noht,", "tokens": ["Vnd", "was", "ir\u00b7gends", "ist", "f\u00fcr", "Noht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ADV", "VAFIN", "APPR", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Sie verlachen Brand und Schwerd,", "tokens": ["Sie", "ver\u00b7la\u00b7chen", "Brand", "und", "Schwerd", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "So uns dieser Zeit verheert,", "tokens": ["So", "uns", "die\u00b7ser", "Zeit", "ver\u00b7heert", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "PDAT", "NN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Vnd sind in sich gekehrt.", "tokens": ["Vnd", "sind", "in", "sich", "ge\u00b7kehrt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "APPR", "PRF", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Vrsach, ihre Glut mu\u00df rein", "tokens": ["Vr\u00b7sach", ",", "ih\u00b7re", "Glut", "mu\u00df", "rein"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NE", "$,", "PPOSAT", "NN", "VMFIN", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Von der Erd' und himmlisch seyn,", "tokens": ["Von", "der", "Erd'", "und", "himm\u00b7lisch", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "KON", "ADJD", "VAINF", "$,"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.3": {"text": "Darumb ist sie f\u00fcr der Zeit,", "tokens": ["Da\u00b7rumb", "ist", "sie", "f\u00fcr", "der", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Was Gewalt und Angst sie dreut,", "tokens": ["Was", "Ge\u00b7walt", "und", "Angst", "sie", "dreut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "KON", "NN", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Gesichert und befreyt.", "tokens": ["Ge\u00b7si\u00b7chert", "und", "be\u00b7freyt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVPP", "KON", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "F\u00fcgt der reinen Vnschuld Hand", "tokens": ["F\u00fcgt", "der", "rei\u00b7nen", "Vn\u00b7schuld", "Hand"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "ADJA", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Sie durch [ei]n geheiligt Band,", "tokens": ["Sie", "durch", "ei", "n", "ge\u00b7hei\u00b7ligt", "Band", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "$(", "XY", "XY", "XY", "VVPP", "NN", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.3": {"text": ". . . . . . . . . . . . t auff Erden, so", "tokens": [".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", "t", "auff", "Er\u00b7den", ",", "so"], "token_info": ["punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "word", "word", "word", "punct", "word"], "pos": ["$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "VVFIN", "APPR", "NN", "$,", "ADV"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.4": {"text": ". . . . . . . . . . . . . . . schen Loh", "tokens": [".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", "schen", "Loh"], "token_info": ["punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "word", "word"], "pos": ["$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "ADJA", "NN"], "meter": "-+", "measure": "iambic.single"}, "line.5": {"text": ". . . . . . . . . . . . . eis ich, froh.", "tokens": [".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", "eis", "ich", ",", "froh", "."], "token_info": ["punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "word", "word", "punct", "word", "punct"], "pos": ["$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "FM.la", "FM.la", "$,", "ADJD", "$."], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.5": {"line.1": {"text": "Seiten werden da ger\u00fchrt,", "tokens": ["Sei\u00b7ten", "wer\u00b7den", "da", "ge\u00b7r\u00fchrt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ADV", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Ja auch T\u00e4ntze wol gef\u00fchrt,", "tokens": ["Ja", "auch", "T\u00e4nt\u00b7ze", "wol", "ge\u00b7f\u00fchrt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "ADV", "NN", "ADV", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Weil ihm \u00fcberaus gef\u00e4llt,", "tokens": ["Weil", "ihm", "\u00fc\u00b7be\u00b7raus", "ge\u00b7f\u00e4llt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wenn in reiner Treu die Welt", "tokens": ["Wenn", "in", "rei\u00b7ner", "Treu", "die", "Welt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "APPR", "ADJA", "NN", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Verliebt zusammen h\u00e4lt.", "tokens": ["Ver\u00b7liebt", "zu\u00b7sam\u00b7men", "h\u00e4lt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Selig sind wir in gemein,", "tokens": ["Se\u00b7lig", "sind", "wir", "in", "ge\u00b7mein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PPER", "APPR", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Reget uns die Lieb' allein,", "tokens": ["Re\u00b7get", "uns", "die", "Lieb'", "al\u00b7lein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Die, gesaubert von dem Zwist", "tokens": ["Die", ",", "ge\u00b7sau\u00b7bert", "von", "dem", "Zwist"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["ART", "$,", "VVPP", "APPR", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Dieser Welt, zu aller frist", "tokens": ["Die\u00b7ser", "Welt", ",", "zu", "al\u00b7ler", "frist"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PDAT", "NN", "$,", "APPR", "PIAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Des Himmels Wesen ist.", "tokens": ["Des", "Him\u00b7mels", "We\u00b7sen", "ist", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Zwey gepaarter Hertzen Trew", "tokens": ["Zwey", "ge\u00b7paar\u00b7ter", "Hert\u00b7zen", "Trew"], "token_info": ["word", "word", "word", "word"], "pos": ["CARD", "ADJA", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Hat f\u00fcr keinem Wetter schew,", "tokens": ["Hat", "f\u00fcr", "kei\u00b7nem", "Wet\u00b7ter", "schew", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "PIAT", "NN", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Geht mit unbewegtem Sinn", "tokens": ["Geht", "mit", "un\u00b7be\u00b7weg\u00b7tem", "Sinn"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Durch Gefahr und Grauen hin,", "tokens": ["Durch", "Ge\u00b7fahr", "und", "Grau\u00b7en", "hin", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Die Lieb' ist ihr Gewinn.", "tokens": ["Die", "Lieb'", "ist", "ihr", "Ge\u00b7winn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Dringen auff sie Hell und Tod", "tokens": ["Drin\u00b7gen", "auff", "sie", "Hell", "und", "Tod"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "PPER", "NE", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Vnd was irgends ist f\u00fcr Noht,", "tokens": ["Vnd", "was", "ir\u00b7gends", "ist", "f\u00fcr", "Noht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ADV", "VAFIN", "APPR", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Sie verlachen Brand und Schwerd,", "tokens": ["Sie", "ver\u00b7la\u00b7chen", "Brand", "und", "Schwerd", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "So uns dieser Zeit verheert,", "tokens": ["So", "uns", "die\u00b7ser", "Zeit", "ver\u00b7heert", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "PDAT", "NN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Vnd sind in sich gekehrt.", "tokens": ["Vnd", "sind", "in", "sich", "ge\u00b7kehrt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "APPR", "PRF", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Vrsach, ihre Glut mu\u00df rein", "tokens": ["Vr\u00b7sach", ",", "ih\u00b7re", "Glut", "mu\u00df", "rein"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NE", "$,", "PPOSAT", "NN", "VMFIN", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Von der Erd' und himmlisch seyn,", "tokens": ["Von", "der", "Erd'", "und", "himm\u00b7lisch", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "KON", "ADJD", "VAINF", "$,"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.3": {"text": "Darumb ist sie f\u00fcr der Zeit,", "tokens": ["Da\u00b7rumb", "ist", "sie", "f\u00fcr", "der", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Was Gewalt und Angst sie dreut,", "tokens": ["Was", "Ge\u00b7walt", "und", "Angst", "sie", "dreut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "KON", "NN", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Gesichert und befreyt.", "tokens": ["Ge\u00b7si\u00b7chert", "und", "be\u00b7freyt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVPP", "KON", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "F\u00fcgt der reinen Vnschuld Hand", "tokens": ["F\u00fcgt", "der", "rei\u00b7nen", "Vn\u00b7schuld", "Hand"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "ADJA", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Sie durch [ei]n geheiligt Band,", "tokens": ["Sie", "durch", "ei", "n", "ge\u00b7hei\u00b7ligt", "Band", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "$(", "XY", "XY", "XY", "VVPP", "NN", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.3": {"text": ". . . . . . . . . . . . t auff Erden, so", "tokens": [".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", "t", "auff", "Er\u00b7den", ",", "so"], "token_info": ["punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "word", "word", "word", "punct", "word"], "pos": ["$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "VVFIN", "APPR", "NN", "$,", "ADV"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.4": {"text": ". . . . . . . . . . . . . . . schen Loh", "tokens": [".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", "schen", "Loh"], "token_info": ["punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "word", "word"], "pos": ["$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "ADJA", "NN"], "meter": "-+", "measure": "iambic.single"}, "line.5": {"text": ". . . . . . . . . . . . . eis ich, froh.", "tokens": [".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", "eis", "ich", ",", "froh", "."], "token_info": ["punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "word", "word", "punct", "word", "punct"], "pos": ["$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "FM.la", "FM.la", "$,", "ADJD", "$."], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.11": {"line.1": {"text": "Seiten werden da ger\u00fchrt,", "tokens": ["Sei\u00b7ten", "wer\u00b7den", "da", "ge\u00b7r\u00fchrt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ADV", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Ja auch T\u00e4ntze wol gef\u00fchrt,", "tokens": ["Ja", "auch", "T\u00e4nt\u00b7ze", "wol", "ge\u00b7f\u00fchrt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "ADV", "NN", "ADV", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Weil ihm \u00fcberaus gef\u00e4llt,", "tokens": ["Weil", "ihm", "\u00fc\u00b7be\u00b7raus", "ge\u00b7f\u00e4llt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wenn in reiner Treu die Welt", "tokens": ["Wenn", "in", "rei\u00b7ner", "Treu", "die", "Welt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "APPR", "ADJA", "NN", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Verliebt zusammen h\u00e4lt.", "tokens": ["Ver\u00b7liebt", "zu\u00b7sam\u00b7men", "h\u00e4lt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "Selig sind wir in gemein,", "tokens": ["Se\u00b7lig", "sind", "wir", "in", "ge\u00b7mein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PPER", "APPR", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Reget uns die Lieb' allein,", "tokens": ["Re\u00b7get", "uns", "die", "Lieb'", "al\u00b7lein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Die, gesaubert von dem Zwist", "tokens": ["Die", ",", "ge\u00b7sau\u00b7bert", "von", "dem", "Zwist"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["ART", "$,", "VVPP", "APPR", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Dieser Welt, zu aller frist", "tokens": ["Die\u00b7ser", "Welt", ",", "zu", "al\u00b7ler", "frist"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PDAT", "NN", "$,", "APPR", "PIAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Des Himmels Wesen ist.", "tokens": ["Des", "Him\u00b7mels", "We\u00b7sen", "ist", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}}}}