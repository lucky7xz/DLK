{"textgrid.poem.42393": {"metadata": {"author": {"name": "Lachmann, Hedwig", "birth": "N.A.", "death": "N.A."}, "title": "1L: Du gibst mir F\u00fclle, Gl\u00fcck, Gen\u00fcge, Weihe;", "genre": "verse", "period": "N.A.", "pub_year": 1891, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Du gibst mir F\u00fclle, Gl\u00fcck, Gen\u00fcge, Weihe;", "tokens": ["Du", "gibst", "mir", "F\u00fcl\u00b7le", ",", "Gl\u00fcck", ",", "Ge\u00b7n\u00fc\u00b7ge", ",", "Wei\u00b7he", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Du breitetest ein Los vor mich, so klar,", "tokens": ["Du", "brei\u00b7te\u00b7test", "ein", "Los", "vor", "mich", ",", "so", "klar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "PPER", "$,", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Dass, sanft gef\u00fcgt zu einer goldnen Reihe,", "tokens": ["Dass", ",", "sanft", "ge\u00b7f\u00fcgt", "zu", "ei\u00b7ner", "gold\u00b7nen", "Rei\u00b7he", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "$,", "ADJD", "VVPP", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "An mir vor\u00fcbergleitet Jahr um Jahr.", "tokens": ["An", "mir", "vor\u00b7\u00fc\u00b7berg\u00b7lei\u00b7tet", "Jahr", "um", "Jahr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVFIN", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Mir ist, als ob in deiner Hut gedeihe", "tokens": ["Mir", "ist", ",", "als", "ob", "in", "dei\u00b7ner", "Hut", "ge\u00b7dei\u00b7he"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "$,", "KOKOM", "KOUS", "APPR", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Das Kargste, das in mir verschlossen war,", "tokens": ["Das", "Kargs\u00b7te", ",", "das", "in", "mir", "ver\u00b7schlos\u00b7sen", "war", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "APPR", "PPER", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Als ob dein starker Sinn mir Mut verleihe,", "tokens": ["Als", "ob", "dein", "star\u00b7ker", "Sinn", "mir", "Mut", "ver\u00b7lei\u00b7he", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "PPOSAT", "ADJA", "NN", "PPER", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Reichst du mir nur dein Wort zum St\u00fctzpunkt dar.", "tokens": ["Reichst", "du", "mir", "nur", "dein", "Wort", "zum", "St\u00fctz\u00b7punkt", "dar", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "ADV", "PPOSAT", "NN", "APPRART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "War ich vereinsamt, eh ich dich gekannt?", "tokens": ["War", "ich", "ver\u00b7ein\u00b7samt", ",", "eh", "ich", "dich", "ge\u00b7kannt", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "VVPP", "$,", "KOUS", "PPER", "PRF", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Kamst du zu mir, wie oft in letzter Stunde", "tokens": ["Kamst", "du", "zu", "mir", ",", "wie", "oft", "in", "letz\u00b7ter", "Stun\u00b7de"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "APPR", "PPER", "$,", "PWAV", "ADV", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Noch Rettung naht, und riefst mich auf zum Bunde?", "tokens": ["Noch", "Ret\u00b7tung", "naht", ",", "und", "riefst", "mich", "auf", "zum", "Bun\u00b7de", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "VVFIN", "$,", "KON", "VVFIN", "PRF", "APPR", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Ich weiss nur, dies ist alles wie zerronnen,", "tokens": ["Ich", "weiss", "nur", ",", "dies", "ist", "al\u00b7les", "wie", "zer\u00b7ron\u00b7nen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "PDS", "VAFIN", "PIS", "KOKOM", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Als h\u00e4tte ich mein Leben neu begonnen \u2013", "tokens": ["Als", "h\u00e4t\u00b7te", "ich", "mein", "Le\u00b7ben", "neu", "be\u00b7gon\u00b7nen", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VAFIN", "PPER", "PPOSAT", "NN", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und bin doch allen Schmerzen noch verwandt!", "tokens": ["Und", "bin", "doch", "al\u00b7len", "Schmer\u00b7zen", "noch", "ver\u00b7wandt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "PIAT", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "Du gibst mir F\u00fclle, Gl\u00fcck, Gen\u00fcge, Weihe;", "tokens": ["Du", "gibst", "mir", "F\u00fcl\u00b7le", ",", "Gl\u00fcck", ",", "Ge\u00b7n\u00fc\u00b7ge", ",", "Wei\u00b7he", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Du breitetest ein Los vor mich, so klar,", "tokens": ["Du", "brei\u00b7te\u00b7test", "ein", "Los", "vor", "mich", ",", "so", "klar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "PPER", "$,", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Dass, sanft gef\u00fcgt zu einer goldnen Reihe,", "tokens": ["Dass", ",", "sanft", "ge\u00b7f\u00fcgt", "zu", "ei\u00b7ner", "gold\u00b7nen", "Rei\u00b7he", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "$,", "ADJD", "VVPP", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "An mir vor\u00fcbergleitet Jahr um Jahr.", "tokens": ["An", "mir", "vor\u00b7\u00fc\u00b7berg\u00b7lei\u00b7tet", "Jahr", "um", "Jahr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVFIN", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "Mir ist, als ob in deiner Hut gedeihe", "tokens": ["Mir", "ist", ",", "als", "ob", "in", "dei\u00b7ner", "Hut", "ge\u00b7dei\u00b7he"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "$,", "KOKOM", "KOUS", "APPR", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Das Kargste, das in mir verschlossen war,", "tokens": ["Das", "Kargs\u00b7te", ",", "das", "in", "mir", "ver\u00b7schlos\u00b7sen", "war", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "APPR", "PPER", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Als ob dein starker Sinn mir Mut verleihe,", "tokens": ["Als", "ob", "dein", "star\u00b7ker", "Sinn", "mir", "Mut", "ver\u00b7lei\u00b7he", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "PPOSAT", "ADJA", "NN", "PPER", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Reichst du mir nur dein Wort zum St\u00fctzpunkt dar.", "tokens": ["Reichst", "du", "mir", "nur", "dein", "Wort", "zum", "St\u00fctz\u00b7punkt", "dar", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "ADV", "PPOSAT", "NN", "APPRART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.7": {"line.1": {"text": "War ich vereinsamt, eh ich dich gekannt?", "tokens": ["War", "ich", "ver\u00b7ein\u00b7samt", ",", "eh", "ich", "dich", "ge\u00b7kannt", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "VVPP", "$,", "KOUS", "PPER", "PRF", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Kamst du zu mir, wie oft in letzter Stunde", "tokens": ["Kamst", "du", "zu", "mir", ",", "wie", "oft", "in", "letz\u00b7ter", "Stun\u00b7de"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "APPR", "PPER", "$,", "PWAV", "ADV", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Noch Rettung naht, und riefst mich auf zum Bunde?", "tokens": ["Noch", "Ret\u00b7tung", "naht", ",", "und", "riefst", "mich", "auf", "zum", "Bun\u00b7de", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "VVFIN", "$,", "KON", "VVFIN", "PRF", "APPR", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.8": {"line.1": {"text": "Ich weiss nur, dies ist alles wie zerronnen,", "tokens": ["Ich", "weiss", "nur", ",", "dies", "ist", "al\u00b7les", "wie", "zer\u00b7ron\u00b7nen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "PDS", "VAFIN", "PIS", "KOKOM", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Als h\u00e4tte ich mein Leben neu begonnen \u2013", "tokens": ["Als", "h\u00e4t\u00b7te", "ich", "mein", "Le\u00b7ben", "neu", "be\u00b7gon\u00b7nen", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VAFIN", "PPER", "PPOSAT", "NN", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und bin doch allen Schmerzen noch verwandt!", "tokens": ["Und", "bin", "doch", "al\u00b7len", "Schmer\u00b7zen", "noch", "ver\u00b7wandt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "PIAT", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}}}}