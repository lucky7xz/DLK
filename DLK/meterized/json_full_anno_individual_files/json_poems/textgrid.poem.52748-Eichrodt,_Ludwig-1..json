{"textgrid.poem.52748": {"metadata": {"author": {"name": "Eichrodt, Ludwig", "birth": "N.A.", "death": "N.A."}, "title": "1.", "genre": "verse", "period": "N.A.", "pub_year": 1859, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ich bin ein Turner wohlgemuth,", "tokens": ["Ich", "bin", "ein", "Tur\u00b7ner", "wohl\u00b7ge\u00b7muth", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mit vollen Backen, rothem Blut,", "tokens": ["Mit", "vol\u00b7len", "Ba\u00b7cken", ",", "ro\u00b7them", "Blut", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mir ist der W\u00fcstling stets verha\u00dft,", "tokens": ["Mir", "ist", "der", "W\u00fcst\u00b7ling", "stets", "ver\u00b7ha\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der seiner Eltern Gut verpra\u00dft.", "tokens": ["Der", "sei\u00b7ner", "El\u00b7tern", "Gut", "ver\u00b7pra\u00dft", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Der Turner ist ein Ehrenmann,", "tokens": ["Der", "Tur\u00b7ner", "ist", "ein", "Eh\u00b7ren\u00b7mann", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der ausgezeichnet krebseln kann,", "tokens": ["Der", "aus\u00b7ge\u00b7zeich\u00b7net", "kreb\u00b7seln", "kann", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Er schwingt sich zw\u00f6lfmal auf am Reck,", "tokens": ["Er", "schwingt", "sich", "zw\u00f6lf\u00b7mal", "auf", "am", "Reck", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "ADV", "APPR", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und Centnersteine schmei\u00dft er weg.", "tokens": ["Und", "Cent\u00b7ner\u00b7stei\u00b7ne", "schmei\u00dft", "er", "weg", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Vor'm Heuchler nimmt er sich in Acht,", "tokens": ["Vor'm", "Heuch\u00b7ler", "nimmt", "er", "sich", "in", "Acht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PPER", "PRF", "APPR", "CARD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Vor falschem Freund und Ofenpacht,", "tokens": ["Vor", "fal\u00b7schem", "Freund", "und", "O\u00b7fen\u00b7pacht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Geschn\u00fcrtes Wesen ist ihm Gr\u00e4u'l,", "tokens": ["Ge\u00b7schn\u00fcr\u00b7tes", "We\u00b7sen", "ist", "ihm", "Gr\u00e4u'l", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VAFIN", "PPER", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und keine Felswand ihm zu steil.", "tokens": ["Und", "kei\u00b7ne", "Fels\u00b7wand", "ihm", "zu", "steil", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "PPER", "PTKA", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Er legt sich muthig in das Bett,", "tokens": ["Er", "legt", "sich", "mut\u00b7hig", "in", "das", "Bett", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "ADJD", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wenn's dunkel, doch nicht allzusp\u00e4t.", "tokens": ["Wenn's", "dun\u00b7kel", ",", "doch", "nicht", "all\u00b7zu\u00b7sp\u00e4t", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJD", "$,", "ADV", "PTKNEG", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Er ist schon wieder auf dem Bein,", "tokens": ["Er", "ist", "schon", "wie\u00b7der", "auf", "dem", "Bein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wenn in der Fr\u00fch' die Gockler schrei'n.", "tokens": ["Wenn", "in", "der", "Fr\u00fch'", "die", "Gock\u00b7ler", "schrei'", "n."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "abbreviation"], "pos": ["KOUS", "APPR", "ART", "NN", "ART", "NN", "VVFIN", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Er wei\u00df daf\u00fcr den edeln Grund,", "tokens": ["Er", "wei\u00df", "da\u00b7f\u00fcr", "den", "e\u00b7deln", "Grund", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PAV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df Morgenstund' hat Gold im Mund;", "tokens": ["Da\u00df", "Mor\u00b7gen\u00b7stund'", "hat", "Gold", "im", "Mund", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "VAFIN", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Dann zieht er auf den Tummelort,", "tokens": ["Dann", "zieht", "er", "auf", "den", "Tum\u00b7me\u00b7lort", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und Gott im Himmel ist sein Hort.", "tokens": ["Und", "Gott", "im", "Him\u00b7mel", "ist", "sein", "Hort", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "APPRART", "NN", "VAFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Feind ist er schn\u00f6dem W\u00e4lschlingsbub,", "tokens": ["Feind", "ist", "er", "schn\u00f6\u00b7dem", "W\u00e4l\u00b7schlings\u00b7bub", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mit Schwarzbrod, mit Kartoffelsupp',", "tokens": ["Mit", "Schwarz\u00b7brod", ",", "mit", "Kar\u00b7tof\u00b7fel\u00b7sup\u00b7p'", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "APPR", "NE", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Mit frischem Obst und etwas Fleisch", "tokens": ["Mit", "fri\u00b7schem", "Obst", "und", "et\u00b7was", "Fleisch"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "KON", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Bleibt er zufrieden, frei und keusch.", "tokens": ["Bleibt", "er", "zu\u00b7frie\u00b7den", ",", "frei", "und", "keusch", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "$,", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "So lebt der Turner frei und frank,", "tokens": ["So", "lebt", "der", "Tur\u00b7ner", "frei", "und", "frank", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ADJD", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Seuchen baar und sonder Wank,", "tokens": ["Der", "Seu\u00b7chen", "baar", "und", "son\u00b7der", "Wank", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Auch \u00fcbt er edlen Wissensdurst,", "tokens": ["Auch", "\u00fcbt", "er", "ed\u00b7len", "Wis\u00b7sens\u00b7durst", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und Sturm und Regen ist ihm Wurst.", "tokens": ["Und", "Sturm", "und", "Re\u00b7gen", "ist", "ihm", "Wurst", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "KON", "NN", "VAFIN", "PPER", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Die deutsche Hausfrau f\u00fchrt er heim,", "tokens": ["Die", "deut\u00b7sche", "Haus\u00b7frau", "f\u00fchrt", "er", "heim", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und legt in's Kind des Turnens Keim,", "tokens": ["Und", "legt", "in's", "Kind", "des", "Tur\u00b7nens", "Keim", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPRART", "NN", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Auf da\u00df es einstmals werd' entbrannt,", "tokens": ["Auf", "da\u00df", "es", "einst\u00b7mals", "werd'", "ent\u00b7brannt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "KOUS", "PPER", "ADV", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "F\u00fcr Freiheit, F\u00fcrst und Vaterland!!", "tokens": ["F\u00fcr", "Frei\u00b7heit", ",", "F\u00fcrst", "und", "Va\u00b7ter\u00b7land", "!!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Ich bin ein Turner wohlgemuth,", "tokens": ["Ich", "bin", "ein", "Tur\u00b7ner", "wohl\u00b7ge\u00b7muth", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mit vollen Backen, rothem Blut,", "tokens": ["Mit", "vol\u00b7len", "Ba\u00b7cken", ",", "ro\u00b7them", "Blut", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mir ist der W\u00fcstling stets verha\u00dft,", "tokens": ["Mir", "ist", "der", "W\u00fcst\u00b7ling", "stets", "ver\u00b7ha\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der seiner Eltern Gut verpra\u00dft.", "tokens": ["Der", "sei\u00b7ner", "El\u00b7tern", "Gut", "ver\u00b7pra\u00dft", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Der Turner ist ein Ehrenmann,", "tokens": ["Der", "Tur\u00b7ner", "ist", "ein", "Eh\u00b7ren\u00b7mann", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der ausgezeichnet krebseln kann,", "tokens": ["Der", "aus\u00b7ge\u00b7zeich\u00b7net", "kreb\u00b7seln", "kann", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Er schwingt sich zw\u00f6lfmal auf am Reck,", "tokens": ["Er", "schwingt", "sich", "zw\u00f6lf\u00b7mal", "auf", "am", "Reck", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "ADV", "APPR", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und Centnersteine schmei\u00dft er weg.", "tokens": ["Und", "Cent\u00b7ner\u00b7stei\u00b7ne", "schmei\u00dft", "er", "weg", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Vor'm Heuchler nimmt er sich in Acht,", "tokens": ["Vor'm", "Heuch\u00b7ler", "nimmt", "er", "sich", "in", "Acht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PPER", "PRF", "APPR", "CARD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Vor falschem Freund und Ofenpacht,", "tokens": ["Vor", "fal\u00b7schem", "Freund", "und", "O\u00b7fen\u00b7pacht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Geschn\u00fcrtes Wesen ist ihm Gr\u00e4u'l,", "tokens": ["Ge\u00b7schn\u00fcr\u00b7tes", "We\u00b7sen", "ist", "ihm", "Gr\u00e4u'l", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VAFIN", "PPER", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und keine Felswand ihm zu steil.", "tokens": ["Und", "kei\u00b7ne", "Fels\u00b7wand", "ihm", "zu", "steil", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "PPER", "PTKA", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Er legt sich muthig in das Bett,", "tokens": ["Er", "legt", "sich", "mut\u00b7hig", "in", "das", "Bett", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "ADJD", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wenn's dunkel, doch nicht allzusp\u00e4t.", "tokens": ["Wenn's", "dun\u00b7kel", ",", "doch", "nicht", "all\u00b7zu\u00b7sp\u00e4t", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJD", "$,", "ADV", "PTKNEG", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Er ist schon wieder auf dem Bein,", "tokens": ["Er", "ist", "schon", "wie\u00b7der", "auf", "dem", "Bein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wenn in der Fr\u00fch' die Gockler schrei'n.", "tokens": ["Wenn", "in", "der", "Fr\u00fch'", "die", "Gock\u00b7ler", "schrei'", "n."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "abbreviation"], "pos": ["KOUS", "APPR", "ART", "NN", "ART", "NN", "VVFIN", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Er wei\u00df daf\u00fcr den edeln Grund,", "tokens": ["Er", "wei\u00df", "da\u00b7f\u00fcr", "den", "e\u00b7deln", "Grund", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PAV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df Morgenstund' hat Gold im Mund;", "tokens": ["Da\u00df", "Mor\u00b7gen\u00b7stund'", "hat", "Gold", "im", "Mund", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "VAFIN", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Dann zieht er auf den Tummelort,", "tokens": ["Dann", "zieht", "er", "auf", "den", "Tum\u00b7me\u00b7lort", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und Gott im Himmel ist sein Hort.", "tokens": ["Und", "Gott", "im", "Him\u00b7mel", "ist", "sein", "Hort", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "APPRART", "NN", "VAFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Feind ist er schn\u00f6dem W\u00e4lschlingsbub,", "tokens": ["Feind", "ist", "er", "schn\u00f6\u00b7dem", "W\u00e4l\u00b7schlings\u00b7bub", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mit Schwarzbrod, mit Kartoffelsupp',", "tokens": ["Mit", "Schwarz\u00b7brod", ",", "mit", "Kar\u00b7tof\u00b7fel\u00b7sup\u00b7p'", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "APPR", "NE", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Mit frischem Obst und etwas Fleisch", "tokens": ["Mit", "fri\u00b7schem", "Obst", "und", "et\u00b7was", "Fleisch"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "KON", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Bleibt er zufrieden, frei und keusch.", "tokens": ["Bleibt", "er", "zu\u00b7frie\u00b7den", ",", "frei", "und", "keusch", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "$,", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "So lebt der Turner frei und frank,", "tokens": ["So", "lebt", "der", "Tur\u00b7ner", "frei", "und", "frank", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ADJD", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Seuchen baar und sonder Wank,", "tokens": ["Der", "Seu\u00b7chen", "baar", "und", "son\u00b7der", "Wank", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Auch \u00fcbt er edlen Wissensdurst,", "tokens": ["Auch", "\u00fcbt", "er", "ed\u00b7len", "Wis\u00b7sens\u00b7durst", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und Sturm und Regen ist ihm Wurst.", "tokens": ["Und", "Sturm", "und", "Re\u00b7gen", "ist", "ihm", "Wurst", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "KON", "NN", "VAFIN", "PPER", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "Die deutsche Hausfrau f\u00fchrt er heim,", "tokens": ["Die", "deut\u00b7sche", "Haus\u00b7frau", "f\u00fchrt", "er", "heim", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und legt in's Kind des Turnens Keim,", "tokens": ["Und", "legt", "in's", "Kind", "des", "Tur\u00b7nens", "Keim", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPRART", "NN", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Auf da\u00df es einstmals werd' entbrannt,", "tokens": ["Auf", "da\u00df", "es", "einst\u00b7mals", "werd'", "ent\u00b7brannt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "KOUS", "PPER", "ADV", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "F\u00fcr Freiheit, F\u00fcrst und Vaterland!!", "tokens": ["F\u00fcr", "Frei\u00b7heit", ",", "F\u00fcrst", "und", "Va\u00b7ter\u00b7land", "!!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}