{"textgrid.poem.42281": {"metadata": {"author": {"name": "B\u00fcrger, Gottfried August", "birth": "N.A.", "death": "N.A."}, "title": "Der Raubgraf", "genre": "verse", "period": "N.A.", "pub_year": 1773, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Es liegt nicht weit von hier ein Land,", "tokens": ["Es", "liegt", "nicht", "weit", "von", "hier", "ein", "Land", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "ADJD", "APPR", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da reist' ich einst hindurch;", "tokens": ["Da", "reist'", "ich", "einst", "hin\u00b7durch", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "PAV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Am Weg' auf hohem Felsen stand,", "tokens": ["Am", "Weg'", "auf", "ho\u00b7hem", "Fel\u00b7sen", "stand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Vor alters, eine Burg.", "tokens": ["Vor", "al\u00b7ters", ",", "ei\u00b7ne", "Burg", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ADJA", "$,", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Die alten Rudera davon", "tokens": ["Die", "al\u00b7ten", "Ru\u00b7de\u00b7ra", "da\u00b7von"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "PAV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wies mir der Schwager Postillon.", "tokens": ["Wies", "mir", "der", "Schwa\u00b7ger", "Pos\u00b7til\u00b7lon", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ART", "NN", "NE", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}}, "stanza.2": {"line.1": {"text": "\u00bbmein Herr, begann der Schwager Matz,", "tokens": ["\u00bb", "mein", "Herr", ",", "be\u00b7gann", "der", "Schwa\u00b7ger", "Matz", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPOSAT", "NN", "$,", "VVFIN", "ART", "NN", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mit heimlichem Gesicht,", "tokens": ["Mit", "heim\u00b7li\u00b7chem", "Ge\u00b7sicht", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "W\u00e4r' mir beschert dort jener Schatz,", "tokens": ["W\u00e4r'", "mir", "be\u00b7schert", "dort", "je\u00b7ner", "Schatz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "VVFIN", "ADV", "PDAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "F\u00fchr' ich den Herrn wohl nicht.", "tokens": ["F\u00fchr'", "ich", "den", "Herrn", "wohl", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ART", "NN", "ADV", "PTKNEG", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Mein Seel! den K\u00f6nig fragt' ich gleich:", "tokens": ["Mein", "Seel", "!", "den", "K\u00f6\u00b7nig", "fragt'", "ich", "gleich", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$.", "ART", "NN", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wie teuer, Herr, sein K\u00f6nigreich?", "tokens": ["Wie", "teu\u00b7er", ",", "Herr", ",", "sein", "K\u00f6\u00b7nig\u00b7reich", "?"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "$,", "NN", "$,", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Wohl manchem w\u00e4sserte der Mund,", "tokens": ["Wohl", "man\u00b7chem", "w\u00e4s\u00b7ser\u00b7te", "der", "Mund", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Doch mancher ward geprellt.", "tokens": ["Doch", "man\u00b7cher", "ward", "ge\u00b7prellt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VAFIN", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Denn, Herr, Gott sei bei uns! Ein Hund", "tokens": ["Denn", ",", "Herr", ",", "Gott", "sei", "bei", "uns", "!", "Ein", "Hund"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "$,", "NN", "$,", "NN", "VAFIN", "APPR", "PPER", "$.", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Bewacht das sch\u00f6ne Geld.", "tokens": ["Be\u00b7wacht", "das", "sch\u00f6\u00b7ne", "Geld", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Ein schwarzer Hund, die Z\u00e4hne blo\u00df,", "tokens": ["Ein", "schwar\u00b7zer", "Hund", ",", "die", "Z\u00e4h\u00b7ne", "blo\u00df", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Mit Feueraugen, tellersgro\u00df!", "tokens": ["Mit", "Feu\u00b7er\u00b7au\u00b7gen", ",", "tel\u00b7lers\u00b7gro\u00df", "!"], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["APPR", "NN", "$,", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Nur immer alle sieben Jahr'", "tokens": ["Nur", "im\u00b7mer", "al\u00b7le", "sie\u00b7ben", "Jahr'"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "PIAT", "CARD", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "L\u00e4\u00dft sich ein Fl\u00e4mmchen sehn.", "tokens": ["L\u00e4\u00dft", "sich", "ein", "Fl\u00e4mm\u00b7chen", "sehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Dann mag ein Bock, kohlschwarz von Haar,", "tokens": ["Dann", "mag", "ein", "Bock", ",", "kohl\u00b7schwarz", "von", "Haar", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "NE", "$,", "ADJD", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Hebung wohl bestehn.", "tokens": ["Die", "He\u00b7bung", "wohl", "be\u00b7stehn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Um zw\u00f6lf Uhr in Walpurgis Nacht,", "tokens": ["Um", "zw\u00f6lf", "Uhr", "in", "Wal\u00b7pur\u00b7gis", "Nacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "CARD", "NN", "APPR", "NE", "NN", "$,"], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.6": {"text": "Wird der dem Unhold dargebracht.", "tokens": ["Wird", "der", "dem", "Un\u00b7hold", "dar\u00b7ge\u00b7bracht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Doch merk' eins nur des B\u00f6sen List!", "tokens": ["Doch", "merk'", "eins", "nur", "des", "B\u00f6\u00b7sen", "List", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIS", "ADV", "ART", "NN", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wo noch zum Ungel\u00fcck", "tokens": ["Wo", "noch", "zum", "Un\u00b7ge\u00b7l\u00fcck"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "ADV", "APPRART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Am Bock ein wei\u00dfes H\u00e4rchen ist,", "tokens": ["Am", "Bock", "ein", "wei\u00b7\u00dfes", "H\u00e4r\u00b7chen", "ist", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NE", "ART", "ADJA", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Alsdann: Ade, Genick!", "tokens": ["Als\u00b7dann", ":", "A\u00b7de", ",", "Ge\u00b7nick", "!"], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["ADV", "$.", "NN", "$,", "NN", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.5": {"text": "Den Kniff hat mancher nicht bedacht,", "tokens": ["Den", "Kniff", "hat", "man\u00b7cher", "nicht", "be\u00b7dacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PIS", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und sich um Leib und Seel' gebracht.", "tokens": ["Und", "sich", "um", "Leib", "und", "Seel'", "ge\u00b7bracht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "APPR", "NN", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "F\u00fcr meinen Part, mit gro\u00dfen Herrn,", "tokens": ["F\u00fcr", "mei\u00b7nen", "Part", ",", "mit", "gro\u00b7\u00dfen", "Herrn", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und Meister Urian,", "tokens": ["Und", "Meis\u00b7ter", "U\u00b7ri\u00b7an", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "NE", "NE", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "\u00c4\u00df' ich wohl keine Kirschen gern.", "tokens": ["\u00c4\u00df'", "ich", "wohl", "kei\u00b7ne", "Kir\u00b7schen", "gern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ADV", "PIAT", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Man l\u00e4uft verdammt oft an.", "tokens": ["Man", "l\u00e4uft", "ver\u00b7dammt", "oft", "an", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "VVFIN", "ADV", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Sie werfen einem, wie man spricht,", "tokens": ["Sie", "wer\u00b7fen", "ei\u00b7nem", ",", "wie", "man", "spricht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "$,", "PWAV", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Gern Stiel und Stein ins Angesicht.", "tokens": ["Gern", "Stiel", "und", "Stein", "ins", "An\u00b7ge\u00b7sicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "KON", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "D'rum rat ich immer: Lieber Christ,", "tokens": ["D'\u00b7rum", "rat", "ich", "im\u00b7mer", ":", "Lie\u00b7ber", "Christ", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "ADV", "$.", "ADJD", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "La\u00df dich mit keinem ein!", "tokens": ["La\u00df", "dich", "mit", "kei\u00b7nem", "ein", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "APPR", "PIS", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Wann der Kontrakt geschlossen ist,", "tokens": ["Wann", "der", "Kon\u00b7trakt", "ge\u00b7schlos\u00b7sen", "ist", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Bricht man dir Hals und Bein.", "tokens": ["Bricht", "man", "dir", "Hals", "und", "Bein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PPER", "NN", "KON", "NN", "$."], "meter": "++-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Trotz allen Klauseln, glaube du,", "tokens": ["Trotz", "al\u00b7len", "Klau\u00b7seln", ",", "glau\u00b7be", "du", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "$,", "VVFIN", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Macht jeder dir ein X f\u00fcr U. \u2013", "tokens": ["Macht", "je\u00b7der", "dir", "ein", "X", "f\u00fcr", "U.", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "abbreviation", "punct"], "pos": ["NN", "PIS", "PPER", "ART", "XY", "APPR", "NE", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.8": {"line.1": {"text": "Goldmacherei und Lotterie,", "tokens": ["Gold\u00b7ma\u00b7che\u00b7rei", "und", "Lot\u00b7te\u00b7rie", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Nach reichen Weibern frei'n,", "tokens": ["Nach", "rei\u00b7chen", "Wei\u00b7bern", "frei'n", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und Sch\u00e4tze graben, segnet nie,", "tokens": ["Und", "Sch\u00e4t\u00b7ze", "gra\u00b7ben", ",", "seg\u00b7net", "nie", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "NN", "VVINF", "$,", "VVFIN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wird manchen noch gereu'n.", "tokens": ["Wird", "man\u00b7chen", "noch", "ge\u00b7reu'", "n."], "token_info": ["word", "word", "word", "word", "abbreviation"], "pos": ["VAFIN", "PIS", "ADV", "ADJD", "NE"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Mein Spr\u00fcchlein hei\u00dft: Auf Gott vertrau,", "tokens": ["Mein", "Spr\u00fcch\u00b7lein", "hei\u00dft", ":", "Auf", "Gott", "ver\u00b7trau", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "$.", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Arbeite brav und leb' genau!", "tokens": ["Ar\u00b7bei\u00b7te", "brav", "und", "leb'", "ge\u00b7nau", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "KON", "VVFIN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Ein alter Graf, fuhr Schwager Matz", "tokens": ["Ein", "al\u00b7ter", "Graf", ",", "fuhr", "Schwa\u00b7ger", "Matz"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "VVFIN", "NE", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Nach seiner Weise fort,", "tokens": ["Nach", "sei\u00b7ner", "Wei\u00b7se", "fort", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Vergrub zu Olims Zeit den Schatz", "tokens": ["Ver\u00b7grub", "zu", "O\u00b7lims", "Zeit", "den", "Schatz"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "NE", "NN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "In seinem Keller dort.", "tokens": ["In", "sei\u00b7nem", "Kel\u00b7ler", "dort", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Der Graf, mein Herr, hie\u00df Graf von Rips,", "tokens": ["Der", "Graf", ",", "mein", "Herr", ",", "hie\u00df", "Graf", "von", "Rips", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PPOSAT", "NN", "$,", "VVFIN", "NE", "APPR", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ein Kraut, wie K\u00e4sebier und Lips.", "tokens": ["Ein", "Kraut", ",", "wie", "K\u00e4\u00b7se\u00b7bier", "und", "Lips", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PWAV", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Der streifte durch das ganze Land,", "tokens": ["Der", "streif\u00b7te", "durch", "das", "gan\u00b7ze", "Land", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mit Wagen, Ro\u00df und Mann,", "tokens": ["Mit", "Wa\u00b7gen", ",", "Ro\u00df", "und", "Mann", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und wo er was zu kapern fand,", "tokens": ["Und", "wo", "er", "was", "zu", "ka\u00b7pern", "fand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPER", "PIS", "PTKZU", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Da macht' er frisch sich d'ran.", "tokens": ["Da", "macht'", "er", "frisch", "sich", "d'\u00b7ran", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "PRF", "PTKVZ", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.5": {"text": "Wips! hatt' er's weg, wips! ging er", "tokens": ["Wips", "!", "hatt'", "er's", "weg", ",", "wips", "!", "ging", "er"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["NN", "$.", "VAFIN", "PIS", "PTKVZ", "$,", "ITJ", "$.", "VVFIN", "PPER"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Und schleppt' es heim auf seine Burg.", "tokens": ["Und", "schleppt'", "es", "heim", "auf", "sei\u00b7ne", "Burg", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PTKVZ", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Und wann er erst zu Loche sa\u00df,", "tokens": ["Und", "wann", "er", "erst", "zu", "Lo\u00b7che", "sa\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPER", "ADV", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So schlug mein Graf von Rips, \u2013", "tokens": ["So", "schlug", "mein", "Graf", "von", "Rips", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "APPR", "NE", "$,", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Denn hier that ihm kein Teufel was, \u2013", "tokens": ["Denn", "hier", "that", "ihm", "kein", "Teu\u00b7fel", "was", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "PIAT", "NN", "PWS", "$,", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Gar h\u00f6hnisch seinen Schnips.", "tokens": ["Gar", "h\u00f6h\u00b7nisch", "sei\u00b7nen", "Schnips", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Sein allverfluchtes Felsennest", "tokens": ["Sein", "all\u00b7ver\u00b7fluch\u00b7tes", "Fel\u00b7sen\u00b7nest"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "War, wie der K\u00f6nigstein, so fest.", "tokens": ["War", ",", "wie", "der", "K\u00f6\u00b7nig\u00b7stein", ",", "so", "fest", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "$,", "PWAV", "ART", "NN", "$,", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "So \u00fcbt' er nun gar lang' und oft", "tokens": ["So", "\u00fcbt'", "er", "nun", "gar", "lang'", "und", "oft"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ADV", "ADV", "KON", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Viel Bubenst\u00fccken aus,", "tokens": ["Viel", "Bu\u00b7ben\u00b7st\u00fc\u00b7cken", "aus", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PIAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und fiel den Nachbarn unverhofft", "tokens": ["Und", "fiel", "den", "Nach\u00b7barn", "un\u00b7ver\u00b7hofft"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ART", "NN", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "In Hof und Stall und Haus.", "tokens": ["In", "Hof", "und", "Stall", "und", "Haus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "KON", "NN", "KON", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Allein, der Krug geht, wie man spricht,", "tokens": ["Al\u00b7lein", ",", "der", "Krug", "geht", ",", "wie", "man", "spricht", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "ART", "NN", "VVFIN", "$,", "PWAV", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "So lang' zu Wasser, bis er bricht.", "tokens": ["So", "lang'", "zu", "Was\u00b7ser", ",", "bis", "er", "bricht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "NN", "$,", "KOUS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Das Ding verdro\u00df den Magistrat", "tokens": ["Das", "Ding", "ver\u00b7dro\u00df", "den", "Ma\u00b7gist\u00b7rat"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Im n\u00e4chsten St\u00e4dtchen sehr,", "tokens": ["Im", "n\u00e4chs\u00b7ten", "St\u00e4dt\u00b7chen", "sehr", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "ADV", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "D'rum riet der l\u00e4ngst auf klugen Rat", "tokens": ["D'\u00b7rum", "riet", "der", "l\u00e4ngst", "auf", "klu\u00b7gen", "Rat"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "ART", "ADV", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Bed\u00e4chtlich hin und her,", "tokens": ["Be\u00b7d\u00e4cht\u00b7lich", "hin", "und", "her", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "PTKVZ", "KON", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Und riet und riet \u2013 doch wei\u00df man wohl! \u2013", "tokens": ["Und", "riet", "und", "riet", "\u2013", "doch", "wei\u00df", "man", "wohl", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "KON", "VVFIN", "$(", "ADV", "VVFIN", "PIS", "ADV", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Die Herren rieten sich halb toll.", "tokens": ["Die", "Her\u00b7ren", "rie\u00b7ten", "sich", "halb", "toll", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PRF", "ADJD", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Da nun begab sich's da\u00df einsmals,", "tokens": ["Da", "nun", "be\u00b7gab", "sich's", "da\u00df", "eins\u00b7mals", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PIS", "KOUS", "ADV", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Ob vielem Teufelsspa\u00df,", "tokens": ["Ob", "vie\u00b7lem", "Teu\u00b7fels\u00b7spa\u00df", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ein Lumpenhexchen auf den Hals", "tokens": ["Ein", "Lum\u00b7pen\u00b7hex\u00b7chen", "auf", "den", "Hals"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "In Kett' und Banden sa\u00df.", "tokens": ["In", "Kett'", "und", "Ban\u00b7den", "sa\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Schon wetzte Meister Urian", "tokens": ["Schon", "wetz\u00b7te", "Meis\u00b7ter", "U\u00b7ri\u00b7an"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "NE", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Auf diesen Braten seinen Zahn.", "tokens": ["Auf", "die\u00b7sen", "Bra\u00b7ten", "sei\u00b7nen", "Zahn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "Dies Hexchen sprach: H\u00f6rt! La\u00dft mich frei,", "tokens": ["Dies", "Hex\u00b7chen", "sprach", ":", "H\u00f6rt", "!", "La\u00dft", "mich", "frei", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "NN", "VVFIN", "$.", "VVIMP", "$.", "VVIMP", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So schaff' ich ihn herein.", "tokens": ["So", "schaff'", "ich", "ihn", "her\u00b7ein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Wohl! sprach ein edler Rat, es sei!", "tokens": ["Wohl", "!", "sprach", "ein", "ed\u00b7ler", "Rat", ",", "es", "sei", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "$.", "VVFIN", "ART", "ADJA", "NN", "$,", "PPER", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und gab ihr oben d'rein", "tokens": ["Und", "gab", "ihr", "o\u00b7ben", "d'\u00b7rein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "ADV", "NE"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.5": {"text": "Ein eisern Privilegium,", "tokens": ["Ein", "ei\u00b7sern", "Pri\u00b7vi\u00b7le\u00b7gi\u00b7um", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.6": {"text": "Zu hexen frank und frei herum.", "tokens": ["Zu", "he\u00b7xen", "frank", "und", "frei", "he\u00b7rum", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "VVFIN", "KON", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "Ein n\u00e4rrscher Handel! Unsereins", "tokens": ["Ein", "n\u00e4rr\u00b7scher", "Han\u00b7del", "!", "Un\u00b7ser\u00b7eins"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["ART", "ADJA", "NN", "$.", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Th\u00e4t' nichts auf solchen Kauf.", "tokens": ["Th\u00e4t'", "nichts", "auf", "sol\u00b7chen", "Kauf", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Doch Satans Reich ist selten eins,", "tokens": ["Doch", "Sa\u00b7tans", "Reich", "ist", "sel\u00b7ten", "eins", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "NE", "VAFIN", "ADJD", "PIS", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und reibt sich selber auf.", "tokens": ["Und", "reibt", "sich", "sel\u00b7ber", "auf", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "ADV", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "F\u00fcr diesmal spielt die L\u00fcgenbrut", "tokens": ["F\u00fcr", "dies\u00b7mal", "spielt", "die", "L\u00fc\u00b7gen\u00b7brut"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ADV", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ihr St\u00fcckchen ehrlich und auch gut.", "tokens": ["Ihr", "St\u00fcck\u00b7chen", "ehr\u00b7lich", "und", "auch", "gut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADJD", "KON", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.17": {"line.1": {"text": "Sie kroch, als Kr\u00f6t', auf's R\u00e4uberschlo\u00df,", "tokens": ["Sie", "kroch", ",", "als", "Kr\u00f6t'", ",", "auf's", "R\u00e4u\u00b7ber\u00b7schlo\u00df", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "NN", "$,", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mit losem leisen Tritt,", "tokens": ["Mit", "lo\u00b7sem", "lei\u00b7sen", "Tritt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Verwandelte sich in das Ro\u00df,", "tokens": ["Ver\u00b7wan\u00b7del\u00b7te", "sich", "in", "das", "Ro\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Das Rips gew\u00f6hnlich ritt;", "tokens": ["Das", "Rips", "ge\u00b7w\u00f6hn\u00b7lich", "ritt", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Und als der Schlo\u00dfhahn kr\u00e4hte fr\u00fch,", "tokens": ["Und", "als", "der", "Schlo\u00df\u00b7hahn", "kr\u00e4h\u00b7te", "fr\u00fch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "VVFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Bestieg der Graf gesattelt sie.", "tokens": ["Be\u00b7stieg", "der", "Graf", "ge\u00b7sat\u00b7telt", "sie", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "VVPP", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.18": {"line.1": {"text": "Sie aber trug, trotz Gert' und Sporn,", "tokens": ["Sie", "a\u00b7ber", "trug", ",", "trotz", "Gert'", "und", "Sporn", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "$,", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So sehr er hieb und trat,", "tokens": ["So", "sehr", "er", "hieb", "und", "trat", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ihn, \u00fcber Stock und Stein und Dorn,", "tokens": ["Ihn", ",", "\u00fc\u00b7ber", "Stock", "und", "Stein", "und", "Dorn", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "APPR", "NN", "KON", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Gerades Wegs zur Stadt.", "tokens": ["Ge\u00b7ra\u00b7des", "Wegs", "zur", "Stadt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Fr\u00fch, als das Thor ward aufgethan,", "tokens": ["Fr\u00fch", ",", "als", "das", "Thor", "ward", "auf\u00b7ge\u00b7than", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "KOUS", "ART", "NN", "VAFIN", "VVPP", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.6": {"text": "Sieh da! kam unser Hexlein an.", "tokens": ["Sieh", "da", "!", "kam", "un\u00b7ser", "Hex\u00b7lein", "an", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "PTKVZ", "$.", "VVFIN", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.19": {"line.1": {"text": "Mit Kratzfu\u00df und mit Reverenz", "tokens": ["Mit", "Kratz\u00b7fu\u00df", "und", "mit", "Re\u00b7ve\u00b7renz"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Naht h\u00f6hnisch alle Welt:", "tokens": ["Naht", "h\u00f6h\u00b7nisch", "al\u00b7le", "Welt", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "PIAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Willkommen hier, Ihr' Excellenz!", "tokens": ["Will\u00b7kom\u00b7men", "hier", ",", "Ih\u00b7r'", "Ex\u00b7cel\u00b7lenz", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "ADV", "$,", "PPOSAT", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Quartier ist schon bestellt!", "tokens": ["Quar\u00b7tier", "ist", "schon", "be\u00b7stellt", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ADV", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Du hast uns lange satt geknufft;", "tokens": ["Du", "hast", "uns", "lan\u00b7ge", "satt", "ge\u00b7knufft", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Man wird dich wieder knuffen, Schuft!", "tokens": ["Man", "wird", "dich", "wie\u00b7der", "knuf\u00b7fen", ",", "Schuft", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PIS", "VAFIN", "PPER", "ADV", "VVFIN", "$,", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.20": {"line.1": {"text": "Dem Schnapphahn ward, wie sich's geb\u00fchrt,", "tokens": ["Dem", "Schnap\u00b7phahn", "ward", ",", "wie", "sich's", "ge\u00b7b\u00fchrt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "$,", "PWAV", "PIS", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Bald der Proze\u00df gemacht,", "tokens": ["Bald", "der", "Pro\u00b7ze\u00df", "ge\u00b7macht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und d'rauf, als man ihn kondemniert,", "tokens": ["Und", "d'\u00b7rauf", ",", "als", "man", "ihn", "kon\u00b7dem\u00b7niert", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PAV", "$,", "KOUS", "PIS", "PPER", "VVPP", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Ein K\u00e4ficht ausgedacht.", "tokens": ["Ein", "K\u00e4\u00b7ficht", "aus\u00b7ge\u00b7dacht", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Da ward mein Rips hineingesperrt", "tokens": ["Da", "ward", "mein", "Rips", "hin\u00b7ein\u00b7ge\u00b7sperrt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPOSAT", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und wie ein Murmeltier gen\u00e4rrt.", "tokens": ["Und", "wie", "ein", "Mur\u00b7mel\u00b7tier", "ge\u00b7n\u00e4rrt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.21": {"line.1": {"text": "Und, als ihn hungern th\u00e4t, da schnitt", "tokens": ["Und", ",", "als", "ihn", "hun\u00b7gern", "th\u00e4t", ",", "da", "schnitt"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "$,", "KOUS", "PPER", "VVFIN", "VVFIN", "$,", "ADV", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Knips, mit H\u00f6llenqual,", "tokens": ["Der", "Knips", ",", "mit", "H\u00f6l\u00b7len\u00b7qual", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "APPR", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Vom eignen Leib' ihm Glied f\u00fcr Glied,", "tokens": ["Vom", "eig\u00b7nen", "Leib'", "ihm", "Glied", "f\u00fcr", "Glied", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "PPER", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und briet es ihm zum Mahl.", "tokens": ["Und", "briet", "es", "ihm", "zum", "Mahl", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PPER", "APPRART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Als jeglich Glied verzehret war,", "tokens": ["Als", "jeg\u00b7lich", "Glied", "ver\u00b7zeh\u00b7ret", "war", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "NN", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Briet er ihm seinen Magen gar.", "tokens": ["Briet", "er", "ihm", "sei\u00b7nen", "Ma\u00b7gen", "gar", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "PPOSAT", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.22": {"line.1": {"text": "So schmaust' er sich denn selber auf,", "tokens": ["So", "schmaust'", "er", "sich", "denn", "sel\u00b7ber", "auf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "ADV", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Bis auf den letzten Stumpf,", "tokens": ["Bis", "auf", "den", "letz\u00b7ten", "Stumpf", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und endigte den Lebenslauf,", "tokens": ["Und", "en\u00b7dig\u00b7te", "den", "Le\u00b7bens\u00b7lauf", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Den Nachbarn zum Triumph.", "tokens": ["Den", "Nach\u00b7barn", "zum", "Tri\u00b7umph", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.5": {"text": "Der Eisenbau'r, worin er lag,", "tokens": ["Der", "Ei\u00b7sen\u00b7bau'r", ",", "wo\u00b7rin", "er", "lag", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PWAV", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wird aufbewahrt, bis diesen Tag. \u2013", "tokens": ["Wird", "auf\u00b7be\u00b7wahrt", ",", "bis", "die\u00b7sen", "Tag", ".", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["VAFIN", "VVPP", "$,", "APPR", "PDAT", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.23": {"line.1": {"text": "Mein Herr, f\u00e4llt mir der K\u00e4ficht ein,", "tokens": ["Mein", "Herr", ",", "f\u00e4llt", "mir", "der", "K\u00e4\u00b7ficht", "ein", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "VVFIN", "PPER", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So denk' ich oft bei mir:", "tokens": ["So", "denk'", "ich", "oft", "bei", "mir", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPR", "PPER", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Er d\u00fcrfte noch zu brauchen sein,", "tokens": ["Er", "d\u00fcrf\u00b7te", "noch", "zu", "brau\u00b7chen", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "PTKZU", "VVFIN", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und wei\u00df der Herr, wof\u00fcr? \u2013 \u2013", "tokens": ["Und", "wei\u00df", "der", "Herr", ",", "wo\u00b7f\u00fcr", "?", "\u2013", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "punct", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "$,", "PWAV", "$.", "$(", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "F\u00fcr die franz\u00f6schen Raubmarquis", "tokens": ["F\u00fcr", "die", "fran\u00b7z\u00f6\u00b7schen", "Raub\u00b7mar\u00b7quis"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Die man zur Ferme kommen lie\u00df.\u00ab \u2013", "tokens": ["Die", "man", "zur", "Fer\u00b7me", "kom\u00b7men", "lie\u00df", ".", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["ART", "PIS", "APPRART", "NN", "VVINF", "VVFIN", "$.", "$(", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.24": {"line.1": {"text": "Als Matz kaum ausgeperoriert,", "tokens": ["Als", "Matz", "kaum", "aus\u00b7ge\u00b7pe\u00b7ro\u00b7riert", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sieh da! kam querfeldan", "tokens": ["Sieh", "da", "!", "kam", "quer\u00b7fel\u00b7dan"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["NE", "PTKVZ", "$.", "VVFIN", "NE"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ein Sansfa\u00e7on daher trottiert,", "tokens": ["Ein", "Sans\u00b7fa\u00e7on", "da\u00b7her", "trot\u00b7tiert", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "PAV", "VVFIN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Und hielt den Wagen an,", "tokens": ["Und", "hielt", "den", "Wa\u00b7gen", "an", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Und visitierte, Pack f\u00fcr Pack,", "tokens": ["Und", "vi\u00b7si\u00b7tier\u00b7te", ",", "Pack", "f\u00fcr", "Pack", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Nach ungestempeltem Taback.", "tokens": ["Nach", "un\u00b7ge\u00b7stem\u00b7pel\u00b7tem", "Ta\u00b7back", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.25": {"line.1": {"text": "Es liegt nicht weit von hier ein Land,", "tokens": ["Es", "liegt", "nicht", "weit", "von", "hier", "ein", "Land", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "ADJD", "APPR", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da reist' ich einst hindurch;", "tokens": ["Da", "reist'", "ich", "einst", "hin\u00b7durch", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "PAV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Am Weg' auf hohem Felsen stand,", "tokens": ["Am", "Weg'", "auf", "ho\u00b7hem", "Fel\u00b7sen", "stand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Vor alters, eine Burg.", "tokens": ["Vor", "al\u00b7ters", ",", "ei\u00b7ne", "Burg", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ADJA", "$,", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Die alten Rudera davon", "tokens": ["Die", "al\u00b7ten", "Ru\u00b7de\u00b7ra", "da\u00b7von"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "PAV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wies mir der Schwager Postillon.", "tokens": ["Wies", "mir", "der", "Schwa\u00b7ger", "Pos\u00b7til\u00b7lon", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ART", "NN", "NE", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}}, "stanza.26": {"line.1": {"text": "\u00bbmein Herr, begann der Schwager Matz,", "tokens": ["\u00bb", "mein", "Herr", ",", "be\u00b7gann", "der", "Schwa\u00b7ger", "Matz", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPOSAT", "NN", "$,", "VVFIN", "ART", "NN", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mit heimlichem Gesicht,", "tokens": ["Mit", "heim\u00b7li\u00b7chem", "Ge\u00b7sicht", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "W\u00e4r' mir beschert dort jener Schatz,", "tokens": ["W\u00e4r'", "mir", "be\u00b7schert", "dort", "je\u00b7ner", "Schatz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "VVFIN", "ADV", "PDAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "F\u00fchr' ich den Herrn wohl nicht.", "tokens": ["F\u00fchr'", "ich", "den", "Herrn", "wohl", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ART", "NN", "ADV", "PTKNEG", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Mein Seel! den K\u00f6nig fragt' ich gleich:", "tokens": ["Mein", "Seel", "!", "den", "K\u00f6\u00b7nig", "fragt'", "ich", "gleich", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$.", "ART", "NN", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wie teuer, Herr, sein K\u00f6nigreich?", "tokens": ["Wie", "teu\u00b7er", ",", "Herr", ",", "sein", "K\u00f6\u00b7nig\u00b7reich", "?"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "$,", "NN", "$,", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.27": {"line.1": {"text": "Wohl manchem w\u00e4sserte der Mund,", "tokens": ["Wohl", "man\u00b7chem", "w\u00e4s\u00b7ser\u00b7te", "der", "Mund", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Doch mancher ward geprellt.", "tokens": ["Doch", "man\u00b7cher", "ward", "ge\u00b7prellt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VAFIN", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Denn, Herr, Gott sei bei uns! Ein Hund", "tokens": ["Denn", ",", "Herr", ",", "Gott", "sei", "bei", "uns", "!", "Ein", "Hund"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "$,", "NN", "$,", "NN", "VAFIN", "APPR", "PPER", "$.", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Bewacht das sch\u00f6ne Geld.", "tokens": ["Be\u00b7wacht", "das", "sch\u00f6\u00b7ne", "Geld", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Ein schwarzer Hund, die Z\u00e4hne blo\u00df,", "tokens": ["Ein", "schwar\u00b7zer", "Hund", ",", "die", "Z\u00e4h\u00b7ne", "blo\u00df", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Mit Feueraugen, tellersgro\u00df!", "tokens": ["Mit", "Feu\u00b7er\u00b7au\u00b7gen", ",", "tel\u00b7lers\u00b7gro\u00df", "!"], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["APPR", "NN", "$,", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.28": {"line.1": {"text": "Nur immer alle sieben Jahr'", "tokens": ["Nur", "im\u00b7mer", "al\u00b7le", "sie\u00b7ben", "Jahr'"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "PIAT", "CARD", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "L\u00e4\u00dft sich ein Fl\u00e4mmchen sehn.", "tokens": ["L\u00e4\u00dft", "sich", "ein", "Fl\u00e4mm\u00b7chen", "sehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Dann mag ein Bock, kohlschwarz von Haar,", "tokens": ["Dann", "mag", "ein", "Bock", ",", "kohl\u00b7schwarz", "von", "Haar", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "NE", "$,", "ADJD", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Hebung wohl bestehn.", "tokens": ["Die", "He\u00b7bung", "wohl", "be\u00b7stehn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Um zw\u00f6lf Uhr in Walpurgis Nacht,", "tokens": ["Um", "zw\u00f6lf", "Uhr", "in", "Wal\u00b7pur\u00b7gis", "Nacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "CARD", "NN", "APPR", "NE", "NN", "$,"], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.6": {"text": "Wird der dem Unhold dargebracht.", "tokens": ["Wird", "der", "dem", "Un\u00b7hold", "dar\u00b7ge\u00b7bracht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.29": {"line.1": {"text": "Doch merk' eins nur des B\u00f6sen List!", "tokens": ["Doch", "merk'", "eins", "nur", "des", "B\u00f6\u00b7sen", "List", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIS", "ADV", "ART", "NN", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wo noch zum Ungel\u00fcck", "tokens": ["Wo", "noch", "zum", "Un\u00b7ge\u00b7l\u00fcck"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "ADV", "APPRART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Am Bock ein wei\u00dfes H\u00e4rchen ist,", "tokens": ["Am", "Bock", "ein", "wei\u00b7\u00dfes", "H\u00e4r\u00b7chen", "ist", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NE", "ART", "ADJA", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Alsdann: Ade, Genick!", "tokens": ["Als\u00b7dann", ":", "A\u00b7de", ",", "Ge\u00b7nick", "!"], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["ADV", "$.", "NN", "$,", "NN", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.5": {"text": "Den Kniff hat mancher nicht bedacht,", "tokens": ["Den", "Kniff", "hat", "man\u00b7cher", "nicht", "be\u00b7dacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PIS", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und sich um Leib und Seel' gebracht.", "tokens": ["Und", "sich", "um", "Leib", "und", "Seel'", "ge\u00b7bracht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "APPR", "NN", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.30": {"line.1": {"text": "F\u00fcr meinen Part, mit gro\u00dfen Herrn,", "tokens": ["F\u00fcr", "mei\u00b7nen", "Part", ",", "mit", "gro\u00b7\u00dfen", "Herrn", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und Meister Urian,", "tokens": ["Und", "Meis\u00b7ter", "U\u00b7ri\u00b7an", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "NE", "NE", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "\u00c4\u00df' ich wohl keine Kirschen gern.", "tokens": ["\u00c4\u00df'", "ich", "wohl", "kei\u00b7ne", "Kir\u00b7schen", "gern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ADV", "PIAT", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Man l\u00e4uft verdammt oft an.", "tokens": ["Man", "l\u00e4uft", "ver\u00b7dammt", "oft", "an", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "VVFIN", "ADV", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Sie werfen einem, wie man spricht,", "tokens": ["Sie", "wer\u00b7fen", "ei\u00b7nem", ",", "wie", "man", "spricht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "$,", "PWAV", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Gern Stiel und Stein ins Angesicht.", "tokens": ["Gern", "Stiel", "und", "Stein", "ins", "An\u00b7ge\u00b7sicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "KON", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.31": {"line.1": {"text": "D'rum rat ich immer: Lieber Christ,", "tokens": ["D'\u00b7rum", "rat", "ich", "im\u00b7mer", ":", "Lie\u00b7ber", "Christ", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "ADV", "$.", "ADJD", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "La\u00df dich mit keinem ein!", "tokens": ["La\u00df", "dich", "mit", "kei\u00b7nem", "ein", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "APPR", "PIS", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Wann der Kontrakt geschlossen ist,", "tokens": ["Wann", "der", "Kon\u00b7trakt", "ge\u00b7schlos\u00b7sen", "ist", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Bricht man dir Hals und Bein.", "tokens": ["Bricht", "man", "dir", "Hals", "und", "Bein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PPER", "NN", "KON", "NN", "$."], "meter": "++-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Trotz allen Klauseln, glaube du,", "tokens": ["Trotz", "al\u00b7len", "Klau\u00b7seln", ",", "glau\u00b7be", "du", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "$,", "VVFIN", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Macht jeder dir ein X f\u00fcr U. \u2013", "tokens": ["Macht", "je\u00b7der", "dir", "ein", "X", "f\u00fcr", "U.", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "abbreviation", "punct"], "pos": ["NN", "PIS", "PPER", "ART", "XY", "APPR", "NE", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.32": {"line.1": {"text": "Goldmacherei und Lotterie,", "tokens": ["Gold\u00b7ma\u00b7che\u00b7rei", "und", "Lot\u00b7te\u00b7rie", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Nach reichen Weibern frei'n,", "tokens": ["Nach", "rei\u00b7chen", "Wei\u00b7bern", "frei'n", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und Sch\u00e4tze graben, segnet nie,", "tokens": ["Und", "Sch\u00e4t\u00b7ze", "gra\u00b7ben", ",", "seg\u00b7net", "nie", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "NN", "VVINF", "$,", "VVFIN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wird manchen noch gereu'n.", "tokens": ["Wird", "man\u00b7chen", "noch", "ge\u00b7reu'", "n."], "token_info": ["word", "word", "word", "word", "abbreviation"], "pos": ["VAFIN", "PIS", "ADV", "ADJD", "NE"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Mein Spr\u00fcchlein hei\u00dft: Auf Gott vertrau,", "tokens": ["Mein", "Spr\u00fcch\u00b7lein", "hei\u00dft", ":", "Auf", "Gott", "ver\u00b7trau", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "$.", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Arbeite brav und leb' genau!", "tokens": ["Ar\u00b7bei\u00b7te", "brav", "und", "leb'", "ge\u00b7nau", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "KON", "VVFIN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.33": {"line.1": {"text": "Ein alter Graf, fuhr Schwager Matz", "tokens": ["Ein", "al\u00b7ter", "Graf", ",", "fuhr", "Schwa\u00b7ger", "Matz"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "VVFIN", "NE", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Nach seiner Weise fort,", "tokens": ["Nach", "sei\u00b7ner", "Wei\u00b7se", "fort", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Vergrub zu Olims Zeit den Schatz", "tokens": ["Ver\u00b7grub", "zu", "O\u00b7lims", "Zeit", "den", "Schatz"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "NE", "NN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "In seinem Keller dort.", "tokens": ["In", "sei\u00b7nem", "Kel\u00b7ler", "dort", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Der Graf, mein Herr, hie\u00df Graf von Rips,", "tokens": ["Der", "Graf", ",", "mein", "Herr", ",", "hie\u00df", "Graf", "von", "Rips", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PPOSAT", "NN", "$,", "VVFIN", "NE", "APPR", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ein Kraut, wie K\u00e4sebier und Lips.", "tokens": ["Ein", "Kraut", ",", "wie", "K\u00e4\u00b7se\u00b7bier", "und", "Lips", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PWAV", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.34": {"line.1": {"text": "Der streifte durch das ganze Land,", "tokens": ["Der", "streif\u00b7te", "durch", "das", "gan\u00b7ze", "Land", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mit Wagen, Ro\u00df und Mann,", "tokens": ["Mit", "Wa\u00b7gen", ",", "Ro\u00df", "und", "Mann", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und wo er was zu kapern fand,", "tokens": ["Und", "wo", "er", "was", "zu", "ka\u00b7pern", "fand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPER", "PIS", "PTKZU", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Da macht' er frisch sich d'ran.", "tokens": ["Da", "macht'", "er", "frisch", "sich", "d'\u00b7ran", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "PRF", "PTKVZ", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.5": {"text": "Wips! hatt' er's weg, wips! ging er", "tokens": ["Wips", "!", "hatt'", "er's", "weg", ",", "wips", "!", "ging", "er"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["NN", "$.", "VAFIN", "PIS", "PTKVZ", "$,", "ITJ", "$.", "VVFIN", "PPER"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Und schleppt' es heim auf seine Burg.", "tokens": ["Und", "schleppt'", "es", "heim", "auf", "sei\u00b7ne", "Burg", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PTKVZ", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.35": {"line.1": {"text": "Und wann er erst zu Loche sa\u00df,", "tokens": ["Und", "wann", "er", "erst", "zu", "Lo\u00b7che", "sa\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPER", "ADV", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So schlug mein Graf von Rips, \u2013", "tokens": ["So", "schlug", "mein", "Graf", "von", "Rips", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "APPR", "NE", "$,", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Denn hier that ihm kein Teufel was, \u2013", "tokens": ["Denn", "hier", "that", "ihm", "kein", "Teu\u00b7fel", "was", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "PIAT", "NN", "PWS", "$,", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Gar h\u00f6hnisch seinen Schnips.", "tokens": ["Gar", "h\u00f6h\u00b7nisch", "sei\u00b7nen", "Schnips", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Sein allverfluchtes Felsennest", "tokens": ["Sein", "all\u00b7ver\u00b7fluch\u00b7tes", "Fel\u00b7sen\u00b7nest"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "War, wie der K\u00f6nigstein, so fest.", "tokens": ["War", ",", "wie", "der", "K\u00f6\u00b7nig\u00b7stein", ",", "so", "fest", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "$,", "PWAV", "ART", "NN", "$,", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.36": {"line.1": {"text": "So \u00fcbt' er nun gar lang' und oft", "tokens": ["So", "\u00fcbt'", "er", "nun", "gar", "lang'", "und", "oft"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ADV", "ADV", "KON", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Viel Bubenst\u00fccken aus,", "tokens": ["Viel", "Bu\u00b7ben\u00b7st\u00fc\u00b7cken", "aus", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PIAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und fiel den Nachbarn unverhofft", "tokens": ["Und", "fiel", "den", "Nach\u00b7barn", "un\u00b7ver\u00b7hofft"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ART", "NN", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "In Hof und Stall und Haus.", "tokens": ["In", "Hof", "und", "Stall", "und", "Haus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "KON", "NN", "KON", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Allein, der Krug geht, wie man spricht,", "tokens": ["Al\u00b7lein", ",", "der", "Krug", "geht", ",", "wie", "man", "spricht", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "ART", "NN", "VVFIN", "$,", "PWAV", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "So lang' zu Wasser, bis er bricht.", "tokens": ["So", "lang'", "zu", "Was\u00b7ser", ",", "bis", "er", "bricht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "NN", "$,", "KOUS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.37": {"line.1": {"text": "Das Ding verdro\u00df den Magistrat", "tokens": ["Das", "Ding", "ver\u00b7dro\u00df", "den", "Ma\u00b7gist\u00b7rat"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Im n\u00e4chsten St\u00e4dtchen sehr,", "tokens": ["Im", "n\u00e4chs\u00b7ten", "St\u00e4dt\u00b7chen", "sehr", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "ADV", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "D'rum riet der l\u00e4ngst auf klugen Rat", "tokens": ["D'\u00b7rum", "riet", "der", "l\u00e4ngst", "auf", "klu\u00b7gen", "Rat"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "ART", "ADV", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Bed\u00e4chtlich hin und her,", "tokens": ["Be\u00b7d\u00e4cht\u00b7lich", "hin", "und", "her", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "PTKVZ", "KON", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Und riet und riet \u2013 doch wei\u00df man wohl! \u2013", "tokens": ["Und", "riet", "und", "riet", "\u2013", "doch", "wei\u00df", "man", "wohl", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "KON", "VVFIN", "$(", "ADV", "VVFIN", "PIS", "ADV", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Die Herren rieten sich halb toll.", "tokens": ["Die", "Her\u00b7ren", "rie\u00b7ten", "sich", "halb", "toll", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PRF", "ADJD", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.38": {"line.1": {"text": "Da nun begab sich's da\u00df einsmals,", "tokens": ["Da", "nun", "be\u00b7gab", "sich's", "da\u00df", "eins\u00b7mals", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PIS", "KOUS", "ADV", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Ob vielem Teufelsspa\u00df,", "tokens": ["Ob", "vie\u00b7lem", "Teu\u00b7fels\u00b7spa\u00df", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ein Lumpenhexchen auf den Hals", "tokens": ["Ein", "Lum\u00b7pen\u00b7hex\u00b7chen", "auf", "den", "Hals"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "In Kett' und Banden sa\u00df.", "tokens": ["In", "Kett'", "und", "Ban\u00b7den", "sa\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Schon wetzte Meister Urian", "tokens": ["Schon", "wetz\u00b7te", "Meis\u00b7ter", "U\u00b7ri\u00b7an"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "NE", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Auf diesen Braten seinen Zahn.", "tokens": ["Auf", "die\u00b7sen", "Bra\u00b7ten", "sei\u00b7nen", "Zahn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.39": {"line.1": {"text": "Dies Hexchen sprach: H\u00f6rt! La\u00dft mich frei,", "tokens": ["Dies", "Hex\u00b7chen", "sprach", ":", "H\u00f6rt", "!", "La\u00dft", "mich", "frei", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "NN", "VVFIN", "$.", "VVIMP", "$.", "VVIMP", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So schaff' ich ihn herein.", "tokens": ["So", "schaff'", "ich", "ihn", "her\u00b7ein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Wohl! sprach ein edler Rat, es sei!", "tokens": ["Wohl", "!", "sprach", "ein", "ed\u00b7ler", "Rat", ",", "es", "sei", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "$.", "VVFIN", "ART", "ADJA", "NN", "$,", "PPER", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und gab ihr oben d'rein", "tokens": ["Und", "gab", "ihr", "o\u00b7ben", "d'\u00b7rein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "ADV", "NE"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.5": {"text": "Ein eisern Privilegium,", "tokens": ["Ein", "ei\u00b7sern", "Pri\u00b7vi\u00b7le\u00b7gi\u00b7um", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.6": {"text": "Zu hexen frank und frei herum.", "tokens": ["Zu", "he\u00b7xen", "frank", "und", "frei", "he\u00b7rum", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "VVFIN", "KON", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.40": {"line.1": {"text": "Ein n\u00e4rrscher Handel! Unsereins", "tokens": ["Ein", "n\u00e4rr\u00b7scher", "Han\u00b7del", "!", "Un\u00b7ser\u00b7eins"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["ART", "ADJA", "NN", "$.", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Th\u00e4t' nichts auf solchen Kauf.", "tokens": ["Th\u00e4t'", "nichts", "auf", "sol\u00b7chen", "Kauf", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Doch Satans Reich ist selten eins,", "tokens": ["Doch", "Sa\u00b7tans", "Reich", "ist", "sel\u00b7ten", "eins", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "NE", "VAFIN", "ADJD", "PIS", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und reibt sich selber auf.", "tokens": ["Und", "reibt", "sich", "sel\u00b7ber", "auf", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "ADV", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "F\u00fcr diesmal spielt die L\u00fcgenbrut", "tokens": ["F\u00fcr", "dies\u00b7mal", "spielt", "die", "L\u00fc\u00b7gen\u00b7brut"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ADV", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ihr St\u00fcckchen ehrlich und auch gut.", "tokens": ["Ihr", "St\u00fcck\u00b7chen", "ehr\u00b7lich", "und", "auch", "gut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADJD", "KON", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.41": {"line.1": {"text": "Sie kroch, als Kr\u00f6t', auf's R\u00e4uberschlo\u00df,", "tokens": ["Sie", "kroch", ",", "als", "Kr\u00f6t'", ",", "auf's", "R\u00e4u\u00b7ber\u00b7schlo\u00df", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "NN", "$,", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mit losem leisen Tritt,", "tokens": ["Mit", "lo\u00b7sem", "lei\u00b7sen", "Tritt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Verwandelte sich in das Ro\u00df,", "tokens": ["Ver\u00b7wan\u00b7del\u00b7te", "sich", "in", "das", "Ro\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Das Rips gew\u00f6hnlich ritt;", "tokens": ["Das", "Rips", "ge\u00b7w\u00f6hn\u00b7lich", "ritt", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Und als der Schlo\u00dfhahn kr\u00e4hte fr\u00fch,", "tokens": ["Und", "als", "der", "Schlo\u00df\u00b7hahn", "kr\u00e4h\u00b7te", "fr\u00fch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "VVFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Bestieg der Graf gesattelt sie.", "tokens": ["Be\u00b7stieg", "der", "Graf", "ge\u00b7sat\u00b7telt", "sie", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "VVPP", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.42": {"line.1": {"text": "Sie aber trug, trotz Gert' und Sporn,", "tokens": ["Sie", "a\u00b7ber", "trug", ",", "trotz", "Gert'", "und", "Sporn", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "$,", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So sehr er hieb und trat,", "tokens": ["So", "sehr", "er", "hieb", "und", "trat", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ihn, \u00fcber Stock und Stein und Dorn,", "tokens": ["Ihn", ",", "\u00fc\u00b7ber", "Stock", "und", "Stein", "und", "Dorn", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "APPR", "NN", "KON", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Gerades Wegs zur Stadt.", "tokens": ["Ge\u00b7ra\u00b7des", "Wegs", "zur", "Stadt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Fr\u00fch, als das Thor ward aufgethan,", "tokens": ["Fr\u00fch", ",", "als", "das", "Thor", "ward", "auf\u00b7ge\u00b7than", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "KOUS", "ART", "NN", "VAFIN", "VVPP", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.6": {"text": "Sieh da! kam unser Hexlein an.", "tokens": ["Sieh", "da", "!", "kam", "un\u00b7ser", "Hex\u00b7lein", "an", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "PTKVZ", "$.", "VVFIN", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.43": {"line.1": {"text": "Mit Kratzfu\u00df und mit Reverenz", "tokens": ["Mit", "Kratz\u00b7fu\u00df", "und", "mit", "Re\u00b7ve\u00b7renz"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Naht h\u00f6hnisch alle Welt:", "tokens": ["Naht", "h\u00f6h\u00b7nisch", "al\u00b7le", "Welt", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "PIAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Willkommen hier, Ihr' Excellenz!", "tokens": ["Will\u00b7kom\u00b7men", "hier", ",", "Ih\u00b7r'", "Ex\u00b7cel\u00b7lenz", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "ADV", "$,", "PPOSAT", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Quartier ist schon bestellt!", "tokens": ["Quar\u00b7tier", "ist", "schon", "be\u00b7stellt", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ADV", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Du hast uns lange satt geknufft;", "tokens": ["Du", "hast", "uns", "lan\u00b7ge", "satt", "ge\u00b7knufft", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Man wird dich wieder knuffen, Schuft!", "tokens": ["Man", "wird", "dich", "wie\u00b7der", "knuf\u00b7fen", ",", "Schuft", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PIS", "VAFIN", "PPER", "ADV", "VVFIN", "$,", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.44": {"line.1": {"text": "Dem Schnapphahn ward, wie sich's geb\u00fchrt,", "tokens": ["Dem", "Schnap\u00b7phahn", "ward", ",", "wie", "sich's", "ge\u00b7b\u00fchrt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "$,", "PWAV", "PIS", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Bald der Proze\u00df gemacht,", "tokens": ["Bald", "der", "Pro\u00b7ze\u00df", "ge\u00b7macht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und d'rauf, als man ihn kondemniert,", "tokens": ["Und", "d'\u00b7rauf", ",", "als", "man", "ihn", "kon\u00b7dem\u00b7niert", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PAV", "$,", "KOUS", "PIS", "PPER", "VVPP", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Ein K\u00e4ficht ausgedacht.", "tokens": ["Ein", "K\u00e4\u00b7ficht", "aus\u00b7ge\u00b7dacht", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Da ward mein Rips hineingesperrt", "tokens": ["Da", "ward", "mein", "Rips", "hin\u00b7ein\u00b7ge\u00b7sperrt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPOSAT", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und wie ein Murmeltier gen\u00e4rrt.", "tokens": ["Und", "wie", "ein", "Mur\u00b7mel\u00b7tier", "ge\u00b7n\u00e4rrt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.45": {"line.1": {"text": "Und, als ihn hungern th\u00e4t, da schnitt", "tokens": ["Und", ",", "als", "ihn", "hun\u00b7gern", "th\u00e4t", ",", "da", "schnitt"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "$,", "KOUS", "PPER", "VVFIN", "VVFIN", "$,", "ADV", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Knips, mit H\u00f6llenqual,", "tokens": ["Der", "Knips", ",", "mit", "H\u00f6l\u00b7len\u00b7qual", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "APPR", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Vom eignen Leib' ihm Glied f\u00fcr Glied,", "tokens": ["Vom", "eig\u00b7nen", "Leib'", "ihm", "Glied", "f\u00fcr", "Glied", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "PPER", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und briet es ihm zum Mahl.", "tokens": ["Und", "briet", "es", "ihm", "zum", "Mahl", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PPER", "APPRART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Als jeglich Glied verzehret war,", "tokens": ["Als", "jeg\u00b7lich", "Glied", "ver\u00b7zeh\u00b7ret", "war", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "NN", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Briet er ihm seinen Magen gar.", "tokens": ["Briet", "er", "ihm", "sei\u00b7nen", "Ma\u00b7gen", "gar", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "PPOSAT", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.46": {"line.1": {"text": "So schmaust' er sich denn selber auf,", "tokens": ["So", "schmaust'", "er", "sich", "denn", "sel\u00b7ber", "auf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "ADV", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Bis auf den letzten Stumpf,", "tokens": ["Bis", "auf", "den", "letz\u00b7ten", "Stumpf", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und endigte den Lebenslauf,", "tokens": ["Und", "en\u00b7dig\u00b7te", "den", "Le\u00b7bens\u00b7lauf", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Den Nachbarn zum Triumph.", "tokens": ["Den", "Nach\u00b7barn", "zum", "Tri\u00b7umph", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.5": {"text": "Der Eisenbau'r, worin er lag,", "tokens": ["Der", "Ei\u00b7sen\u00b7bau'r", ",", "wo\u00b7rin", "er", "lag", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PWAV", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wird aufbewahrt, bis diesen Tag. \u2013", "tokens": ["Wird", "auf\u00b7be\u00b7wahrt", ",", "bis", "die\u00b7sen", "Tag", ".", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["VAFIN", "VVPP", "$,", "APPR", "PDAT", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.47": {"line.1": {"text": "Mein Herr, f\u00e4llt mir der K\u00e4ficht ein,", "tokens": ["Mein", "Herr", ",", "f\u00e4llt", "mir", "der", "K\u00e4\u00b7ficht", "ein", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "VVFIN", "PPER", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So denk' ich oft bei mir:", "tokens": ["So", "denk'", "ich", "oft", "bei", "mir", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPR", "PPER", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Er d\u00fcrfte noch zu brauchen sein,", "tokens": ["Er", "d\u00fcrf\u00b7te", "noch", "zu", "brau\u00b7chen", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "PTKZU", "VVFIN", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und wei\u00df der Herr, wof\u00fcr? \u2013 \u2013", "tokens": ["Und", "wei\u00df", "der", "Herr", ",", "wo\u00b7f\u00fcr", "?", "\u2013", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "punct", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "$,", "PWAV", "$.", "$(", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "F\u00fcr die franz\u00f6schen Raubmarquis", "tokens": ["F\u00fcr", "die", "fran\u00b7z\u00f6\u00b7schen", "Raub\u00b7mar\u00b7quis"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Die man zur Ferme kommen lie\u00df.\u00ab \u2013", "tokens": ["Die", "man", "zur", "Fer\u00b7me", "kom\u00b7men", "lie\u00df", ".", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["ART", "PIS", "APPRART", "NN", "VVINF", "VVFIN", "$.", "$(", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.48": {"line.1": {"text": "Als Matz kaum ausgeperoriert,", "tokens": ["Als", "Matz", "kaum", "aus\u00b7ge\u00b7pe\u00b7ro\u00b7riert", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sieh da! kam querfeldan", "tokens": ["Sieh", "da", "!", "kam", "quer\u00b7fel\u00b7dan"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["NE", "PTKVZ", "$.", "VVFIN", "NE"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ein Sansfa\u00e7on daher trottiert,", "tokens": ["Ein", "Sans\u00b7fa\u00e7on", "da\u00b7her", "trot\u00b7tiert", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "PAV", "VVFIN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Und hielt den Wagen an,", "tokens": ["Und", "hielt", "den", "Wa\u00b7gen", "an", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Und visitierte, Pack f\u00fcr Pack,", "tokens": ["Und", "vi\u00b7si\u00b7tier\u00b7te", ",", "Pack", "f\u00fcr", "Pack", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Nach ungestempeltem Taback.", "tokens": ["Nach", "un\u00b7ge\u00b7stem\u00b7pel\u00b7tem", "Ta\u00b7back", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}}}}