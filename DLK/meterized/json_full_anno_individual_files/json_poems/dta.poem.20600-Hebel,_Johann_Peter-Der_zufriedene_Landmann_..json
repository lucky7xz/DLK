{"dta.poem.20600": {"metadata": {"author": {"name": "Hebel, Johann Peter", "birth": "N.A.", "death": "N.A."}, "title": "Der zufriedene Landmann .", "genre": "Lyrik", "period": "N.A.", "pub_year": "1803", "urn": "urn:nbn:de:kobv:b4-200905192133", "language": ["de:0.99"], "booktitle": "[Hebel, Johann Peter]: Allemannische Gedichte. Karlsruhe, 1803."}, "poem": {"stanza.1": {"line.1": {"text": "Denkwol, iez lengi au in Sack,               ", "tokens": ["Denk\u00b7wol", ",", "iez", "len\u00b7gi", "au", "in", "Sack", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "FM", "FM", "FM", "APPR", "NN", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.2": {"text": "und trink e Pfifli Rauchtuback,", "tokens": ["und", "trink", "e", "Pfif\u00b7li", "Rauch\u00b7tu\u00b7back", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "NE", "NE", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "und fahr iez heim mit Eg und Pflug,", "tokens": ["und", "fahr", "iez", "heim", "mit", "Eg", "und", "Pflug", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "NE", "PTKVZ", "APPR", "NE", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "der Laubi meint scho lang, \u2019s w\u00e4r gnug.", "tokens": ["der", "Lau\u00b7bi", "meint", "scho", "lang", ",", "'s", "w\u00e4r", "gnug", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "ADJD", "$,", "PPER", "VAFIN", "ADV", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.2": {"line.1": {"text": "Und wenn der Kayser usem Roth", "tokens": ["Und", "wenn", "der", "Kay\u00b7ser", "u\u00b7sem", "Roth"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "in Feld und Forst ufs Jage goht,", "tokens": ["in", "Feld", "und", "Forst", "ufs", "Ja\u00b7ge", "goht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "se lengt er eben au in Sack,", "tokens": ["se", "lengt", "er", "e\u00b7ben", "au", "in", "Sack", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "NE", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "und trinkt e Pfifli Rauchtuback.", "tokens": ["und", "trinkt", "e", "Pfif\u00b7li", "Rauch\u00b7tu\u00b7back", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "NE", "NE", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Doch trinkt er wenig Freud und Lust,", "tokens": ["Doch", "trinkt", "er", "we\u00b7nig", "Freud", "und", "Lust", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PIAT", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "es isch em n\u00e4ume gar nit iust.", "tokens": ["es", "isch", "em", "n\u00e4u\u00b7me", "gar", "nit", "i\u00b7ust", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Die goldne Chrone drucke schwer;", "tokens": ["Die", "gold\u00b7ne", "Chro\u00b7ne", "dru\u00b7cke", "schwer", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "\u2019s isch nit, a\u00df wenns e Schie-Hut w\u00e4r.", "tokens": ["'s", "isch", "nit", ",", "a\u00df", "wenns", "e", "Schie\u00b7Hut", "w\u00e4r", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "PTKNEG", "$,", "VVFIN", "KOUS", "NE", "NE", "VAFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Wohl goht em menge Batzen i,", "tokens": ["Wohl", "goht", "em", "men\u00b7ge", "Bat\u00b7zen", "i", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADJA", "NN", "NE", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "doch will au menge gfuttert sy;", "tokens": ["doch", "will", "au", "men\u00b7ge", "gfut\u00b7tert", "sy", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "NE", "NE", "NE", "NE", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.3": {"text": "und woner lost isch Bitt und Bitt,", "tokens": ["und", "wo\u00b7ner", "lost", "isch", "Bitt", "und", "Bitt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "ADJD", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "und alli tr\u00f6ste chaner nit.", "tokens": ["und", "al\u00b7li", "tr\u00f6s\u00b7te", "cha\u00b7ner", "nit", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "ADJA", "NN", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Und wenn er hilft, und sorgt und wacht", "tokens": ["Und", "wenn", "er", "hilft", ",", "und", "sorgt", "und", "wacht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "VVFIN", "$,", "KON", "ADJD", "KON", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "vom fr\u00fceihe Morge bis in d\u2019 Nacht,", "tokens": ["vom", "fr\u00fce\u00b7i\u00b7he", "Mor\u00b7ge", "bis", "in", "d'", "Nacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "APPR", "APPR", "NE", "NN", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "und meint, iez heiger alles tho,", "tokens": ["und", "meint", ",", "iez", "hei\u00b7ger", "al\u00b7les", "tho", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "FM.la", "FM.la", "FM.la", "FM.la", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "se het er erst kei Dank dervo.", "tokens": ["se", "het", "er", "erst", "kei", "Dank", "der\u00b7vo", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "PIAT", "NN", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Und wenn, vom Treffe blutig roth,", "tokens": ["Und", "wenn", ",", "vom", "Tref\u00b7fe", "blu\u00b7tig", "roth", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "$,", "APPRART", "NN", "ADJD", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "der Jenneral im Lager stoht,", "tokens": ["der", "Jen\u00b7ne\u00b7ral", "im", "La\u00b7ger", "stoht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "se lengt er endli au in Sack,", "tokens": ["se", "lengt", "er", "end\u00b7li", "au", "in", "Sack", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "NE", "NE", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "und trinkt e Pfifli Rauchtuback.", "tokens": ["und", "trinkt", "e", "Pfif\u00b7li", "Rauch\u00b7tu\u00b7back", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "NE", "NE", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Doch schmeckts em nit im wilde Gw\u00fchl,", "tokens": ["Doch", "schmeckts", "em", "nit", "im", "wil\u00b7de", "Gw\u00fchl", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIS", "PTKNEG", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "by\u2019m Ach und Weh und Saitespiel;", "tokens": ["by'm", "Ach", "und", "Weh", "und", "Sai\u00b7te\u00b7spiel", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "KON", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "er het thurnieret um und um,", "tokens": ["er", "het", "thur\u00b7nie\u00b7ret", "um", "und", "um", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVFIN", "PTKVZ", "KON", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "und niemes will en lobe drum.", "tokens": ["und", "nie\u00b7mes", "will", "en", "lo\u00b7be", "drum", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VMFIN", "VVINF", "VVFIN", "PAV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Und F\u00fcrio und Mordio", "tokens": ["Und", "F\u00fc\u00b7rio", "und", "Mor\u00b7dio"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "NN", "KON", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "und schweri Wetter ziehnem no;", "tokens": ["und", "schwe\u00b7ri", "Wet\u00b7ter", "zieh\u00b7nem", "no", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "ADJA", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "do lit der Granedier im Blut,", "tokens": ["do", "lit", "der", "Gra\u00b7ne\u00b7dier", "im", "Blut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPRART", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "und d\u00f6rt e Dorf in Rauch und Glut.", "tokens": ["und", "d\u00f6rt", "e", "Dorf", "in", "Rauch", "und", "Glut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "NE", "NN", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Und wenn in d\u2019 Me\u00df mit Gut und Geld", "tokens": ["Und", "wenn", "in", "d'", "Me\u00df", "mit", "Gut", "und", "Geld"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "APPR", "NE", "NN", "APPR", "NN", "KON", "NN"], "meter": "----+-+-+", "measure": "unknown.measure.tri"}, "line.2": {"text": "der Chaufher reist im wite Feld,", "tokens": ["der", "Chauf\u00b7her", "reist", "im", "wi\u00b7te", "Feld", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "se lengt er eben an in Sack,", "tokens": ["se", "lengt", "er", "e\u00b7ben", "an", "in", "Sack", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPR", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "und holt si Pfifli Rauchtuback.", "tokens": ["und", "holt", "si", "Pfif\u00b7li", "Rauch\u00b7tu\u00b7back", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "NE", "NE", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Doch schmeckts der nit, du arme Ma!", "tokens": ["Doch", "schmeckts", "der", "nit", ",", "du", "ar\u00b7me", "Ma", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "PTKNEG", "$,", "PPER", "ADJA", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Me sieht der dini Sorgen a,", "tokens": ["Me", "sieht", "der", "di\u00b7ni", "Sor\u00b7gen", "a", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ART", "ADJA", "NN", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "unds Ei mol eis, es isch e Gruus,", "tokens": ["unds", "Ei", "mol", "eis", ",", "es", "isch", "e", "Gru\u00b7us", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "$,", "FM.la", "FM.la", "FM.la", "FM.la", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "es luegt der zu den Augen us.", "tokens": ["es", "luegt", "der", "zu", "den", "Au\u00b7gen", "us", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "APPR", "ART", "NN", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "De treisch so schwer, es thut der weh;", "tokens": ["De", "treisch", "so", "schwer", ",", "es", "thut", "der", "weh", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADJD", "ADV", "ADJD", "$,", "PPER", "VVFIN", "ART", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Doch hesch nit gnug, und m\u00f6chtsch no me,", "tokens": ["Doch", "hesch", "nit", "gnug", ",", "und", "m\u00f6chtsch", "no", "me", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "PTKNEG", "ADV", "$,", "KON", "ADJD", "FM", "FM", "$,"], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}, "line.3": {"text": "und weisch io nit, wo ane mit;", "tokens": ["und", "weisch", "i\u00b7o", "nit", ",", "wo", "a\u00b7ne", "mit", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "ADV", "PTKNEG", "$,", "PWAV", "NE", "PTKVZ", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "drum schmeckt der au di Pfifli nit.", "tokens": ["drum", "schmeckt", "der", "au", "di", "Pfif\u00b7li", "nit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "ART", "NE", "NE", "NE", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Mir schmeckts, Gottlob, und \u2019s isch mer", "tokens": ["Mir", "schmeckts", ",", "Gott\u00b7lob", ",", "und", "'s", "isch", "mer"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "NN", "$,", "KON", "PPER", "ADJD", "ADJA"], "meter": "-+-+-++-", "measure": "unknown.measure.tetra"}, "line.2": {"text": "gsund;", "tokens": ["gsund", ";"], "token_info": ["word", "punct"], "pos": ["ADJD", "$."], "meter": "-", "measure": "single.down"}, "line.3": {"text": "der Weize lit im f\u00fcechte Grund,", "tokens": ["der", "Wei\u00b7ze", "lit", "im", "f\u00fcech\u00b7te", "Grund", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "und mittem Thau im Morgeroth,", "tokens": ["und", "mit\u00b7tem", "Thau", "im", "Mor\u00b7ge\u00b7roth", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "und mit sim Othem segnets Gott.", "tokens": ["und", "mit", "sim", "O\u00b7them", "seg\u00b7nets", "Gott", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "APPRART", "NN", "ADV", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Und \u2019s Anne Meili flink und froh,", "tokens": ["Und", "'s", "An\u00b7ne", "Mei\u00b7li", "flink", "und", "froh", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "NE", "NE", "VVFIN", "KON", "ADJD", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "es wartet mit der Suppe scho,", "tokens": ["es", "war\u00b7tet", "mit", "der", "Sup\u00b7pe", "scho", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "und d\u2019 Chinderli am chleine Tisch,", "tokens": ["und", "d'", "Chin\u00b7der\u00b7li", "am", "chlei\u00b7ne", "Tisch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "NE", "APPRART", "ADJA", "NN", "$,"], "meter": "--+-+-+-+", "measure": "anapaest.init"}, "line.4": {"text": "me wei\u00df nit, welles \u2019s f\u00fcrnehmst isch.", "tokens": ["me", "wei\u00df", "nit", ",", "wel\u00b7les", "'s", "f\u00fcr\u00b7nehmst", "isch", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "VVFIN", "PTKNEG", "$,", "PRELS", "PPER", "VVFIN", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Drum schmeckt mer au mi Pfifli wohl;", "tokens": ["Drum", "schmeckt", "mer", "au", "mi", "Pfif\u00b7li", "wohl", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "ADV", "NE", "NE", "NE", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "denkwol, i f\u00fcllmers no ne mol!", "tokens": ["denk\u00b7wol", ",", "i", "f\u00fcll\u00b7mers", "no", "ne", "mol", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "FM", "FM", "FM", "FM", "FM", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Zum frohe Sinn, zum freie Muth,", "tokens": ["Zum", "fro\u00b7he", "Sinn", ",", "zum", "frei\u00b7e", "Muth", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "$,", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "und heimetzu schmeckt alles gut.", "tokens": ["und", "hei\u00b7met\u00b7zu", "schmeckt", "al\u00b7les", "gut", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "PIS", "ADJD", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}}}}}