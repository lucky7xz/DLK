{"dta.poem.3213": {"metadata": {"author": {"name": "R\u00fcckert, Friedrich", "birth": "N.A.", "death": "N.A."}, "title": "64.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1838", "urn": "urn:nbn:de:kobv:b4-200905195108", "language": ["de:0.85", "af:0.14"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Fr\u00fchzeitig wardst du in die Schule dieses Lebens", "tokens": ["Fr\u00fch\u00b7zei\u00b7tig", "wardst", "du", "in", "die", "Schu\u00b7le", "die\u00b7ses", "Le\u00b7bens"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADJD", "VAFIN", "PPER", "APPR", "ART", "NN", "PDAT", "NN"], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.2": {"text": "Gesandt, und durchgemacht hast du sie nicht vergebens.", "tokens": ["Ge\u00b7sandt", ",", "und", "durch\u00b7ge\u00b7macht", "hast", "du", "sie", "nicht", "ver\u00b7ge\u00b7bens", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "KON", "VVPP", "VAFIN", "PPER", "PPER", "PTKNEG", "ADV", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Jung, jede Pr\u00fcfung hast du r\u00fchmlich so bestanden,", "tokens": ["Jung", ",", "je\u00b7de", "Pr\u00fc\u00b7fung", "hast", "du", "r\u00fchm\u00b7lich", "so", "be\u00b7stan\u00b7den", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PIAT", "NN", "VAFIN", "PPER", "ADJD", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Da\u00df sie dich w\u00fcrdig bald zum Weiterr\u00fccken fanden.", "tokens": ["Da\u00df", "sie", "dich", "w\u00fcr\u00b7dig", "bald", "zum", "Wei\u00b7ter\u00b7r\u00fc\u00b7cken", "fan\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ADJD", "ADV", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Erhebung ohne Stolz, Ergebung ohne Beugni\u00df:", "tokens": ["Er\u00b7he\u00b7bung", "oh\u00b7ne", "Stolz", ",", "Er\u00b7ge\u00b7bung", "oh\u00b7ne", "Beug\u00b7ni\u00df", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "$,", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der Schul' entlassen bist du mit dem besten Zeugni\u00df.", "tokens": ["Der", "Schul'", "ent\u00b7las\u00b7sen", "bist", "du", "mit", "dem", "bes\u00b7ten", "Zeug\u00b7ni\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "VAFIN", "PPER", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Du hast viel sp\u00e4ter als wir selbst den Gang begonnen,", "tokens": ["Du", "hast", "viel", "sp\u00e4\u00b7ter", "als", "wir", "selbst", "den", "Gang", "be\u00b7gon\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "KOKOM", "PPER", "ADV", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und unerwartet uns den Vorsprung abgewonnen.", "tokens": ["Und", "un\u00b7er\u00b7war\u00b7tet", "uns", "den", "Vor\u00b7sprung", "ab\u00b7ge\u00b7won\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "PPER", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Du hast die H\u00f6h' erreicht, nach der dich's fr\u00fch getrieben;", "tokens": ["Du", "hast", "die", "H\u00f6h'", "er\u00b7reicht", ",", "nach", "der", "dich's", "fr\u00fch", "ge\u00b7trie\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "VVPP", "$,", "APPR", "ART", "ADJA", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wir sind hier unten auf der Schulbank sitzen blieben.", "tokens": ["Wir", "sind", "hier", "un\u00b7ten", "auf", "der", "Schul\u00b7bank", "sit\u00b7zen", "blie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "APPR", "ART", "NN", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Ein Zeichen, da\u00df wir noch genug gelernt nicht haben,", "tokens": ["Ein", "Zei\u00b7chen", ",", "da\u00df", "wir", "noch", "ge\u00b7nug", "ge\u00b7lernt", "nicht", "ha\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "KOUS", "PPER", "ADV", "ADV", "VVPP", "PTKNEG", "VAINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "F\u00fcr jene Klass', in die sie dir den Zutritt gaben.", "tokens": ["F\u00fcr", "je\u00b7ne", "Klass'", ",", "in", "die", "sie", "dir", "den", "Zu\u00b7tritt", "ga\u00b7ben", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "$,", "APPR", "PRELS", "PPER", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}