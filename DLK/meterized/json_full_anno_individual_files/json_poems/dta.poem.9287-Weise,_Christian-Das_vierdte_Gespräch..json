{"dta.poem.9287": {"metadata": {"author": {"name": "Weise, Christian", "birth": "N.A.", "death": "N.A."}, "title": "Das vierdte Gespr\u00e4ch.", "genre": "Lyrik; Drama; Prosa", "period": "N.A.", "pub_year": "1701", "urn": "urn:nbn:de:kobv:b4-25043-0", "language": ["de:0.99"], "booktitle": "Weise, Christian: \u00dcberfl\u00fc\u00dfige Gedancken Der gr\u00fcnenden jugend. Leipzig, 1701."}, "poem": {"stanza.1": {"line.1": {"text": "Gehab dich wohl mein kind/ gehab dich wohl mein leben/", "tokens": ["Ge\u00b7hab", "dich", "wohl", "mein", "kind", "/", "ge\u00b7hab", "dich", "wohl", "mein", "le\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "PPOSAT", "NN", "$(", "VVFIN", "PPER", "ADV", "PPOSAT", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wilst du mir einen trost mit auf die reise geben?", "tokens": ["Wilst", "du", "mir", "ei\u00b7nen", "trost", "mit", "auf", "die", "rei\u00b7se", "ge\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PPER", "ART", "NN", "APPR", "APPR", "ART", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "So schau mich g\u00fcnstig an/ und nimm zu guter letzt", "tokens": ["So", "schau", "mich", "g\u00fcns\u00b7tig", "an", "/", "und", "nimm", "zu", "gu\u00b7ter", "letzt"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "PPER", "ADJD", "PTKVZ", "$(", "KON", "VVIMP", "APPR", "ADJA", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Was die betr\u00fcbte faust dir zu gefallen setzt.", "tokens": ["Was", "die", "be\u00b7tr\u00fcb\u00b7te", "faust", "dir", "zu", "ge\u00b7fal\u00b7len", "setzt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "ADJA", "NN", "PPER", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "2. Du hast dein s\u00fcsses theil zwar allbereit in armen/", "tokens": ["Du", "hast", "dein", "s\u00fcs\u00b7ses", "theil", "zwar", "all\u00b7be\u00b7reit", "in", "ar\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "ADJA", "NN", "ADV", "ADV", "APPR", "ADJA", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Drum such ich keine gunst/ ich suche nur erbarmen.", "tokens": ["Drum", "such", "ich", "kei\u00b7ne", "gunst", "/", "ich", "su\u00b7che", "nur", "er\u00b7bar\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "PIAT", "NN", "$(", "PPER", "VVFIN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Gieb mir den abschieds-gru\u00df/ es schadt der liebe nicht", "tokens": ["Gieb", "mir", "den", "ab\u00b7schieds\u00b7gru\u00df", "/", "es", "schadt", "der", "lie\u00b7be", "nicht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVIMP", "PPER", "ART", "NN", "$(", "PPER", "VVFIN", "ART", "VVFIN", "PTKNEG"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wenn gleich dein sch\u00f6ner mund mir einen ku\u00df verspricht.", "tokens": ["Wenn", "gleich", "dein", "sch\u00f6\u00b7ner", "mund", "mir", "ei\u00b7nen", "ku\u00df", "ver\u00b7spricht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PPOSAT", "ADJA", "NN", "PPER", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "3. Gedenck an meine noth darin ich mich betr\u00fcbe/", "tokens": ["Ge\u00b7denck", "an", "mei\u00b7ne", "noth", "da\u00b7rin", "ich", "mich", "be\u00b7tr\u00fc\u00b7be", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPOSAT", "NN", "PAV", "PPER", "PRF", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ich liebte deinen glantz in keuscher gegenliebe/", "tokens": ["Ich", "lieb\u00b7te", "dei\u00b7nen", "glantz", "in", "keu\u00b7scher", "ge\u00b7gen\u00b7lie\u00b7be", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ich war in deiner gunst was kaum ein bruder ist.", "tokens": ["Ich", "war", "in", "dei\u00b7ner", "gunst", "was", "kaum", "ein", "bru\u00b7der", "ist", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "PPOSAT", "NN", "PWS", "ADV", "ART", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Nun soll ich fremde thun weil du versprochen bist.", "tokens": ["Nun", "soll", "ich", "frem\u00b7de", "thun", "weil", "du", "ver\u00b7spro\u00b7chen", "bist", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADJA", "VVINF", "KOUS", "PPER", "VVINF", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "4. Ist unser freundlichkeit so unverhofft verschwunden", "tokens": ["Ist", "un\u00b7ser", "freund\u00b7lich\u00b7keit", "so", "un\u00b7ver\u00b7hofft", "ver\u00b7schwun\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPOSAT", "NN", "ADV", "ADJD", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wo ist die liebe zeit/ wo sind die sch\u00f6nen stunden/", "tokens": ["Wo", "ist", "die", "lie\u00b7be", "zeit", "/", "wo", "sind", "die", "sch\u00f6\u00b7nen", "stun\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "ART", "ADJA", "NN", "$(", "PWAV", "VAFIN", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Da ich mit stiller lust in deinen schosse sa\u00df/", "tokens": ["Da", "ich", "mit", "stil\u00b7ler", "lust", "in", "dei\u00b7nen", "schos\u00b7se", "sa\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und alle liebligkeit von deinen lippen la\u00df?", "tokens": ["Und", "al\u00b7le", "lieb\u00b7lig\u00b7keit", "von", "dei\u00b7nen", "lip\u00b7pen", "la\u00df", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "APPR", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "5. Ach freylich ist es au\u00df/ ein ander hat das gl\u00fccke/", "tokens": ["Ach", "frey\u00b7lich", "ist", "es", "au\u00df", "/", "ein", "an\u00b7der", "hat", "das", "gl\u00fc\u00b7cke", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "ADV", "VAFIN", "PPER", "PTKVZ", "$(", "ART", "ADJD", "VAFIN", "PDS", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der jagt durch nneue spa\u00df den alten schertz zur\u00fccke/", "tokens": ["Der", "jagt", "durch", "nneu\u00b7e", "spa\u00df", "den", "al\u00b7ten", "schertz", "zu\u00b7r\u00fc\u00b7cke", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPR", "ADJA", "VVFIN", "ART", "ADJA", "NN", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und wenn er in der lust sein mandeln\u00fc\u00dfgen schmeckt/", "tokens": ["Und", "wenn", "er", "in", "der", "lust", "sein", "man\u00b7del\u00b7n\u00fc\u00df\u00b7gen", "schmeckt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "APPR", "ART", "NN", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So l\u00e4cht er mich wol au\u00df da\u00df ich den rand geleckt.", "tokens": ["So", "l\u00e4cht", "er", "mich", "wol", "au\u00df", "da\u00df", "ich", "den", "rand", "ge\u00b7leckt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "ADV", "APPR", "KOUS", "PPER", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "6. Di\u00df ist mir endlich lieb/ da\u00df du dich hast erkl\u00e4ret:", "tokens": ["Di\u00df", "ist", "mir", "end\u00b7lich", "lieb", "/", "da\u00df", "du", "dich", "hast", "er\u00b7kl\u00e4\u00b7ret", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "ADV", "ADJD", "$(", "KOUS", "PPER", "PPER", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und also sind wir doch einander nicht bescheret:", "tokens": ["Und", "al\u00b7so", "sind", "wir", "doch", "ein\u00b7an\u00b7der", "nicht", "be\u00b7sche\u00b7ret", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "PPER", "ADV", "ADV", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Drum reis\u2019 ich auch von hier. Wie solte mir geschehn/", "tokens": ["Drum", "reis'", "ich", "auch", "von", "hier", ".", "Wie", "sol\u00b7te", "mir", "ge\u00b7schehn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "ADV", "APPR", "ADV", "$.", "PWAV", "VMFIN", "PPER", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wenn ich das hertzeleid solt alle tage sehn.", "tokens": ["Wenn", "ich", "das", "hert\u00b7ze\u00b7leid", "solt", "al\u00b7le", "ta\u00b7ge", "sehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VMFIN", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "7. Mein kind ich bitte nur durch ihre weichen h\u00e4nde/", "tokens": ["Mein", "kind", "ich", "bit\u00b7te", "nur", "durch", "ih\u00b7re", "wei\u00b7chen", "h\u00e4n\u00b7de", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PPER", "ADV", "ADV", "APPR", "PPOSAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und durch den rothen mund/ sie mach ein gutes ende.", "tokens": ["Und", "durch", "den", "ro\u00b7then", "mund", "/", "sie", "mach", "ein", "gu\u00b7tes", "en\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "$(", "PPER", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wiewol mein abschied ihut ihr nicht zu \u00fcbrig weh.", "tokens": ["Wie\u00b7wol", "mein", "ab\u00b7schied", "i\u00b7hut", "ihr", "nicht", "zu", "\u00fcb\u00b7rig", "weh", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "VVFIN", "PPER", "PTKNEG", "PTKA", "ADJD", "PTKVZ", "$."], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Es ist auch schon genung da\u00df ich ins elend geh.", "tokens": ["Es", "ist", "auch", "schon", "ge\u00b7nung", "da\u00df", "ich", "ins", "e\u00b7lend", "geh."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "abbreviation"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "ADV", "KOUS", "PPER", "APPRART", "ADJD", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.8": {"line.1": {"text": "8. Der himmel segne sie mit ihren sch\u00f6nen gaben/", "tokens": ["Der", "him\u00b7mel", "seg\u00b7ne", "sie", "mit", "ih\u00b7ren", "sch\u00f6\u00b7nen", "ga\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "APPR", "PPOSAT", "ADJA", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Kein mensch hats wol gemerckt da\u00df wir gel\u00f6ffelt haben/", "tokens": ["Kein", "mensch", "hats", "wol", "ge\u00b7merckt", "da\u00df", "wir", "ge\u00b7l\u00f6f\u00b7felt", "ha\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "ADV", "VVPP", "KOUS", "PPER", "VVPP", "VAINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Drum schweig ich auch davon/ und sage mit bedacht/", "tokens": ["Drum", "schweig", "ich", "auch", "da\u00b7von", "/", "und", "sa\u00b7ge", "mit", "be\u00b7dacht", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "ADV", "PAV", "$(", "KON", "VVFIN", "APPR", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Gantz still da\u00df niemand h\u00f6rt/ mein hertzgen gute nacht.", "tokens": ["Gantz", "still", "da\u00df", "nie\u00b7mand", "h\u00f6rt", "/", "mein", "hertz\u00b7gen", "gu\u00b7te", "nacht", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KOUS", "PIS", "VVFIN", "$(", "PPOSAT", "ADJA", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}