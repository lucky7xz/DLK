{"textgrid.poem.39014": {"metadata": {"author": {"name": "Tieck, Ludwig", "birth": "N.A.", "death": "N.A."}, "title": "1L: Die k\u00fcnstlichen Burattini zu sehn", "genre": "verse", "period": "N.A.", "pub_year": 1813, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Die k\u00fcnstlichen Burattini zu sehn", "tokens": ["Die", "k\u00fcnst\u00b7li\u00b7chen", "Bu\u00b7rat\u00b7ti\u00b7ni", "zu", "sehn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Sucht' ich in finstrer Nacht", "tokens": ["Sucht'", "ich", "in", "finst\u00b7rer", "Nacht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "APPR", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Den gro\u00dfen Platz Navona.", "tokens": ["Den", "gro\u00b7\u00dfen", "Platz", "Na\u00b7vo\u00b7na", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NE", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "Im Corso blendeten die Feuer,", "tokens": ["Im", "Cor\u00b7so", "blen\u00b7de\u00b7ten", "die", "Feu\u00b7er", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Bet\u00e4ubte das Geschrei", "tokens": ["Be\u00b7t\u00e4ub\u00b7te", "das", "Ge\u00b7schrei"], "token_info": ["word", "word", "word"], "pos": ["VVFIN", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Der Fruchtverk\u00e4ufer.", "tokens": ["Der", "Frucht\u00b7ver\u00b7k\u00e4u\u00b7fer", "."], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.7": {"text": "Still und dunkel in den Nebengassen:", "tokens": ["Still", "und", "dun\u00b7kel", "in", "den", "Ne\u00b7ben\u00b7gas\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "KON", "ADJD", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.8": {"text": "Als ich geblendet, bet\u00e4ubt", "tokens": ["Als", "ich", "ge\u00b7blen\u00b7det", ",", "be\u00b7t\u00e4ubt"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["KOUS", "PPER", "VVPP", "$,", "VVPP"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.9": {"text": "Den Weg erfrage,", "tokens": ["Den", "Weg", "er\u00b7fra\u00b7ge", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.10": {"text": "St\u00fcrzt mit L\u00f6ffel und Sch\u00fcrze", "tokens": ["St\u00fcrzt", "mit", "L\u00f6f\u00b7fel", "und", "Sch\u00fcr\u00b7ze"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "NN", "KON", "NN"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.11": {"text": "Ein Koch aus dem Pallaste", "tokens": ["Ein", "Koch", "aus", "dem", "Pal\u00b7las\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NE", "APPR", "ART", "NN"], "meter": "-+---+-", "measure": "dactylic.init"}, "line.12": {"text": "Und f\u00fchrt mich belehrend und schwatzend", "tokens": ["Und", "f\u00fchrt", "mich", "be\u00b7leh\u00b7rend", "und", "schwat\u00b7zend"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "VVPP", "KON", "ADJD"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.13": {"text": "Einige Stra\u00dfen hindurch,", "tokens": ["Ei\u00b7ni\u00b7ge", "Stra\u00b7\u00dfen", "hin\u00b7durch", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PIAT", "NN", "PAV", "$,"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.14": {"text": "Sich dann entschuldigend", "tokens": ["Sich", "dann", "ent\u00b7schul\u00b7di\u00b7gend"], "token_info": ["word", "word", "word"], "pos": ["PRF", "ADV", "VVPP"], "meter": "-+-+--", "measure": "unknown.measure.di"}, "line.15": {"text": "Da\u00df seine Bestimmung zur\u00fcck ihn rufe", "tokens": ["Da\u00df", "sei\u00b7ne", "Be\u00b7stim\u00b7mung", "zu\u00b7r\u00fcck", "ihn", "ru\u00b7fe"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPOSAT", "NN", "PTKVZ", "PPER", "VVFIN"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.16": {"text": "Rennt er hastig von mir", "tokens": ["Rennt", "er", "has\u00b7tig", "von", "mir"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADJD", "APPR", "PPER"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.17": {"text": "Ohne nur Dank zu erwarten.", "tokens": ["Oh\u00b7ne", "nur", "Dank", "zu", "er\u00b7war\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "NN", "PTKZU", "VVINF", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.18": {"text": "Seiner Weisung folgend", "tokens": ["Sei\u00b7ner", "Wei\u00b7sung", "fol\u00b7gend"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "NN", "ADJD"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.19": {"text": "Tapp' ich durch die Finsterni\u00df hin", "tokens": ["Tapp'", "ich", "durch", "die", "Fins\u00b7ter\u00b7ni\u00df", "hin"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVIMP", "PPER", "APPR", "ART", "NN", "PTKVZ"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.20": {"text": "Die dichter und dichter sich vor mich baut.", "tokens": ["Die", "dich\u00b7ter", "und", "dich\u00b7ter", "sich", "vor", "mich", "baut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "KON", "PPER", "PRF", "APPR", "PPER", "VVFIN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.21": {"text": "Endlich steh' ich ruhend,", "tokens": ["End\u00b7lich", "steh'", "ich", "ru\u00b7hend", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "VVPP", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.22": {"text": "Rathlos und verirrt,", "tokens": ["Rath\u00b7los", "und", "ver\u00b7irrt", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "VVPP", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.23": {"text": "Kein Mensch in der N\u00e4he.", "tokens": ["Kein", "Mensch", "in", "der", "N\u00e4\u00b7he", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "APPR", "ART", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.2": {"line.1": {"text": "Da wandelt' eine Gestalt heran:", "tokens": ["Da", "wan\u00b7delt'", "ei\u00b7ne", "Ge\u00b7stalt", "he\u00b7ran", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Wo geh' ich wohl zum Platz Navona?", "tokens": ["Wo", "geh'", "ich", "wohl", "zum", "Platz", "Na\u00b7vo\u00b7na", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "ADV", "APPRART", "NN", "NE", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Ert\u00f6nt die bescheidene Frage.", "tokens": ["Er\u00b7t\u00f6nt", "die", "be\u00b7schei\u00b7de\u00b7ne", "Fra\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Der edle R\u00f6mer kommt mir n\u00e4her.", "tokens": ["Der", "ed\u00b7le", "R\u00f6\u00b7mer", "kommt", "mir", "n\u00e4\u00b7her", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Sie sind ein Fremder, so beginnt er,", "tokens": ["Sie", "sind", "ein", "Frem\u00b7der", ",", "so", "be\u00b7ginnt", "er", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "$,", "ADV", "VVFIN", "PPER", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Kein Wunder, da\u00df in der furchtbaren Finsterni\u00df", "tokens": ["Kein", "Wun\u00b7der", ",", "da\u00df", "in", "der", "furcht\u00b7ba\u00b7ren", "Fins\u00b7ter\u00b7ni\u00df"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "$,", "KOUS", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Ihr Fu\u00df irre geht,", "tokens": ["Ihr", "Fu\u00df", "ir\u00b7re", "geht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "NN", "VVFIN", "$,"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.8": {"text": "Und wir Armen, Elenden", "tokens": ["Und", "wir", "Ar\u00b7men", ",", "E\u00b7len\u00b7den"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["KON", "PPER", "NN", "$,", "NN"], "meter": "+-+-+--", "measure": "unknown.measure.tri"}, "line.9": {"text": "Stehn noch so weit andern Nationen zur\u00fcck,", "tokens": ["Stehn", "noch", "so", "weit", "an\u00b7dern", "Na\u00b7ti\u00b7o\u00b7nen", "zu\u00b7r\u00fcck", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ADV", "ADJD", "ADJA", "NN", "PTKVZ", "$,"], "meter": "+--+--+-+--+", "measure": "dactylic.di.plus"}, "line.10": {"text": "Da\u00df wir niemals Laternen z\u00fcnden", "tokens": ["Da\u00df", "wir", "nie\u00b7mals", "La\u00b7ter\u00b7nen", "z\u00fcn\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "NN", "VVINF"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.11": {"text": "Als nur vor Marienbildern. \u2013", "tokens": ["Als", "nur", "vor", "Ma\u00b7ri\u00b7en\u00b7bil\u00b7dern", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "ADV", "APPR", "NN", "$.", "$("], "meter": "+---+-+-", "measure": "dactylic.init"}, "line.12": {"text": "Er trat mir n\u00e4her und fa\u00dfte meine Hand:", "tokens": ["Er", "trat", "mir", "n\u00e4\u00b7her", "und", "fa\u00df\u00b7te", "mei\u00b7ne", "Hand", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADJD", "KON", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.13": {"text": "Doch gute, h\u00fclfreiche Menschen,", "tokens": ["Doch", "gu\u00b7te", ",", "h\u00fclf\u00b7rei\u00b7che", "Men\u00b7schen", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ADJA", "$,", "ADJA", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.14": {"text": "Sprach er leiser und liebevoller,", "tokens": ["Sprach", "er", "lei\u00b7ser", "und", "lie\u00b7be\u00b7vol\u00b7ler", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADJD", "KON", "ADJD", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.15": {"text": "Ersetzen Licht und Fackel;", "tokens": ["Er\u00b7set\u00b7zen", "Licht", "und", "Fa\u00b7ckel", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "KON", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.16": {"text": "Und wer w\u00e4re der Elende,", "tokens": ["Und", "wer", "w\u00e4\u00b7re", "der", "E\u00b7len\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VAFIN", "ART", "NN", "$,"], "meter": "--+--+--", "measure": "anapaest.di.plus"}, "line.17": {"text": "Der nicht gern und mit Freuden selbst", "tokens": ["Der", "nicht", "gern", "und", "mit", "Freu\u00b7den", "selbst"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "PTKNEG", "ADV", "KON", "APPR", "NN", "ADV"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.18": {"text": "Dem verirrten N\u00e4chsten h\u00fclfe?", "tokens": ["Dem", "ver\u00b7irr\u00b7ten", "N\u00e4chs\u00b7ten", "h\u00fcl\u00b7fe", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.19": {"text": "Sei's auch mit Opfer der Zeit,", "tokens": ["Sei's", "auch", "mit", "Op\u00b7fer", "der", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "APPR", "NN", "ART", "NN", "$,"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.20": {"text": "Da\u00df er mit ihm bleibt und wandelt.", "tokens": ["Da\u00df", "er", "mit", "ihm", "bleibt", "und", "wan\u00b7delt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PPER", "VVFIN", "KON", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.21": {"text": "Und wehe dem Eigenn\u00fctzigen,", "tokens": ["Und", "we\u00b7he", "dem", "Ei\u00b7gen\u00b7n\u00fct\u00b7zi\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "ART", "NN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.22": {"text": "(er ist kein \u00e4chter R\u00f6mer)", "tokens": ["(", "er", "ist", "kein", "\u00e4ch\u00b7ter", "R\u00f6\u00b7mer", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "PIAT", "ADJA", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.23": {"text": "Der nur um schn\u00f6des Geld", "tokens": ["Der", "nur", "um", "schn\u00f6\u00b7des", "Geld"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "APPR", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.24": {"text": "Dem Fremdling seine Dienste widmet.", "tokens": ["Dem", "Fremd\u00b7ling", "sei\u00b7ne", "Diens\u00b7te", "wid\u00b7met", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.25": {"text": "Nein, immer war unsre hohe Stadt ber\u00fchmt,", "tokens": ["Nein", ",", "im\u00b7mer", "war", "uns\u00b7re", "ho\u00b7he", "Stadt", "be\u00b7r\u00fchmt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "ADV", "VAFIN", "PPOSAT", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+----+-+-+", "measure": "dactylic.init"}, "line.26": {"text": "Da\u00df sie gern H\u00fclfe, Rath und Trost spendete,", "tokens": ["Da\u00df", "sie", "gern", "H\u00fcl\u00b7fe", ",", "Rath", "und", "Trost", "spen\u00b7de\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "NN", "$,", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-++-+", "measure": "unknown.measure.hexa"}, "line.27": {"text": "Ohne nach dem blanken Gewinn zu schielen.", "tokens": ["Oh\u00b7ne", "nach", "dem", "blan\u00b7ken", "Ge\u00b7winn", "zu", "schie\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "APPR", "ART", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.28": {"text": "Auch ich r\u00fchme mich ein solcher B\u00fcrger zu seyn,", "tokens": ["Auch", "ich", "r\u00fch\u00b7me", "mich", "ein", "sol\u00b7cher", "B\u00fcr\u00b7ger", "zu", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VVFIN", "PPER", "ART", "PIAT", "NN", "PTKZU", "VAINF", "$,"], "meter": "+-+-+-+-+--+", "measure": "iambic.hexa.chol"}, "line.29": {"text": "Und mancher Dankbare nennt meinen Namen", "tokens": ["Und", "man\u00b7cher", "Dank\u00b7ba\u00b7re", "nennt", "mei\u00b7nen", "Na\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PIAT", "NN", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.30": {"text": "Und mancher Undankbare verschweigt ihn.", "tokens": ["Und", "man\u00b7cher", "Un\u00b7dank\u00b7ba\u00b7re", "ver\u00b7schweigt", "ihn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "VVFIN", "PPER", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.31": {"text": "So hat das Schicksal es freilich gef\u00fcgt,", "tokens": ["So", "hat", "das", "Schick\u00b7sal", "es", "frei\u00b7lich", "ge\u00b7f\u00fcgt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.32": {"text": "Da\u00df ich meiner Gro\u00dfmuth nicht mehr gehorchen darf,", "tokens": ["Da\u00df", "ich", "mei\u00b7ner", "Gro\u00df\u00b7muth", "nicht", "mehr", "ge\u00b7hor\u00b7chen", "darf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "PTKNEG", "ADV", "VVINF", "VMFIN", "$,"], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.33": {"text": "Flehende Kinder, die weinende Gattin", "tokens": ["Fle\u00b7hen\u00b7de", "Kin\u00b7der", ",", "die", "wei\u00b7nen\u00b7de", "Gat\u00b7tin"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ADJA", "NN", "$,", "ART", "ADJA", "NN"], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.34": {"text": "Jammern ihr m\u00e4chtiges Nein entgegen,", "tokens": ["Jam\u00b7mern", "ihr", "m\u00e4ch\u00b7ti\u00b7ges", "Nein", "ent\u00b7ge\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "ADJA", "NN", "PTKVZ", "$,"], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}, "line.35": {"text": "Doch kann sich mein Herz nicht gew\u00e4hren", "tokens": ["Doch", "kann", "sich", "mein", "Herz", "nicht", "ge\u00b7w\u00e4h\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VMFIN", "PRF", "PPOSAT", "NN", "PTKNEG", "VVINF"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.36": {"text": "Eng und kargend nach Geld zu trachten.", "tokens": ["Eng", "und", "kar\u00b7gend", "nach", "Geld", "zu", "trach\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "ADJD", "APPR", "NN", "PTKZU", "VVINF", "$."], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.37": {"text": "Anders ist es freilich mit Edlen,", "tokens": ["An\u00b7ders", "ist", "es", "frei\u00b7lich", "mit", "Ed\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "APPR", "NN", "$,"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.38": {"text": "Von denen darf auch der Stolze empfangen,", "tokens": ["Von", "de\u00b7nen", "darf", "auch", "der", "Stol\u00b7ze", "emp\u00b7fan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDS", "VMFIN", "ADV", "ART", "NN", "VVPP", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.39": {"text": "Und der Freigebige, der tausendmal gab,", "tokens": ["Und", "der", "Frei\u00b7ge\u00b7bi\u00b7ge", ",", "der", "tau\u00b7send\u00b7mal", "gab", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "PRELS", "ADV", "VVFIN", "$,"], "meter": "--+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.40": {"text": "Werde nicht roth auch einmal zu nehmen,", "tokens": ["Wer\u00b7de", "nicht", "roth", "auch", "ein\u00b7mal", "zu", "neh\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PTKNEG", "ADJD", "ADV", "ADV", "PTKZU", "VVINF", "$,"], "meter": "+-+---+-+-", "measure": "unknown.measure.tetra"}, "line.41": {"text": "Denn das ist gewi\u00df,", "tokens": ["Denn", "das", "ist", "ge\u00b7wi\u00df", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VAFIN", "ADV", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.42": {"text": "Die gr\u00f6\u00dfesten Herzen,", "tokens": ["Die", "gr\u00f6\u00b7\u00dfes\u00b7ten", "Her\u00b7zen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.43": {"text": "Die feinsten Gem\u00fcther,", "tokens": ["Die", "feins\u00b7ten", "Ge\u00b7m\u00fc\u00b7ther", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.44": {"text": "Kommen jenseit der Alpen uns her\u00fcber.", "tokens": ["Kom\u00b7men", "jen\u00b7seit", "der", "Al\u00b7pen", "uns", "her\u00b7\u00fc\u00b7ber", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "PPER", "ADV", "$."], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}}, "stanza.3": {"line.1": {"text": "Ich, des Geschw\u00e4tzes m\u00fcde,", "tokens": ["Ich", ",", "des", "Ge\u00b7schw\u00e4t\u00b7zes", "m\u00fc\u00b7de", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Hatte schon die Silbergroschen gefa\u00dft,", "tokens": ["Hat\u00b7te", "schon", "die", "Sil\u00b7ber\u00b7gro\u00b7schen", "ge\u00b7fa\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.3": {"text": "Die ihm nun in die Finger glitten:", "tokens": ["Die", "ihm", "nun", "in", "die", "Fin\u00b7ger", "glit\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Doch wo ist der Platz?", "tokens": ["Doch", "wo", "ist", "der", "Platz", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "VAFIN", "ART", "NN", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.5": {"text": "Fragt' ich ungeduldig.", "tokens": ["Fragt'", "ich", "un\u00b7ge\u00b7dul\u00b7dig", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.4": {"line.1": {"text": "Trefflichster, sagte der Schalk,", "tokens": ["Treff\u00b7lichs\u00b7ter", ",", "sag\u00b7te", "der", "Schalk", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Indem er mit leiser Hand", "tokens": ["In\u00b7dem", "er", "mit", "lei\u00b7ser", "Hand"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Die Wange mir r\u00fchrend den Kopf mir richtete,", "tokens": ["Die", "Wan\u00b7ge", "mir", "r\u00fch\u00b7rend", "den", "Kopf", "mir", "rich\u00b7te\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPER", "VVPP", "ART", "NN", "PPER", "VVFIN", "$,"], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Hier liegt er vor denenselben,", "tokens": ["Hier", "liegt", "er", "vor", "de\u00b7nen\u00b7sel\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "PDAT", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Wir stehn schon darauf.", "tokens": ["Wir", "stehn", "schon", "da\u00b7rauf", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PAV", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}}, "stanza.5": {"line.1": {"text": "Weder mein Lachen noch den Zorn erwartend,", "tokens": ["We\u00b7der", "mein", "La\u00b7chen", "noch", "den", "Zorn", "er\u00b7war\u00b7tend", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "ADV", "ART", "NN", "VVPP", "$,"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.2": {"text": "War er schnell in der Dunkelheit entwichen.", "tokens": ["War", "er", "schnell", "in", "der", "Dun\u00b7kel\u00b7heit", "ent\u00b7wi\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADJD", "APPR", "ART", "NN", "VVPP", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}}, "stanza.6": {"line.1": {"text": "Die k\u00fcnstlichen Burattini zu sehn", "tokens": ["Die", "k\u00fcnst\u00b7li\u00b7chen", "Bu\u00b7rat\u00b7ti\u00b7ni", "zu", "sehn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Sucht' ich in finstrer Nacht", "tokens": ["Sucht'", "ich", "in", "finst\u00b7rer", "Nacht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "APPR", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Den gro\u00dfen Platz Navona.", "tokens": ["Den", "gro\u00b7\u00dfen", "Platz", "Na\u00b7vo\u00b7na", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NE", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "Im Corso blendeten die Feuer,", "tokens": ["Im", "Cor\u00b7so", "blen\u00b7de\u00b7ten", "die", "Feu\u00b7er", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Bet\u00e4ubte das Geschrei", "tokens": ["Be\u00b7t\u00e4ub\u00b7te", "das", "Ge\u00b7schrei"], "token_info": ["word", "word", "word"], "pos": ["VVFIN", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Der Fruchtverk\u00e4ufer.", "tokens": ["Der", "Frucht\u00b7ver\u00b7k\u00e4u\u00b7fer", "."], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.7": {"text": "Still und dunkel in den Nebengassen:", "tokens": ["Still", "und", "dun\u00b7kel", "in", "den", "Ne\u00b7ben\u00b7gas\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "KON", "ADJD", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.8": {"text": "Als ich geblendet, bet\u00e4ubt", "tokens": ["Als", "ich", "ge\u00b7blen\u00b7det", ",", "be\u00b7t\u00e4ubt"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["KOUS", "PPER", "VVPP", "$,", "VVPP"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.9": {"text": "Den Weg erfrage,", "tokens": ["Den", "Weg", "er\u00b7fra\u00b7ge", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.10": {"text": "St\u00fcrzt mit L\u00f6ffel und Sch\u00fcrze", "tokens": ["St\u00fcrzt", "mit", "L\u00f6f\u00b7fel", "und", "Sch\u00fcr\u00b7ze"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "NN", "KON", "NN"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.11": {"text": "Ein Koch aus dem Pallaste", "tokens": ["Ein", "Koch", "aus", "dem", "Pal\u00b7las\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NE", "APPR", "ART", "NN"], "meter": "-+---+-", "measure": "dactylic.init"}, "line.12": {"text": "Und f\u00fchrt mich belehrend und schwatzend", "tokens": ["Und", "f\u00fchrt", "mich", "be\u00b7leh\u00b7rend", "und", "schwat\u00b7zend"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "VVPP", "KON", "ADJD"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.13": {"text": "Einige Stra\u00dfen hindurch,", "tokens": ["Ei\u00b7ni\u00b7ge", "Stra\u00b7\u00dfen", "hin\u00b7durch", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PIAT", "NN", "PAV", "$,"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.14": {"text": "Sich dann entschuldigend", "tokens": ["Sich", "dann", "ent\u00b7schul\u00b7di\u00b7gend"], "token_info": ["word", "word", "word"], "pos": ["PRF", "ADV", "VVPP"], "meter": "-+-+--", "measure": "unknown.measure.di"}, "line.15": {"text": "Da\u00df seine Bestimmung zur\u00fcck ihn rufe", "tokens": ["Da\u00df", "sei\u00b7ne", "Be\u00b7stim\u00b7mung", "zu\u00b7r\u00fcck", "ihn", "ru\u00b7fe"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPOSAT", "NN", "PTKVZ", "PPER", "VVFIN"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.16": {"text": "Rennt er hastig von mir", "tokens": ["Rennt", "er", "has\u00b7tig", "von", "mir"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADJD", "APPR", "PPER"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.17": {"text": "Ohne nur Dank zu erwarten.", "tokens": ["Oh\u00b7ne", "nur", "Dank", "zu", "er\u00b7war\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "NN", "PTKZU", "VVINF", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.18": {"text": "Seiner Weisung folgend", "tokens": ["Sei\u00b7ner", "Wei\u00b7sung", "fol\u00b7gend"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "NN", "ADJD"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.19": {"text": "Tapp' ich durch die Finsterni\u00df hin", "tokens": ["Tapp'", "ich", "durch", "die", "Fins\u00b7ter\u00b7ni\u00df", "hin"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVIMP", "PPER", "APPR", "ART", "NN", "PTKVZ"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.20": {"text": "Die dichter und dichter sich vor mich baut.", "tokens": ["Die", "dich\u00b7ter", "und", "dich\u00b7ter", "sich", "vor", "mich", "baut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "KON", "PPER", "PRF", "APPR", "PPER", "VVFIN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.21": {"text": "Endlich steh' ich ruhend,", "tokens": ["End\u00b7lich", "steh'", "ich", "ru\u00b7hend", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "VVPP", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.22": {"text": "Rathlos und verirrt,", "tokens": ["Rath\u00b7los", "und", "ver\u00b7irrt", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "VVPP", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.23": {"text": "Kein Mensch in der N\u00e4he.", "tokens": ["Kein", "Mensch", "in", "der", "N\u00e4\u00b7he", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "APPR", "ART", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.7": {"line.1": {"text": "Da wandelt' eine Gestalt heran:", "tokens": ["Da", "wan\u00b7delt'", "ei\u00b7ne", "Ge\u00b7stalt", "he\u00b7ran", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Wo geh' ich wohl zum Platz Navona?", "tokens": ["Wo", "geh'", "ich", "wohl", "zum", "Platz", "Na\u00b7vo\u00b7na", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "ADV", "APPRART", "NN", "NE", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Ert\u00f6nt die bescheidene Frage.", "tokens": ["Er\u00b7t\u00f6nt", "die", "be\u00b7schei\u00b7de\u00b7ne", "Fra\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Der edle R\u00f6mer kommt mir n\u00e4her.", "tokens": ["Der", "ed\u00b7le", "R\u00f6\u00b7mer", "kommt", "mir", "n\u00e4\u00b7her", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Sie sind ein Fremder, so beginnt er,", "tokens": ["Sie", "sind", "ein", "Frem\u00b7der", ",", "so", "be\u00b7ginnt", "er", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "$,", "ADV", "VVFIN", "PPER", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Kein Wunder, da\u00df in der furchtbaren Finsterni\u00df", "tokens": ["Kein", "Wun\u00b7der", ",", "da\u00df", "in", "der", "furcht\u00b7ba\u00b7ren", "Fins\u00b7ter\u00b7ni\u00df"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "$,", "KOUS", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Ihr Fu\u00df irre geht,", "tokens": ["Ihr", "Fu\u00df", "ir\u00b7re", "geht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "NN", "VVFIN", "$,"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.8": {"text": "Und wir Armen, Elenden", "tokens": ["Und", "wir", "Ar\u00b7men", ",", "E\u00b7len\u00b7den"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["KON", "PPER", "NN", "$,", "NN"], "meter": "+-+-+--", "measure": "unknown.measure.tri"}, "line.9": {"text": "Stehn noch so weit andern Nationen zur\u00fcck,", "tokens": ["Stehn", "noch", "so", "weit", "an\u00b7dern", "Na\u00b7ti\u00b7o\u00b7nen", "zu\u00b7r\u00fcck", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ADV", "ADJD", "ADJA", "NN", "PTKVZ", "$,"], "meter": "+--+--+-+--+", "measure": "dactylic.di.plus"}, "line.10": {"text": "Da\u00df wir niemals Laternen z\u00fcnden", "tokens": ["Da\u00df", "wir", "nie\u00b7mals", "La\u00b7ter\u00b7nen", "z\u00fcn\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "NN", "VVINF"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.11": {"text": "Als nur vor Marienbildern. \u2013", "tokens": ["Als", "nur", "vor", "Ma\u00b7ri\u00b7en\u00b7bil\u00b7dern", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "ADV", "APPR", "NN", "$.", "$("], "meter": "+---+-+-", "measure": "dactylic.init"}, "line.12": {"text": "Er trat mir n\u00e4her und fa\u00dfte meine Hand:", "tokens": ["Er", "trat", "mir", "n\u00e4\u00b7her", "und", "fa\u00df\u00b7te", "mei\u00b7ne", "Hand", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADJD", "KON", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.13": {"text": "Doch gute, h\u00fclfreiche Menschen,", "tokens": ["Doch", "gu\u00b7te", ",", "h\u00fclf\u00b7rei\u00b7che", "Men\u00b7schen", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ADJA", "$,", "ADJA", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.14": {"text": "Sprach er leiser und liebevoller,", "tokens": ["Sprach", "er", "lei\u00b7ser", "und", "lie\u00b7be\u00b7vol\u00b7ler", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADJD", "KON", "ADJD", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.15": {"text": "Ersetzen Licht und Fackel;", "tokens": ["Er\u00b7set\u00b7zen", "Licht", "und", "Fa\u00b7ckel", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "KON", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.16": {"text": "Und wer w\u00e4re der Elende,", "tokens": ["Und", "wer", "w\u00e4\u00b7re", "der", "E\u00b7len\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VAFIN", "ART", "NN", "$,"], "meter": "--+--+--", "measure": "anapaest.di.plus"}, "line.17": {"text": "Der nicht gern und mit Freuden selbst", "tokens": ["Der", "nicht", "gern", "und", "mit", "Freu\u00b7den", "selbst"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "PTKNEG", "ADV", "KON", "APPR", "NN", "ADV"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.18": {"text": "Dem verirrten N\u00e4chsten h\u00fclfe?", "tokens": ["Dem", "ver\u00b7irr\u00b7ten", "N\u00e4chs\u00b7ten", "h\u00fcl\u00b7fe", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.19": {"text": "Sei's auch mit Opfer der Zeit,", "tokens": ["Sei's", "auch", "mit", "Op\u00b7fer", "der", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "APPR", "NN", "ART", "NN", "$,"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.20": {"text": "Da\u00df er mit ihm bleibt und wandelt.", "tokens": ["Da\u00df", "er", "mit", "ihm", "bleibt", "und", "wan\u00b7delt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PPER", "VVFIN", "KON", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.21": {"text": "Und wehe dem Eigenn\u00fctzigen,", "tokens": ["Und", "we\u00b7he", "dem", "Ei\u00b7gen\u00b7n\u00fct\u00b7zi\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "ART", "NN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.22": {"text": "(er ist kein \u00e4chter R\u00f6mer)", "tokens": ["(", "er", "ist", "kein", "\u00e4ch\u00b7ter", "R\u00f6\u00b7mer", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "PIAT", "ADJA", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.23": {"text": "Der nur um schn\u00f6des Geld", "tokens": ["Der", "nur", "um", "schn\u00f6\u00b7des", "Geld"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "APPR", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.24": {"text": "Dem Fremdling seine Dienste widmet.", "tokens": ["Dem", "Fremd\u00b7ling", "sei\u00b7ne", "Diens\u00b7te", "wid\u00b7met", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.25": {"text": "Nein, immer war unsre hohe Stadt ber\u00fchmt,", "tokens": ["Nein", ",", "im\u00b7mer", "war", "uns\u00b7re", "ho\u00b7he", "Stadt", "be\u00b7r\u00fchmt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "ADV", "VAFIN", "PPOSAT", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+----+-+-+", "measure": "dactylic.init"}, "line.26": {"text": "Da\u00df sie gern H\u00fclfe, Rath und Trost spendete,", "tokens": ["Da\u00df", "sie", "gern", "H\u00fcl\u00b7fe", ",", "Rath", "und", "Trost", "spen\u00b7de\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "NN", "$,", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-++-+", "measure": "unknown.measure.hexa"}, "line.27": {"text": "Ohne nach dem blanken Gewinn zu schielen.", "tokens": ["Oh\u00b7ne", "nach", "dem", "blan\u00b7ken", "Ge\u00b7winn", "zu", "schie\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "APPR", "ART", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.28": {"text": "Auch ich r\u00fchme mich ein solcher B\u00fcrger zu seyn,", "tokens": ["Auch", "ich", "r\u00fch\u00b7me", "mich", "ein", "sol\u00b7cher", "B\u00fcr\u00b7ger", "zu", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VVFIN", "PPER", "ART", "PIAT", "NN", "PTKZU", "VAINF", "$,"], "meter": "+-+-+-+-+--+", "measure": "iambic.hexa.chol"}, "line.29": {"text": "Und mancher Dankbare nennt meinen Namen", "tokens": ["Und", "man\u00b7cher", "Dank\u00b7ba\u00b7re", "nennt", "mei\u00b7nen", "Na\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PIAT", "NN", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.30": {"text": "Und mancher Undankbare verschweigt ihn.", "tokens": ["Und", "man\u00b7cher", "Un\u00b7dank\u00b7ba\u00b7re", "ver\u00b7schweigt", "ihn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "VVFIN", "PPER", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.31": {"text": "So hat das Schicksal es freilich gef\u00fcgt,", "tokens": ["So", "hat", "das", "Schick\u00b7sal", "es", "frei\u00b7lich", "ge\u00b7f\u00fcgt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.32": {"text": "Da\u00df ich meiner Gro\u00dfmuth nicht mehr gehorchen darf,", "tokens": ["Da\u00df", "ich", "mei\u00b7ner", "Gro\u00df\u00b7muth", "nicht", "mehr", "ge\u00b7hor\u00b7chen", "darf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "PTKNEG", "ADV", "VVINF", "VMFIN", "$,"], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.33": {"text": "Flehende Kinder, die weinende Gattin", "tokens": ["Fle\u00b7hen\u00b7de", "Kin\u00b7der", ",", "die", "wei\u00b7nen\u00b7de", "Gat\u00b7tin"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ADJA", "NN", "$,", "ART", "ADJA", "NN"], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.34": {"text": "Jammern ihr m\u00e4chtiges Nein entgegen,", "tokens": ["Jam\u00b7mern", "ihr", "m\u00e4ch\u00b7ti\u00b7ges", "Nein", "ent\u00b7ge\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "ADJA", "NN", "PTKVZ", "$,"], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}, "line.35": {"text": "Doch kann sich mein Herz nicht gew\u00e4hren", "tokens": ["Doch", "kann", "sich", "mein", "Herz", "nicht", "ge\u00b7w\u00e4h\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VMFIN", "PRF", "PPOSAT", "NN", "PTKNEG", "VVINF"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.36": {"text": "Eng und kargend nach Geld zu trachten.", "tokens": ["Eng", "und", "kar\u00b7gend", "nach", "Geld", "zu", "trach\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "ADJD", "APPR", "NN", "PTKZU", "VVINF", "$."], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.37": {"text": "Anders ist es freilich mit Edlen,", "tokens": ["An\u00b7ders", "ist", "es", "frei\u00b7lich", "mit", "Ed\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "APPR", "NN", "$,"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.38": {"text": "Von denen darf auch der Stolze empfangen,", "tokens": ["Von", "de\u00b7nen", "darf", "auch", "der", "Stol\u00b7ze", "emp\u00b7fan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDS", "VMFIN", "ADV", "ART", "NN", "VVPP", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.39": {"text": "Und der Freigebige, der tausendmal gab,", "tokens": ["Und", "der", "Frei\u00b7ge\u00b7bi\u00b7ge", ",", "der", "tau\u00b7send\u00b7mal", "gab", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "PRELS", "ADV", "VVFIN", "$,"], "meter": "--+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.40": {"text": "Werde nicht roth auch einmal zu nehmen,", "tokens": ["Wer\u00b7de", "nicht", "roth", "auch", "ein\u00b7mal", "zu", "neh\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PTKNEG", "ADJD", "ADV", "ADV", "PTKZU", "VVINF", "$,"], "meter": "+-+---+-+-", "measure": "unknown.measure.tetra"}, "line.41": {"text": "Denn das ist gewi\u00df,", "tokens": ["Denn", "das", "ist", "ge\u00b7wi\u00df", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VAFIN", "ADV", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.42": {"text": "Die gr\u00f6\u00dfesten Herzen,", "tokens": ["Die", "gr\u00f6\u00b7\u00dfes\u00b7ten", "Her\u00b7zen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.43": {"text": "Die feinsten Gem\u00fcther,", "tokens": ["Die", "feins\u00b7ten", "Ge\u00b7m\u00fc\u00b7ther", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.44": {"text": "Kommen jenseit der Alpen uns her\u00fcber.", "tokens": ["Kom\u00b7men", "jen\u00b7seit", "der", "Al\u00b7pen", "uns", "her\u00b7\u00fc\u00b7ber", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "PPER", "ADV", "$."], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}}, "stanza.8": {"line.1": {"text": "Ich, des Geschw\u00e4tzes m\u00fcde,", "tokens": ["Ich", ",", "des", "Ge\u00b7schw\u00e4t\u00b7zes", "m\u00fc\u00b7de", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Hatte schon die Silbergroschen gefa\u00dft,", "tokens": ["Hat\u00b7te", "schon", "die", "Sil\u00b7ber\u00b7gro\u00b7schen", "ge\u00b7fa\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.3": {"text": "Die ihm nun in die Finger glitten:", "tokens": ["Die", "ihm", "nun", "in", "die", "Fin\u00b7ger", "glit\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Doch wo ist der Platz?", "tokens": ["Doch", "wo", "ist", "der", "Platz", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "VAFIN", "ART", "NN", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.5": {"text": "Fragt' ich ungeduldig.", "tokens": ["Fragt'", "ich", "un\u00b7ge\u00b7dul\u00b7dig", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.9": {"line.1": {"text": "Trefflichster, sagte der Schalk,", "tokens": ["Treff\u00b7lichs\u00b7ter", ",", "sag\u00b7te", "der", "Schalk", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Indem er mit leiser Hand", "tokens": ["In\u00b7dem", "er", "mit", "lei\u00b7ser", "Hand"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Die Wange mir r\u00fchrend den Kopf mir richtete,", "tokens": ["Die", "Wan\u00b7ge", "mir", "r\u00fch\u00b7rend", "den", "Kopf", "mir", "rich\u00b7te\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPER", "VVPP", "ART", "NN", "PPER", "VVFIN", "$,"], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Hier liegt er vor denenselben,", "tokens": ["Hier", "liegt", "er", "vor", "de\u00b7nen\u00b7sel\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "PDAT", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Wir stehn schon darauf.", "tokens": ["Wir", "stehn", "schon", "da\u00b7rauf", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PAV", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}}, "stanza.10": {"line.1": {"text": "Weder mein Lachen noch den Zorn erwartend,", "tokens": ["We\u00b7der", "mein", "La\u00b7chen", "noch", "den", "Zorn", "er\u00b7war\u00b7tend", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "ADV", "ART", "NN", "VVPP", "$,"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.2": {"text": "War er schnell in der Dunkelheit entwichen.", "tokens": ["War", "er", "schnell", "in", "der", "Dun\u00b7kel\u00b7heit", "ent\u00b7wi\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADJD", "APPR", "ART", "NN", "VVPP", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}}}}}