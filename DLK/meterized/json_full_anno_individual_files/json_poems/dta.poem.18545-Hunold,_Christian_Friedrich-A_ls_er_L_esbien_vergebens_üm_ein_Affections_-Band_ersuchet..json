{"dta.poem.18545": {"metadata": {"author": {"name": "Hunold, Christian Friedrich", "birth": "N.A.", "death": "N.A."}, "title": "A ls er  L esbien vergebens \u00fcm  \n ein  Affections -Band ersuchet.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1702", "urn": "urn:nbn:de:kobv:b4-200905197766", "language": ["de:0.99"], "booktitle": "Hunold, Christian Friedrich: Die Edle Bem\u00fchung m\u00fcssiger Stunden. Hamburg, 1702."}, "poem": {"stanza.1": {"line.1": {"text": "Beliebtes Lindenfeld! ich soll dir dienstbar seyn/", "tokens": ["Be\u00b7lieb\u00b7tes", "Lin\u00b7den\u00b7feld", "!", "ich", "soll", "dir", "dienst\u00b7bar", "seyn", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$.", "PPER", "VMFIN", "PPER", "ADJD", "VAINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Dieweil dir meine Brust so manchen Seufftzer schencket/", "tokens": ["Die\u00b7weil", "dir", "mei\u00b7ne", "Brust", "so", "man\u00b7chen", "Seufft\u00b7zer", "schen\u00b7cket", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "ADV", "PIAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Du f\u00e4llst mir sch\u00f6ner Ort/ vor allen andern ein/", "tokens": ["Du", "f\u00e4llst", "mir", "sch\u00f6\u00b7ner", "Ort", "/", "vor", "al\u00b7len", "an\u00b7dern", "ein", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADJA", "NN", "$(", "APPR", "PIAT", "PIS", "ART", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So offt nur mein Gem\u00fcth an was galantes dencket.", "tokens": ["So", "offt", "nur", "mein", "Ge\u00b7m\u00fcth", "an", "was", "ga\u00b7lan\u00b7tes", "den\u00b7cket", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "PPOSAT", "NN", "APPR", "PRELS", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Doch dieses alles ist nur der Gedancken Spiel/", "tokens": ["Doch", "die\u00b7ses", "al\u00b7les", "ist", "nur", "der", "Ge\u00b7dan\u00b7cken", "Spiel", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "PIS", "VAFIN", "ADV", "ART", "NN", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Denn niemahls darff ich wohl von dir was liebes hoffen.", "tokens": ["Denn", "nie\u00b7mahls", "darff", "ich", "wohl", "von", "dir", "was", "lie\u00b7bes", "hof\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VMFIN", "PPER", "ADV", "APPR", "PPER", "PIS", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Du weist/ die strenge Hand verr\u00fccket mir das Ziel/", "tokens": ["Du", "weist", "/", "die", "stren\u00b7ge", "Hand", "ver\u00b7r\u00fc\u00b7cket", "mir", "das", "Ziel", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$(", "ART", "ADJA", "NN", "VVFIN", "PPER", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und machet/ da\u00df ich nur was leeres angetroffen.", "tokens": ["Und", "ma\u00b7chet", "/", "da\u00df", "ich", "nur", "was", "lee\u00b7res", "an\u00b7ge\u00b7trof\u00b7fen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$(", "KOUS", "PPER", "ADV", "PWS", "ADJA", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Die Lesbia so dort in deinen Mauren strahlt/", "tokens": ["Die", "Les\u00b7bia", "so", "dort", "in", "dei\u00b7nen", "Mau\u00b7ren", "strahlt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ADV", "APPR", "PPOSAT", "NN", "VVFIN", "$("], "meter": "--+-+-+-+-+", "measure": "anapaest.init"}, "line.10": {"text": "Durch deren Sch\u00f6nheits-Pracht ich dich als Sch\u00f6ne kenne/", "tokens": ["Durch", "de\u00b7ren", "Sch\u00f6n\u00b7heits\u00b7Pracht", "ich", "dich", "als", "Sch\u00f6\u00b7ne", "ken\u00b7ne", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELAT", "NN", "PPER", "PRF", "KOUS", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Hat mein Verlangen nicht mit rechter M\u00fcntz bezahlt/", "tokens": ["Hat", "mein", "Ver\u00b7lan\u00b7gen", "nicht", "mit", "rech\u00b7ter", "M\u00fcntz", "be\u00b7zahlt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "PTKNEG", "APPR", "ADJA", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Und machet/ da\u00df ich dich auch itzo grausam nenne.", "tokens": ["Und", "ma\u00b7chet", "/", "da\u00df", "ich", "dich", "auch", "it\u00b7zo", "grau\u00b7sam", "nen\u00b7ne", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$(", "KOUS", "PPER", "PRF", "ADV", "ADV", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Ihr Auge/ welches stets in holder Anmuth lacht/", "tokens": ["Ihr", "Au\u00b7ge", "/", "wel\u00b7ches", "stets", "in", "hol\u00b7der", "An\u00b7muth", "lacht", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$(", "PWS", "ADV", "APPR", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Lie\u00df mich von aussen nur der Liebe Strahlen lesen/", "tokens": ["Lie\u00df", "mich", "von", "aus\u00b7sen", "nur", "der", "Lie\u00b7be", "Strah\u00b7len", "le\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "APPR", "NE", "ADV", "ART", "NN", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Denn da ich auff den Grund und Uhrsprung war bedacht/", "tokens": ["Denn", "da", "ich", "auff", "den", "Grund", "und", "Uhrs\u00b7prung", "war", "be\u00b7dacht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "APPR", "ART", "NN", "KON", "NN", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "So war es blosser Schertz und H\u00f6fflichkeit gewesen.", "tokens": ["So", "war", "es", "blos\u00b7ser", "Schertz", "und", "H\u00f6ff\u00b7lich\u00b7keit", "ge\u00b7we\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADJA", "NN", "KON", "NN", "VAPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Ich bathe sie mit Flei\u00df nur \u00fcm ein solches Band", "tokens": ["Ich", "ba\u00b7the", "sie", "mit", "Flei\u00df", "nur", "\u00fcm", "ein", "sol\u00b7ches", "Band"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "NN", "ADV", "ADV", "ART", "PIAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Das aus Galanterie offt mancher hat empfangen:", "tokens": ["Das", "aus", "Ga\u00b7lan\u00b7te\u00b7rie", "offt", "man\u00b7cher", "hat", "emp\u00b7fan\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "APPR", "NN", "ADV", "PIS", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Jedoch/ die sch\u00f6ne Sprach: Dis ist ein Liebes Pfand/", "tokens": ["Je\u00b7doch", "/", "die", "sch\u00f6\u00b7ne", "Sprach", ":", "Dis", "ist", "ein", "Lie\u00b7bes", "Pfand", "/"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$(", "ART", "ADJA", "NN", "$.", "PDS", "VAFIN", "ART", "ADJA", "NN", "$("], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.20": {"text": "Und der mein Liebster hei\u00dft/ pflegt nur damit zu prangen.", "tokens": ["Und", "der", "mein", "Liebs\u00b7ter", "hei\u00dft", "/", "pflegt", "nur", "da\u00b7mit", "zu", "pran\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "PPOSAT", "NN", "VVFIN", "$(", "VVFIN", "ADV", "PAV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Und so ward mir der Korb gantz freundlich zugestellt/", "tokens": ["Und", "so", "ward", "mir", "der", "Korb", "gantz", "freund\u00b7lich", "zu\u00b7ge\u00b7stellt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "PPER", "ART", "NN", "ADV", "ADJD", "VVPP", "$("], "meter": "--+--+-+-+-+", "measure": "anapaest.di.plus"}, "line.22": {"text": "Da durch sie sich dennoch gewogen will erweisen;", "tokens": ["Da", "durch", "sie", "sich", "den\u00b7noch", "ge\u00b7wo\u00b7gen", "will", "er\u00b7wei\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPER", "PRF", "ADV", "VVINF", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Denn spricht sie: ", "tokens": ["Denn", "spricht", "sie", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.24": {"text": "So kan dein freyer Sinn mich mehr als g\u00fctig heissen.", "tokens": ["So", "kan", "dein", "frey\u00b7er", "Sinn", "mich", "mehr", "als", "g\u00fc\u00b7tig", "heis\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPOSAT", "ADJA", "NN", "PPER", "PIAT", "KOKOM", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Nun wohl/ ich nehme gern der Freyheit Kleinod an/", "tokens": ["Nun", "wohl", "/", "ich", "neh\u00b7me", "gern", "der", "Frey\u00b7heit", "Klei\u00b7nod", "an", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$(", "PPER", "VVFIN", "ADV", "ART", "NN", "NN", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Und l\u00f6se/ wenn ich kan/ den Geist von schweren Ketten/", "tokens": ["Und", "l\u00f6\u00b7se", "/", "wenn", "ich", "kan", "/", "den", "Geist", "von", "schwe\u00b7ren", "Ket\u00b7ten", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$(", "KOUS", "PPER", "VMFIN", "$(", "ART", "NN", "APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Wenn nur/ was ihre Hand itzo nicht geben kan/", "tokens": ["Wenn", "nur", "/", "was", "ih\u00b7re", "Hand", "it\u00b7zo", "nicht", "ge\u00b7ben", "kan", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "$(", "PWS", "PPOSAT", "NN", "ADV", "PTKNEG", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Die sch\u00f6nen Augen mir nicht schon geschencket h\u00e4tten.", "tokens": ["Die", "sch\u00f6\u00b7nen", "Au\u00b7gen", "mir", "nicht", "schon", "ge\u00b7schen\u00b7cket", "h\u00e4t\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PPER", "PTKNEG", "ADV", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}