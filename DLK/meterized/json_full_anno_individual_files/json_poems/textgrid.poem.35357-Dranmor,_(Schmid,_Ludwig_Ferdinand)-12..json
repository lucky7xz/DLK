{"textgrid.poem.35357": {"metadata": {"author": {"name": "Dranmor, (Schmid, Ludwig Ferdinand)", "birth": "N.A.", "death": "N.A."}, "title": "12.", "genre": "verse", "period": "N.A.", "pub_year": 1855, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ach, wer des Lebens Labyrinthe kennt,", "tokens": ["Ach", ",", "wer", "des", "Le\u00b7bens", "La\u00b7by\u00b7rin\u00b7the", "kennt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "PWS", "ART", "NN", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "L\u00e4\u00dft jede gutgemeinte Regung gelten!", "tokens": ["L\u00e4\u00dft", "je\u00b7de", "gut\u00b7ge\u00b7mein\u00b7te", "Re\u00b7gung", "gel\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Ist doch des Jammers schon genug und selten", "tokens": ["Ist", "doch", "des", "Jam\u00b7mers", "schon", "ge\u00b7nug", "und", "sel\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "ART", "NN", "ADV", "ADV", "KON", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Die Thr\u00e4ne, welche tiefe Furchen brennt.", "tokens": ["Die", "Thr\u00e4\u00b7ne", ",", "wel\u00b7che", "tie\u00b7fe", "Fur\u00b7chen", "brennt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PWAT", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Berauschend sind des Lenzes Wunderm\u00e4ren,", "tokens": ["Be\u00b7rau\u00b7schend", "sind", "des", "Len\u00b7zes", "Wun\u00b7der\u00b7m\u00e4\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Bis wir uns beugen vor des Schicksals Streichen,", "tokens": ["Bis", "wir", "uns", "beu\u00b7gen", "vor", "des", "Schick\u00b7sals", "Strei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "VVINF", "APPR", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Und nicht aus vielen Augen fallen Z\u00e4hren", "tokens": ["Und", "nicht", "aus", "vie\u00b7len", "Au\u00b7gen", "fal\u00b7len", "Z\u00e4h\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PTKNEG", "APPR", "PIAT", "NN", "VVFIN", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Stolzer Entsagung auf geliebte Leichen:", "tokens": ["Stol\u00b7zer", "Ent\u00b7sa\u00b7gung", "auf", "ge\u00b7lieb\u00b7te", "Lei\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "APPR", "ADJA", "NN", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.9": {"text": "Tribut, nur in verschloss'nen Kammern funkelnd,", "tokens": ["Tri\u00b7but", ",", "nur", "in", "ver\u00b7schloss'\u00b7nen", "Kam\u00b7mern", "fun\u00b7kelnd", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADV", "APPR", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Versch\u00e4mte Thr\u00e4nen, die nicht jedem eigen,", "tokens": ["Ver\u00b7sch\u00e4m\u00b7te", "Thr\u00e4\u00b7nen", ",", "die", "nicht", "je\u00b7dem", "ei\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "PRELS", "PTKNEG", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "La\u00dft sie, der Elegien Glanz verdunkelnd,", "tokens": ["La\u00dft", "sie", ",", "der", "E\u00b7le\u00b7gi\u00b7en", "Glanz", "ver\u00b7dun\u00b7kelnd", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "$,", "ART", "NN", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Einsame Furchen ziehn \u2013 der Rest ist Schweigen.", "tokens": ["Ein\u00b7sa\u00b7me", "Fur\u00b7chen", "ziehn", "\u2013", "der", "Rest", "ist", "Schwei\u00b7gen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "$(", "ART", "NN", "VAFIN", "NN", "$."], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}}, "stanza.2": {"line.1": {"text": "Ach, wer des Lebens Labyrinthe kennt,", "tokens": ["Ach", ",", "wer", "des", "Le\u00b7bens", "La\u00b7by\u00b7rin\u00b7the", "kennt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "PWS", "ART", "NN", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "L\u00e4\u00dft jede gutgemeinte Regung gelten!", "tokens": ["L\u00e4\u00dft", "je\u00b7de", "gut\u00b7ge\u00b7mein\u00b7te", "Re\u00b7gung", "gel\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Ist doch des Jammers schon genug und selten", "tokens": ["Ist", "doch", "des", "Jam\u00b7mers", "schon", "ge\u00b7nug", "und", "sel\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "ART", "NN", "ADV", "ADV", "KON", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Die Thr\u00e4ne, welche tiefe Furchen brennt.", "tokens": ["Die", "Thr\u00e4\u00b7ne", ",", "wel\u00b7che", "tie\u00b7fe", "Fur\u00b7chen", "brennt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PWAT", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Berauschend sind des Lenzes Wunderm\u00e4ren,", "tokens": ["Be\u00b7rau\u00b7schend", "sind", "des", "Len\u00b7zes", "Wun\u00b7der\u00b7m\u00e4\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Bis wir uns beugen vor des Schicksals Streichen,", "tokens": ["Bis", "wir", "uns", "beu\u00b7gen", "vor", "des", "Schick\u00b7sals", "Strei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "VVINF", "APPR", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Und nicht aus vielen Augen fallen Z\u00e4hren", "tokens": ["Und", "nicht", "aus", "vie\u00b7len", "Au\u00b7gen", "fal\u00b7len", "Z\u00e4h\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PTKNEG", "APPR", "PIAT", "NN", "VVFIN", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Stolzer Entsagung auf geliebte Leichen:", "tokens": ["Stol\u00b7zer", "Ent\u00b7sa\u00b7gung", "auf", "ge\u00b7lieb\u00b7te", "Lei\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "APPR", "ADJA", "NN", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.9": {"text": "Tribut, nur in verschloss'nen Kammern funkelnd,", "tokens": ["Tri\u00b7but", ",", "nur", "in", "ver\u00b7schloss'\u00b7nen", "Kam\u00b7mern", "fun\u00b7kelnd", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADV", "APPR", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Versch\u00e4mte Thr\u00e4nen, die nicht jedem eigen,", "tokens": ["Ver\u00b7sch\u00e4m\u00b7te", "Thr\u00e4\u00b7nen", ",", "die", "nicht", "je\u00b7dem", "ei\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "PRELS", "PTKNEG", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "La\u00dft sie, der Elegien Glanz verdunkelnd,", "tokens": ["La\u00dft", "sie", ",", "der", "E\u00b7le\u00b7gi\u00b7en", "Glanz", "ver\u00b7dun\u00b7kelnd", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "$,", "ART", "NN", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Einsame Furchen ziehn \u2013 der Rest ist Schweigen.", "tokens": ["Ein\u00b7sa\u00b7me", "Fur\u00b7chen", "ziehn", "\u2013", "der", "Rest", "ist", "Schwei\u00b7gen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "$(", "ART", "NN", "VAFIN", "NN", "$."], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}}}}}