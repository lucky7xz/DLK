{"dta.poem.2751": {"metadata": {"author": {"name": "M\u00fchlpfort, Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "Wechsel-Rede des Adels und der Nachwelt/  \n  Bey Beerdigung Hn. H. v. P. den  30.  \n Octobr. 1680.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1686", "urn": "urn:nbn:de:kobv:b4-20414-7", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Ach G\u00f6ttin die du siehst in Abgrund aller Zeiten/", "tokens": ["Ach", "G\u00f6t\u00b7tin", "die", "du", "siehst", "in", "Ab\u00b7grund", "al\u00b7ler", "Zei\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "NN", "ART", "PPER", "VVFIN", "APPR", "NN", "PIAT", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die kein Lebendiger in seinen Arm gefa\u00dft/", "tokens": ["Die", "kein", "Le\u00b7ben\u00b7di\u00b7ger", "in", "sei\u00b7nen", "Arm", "ge\u00b7fa\u00dft", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "APPR", "PPOSAT", "NN", "VVPP", "$("], "meter": "--+--+-+-+-+", "measure": "anapaest.di.plus"}, "line.3": {"text": "Die zwar kein Mensch gesehn/ da du doch Augen hast/", "tokens": ["Die", "zwar", "kein", "Mensch", "ge\u00b7sehn", "/", "da", "du", "doch", "Au\u00b7gen", "hast", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "PIAT", "NN", "VVPP", "$(", "KOUS", "PPER", "ADV", "NN", "VAFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und must der Menschen Thun mit deinem Mund ausbreit\u0113!", "tokens": ["Und", "must", "der", "Men\u00b7schen", "Thun", "mit", "dei\u00b7nem", "Mund", "aus\u00b7breit\u0113", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ART", "NN", "VVFIN", "APPR", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die du den Urtheil-Spruch von unsern Thaten sag\u2019st/", "tokens": ["Die", "du", "den", "Urt\u00b7heil\u00b7Spruch", "von", "un\u00b7sern", "Tha\u00b7ten", "sag'st", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ART", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und frey die Tugend lobst und an die Laster klag\u2019st.", "tokens": ["Und", "frey", "die", "Tu\u00b7gend", "lobst", "und", "an", "die", "Las\u00b7ter", "klag'", "st."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "abbreviation"], "pos": ["KON", "ADJD", "ART", "NN", "VVFIN", "KON", "APPR", "ART", "NN", "VVFIN", "NE"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Die man sucht \u00fcberall und nirgend doch kan finden/", "tokens": ["Die", "man", "sucht", "\u00fc\u00b7be\u00b7rall", "und", "nir\u00b7gend", "doch", "kan", "fin\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VVFIN", "ADV", "KON", "ADV", "ADV", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Dem der dir nachgesetzt/ pflegstu nur zu entfliehn/", "tokens": ["Dem", "der", "dir", "nach\u00b7ge\u00b7setzt", "/", "pflegs\u00b7tu", "nur", "zu", "ent\u00b7fliehn", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PRELS", "PPER", "VVPP", "$(", "VVFIN", "ADV", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Du wirst bey Hochmuth nicht und Eitelkeit einziehn", "tokens": ["Du", "wirst", "bey", "Hoch\u00b7muth", "nicht", "und", "Ei\u00b7tel\u00b7keit", "ein\u00b7ziehn"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "APPR", "NE", "PTKNEG", "KON", "NN", "VVINF"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Den Sitz mehr auff ein Grab als Thron und Cronen gr\u00fcnden/", "tokens": ["Den", "Sitz", "mehr", "auff", "ein", "Grab", "als", "Thron", "und", "Cro\u00b7nen", "gr\u00fcn\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "APPR", "ART", "NN", "KOUS", "NN", "KON", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Wo dir mein Aug\u2019 als Blut/ mein Mund erscheint als Bley/", "tokens": ["Wo", "dir", "mein", "Aug'", "als", "Blut", "/", "mein", "Mund", "er\u00b7scheint", "als", "Bley", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PPOSAT", "NN", "KOUS", "NN", "$(", "PPOSAT", "NN", "VVFIN", "KOKOM", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "So dencke da\u00df mein Schmertz gewi\u00df h\u00f6chstklagbar sey.", "tokens": ["So", "den\u00b7cke", "da\u00df", "mein", "Schmertz", "ge\u00b7wi\u00df", "h\u00f6chst\u00b7klag\u00b7bar", "sey", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "KOUS", "PPOSAT", "NN", "ADV", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Betr\u00fcbtste/ was ist das? welch grausam Ungewitter", "tokens": ["Be\u00b7tr\u00b7\u00fcbts\u00b7te", "/", "was", "ist", "das", "?", "welch", "grau\u00b7sam", "Un\u00b7ge\u00b7wit\u00b7ter"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "$(", "PWS", "VAFIN", "PDS", "$.", "PWAT", "ADJA", "NN"], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Blitzt \u00fcber deinem Kopff/ zerbricht dir Helm und Schild/", "tokens": ["Blitzt", "\u00fc\u00b7ber", "dei\u00b7nem", "Kopff", "/", "zer\u00b7bricht", "dir", "Helm", "und", "Schild", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PPOSAT", "NN", "$(", "VVFIN", "PPER", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Zerreist die Sieges-Fahn/ und hat schon eingeh\u00fcllt", "tokens": ["Zer\u00b7reist", "die", "Sie\u00b7ges\u00b7Fahn", "/", "und", "hat", "schon", "ein\u00b7ge\u00b7h\u00fcllt"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "NN", "$(", "KON", "VAFIN", "ADV", "VVPP"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ach Schmertz! ins Leichen-Tuch den hochgebornen Ritter?", "tokens": ["Ach", "Schmertz", "!", "ins", "Lei\u00b7chen\u00b7Tuch", "den", "hoch\u00b7ge\u00b7bor\u00b7nen", "Rit\u00b7ter", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "NN", "$.", "APPRART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Der einem Atlas gleich das Land hat unterst\u00fctzt.", "tokens": ["Der", "ei\u00b7nem", "At\u00b7las", "gleich", "das", "Land", "hat", "un\u00b7ter\u00b7st\u00fctzt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "ADV", "ART", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Gemeines Heil geliebt und deinen Ruhm besch\u00fctzt.", "tokens": ["Ge\u00b7mei\u00b7nes", "Heil", "ge\u00b7liebt", "und", "dei\u00b7nen", "Ruhm", "be\u00b7sch\u00fctzt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVPP", "KON", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Nein Schwester dencke nicht das ", "tokens": ["Nein", "Schwes\u00b7ter", "den\u00b7cke", "nicht", "das"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PTKANT", "NN", "VVFIN", "PTKNEG", "ART"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Als aus dem C\u00f6rper nur entwich der edle Geist/", "tokens": ["Als", "aus", "dem", "C\u00f6r\u00b7per", "nur", "ent\u00b7wich", "der", "ed\u00b7le", "Geist", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "ART", "NN", "ADV", "ADJD", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Und seinem Ursprung nach den Sternen zugereist/", "tokens": ["Und", "sei\u00b7nem", "Ur\u00b7sprung", "nach", "den", "Ster\u00b7nen", "zu\u00b7ge\u00b7reist", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "APPR", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Hie\u00df die Unsterblichkeit ein ewig Lob ihn erben.", "tokens": ["Hie\u00df", "die", "U\u00b7nsterb\u00b7lich\u00b7keit", "ein", "e\u00b7wig", "Lob", "ihn", "er\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "ART", "ADJD", "NN", "PPER", "VVINF", "$."], "meter": "+-+--+-+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.11": {"text": "Ertheilte mir Befehl/ da\u00df ich durch meinen Klang", "tokens": ["Er\u00b7theil\u00b7te", "mir", "Be\u00b7fehl", "/", "da\u00df", "ich", "durch", "mei\u00b7nen", "Klang"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "NN", "$(", "KOUS", "PPER", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Verk\u00fcndigte dein Ruhm bey Auf- und Untergang.", "tokens": ["Ver\u00b7k\u00fcn\u00b7dig\u00b7te", "dein", "Ruhm", "bey", "Auf", "und", "Un\u00b7ter\u00b7gang", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "APPR", "TRUNC", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Mein sch\u00f6nstes Kleinod ist aus meinem Ring gefallen/", "tokens": ["Mein", "sch\u00f6ns\u00b7tes", "Klei\u00b7nod", "ist", "aus", "mei\u00b7nem", "Ring", "ge\u00b7fal\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VAFIN", "APPR", "PPOSAT", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Er war in meiner Cron ein mehr als edler Stein/", "tokens": ["Er", "war", "in", "mei\u00b7ner", "Cron", "ein", "mehr", "als", "ed\u00b7ler", "Stein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "PPOSAT", "NN", "ART", "PIAT", "KOKOM", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wie offt hat mich erquickt der Tugend Sonnen-Schein/", "tokens": ["Wie", "offt", "hat", "mich", "er\u00b7quickt", "der", "Tu\u00b7gend", "Son\u00b7nen\u00b7Schein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "VAFIN", "PPER", "VVFIN", "ART", "NN", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ach da\u00df doch Cedern auch gleich andern B\u00e4umen fallen!", "tokens": ["Ach", "da\u00df", "doch", "Ce\u00b7dern", "auch", "gleich", "an\u00b7dern", "B\u00e4u\u00b7men", "fal\u00b7len", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "KOUS", "ADV", "NN", "ADV", "ADV", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "So gibt der werthe Mund mir ferner keinen Rath", "tokens": ["So", "gibt", "der", "wert\u00b7he", "Mund", "mir", "fer\u00b7ner", "kei\u00b7nen", "Rath"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "PPER", "ADV", "PIAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Der Perlen ausgesch\u00fctt\u2019t und Gold geregnet hat.", "tokens": ["Der", "Per\u00b7len", "aus\u00b7ge\u00b7sch\u00fctt't", "und", "Gold", "ge\u00b7reg\u00b7net", "hat", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "KON", "NN", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Sein ", "tokens": ["Sein"], "token_info": ["word"], "pos": ["PPOSAT"], "meter": "-", "measure": "single.down"}, "line.8": {"text": "Schenckt keinen Ph\u00f6nix mehr zu Nutz und Trost der Welt.", "tokens": ["Schenckt", "kei\u00b7nen", "Ph\u00f6\u00b7nix", "mehr", "zu", "Nutz", "und", "Trost", "der", "Welt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "NN", "ADV", "APPR", "NN", "KON", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Die Wurtzel ist verletzt/ die Aeste sind gef\u00e4llt/", "tokens": ["Die", "Wurt\u00b7zel", "ist", "ver\u00b7letzt", "/", "die", "A\u00b7es\u00b7te", "sind", "ge\u00b7f\u00e4llt", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVPP", "$(", "ART", "NN", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.10": {"text": "Was einmal schon entzwey kan Chiron nicht erg\u00e4ntzen.", "tokens": ["Was", "ein\u00b7mal", "schon", "ent\u00b7zwey", "kan", "Chi\u00b7ron", "nicht", "er\u00b7g\u00e4nt\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "ADV", "PTKVZ", "VMFIN", "NE", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Di\u00df ist der Uberrest was ich zu Grabe f\u00fchr\u2019", "tokens": ["Di\u00df", "ist", "der", "Ub\u00b7er\u00b7rest", "was", "ich", "zu", "Gra\u00b7be", "f\u00fchr'"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "ART", "NN", "PWS", "PPER", "APPR", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Und noch zuletzt die Asch\u2019 aus Treu und Pflicht ber\u00fchr.", "tokens": ["Und", "noch", "zu\u00b7letzt", "die", "Asch'", "aus", "Treu", "und", "Pflicht", "be\u00b7r\u00fchr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "ART", "NN", "APPR", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Es sey/ du lieferst ja nur blo\u00df des Leibes Schalen/", "tokens": ["Es", "sey", "/", "du", "lie\u00b7ferst", "ja", "nur", "blo\u00df", "des", "Lei\u00b7bes", "Scha\u00b7len", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$(", "PPER", "VVFIN", "ADV", "ADV", "ADV", "ART", "NN", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der Seelen himmlisch Fener blitzt unter Sternen schon.", "tokens": ["Der", "See\u00b7len", "himm\u00b7lisch", "Fe\u00b7ner", "blitzt", "un\u00b7ter", "Ster\u00b7nen", "schon", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "NN", "VVFIN", "APPR", "NN", "ADV", "$."], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Jetzt geb ich billich ihm den l\u00e4ngst erworb\u2019nen Lohn", "tokens": ["Jetzt", "geb", "ich", "bil\u00b7lich", "ihm", "den", "l\u00e4ngst", "er\u00b7wor\u00b7b'\u00b7nen", "Lohn"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "PPER", "ART", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Und will den ", "tokens": ["Und", "will", "den"], "token_info": ["word", "word", "word"], "pos": ["KON", "VMFIN", "ART"], "meter": "-+-", "measure": "amphibrach.single"}, "line.5": {"text": "Rei\u00df meinen Vorsatz nicht durch deine Thr\u00e4nen ein/", "tokens": ["Rei\u00df", "mei\u00b7nen", "Vor\u00b7satz", "nicht", "durch", "dei\u00b7ne", "Thr\u00e4\u00b7nen", "ein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "PTKNEG", "APPR", "PPOSAT", "NN", "ART", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Di\u00df Opffer f\u00fchlt er nicht/ nur blo\u00df der Leichenstein.", "tokens": ["Di\u00df", "Opf\u00b7fer", "f\u00fchlt", "er", "nicht", "/", "nur", "blo\u00df", "der", "Lei\u00b7chen\u00b7stein", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "NN", "VVFIN", "PPER", "PTKNEG", "$(", "ADV", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Rom hat mit im Triumph der Ahnen Rey getragen/", "tokens": ["Rom", "hat", "mit", "im", "Tri\u00b7umph", "der", "Ah\u00b7nen", "Rey", "ge\u00b7tra\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "APPR", "APPRART", "NN", "ART", "NN", "NN", "VVPP", "$("], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.8": {"text": "Wenn das begraute Wax die ersten V\u00e4ter wie\u00df;", "tokens": ["Wenn", "das", "be\u00b7grau\u00b7te", "Wax", "die", "ers\u00b7ten", "V\u00e4\u00b7ter", "wie\u00df", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Sie auf das Rahthau\u00df hieng/ an Seulen sehen lie\u00df/", "tokens": ["Sie", "auf", "das", "Rah\u00b7thau\u00df", "hieng", "/", "an", "Seu\u00b7len", "se\u00b7hen", "lie\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "ART", "NN", "VVFIN", "$(", "APPR", "NN", "VVINF", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Den Kindern gleichen Trieb der Tugend einzujagen.", "tokens": ["Den", "Kin\u00b7dern", "glei\u00b7chen", "Trieb", "der", "Tu\u00b7gend", "ein\u00b7zu\u00b7ja\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "ART", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Weil doch der Adelstand durch Waffen und durch Kunst/", "tokens": ["Weil", "doch", "der", "A\u00b7del\u00b7stand", "durch", "Waf\u00b7fen", "und", "durch", "Kunst", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "APPR", "NN", "KON", "APPR", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Ersteigt der Ehre Schlo\u00df/ erlangt der F\u00fcrsten Gunst.", "tokens": ["Er\u00b7steigt", "der", "Eh\u00b7re", "Schlo\u00df", "/", "er\u00b7langt", "der", "F\u00fcrs\u00b7ten", "Gunst", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "NN", "$(", "VVFIN", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Ein solcher Ritter war mein ", "tokens": ["Ein", "sol\u00b7cher", "Rit\u00b7ter", "war", "mein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "PIAT", "NN", "VAFIN", "PPOSAT"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Sein Stamm-Register ligt mir immer im Gesicht;", "tokens": ["Sein", "Stam\u00b7mRe\u00b7gis\u00b7ter", "ligt", "mir", "im\u00b7mer", "im", "Ge\u00b7sicht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Den Nestor unser Zeit/ wer kennt den Vater nicht?", "tokens": ["Den", "Nes\u00b7tor", "un\u00b7ser", "Zeit", "/", "wer", "kennt", "den", "Va\u00b7ter", "nicht", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "$(", "PWS", "VVFIN", "ART", "NN", "PTKNEG", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der seinem Vaterland zu grossem Ruhm geboren/", "tokens": ["Der", "sei\u00b7nem", "Va\u00b7ter\u00b7land", "zu", "gros\u00b7sem", "Ruhm", "ge\u00b7bo\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "APPR", "ADJA", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Viel treue Dienste hat bi\u00df in sein Grab gethan/", "tokens": ["Viel", "treu\u00b7e", "Diens\u00b7te", "hat", "bi\u00df", "in", "sein", "Grab", "ge\u00b7than", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "VAFIN", "ADV", "APPR", "PPOSAT", "NN", "VVPP", "$("], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Den mit Verwundern sah\u2019 der Per\u00df und Indian.", "tokens": ["Den", "mit", "Ver\u00b7wun\u00b7dern", "sah'", "der", "Per\u00df", "und", "In\u00b7di\u00b7an."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "abbreviation"], "pos": ["ART", "APPR", "NN", "VVFIN", "ART", "NN", "KON", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Dergleichen Helden Muth und Eyfer zu der Tugend", "tokens": ["Derg\u00b7lei\u00b7chen", "Hel\u00b7den", "Muth", "und", "Ey\u00b7fer", "zu", "der", "Tu\u00b7gend"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PIS", "NN", "NN", "KON", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Wuchs in des Sohnes Brust; wie aus Aurorens Schein", "tokens": ["Wuchs", "in", "des", "Soh\u00b7nes", "Brust", ";", "wie", "aus", "Au\u00b7ro\u00b7rens", "Schein"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "APPR", "ART", "NN", "NN", "$.", "KOKOM", "APPR", "NE", "NN"], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.9": {"text": "Man sicher schliessen kan was f\u00fcr ein Tag wird seyn/", "tokens": ["Man", "si\u00b7cher", "schlies\u00b7sen", "kan", "was", "f\u00fcr", "ein", "Tag", "wird", "seyn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "ADJD", "VVINF", "VMFIN", "PIS", "APPR", "ART", "NN", "VAFIN", "VAINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "So lie\u00df er auch bald sehn den Morgen seiner Jugend.", "tokens": ["So", "lie\u00df", "er", "auch", "bald", "sehn", "den", "Mor\u00b7gen", "sei\u00b7ner", "Ju\u00b7gend", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ADV", "VVFIN", "ART", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Sein ausgekl\u00e4rter Sinn stieg auf Parnassus H\u00f6h/", "tokens": ["Sein", "aus\u00b7ge\u00b7kl\u00e4r\u00b7ter", "Sinn", "stieg", "auf", "Par\u00b7nas\u00b7sus", "H\u00f6h", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVFIN", "APPR", "NE", "NN", "$("], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.12": {"text": "Und saugte Bienen gleich der Musen s\u00fcssen Klee.", "tokens": ["Und", "saug\u00b7te", "Bie\u00b7nen", "gleich", "der", "Mu\u00b7sen", "s\u00fcs\u00b7sen", "Klee", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "NN", "ADV", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Es pr\u00fcffte seinen Flei\u00df der treuen Lehrer Stimme;", "tokens": ["Es", "pr\u00fcff\u00b7te", "sei\u00b7nen", "Flei\u00df", "der", "treu\u00b7en", "Leh\u00b7rer", "Stim\u00b7me", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "ART", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Gleich wie ein hurtig Pferd so bald man es sticht an/", "tokens": ["Gleich", "wie", "ein", "hur\u00b7tig", "Pferd", "so", "bald", "man", "es", "sticht", "an", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "ART", "ADJD", "NN", "ADV", "ADV", "PIS", "PPER", "VVFIN", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Laufft schnell als Pfeil und Wind auf seiner Rennebahn.", "tokens": ["Laufft", "schnell", "als", "Pfeil", "und", "Wind", "auf", "sei\u00b7ner", "Ren\u00b7ne\u00b7bahn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "KOKOM", "NN", "KON", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Sie sahen was in ihm f\u00fcr edler Zunder glimme.", "tokens": ["Sie", "sa\u00b7hen", "was", "in", "ihm", "f\u00fcr", "ed\u00b7ler", "Zun\u00b7der", "glim\u00b7me", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PWS", "APPR", "PPER", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und weil die Pallas wird geharnischt f\u00fcrgestellt", "tokens": ["Und", "weil", "die", "Pal\u00b7las", "wird", "ge\u00b7har\u00b7nischt", "f\u00fcr\u00b7ge\u00b7stellt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "ART", "NN", "VAFIN", "VVPP", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Hat er der Ritter-Schwei\u00df dem B\u00fccher-Flei\u00df gesellt.", "tokens": ["Hat", "er", "der", "Rit\u00b7ter\u00b7Schwei\u00df", "dem", "B\u00fc\u00b7cher\u00b7Flei\u00df", "ge\u00b7sellt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Denn gieng er in die Welt wie Adler in die Sonne/", "tokens": ["Denn", "gieng", "er", "in", "die", "Welt", "wie", "Ad\u00b7ler", "in", "die", "Son\u00b7ne", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "ART", "NN", "KOKOM", "NN", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Es schien ihm dieses Rund wie Alexandern klein.", "tokens": ["Es", "schien", "ihm", "die\u00b7ses", "Rund", "wie", "A\u00b7lex\u00b7an\u00b7dern", "klein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PDAT", "NN", "KOKOM", "NE", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Er wolte bald bey Ost und bald bey Norden seyn/", "tokens": ["Er", "wol\u00b7te", "bald", "bey", "Ost", "und", "bald", "bey", "Nor\u00b7den", "seyn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "APPR", "NE", "KON", "ADV", "APPR", "NN", "VAINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Denn schwam er auf der Maa\u00df/ beschiffte die Garonne", "tokens": ["Denn", "schwam", "er", "auf", "der", "Maa\u00df", "/", "be\u00b7schiff\u00b7te", "die", "Ga\u00b7ron\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "APPR", "ART", "NN", "$(", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Jhm war so wol der Po als auch der Belth bekandt/", "tokens": ["Jhm", "war", "so", "wol", "der", "Po", "als", "auch", "der", "Belth", "be\u00b7kandt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "ART", "NN", "KOKOM", "ADV", "ART", "NN", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Nannt jeden frembden Ort sein ander Vaterland.", "tokens": ["Nannt", "je\u00b7den", "fremb\u00b7den", "Ort", "sein", "an\u00b7der", "Va\u00b7ter\u00b7land", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "ADJA", "NN", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Er hat den schwartzen Mohr/ den weisen Scyth gesehen/", "tokens": ["Er", "hat", "den", "schwart\u00b7zen", "Mohr", "/", "den", "wei\u00b7sen", "Scyth", "ge\u00b7se\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "$(", "ART", "ADJA", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der K\u00f6nige Pal\u00e4st und H\u00f6fe wol betracht:", "tokens": ["Der", "K\u00f6\u00b7ni\u00b7ge", "Pa\u00b7l\u00e4st", "und", "H\u00f6\u00b7fe", "wol", "be\u00b7tracht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "KON", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Zu Gnad und Hulden sich bey F\u00fcrsten angebracht:", "tokens": ["Zu", "Gnad", "und", "Hul\u00b7den", "sich", "bey", "F\u00fcrs\u00b7ten", "an\u00b7ge\u00b7bracht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "PRF", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und wolte gleich das Gl\u00fcck den Vorsatz offt verdr\u00e4hen/", "tokens": ["Und", "wol\u00b7te", "gleich", "das", "Gl\u00fcck", "den", "Vor\u00b7satz", "offt", "ver\u00b7dr\u00e4\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ADV", "ART", "NN", "ART", "NN", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "So pr\u00fcfft er in Gedult den Wechselgang der Zeit", "tokens": ["So", "pr\u00fcfft", "er", "in", "Ge\u00b7dult", "den", "Wech\u00b7sel\u00b7gang", "der", "Zeit"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "NN", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Der heute Wermuth reicht und morgen Zucker streut.", "tokens": ["Der", "heu\u00b7te", "Wer\u00b7muth", "reicht", "und", "mor\u00b7gen", "Zu\u00b7cker", "streut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "KON", "ADV", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Ulysses gab ihm Witz/ und C\u00e4sar zeigt ihm Thaten/", "tokens": ["U\u00b7lys\u00b7ses", "gab", "ihm", "Witz", "/", "und", "C\u00e4\u00b7sar", "zeigt", "ihm", "Tha\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "NN", "$(", "KON", "NE", "VVFIN", "PPER", "NN", "$("], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.8": {"text": "Camillus seine Treu und Scipio den Muth:", "tokens": ["Ca\u00b7mil\u00b7lus", "sei\u00b7ne", "Treu", "und", "Sci\u00b7pio", "den", "Muth", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPOSAT", "NN", "KON", "NE", "ART", "NN", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.9": {"text": "Der Cato den Bestand besigelt durch sein Blut/", "tokens": ["Der", "Ca\u00b7to", "den", "Be\u00b7stand", "be\u00b7si\u00b7gelt", "durch", "sein", "Blut", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "ART", "NN", "VVFIN", "APPR", "PPOSAT", "NN", "$("], "meter": "--+--+-+-+-+", "measure": "anapaest.di.plus"}, "line.10": {"text": "Ein friedlicher August wie glimpflich sey zu rathen.", "tokens": ["Ein", "fried\u00b7li\u00b7cher", "Au\u00b7gust", "wie", "glimpf\u00b7lich", "sey", "zu", "ra\u00b7then", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "KOKOM", "ADJD", "VAFIN", "PTKZU", "VVINF", "$."], "meter": "-+--++-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.11": {"text": "Er kam wie Jason heim/ der Tugend g\u00fcldnes Flie\u00df", "tokens": ["Er", "kam", "wie", "Ja\u00b7son", "heim", "/", "der", "Tu\u00b7gend", "g\u00fcld\u00b7nes", "Flie\u00df"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "KOKOM", "NE", "PTKVZ", "$(", "ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "War Wissenschafft und Witz so h\u00e4uffig sich erwie\u00df.", "tokens": ["War", "Wis\u00b7sen\u00b7schafft", "und", "Witz", "so", "h\u00e4uf\u00b7fig", "sich", "er\u00b7wie\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "KON", "NN", "ADV", "ADJD", "PRF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}