{"textgrid.poem.60586": {"metadata": {"author": {"name": "Uz, Johann Peter", "birth": "N.A.", "death": "N.A."}, "title": "Den Tod Des Freyherrn Johann Friedrich von Cronegk beklagen Seine Freunde", "genre": "verse", "period": "N.A.", "pub_year": 1758, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wir warteten umsonst, von Cronegks Tod zu singen,", "tokens": ["Wir", "war\u00b7te\u00b7ten", "um\u00b7sonst", ",", "von", "Cro\u00b7negks", "Tod", "zu", "sin\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "APPR", "NE", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Auf sp\u00e4ten Trost entfernter Zeit:", "tokens": ["Auf", "sp\u00e4\u00b7ten", "Trost", "ent\u00b7fern\u00b7ter", "Zeit", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Noch itzt umschattet uns, mit f\u00fcrchterlichen Schwingen,", "tokens": ["Noch", "itzt", "um\u00b7schat\u00b7tet", "uns", ",", "mit", "f\u00fcrch\u00b7ter\u00b7li\u00b7chen", "Schwin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die unbesiegte Traurigkeit.", "tokens": ["Die", "un\u00b7be\u00b7sieg\u00b7te", "Trau\u00b7rig\u00b7keit", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Umsonst gelobten wir den schlafenden Gebeinen", "tokens": ["Um\u00b7sonst", "ge\u00b7lob\u00b7ten", "wir", "den", "schla\u00b7fen\u00b7den", "Ge\u00b7bei\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Ein Lied, ein unverg\u00e4nglich Lied:", "tokens": ["Ein", "Lied", ",", "ein", "un\u00b7ver\u00b7g\u00e4ng\u00b7lich", "Lied", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "ADJD", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Wir denken Cronegks Grab, und weinen,", "tokens": ["Wir", "den\u00b7ken", "Cro\u00b7negks", "Grab", ",", "und", "wei\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NE", "NN", "$,", "KON", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Und jede Muse flieht!", "tokens": ["Und", "je\u00b7de", "Mu\u00b7se", "flieht", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "O Grab des liebsten Freunds! O Cronegk, theurer Nahme,", "tokens": ["O", "Grab", "des", "liebs\u00b7ten", "Freunds", "!", "O", "Cro\u00b7negk", ",", "theu\u00b7rer", "Nah\u00b7me", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "NN", "ART", "ADJA", "NN", "$.", "NE", "NN", "$,", "ADJD", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Sonst unser Stolz, nun unser Schmerz!", "tokens": ["Sonst", "un\u00b7ser", "Stolz", ",", "nun", "un\u00b7ser", "Schmerz", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "$,", "ADV", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die Zeit, mit ihrem Trost, entw\u00f6lkt von finsterm Grame", "tokens": ["Die", "Zeit", ",", "mit", "ih\u00b7rem", "Trost", ",", "ent\u00b7w\u00f6lkt", "von", "fins\u00b7term", "Gra\u00b7me"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "APPR", "PPOSAT", "NN", "$,", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Nur unsre Stirn, nicht unser Herz.", "tokens": ["Nur", "uns\u00b7re", "Stirn", ",", "nicht", "un\u00b7ser", "Herz", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "$,", "PTKNEG", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wir trauern schweigend fort, und haben Recht zu trauern:", "tokens": ["Wir", "trau\u00b7ern", "schwei\u00b7gend", "fort", ",", "und", "ha\u00b7ben", "Recht", "zu", "trau\u00b7ern", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "PTKVZ", "$,", "KON", "VAFIN", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Dein Herz war uns zu nah verwandt!", "tokens": ["Dein", "Herz", "war", "uns", "zu", "nah", "ver\u00b7wandt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "PPER", "PTKA", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Mu\u00df doch die Menge Dich bedauern,", "tokens": ["Mu\u00df", "doch", "die", "Men\u00b7ge", "Dich", "be\u00b7dau\u00b7ern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "ART", "NN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Die Dich nur halb gekannt.", "tokens": ["Die", "Dich", "nur", "halb", "ge\u00b7kannt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Wenn sie, bey Deinem Grab, nur weil Du kurz gelebet,", "tokens": ["Wenn", "sie", ",", "bey", "Dei\u00b7nem", "Grab", ",", "nur", "weil", "Du", "kurz", "ge\u00b7le\u00b7bet", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "APPR", "PPOSAT", "NN", "$,", "ADV", "KOUS", "PPER", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Um Deine sch\u00f6ne Jugend weint,", "tokens": ["Um", "Dei\u00b7ne", "sch\u00f6\u00b7ne", "Ju\u00b7gend", "weint", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PPOSAT", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und Deine G\u00fctigkeit mit nassem Aug erhebet;", "tokens": ["Und", "Dei\u00b7ne", "G\u00fc\u00b7tig\u00b7keit", "mit", "nas\u00b7sem", "Aug", "er\u00b7he\u00b7bet", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Beweinen wir in Dir den Freund:", "tokens": ["Be\u00b7wei\u00b7nen", "wir", "in", "Dir", "den", "Freund", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Den Freund voll Z\u00e4rtlichkeit, der mit Geschmack und Sitten", "tokens": ["Den", "Freund", "voll", "Z\u00e4rt\u00b7lich\u00b7keit", ",", "der", "mit", "Ge\u00b7schmack", "und", "Sit\u00b7ten"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADJD", "NN", "$,", "PRELS", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Ein liebensw\u00fcrdig Herz verband,", "tokens": ["Ein", "lie\u00b7bens\u00b7w\u00fcr\u00b7dig", "Herz", "ver\u00b7band", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Selbst litt, wenn seine Freunde litten,", "tokens": ["Selbst", "litt", ",", "wenn", "sei\u00b7ne", "Freun\u00b7de", "lit\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "KOUS", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Und selbst ihr Gl\u00fcck empfand:", "tokens": ["Und", "selbst", "ihr", "Gl\u00fcck", "emp\u00b7fand", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Den Edlen, den Sein Herz mehr, als Geburt, geadelt,", "tokens": ["Den", "Ed\u00b7len", ",", "den", "Sein", "Herz", "mehr", ",", "als", "Ge\u00b7burt", ",", "ge\u00b7a\u00b7delt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPOSAT", "NN", "ADV", "$,", "KOUS", "NN", "$,", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und keine niedre That entehrt;", "tokens": ["Und", "kei\u00b7ne", "nied\u00b7re", "That", "ent\u00b7ehrt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Den k\u00fchne Schm\u00e4hsucht selbst nur leis und sch\u00fcchtern tadelt,", "tokens": ["Den", "k\u00fch\u00b7ne", "Schm\u00e4h\u00b7sucht", "selbst", "nur", "leis", "und", "sch\u00fcch\u00b7tern", "ta\u00b7delt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "ADV", "ADJD", "KON", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Nur bey dem P\u00f6bel, der sie h\u00f6rt;", "tokens": ["Nur", "bey", "dem", "P\u00f6\u00b7bel", ",", "der", "sie", "h\u00f6rt", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Der Tugend \u00e4chten Freund, doch einer sanften Tugend,", "tokens": ["Der", "Tu\u00b7gend", "\u00e4ch\u00b7ten", "Freund", ",", "doch", "ei\u00b7ner", "sanf\u00b7ten", "Tu\u00b7gend", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$,", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Die, von den Grazien geschm\u00fcckt,", "tokens": ["Die", ",", "von", "den", "Gra\u00b7zi\u00b7en", "ge\u00b7schm\u00fcckt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Umkr\u00e4nzt mit Rosen muntrer Jugend,", "tokens": ["Um\u00b7kr\u00e4nzt", "mit", "Ro\u00b7sen", "mun\u00b7trer", "Ju\u00b7gend", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Durch stillen Reiz entz\u00fcckt.", "tokens": ["Durch", "stil\u00b7len", "Reiz", "ent\u00b7z\u00fcckt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Nicht rauschendes Verdienst, das Nationen preisen,", "tokens": ["Nicht", "rau\u00b7schen\u00b7des", "Ver\u00b7dienst", ",", "das", "Na\u00b7ti\u00b7o\u00b7nen", "prei\u00b7sen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADJA", "NN", "$,", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Nicht Ruhm, erhitzter Ehrsucht Kind,", "tokens": ["Nicht", "Ruhm", ",", "er\u00b7hitz\u00b7ter", "Ehr\u00b7sucht", "Kind", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "NN", "$,", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Das Herz macht unsern Werth bey aufgekl\u00e4rten Weisen,", "tokens": ["Das", "Herz", "macht", "un\u00b7sern", "Werth", "bey", "auf\u00b7ge\u00b7kl\u00e4r\u00b7ten", "Wei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPOSAT", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die unsre wahre Richter sind:", "tokens": ["Die", "uns\u00b7re", "wah\u00b7re", "Rich\u00b7ter", "sind", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "ADJA", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ein Herz, wie Cronegks Herz, das blo\u00df aus Menschenliebe", "tokens": ["Ein", "Herz", ",", "wie", "Cro\u00b7negks", "Herz", ",", "das", "blo\u00df", "aus", "Men\u00b7schen\u00b7lie\u00b7be"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PWAV", "NE", "NN", "$,", "PRELS", "ADV", "APPR", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Den Menschen wohl zu thun sich freut,", "tokens": ["Den", "Men\u00b7schen", "wohl", "zu", "thun", "sich", "freut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "PTKZU", "VVINF", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und wenn es auch verborgen bliebe,", "tokens": ["Und", "wenn", "es", "auch", "ver\u00b7bor\u00b7gen", "blie\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "VVPP", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Das Gute nicht bereut.", "tokens": ["Das", "Gu\u00b7te", "nicht", "be\u00b7reut", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Er g\u00f6nnte schimmernd Gl\u00fcck, das Tausende beneiden,", "tokens": ["Er", "g\u00f6nn\u00b7te", "schim\u00b7mernd", "Gl\u00fcck", ",", "das", "Tau\u00b7sen\u00b7de", "be\u00b7nei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "NN", "$,", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Den Sclaven ungeliebter Pracht:", "tokens": ["Den", "Scla\u00b7ven", "un\u00b7ge\u00b7lieb\u00b7ter", "Pracht", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sein Stolz war be\u00dfrer Art! Er h\u00e4tte voller Freuden", "tokens": ["Sein", "Stolz", "war", "be\u00df\u00b7rer", "Art", "!", "Er", "h\u00e4t\u00b7te", "vol\u00b7ler", "Freu\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VAFIN", "ADJA", "NN", "$.", "PPER", "VAFIN", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Auch eine Welt begl\u00fcckt gemacht.", "tokens": ["Auch", "ei\u00b7ne", "Welt", "be\u00b7gl\u00fcckt", "ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVPP", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Nur Freunde kannten Ihn und wu\u00dften Ihn zu sch\u00e4tzen:", "tokens": ["Nur", "Freun\u00b7de", "kann\u00b7ten", "Ihn", "und", "wu\u00df\u00b7ten", "Ihn", "zu", "sch\u00e4t\u00b7zen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "VVFIN", "PPER", "KON", "VVFIN", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wir haben Ihn zu sehr gekannt,", "tokens": ["Wir", "ha\u00b7ben", "Ihn", "zu", "sehr", "ge\u00b7kannt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "PTKA", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und Welten k\u00f6nnen nicht ersetzen,", "tokens": ["Und", "Wel\u00b7ten", "k\u00f6n\u00b7nen", "nicht", "er\u00b7set\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VMFIN", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Was uns das Grab entwandt!", "tokens": ["Was", "uns", "das", "Grab", "ent\u00b7wandt", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Wenn Cronegk um uns war, o welche g\u00fcldne Stunden!", "tokens": ["Wenn", "Cro\u00b7negk", "um", "uns", "war", ",", "o", "wel\u00b7che", "g\u00fcld\u00b7ne", "Stun\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "APPR", "PPER", "VAFIN", "$,", "FM", "PWAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "O g\u00fcldne Zeit, die schnell verstrich!", "tokens": ["O", "g\u00fcld\u00b7ne", "Zeit", ",", "die", "schnell", "ver\u00b7strich", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$,", "PRELS", "ADJD", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "H\u00e4lt nun ein dunkles Grab den leichten Scherz gebunden,", "tokens": ["H\u00e4lt", "nun", "ein", "dunk\u00b7les", "Grab", "den", "leich\u00b7ten", "Scherz", "ge\u00b7bun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "ADJA", "NN", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der nie von Seinen Lippen wich?", "tokens": ["Der", "nie", "von", "Sei\u00b7nen", "Lip\u00b7pen", "wich", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die\u00df gl\u00fcckliche Genie, das fl\u00fcchtig, gleich dem Blitze,", "tokens": ["Die\u00df", "gl\u00fcck\u00b7li\u00b7che", "Ge\u00b7nie", ",", "das", "fl\u00fcch\u00b7tig", ",", "gleich", "dem", "Blit\u00b7ze", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "ADJA", "NN", "$,", "PRELS", "ADJD", "$,", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Durch alle sch\u00f6ne Kenntni\u00df flog,", "tokens": ["Durch", "al\u00b7le", "sch\u00f6\u00b7ne", "Kennt\u00b7ni\u00df", "flog", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und S\u00fc\u00dfigkeit, mit scharfem Witze,", "tokens": ["Und", "S\u00fc\u00b7\u00dfig\u00b7keit", ",", "mit", "schar\u00b7fem", "Wit\u00b7ze", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "NN", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Von allen Blumen sog?", "tokens": ["Von", "al\u00b7len", "Blu\u00b7men", "sog", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Sein reizend Saitenspiel, wo holde Lieder t\u00f6nten,", "tokens": ["Sein", "rei\u00b7zend", "Sai\u00b7ten\u00b7spiel", ",", "wo", "hol\u00b7de", "Lie\u00b7der", "t\u00f6n\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJD", "NN", "$,", "PWAV", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Sonst unsre Lust, ist uns geraubt?", "tokens": ["Sonst", "uns\u00b7re", "Lust", ",", "ist", "uns", "ge\u00b7raubt", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "$,", "VAFIN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die Musen liebten Ihn, mit fr\u00fchen Lorbeern kr\u00f6nten", "tokens": ["Die", "Mu\u00b7sen", "lieb\u00b7ten", "Ihn", ",", "mit", "fr\u00fc\u00b7hen", "Lor\u00b7beern", "kr\u00f6n\u00b7ten"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PPER", "$,", "APPR", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die Musen ihres Lieblings Haupt.", "tokens": ["Die", "Mu\u00b7sen", "ih\u00b7res", "Lieb\u00b7lings", "Haupt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Er sang mit Leichtigkeit und feuriger Empfindung,", "tokens": ["Er", "sang", "mit", "Leich\u00b7tig\u00b7keit", "und", "feu\u00b7ri\u00b7ger", "Emp\u00b7fin\u00b7dung", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Ein Sch\u00fcler Gellerts und sein Freund,", "tokens": ["Ein", "Sch\u00fc\u00b7ler", "Gel\u00b7lerts", "und", "sein", "Freund", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "KON", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Stets unersch\u00f6pflich an Erfindung,", "tokens": ["Stets", "un\u00b7er\u00b7sch\u00f6pf\u00b7lich", "an", "Er\u00b7fin\u00b7dung", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Und allem Unsinn feind.", "tokens": ["Und", "al\u00b7lem", "Un\u00b7sinn", "feind", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "NN", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Er hatte, da durch ihn die Tugend lehren wollte,", "tokens": ["Er", "hat\u00b7te", ",", "da", "durch", "ihn", "die", "Tu\u00b7gend", "leh\u00b7ren", "woll\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "KOUS", "APPR", "PPER", "ART", "NN", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Das hohe Trauerspiel erw\u00e4hlt:", "tokens": ["Das", "ho\u00b7he", "Trau\u00b7er\u00b7spiel", "er\u00b7w\u00e4hlt", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wir hofften da\u00df an Ihm auch Deutschland haben sollte,", "tokens": ["Wir", "hoff\u00b7ten", "da\u00df", "an", "Ihm", "auch", "Deutschland", "ha\u00b7ben", "soll\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KOUS", "APPR", "PPER", "ADV", "NE", "VAINF", "VMFIN", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.4": {"text": "Was ihm vor andern V\u00f6lkern fehlt:", "tokens": ["Was", "ihm", "vor", "an\u00b7dern", "V\u00f6l\u00b7kern", "fehlt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Den griechischen Cothurn, den Schmuck der bessern B\u00fchne,", "tokens": ["Den", "grie\u00b7chi\u00b7schen", "Cot\u00b7hurn", ",", "den", "Schmuck", "der", "bes\u00b7sern", "B\u00fch\u00b7ne", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+--++-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "Corneillens k\u00fchn erhabnen Geist,", "tokens": ["Cor\u00b7neil\u00b7lens", "k\u00fchn", "er\u00b7hab\u00b7nen", "Geist", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Mit aller Anmuth des Racine,", "tokens": ["Mit", "al\u00b7ler", "An\u00b7muth", "des", "Ra\u00b7ci\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Die uns zu Thr\u00e4nen rei\u00dft.", "tokens": ["Die", "uns", "zu", "Thr\u00e4\u00b7nen", "rei\u00dft", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "Umsonst! Melpomene weint, unter den Cypressen,", "tokens": ["Um\u00b7sonst", "!", "Mel\u00b7po\u00b7me\u00b7ne", "weint", ",", "un\u00b7ter", "den", "Cyp\u00b7res\u00b7sen", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$.", "NE", "VVFIN", "$,", "APPR", "ART", "NN", "$,"], "meter": "-+--+-++--+--", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Um Cronegk, der so viel versprach.", "tokens": ["Um", "Cro\u00b7negk", ",", "der", "so", "viel", "ver\u00b7sprach", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "NN", "$,", "PRELS", "ADV", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der Hain, in welchem Er oft neben ihr gesessen,", "tokens": ["Der", "Hain", ",", "in", "wel\u00b7chem", "Er", "oft", "ne\u00b7ben", "ihr", "ge\u00b7ses\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "APPR", "PRELS", "PPER", "ADV", "APPR", "PPOSAT", "VVPP", "$,"], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Seufzt ihre Klagen traurig nach.", "tokens": ["Seufzt", "ih\u00b7re", "Kla\u00b7gen", "trau\u00b7rig", "nach", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die Musen gehn betr\u00fcbt in einsamen Gestr\u00e4uchen,", "tokens": ["Die", "Mu\u00b7sen", "gehn", "be\u00b7tr\u00fcbt", "in", "ein\u00b7sa\u00b7men", "Ge\u00b7str\u00e4u\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Und klagen: unser Freund ist todt!", "tokens": ["Und", "kla\u00b7gen", ":", "un\u00b7ser", "Freund", "ist", "todt", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVINF", "$.", "PPOSAT", "NN", "VAFIN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "O Musen, m\u00fcssen wir euch gleichen?", "tokens": ["O", "Mu\u00b7sen", ",", "m\u00fcs\u00b7sen", "wir", "euch", "glei\u00b7chen", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "VMFIN", "PPER", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Auch unser Freund ist todt!", "tokens": ["Auch", "un\u00b7ser", "Freund", "ist", "todt", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "VAFIN", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "Er ist auf ewig hin! verbl\u00fchn so grosse Gaben", "tokens": ["Er", "ist", "auf", "e\u00b7wig", "hin", "!", "ver\u00b7bl\u00fchn", "so", "gros\u00b7se", "Ga\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "APPR", "ADJD", "PTKVZ", "$.", "VVFIN", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Noch ungereift und kaum gekannt?", "tokens": ["Noch", "un\u00b7ge\u00b7reift", "und", "kaum", "ge\u00b7kannt", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KON", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die Welt, wo Tugenden die\u00df rauhe Schicksal haben,", "tokens": ["Die", "Welt", ",", "wo", "Tu\u00b7gen\u00b7den", "die\u00df", "rau\u00b7he", "Schick\u00b7sal", "ha\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PWAV", "NN", "PDS", "ADJA", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Regiert ein g\u00f6ttlicher Verstand?", "tokens": ["Re\u00b7giert", "ein", "g\u00f6tt\u00b7li\u00b7cher", "Ver\u00b7stand", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "ART", "ADJA", "NN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.5": {"text": "Wir zweifeln? sollten wir das grosse Ganze kennen,", "tokens": ["Wir", "zwei\u00b7feln", "?", "soll\u00b7ten", "wir", "das", "gros\u00b7se", "Gan\u00b7ze", "ken\u00b7nen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVINF", "$.", "VMFIN", "PPER", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Die\u00df Ganze, das kein Auge mi\u00dft;", "tokens": ["Die\u00df", "Gan\u00b7ze", ",", "das", "kein", "Au\u00b7ge", "mi\u00dft", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "NN", "$,", "PRELS", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "So w\u00fcrden wir nicht Fehler nennen,", "tokens": ["So", "w\u00fcr\u00b7den", "wir", "nicht", "Feh\u00b7ler", "nen\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PTKNEG", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Was regelm\u00e4\u00dfig ist.", "tokens": ["Was", "re\u00b7gel\u00b7m\u00e4\u00b7\u00dfig", "ist", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PWS", "ADJD", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "Vermessen fragen wir nach jedes Zufalls Grunde:", "tokens": ["Ver\u00b7mes\u00b7sen", "fra\u00b7gen", "wir", "nach", "je\u00b7des", "Zu\u00b7falls", "Grun\u00b7de", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "APPR", "PIAT", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Was unser Sch\u00f6pfer will, ist gut.", "tokens": ["Was", "un\u00b7ser", "Sch\u00f6p\u00b7fer", "will", ",", "ist", "gut", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "PPOSAT", "NN", "VMFIN", "$,", "VAFIN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Er w\u00e4hlt f\u00fcr unsern Tod die allerbeste Stunde,", "tokens": ["Er", "w\u00e4hlt", "f\u00fcr", "un\u00b7sern", "Tod", "die", "al\u00b7ler\u00b7bes\u00b7te", "Stun\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die vor des Schicksals Throne ruht.", "tokens": ["Die", "vor", "des", "Schick\u00b7sals", "Thro\u00b7ne", "ruht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Zwar wider die Vernunft will sich der Schmerz emp\u00f6ren,", "tokens": ["Zwar", "wi\u00b7der", "die", "Ver\u00b7nunft", "will", "sich", "der", "Schmerz", "em\u00b7p\u00f6\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "VMFIN", "PRF", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Der vor sich hin zur Erde schaut.", "tokens": ["Der", "vor", "sich", "hin", "zur", "Er\u00b7de", "schaut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "PRF", "ADV", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Wir m\u00fcssen doch zuletzt sie h\u00f6ren:", "tokens": ["Wir", "m\u00fcs\u00b7sen", "doch", "zu\u00b7letzt", "sie", "h\u00f6\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "ADV", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Sie ruft uns allzulaut.", "tokens": ["Sie", "ruft", "uns", "all\u00b7zu\u00b7laut", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.13": {"line.1": {"text": "Sie sagt uns: Cronegk lebt in einer h\u00f6hern Sph\u00e4re!", "tokens": ["Sie", "sagt", "uns", ":", "Cro\u00b7negk", "lebt", "in", "ei\u00b7ner", "h\u00f6\u00b7hern", "Sph\u00e4\u00b7re", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$.", "NN", "VVFIN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wir glauben ihr mit Freudigkeit:", "tokens": ["Wir", "glau\u00b7ben", "ihr", "mit", "Freu\u00b7dig\u00b7keit", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wenn nicht sein be\u00dfrer Theil dem Grab entronnen w\u00e4re,", "tokens": ["Wenn", "nicht", "sein", "be\u00df\u00b7rer", "Theil", "dem", "Grab", "ent\u00b7ron\u00b7nen", "w\u00e4\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PTKNEG", "PPOSAT", "ADJA", "NN", "ART", "NN", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wo w\u00e4r ein Trost f\u00fcr unser Leid?", "tokens": ["Wo", "w\u00e4r", "ein", "Trost", "f\u00fcr", "un\u00b7ser", "Leid", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "ART", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Er lebt! in jene Welt der Geister aufgenommen,", "tokens": ["Er", "lebt", "!", "in", "je\u00b7ne", "Welt", "der", "Geis\u00b7ter", "auf\u00b7ge\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "APPR", "PDAT", "NN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Setzt Er sein Leben ewig fort:", "tokens": ["Setzt", "Er", "sein", "Le\u00b7ben", "e\u00b7wig", "fort", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPOSAT", "NN", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Was hier zur Reife nicht gekommen,", "tokens": ["Was", "hier", "zur", "Rei\u00b7fe", "nicht", "ge\u00b7kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "APPRART", "NN", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Das reift und bl\u00fchet dort.", "tokens": ["Das", "reift", "und", "bl\u00fc\u00b7het", "dort", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "KON", "VVFIN", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.14": {"line.1": {"text": "So hangen Ewigkeit und unsre Zeit zusammen,", "tokens": ["So", "han\u00b7gen", "E\u00b7wig\u00b7keit", "und", "uns\u00b7re", "Zeit", "zu\u00b7sam\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NN", "KON", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Durch einen f\u00fcrchterlichen Pfad!", "tokens": ["Durch", "ei\u00b7nen", "f\u00fcrch\u00b7ter\u00b7li\u00b7chen", "Pfad", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Was konnte ", "tokens": ["Was", "konn\u00b7te"], "token_info": ["word", "word"], "pos": ["PWS", "VMFIN"], "meter": "-+-", "measure": "amphibrach.single"}, "line.4": {"text": "Der diesen Weg getrost betrat?", "tokens": ["Der", "die\u00b7sen", "Weg", "ge\u00b7trost", "be\u00b7trat", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PDAT", "NN", "VVPP", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wie? kann mit heitrer Stirn der muntre J\u00fcngling scheiden,", "tokens": ["Wie", "?", "kann", "mit", "hei\u00b7trer", "Stirn", "der", "mun\u00b7tre", "J\u00fcng\u00b7ling", "schei\u00b7den", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$.", "VMFIN", "APPR", "ADJA", "NN", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Der, schimmernder Entw\u00fcrfe voll,", "tokens": ["Der", ",", "schim\u00b7mern\u00b7der", "Ent\u00b7w\u00fcr\u00b7fe", "voll", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "$,", "ADJA", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und aus den Armen aller Freuden,", "tokens": ["Und", "aus", "den", "Ar\u00b7men", "al\u00b7ler", "Freu\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Zum Grab entweichen soll?", "tokens": ["Zum", "Grab", "ent\u00b7wei\u00b7chen", "soll", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.15": {"line.1": {"text": "Die drohende Gefahr schwebt' um den edlen Kranken:", "tokens": ["Die", "dro\u00b7hen\u00b7de", "Ge\u00b7fahr", "schwebt'", "um", "den", "ed\u00b7len", "Kran\u00b7ken", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Nun wog Er Ewigkeit und Zeit;", "tokens": ["Nun", "wog", "Er", "E\u00b7wig\u00b7keit", "und", "Zeit", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und Seine Seele war voll w\u00fcrdiger Gedanken,", "tokens": ["Und", "Sei\u00b7ne", "See\u00b7le", "war", "voll", "w\u00fcr\u00b7di\u00b7ger", "Ge\u00b7dan\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VAFIN", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Gedanken der Unsterblichkeit.", "tokens": ["Ge\u00b7dan\u00b7ken", "der", "U\u00b7nsterb\u00b7lich\u00b7keit", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.5": {"text": "Die Hoffnung sah erstaunt, in diesen ernsten Stunden,", "tokens": ["Die", "Hoff\u00b7nung", "sah", "er\u00b7staunt", ",", "in", "die\u00b7sen", "erns\u00b7ten", "Stun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJD", "$,", "APPR", "PDAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Den jungen Weisen ihr entfliehn:", "tokens": ["Den", "jun\u00b7gen", "Wei\u00b7sen", "ihr", "ent\u00b7fliehn", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Die Erde war vor Ihm verschwunden,", "tokens": ["Die", "Er\u00b7de", "war", "vor", "Ihm", "ver\u00b7schwun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "APPR", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Und Himmel war um Ihn.", "tokens": ["Und", "Him\u00b7mel", "war", "um", "Ihn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VAFIN", "APPR", "PPER", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.16": {"line.1": {"text": "Du Mutter unsers Freunds, die vor Ihm hingegangen,", "tokens": ["Du", "Mut\u00b7ter", "un\u00b7sers", "Freunds", ",", "die", "vor", "Ihm", "hin\u00b7ge\u00b7gan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "PPOSAT", "NN", "$,", "PRELS", "APPR", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wo die gekr\u00f6nte Tugend wohnt,", "tokens": ["Wo", "die", "ge\u00b7kr\u00f6n\u00b7te", "Tu\u00b7gend", "wohnt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und sterbend Ihn gelehrt, den Lorbeer zu erlangen,", "tokens": ["Und", "ster\u00b7bend", "Ihn", "ge\u00b7lehrt", ",", "den", "Lor\u00b7beer", "zu", "er\u00b7lan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "PPER", "VVPP", "$,", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der wahren Heldenmuth belohnt:", "tokens": ["Der", "wah\u00b7ren", "Hel\u00b7den\u00b7muth", "be\u00b7lohnt", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wenn du Ihn sterben sahst (den sch\u00f6nen Tod des Weisen", "tokens": ["Wenn", "du", "Ihn", "ster\u00b7ben", "sahst", "(", "den", "sch\u00f6\u00b7nen", "Tod", "des", "Wei\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PPER", "VVINF", "VVFIN", "$(", "ART", "ADJA", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Sehn auch Unsterbliche mit Lust)", "tokens": ["Sehn", "auch", "U\u00b7nsterb\u00b7li\u00b7che", "mit", "Lust", ")"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "NN", "APPR", "NN", "$("], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.7": {"text": "Wie gl\u00fccklich mu\u00dftest du Ihn preisen,", "tokens": ["Wie", "gl\u00fcck\u00b7lich", "mu\u00df\u00b7test", "du", "Ihn", "prei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VMFIN", "PPER", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Den du bewundern mu\u00dft!", "tokens": ["Den", "du", "be\u00b7wun\u00b7dern", "mu\u00dft", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVINF", "VMFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.17": {"line.1": {"text": "Wie brannte nicht dein Herz, als, nach begl\u00fccktem Streite,", "tokens": ["Wie", "brann\u00b7te", "nicht", "dein", "Herz", ",", "als", ",", "nach", "be\u00b7gl\u00fcck\u00b7tem", "Strei\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PTKNEG", "PPOSAT", "NN", "$,", "KOUS", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Dich dieser theure Sohn umfieng,", "tokens": ["Dich", "die\u00b7ser", "theu\u00b7re", "Sohn", "um\u00b7fi\u00b7eng", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PDAT", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Und, selbst unsterblich, nun an einer Mutter Seite", "tokens": ["Und", ",", "selbst", "uns\u00b7terb\u00b7lich", ",", "nun", "an", "ei\u00b7ner", "Mut\u00b7ter", "Sei\u00b7te"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "$,", "ADV", "ADJD", "$,", "ADV", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Durch jauchzende Gerechte gieng?", "tokens": ["Durch", "jauch\u00b7zen\u00b7de", "Ge\u00b7rech\u00b7te", "gieng", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+---+-+", "measure": "dactylic.init"}, "line.5": {"text": "Du segnetest den Tod, der Ihn aus Finsternissen", "tokens": ["Du", "seg\u00b7ne\u00b7test", "den", "Tod", ",", "der", "Ihn", "aus", "Fins\u00b7ter\u00b7nis\u00b7sen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "PRELS", "PPER", "APPR", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und Schlingen lockender Gefahr,", "tokens": ["Und", "Schlin\u00b7gen", "lo\u00b7cken\u00b7der", "Ge\u00b7fahr", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Zu einer bessern Welt entrissen,", "tokens": ["Zu", "ei\u00b7ner", "bes\u00b7sern", "Welt", "ent\u00b7ris\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Die Cronegks w\u00fcrdig war.", "tokens": ["Die", "Cro\u00b7negks", "w\u00fcr\u00b7dig", "war", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.18": {"line.1": {"text": "Sollt ungest\u00fcmer Schmerz des Weisen Grab entweihen,", "tokens": ["Sollt", "un\u00b7ge\u00b7st\u00fc\u00b7mer", "Schmerz", "des", "Wei\u00b7sen", "Grab", "ent\u00b7wei\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADJA", "NN", "ART", "NN", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der zur Unsterblichkeit gelangt?", "tokens": ["Der", "zur", "U\u00b7nsterb\u00b7lich\u00b7keit", "ge\u00b7langt", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "APPRART", "NN", "VVPP", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.3": {"text": "Doch auch die Weisheit wird ein stilles Leid verzeihen,", "tokens": ["Doch", "auch", "die", "Weis\u00b7heit", "wird", "ein", "stil\u00b7les", "Leid", "ver\u00b7zei\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "VAFIN", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Das nicht mit stolzen Thr\u00e4nen prangt.", "tokens": ["Das", "nicht", "mit", "stol\u00b7zen", "Thr\u00e4\u00b7nen", "prangt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PTKNEG", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Verzeih, Unsterblicher, die wehmuthvollen Thr\u00e4nen,", "tokens": ["Ver\u00b7zeih", ",", "U\u00b7nsterb\u00b7li\u00b7cher", ",", "die", "weh\u00b7muth\u00b7vol\u00b7len", "Thr\u00e4\u00b7nen", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADJD", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Die ein geliebter Vater weint!", "tokens": ["Die", "ein", "ge\u00b7lieb\u00b7ter", "Va\u00b7ter", "weint", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Verzeih der Freundschaft z\u00e4rtlich Sehnen", "tokens": ["Ver\u00b7zeih", "der", "Freund\u00b7schaft", "z\u00e4rt\u00b7lich", "Seh\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVIMP", "ART", "NN", "ADJD", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Nach Dir, dem besten Freund!", "tokens": ["Nach", "Dir", ",", "dem", "bes\u00b7ten", "Freund", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "$,", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.19": {"line.1": {"text": "Wir sehn, um Mitternacht, in jene blaue Ferne,", "tokens": ["Wir", "sehn", ",", "um", "Mit\u00b7ter\u00b7nacht", ",", "in", "je\u00b7ne", "blau\u00b7e", "Fer\u00b7ne", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUI", "NN", "$,", "APPR", "PDAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wohin die Tugend Dich erhob:", "tokens": ["Wo\u00b7hin", "die", "Tu\u00b7gend", "Dich", "er\u00b7hob", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wo bist Du? seufzen wir; auf welchem lichten Sterne", "tokens": ["Wo", "bist", "Du", "?", "seuf\u00b7zen", "wir", ";", "auf", "wel\u00b7chem", "lich\u00b7ten", "Ster\u00b7ne"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWAV", "VAFIN", "PPER", "$.", "VVFIN", "PPER", "$.", "APPR", "PWAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Besingst Du nun der Gottheit Lob?", "tokens": ["Be\u00b7singst", "Du", "nun", "der", "Got\u00b7theit", "Lob", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Der Himmel h\u00f6rt entz\u00fcckt die Harmonie der Lieder!", "tokens": ["Der", "Him\u00b7mel", "h\u00f6rt", "ent\u00b7z\u00fcckt", "die", "Har\u00b7mo\u00b7nie", "der", "Lie\u00b7der", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "VVFIN", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Du wirfst noch einen kurzen Blick", "tokens": ["Du", "wirfst", "noch", "ei\u00b7nen", "kur\u00b7zen", "Blick"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Nach unsrer dunkeln Erde nieder,", "tokens": ["Nach", "uns\u00b7rer", "dun\u00b7keln", "Er\u00b7de", "nie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Und f\u00fchlst Dein ganzes Gl\u00fcck.", "tokens": ["Und", "f\u00fchlst", "Dein", "gan\u00b7zes", "Gl\u00fcck", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.20": {"line.1": {"text": "Wir singen Deinen Ruhm, und schildern fernen Tagen", "tokens": ["Wir", "sin\u00b7gen", "Dei\u00b7nen", "Ruhm", ",", "und", "schil\u00b7dern", "fer\u00b7nen", "Ta\u00b7gen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "$,", "KON", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Dein Herz und unsre Freundschaft ab.", "tokens": ["Dein", "Herz", "und", "uns\u00b7re", "Freund\u00b7schaft", "ab", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die Nachwelt m\u00fcss' um Dich aus unsern Liedern klagen!", "tokens": ["Die", "Nach\u00b7welt", "m\u00fcss'", "um", "Dich", "aus", "un\u00b7sern", "Lie\u00b7dern", "kla\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "APPR", "PRF", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Sie streue Blumen auf Dein Grab!", "tokens": ["Sie", "streu\u00b7e", "Blu\u00b7men", "auf", "Dein", "Grab", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wir werden sp\u00e4te noch Dir manche Thr\u00e4ne schenken:", "tokens": ["Wir", "wer\u00b7den", "sp\u00e4\u00b7te", "noch", "Dir", "man\u00b7che", "Thr\u00e4\u00b7ne", "schen\u00b7ken", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVFIN", "ADV", "PPER", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+++-+-+-", "measure": "unknown.measure.septa"}, "line.6": {"text": "Auch wenn wir k\u00fcnftig uns erfreun,", "tokens": ["Auch", "wenn", "wir", "k\u00fcnf\u00b7tig", "uns", "er\u00b7freun", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PPER", "ADJD", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Soll unsers Cronegks Angedenken", "tokens": ["Soll", "un\u00b7sers", "Cro\u00b7negks", "An\u00b7ge\u00b7den\u00b7ken"], "token_info": ["word", "word", "word", "word"], "pos": ["VMFIN", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Uns immer heilig seyn!", "tokens": ["Uns", "im\u00b7mer", "hei\u00b7lig", "seyn", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADJD", "VAINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.21": {"line.1": {"text": "Wir warteten umsonst, von Cronegks Tod zu singen,", "tokens": ["Wir", "war\u00b7te\u00b7ten", "um\u00b7sonst", ",", "von", "Cro\u00b7negks", "Tod", "zu", "sin\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "APPR", "NE", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Auf sp\u00e4ten Trost entfernter Zeit:", "tokens": ["Auf", "sp\u00e4\u00b7ten", "Trost", "ent\u00b7fern\u00b7ter", "Zeit", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Noch itzt umschattet uns, mit f\u00fcrchterlichen Schwingen,", "tokens": ["Noch", "itzt", "um\u00b7schat\u00b7tet", "uns", ",", "mit", "f\u00fcrch\u00b7ter\u00b7li\u00b7chen", "Schwin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die unbesiegte Traurigkeit.", "tokens": ["Die", "un\u00b7be\u00b7sieg\u00b7te", "Trau\u00b7rig\u00b7keit", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Umsonst gelobten wir den schlafenden Gebeinen", "tokens": ["Um\u00b7sonst", "ge\u00b7lob\u00b7ten", "wir", "den", "schla\u00b7fen\u00b7den", "Ge\u00b7bei\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Ein Lied, ein unverg\u00e4nglich Lied:", "tokens": ["Ein", "Lied", ",", "ein", "un\u00b7ver\u00b7g\u00e4ng\u00b7lich", "Lied", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "ADJD", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Wir denken Cronegks Grab, und weinen,", "tokens": ["Wir", "den\u00b7ken", "Cro\u00b7negks", "Grab", ",", "und", "wei\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NE", "NN", "$,", "KON", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Und jede Muse flieht!", "tokens": ["Und", "je\u00b7de", "Mu\u00b7se", "flieht", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.22": {"line.1": {"text": "O Grab des liebsten Freunds! O Cronegk, theurer Nahme,", "tokens": ["O", "Grab", "des", "liebs\u00b7ten", "Freunds", "!", "O", "Cro\u00b7negk", ",", "theu\u00b7rer", "Nah\u00b7me", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "NN", "ART", "ADJA", "NN", "$.", "NE", "NN", "$,", "ADJD", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Sonst unser Stolz, nun unser Schmerz!", "tokens": ["Sonst", "un\u00b7ser", "Stolz", ",", "nun", "un\u00b7ser", "Schmerz", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "$,", "ADV", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die Zeit, mit ihrem Trost, entw\u00f6lkt von finsterm Grame", "tokens": ["Die", "Zeit", ",", "mit", "ih\u00b7rem", "Trost", ",", "ent\u00b7w\u00f6lkt", "von", "fins\u00b7term", "Gra\u00b7me"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "APPR", "PPOSAT", "NN", "$,", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Nur unsre Stirn, nicht unser Herz.", "tokens": ["Nur", "uns\u00b7re", "Stirn", ",", "nicht", "un\u00b7ser", "Herz", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "$,", "PTKNEG", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wir trauern schweigend fort, und haben Recht zu trauern:", "tokens": ["Wir", "trau\u00b7ern", "schwei\u00b7gend", "fort", ",", "und", "ha\u00b7ben", "Recht", "zu", "trau\u00b7ern", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "PTKVZ", "$,", "KON", "VAFIN", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Dein Herz war uns zu nah verwandt!", "tokens": ["Dein", "Herz", "war", "uns", "zu", "nah", "ver\u00b7wandt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "PPER", "PTKA", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Mu\u00df doch die Menge Dich bedauern,", "tokens": ["Mu\u00df", "doch", "die", "Men\u00b7ge", "Dich", "be\u00b7dau\u00b7ern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "ART", "NN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Die Dich nur halb gekannt.", "tokens": ["Die", "Dich", "nur", "halb", "ge\u00b7kannt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.23": {"line.1": {"text": "Wenn sie, bey Deinem Grab, nur weil Du kurz gelebet,", "tokens": ["Wenn", "sie", ",", "bey", "Dei\u00b7nem", "Grab", ",", "nur", "weil", "Du", "kurz", "ge\u00b7le\u00b7bet", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "APPR", "PPOSAT", "NN", "$,", "ADV", "KOUS", "PPER", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Um Deine sch\u00f6ne Jugend weint,", "tokens": ["Um", "Dei\u00b7ne", "sch\u00f6\u00b7ne", "Ju\u00b7gend", "weint", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PPOSAT", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und Deine G\u00fctigkeit mit nassem Aug erhebet;", "tokens": ["Und", "Dei\u00b7ne", "G\u00fc\u00b7tig\u00b7keit", "mit", "nas\u00b7sem", "Aug", "er\u00b7he\u00b7bet", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Beweinen wir in Dir den Freund:", "tokens": ["Be\u00b7wei\u00b7nen", "wir", "in", "Dir", "den", "Freund", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Den Freund voll Z\u00e4rtlichkeit, der mit Geschmack und Sitten", "tokens": ["Den", "Freund", "voll", "Z\u00e4rt\u00b7lich\u00b7keit", ",", "der", "mit", "Ge\u00b7schmack", "und", "Sit\u00b7ten"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADJD", "NN", "$,", "PRELS", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Ein liebensw\u00fcrdig Herz verband,", "tokens": ["Ein", "lie\u00b7bens\u00b7w\u00fcr\u00b7dig", "Herz", "ver\u00b7band", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Selbst litt, wenn seine Freunde litten,", "tokens": ["Selbst", "litt", ",", "wenn", "sei\u00b7ne", "Freun\u00b7de", "lit\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "KOUS", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Und selbst ihr Gl\u00fcck empfand:", "tokens": ["Und", "selbst", "ihr", "Gl\u00fcck", "emp\u00b7fand", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.24": {"line.1": {"text": "Den Edlen, den Sein Herz mehr, als Geburt, geadelt,", "tokens": ["Den", "Ed\u00b7len", ",", "den", "Sein", "Herz", "mehr", ",", "als", "Ge\u00b7burt", ",", "ge\u00b7a\u00b7delt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPOSAT", "NN", "ADV", "$,", "KOUS", "NN", "$,", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und keine niedre That entehrt;", "tokens": ["Und", "kei\u00b7ne", "nied\u00b7re", "That", "ent\u00b7ehrt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Den k\u00fchne Schm\u00e4hsucht selbst nur leis und sch\u00fcchtern tadelt,", "tokens": ["Den", "k\u00fch\u00b7ne", "Schm\u00e4h\u00b7sucht", "selbst", "nur", "leis", "und", "sch\u00fcch\u00b7tern", "ta\u00b7delt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "ADV", "ADJD", "KON", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Nur bey dem P\u00f6bel, der sie h\u00f6rt;", "tokens": ["Nur", "bey", "dem", "P\u00f6\u00b7bel", ",", "der", "sie", "h\u00f6rt", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Der Tugend \u00e4chten Freund, doch einer sanften Tugend,", "tokens": ["Der", "Tu\u00b7gend", "\u00e4ch\u00b7ten", "Freund", ",", "doch", "ei\u00b7ner", "sanf\u00b7ten", "Tu\u00b7gend", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$,", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Die, von den Grazien geschm\u00fcckt,", "tokens": ["Die", ",", "von", "den", "Gra\u00b7zi\u00b7en", "ge\u00b7schm\u00fcckt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Umkr\u00e4nzt mit Rosen muntrer Jugend,", "tokens": ["Um\u00b7kr\u00e4nzt", "mit", "Ro\u00b7sen", "mun\u00b7trer", "Ju\u00b7gend", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Durch stillen Reiz entz\u00fcckt.", "tokens": ["Durch", "stil\u00b7len", "Reiz", "ent\u00b7z\u00fcckt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.25": {"line.1": {"text": "Nicht rauschendes Verdienst, das Nationen preisen,", "tokens": ["Nicht", "rau\u00b7schen\u00b7des", "Ver\u00b7dienst", ",", "das", "Na\u00b7ti\u00b7o\u00b7nen", "prei\u00b7sen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADJA", "NN", "$,", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Nicht Ruhm, erhitzter Ehrsucht Kind,", "tokens": ["Nicht", "Ruhm", ",", "er\u00b7hitz\u00b7ter", "Ehr\u00b7sucht", "Kind", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "NN", "$,", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Das Herz macht unsern Werth bey aufgekl\u00e4rten Weisen,", "tokens": ["Das", "Herz", "macht", "un\u00b7sern", "Werth", "bey", "auf\u00b7ge\u00b7kl\u00e4r\u00b7ten", "Wei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPOSAT", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die unsre wahre Richter sind:", "tokens": ["Die", "uns\u00b7re", "wah\u00b7re", "Rich\u00b7ter", "sind", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "ADJA", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ein Herz, wie Cronegks Herz, das blo\u00df aus Menschenliebe", "tokens": ["Ein", "Herz", ",", "wie", "Cro\u00b7negks", "Herz", ",", "das", "blo\u00df", "aus", "Men\u00b7schen\u00b7lie\u00b7be"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PWAV", "NE", "NN", "$,", "PRELS", "ADV", "APPR", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Den Menschen wohl zu thun sich freut,", "tokens": ["Den", "Men\u00b7schen", "wohl", "zu", "thun", "sich", "freut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "PTKZU", "VVINF", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und wenn es auch verborgen bliebe,", "tokens": ["Und", "wenn", "es", "auch", "ver\u00b7bor\u00b7gen", "blie\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "VVPP", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Das Gute nicht bereut.", "tokens": ["Das", "Gu\u00b7te", "nicht", "be\u00b7reut", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.26": {"line.1": {"text": "Er g\u00f6nnte schimmernd Gl\u00fcck, das Tausende beneiden,", "tokens": ["Er", "g\u00f6nn\u00b7te", "schim\u00b7mernd", "Gl\u00fcck", ",", "das", "Tau\u00b7sen\u00b7de", "be\u00b7nei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "NN", "$,", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Den Sclaven ungeliebter Pracht:", "tokens": ["Den", "Scla\u00b7ven", "un\u00b7ge\u00b7lieb\u00b7ter", "Pracht", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sein Stolz war be\u00dfrer Art! Er h\u00e4tte voller Freuden", "tokens": ["Sein", "Stolz", "war", "be\u00df\u00b7rer", "Art", "!", "Er", "h\u00e4t\u00b7te", "vol\u00b7ler", "Freu\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VAFIN", "ADJA", "NN", "$.", "PPER", "VAFIN", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Auch eine Welt begl\u00fcckt gemacht.", "tokens": ["Auch", "ei\u00b7ne", "Welt", "be\u00b7gl\u00fcckt", "ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVPP", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Nur Freunde kannten Ihn und wu\u00dften Ihn zu sch\u00e4tzen:", "tokens": ["Nur", "Freun\u00b7de", "kann\u00b7ten", "Ihn", "und", "wu\u00df\u00b7ten", "Ihn", "zu", "sch\u00e4t\u00b7zen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "VVFIN", "PPER", "KON", "VVFIN", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wir haben Ihn zu sehr gekannt,", "tokens": ["Wir", "ha\u00b7ben", "Ihn", "zu", "sehr", "ge\u00b7kannt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "PTKA", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und Welten k\u00f6nnen nicht ersetzen,", "tokens": ["Und", "Wel\u00b7ten", "k\u00f6n\u00b7nen", "nicht", "er\u00b7set\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VMFIN", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Was uns das Grab entwandt!", "tokens": ["Was", "uns", "das", "Grab", "ent\u00b7wandt", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.27": {"line.1": {"text": "Wenn Cronegk um uns war, o welche g\u00fcldne Stunden!", "tokens": ["Wenn", "Cro\u00b7negk", "um", "uns", "war", ",", "o", "wel\u00b7che", "g\u00fcld\u00b7ne", "Stun\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "APPR", "PPER", "VAFIN", "$,", "FM", "PWAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "O g\u00fcldne Zeit, die schnell verstrich!", "tokens": ["O", "g\u00fcld\u00b7ne", "Zeit", ",", "die", "schnell", "ver\u00b7strich", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$,", "PRELS", "ADJD", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "H\u00e4lt nun ein dunkles Grab den leichten Scherz gebunden,", "tokens": ["H\u00e4lt", "nun", "ein", "dunk\u00b7les", "Grab", "den", "leich\u00b7ten", "Scherz", "ge\u00b7bun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "ADJA", "NN", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der nie von Seinen Lippen wich?", "tokens": ["Der", "nie", "von", "Sei\u00b7nen", "Lip\u00b7pen", "wich", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die\u00df gl\u00fcckliche Genie, das fl\u00fcchtig, gleich dem Blitze,", "tokens": ["Die\u00df", "gl\u00fcck\u00b7li\u00b7che", "Ge\u00b7nie", ",", "das", "fl\u00fcch\u00b7tig", ",", "gleich", "dem", "Blit\u00b7ze", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "ADJA", "NN", "$,", "PRELS", "ADJD", "$,", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Durch alle sch\u00f6ne Kenntni\u00df flog,", "tokens": ["Durch", "al\u00b7le", "sch\u00f6\u00b7ne", "Kennt\u00b7ni\u00df", "flog", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und S\u00fc\u00dfigkeit, mit scharfem Witze,", "tokens": ["Und", "S\u00fc\u00b7\u00dfig\u00b7keit", ",", "mit", "schar\u00b7fem", "Wit\u00b7ze", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "NN", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Von allen Blumen sog?", "tokens": ["Von", "al\u00b7len", "Blu\u00b7men", "sog", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.28": {"line.1": {"text": "Sein reizend Saitenspiel, wo holde Lieder t\u00f6nten,", "tokens": ["Sein", "rei\u00b7zend", "Sai\u00b7ten\u00b7spiel", ",", "wo", "hol\u00b7de", "Lie\u00b7der", "t\u00f6n\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJD", "NN", "$,", "PWAV", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Sonst unsre Lust, ist uns geraubt?", "tokens": ["Sonst", "uns\u00b7re", "Lust", ",", "ist", "uns", "ge\u00b7raubt", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "$,", "VAFIN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die Musen liebten Ihn, mit fr\u00fchen Lorbeern kr\u00f6nten", "tokens": ["Die", "Mu\u00b7sen", "lieb\u00b7ten", "Ihn", ",", "mit", "fr\u00fc\u00b7hen", "Lor\u00b7beern", "kr\u00f6n\u00b7ten"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PPER", "$,", "APPR", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die Musen ihres Lieblings Haupt.", "tokens": ["Die", "Mu\u00b7sen", "ih\u00b7res", "Lieb\u00b7lings", "Haupt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Er sang mit Leichtigkeit und feuriger Empfindung,", "tokens": ["Er", "sang", "mit", "Leich\u00b7tig\u00b7keit", "und", "feu\u00b7ri\u00b7ger", "Emp\u00b7fin\u00b7dung", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Ein Sch\u00fcler Gellerts und sein Freund,", "tokens": ["Ein", "Sch\u00fc\u00b7ler", "Gel\u00b7lerts", "und", "sein", "Freund", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "KON", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Stets unersch\u00f6pflich an Erfindung,", "tokens": ["Stets", "un\u00b7er\u00b7sch\u00f6pf\u00b7lich", "an", "Er\u00b7fin\u00b7dung", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Und allem Unsinn feind.", "tokens": ["Und", "al\u00b7lem", "Un\u00b7sinn", "feind", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "NN", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.29": {"line.1": {"text": "Er hatte, da durch ihn die Tugend lehren wollte,", "tokens": ["Er", "hat\u00b7te", ",", "da", "durch", "ihn", "die", "Tu\u00b7gend", "leh\u00b7ren", "woll\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "KOUS", "APPR", "PPER", "ART", "NN", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Das hohe Trauerspiel erw\u00e4hlt:", "tokens": ["Das", "ho\u00b7he", "Trau\u00b7er\u00b7spiel", "er\u00b7w\u00e4hlt", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wir hofften da\u00df an Ihm auch Deutschland haben sollte,", "tokens": ["Wir", "hoff\u00b7ten", "da\u00df", "an", "Ihm", "auch", "Deutschland", "ha\u00b7ben", "soll\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KOUS", "APPR", "PPER", "ADV", "NE", "VAINF", "VMFIN", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.4": {"text": "Was ihm vor andern V\u00f6lkern fehlt:", "tokens": ["Was", "ihm", "vor", "an\u00b7dern", "V\u00f6l\u00b7kern", "fehlt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Den griechischen Cothurn, den Schmuck der bessern B\u00fchne,", "tokens": ["Den", "grie\u00b7chi\u00b7schen", "Cot\u00b7hurn", ",", "den", "Schmuck", "der", "bes\u00b7sern", "B\u00fch\u00b7ne", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+--++-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "Corneillens k\u00fchn erhabnen Geist,", "tokens": ["Cor\u00b7neil\u00b7lens", "k\u00fchn", "er\u00b7hab\u00b7nen", "Geist", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Mit aller Anmuth des Racine,", "tokens": ["Mit", "al\u00b7ler", "An\u00b7muth", "des", "Ra\u00b7ci\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Die uns zu Thr\u00e4nen rei\u00dft.", "tokens": ["Die", "uns", "zu", "Thr\u00e4\u00b7nen", "rei\u00dft", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.30": {"line.1": {"text": "Umsonst! Melpomene weint, unter den Cypressen,", "tokens": ["Um\u00b7sonst", "!", "Mel\u00b7po\u00b7me\u00b7ne", "weint", ",", "un\u00b7ter", "den", "Cyp\u00b7res\u00b7sen", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$.", "NE", "VVFIN", "$,", "APPR", "ART", "NN", "$,"], "meter": "-+--+-++--+--", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Um Cronegk, der so viel versprach.", "tokens": ["Um", "Cro\u00b7negk", ",", "der", "so", "viel", "ver\u00b7sprach", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "NN", "$,", "PRELS", "ADV", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der Hain, in welchem Er oft neben ihr gesessen,", "tokens": ["Der", "Hain", ",", "in", "wel\u00b7chem", "Er", "oft", "ne\u00b7ben", "ihr", "ge\u00b7ses\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "APPR", "PRELS", "PPER", "ADV", "APPR", "PPOSAT", "VVPP", "$,"], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Seufzt ihre Klagen traurig nach.", "tokens": ["Seufzt", "ih\u00b7re", "Kla\u00b7gen", "trau\u00b7rig", "nach", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die Musen gehn betr\u00fcbt in einsamen Gestr\u00e4uchen,", "tokens": ["Die", "Mu\u00b7sen", "gehn", "be\u00b7tr\u00fcbt", "in", "ein\u00b7sa\u00b7men", "Ge\u00b7str\u00e4u\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Und klagen: unser Freund ist todt!", "tokens": ["Und", "kla\u00b7gen", ":", "un\u00b7ser", "Freund", "ist", "todt", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVINF", "$.", "PPOSAT", "NN", "VAFIN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "O Musen, m\u00fcssen wir euch gleichen?", "tokens": ["O", "Mu\u00b7sen", ",", "m\u00fcs\u00b7sen", "wir", "euch", "glei\u00b7chen", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "VMFIN", "PPER", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Auch unser Freund ist todt!", "tokens": ["Auch", "un\u00b7ser", "Freund", "ist", "todt", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "VAFIN", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.31": {"line.1": {"text": "Er ist auf ewig hin! verbl\u00fchn so grosse Gaben", "tokens": ["Er", "ist", "auf", "e\u00b7wig", "hin", "!", "ver\u00b7bl\u00fchn", "so", "gros\u00b7se", "Ga\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "APPR", "ADJD", "PTKVZ", "$.", "VVFIN", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Noch ungereift und kaum gekannt?", "tokens": ["Noch", "un\u00b7ge\u00b7reift", "und", "kaum", "ge\u00b7kannt", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KON", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die Welt, wo Tugenden die\u00df rauhe Schicksal haben,", "tokens": ["Die", "Welt", ",", "wo", "Tu\u00b7gen\u00b7den", "die\u00df", "rau\u00b7he", "Schick\u00b7sal", "ha\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PWAV", "NN", "PDS", "ADJA", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Regiert ein g\u00f6ttlicher Verstand?", "tokens": ["Re\u00b7giert", "ein", "g\u00f6tt\u00b7li\u00b7cher", "Ver\u00b7stand", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "ART", "ADJA", "NN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.5": {"text": "Wir zweifeln? sollten wir das grosse Ganze kennen,", "tokens": ["Wir", "zwei\u00b7feln", "?", "soll\u00b7ten", "wir", "das", "gros\u00b7se", "Gan\u00b7ze", "ken\u00b7nen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVINF", "$.", "VMFIN", "PPER", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Die\u00df Ganze, das kein Auge mi\u00dft;", "tokens": ["Die\u00df", "Gan\u00b7ze", ",", "das", "kein", "Au\u00b7ge", "mi\u00dft", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "NN", "$,", "PRELS", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "So w\u00fcrden wir nicht Fehler nennen,", "tokens": ["So", "w\u00fcr\u00b7den", "wir", "nicht", "Feh\u00b7ler", "nen\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PTKNEG", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Was regelm\u00e4\u00dfig ist.", "tokens": ["Was", "re\u00b7gel\u00b7m\u00e4\u00b7\u00dfig", "ist", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PWS", "ADJD", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.32": {"line.1": {"text": "Vermessen fragen wir nach jedes Zufalls Grunde:", "tokens": ["Ver\u00b7mes\u00b7sen", "fra\u00b7gen", "wir", "nach", "je\u00b7des", "Zu\u00b7falls", "Grun\u00b7de", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "APPR", "PIAT", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Was unser Sch\u00f6pfer will, ist gut.", "tokens": ["Was", "un\u00b7ser", "Sch\u00f6p\u00b7fer", "will", ",", "ist", "gut", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "PPOSAT", "NN", "VMFIN", "$,", "VAFIN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Er w\u00e4hlt f\u00fcr unsern Tod die allerbeste Stunde,", "tokens": ["Er", "w\u00e4hlt", "f\u00fcr", "un\u00b7sern", "Tod", "die", "al\u00b7ler\u00b7bes\u00b7te", "Stun\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die vor des Schicksals Throne ruht.", "tokens": ["Die", "vor", "des", "Schick\u00b7sals", "Thro\u00b7ne", "ruht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Zwar wider die Vernunft will sich der Schmerz emp\u00f6ren,", "tokens": ["Zwar", "wi\u00b7der", "die", "Ver\u00b7nunft", "will", "sich", "der", "Schmerz", "em\u00b7p\u00f6\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "VMFIN", "PRF", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Der vor sich hin zur Erde schaut.", "tokens": ["Der", "vor", "sich", "hin", "zur", "Er\u00b7de", "schaut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "PRF", "ADV", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Wir m\u00fcssen doch zuletzt sie h\u00f6ren:", "tokens": ["Wir", "m\u00fcs\u00b7sen", "doch", "zu\u00b7letzt", "sie", "h\u00f6\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "ADV", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Sie ruft uns allzulaut.", "tokens": ["Sie", "ruft", "uns", "all\u00b7zu\u00b7laut", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.33": {"line.1": {"text": "Sie sagt uns: Cronegk lebt in einer h\u00f6hern Sph\u00e4re!", "tokens": ["Sie", "sagt", "uns", ":", "Cro\u00b7negk", "lebt", "in", "ei\u00b7ner", "h\u00f6\u00b7hern", "Sph\u00e4\u00b7re", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$.", "NN", "VVFIN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wir glauben ihr mit Freudigkeit:", "tokens": ["Wir", "glau\u00b7ben", "ihr", "mit", "Freu\u00b7dig\u00b7keit", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wenn nicht sein be\u00dfrer Theil dem Grab entronnen w\u00e4re,", "tokens": ["Wenn", "nicht", "sein", "be\u00df\u00b7rer", "Theil", "dem", "Grab", "ent\u00b7ron\u00b7nen", "w\u00e4\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PTKNEG", "PPOSAT", "ADJA", "NN", "ART", "NN", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wo w\u00e4r ein Trost f\u00fcr unser Leid?", "tokens": ["Wo", "w\u00e4r", "ein", "Trost", "f\u00fcr", "un\u00b7ser", "Leid", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "ART", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Er lebt! in jene Welt der Geister aufgenommen,", "tokens": ["Er", "lebt", "!", "in", "je\u00b7ne", "Welt", "der", "Geis\u00b7ter", "auf\u00b7ge\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "APPR", "PDAT", "NN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Setzt Er sein Leben ewig fort:", "tokens": ["Setzt", "Er", "sein", "Le\u00b7ben", "e\u00b7wig", "fort", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPOSAT", "NN", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Was hier zur Reife nicht gekommen,", "tokens": ["Was", "hier", "zur", "Rei\u00b7fe", "nicht", "ge\u00b7kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "APPRART", "NN", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Das reift und bl\u00fchet dort.", "tokens": ["Das", "reift", "und", "bl\u00fc\u00b7het", "dort", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "KON", "VVFIN", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.34": {"line.1": {"text": "So hangen Ewigkeit und unsre Zeit zusammen,", "tokens": ["So", "han\u00b7gen", "E\u00b7wig\u00b7keit", "und", "uns\u00b7re", "Zeit", "zu\u00b7sam\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NN", "KON", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Durch einen f\u00fcrchterlichen Pfad!", "tokens": ["Durch", "ei\u00b7nen", "f\u00fcrch\u00b7ter\u00b7li\u00b7chen", "Pfad", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Was konnte ", "tokens": ["Was", "konn\u00b7te"], "token_info": ["word", "word"], "pos": ["PWS", "VMFIN"], "meter": "-+-", "measure": "amphibrach.single"}, "line.4": {"text": "Der diesen Weg getrost betrat?", "tokens": ["Der", "die\u00b7sen", "Weg", "ge\u00b7trost", "be\u00b7trat", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PDAT", "NN", "VVPP", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wie? kann mit heitrer Stirn der muntre J\u00fcngling scheiden,", "tokens": ["Wie", "?", "kann", "mit", "hei\u00b7trer", "Stirn", "der", "mun\u00b7tre", "J\u00fcng\u00b7ling", "schei\u00b7den", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$.", "VMFIN", "APPR", "ADJA", "NN", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Der, schimmernder Entw\u00fcrfe voll,", "tokens": ["Der", ",", "schim\u00b7mern\u00b7der", "Ent\u00b7w\u00fcr\u00b7fe", "voll", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "$,", "ADJA", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und aus den Armen aller Freuden,", "tokens": ["Und", "aus", "den", "Ar\u00b7men", "al\u00b7ler", "Freu\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Zum Grab entweichen soll?", "tokens": ["Zum", "Grab", "ent\u00b7wei\u00b7chen", "soll", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.35": {"line.1": {"text": "Die drohende Gefahr schwebt' um den edlen Kranken:", "tokens": ["Die", "dro\u00b7hen\u00b7de", "Ge\u00b7fahr", "schwebt'", "um", "den", "ed\u00b7len", "Kran\u00b7ken", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Nun wog Er Ewigkeit und Zeit;", "tokens": ["Nun", "wog", "Er", "E\u00b7wig\u00b7keit", "und", "Zeit", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und Seine Seele war voll w\u00fcrdiger Gedanken,", "tokens": ["Und", "Sei\u00b7ne", "See\u00b7le", "war", "voll", "w\u00fcr\u00b7di\u00b7ger", "Ge\u00b7dan\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VAFIN", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Gedanken der Unsterblichkeit.", "tokens": ["Ge\u00b7dan\u00b7ken", "der", "U\u00b7nsterb\u00b7lich\u00b7keit", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.5": {"text": "Die Hoffnung sah erstaunt, in diesen ernsten Stunden,", "tokens": ["Die", "Hoff\u00b7nung", "sah", "er\u00b7staunt", ",", "in", "die\u00b7sen", "erns\u00b7ten", "Stun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJD", "$,", "APPR", "PDAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Den jungen Weisen ihr entfliehn:", "tokens": ["Den", "jun\u00b7gen", "Wei\u00b7sen", "ihr", "ent\u00b7fliehn", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Die Erde war vor Ihm verschwunden,", "tokens": ["Die", "Er\u00b7de", "war", "vor", "Ihm", "ver\u00b7schwun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "APPR", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Und Himmel war um Ihn.", "tokens": ["Und", "Him\u00b7mel", "war", "um", "Ihn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VAFIN", "APPR", "PPER", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.36": {"line.1": {"text": "Du Mutter unsers Freunds, die vor Ihm hingegangen,", "tokens": ["Du", "Mut\u00b7ter", "un\u00b7sers", "Freunds", ",", "die", "vor", "Ihm", "hin\u00b7ge\u00b7gan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "PPOSAT", "NN", "$,", "PRELS", "APPR", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wo die gekr\u00f6nte Tugend wohnt,", "tokens": ["Wo", "die", "ge\u00b7kr\u00f6n\u00b7te", "Tu\u00b7gend", "wohnt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und sterbend Ihn gelehrt, den Lorbeer zu erlangen,", "tokens": ["Und", "ster\u00b7bend", "Ihn", "ge\u00b7lehrt", ",", "den", "Lor\u00b7beer", "zu", "er\u00b7lan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "PPER", "VVPP", "$,", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der wahren Heldenmuth belohnt:", "tokens": ["Der", "wah\u00b7ren", "Hel\u00b7den\u00b7muth", "be\u00b7lohnt", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wenn du Ihn sterben sahst (den sch\u00f6nen Tod des Weisen", "tokens": ["Wenn", "du", "Ihn", "ster\u00b7ben", "sahst", "(", "den", "sch\u00f6\u00b7nen", "Tod", "des", "Wei\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PPER", "VVINF", "VVFIN", "$(", "ART", "ADJA", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Sehn auch Unsterbliche mit Lust)", "tokens": ["Sehn", "auch", "U\u00b7nsterb\u00b7li\u00b7che", "mit", "Lust", ")"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "NN", "APPR", "NN", "$("], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.7": {"text": "Wie gl\u00fccklich mu\u00dftest du Ihn preisen,", "tokens": ["Wie", "gl\u00fcck\u00b7lich", "mu\u00df\u00b7test", "du", "Ihn", "prei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VMFIN", "PPER", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Den du bewundern mu\u00dft!", "tokens": ["Den", "du", "be\u00b7wun\u00b7dern", "mu\u00dft", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVINF", "VMFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.37": {"line.1": {"text": "Wie brannte nicht dein Herz, als, nach begl\u00fccktem Streite,", "tokens": ["Wie", "brann\u00b7te", "nicht", "dein", "Herz", ",", "als", ",", "nach", "be\u00b7gl\u00fcck\u00b7tem", "Strei\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PTKNEG", "PPOSAT", "NN", "$,", "KOUS", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Dich dieser theure Sohn umfieng,", "tokens": ["Dich", "die\u00b7ser", "theu\u00b7re", "Sohn", "um\u00b7fi\u00b7eng", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PDAT", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Und, selbst unsterblich, nun an einer Mutter Seite", "tokens": ["Und", ",", "selbst", "uns\u00b7terb\u00b7lich", ",", "nun", "an", "ei\u00b7ner", "Mut\u00b7ter", "Sei\u00b7te"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "$,", "ADV", "ADJD", "$,", "ADV", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Durch jauchzende Gerechte gieng?", "tokens": ["Durch", "jauch\u00b7zen\u00b7de", "Ge\u00b7rech\u00b7te", "gieng", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+---+-+", "measure": "dactylic.init"}, "line.5": {"text": "Du segnetest den Tod, der Ihn aus Finsternissen", "tokens": ["Du", "seg\u00b7ne\u00b7test", "den", "Tod", ",", "der", "Ihn", "aus", "Fins\u00b7ter\u00b7nis\u00b7sen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "PRELS", "PPER", "APPR", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und Schlingen lockender Gefahr,", "tokens": ["Und", "Schlin\u00b7gen", "lo\u00b7cken\u00b7der", "Ge\u00b7fahr", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Zu einer bessern Welt entrissen,", "tokens": ["Zu", "ei\u00b7ner", "bes\u00b7sern", "Welt", "ent\u00b7ris\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Die Cronegks w\u00fcrdig war.", "tokens": ["Die", "Cro\u00b7negks", "w\u00fcr\u00b7dig", "war", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.38": {"line.1": {"text": "Sollt ungest\u00fcmer Schmerz des Weisen Grab entweihen,", "tokens": ["Sollt", "un\u00b7ge\u00b7st\u00fc\u00b7mer", "Schmerz", "des", "Wei\u00b7sen", "Grab", "ent\u00b7wei\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADJA", "NN", "ART", "NN", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der zur Unsterblichkeit gelangt?", "tokens": ["Der", "zur", "U\u00b7nsterb\u00b7lich\u00b7keit", "ge\u00b7langt", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "APPRART", "NN", "VVPP", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.3": {"text": "Doch auch die Weisheit wird ein stilles Leid verzeihen,", "tokens": ["Doch", "auch", "die", "Weis\u00b7heit", "wird", "ein", "stil\u00b7les", "Leid", "ver\u00b7zei\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "VAFIN", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Das nicht mit stolzen Thr\u00e4nen prangt.", "tokens": ["Das", "nicht", "mit", "stol\u00b7zen", "Thr\u00e4\u00b7nen", "prangt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PTKNEG", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Verzeih, Unsterblicher, die wehmuthvollen Thr\u00e4nen,", "tokens": ["Ver\u00b7zeih", ",", "U\u00b7nsterb\u00b7li\u00b7cher", ",", "die", "weh\u00b7muth\u00b7vol\u00b7len", "Thr\u00e4\u00b7nen", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADJD", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Die ein geliebter Vater weint!", "tokens": ["Die", "ein", "ge\u00b7lieb\u00b7ter", "Va\u00b7ter", "weint", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Verzeih der Freundschaft z\u00e4rtlich Sehnen", "tokens": ["Ver\u00b7zeih", "der", "Freund\u00b7schaft", "z\u00e4rt\u00b7lich", "Seh\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVIMP", "ART", "NN", "ADJD", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Nach Dir, dem besten Freund!", "tokens": ["Nach", "Dir", ",", "dem", "bes\u00b7ten", "Freund", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "$,", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.39": {"line.1": {"text": "Wir sehn, um Mitternacht, in jene blaue Ferne,", "tokens": ["Wir", "sehn", ",", "um", "Mit\u00b7ter\u00b7nacht", ",", "in", "je\u00b7ne", "blau\u00b7e", "Fer\u00b7ne", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUI", "NN", "$,", "APPR", "PDAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wohin die Tugend Dich erhob:", "tokens": ["Wo\u00b7hin", "die", "Tu\u00b7gend", "Dich", "er\u00b7hob", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wo bist Du? seufzen wir; auf welchem lichten Sterne", "tokens": ["Wo", "bist", "Du", "?", "seuf\u00b7zen", "wir", ";", "auf", "wel\u00b7chem", "lich\u00b7ten", "Ster\u00b7ne"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWAV", "VAFIN", "PPER", "$.", "VVFIN", "PPER", "$.", "APPR", "PWAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Besingst Du nun der Gottheit Lob?", "tokens": ["Be\u00b7singst", "Du", "nun", "der", "Got\u00b7theit", "Lob", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Der Himmel h\u00f6rt entz\u00fcckt die Harmonie der Lieder!", "tokens": ["Der", "Him\u00b7mel", "h\u00f6rt", "ent\u00b7z\u00fcckt", "die", "Har\u00b7mo\u00b7nie", "der", "Lie\u00b7der", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "VVFIN", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Du wirfst noch einen kurzen Blick", "tokens": ["Du", "wirfst", "noch", "ei\u00b7nen", "kur\u00b7zen", "Blick"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Nach unsrer dunkeln Erde nieder,", "tokens": ["Nach", "uns\u00b7rer", "dun\u00b7keln", "Er\u00b7de", "nie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Und f\u00fchlst Dein ganzes Gl\u00fcck.", "tokens": ["Und", "f\u00fchlst", "Dein", "gan\u00b7zes", "Gl\u00fcck", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.40": {"line.1": {"text": "Wir singen Deinen Ruhm, und schildern fernen Tagen", "tokens": ["Wir", "sin\u00b7gen", "Dei\u00b7nen", "Ruhm", ",", "und", "schil\u00b7dern", "fer\u00b7nen", "Ta\u00b7gen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "$,", "KON", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Dein Herz und unsre Freundschaft ab.", "tokens": ["Dein", "Herz", "und", "uns\u00b7re", "Freund\u00b7schaft", "ab", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die Nachwelt m\u00fcss' um Dich aus unsern Liedern klagen!", "tokens": ["Die", "Nach\u00b7welt", "m\u00fcss'", "um", "Dich", "aus", "un\u00b7sern", "Lie\u00b7dern", "kla\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "APPR", "PRF", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Sie streue Blumen auf Dein Grab!", "tokens": ["Sie", "streu\u00b7e", "Blu\u00b7men", "auf", "Dein", "Grab", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wir werden sp\u00e4te noch Dir manche Thr\u00e4ne schenken:", "tokens": ["Wir", "wer\u00b7den", "sp\u00e4\u00b7te", "noch", "Dir", "man\u00b7che", "Thr\u00e4\u00b7ne", "schen\u00b7ken", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVFIN", "ADV", "PPER", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+++-+-+-", "measure": "unknown.measure.septa"}, "line.6": {"text": "Auch wenn wir k\u00fcnftig uns erfreun,", "tokens": ["Auch", "wenn", "wir", "k\u00fcnf\u00b7tig", "uns", "er\u00b7freun", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PPER", "ADJD", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Soll unsers Cronegks Angedenken", "tokens": ["Soll", "un\u00b7sers", "Cro\u00b7negks", "An\u00b7ge\u00b7den\u00b7ken"], "token_info": ["word", "word", "word", "word"], "pos": ["VMFIN", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Uns immer heilig seyn!", "tokens": ["Uns", "im\u00b7mer", "hei\u00b7lig", "seyn", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADJD", "VAINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}}}}