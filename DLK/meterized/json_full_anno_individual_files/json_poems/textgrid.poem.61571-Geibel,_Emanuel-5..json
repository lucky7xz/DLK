{"textgrid.poem.61571": {"metadata": {"author": {"name": "Geibel, Emanuel", "birth": "N.A.", "death": "N.A."}, "title": "5.", "genre": "verse", "period": "N.A.", "pub_year": 1833, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "In diesen Fr\u00fchlingstagen, da genesen", "tokens": ["In", "die\u00b7sen", "Fr\u00fch\u00b7lings\u00b7ta\u00b7gen", ",", "da", "ge\u00b7ne\u00b7sen"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "PDAT", "NN", "$,", "ADV", "VVINF"], "meter": "-+-+-+-++--", "measure": "unknown.measure.penta"}, "line.2": {"text": "Das Herz nicht will vom s\u00fc\u00dfen Sehnsuchtsleid,", "tokens": ["Das", "Herz", "nicht", "will", "vom", "s\u00fc\u00b7\u00dfen", "Sehn\u00b7suchts\u00b7leid", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKNEG", "VMFIN", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Wie spricht, was einst bei Platon ich gelesen,", "tokens": ["Wie", "spricht", ",", "was", "einst", "bei", "Pla\u00b7ton", "ich", "ge\u00b7le\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "$,", "PRELS", "ADV", "APPR", "NE", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Vertraut mich an aus dunkler Fabel Kleid!", "tokens": ["Ver\u00b7traut", "mich", "an", "aus", "dunk\u00b7ler", "Fa\u00b7bel", "Kleid", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "APPR", "APPR", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Geschaffen, schreibt er, ward als Doppelwesen", "tokens": ["Ge\u00b7schaf\u00b7fen", ",", "schreibt", "er", ",", "ward", "als", "Dop\u00b7pel\u00b7we\u00b7sen"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "VVFIN", "PPER", "$,", "VAFIN", "KOUS", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Der Mensch dereinst im Anbeginn der Zeit,", "tokens": ["Der", "Mensch", "de\u00b7reinst", "im", "An\u00b7be\u00b7ginn", "der", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "APPRART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Bis ihn ein Gott, weil er nicht Schuld gemieden,", "tokens": ["Bis", "ihn", "ein", "Gott", ",", "weil", "er", "nicht", "Schuld", "ge\u00b7mie\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ART", "NN", "$,", "KOUS", "PPER", "PTKNEG", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "In seine Teile, Mann und Weib, geschieden.", "tokens": ["In", "sei\u00b7ne", "Tei\u00b7le", ",", "Mann", "und", "Weib", ",", "ge\u00b7schie\u00b7den", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "NN", "KON", "NN", "$,", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Ein heilig R\u00e4tsel deutet mir dies Wort;", "tokens": ["Ein", "hei\u00b7lig", "R\u00e4t\u00b7sel", "deu\u00b7tet", "mir", "dies", "Wort", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "VVFIN", "PPER", "PDS", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Wer f\u00fchlt' es nie, da\u00df Bruchst\u00fcck nur sein Leben,", "tokens": ["Wer", "f\u00fchlt'", "es", "nie", ",", "da\u00df", "Bruchs\u00b7t\u00fcck", "nur", "sein", "Le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "$,", "KOUS", "NN", "ADV", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Ein Ton, nur angeschlagen, zum Akkord", "tokens": ["Ein", "Ton", ",", "nur", "an\u00b7ge\u00b7schla\u00b7gen", ",", "zum", "Ak\u00b7kord"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "$,", "ADV", "VVPP", "$,", "APPRART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Mit seinem Gegenton sich zu verweben?", "tokens": ["Mit", "sei\u00b7nem", "Ge\u00b7gen\u00b7ton", "sich", "zu", "ver\u00b7we\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PRF", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Wir all' sind H\u00e4lften, ach, die fort und fort", "tokens": ["Wir", "all'", "sind", "H\u00e4lf\u00b7ten", ",", "ach", ",", "die", "fort", "und", "fort"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "PIS", "VAFIN", "NN", "$,", "ITJ", "$,", "PRELS", "PTKVZ", "KON", "PTKVZ"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Nach den verlornen Zwillingsh\u00e4lften streben,", "tokens": ["Nach", "den", "ver\u00b7lor\u00b7nen", "Zwil\u00b7lings\u00b7h\u00e4lf\u00b7ten", "stre\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Und dieses Suchens Leid im Weltgetriebe \u2013", "tokens": ["Und", "die\u00b7ses", "Su\u00b7chens", "Leid", "im", "Welt\u00b7ge\u00b7trie\u00b7be", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDAT", "NN", "NN", "APPRART", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Wir hei\u00dfen's Sehnsucht und das Finden Liebe.", "tokens": ["Wir", "hei\u00b7\u00dfen's", "Sehn\u00b7sucht", "und", "das", "Fin\u00b7den", "Lie\u00b7be", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "KON", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "In diesen Fr\u00fchlingstagen, da genesen", "tokens": ["In", "die\u00b7sen", "Fr\u00fch\u00b7lings\u00b7ta\u00b7gen", ",", "da", "ge\u00b7ne\u00b7sen"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "PDAT", "NN", "$,", "ADV", "VVINF"], "meter": "-+-+-+-++--", "measure": "unknown.measure.penta"}, "line.2": {"text": "Das Herz nicht will vom s\u00fc\u00dfen Sehnsuchtsleid,", "tokens": ["Das", "Herz", "nicht", "will", "vom", "s\u00fc\u00b7\u00dfen", "Sehn\u00b7suchts\u00b7leid", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKNEG", "VMFIN", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Wie spricht, was einst bei Platon ich gelesen,", "tokens": ["Wie", "spricht", ",", "was", "einst", "bei", "Pla\u00b7ton", "ich", "ge\u00b7le\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "$,", "PRELS", "ADV", "APPR", "NE", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Vertraut mich an aus dunkler Fabel Kleid!", "tokens": ["Ver\u00b7traut", "mich", "an", "aus", "dunk\u00b7ler", "Fa\u00b7bel", "Kleid", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "APPR", "APPR", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Geschaffen, schreibt er, ward als Doppelwesen", "tokens": ["Ge\u00b7schaf\u00b7fen", ",", "schreibt", "er", ",", "ward", "als", "Dop\u00b7pel\u00b7we\u00b7sen"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "VVFIN", "PPER", "$,", "VAFIN", "KOUS", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Der Mensch dereinst im Anbeginn der Zeit,", "tokens": ["Der", "Mensch", "de\u00b7reinst", "im", "An\u00b7be\u00b7ginn", "der", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "APPRART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Bis ihn ein Gott, weil er nicht Schuld gemieden,", "tokens": ["Bis", "ihn", "ein", "Gott", ",", "weil", "er", "nicht", "Schuld", "ge\u00b7mie\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ART", "NN", "$,", "KOUS", "PPER", "PTKNEG", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "In seine Teile, Mann und Weib, geschieden.", "tokens": ["In", "sei\u00b7ne", "Tei\u00b7le", ",", "Mann", "und", "Weib", ",", "ge\u00b7schie\u00b7den", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "NN", "KON", "NN", "$,", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Ein heilig R\u00e4tsel deutet mir dies Wort;", "tokens": ["Ein", "hei\u00b7lig", "R\u00e4t\u00b7sel", "deu\u00b7tet", "mir", "dies", "Wort", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "VVFIN", "PPER", "PDS", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Wer f\u00fchlt' es nie, da\u00df Bruchst\u00fcck nur sein Leben,", "tokens": ["Wer", "f\u00fchlt'", "es", "nie", ",", "da\u00df", "Bruchs\u00b7t\u00fcck", "nur", "sein", "Le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "$,", "KOUS", "NN", "ADV", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Ein Ton, nur angeschlagen, zum Akkord", "tokens": ["Ein", "Ton", ",", "nur", "an\u00b7ge\u00b7schla\u00b7gen", ",", "zum", "Ak\u00b7kord"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "$,", "ADV", "VVPP", "$,", "APPRART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Mit seinem Gegenton sich zu verweben?", "tokens": ["Mit", "sei\u00b7nem", "Ge\u00b7gen\u00b7ton", "sich", "zu", "ver\u00b7we\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PRF", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Wir all' sind H\u00e4lften, ach, die fort und fort", "tokens": ["Wir", "all'", "sind", "H\u00e4lf\u00b7ten", ",", "ach", ",", "die", "fort", "und", "fort"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "PIS", "VAFIN", "NN", "$,", "ITJ", "$,", "PRELS", "PTKVZ", "KON", "PTKVZ"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Nach den verlornen Zwillingsh\u00e4lften streben,", "tokens": ["Nach", "den", "ver\u00b7lor\u00b7nen", "Zwil\u00b7lings\u00b7h\u00e4lf\u00b7ten", "stre\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Und dieses Suchens Leid im Weltgetriebe \u2013", "tokens": ["Und", "die\u00b7ses", "Su\u00b7chens", "Leid", "im", "Welt\u00b7ge\u00b7trie\u00b7be", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDAT", "NN", "NN", "APPRART", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Wir hei\u00dfen's Sehnsucht und das Finden Liebe.", "tokens": ["Wir", "hei\u00b7\u00dfen's", "Sehn\u00b7sucht", "und", "das", "Fin\u00b7den", "Lie\u00b7be", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "KON", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}}}}