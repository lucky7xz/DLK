{"textgrid.poem.53470": {"metadata": {"author": {"name": "Tucholsky, Kurt", "birth": "N.A.", "death": "N.A."}, "title": "Home, sweet home", "genre": "verse", "period": "N.A.", "pub_year": 1912, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Berliner Muse mit den runden H\u00fcften,", "tokens": ["Ber\u00b7li\u00b7ner", "Mu\u00b7se", "mit", "den", "run\u00b7den", "H\u00fcf\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.2": {"text": "den Tuchgamaschen und dem Samtbarett,", "tokens": ["den", "Tuch\u00b7ga\u00b7ma\u00b7schen", "und", "dem", "Samt\u00b7ba\u00b7rett", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "umgaukle du mich in den staubigen L\u00fcften:", "tokens": ["um\u00b7gauk\u00b7le", "du", "mich", "in", "den", "stau\u00b7bi\u00b7gen", "L\u00fcf\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Komm, G\u00f6ttin, sei mal nett!", "tokens": ["Komm", ",", "G\u00f6t\u00b7tin", ",", "sei", "mal", "nett", "!"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "NN", "$,", "VAFIN", "ADV", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Hier auf dem Rathausturm ists windig, Muse,", "tokens": ["Hier", "auf", "dem", "Rat\u00b7haus\u00b7turm", "ists", "win\u00b7dig", ",", "Mu\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "VAFIN", "ADJD", "$,", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "der kalte Zug rei\u00dft mir die Leier weg \u2013", "tokens": ["der", "kal\u00b7te", "Zug", "rei\u00dft", "mir", "die", "Lei\u00b7er", "weg", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PPER", "ART", "NN", "PTKVZ", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "begleite mich, mein s\u00fc\u00dfes Kind, halt du se:", "tokens": ["be\u00b7glei\u00b7te", "mich", ",", "mein", "s\u00fc\u00b7\u00dfes", "Kind", ",", "halt", "du", "se", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "PPOSAT", "ADJA", "NN", "$,", "VVFIN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-++", "measure": "unknown.measure.hexa"}, "line.4": {"text": "Ich singe so freiweg.", "tokens": ["Ich", "sin\u00b7ge", "so", "frei\u00b7weg", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Da liegt die Stadt \u2013 nur sch\u00f6n bei Regenst\u00fcrmen \u2013", "tokens": ["Da", "liegt", "die", "Stadt", "\u2013", "nur", "sch\u00f6n", "bei", "Re\u00b7gen\u00b7st\u00fcr\u00b7men", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$(", "ADV", "ADJD", "APPR", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "teils an der Panke und teils an der Spree,", "tokens": ["teils", "an", "der", "Pan\u00b7ke", "und", "teils", "an", "der", "Spree", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "KON", "ADV", "APPR", "ART", "NE", "$,"], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.3": {"text": "mit Synagogenkuppeln, Kirchent\u00fcrmen", "tokens": ["mit", "Syn\u00b7a\u00b7go\u00b7gen\u00b7kup\u00b7peln", ",", "Kir\u00b7chen\u00b7t\u00fcr\u00b7men"], "token_info": ["word", "word", "punct", "word"], "pos": ["APPR", "NN", "$,", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "und einem Tanzpaleeh.", "tokens": ["und", "ei\u00b7nem", "Tanz\u00b7pa\u00b7leeh", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Und was da l\u00e4ngs des gr\u00fcnen B\u00e4umewalles", "tokens": ["Und", "was", "da", "l\u00e4ngs", "des", "gr\u00fc\u00b7nen", "B\u00e4u\u00b7me\u00b7wal\u00b7les"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWS", "ADV", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "so g\u00fclden glei\u00dft (ich wei\u00df nicht, ob dus kennst):", "tokens": ["so", "g\u00fcl\u00b7den", "glei\u00dft", "(", "ich", "wei\u00df", "nicht", ",", "ob", "dus", "kennst", ")", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "$(", "PPER", "VVFIN", "PTKNEG", "$,", "KOUS", "PIS", "VVFIN", "$(", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "das ist der Reichstag \u2013 doch es ist nicht alles", "tokens": ["das", "ist", "der", "Reichs\u00b7tag", "\u2013", "doch", "es", "ist", "nicht", "al\u00b7les"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "ART", "NN", "$(", "KON", "PPER", "VAFIN", "PTKNEG", "PIS"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "hienieden Gold, was gl\u00e4nzt.", "tokens": ["hien\u00b7ie\u00b7den", "Gold", ",", "was", "gl\u00e4nzt", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "NN", "$,", "PWS", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "In jener Gegend wohnt die gro\u00dfe Presse \u2013", "tokens": ["In", "je\u00b7ner", "Ge\u00b7gend", "wohnt", "die", "gro\u00b7\u00dfe", "Pres\u00b7se", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "VVFIN", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "sie macht erst unsre Zeit in Wort und Bild:", "tokens": ["sie", "macht", "erst", "uns\u00b7re", "Zeit", "in", "Wort", "und", "Bild", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PPOSAT", "NN", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "dort s\u00e4ttigt der Berliner sein Interesse,", "tokens": ["dort", "s\u00e4t\u00b7tigt", "der", "Ber\u00b7li\u00b7ner", "sein", "In\u00b7ter\u00b7es\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "PPOSAT", "NN", "$,"], "meter": "-+--+---+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "nerv\u00f6s und injebildt.", "tokens": ["ner\u00b7v\u00f6s", "und", "in\u00b7je\u00b7bildt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "KON", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Da hinten rechts, in jener dunstigen Weite,", "tokens": ["Da", "hin\u00b7ten", "rechts", ",", "in", "je\u00b7ner", "duns\u00b7ti\u00b7gen", "Wei\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "$,", "APPR", "PDAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "liegt der Kom\u00f6dienh\u00e4user dichter Hauf \u2013", "tokens": ["liegt", "der", "Ko\u00b7m\u00f6\u00b7di\u00b7en\u00b7h\u00e4u\u00b7ser", "dich\u00b7ter", "Hauf", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ADJA", "NN", "$("], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.3": {"text": "und gehn sie alle, alle langsam pleite:", "tokens": ["und", "gehn", "sie", "al\u00b7le", ",", "al\u00b7le", "lang\u00b7sam", "plei\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PIS", "$,", "PIS", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "dann macht man neue auf.", "tokens": ["dann", "macht", "man", "neu\u00b7e", "auf", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "ADJA", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Und, siehst du, hier verbringt man so sein Leben.", "tokens": ["Und", ",", "siehst", "du", ",", "hier", "ver\u00b7bringt", "man", "so", "sein", "Le\u00b7ben", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "VVFIN", "PPER", "$,", "ADV", "VVFIN", "PIS", "ADV", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Da drau\u00dfen rauschen W\u00e4lder, Wolken ziehn \u2013", "tokens": ["Da", "drau\u00b7\u00dfen", "rau\u00b7schen", "W\u00e4l\u00b7der", ",", "Wol\u00b7ken", "ziehn", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADJA", "NN", "$,", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Wir passen auf, was sie f\u00fcr Possen geben,", "tokens": ["Wir", "pas\u00b7sen", "auf", ",", "was", "sie", "f\u00fcr", "Pos\u00b7sen", "ge\u00b7ben", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKVZ", "$,", "PRELS", "PPER", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "und wie sie vor den Uniformen beben! \u2013", "tokens": ["und", "wie", "sie", "vor", "den", "U\u00b7nif\u00b7or\u00b7men", "be\u00b7ben", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "PWAV", "PPER", "APPR", "ART", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "O du mein Heimatland, du mein Berlin!", "tokens": ["O", "du", "mein", "Hei\u00b7mat\u00b7land", ",", "du", "mein", "Ber\u00b7lin", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NE", "PPOSAT", "NN", "$,", "PPER", "PPOSAT", "NE", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.8": {"line.1": {"text": "Berliner Muse mit den runden H\u00fcften,", "tokens": ["Ber\u00b7li\u00b7ner", "Mu\u00b7se", "mit", "den", "run\u00b7den", "H\u00fcf\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.2": {"text": "den Tuchgamaschen und dem Samtbarett,", "tokens": ["den", "Tuch\u00b7ga\u00b7ma\u00b7schen", "und", "dem", "Samt\u00b7ba\u00b7rett", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "umgaukle du mich in den staubigen L\u00fcften:", "tokens": ["um\u00b7gauk\u00b7le", "du", "mich", "in", "den", "stau\u00b7bi\u00b7gen", "L\u00fcf\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Komm, G\u00f6ttin, sei mal nett!", "tokens": ["Komm", ",", "G\u00f6t\u00b7tin", ",", "sei", "mal", "nett", "!"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "NN", "$,", "VAFIN", "ADV", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Hier auf dem Rathausturm ists windig, Muse,", "tokens": ["Hier", "auf", "dem", "Rat\u00b7haus\u00b7turm", "ists", "win\u00b7dig", ",", "Mu\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "VAFIN", "ADJD", "$,", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "der kalte Zug rei\u00dft mir die Leier weg \u2013", "tokens": ["der", "kal\u00b7te", "Zug", "rei\u00dft", "mir", "die", "Lei\u00b7er", "weg", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PPER", "ART", "NN", "PTKVZ", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "begleite mich, mein s\u00fc\u00dfes Kind, halt du se:", "tokens": ["be\u00b7glei\u00b7te", "mich", ",", "mein", "s\u00fc\u00b7\u00dfes", "Kind", ",", "halt", "du", "se", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "PPOSAT", "ADJA", "NN", "$,", "VVFIN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-++", "measure": "unknown.measure.hexa"}, "line.4": {"text": "Ich singe so freiweg.", "tokens": ["Ich", "sin\u00b7ge", "so", "frei\u00b7weg", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "Da liegt die Stadt \u2013 nur sch\u00f6n bei Regenst\u00fcrmen \u2013", "tokens": ["Da", "liegt", "die", "Stadt", "\u2013", "nur", "sch\u00f6n", "bei", "Re\u00b7gen\u00b7st\u00fcr\u00b7men", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$(", "ADV", "ADJD", "APPR", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "teils an der Panke und teils an der Spree,", "tokens": ["teils", "an", "der", "Pan\u00b7ke", "und", "teils", "an", "der", "Spree", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "KON", "ADV", "APPR", "ART", "NE", "$,"], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.3": {"text": "mit Synagogenkuppeln, Kirchent\u00fcrmen", "tokens": ["mit", "Syn\u00b7a\u00b7go\u00b7gen\u00b7kup\u00b7peln", ",", "Kir\u00b7chen\u00b7t\u00fcr\u00b7men"], "token_info": ["word", "word", "punct", "word"], "pos": ["APPR", "NN", "$,", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "und einem Tanzpaleeh.", "tokens": ["und", "ei\u00b7nem", "Tanz\u00b7pa\u00b7leeh", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "Und was da l\u00e4ngs des gr\u00fcnen B\u00e4umewalles", "tokens": ["Und", "was", "da", "l\u00e4ngs", "des", "gr\u00fc\u00b7nen", "B\u00e4u\u00b7me\u00b7wal\u00b7les"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWS", "ADV", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "so g\u00fclden glei\u00dft (ich wei\u00df nicht, ob dus kennst):", "tokens": ["so", "g\u00fcl\u00b7den", "glei\u00dft", "(", "ich", "wei\u00df", "nicht", ",", "ob", "dus", "kennst", ")", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "$(", "PPER", "VVFIN", "PTKNEG", "$,", "KOUS", "PIS", "VVFIN", "$(", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "das ist der Reichstag \u2013 doch es ist nicht alles", "tokens": ["das", "ist", "der", "Reichs\u00b7tag", "\u2013", "doch", "es", "ist", "nicht", "al\u00b7les"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "ART", "NN", "$(", "KON", "PPER", "VAFIN", "PTKNEG", "PIS"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "hienieden Gold, was gl\u00e4nzt.", "tokens": ["hien\u00b7ie\u00b7den", "Gold", ",", "was", "gl\u00e4nzt", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "NN", "$,", "PWS", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "In jener Gegend wohnt die gro\u00dfe Presse \u2013", "tokens": ["In", "je\u00b7ner", "Ge\u00b7gend", "wohnt", "die", "gro\u00b7\u00dfe", "Pres\u00b7se", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "VVFIN", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "sie macht erst unsre Zeit in Wort und Bild:", "tokens": ["sie", "macht", "erst", "uns\u00b7re", "Zeit", "in", "Wort", "und", "Bild", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PPOSAT", "NN", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "dort s\u00e4ttigt der Berliner sein Interesse,", "tokens": ["dort", "s\u00e4t\u00b7tigt", "der", "Ber\u00b7li\u00b7ner", "sein", "In\u00b7ter\u00b7es\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "PPOSAT", "NN", "$,"], "meter": "-+--+---+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "nerv\u00f6s und injebildt.", "tokens": ["ner\u00b7v\u00f6s", "und", "in\u00b7je\u00b7bildt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "KON", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.13": {"line.1": {"text": "Da hinten rechts, in jener dunstigen Weite,", "tokens": ["Da", "hin\u00b7ten", "rechts", ",", "in", "je\u00b7ner", "duns\u00b7ti\u00b7gen", "Wei\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "$,", "APPR", "PDAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "liegt der Kom\u00f6dienh\u00e4user dichter Hauf \u2013", "tokens": ["liegt", "der", "Ko\u00b7m\u00f6\u00b7di\u00b7en\u00b7h\u00e4u\u00b7ser", "dich\u00b7ter", "Hauf", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ADJA", "NN", "$("], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.3": {"text": "und gehn sie alle, alle langsam pleite:", "tokens": ["und", "gehn", "sie", "al\u00b7le", ",", "al\u00b7le", "lang\u00b7sam", "plei\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PIS", "$,", "PIS", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "dann macht man neue auf.", "tokens": ["dann", "macht", "man", "neu\u00b7e", "auf", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "ADJA", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.14": {"line.1": {"text": "Und, siehst du, hier verbringt man so sein Leben.", "tokens": ["Und", ",", "siehst", "du", ",", "hier", "ver\u00b7bringt", "man", "so", "sein", "Le\u00b7ben", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "VVFIN", "PPER", "$,", "ADV", "VVFIN", "PIS", "ADV", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Da drau\u00dfen rauschen W\u00e4lder, Wolken ziehn \u2013", "tokens": ["Da", "drau\u00b7\u00dfen", "rau\u00b7schen", "W\u00e4l\u00b7der", ",", "Wol\u00b7ken", "ziehn", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADJA", "NN", "$,", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Wir passen auf, was sie f\u00fcr Possen geben,", "tokens": ["Wir", "pas\u00b7sen", "auf", ",", "was", "sie", "f\u00fcr", "Pos\u00b7sen", "ge\u00b7ben", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKVZ", "$,", "PRELS", "PPER", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "und wie sie vor den Uniformen beben! \u2013", "tokens": ["und", "wie", "sie", "vor", "den", "U\u00b7nif\u00b7or\u00b7men", "be\u00b7ben", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "PWAV", "PPER", "APPR", "ART", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "O du mein Heimatland, du mein Berlin!", "tokens": ["O", "du", "mein", "Hei\u00b7mat\u00b7land", ",", "du", "mein", "Ber\u00b7lin", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NE", "PPOSAT", "NN", "$,", "PPER", "PPOSAT", "NE", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}}}}