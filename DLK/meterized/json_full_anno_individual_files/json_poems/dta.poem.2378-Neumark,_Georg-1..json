{"dta.poem.2378": {"metadata": {"author": {"name": "Neumark, Georg", "birth": "N.A.", "death": "N.A."}, "title": "1.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1652", "urn": "urn:nbn:de:kobv:b4-20428-0", "language": ["de:0.99"], "booktitle": "Neumark, Georg: Poetisch- und Musikalisches Lustw\u00e4ldchen. Hamburg, 1652."}, "poem": {"stanza.1": {"line.1": {"text": "Thyrsis gieng in tieffen Sinnen/", "tokens": ["Thyr\u00b7sis", "gieng", "in", "tief\u00b7fen", "Sin\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPR", "ADJA", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und bedachte mancherley/", "tokens": ["Und", "be\u00b7dach\u00b7te", "man\u00b7cher\u00b7ley", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Bi\u00df ", "tokens": ["Bi\u00df"], "token_info": ["word"], "pos": ["APPR"], "meter": "+", "measure": "single.up"}, "line.4": {"text": "Reitzender ", "tokens": ["Reit\u00b7zen\u00b7der"], "token_info": ["word"], "pos": ["NN"], "meter": "+--", "measure": "dactylic.init"}, "line.5": {"text": "Lie\u00df sein Seitenspiel ihm bringen/", "tokens": ["Lie\u00df", "sein", "Sei\u00b7ten\u00b7spiel", "ihm", "brin\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "PPER", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Und fieng also an zu singen:", "tokens": ["Und", "fi\u00b7eng", "al\u00b7so", "an", "zu", "sin\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "PTKVZ", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Hilff mir nun du mein getreuer/", "tokens": ["Hilff", "mir", "nun", "du", "mein", "ge\u00b7treu\u00b7er", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "PPER", "PPOSAT", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Du mein \u00e4dler ", "tokens": ["Du", "mein", "\u00e4d\u00b7ler"], "token_info": ["word", "word", "word"], "pos": ["PPER", "PPOSAT", "ADJA"], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "Und auch du mein Sinnerfreuer/", "tokens": ["Und", "auch", "du", "mein", "Sin\u00b7ner\u00b7freu\u00b7er", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PPER", "PPOSAT", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Teutschgesinnter Sylvius/", "tokens": ["Teutschge\u00b7sinn\u00b7ter", "Syl\u00b7vius", "/"], "token_info": ["word", "word", "punct"], "pos": ["NE", "NE", "$("], "meter": "-+-+-", "measure": "iambic.di"}, "line.5": {"text": "Die ihr St\u00fckke meines Hertzens/", "tokens": ["Die", "ihr", "St\u00fck\u00b7ke", "mei\u00b7nes", "Hert\u00b7zens", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "PPOSAT", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Und Mittr\u00e4ger meines Schmertzens.", "tokens": ["Und", "Mit\u00b7tr\u00e4\u00b7ger", "mei\u00b7nes", "Schmert\u00b7zens", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Die ihr bey den ", "tokens": ["Die", "ihr", "bey", "den"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "PPER", "APPR", "ART"], "meter": "+-+-", "measure": "trochaic.di"}, "line.2": {"text": "Dort am \u00e4dlen ", "tokens": ["Dort", "am", "\u00e4d\u00b7len"], "token_info": ["word", "word", "word"], "pos": ["ADV", "APPRART", "ADJA"], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "Eure tiefgesinnte Sinnen", "tokens": ["Eu\u00b7re", "tief\u00b7ge\u00b7sinn\u00b7te", "Sin\u00b7nen"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Sch\u00e4rfet sonder Uberdru\u00df", "tokens": ["Sch\u00e4r\u00b7fet", "son\u00b7der", "U\u00b7berd\u00b7ru\u00df"], "token_info": ["word", "word", "word"], "pos": ["NE", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Last uns doch ein Liedchen h\u00f6ren/", "tokens": ["Last", "uns", "doch", "ein", "Lied\u00b7chen", "h\u00f6\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ART", "NN", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Herren Floridan zu Ehren.", "tokens": ["Her\u00b7ren", "Flo\u00b7ri\u00b7dan", "zu", "Eh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "APPR", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Denn hier wil mir nichts von ", "tokens": ["Denn", "hier", "wil", "mir", "nichts", "von"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VMFIN", "PPER", "PIS", "APPR"], "meter": "--+-+-", "measure": "anapaest.init"}, "line.2": {"text": "Nichtes wil mir t\u00fcchtig gehn/", "tokens": ["Nich\u00b7tes", "wil", "mir", "t\u00fcch\u00b7tig", "gehn", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "PPER", "ADJD", "VVINF", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Weil ich mu\u00df im finstren Schatten/", "tokens": ["Weil", "ich", "mu\u00df", "im", "finst\u00b7ren", "Schat\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VMFIN", "APPRART", "ADJA", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Weit von meinem Pyndus stehn;", "tokens": ["Weit", "von", "mei\u00b7nem", "Pyn\u00b7dus", "stehn", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "PPOSAT", "NE", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Ich sitz\u2019 als im dikken Hayne/", "tokens": ["Ich", "sitz'", "als", "im", "dik\u00b7ken", "Hay\u00b7ne", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KOKOM", "APPRART", "ADJA", "NN", "$("], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Fast wie wer' ich selbst nicht meine.", "tokens": ["Fast", "wie", "wer'", "ich", "selbst", "nicht", "mei\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "VAFIN", "PPER", "ADV", "PTKNEG", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Was mich innerlich benaget/", "tokens": ["Was", "mich", "in\u00b7ner\u00b7lich", "be\u00b7na\u00b7get", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADJD", "VVFIN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Was f\u00fcr schwartzer Uberdru\u00df", "tokens": ["Was", "f\u00fcr", "schwart\u00b7zer", "U\u00b7berd\u00b7ru\u00df"], "token_info": ["word", "word", "word", "word"], "pos": ["PWS", "APPR", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Mein aufrichtigs Hertze plaget/", "tokens": ["Mein", "auf\u00b7rich\u00b7tigs", "Hert\u00b7ze", "pla\u00b7get", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVFIN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Weist-nur-du mein Tytirus.", "tokens": ["Weist\u00b7\u00b7nur\u00b7du", "mein", "Ty\u00b7ti\u00b7rus", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "PPOSAT", "NN", "$."], "meter": "+-+-+--", "measure": "unknown.measure.tri"}, "line.5": {"text": "Aber thu mir diesen ", "tokens": ["A\u00b7ber", "thu", "mir", "die\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "PDAT"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.6": {"text": "Sage nichts von Karitillen.", "tokens": ["Sa\u00b7ge", "nichts", "von", "Ka\u00b7ri\u00b7til\u00b7len", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PIS", "APPR", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Doch ich setz\u2019 es an die Seiten/", "tokens": ["Doch", "ich", "setz'", "es", "an", "die", "Sei\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPER", "APPR", "ART", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Was mich nun betr\u00fcbet macht/", "tokens": ["Was", "mich", "nun", "be\u00b7tr\u00fc\u00b7bet", "macht", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "VVFIN", "VVFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wil auf die Begebenheiten/", "tokens": ["Wil", "auf", "die", "Be\u00b7ge\u00b7ben\u00b7hei\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "APPR", "ART", "NN", "$("], "meter": "+---+-+-", "measure": "dactylic.init"}, "line.4": {"text": "Nur alleine sein bedacht/", "tokens": ["Nur", "al\u00b7lei\u00b7ne", "sein", "be\u00b7dacht", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPOSAT", "VVPP", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Wie unl\u00e4ngst aus unsrem Orden", "tokens": ["Wie", "un\u00b7l\u00e4ngst", "aus", "uns\u00b7rem", "Or\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "ADJD", "APPR", "PPOSAT", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Floridan sey Breutgam worden.", "tokens": ["Flo\u00b7ri\u00b7dan", "sey", "Breut\u00b7gam", "wor\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "NE", "VAPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Manches Jahr ist schon vergangen/", "tokens": ["Man\u00b7ches", "Jahr", "ist", "schon", "ver\u00b7gan\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "ADV", "VVPP", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Mit Hertzsehnlichem ", "tokens": ["Mit", "Hertz\u00b7sehn\u00b7li\u00b7chem"], "token_info": ["word", "word"], "pos": ["APPR", "NN"], "meter": "-++--", "measure": "unknown.measure.di"}, "line.3": {"text": "Ist gestiegen ", "tokens": ["Ist", "ge\u00b7stie\u00b7gen"], "token_info": ["word", "word"], "pos": ["VAFIN", "VVPP"], "meter": "+-+-", "measure": "trochaic.di"}, "line.4": {"text": "Da\u00df ", "tokens": ["Da\u00df"], "token_info": ["word"], "pos": ["KOUS"], "meter": "+", "measure": "single.up"}, "line.5": {"text": "Hat erreicht Olympuszinnen.", "tokens": ["Hat", "er\u00b7reicht", "O\u00b7lym\u00b7pus\u00b7zin\u00b7nen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "VVPP", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Jener weltbekandten ", "tokens": ["Je\u00b7ner", "welt\u00b7be\u00b7kand\u00b7ten"], "token_info": ["word", "word"], "pos": ["PDAT", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "In dem grossen ", "tokens": ["In", "dem", "gros\u00b7sen"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ART", "ADJA"], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "Und den H\u00fcrten an dem Rheine", "tokens": ["Und", "den", "H\u00fcr\u00b7ten", "an", "dem", "Rhei\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "APPR", "ART", "NE"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Bleibt sein sch\u00f6ner Geist bekandt/", "tokens": ["Bleibt", "sein", "sch\u00f6\u00b7ner", "Geist", "be\u00b7kandt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "ADJA", "NN", "ADJD", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Sie empfunden grosse Freuden", "tokens": ["Sie", "emp\u00b7fun\u00b7den", "gros\u00b7se", "Freu\u00b7den"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVPP", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Nur bey ", "tokens": ["Nur", "bey"], "token_info": ["word", "word"], "pos": ["ADV", "APPR"], "meter": "+-", "measure": "trochaic.single"}}, "stanza.9": {"line.1": {"text": "Da/ wo reichlich sich ergossen/", "tokens": ["Da", "/", "wo", "reich\u00b7lich", "sich", "er\u00b7gos\u00b7sen", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$(", "PWAV", "ADJD", "PRF", "VVPP", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Meines ", "tokens": ["Mei\u00b7nes"], "token_info": ["word"], "pos": ["PPOSAT"], "meter": "+-", "measure": "trochaic.single"}, "line.3": {"text": "Da wo l\u00f6blich aufgesprossen/", "tokens": ["Da", "wo", "l\u00f6b\u00b7lich", "auf\u00b7ge\u00b7spros\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PWAV", "ADJD", "VVPP", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Der ber\u00fchmte Heinsius/", "tokens": ["Der", "be\u00b7r\u00fchm\u00b7te", "Hein\u00b7si\u00b7us", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NE", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Da auch wo die ", "tokens": ["Da", "auch", "wo", "die"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ADV", "PWAV", "ART"], "meter": "-+-+", "measure": "iambic.di"}, "line.6": {"text": "Floridanen man wol kennet.", "tokens": ["Flo\u00b7ri\u00b7da\u00b7nen", "man", "wol", "ken\u00b7net", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ADV", "VVFIN", "$."], "meter": "+-+--++-", "measure": "trochaic.tetra.relaxed"}}, "stanza.10": {"line.1": {"text": "Wenn Er etwan in den Feldern/", "tokens": ["Wenn", "Er", "et\u00b7wan", "in", "den", "Fel\u00b7dern", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "APPR", "ART", "NN", "$("], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Bey den H\u00fcrten in dem Gras/", "tokens": ["Bey", "den", "H\u00fcr\u00b7ten", "in", "dem", "Gras", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "ART", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "der in den krausen ", "tokens": ["der", "in", "den", "krau\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "APPR", "ART", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.4": {"text": "Bey den satten ", "tokens": ["Bey", "den", "sat\u00b7ten"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ART", "ADJA"], "meter": "+-+-", "measure": "trochaic.di"}, "line.5": {"text": "Sang ", "tokens": ["Sang"], "token_info": ["word"], "pos": ["NN"], "meter": "+", "measure": "single.up"}, "line.6": {"text": "In ", "tokens": ["In"], "token_info": ["word"], "pos": ["APPR"], "meter": "-", "measure": "single.down"}}, "stanza.11": {"line.1": {"text": "Vater Foebus deine Treue/", "tokens": ["Va\u00b7ter", "Foe\u00b7bus", "dei\u00b7ne", "Treu\u00b7e", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "PPOSAT", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Macht da\u00df ich mein ", "tokens": ["Macht", "da\u00df", "ich", "mein"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "KOUS", "PPER", "PPOSAT"], "meter": "+--+", "measure": "iambic.di.chol"}, "line.3": {"text": "Zu verlassen fast nicht scheue;", "tokens": ["Zu", "ver\u00b7las\u00b7sen", "fast", "nicht", "scheu\u00b7e", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "ADV", "PTKNEG", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Dein geliebtes Musenband", "tokens": ["Dein", "ge\u00b7lieb\u00b7tes", "Mu\u00b7sen\u00b7band"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "F\u00fchret mich zu solchen dingen/", "tokens": ["F\u00fch\u00b7ret", "mich", "zu", "sol\u00b7chen", "din\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "PIAT", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "So mir nichts als Freude bringen.", "tokens": ["So", "mir", "nichts", "als", "Freu\u00b7de", "brin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "PIS", "KOKOM", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Weg mit solchem der nur lieget", "tokens": ["Weg", "mit", "sol\u00b7chem", "der", "nur", "lie\u00b7get"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "PIAT", "ART", "ADV", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Auf der faulen Schl\u00fcngelbank!", "tokens": ["Auf", "der", "fau\u00b7len", "Schl\u00fcn\u00b7gel\u00b7bank", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wer sich in die Fremde f\u00fcget", "tokens": ["Wer", "sich", "in", "die", "Frem\u00b7de", "f\u00fc\u00b7get"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "PRF", "APPR", "ART", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Der verdienet Lob und Dank.\n(Doch nicht der gleich einem Prasser/", "tokens": ["Der", "ver\u00b7die\u00b7net", "Lob", "und", "Dank", ".", "(", "Doch", "nicht", "der", "gleich", "ei\u00b7nem", "Pras\u00b7ser", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "NN", "KON", "NN", "$.", "$(", "KON", "PTKNEG", "ART", "ADV", "ART", "NN", "$("], "meter": "+-+-+-+-+--+-+-", "measure": "trochaic.septa.relaxed"}, "line.5": {"text": "Sein Verm\u00f6gen macht zu Wasser.)", "tokens": ["Sein", "Ver\u00b7m\u00f6\u00b7gen", "macht", "zu", "Was\u00b7ser", ".", ")"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "APPR", "NN", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Viele zwar sind der Gedanken/", "tokens": ["Vie\u00b7le", "zwar", "sind", "der", "Ge\u00b7dan\u00b7ken", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "ADV", "VAFIN", "ART", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Meinen wenn in gutem Muht'/", "tokens": ["Mei\u00b7nen", "wenn", "in", "gu\u00b7tem", "Muht'", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KOUS", "APPR", "ADJA", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ausser ihres ", "tokens": ["Aus\u00b7ser", "ih\u00b7res"], "token_info": ["word", "word"], "pos": ["APPR", "PPOSAT"], "meter": "+-+-", "measure": "trochaic.di"}, "line.4": {"text": "Durchgebracht ihr Geld und Gut", "tokens": ["Durch\u00b7ge\u00b7bracht", "ihr", "Geld", "und", "Gut"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "PPOSAT", "NN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Da\u00df Sie schon sind kl\u00fcger worden/", "tokens": ["Da\u00df", "Sie", "schon", "sind", "kl\u00fc\u00b7ger", "wor\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VAFIN", "ADJD", "VAPP", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "Es gilt meinen besten H\u00e4mmel/", "tokens": ["Es", "gilt", "mei\u00b7nen", "bes\u00b7ten", "H\u00e4m\u00b7mel", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "ADJA", "NN", "$("], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Gib nur einem Bauren Geld", "tokens": ["Gib", "nur", "ei\u00b7nem", "Bau\u00b7ren", "Geld"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVIMP", "ADV", "ART", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Der kaum wei\u00df was Disch und Schemmel", "tokens": ["Der", "kaum", "wei\u00df", "was", "Disch", "und", "Schem\u00b7mel"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "VVFIN", "PIS", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wo Ers nicht bringt in die Welt?", "tokens": ["Wo", "Ers", "nicht", "bringt", "in", "die", "Welt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "PTKNEG", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.5": {"text": "La\u00df ihn nur fein pr\u00e4chtig putzen", "tokens": ["La\u00df", "ihn", "nur", "fein", "pr\u00e4ch\u00b7tig", "put\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVIMP", "PPER", "ADV", "ADJD", "ADJD", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Er wird eben auch so stutzen.", "tokens": ["Er", "wird", "e\u00b7ben", "auch", "so", "stut\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "ADV", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.15": {"line.1": {"text": "Dr\u00fcm la\u00df mich von diesem ", "tokens": ["Dr\u00fcm", "la\u00df", "mich", "von", "die\u00b7sem"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVIMP", "PPER", "APPR", "PDAT"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Deinen schnellen Pegasus", "tokens": ["Dei\u00b7nen", "schnel\u00b7len", "Pe\u00b7ga\u00b7sus"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Setzen \u00fcber eine Wolke/", "tokens": ["Set\u00b7zen", "\u00fc\u00b7ber", "ei\u00b7ne", "Wol\u00b7ke", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Da mir niemand schaden mu\u00df.", "tokens": ["Da", "mir", "nie\u00b7mand", "scha\u00b7den", "mu\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIS", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Kr\u00f6hne mich/ mich deinen H\u00fcrten/", "tokens": ["Kr\u00f6h\u00b7ne", "mich", "/", "mich", "dei\u00b7nen", "H\u00fcr\u00b7ten", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "$(", "PPER", "PPOSAT", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Foebus mit stets gr\u00fcnen Myreen.", "tokens": ["Foe\u00b7bus", "mit", "stets", "gr\u00fc\u00b7nen", "My\u00b7re\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ADV", "ADJA", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.16": {"line.1": {"text": "Solcher massen war gesonnen/", "tokens": ["Sol\u00b7cher", "mas\u00b7sen", "war", "ge\u00b7son\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "VVPP", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Der ber\u00fchmte Floridan/", "tokens": ["Der", "be\u00b7r\u00fchm\u00b7te", "Flo\u00b7ri\u00b7dan", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df ihm lieber jener Bronnen/", "tokens": ["Da\u00df", "ihm", "lie\u00b7ber", "je\u00b7ner", "Bron\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PDAT", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Der aus Ossens Klippen rann/", "tokens": ["Der", "aus", "Os\u00b7sens", "Klip\u00b7pen", "rann", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "NE", "NN", "VVFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Als ", "tokens": ["Als"], "token_info": ["word"], "pos": ["KOUS"], "meter": "+", "measure": "single.up"}, "line.6": {"text": "Oder Jdens ", "tokens": ["O\u00b7der", "Jdens"], "token_info": ["word", "word"], "pos": ["KON", "NN"], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.17": {"line.1": {"text": "Endlich sagt' Er diese Worte:", "tokens": ["End\u00b7lich", "sagt'", "Er", "die\u00b7se", "Wor\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PDAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wie? soll ich die Vaterstadt/", "tokens": ["Wie", "?", "soll", "ich", "die", "Va\u00b7ter\u00b7stadt", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$.", "VMFIN", "PPER", "ART", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Mein geliebtes Dantzig dorte", "tokens": ["Mein", "ge\u00b7lieb\u00b7tes", "Dant\u00b7zig", "dor\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NE", "NE"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Welches mich gebohren hat/", "tokens": ["Wel\u00b7ches", "mich", "ge\u00b7boh\u00b7ren", "hat", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVPP", "VAFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Gleichsam wie und ankbar fliehen?", "tokens": ["Gleich\u00b7sam", "wie", "und", "ank\u00b7bar", "flie\u00b7hen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "KOKOM", "KON", "ADJD", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Nein. Ich wil von hinnen ziehen.", "tokens": ["Nein", ".", "Ich", "wil", "von", "hin\u00b7nen", "zie\u00b7hen", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$.", "PPER", "VMFIN", "APPR", "ADV", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.18": {"line.1": {"text": "Gute Nacht ihr lieben Br\u00fcder/", "tokens": ["Gu\u00b7te", "Nacht", "ihr", "lie\u00b7ben", "Br\u00fc\u00b7der", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "PPOSAT", "ADJA", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Gute Nacht mein' Herde du/", "tokens": ["Gu\u00b7te", "Nacht", "mein'", "Her\u00b7de", "du", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "PPOSAT", "NN", "PPER", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Gott weis ob wir uns sehn wieder/", "tokens": ["Gott", "weis", "ob", "wir", "uns", "sehn", "wie\u00b7der", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKVZ", "KOUS", "PPER", "PPER", "VVFIN", "ADV", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Lebet stets im Fried' und Ruh;\n\u00e4dles Teutschland gr\u00fcne/ bl\u00fche/", "tokens": ["Le\u00b7bet", "stets", "im", "Fried'", "und", "Ruh", ";", "\u00e4d\u00b7les", "Teutschland", "gr\u00fc\u00b7ne", "/", "bl\u00fc\u00b7he", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["VVFIN", "ADV", "APPRART", "NN", "KON", "NN", "$.", "ADJA", "NN", "VVFIN", "$(", "VVFIN", "$("], "meter": "+-+-+-+--++-+-", "measure": "trochaic.septa.relaxed"}, "line.5": {"text": "Leb ohn' alle Kriegesm\u00fche.", "tokens": ["Leb", "ohn'", "al\u00b7le", "Krie\u00b7ges\u00b7m\u00fc\u00b7he", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVIMP", "APPR", "PIAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.19": {"line.1": {"text": "Also zog ", "tokens": ["Al\u00b7so", "zog"], "token_info": ["word", "word"], "pos": ["ADV", "VVFIN"], "meter": "+-+", "measure": "trochaic.di"}, "line.2": {"text": "W\u00fcnschet' allen gute Zeit/", "tokens": ["W\u00fcn\u00b7schet'", "al\u00b7len", "gu\u00b7te", "Zeit", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "ADJA", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "So ihn mit betr\u00fcbten Sinnen", "tokens": ["So", "ihn", "mit", "be\u00b7tr\u00fcb\u00b7ten", "Sin\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "PPER", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und mit schwerem Hertzeleid'", "tokens": ["Und", "mit", "schwe\u00b7rem", "Hert\u00b7ze\u00b7leid'"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPR", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Als den Redlichen wegliessen/", "tokens": ["Als", "den", "Red\u00b7li\u00b7chen", "weg\u00b7lies\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "VVPP", "$("], "meter": "+-+--++-", "measure": "trochaic.tetra.relaxed"}, "line.6": {"text": "Und getreu zu bleiben hiessen.", "tokens": ["Und", "ge\u00b7treu", "zu", "blei\u00b7ben", "hies\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.20": {"line.1": {"text": "Kaum war Er nach Hause kommen/", "tokens": ["Kaum", "war", "Er", "nach", "Hau\u00b7se", "kom\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "APPR", "NN", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Als Neptun der M\u00e4chtige/", "tokens": ["Als", "Nep\u00b7tun", "der", "M\u00e4ch\u00b7ti\u00b7ge", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "ART", "NN", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Diesen Floridan vernommen/", "tokens": ["Die\u00b7sen", "Flo\u00b7ri\u00b7dan", "ver\u00b7nom\u00b7men", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["PDAT", "NN", "VVPP", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Aus der gr\u00fcnen Oostensee/", "tokens": ["Aus", "der", "gr\u00fc\u00b7nen", "O\u00b7os\u00b7ten\u00b7see", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$("], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.5": {"text": "Als ", "tokens": ["Als"], "token_info": ["word"], "pos": ["KOUS"], "meter": "+", "measure": "single.up"}, "line.6": {"text": "Jhn am ", "tokens": ["Jhn", "am"], "token_info": ["word", "word"], "pos": ["PPER", "APPRART"], "meter": "+-", "measure": "trochaic.single"}}, "stanza.21": {"line.1": {"text": "Mit dem dreygespitzten Skekken/", "tokens": ["Mit", "dem", "drey\u00b7ge\u00b7spitz\u00b7ten", "Skek\u00b7ken", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Schlug er in das blaue ", "tokens": ["Schlug", "er", "in", "das", "blau\u00b7e"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "APPR", "ART", "ADJA"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Bald von allen ", "tokens": ["Bald", "von", "al\u00b7len"], "token_info": ["word", "word", "word"], "pos": ["ADV", "APPR", "PIAT"], "meter": "+-+-", "measure": "trochaic.di"}, "line.4": {"text": "Stellten sich rings \u00fcm ihn her", "tokens": ["Stell\u00b7ten", "sich", "rings", "\u00fcm", "ihn", "her"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PRF", "ADV", "VVFIN", "PPER", "APZR"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.5": {"text": "Die halbfeuchte Najadinnen/", "tokens": ["Die", "halb\u00b7feuch\u00b7te", "Na\u00b7ja\u00b7din\u00b7nen", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Mit den schnellen ", "tokens": ["Mit", "den", "schnel\u00b7len"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ART", "ADJA"], "meter": "+-+-", "measure": "trochaic.di"}}, "stanza.22": {"line.1": {"text": "Triton bring auf deinem R\u00fckken/", "tokens": ["Tri\u00b7ton", "bring", "auf", "dei\u00b7nem", "R\u00fck\u00b7ken", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPR", "PPOSAT", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sprach ", "tokens": ["Sprach"], "token_info": ["word"], "pos": ["NN"], "meter": "-", "measure": "single.down"}, "line.3": {"text": "Dorthin/ wo die lange Br\u00fckken", "tokens": ["Dor\u00b7thin", "/", "wo", "die", "lan\u00b7ge", "Br\u00fck\u00b7ken"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "$(", "PWAV", "ART", "ADJA", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Pohlenland und Preussen bindt/", "tokens": ["Poh\u00b7len\u00b7land", "und", "Preus\u00b7sen", "bindt", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "NN", "VVFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Sag dem ", "tokens": ["Sag", "dem"], "token_info": ["word", "word"], "pos": ["NN", "ART"], "meter": "+-", "measure": "trochaic.single"}, "line.6": {"text": "Floridan sey hier zu gegen.", "tokens": ["Flo\u00b7ri\u00b7dan", "sey", "hier", "zu", "ge\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "ADV", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.23": {"line.1": {"text": "Dafnis der ein Schutz der ", "tokens": ["Daf\u00b7nis", "der", "ein", "Schutz", "der"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "ART", "ART", "NN", "ART"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Dafnis der die Zunft erg\u00e4ntzt/", "tokens": ["Daf\u00b7nis", "der", "die", "Zunft", "er\u00b7g\u00e4ntzt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ART", "ART", "NN", "VVPP", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "De\u00dfen \u00e4dles Haupt mit Myrten/", "tokens": ["De\u00b7\u00dfen", "\u00e4d\u00b7les", "Haupt", "mit", "Myr\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "APPR", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "L\u00f6b- und r\u00fchmlich ist bekr\u00e4ntzt/", "tokens": ["L\u00f6\u00b7b", "und", "r\u00fchm\u00b7lich", "ist", "be\u00b7kr\u00b7\u00e4ntzt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["TRUNC", "KON", "ADJD", "VAFIN", "VVPP", "$("], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.5": {"text": "Welcher billich wird geheissen", "tokens": ["Wel\u00b7cher", "bil\u00b7lich", "wird", "ge\u00b7heis\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAT", "ADJD", "VAFIN", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Eine Fakkel von den Preussen.", "tokens": ["Ei\u00b7ne", "Fak\u00b7kel", "von", "den", "Preus\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.24": {"line.1": {"text": "Sein woll\u00e4dler Geist der stehet", "tokens": ["Sein", "wol\u00b7l\u00e4d\u00b7ler", "Geist", "der", "ste\u00b7het"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN", "ART", "VVFIN"], "meter": "+---+-+-", "measure": "dactylic.init"}, "line.2": {"text": "Da wo Feb' ihr Silber streut/", "tokens": ["Da", "wo", "Feb'", "ihr", "Sil\u00b7ber", "streut", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PWAV", "NN", "PPOSAT", "NN", "VVFIN", "$("], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.3": {"text": "Sein ber\u00fchmter Nahme gehet", "tokens": ["Sein", "be\u00b7r\u00fchm\u00b7ter", "Nah\u00b7me", "ge\u00b7het"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Bey den ", "tokens": ["Bey", "den"], "token_info": ["word", "word"], "pos": ["APPR", "ART"], "meter": "+-", "measure": "trochaic.single"}, "line.5": {"text": "Niederland und ", "tokens": ["Nie\u00b7der\u00b7land", "und"], "token_info": ["word", "word"], "pos": ["NE", "KON"], "meter": "+-+-", "measure": "trochaic.di"}, "line.6": {"text": "Wessen Er sich hat beflissen.", "tokens": ["Wes\u00b7sen", "Er", "sich", "hat", "be\u00b7flis\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "PRF", "VAFIN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.25": {"line.1": {"text": "Wie? soll ich mich unterwinden", "tokens": ["Wie", "?", "soll", "ich", "mich", "un\u00b7ter\u00b7win\u00b7den"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["PWAV", "$.", "VMFIN", "PPER", "PRF", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Durch sein sch\u00f6nes ", "tokens": ["Durch", "sein", "sch\u00f6\u00b7nes"], "token_info": ["word", "word", "word"], "pos": ["APPR", "PPOSAT", "ADJA"], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "Wo sol ich den Worte finden?", "tokens": ["Wo", "sol", "ich", "den", "Wor\u00b7te", "fin\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "PPER", "ART", "NN", "VVINF", "$."], "meter": "++--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Kurtz/ Er ist wie hir zu sehn:\n\u00e4dles Blutes hoher Sinnen/", "tokens": ["Kurtz", "/", "Er", "ist", "wie", "hir", "zu", "sehn", ":", "\u00e4d\u00b7les", "Blu\u00b7tes", "ho\u00b7her", "Sin\u00b7nen", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$(", "PPER", "VAFIN", "KOKOM", "ADV", "PTKZU", "VVINF", "$.", "ADJA", "NN", "ADJA", "NN", "$("], "meter": "+-+-+-+--+-+-+-", "measure": "trochaic.septa.relaxed"}, "line.5": {"text": "Und ein Freund der Aoninnen.", "tokens": ["Und", "ein", "Freund", "der", "A\u00b7o\u00b7nin\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.26": {"line.1": {"text": "Als nun Dafnis hatt\u2019 erfahren", "tokens": ["Als", "nun", "Daf\u00b7nis", "hatt'", "er\u00b7fah\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "NE", "VAFIN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Dafnis dieser sch\u00f6ne Mann", "tokens": ["Daf\u00b7nis", "die\u00b7ser", "sch\u00f6\u00b7ne", "Mann"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "PDAT", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df von so viel langen Jahren", "tokens": ["Da\u00df", "von", "so", "viel", "lan\u00b7gen", "Jah\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "APPR", "ADV", "PIAT", "ADJA", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Wiederkommen Floridan/", "tokens": ["Wie\u00b7der\u00b7kom\u00b7men", "Flo\u00b7ri\u00b7dan", "/"], "token_info": ["word", "word", "punct"], "pos": ["NN", "NE", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Hat er ihn bald bitten lassen", "tokens": ["Hat", "er", "ihn", "bald", "bit\u00b7ten", "las\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "PPER", "ADV", "VVINF", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Und gesaget solcher massen:", "tokens": ["Und", "ge\u00b7sa\u00b7get", "sol\u00b7cher", "mas\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.27": {"line.1": {"text": "Floridan die reine Sinnen/", "tokens": ["Flo\u00b7ri\u00b7dan", "die", "rei\u00b7ne", "Sin\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "ART", "ADJA", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "So ihr teutsch im Hertzen hegt", "tokens": ["So", "ihr", "teutsch", "im", "Hert\u00b7zen", "hegt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "PPER", "ADJD", "APPRART", "NN", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Euer l\u00f6bliches Beginnen", "tokens": ["Eu\u00b7er", "l\u00f6b\u00b7li\u00b7ches", "Be\u00b7gin\u00b7nen"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "So wir ziemlich wol erwegt", "tokens": ["So", "wir", "ziem\u00b7lich", "wol", "er\u00b7wegt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "PPER", "ADV", "ADV", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Und da\u00df ihr so rein gepfiffen", "tokens": ["Und", "da\u00df", "ihr", "so", "rein", "ge\u00b7pfif\u00b7fen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "ADV", "ADJD", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Hat uns unser ", "tokens": ["Hat", "uns", "un\u00b7ser"], "token_info": ["word", "word", "word"], "pos": ["VAFIN", "PPER", "PPOSAT"], "meter": "+-+-", "measure": "trochaic.di"}}, "stanza.28": {"line.1": {"text": "So da\u00df ihr nun auff-m\u00f6gt-schlagen", "tokens": ["So", "da\u00df", "ihr", "nun", "auf\u00b7fm\u00f6g\u00b7tschla\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "KOUS", "PPER", "ADV", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Bey uns wo ihr f\u00fcglich wohnt/", "tokens": ["Bey", "uns", "wo", "ihr", "f\u00fcg\u00b7lich", "wohnt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "PWAV", "PPER", "ADJD", "VVFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und bey euren Lebens-tagen", "tokens": ["Und", "bey", "eu\u00b7ren", "Le\u00b7bens\u00b7ta\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Von uns werden abgelohnt/", "tokens": ["Von", "uns", "wer\u00b7den", "ab\u00b7ge\u00b7lohnt", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VAFIN", "VVPP", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Jhr m\u00f6gt brauchen unsre ", "tokens": ["Ihr", "m\u00f6gt", "brau\u00b7chen", "uns\u00b7re"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "VVFIN", "PPOSAT"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.6": {"text": "Und die weyden-reiche Felder.", "tokens": ["Und", "die", "wey\u00b7den\u00b7rei\u00b7che", "Fel\u00b7der", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.29": {"line.1": {"text": "Nur damit die sch\u00f6ne Heerde", "tokens": ["Nur", "da\u00b7mit", "die", "sch\u00f6\u00b7ne", "Heer\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "PAV", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "So uns hoch vertrauet ist/", "tokens": ["So", "uns", "hoch", "ver\u00b7trau\u00b7et", "ist", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "ADJD", "VVPP", "VAFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Recht und wol geweidet werde", "tokens": ["Recht", "und", "wol", "ge\u00b7wei\u00b7det", "wer\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "KON", "ADV", "VVPP", "VAFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Da\u00df nicht durch des ", "tokens": ["Da\u00df", "nicht", "durch", "des"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PTKNEG", "APPR", "ART"], "meter": "+-+-", "measure": "trochaic.di"}, "line.5": {"text": "Uns ein Sch\u00e4fchen werd' entf\u00fchret/", "tokens": ["Uns", "ein", "Sch\u00e4f\u00b7chen", "werd'", "ent\u00b7f\u00fch\u00b7ret", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "VAFIN", "VVPP", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Oder sch\u00e4dlich anger\u00fchret.", "tokens": ["O\u00b7der", "sch\u00e4d\u00b7lich", "an\u00b7ge\u00b7r\u00fch\u00b7ret", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.30": {"line.1": {"text": "Und damit ihr eure M\u00fche/", "tokens": ["Und", "da\u00b7mit", "ihr", "eu\u00b7re", "M\u00fc\u00b7he", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PPOSAT", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Besser \u00fcberzukkern k\u00f6nnt/", "tokens": ["Bes\u00b7ser", "\u00fc\u00b7ber\u00b7zuk\u00b7kern", "k\u00f6nnt", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "VVINF", "VVFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Bin ichsp\u00e4ht so wol als fr\u00fche/", "tokens": ["Bin", "ich\u00b7sp\u00e4ht", "so", "wol", "als", "fr\u00fc\u00b7he", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ADV", "KOUS", "ADJA", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Euch zu helffen treugesinnt/", "tokens": ["Euch", "zu", "helf\u00b7fen", "treu\u00b7ge\u00b7sinnt", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKZU", "VVINF", "VVFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Jhr solt sp\u00fcrenin den ", "tokens": ["Ihr", "solt", "sp\u00fc\u00b7re\u00b7nin", "den"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ADV", "ART"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.6": {"text": "Wie so n\u00fctzlich ich gerahten.", "tokens": ["Wie", "so", "n\u00fctz\u00b7lich", "ich", "ge\u00b7rah\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "ADJD", "PPER", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.31": {"line.1": {"text": "Seht da ist die Basilene/", "tokens": ["Seht", "da", "ist", "die", "Ba\u00b7si\u00b7le\u00b7ne", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "VAFIN", "ART", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Seht geliebter Floridan/", "tokens": ["Seht", "ge\u00b7lieb\u00b7ter", "Flo\u00b7ri\u00b7dan", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "ADJA", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Basilene diese sch\u00f6ne/", "tokens": ["Ba\u00b7si\u00b7le\u00b7ne", "die\u00b7se", "sch\u00f6\u00b7ne", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "PDAT", "ADJA", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wil allzeit von nunmehr an/", "tokens": ["Wil", "all\u00b7zeit", "von", "nun\u00b7mehr", "an", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "APPR", "ADV", "APPR", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Eure Sorgen helffen mindern/", "tokens": ["Eu\u00b7re", "Sor\u00b7gen", "helf\u00b7fen", "min\u00b7dern", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVINF", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Und die M\u00fch' in etwas lindern.", "tokens": ["Und", "die", "M\u00fch'", "in", "et\u00b7was", "lin\u00b7dern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "APPR", "PIS", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.32": {"line.1": {"text": "Schauet doch der Augenlichter/", "tokens": ["Schau\u00b7et", "doch", "der", "Au\u00b7gen\u00b7lich\u00b7ter", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Schanet doch die ", "tokens": ["Scha\u00b7net", "doch", "die"], "token_info": ["word", "word", "word"], "pos": ["VVFIN", "ADV", "ART"], "meter": "+--+", "measure": "iambic.di.chol"}, "line.3": {"text": "Ist auch wol ein scharfer ", "tokens": ["Ist", "auch", "wol", "ein", "schar\u00b7fer"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "ADV", "ART", "ADJA"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Der sie besser mahlen kan?", "tokens": ["Der", "sie", "bes\u00b7ser", "mah\u00b7len", "kan", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADJD", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Schauet schauet wie sie funkeln/", "tokens": ["Schau\u00b7et", "schau\u00b7et", "wie", "sie", "fun\u00b7keln", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "KOKOM", "PPER", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Wie Karfunkel' in dem dunkeln.", "tokens": ["Wie", "Ka\u00b7rfun\u00b7kel'", "in", "dem", "dun\u00b7keln", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "APPR", "ART", "ADJA", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.33": {"line.1": {"text": "Gleichet sie nicht der Melposen/", "tokens": ["Glei\u00b7chet", "sie", "nicht", "der", "Mel\u00b7po\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKNEG", "ART", "NN", "$("], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.2": {"text": "Einer G\u00f6ttin? saget mir.", "tokens": ["Ei\u00b7ner", "G\u00f6t\u00b7tin", "?", "sa\u00b7get", "mir", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$.", "VVFIN", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Mein betrachtet doch die Rosen/", "tokens": ["Mein", "be\u00b7trach\u00b7tet", "doch", "die", "Ro\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "VVFIN", "ADV", "ART", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "und der weissen ", "tokens": ["und", "der", "weis\u00b7sen"], "token_info": ["word", "word", "word"], "pos": ["KON", "ART", "ADJA"], "meter": "+-+-", "measure": "trochaic.di"}, "line.5": {"text": "Jm Gesichte dieser Sch\u00f6nen/", "tokens": ["Jm", "Ge\u00b7sich\u00b7te", "die\u00b7ser", "Sch\u00f6\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PDAT", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "E\u00fcrer sch\u00f6nen Basilenen.", "tokens": ["E\u00b7\u00fc\u00b7rer", "sch\u00f6\u00b7nen", "Ba\u00b7si\u00b7le\u00b7nen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.34": {"line.1": {"text": "Merket doch auff ihre Sitten/", "tokens": ["Mer\u00b7ket", "doch", "auff", "ih\u00b7re", "Sit\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "PPOSAT", "NN", "$("], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.2": {"text": "Ist auch wol was ", "tokens": ["Ist", "auch", "wol", "was"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "ADV", "PWS"], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "Urtheilt doch aus ihren Schritten/", "tokens": ["Ur\u00b7theilt", "doch", "aus", "ih\u00b7ren", "Schrit\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "PPOSAT", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "K\u00f6mmt auch was der Geilheit nah?", "tokens": ["K\u00f6mmt", "auch", "was", "der", "Geil\u00b7heit", "nah", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PWS", "ART", "NN", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Nein/ von ihrer zarten Jugend/", "tokens": ["Nein", "/", "von", "ih\u00b7rer", "zar\u00b7ten", "Ju\u00b7gend", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$(", "APPR", "PPOSAT", "ADJA", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Hat sie nichts als ", "tokens": ["Hat", "sie", "nichts", "als"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "PIS", "KOKOM"], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.35": {"line.1": {"text": "Floridan sah von der seiten/", "tokens": ["Flo\u00b7ri\u00b7dan", "sah", "von", "der", "sei\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPR", "ART", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Auff die Basilene nun/", "tokens": ["Auff", "die", "Ba\u00b7si\u00b7le\u00b7ne", "nun", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADV", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und begunt' in sich zu streiten", "tokens": ["Und", "beg\u00b7unt'", "in", "sich", "zu", "strei\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "PRF", "PTKZU", "VVINF"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Was er hirauf solte thun?", "tokens": ["Was", "er", "hi\u00b7rauf", "sol\u00b7te", "thun", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "PAV", "VMFIN", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Denn ", "tokens": ["Denn"], "token_info": ["word"], "pos": ["KON"], "meter": "+", "measure": "single.up"}, "line.6": {"text": "Seiner Sinnen heisses k\u00e4mpfen.", "tokens": ["Sei\u00b7ner", "Sin\u00b7nen", "heis\u00b7ses", "k\u00e4mp\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADJA", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.36": {"line.1": {"text": "Haltet still\u2019 ich wil den dingen/", "tokens": ["Hal\u00b7tet", "still'", "ich", "wil", "den", "din\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "VMFIN", "ART", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Also bald ein ", "tokens": ["Al\u00b7so", "bald", "ein"], "token_info": ["word", "word", "word"], "pos": ["ADV", "ADV", "ART"], "meter": "+--+", "measure": "iambic.di.chol"}, "line.3": {"text": "Floridan reicht mir das Hertz.", "tokens": ["Flo\u00b7ri\u00b7dan", "reicht", "mir", "das", "Hertz", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und so hat er \u00fcber hoffen/", "tokens": ["Und", "so", "hat", "er", "\u00fc\u00b7ber", "hof\u00b7fen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "PPER", "APPR", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Recht den Mittel-punct getroffen.", "tokens": ["Recht", "den", "Mit\u00b7tel\u00b7punct", "ge\u00b7trof\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.37": {"line.1": {"text": "Hirauff dankte seinem Rahter", "tokens": ["Hir\u00b7auff", "dank\u00b7te", "sei\u00b7nem", "Rah\u00b7ter"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "VVFIN", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Floridan der gute Mann/", "tokens": ["Flo\u00b7ri\u00b7dan", "der", "gu\u00b7te", "Mann", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "ART", "ADJA", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ehret' ihn als seinen Vater.", "tokens": ["Eh\u00b7ret'", "ihn", "als", "sei\u00b7nen", "Va\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "KOUS", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Seht sprach er was ", "tokens": ["Seht", "sprach", "er", "was"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "VVFIN", "PPER", "PIS"], "meter": "-+-+", "measure": "iambic.di"}, "line.5": {"text": "Denn ich f\u00fchle schon die Schmertzen/", "tokens": ["Denn", "ich", "f\u00fch\u00b7le", "schon", "die", "Schmert\u00b7zen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ADV", "ART", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "In dem \u00fcberwundnem Hertzen.", "tokens": ["In", "dem", "\u00fc\u00b7berw\u00b7und\u00b7nem", "Hert\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.38": {"line.1": {"text": "Seid wilkommen meine sch\u00f6ne", "tokens": ["Seid", "wil\u00b7kom\u00b7men", "mei\u00b7ne", "sch\u00f6\u00b7ne"], "token_info": ["word", "word", "word", "word"], "pos": ["VAIMP", "ADJD", "PPOSAT", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sagt er ihr/ mein ", "tokens": ["Sagt", "er", "ihr", "/", "mein"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["VVFIN", "PPER", "PPER", "$(", "PPOSAT"], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "Meine sch\u00f6ne Basilene/", "tokens": ["Mei\u00b7ne", "sch\u00f6\u00b7ne", "Ba\u00b7si\u00b7le\u00b7ne", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Jhr bleibt nun mein liebster Schatz", "tokens": ["Ihr", "bleibt", "nun", "mein", "liebs\u00b7ter", "Schatz"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "PPOSAT", "ADJA", "NN"], "meter": "+---+-+", "measure": "dactylic.init"}, "line.5": {"text": "und ich bin von diesen Stunden", "tokens": ["und", "ich", "bin", "von", "die\u00b7sen", "Stun\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VAFIN", "APPR", "PDAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Euch di\u00df in mein Grab verbunden.", "tokens": ["Euch", "di\u00df", "in", "mein", "Grab", "ver\u00b7bun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PDS", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.39": {"line.1": {"text": "Darauff eylten Nymf- und H\u00fcrten/", "tokens": ["Dar\u00b7auff", "eyl\u00b7ten", "Nym\u00b7f", "und", "H\u00fcr\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ADJA", "TRUNC", "KON", "NN", "$("], "meter": "--+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Suchten ", "tokens": ["Such\u00b7ten"], "token_info": ["word"], "pos": ["NE"], "meter": "+-", "measure": "trochaic.single"}, "line.3": {"text": "Dafnerslaub und gr\u00fcne Myrten/", "tokens": ["Daf\u00b7ners\u00b7laub", "und", "gr\u00fc\u00b7ne", "Myr\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "ADJA", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wie auch frischen Thymian/\n\u00fcm die Heupter zu bekr\u00f6hnen", "tokens": ["Wie", "auch", "fri\u00b7schen", "Thy\u00b7mi\u00b7an", "/", "\u00fcm", "die", "Heup\u00b7ter", "zu", "be\u00b7kr\u00f6h\u00b7nen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADV", "ADJA", "NE", "$(", "ADV", "ART", "NN", "PTKZU", "VVINF"], "meter": "+-+-+--+-+-+-+-", "measure": "trochaic.septa.relaxed"}, "line.5": {"text": "Floridans und Basilenen.", "tokens": ["Flo\u00b7ri\u00b7dans", "und", "Ba\u00b7si\u00b7le\u00b7nen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "KON", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.40": {"line.1": {"text": "Alle suchten sch\u00f6ne ", "tokens": ["Al\u00b7le", "such\u00b7ten", "sch\u00f6\u00b7ne"], "token_info": ["word", "word", "word"], "pos": ["PIS", "VVFIN", "ADJA"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "und noch andre glatte Beum\u2019", "tokens": ["und", "noch", "and\u00b7re", "glat\u00b7te", "Beum'"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "PIS", "VVFIN", "NE"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Einzugraben deren Rinden/", "tokens": ["Ein\u00b7zu\u00b7gra\u00b7ben", "de\u00b7ren", "Rin\u00b7den", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PRELAT", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Diesen gl\u00fckkw\u00fcnschenden Reim:", "tokens": ["Die\u00b7sen", "gl\u00fck\u00b7kw\u00fcn\u00b7schen\u00b7den", "Reim", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["PDAT", "ADJA", "NN", "$."], "meter": "+-+---+", "measure": "unknown.measure.tri"}, "line.5": {"text": "Der gew\u00fcnschte Himmelssegen/", "tokens": ["Der", "ge\u00b7w\u00fcnschte", "Him\u00b7mels\u00b7se\u00b7gen", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Sey bey euch auf allen Wegen.", "tokens": ["Sey", "bey", "euch", "auf", "al\u00b7len", "We\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "PPER", "APPR", "PIAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}}}}