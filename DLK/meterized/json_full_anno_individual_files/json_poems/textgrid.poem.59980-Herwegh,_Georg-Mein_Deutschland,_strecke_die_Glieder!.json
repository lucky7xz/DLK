{"textgrid.poem.59980": {"metadata": {"author": {"name": "Herwegh, Georg", "birth": "N.A.", "death": "N.A."}, "title": "Mein Deutschland, strecke die Glieder!", "genre": "verse", "period": "N.A.", "pub_year": 1849, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Mein Deutschland, strecke die Glieder", "tokens": ["Mein", "Deutschland", ",", "stre\u00b7cke", "die", "Glie\u00b7der"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PPOSAT", "NN", "$,", "VVFIN", "ART", "NN"], "meter": "-++--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Ins alte Bett, so warm und weich;", "tokens": ["Ins", "al\u00b7te", "Bett", ",", "so", "warm", "und", "weich", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "$,", "ADV", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die Augen fallen dir nieder,", "tokens": ["Die", "Au\u00b7gen", "fal\u00b7len", "dir", "nie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Du schl\u00e4friges deutsches Reich.", "tokens": ["Du", "schl\u00e4f\u00b7ri\u00b7ges", "deut\u00b7sches", "Reich", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "ADJA", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.2": {"line.1": {"text": "Hast lange geschrien dich heiser \u2013", "tokens": ["Hast", "lan\u00b7ge", "ge\u00b7schri\u00b7en", "dich", "hei\u00b7ser", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "VVPP", "PPER", "ADJD", "$("], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Nun schenke dir Gott die ewige Ruh!", "tokens": ["Nun", "schen\u00b7ke", "dir", "Gott", "die", "e\u00b7wi\u00b7ge", "Ruh", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Dich spitzt ein deutscher Kaiser", "tokens": ["Dich", "spitzt", "ein", "deut\u00b7scher", "Kai\u00b7ser"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Pyramidalisch zu.", "tokens": ["Py\u00b7ra\u00b7mi\u00b7da\u00b7lisch", "zu", "."], "token_info": ["word", "word", "punct"], "pos": ["NE", "PTKVZ", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}}, "stanza.3": {"line.1": {"text": "O Freiheit, die wir meinen,", "tokens": ["O", "Frei\u00b7heit", ",", "die", "wir", "mei\u00b7nen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "O deutscher Kaiser, sei gegr\u00fc\u00dft!", "tokens": ["O", "deut\u00b7scher", "Kai\u00b7ser", ",", "sei", "ge\u00b7gr\u00fc\u00dft", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$,", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wir haben auch nicht einen", "tokens": ["Wir", "ha\u00b7ben", "auch", "nicht", "ei\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "PTKNEG", "ART"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Zaunk\u00f6nig eingeb\u00fc\u00dft.", "tokens": ["Zaun\u00b7k\u00f6\u00b7nig", "ein\u00b7ge\u00b7b\u00fc\u00dft", "."], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVPP", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}}, "stanza.4": {"line.1": {"text": "Sie sind uns alle verblieben;", "tokens": ["Sie", "sind", "uns", "al\u00b7le", "ver\u00b7blie\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "PIS", "VVFIN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Und als wir nach dem Sturm gez\u00e4hlt", "tokens": ["Und", "als", "wir", "nach", "dem", "Sturm", "ge\u00b7z\u00e4hlt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "APPR", "ART", "NN", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die H\u00e4upter unsrer Lieben,", "tokens": ["Die", "H\u00e4up\u00b7ter", "uns\u00b7rer", "Lie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "ADJA", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Kein einziges hat gefehlt.", "tokens": ["Kein", "ein\u00b7zi\u00b7ges", "hat", "ge\u00b7fehlt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "VAFIN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Deutschland nimmt nur die H\u00fcte", "tokens": ["Deutschland", "nimmt", "nur", "die", "H\u00fc\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "ADV", "ART", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Den K\u00f6nigen ab, das gen\u00fcgt ihm schon;", "tokens": ["Den", "K\u00f6\u00b7ni\u00b7gen", "ab", ",", "das", "ge\u00b7n\u00fcgt", "ihm", "schon", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "$,", "PDS", "VVFIN", "PPER", "ADV", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Der Deutsche macht in G\u00fcte", "tokens": ["Der", "Deut\u00b7sche", "macht", "in", "G\u00fc\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "APPR", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Die Revolution.", "tokens": ["Die", "Re\u00b7vo\u00b7lu\u00b7ti\u00b7on", "."], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Die Professoren rei\u00dfen", "tokens": ["Die", "Pro\u00b7fes\u00b7so\u00b7ren", "rei\u00b7\u00dfen"], "token_info": ["word", "word", "word"], "pos": ["ART", "NN", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Uns weder Thron noch Altar ein;", "tokens": ["Uns", "we\u00b7der", "Thron", "noch", "Al\u00b7tar", "ein", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "KON", "NN", "ADV", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Auch ist der Stein der Weisen", "tokens": ["Auch", "ist", "der", "Stein", "der", "Wei\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Kein deutscher Pflasterstein.", "tokens": ["Kein", "deut\u00b7scher", "Pflas\u00b7ter\u00b7stein", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Wir haben, was wir brauchen;", "tokens": ["Wir", "ha\u00b7ben", ",", "was", "wir", "brau\u00b7chen", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "PRELS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Gesegnet sei der V\u00f6lkerlenz!", "tokens": ["Ge\u00b7seg\u00b7net", "sei", "der", "V\u00f6l\u00b7ker\u00b7lenz", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wir d\u00fcrfen auch ferner rauchen", "tokens": ["Wir", "d\u00fcr\u00b7fen", "auch", "fer\u00b7ner", "rau\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ADV", "ADV", "VVFIN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "In unsrer Residenz.", "tokens": ["In", "uns\u00b7rer", "Re\u00b7si\u00b7denz", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Wir haben Wrangels S\u00e4bel,", "tokens": ["Wir", "ha\u00b7ben", "Wran\u00b7gels", "S\u00e4\u00b7bel", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NE", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Berlin und seinen Wolkensteg;", "tokens": ["Ber\u00b7lin", "und", "sei\u00b7nen", "Wol\u00b7kens\u00b7teg", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Das Maultier sucht im Nebel", "tokens": ["Das", "Maul\u00b7tier", "sucht", "im", "Ne\u00b7bel"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "APPRART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Noch immer seinen Weg.", "tokens": ["Noch", "im\u00b7mer", "sei\u00b7nen", "Weg", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Wie freun sich die Eunuchen!", "tokens": ["Wie", "freun", "sich", "die", "Eu\u00b7nu\u00b7chen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PRF", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Die bilden jetzo den ersten Stand,", "tokens": ["Die", "bil\u00b7den", "jet\u00b7zo", "den", "ers\u00b7ten", "Stand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+----+-+", "measure": "dactylic.init"}, "line.3": {"text": "Der Welcker fri\u00dft die Kuchen", "tokens": ["Der", "Wel\u00b7cker", "fri\u00dft", "die", "Ku\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Den K\u00f6nigen aus der Hand.", "tokens": ["Den", "K\u00f6\u00b7ni\u00b7gen", "aus", "der", "Hand", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.10": {"line.1": {"text": "Du h\u00e4ltst dir einen Gesandten,", "tokens": ["Du", "h\u00e4ltst", "dir", "ei\u00b7nen", "Ge\u00b7sand\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Deutschland, im Stillen Ozean", "tokens": ["Deutschland", ",", "im", "Stil\u00b7len", "O\u00b7ze\u00b7an"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NE", "$,", "APPRART", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und f\u00fchlest den Elefanten", "tokens": ["Und", "f\u00fch\u00b7lest", "den", "E\u00b7lef\u00b7an\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ART", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "In Indien auf den Zahn.", "tokens": ["In", "In\u00b7di\u00b7en", "auf", "den", "Zahn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Die Fragen sind erledigt,", "tokens": ["Die", "Fra\u00b7gen", "sind", "er\u00b7le\u00b7digt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Die Pfaffen machen bim bam bum;", "tokens": ["Die", "Pfaf\u00b7fen", "ma\u00b7chen", "bim", "bam", "bum", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "FM", "FM", "FM", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Den Armen wird gepredigt", "tokens": ["Den", "Ar\u00b7men", "wird", "ge\u00b7pre\u00b7digt"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "VVPP"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Das Evangelium.", "tokens": ["Das", "E\u00b7van\u00b7ge\u00b7li\u00b7um", "."], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "Wir bauen dem lieben Gotte", "tokens": ["Wir", "bau\u00b7en", "dem", "lie\u00b7ben", "Got\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Den hohen Dom zu C\u00f6llen aus", "tokens": ["Den", "ho\u00b7hen", "Dom", "zu", "C\u00f6l\u00b7len", "aus"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "APPR", "NE", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und geben eine Flotte", "tokens": ["Und", "ge\u00b7ben", "ei\u00b7ne", "Flot\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Auf Subskription heraus.", "tokens": ["Auf", "Sub\u00b7skrip\u00b7ti\u00b7on", "he\u00b7raus", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Die schwarz-rot-goldnen Wimpel", "tokens": ["Die", "schwa\u00b7rz\u00b7rot\u00b7gold\u00b7nen", "Wim\u00b7pel"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-++-+-", "measure": "unknown.measure.tetra"}, "line.2": {"text": "Besorgt der Jakob Venedey,", "tokens": ["Be\u00b7sorgt", "der", "Ja\u00b7kob", "Ve\u00b7ne\u00b7dey", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NE", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Als Wappen nahm er den Gimpel,", "tokens": ["Als", "Wap\u00b7pen", "nahm", "er", "den", "Gim\u00b7pel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Sein eignes Konterfei.", "tokens": ["Sein", "eig\u00b7nes", "Kon\u00b7ter\u00b7fei", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.14": {"line.1": {"text": "F\u00fcnfhundert Narrenschellen", "tokens": ["F\u00fcnf\u00b7hun\u00b7dert", "Nar\u00b7ren\u00b7schel\u00b7len"], "token_info": ["word", "word"], "pos": ["CARD", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Zu Frankfurt spielen die Melodie:", "tokens": ["Zu", "Frank\u00b7furt", "spie\u00b7len", "die", "Me\u00b7lo\u00b7die", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VVFIN", "ART", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Das Schiff streicht durch die Wellen", "tokens": ["Das", "Schiff", "streicht", "durch", "die", "Wel\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Der deutschen Phantasie.", "tokens": ["Der", "deut\u00b7schen", "Phan\u00b7ta\u00b7sie", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.15": {"line.1": {"text": "Mein Deutschland, strecke die Glieder", "tokens": ["Mein", "Deutschland", ",", "stre\u00b7cke", "die", "Glie\u00b7der"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PPOSAT", "NN", "$,", "VVFIN", "ART", "NN"], "meter": "-++--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Ins alte Bett, so warm und weich;", "tokens": ["Ins", "al\u00b7te", "Bett", ",", "so", "warm", "und", "weich", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "$,", "ADV", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die Augen fallen dir nieder,", "tokens": ["Die", "Au\u00b7gen", "fal\u00b7len", "dir", "nie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Du schl\u00e4friges deutsches Reich.", "tokens": ["Du", "schl\u00e4f\u00b7ri\u00b7ges", "deut\u00b7sches", "Reich", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "ADJA", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.16": {"line.1": {"text": "Hast lange geschrien dich heiser \u2013", "tokens": ["Hast", "lan\u00b7ge", "ge\u00b7schri\u00b7en", "dich", "hei\u00b7ser", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "VVPP", "PPER", "ADJD", "$("], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Nun schenke dir Gott die ewige Ruh!", "tokens": ["Nun", "schen\u00b7ke", "dir", "Gott", "die", "e\u00b7wi\u00b7ge", "Ruh", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Dich spitzt ein deutscher Kaiser", "tokens": ["Dich", "spitzt", "ein", "deut\u00b7scher", "Kai\u00b7ser"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Pyramidalisch zu.", "tokens": ["Py\u00b7ra\u00b7mi\u00b7da\u00b7lisch", "zu", "."], "token_info": ["word", "word", "punct"], "pos": ["NE", "PTKVZ", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}}, "stanza.17": {"line.1": {"text": "O Freiheit, die wir meinen,", "tokens": ["O", "Frei\u00b7heit", ",", "die", "wir", "mei\u00b7nen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "O deutscher Kaiser, sei gegr\u00fc\u00dft!", "tokens": ["O", "deut\u00b7scher", "Kai\u00b7ser", ",", "sei", "ge\u00b7gr\u00fc\u00dft", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$,", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wir haben auch nicht einen", "tokens": ["Wir", "ha\u00b7ben", "auch", "nicht", "ei\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "PTKNEG", "ART"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Zaunk\u00f6nig eingeb\u00fc\u00dft.", "tokens": ["Zaun\u00b7k\u00f6\u00b7nig", "ein\u00b7ge\u00b7b\u00fc\u00dft", "."], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVPP", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}}, "stanza.18": {"line.1": {"text": "Sie sind uns alle verblieben;", "tokens": ["Sie", "sind", "uns", "al\u00b7le", "ver\u00b7blie\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "PIS", "VVFIN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Und als wir nach dem Sturm gez\u00e4hlt", "tokens": ["Und", "als", "wir", "nach", "dem", "Sturm", "ge\u00b7z\u00e4hlt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "APPR", "ART", "NN", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die H\u00e4upter unsrer Lieben,", "tokens": ["Die", "H\u00e4up\u00b7ter", "uns\u00b7rer", "Lie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "ADJA", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Kein einziges hat gefehlt.", "tokens": ["Kein", "ein\u00b7zi\u00b7ges", "hat", "ge\u00b7fehlt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "VAFIN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.19": {"line.1": {"text": "Deutschland nimmt nur die H\u00fcte", "tokens": ["Deutschland", "nimmt", "nur", "die", "H\u00fc\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "ADV", "ART", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Den K\u00f6nigen ab, das gen\u00fcgt ihm schon;", "tokens": ["Den", "K\u00f6\u00b7ni\u00b7gen", "ab", ",", "das", "ge\u00b7n\u00fcgt", "ihm", "schon", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "$,", "PDS", "VVFIN", "PPER", "ADV", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Der Deutsche macht in G\u00fcte", "tokens": ["Der", "Deut\u00b7sche", "macht", "in", "G\u00fc\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "APPR", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Die Revolution.", "tokens": ["Die", "Re\u00b7vo\u00b7lu\u00b7ti\u00b7on", "."], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.20": {"line.1": {"text": "Die Professoren rei\u00dfen", "tokens": ["Die", "Pro\u00b7fes\u00b7so\u00b7ren", "rei\u00b7\u00dfen"], "token_info": ["word", "word", "word"], "pos": ["ART", "NN", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Uns weder Thron noch Altar ein;", "tokens": ["Uns", "we\u00b7der", "Thron", "noch", "Al\u00b7tar", "ein", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "KON", "NN", "ADV", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Auch ist der Stein der Weisen", "tokens": ["Auch", "ist", "der", "Stein", "der", "Wei\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Kein deutscher Pflasterstein.", "tokens": ["Kein", "deut\u00b7scher", "Pflas\u00b7ter\u00b7stein", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.21": {"line.1": {"text": "Wir haben, was wir brauchen;", "tokens": ["Wir", "ha\u00b7ben", ",", "was", "wir", "brau\u00b7chen", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "PRELS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Gesegnet sei der V\u00f6lkerlenz!", "tokens": ["Ge\u00b7seg\u00b7net", "sei", "der", "V\u00f6l\u00b7ker\u00b7lenz", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wir d\u00fcrfen auch ferner rauchen", "tokens": ["Wir", "d\u00fcr\u00b7fen", "auch", "fer\u00b7ner", "rau\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ADV", "ADV", "VVFIN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "In unsrer Residenz.", "tokens": ["In", "uns\u00b7rer", "Re\u00b7si\u00b7denz", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.22": {"line.1": {"text": "Wir haben Wrangels S\u00e4bel,", "tokens": ["Wir", "ha\u00b7ben", "Wran\u00b7gels", "S\u00e4\u00b7bel", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NE", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Berlin und seinen Wolkensteg;", "tokens": ["Ber\u00b7lin", "und", "sei\u00b7nen", "Wol\u00b7kens\u00b7teg", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Das Maultier sucht im Nebel", "tokens": ["Das", "Maul\u00b7tier", "sucht", "im", "Ne\u00b7bel"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "APPRART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Noch immer seinen Weg.", "tokens": ["Noch", "im\u00b7mer", "sei\u00b7nen", "Weg", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.23": {"line.1": {"text": "Wie freun sich die Eunuchen!", "tokens": ["Wie", "freun", "sich", "die", "Eu\u00b7nu\u00b7chen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PRF", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Die bilden jetzo den ersten Stand,", "tokens": ["Die", "bil\u00b7den", "jet\u00b7zo", "den", "ers\u00b7ten", "Stand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+----+-+", "measure": "dactylic.init"}, "line.3": {"text": "Der Welcker fri\u00dft die Kuchen", "tokens": ["Der", "Wel\u00b7cker", "fri\u00dft", "die", "Ku\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Den K\u00f6nigen aus der Hand.", "tokens": ["Den", "K\u00f6\u00b7ni\u00b7gen", "aus", "der", "Hand", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.24": {"line.1": {"text": "Du h\u00e4ltst dir einen Gesandten,", "tokens": ["Du", "h\u00e4ltst", "dir", "ei\u00b7nen", "Ge\u00b7sand\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Deutschland, im Stillen Ozean", "tokens": ["Deutschland", ",", "im", "Stil\u00b7len", "O\u00b7ze\u00b7an"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NE", "$,", "APPRART", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und f\u00fchlest den Elefanten", "tokens": ["Und", "f\u00fch\u00b7lest", "den", "E\u00b7lef\u00b7an\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ART", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "In Indien auf den Zahn.", "tokens": ["In", "In\u00b7di\u00b7en", "auf", "den", "Zahn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.25": {"line.1": {"text": "Die Fragen sind erledigt,", "tokens": ["Die", "Fra\u00b7gen", "sind", "er\u00b7le\u00b7digt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Die Pfaffen machen bim bam bum;", "tokens": ["Die", "Pfaf\u00b7fen", "ma\u00b7chen", "bim", "bam", "bum", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "FM", "FM", "FM", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Den Armen wird gepredigt", "tokens": ["Den", "Ar\u00b7men", "wird", "ge\u00b7pre\u00b7digt"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "VVPP"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Das Evangelium.", "tokens": ["Das", "E\u00b7van\u00b7ge\u00b7li\u00b7um", "."], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.26": {"line.1": {"text": "Wir bauen dem lieben Gotte", "tokens": ["Wir", "bau\u00b7en", "dem", "lie\u00b7ben", "Got\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Den hohen Dom zu C\u00f6llen aus", "tokens": ["Den", "ho\u00b7hen", "Dom", "zu", "C\u00f6l\u00b7len", "aus"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "APPR", "NE", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und geben eine Flotte", "tokens": ["Und", "ge\u00b7ben", "ei\u00b7ne", "Flot\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Auf Subskription heraus.", "tokens": ["Auf", "Sub\u00b7skrip\u00b7ti\u00b7on", "he\u00b7raus", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.27": {"line.1": {"text": "Die schwarz-rot-goldnen Wimpel", "tokens": ["Die", "schwa\u00b7rz\u00b7rot\u00b7gold\u00b7nen", "Wim\u00b7pel"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-++-+-", "measure": "unknown.measure.tetra"}, "line.2": {"text": "Besorgt der Jakob Venedey,", "tokens": ["Be\u00b7sorgt", "der", "Ja\u00b7kob", "Ve\u00b7ne\u00b7dey", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NE", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Als Wappen nahm er den Gimpel,", "tokens": ["Als", "Wap\u00b7pen", "nahm", "er", "den", "Gim\u00b7pel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Sein eignes Konterfei.", "tokens": ["Sein", "eig\u00b7nes", "Kon\u00b7ter\u00b7fei", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.28": {"line.1": {"text": "F\u00fcnfhundert Narrenschellen", "tokens": ["F\u00fcnf\u00b7hun\u00b7dert", "Nar\u00b7ren\u00b7schel\u00b7len"], "token_info": ["word", "word"], "pos": ["CARD", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Zu Frankfurt spielen die Melodie:", "tokens": ["Zu", "Frank\u00b7furt", "spie\u00b7len", "die", "Me\u00b7lo\u00b7die", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VVFIN", "ART", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Das Schiff streicht durch die Wellen", "tokens": ["Das", "Schiff", "streicht", "durch", "die", "Wel\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Der deutschen Phantasie.", "tokens": ["Der", "deut\u00b7schen", "Phan\u00b7ta\u00b7sie", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}}}}