{"textgrid.poem.49133": {"metadata": {"author": {"name": "R\u00f6ling, Johann", "birth": "N.A.", "death": "N.A."}, "title": "\u00dcber das Kreutz Christi", "genre": "verse", "period": "N.A.", "pub_year": 1656, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "O seligs Holz, o heilger Stamm,", "tokens": ["O", "se\u00b7ligs", "Holz", ",", "o", "heil\u00b7ger", "Stamm", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$,", "FM", "ADJA", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Daran du, liebster Br\u00e4utigam,", "tokens": ["Da\u00b7ran", "du", ",", "liebs\u00b7ter", "Br\u00e4u\u00b7ti\u00b7gam", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PAV", "PPER", "$,", "ADJA", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "F\u00fcr deine Braut wirst angeschlagen!", "tokens": ["F\u00fcr", "dei\u00b7ne", "Braut", "wirst", "an\u00b7ge\u00b7schla\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Kommt her, ihr T\u00f6chter au\u00df Zion,", "tokens": ["Kommt", "her", ",", "ihr", "T\u00f6ch\u00b7ter", "au\u00df", "Zi\u00b7on", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PTKVZ", "$,", "PPOSAT", "NN", "APPR", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und sehet, was des H\u00f6chsten Sohn", "tokens": ["Und", "se\u00b7het", ",", "was", "des", "H\u00f6chs\u00b7ten", "Sohn"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "$,", "PRELS", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "F\u00fcr unsre Liebe mu\u00df ertragen.", "tokens": ["F\u00fcr", "uns\u00b7re", "Lie\u00b7be", "mu\u00df", "er\u00b7tra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Ach, unser traurigs Erb-Beschwer", "tokens": ["Ach", ",", "un\u00b7ser", "trau\u00b7rigs", "Er\u00b7bBe\u00b7schwer"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["ITJ", "$,", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "R\u00fchrt von dem Baum des Todes her,", "tokens": ["R\u00fchrt", "von", "dem", "Baum", "des", "To\u00b7des", "her", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "ART", "NN", "PTKVZ", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Den unser Vater hat geschmecket;", "tokens": ["Den", "un\u00b7ser", "Va\u00b7ter", "hat", "ge\u00b7schme\u00b7cket", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Schaut hie den Baum des Lebens an,", "tokens": ["Schaut", "hie", "den", "Baum", "des", "Le\u00b7bens", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Was unter jenem mi\u00dfgethan,", "tokens": ["Was", "un\u00b7ter", "je\u00b7nem", "mi\u00df\u00b7ge\u00b7than", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "PDAT", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wird unter diesem gantz verdecket.", "tokens": ["Wird", "un\u00b7ter", "die\u00b7sem", "gantz", "ver\u00b7de\u00b7cket", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "PDAT", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Laufft zu, die ihr das Leben sucht,", "tokens": ["Laufft", "zu", ",", "die", "ihr", "das", "Le\u00b7ben", "sucht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKVZ", "$,", "PRELS", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und schmeckt, wie s\u00fc\u00df doch dessen Frucht,", "tokens": ["Und", "schmeckt", ",", "wie", "s\u00fc\u00df", "doch", "des\u00b7sen", "Frucht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "PWAV", "ADJD", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Das Sternen-Brodt, des Himmels-Quelle,", "tokens": ["Das", "Ster\u00b7nen\u00b7Brodt", ",", "des", "Him\u00b7mels\u00b7Quel\u00b7le", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Der ewge Schatz, das h\u00f6chste Gut,", "tokens": ["Der", "ew\u00b7ge", "Schatz", ",", "das", "h\u00f6chs\u00b7te", "Gut", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Selbst Gottes wahrer Leib und Blut,", "tokens": ["Selbst", "Got\u00b7tes", "wah\u00b7rer", "Leib", "und", "Blut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "ADJA", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Dein Sch\u00f6pffer vor, itzt dein Geselle.", "tokens": ["Dein", "Sch\u00f6pf\u00b7fer", "vor", ",", "itzt", "dein", "Ge\u00b7sel\u00b7le", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PTKVZ", "$,", "ADV", "PPOSAT", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.4": {"line.1": {"text": "Ach, kostet diese Wunder-Fr\u00fccht',", "tokens": ["Ach", ",", "kos\u00b7tet", "die\u00b7se", "Wun\u00b7der\u00b7Fr\u00fccht'", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "VVFIN", "PDAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Kein Cherub treibt davon mehr nicht,", "tokens": ["Kein", "Che\u00b7rub", "treibt", "da\u00b7von", "mehr", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "PAV", "ADV", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der Garten ist nicht mehr umgraben,", "tokens": ["Der", "Gar\u00b7ten", "ist", "nicht", "mehr", "um\u00b7gra\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PTKNEG", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Er stehet frey im freyen Feld',", "tokens": ["Er", "ste\u00b7het", "frey", "im", "frey\u00b7en", "Feld'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Auff da\u00df dazu die gantze Welt", "tokens": ["Auff", "da\u00df", "da\u00b7zu", "die", "gant\u00b7ze", "Welt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "KOUS", "PAV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Mag ihren freyen Zugang haben.", "tokens": ["Mag", "ih\u00b7ren", "frey\u00b7en", "Zu\u00b7gang", "ha\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPOSAT", "ADJA", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "O werthes Kreutz, o unsre Freud'", "tokens": ["O", "wert\u00b7hes", "Kreutz", ",", "o", "uns\u00b7re", "Freud'"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["NE", "ADJA", "NN", "$,", "FM", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "In allem unserm Kreutz und Leid'!", "tokens": ["In", "al\u00b7lem", "un\u00b7serm", "Kreutz", "und", "Leid'", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "PPOSAT", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ist wer, den seine S\u00fcnden plagen?", "tokens": ["Ist", "wer", ",", "den", "sei\u00b7ne", "S\u00fcn\u00b7den", "pla\u00b7gen", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "$,", "PRELS", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Hieher und hol dein' Artzeney,", "tokens": ["Hie\u00b7her", "und", "hol", "dein'", "Art\u00b7ze\u00b7ney", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KON", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die Handschrifft, sieh, ist hie entzwey", "tokens": ["Die", "Hand\u00b7schrifft", ",", "sieh", ",", "ist", "hie", "ent\u00b7zwey"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "$,", "VVFIN", "$,", "VAFIN", "ADV", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und durchgestrichen angeschlagen.", "tokens": ["Und", "durch\u00b7ge\u00b7stri\u00b7chen", "an\u00b7ge\u00b7schla\u00b7gen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "VVIZU", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Wird wer noch durch den Tod bewegt?", "tokens": ["Wird", "wer", "noch", "durch", "den", "Tod", "be\u00b7wegt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PWS", "ADV", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dies ist das Speer, das ihn erlegt,", "tokens": ["Dies", "ist", "das", "Speer", ",", "das", "ihn", "er\u00b7legt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "$,", "PRELS", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die Baar, darauff er au\u00dfgetragen.", "tokens": ["Die", "Baar", ",", "dar\u00b7auff", "er", "au\u00df\u00b7ge\u00b7tra\u00b7gen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PAV", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Schreckt wen der H\u00f6llen Ungemach?", "tokens": ["Schreckt", "wen", "der", "H\u00f6l\u00b7len", "Un\u00b7ge\u00b7mach", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PWS", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Dies ist die Keul, die sie zerbrach", "tokens": ["Dies", "ist", "die", "Keul", ",", "die", "sie", "zer\u00b7brach"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PDS", "VAFIN", "ART", "NN", "$,", "PRELS", "PPER", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und die ihr gantzes Heer geschlagen.", "tokens": ["Und", "die", "ihr", "gant\u00b7zes", "Heer", "ge\u00b7schla\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "PPOSAT", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Da\u00df nicht der Himmel auff uns f\u00e4llt,", "tokens": ["Da\u00df", "nicht", "der", "Him\u00b7mel", "auff", "uns", "f\u00e4llt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PTKNEG", "ART", "NN", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ist dies die St\u00fctze, die ihn h\u00e4lt,", "tokens": ["Ist", "dies", "die", "St\u00fct\u00b7ze", ",", "die", "ihn", "h\u00e4lt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "PDS", "ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und da\u00df kein Fluch die Erde dr\u00fccke,", "tokens": ["Und", "da\u00df", "kein", "Fluch", "die", "Er\u00b7de", "dr\u00fc\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PIAT", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wird dieser benedeyte Stamm,", "tokens": ["Wird", "die\u00b7ser", "be\u00b7ne\u00b7dey\u00b7te", "Stamm", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PDAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Von dem sie ihren Ursprung nam,", "tokens": ["Von", "dem", "sie", "ih\u00b7ren", "Ur\u00b7sprung", "nam", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ihr eingepflantzt, der sie erquicke.", "tokens": ["Ihr", "ein\u00b7ge\u00b7pflantzt", ",", "der", "sie", "er\u00b7qui\u00b7cke", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVPP", "$,", "PRELS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Sprecht nicht, da\u00df er verdorret sey;", "tokens": ["Sprecht", "nicht", ",", "da\u00df", "er", "ver\u00b7dor\u00b7ret", "sey", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "$,", "KOUS", "PPER", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Was uns den Wachsthum bringet bey,", "tokens": ["Was", "uns", "den", "Wach\u00b7sthum", "brin\u00b7get", "bey", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ART", "NN", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Kan man kein d\u00fcrres Holtz nicht nennen,", "tokens": ["Kan", "man", "kein", "d\u00fcr\u00b7res", "Holtz", "nicht", "nen\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIS", "PIAT", "ADJA", "NN", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ach nein, da\u00df unsre Wolfahrt bl\u00fcht", "tokens": ["Ach", "nein", ",", "da\u00df", "uns\u00b7re", "Wol\u00b7fahrt", "bl\u00fcht"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "PTKANT", "$,", "KOUS", "PPOSAT", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und in uns gute Fr\u00fccht' erzieht,", "tokens": ["Und", "in", "uns", "gu\u00b7te", "Fr\u00fccht'", "er\u00b7zieht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPER", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Mu\u00df hieher seinen Safft erkennen.", "tokens": ["Mu\u00df", "hie\u00b7her", "sei\u00b7nen", "Safft", "er\u00b7ken\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PAV", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Bringt Palmen, bringet Oelzweig her,", "tokens": ["Bringt", "Pal\u00b7men", ",", "brin\u00b7get", "O\u00b7el\u00b7zweig", "her", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "$,", "VVFIN", "NE", "PTKVZ", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Zu dieses lieben Kreutzes Ehr,", "tokens": ["Zu", "die\u00b7ses", "lie\u00b7ben", "Kreut\u00b7zes", "Ehr", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die Oelzweig' als der Gnaden Pflantze,", "tokens": ["Die", "O\u00b7el\u00b7zweig'", "als", "der", "Gna\u00b7den", "Pflant\u00b7ze", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KOKOM", "ART", "NN", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "Die Palmen des erhaltnen Streits", "tokens": ["Die", "Pal\u00b7men", "des", "er\u00b7halt\u00b7nen", "Streits"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die schicken recht sich beyderseits", "tokens": ["Die", "schi\u00b7cken", "recht", "sich", "bey\u00b7der\u00b7seits"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "ADJD", "PRF", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Zu dessen au\u00dferwehltem Krantze.", "tokens": ["Zu", "des\u00b7sen", "au\u00b7\u00dfer\u00b7wehl\u00b7tem", "Krant\u00b7ze", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Ach, meine Lieb- und Lust-Begier", "tokens": ["Ach", ",", "mei\u00b7ne", "Lie\u00b7b", "und", "Lust\u00b7Be\u00b7gier"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["ITJ", "$,", "PPOSAT", "TRUNC", "KON", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Ist gantz gekreutziget in mir,", "tokens": ["Ist", "gantz", "ge\u00b7kreut\u00b7zi\u00b7get", "in", "mir", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "VVPP", "APPR", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da, Jesu, du gekreutzigt worden,", "tokens": ["Da", ",", "Je\u00b7su", ",", "du", "ge\u00b7kreut\u00b7zigt", "wor\u00b7den", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "NE", "$,", "PPER", "VVPP", "VAPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ich such' auch nichts mehr bey der Welt;", "tokens": ["Ich", "such'", "auch", "nichts", "mehr", "bey", "der", "Welt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PIS", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Der Orden, welcher mir gef\u00e4llt,", "tokens": ["Der", "Or\u00b7den", ",", "wel\u00b7cher", "mir", "ge\u00b7f\u00e4llt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ist nur allein des Kreutzes Orden.", "tokens": ["Ist", "nur", "al\u00b7lein", "des", "Kreut\u00b7zes", "Or\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "O seligs Holz, o heilger Stamm,", "tokens": ["O", "se\u00b7ligs", "Holz", ",", "o", "heil\u00b7ger", "Stamm", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$,", "FM", "ADJA", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Daran du, liebster Br\u00e4utigam,", "tokens": ["Da\u00b7ran", "du", ",", "liebs\u00b7ter", "Br\u00e4u\u00b7ti\u00b7gam", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PAV", "PPER", "$,", "ADJA", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "F\u00fcr deine Braut wirst angeschlagen!", "tokens": ["F\u00fcr", "dei\u00b7ne", "Braut", "wirst", "an\u00b7ge\u00b7schla\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Kommt her, ihr T\u00f6chter au\u00df Zion,", "tokens": ["Kommt", "her", ",", "ihr", "T\u00f6ch\u00b7ter", "au\u00df", "Zi\u00b7on", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PTKVZ", "$,", "PPOSAT", "NN", "APPR", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und sehet, was des H\u00f6chsten Sohn", "tokens": ["Und", "se\u00b7het", ",", "was", "des", "H\u00f6chs\u00b7ten", "Sohn"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "$,", "PRELS", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "F\u00fcr unsre Liebe mu\u00df ertragen.", "tokens": ["F\u00fcr", "uns\u00b7re", "Lie\u00b7be", "mu\u00df", "er\u00b7tra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Ach, unser traurigs Erb-Beschwer", "tokens": ["Ach", ",", "un\u00b7ser", "trau\u00b7rigs", "Er\u00b7bBe\u00b7schwer"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["ITJ", "$,", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "R\u00fchrt von dem Baum des Todes her,", "tokens": ["R\u00fchrt", "von", "dem", "Baum", "des", "To\u00b7des", "her", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "ART", "NN", "PTKVZ", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Den unser Vater hat geschmecket;", "tokens": ["Den", "un\u00b7ser", "Va\u00b7ter", "hat", "ge\u00b7schme\u00b7cket", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Schaut hie den Baum des Lebens an,", "tokens": ["Schaut", "hie", "den", "Baum", "des", "Le\u00b7bens", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Was unter jenem mi\u00dfgethan,", "tokens": ["Was", "un\u00b7ter", "je\u00b7nem", "mi\u00df\u00b7ge\u00b7than", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "PDAT", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wird unter diesem gantz verdecket.", "tokens": ["Wird", "un\u00b7ter", "die\u00b7sem", "gantz", "ver\u00b7de\u00b7cket", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "PDAT", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Laufft zu, die ihr das Leben sucht,", "tokens": ["Laufft", "zu", ",", "die", "ihr", "das", "Le\u00b7ben", "sucht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKVZ", "$,", "PRELS", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und schmeckt, wie s\u00fc\u00df doch dessen Frucht,", "tokens": ["Und", "schmeckt", ",", "wie", "s\u00fc\u00df", "doch", "des\u00b7sen", "Frucht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "PWAV", "ADJD", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Das Sternen-Brodt, des Himmels-Quelle,", "tokens": ["Das", "Ster\u00b7nen\u00b7Brodt", ",", "des", "Him\u00b7mels\u00b7Quel\u00b7le", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Der ewge Schatz, das h\u00f6chste Gut,", "tokens": ["Der", "ew\u00b7ge", "Schatz", ",", "das", "h\u00f6chs\u00b7te", "Gut", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Selbst Gottes wahrer Leib und Blut,", "tokens": ["Selbst", "Got\u00b7tes", "wah\u00b7rer", "Leib", "und", "Blut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "ADJA", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Dein Sch\u00f6pffer vor, itzt dein Geselle.", "tokens": ["Dein", "Sch\u00f6pf\u00b7fer", "vor", ",", "itzt", "dein", "Ge\u00b7sel\u00b7le", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PTKVZ", "$,", "ADV", "PPOSAT", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.14": {"line.1": {"text": "Ach, kostet diese Wunder-Fr\u00fccht',", "tokens": ["Ach", ",", "kos\u00b7tet", "die\u00b7se", "Wun\u00b7der\u00b7Fr\u00fccht'", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "VVFIN", "PDAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Kein Cherub treibt davon mehr nicht,", "tokens": ["Kein", "Che\u00b7rub", "treibt", "da\u00b7von", "mehr", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "PAV", "ADV", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der Garten ist nicht mehr umgraben,", "tokens": ["Der", "Gar\u00b7ten", "ist", "nicht", "mehr", "um\u00b7gra\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PTKNEG", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Er stehet frey im freyen Feld',", "tokens": ["Er", "ste\u00b7het", "frey", "im", "frey\u00b7en", "Feld'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Auff da\u00df dazu die gantze Welt", "tokens": ["Auff", "da\u00df", "da\u00b7zu", "die", "gant\u00b7ze", "Welt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "KOUS", "PAV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Mag ihren freyen Zugang haben.", "tokens": ["Mag", "ih\u00b7ren", "frey\u00b7en", "Zu\u00b7gang", "ha\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPOSAT", "ADJA", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "O werthes Kreutz, o unsre Freud'", "tokens": ["O", "wert\u00b7hes", "Kreutz", ",", "o", "uns\u00b7re", "Freud'"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["NE", "ADJA", "NN", "$,", "FM", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "In allem unserm Kreutz und Leid'!", "tokens": ["In", "al\u00b7lem", "un\u00b7serm", "Kreutz", "und", "Leid'", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "PPOSAT", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ist wer, den seine S\u00fcnden plagen?", "tokens": ["Ist", "wer", ",", "den", "sei\u00b7ne", "S\u00fcn\u00b7den", "pla\u00b7gen", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "$,", "PRELS", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Hieher und hol dein' Artzeney,", "tokens": ["Hie\u00b7her", "und", "hol", "dein'", "Art\u00b7ze\u00b7ney", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KON", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die Handschrifft, sieh, ist hie entzwey", "tokens": ["Die", "Hand\u00b7schrifft", ",", "sieh", ",", "ist", "hie", "ent\u00b7zwey"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "$,", "VVFIN", "$,", "VAFIN", "ADV", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und durchgestrichen angeschlagen.", "tokens": ["Und", "durch\u00b7ge\u00b7stri\u00b7chen", "an\u00b7ge\u00b7schla\u00b7gen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "VVIZU", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "Wird wer noch durch den Tod bewegt?", "tokens": ["Wird", "wer", "noch", "durch", "den", "Tod", "be\u00b7wegt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PWS", "ADV", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dies ist das Speer, das ihn erlegt,", "tokens": ["Dies", "ist", "das", "Speer", ",", "das", "ihn", "er\u00b7legt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "$,", "PRELS", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die Baar, darauff er au\u00dfgetragen.", "tokens": ["Die", "Baar", ",", "dar\u00b7auff", "er", "au\u00df\u00b7ge\u00b7tra\u00b7gen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PAV", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Schreckt wen der H\u00f6llen Ungemach?", "tokens": ["Schreckt", "wen", "der", "H\u00f6l\u00b7len", "Un\u00b7ge\u00b7mach", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PWS", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Dies ist die Keul, die sie zerbrach", "tokens": ["Dies", "ist", "die", "Keul", ",", "die", "sie", "zer\u00b7brach"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PDS", "VAFIN", "ART", "NN", "$,", "PRELS", "PPER", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und die ihr gantzes Heer geschlagen.", "tokens": ["Und", "die", "ihr", "gant\u00b7zes", "Heer", "ge\u00b7schla\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "PPOSAT", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.17": {"line.1": {"text": "Da\u00df nicht der Himmel auff uns f\u00e4llt,", "tokens": ["Da\u00df", "nicht", "der", "Him\u00b7mel", "auff", "uns", "f\u00e4llt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PTKNEG", "ART", "NN", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ist dies die St\u00fctze, die ihn h\u00e4lt,", "tokens": ["Ist", "dies", "die", "St\u00fct\u00b7ze", ",", "die", "ihn", "h\u00e4lt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "PDS", "ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und da\u00df kein Fluch die Erde dr\u00fccke,", "tokens": ["Und", "da\u00df", "kein", "Fluch", "die", "Er\u00b7de", "dr\u00fc\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PIAT", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wird dieser benedeyte Stamm,", "tokens": ["Wird", "die\u00b7ser", "be\u00b7ne\u00b7dey\u00b7te", "Stamm", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PDAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Von dem sie ihren Ursprung nam,", "tokens": ["Von", "dem", "sie", "ih\u00b7ren", "Ur\u00b7sprung", "nam", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ihr eingepflantzt, der sie erquicke.", "tokens": ["Ihr", "ein\u00b7ge\u00b7pflantzt", ",", "der", "sie", "er\u00b7qui\u00b7cke", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVPP", "$,", "PRELS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.18": {"line.1": {"text": "Sprecht nicht, da\u00df er verdorret sey;", "tokens": ["Sprecht", "nicht", ",", "da\u00df", "er", "ver\u00b7dor\u00b7ret", "sey", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "$,", "KOUS", "PPER", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Was uns den Wachsthum bringet bey,", "tokens": ["Was", "uns", "den", "Wach\u00b7sthum", "brin\u00b7get", "bey", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ART", "NN", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Kan man kein d\u00fcrres Holtz nicht nennen,", "tokens": ["Kan", "man", "kein", "d\u00fcr\u00b7res", "Holtz", "nicht", "nen\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIS", "PIAT", "ADJA", "NN", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ach nein, da\u00df unsre Wolfahrt bl\u00fcht", "tokens": ["Ach", "nein", ",", "da\u00df", "uns\u00b7re", "Wol\u00b7fahrt", "bl\u00fcht"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "PTKANT", "$,", "KOUS", "PPOSAT", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und in uns gute Fr\u00fccht' erzieht,", "tokens": ["Und", "in", "uns", "gu\u00b7te", "Fr\u00fccht'", "er\u00b7zieht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPER", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Mu\u00df hieher seinen Safft erkennen.", "tokens": ["Mu\u00df", "hie\u00b7her", "sei\u00b7nen", "Safft", "er\u00b7ken\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PAV", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.19": {"line.1": {"text": "Bringt Palmen, bringet Oelzweig her,", "tokens": ["Bringt", "Pal\u00b7men", ",", "brin\u00b7get", "O\u00b7el\u00b7zweig", "her", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "$,", "VVFIN", "NE", "PTKVZ", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Zu dieses lieben Kreutzes Ehr,", "tokens": ["Zu", "die\u00b7ses", "lie\u00b7ben", "Kreut\u00b7zes", "Ehr", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die Oelzweig' als der Gnaden Pflantze,", "tokens": ["Die", "O\u00b7el\u00b7zweig'", "als", "der", "Gna\u00b7den", "Pflant\u00b7ze", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KOKOM", "ART", "NN", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "Die Palmen des erhaltnen Streits", "tokens": ["Die", "Pal\u00b7men", "des", "er\u00b7halt\u00b7nen", "Streits"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die schicken recht sich beyderseits", "tokens": ["Die", "schi\u00b7cken", "recht", "sich", "bey\u00b7der\u00b7seits"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "ADJD", "PRF", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Zu dessen au\u00dferwehltem Krantze.", "tokens": ["Zu", "des\u00b7sen", "au\u00b7\u00dfer\u00b7wehl\u00b7tem", "Krant\u00b7ze", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.20": {"line.1": {"text": "Ach, meine Lieb- und Lust-Begier", "tokens": ["Ach", ",", "mei\u00b7ne", "Lie\u00b7b", "und", "Lust\u00b7Be\u00b7gier"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["ITJ", "$,", "PPOSAT", "TRUNC", "KON", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Ist gantz gekreutziget in mir,", "tokens": ["Ist", "gantz", "ge\u00b7kreut\u00b7zi\u00b7get", "in", "mir", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "VVPP", "APPR", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da, Jesu, du gekreutzigt worden,", "tokens": ["Da", ",", "Je\u00b7su", ",", "du", "ge\u00b7kreut\u00b7zigt", "wor\u00b7den", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "NE", "$,", "PPER", "VVPP", "VAPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ich such' auch nichts mehr bey der Welt;", "tokens": ["Ich", "such'", "auch", "nichts", "mehr", "bey", "der", "Welt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PIS", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Der Orden, welcher mir gef\u00e4llt,", "tokens": ["Der", "Or\u00b7den", ",", "wel\u00b7cher", "mir", "ge\u00b7f\u00e4llt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ist nur allein des Kreutzes Orden.", "tokens": ["Ist", "nur", "al\u00b7lein", "des", "Kreut\u00b7zes", "Or\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}