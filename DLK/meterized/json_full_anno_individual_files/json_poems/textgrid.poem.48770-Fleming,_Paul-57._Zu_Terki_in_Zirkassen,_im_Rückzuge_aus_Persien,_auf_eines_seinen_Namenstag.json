{"textgrid.poem.48770": {"metadata": {"author": {"name": "Fleming, Paul", "birth": "N.A.", "death": "N.A."}, "title": "57. Zu Terki in Zirkassen, im R\u00fcckzuge aus Persien, auf eines seinen Namenstag", "genre": "verse", "period": "N.A.", "pub_year": 1624, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Auf hundert Ach und Weh, auf tausend Not und M\u00fchen,", "tokens": ["Auf", "hun\u00b7dert", "Ach", "und", "Weh", ",", "auf", "tau\u00b7send", "Not", "und", "M\u00fc\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "CARD", "NN", "KON", "NN", "$,", "APPR", "CARD", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "auf hunderttausend Leid k\u00f6mt ein Tag endlich her,", "tokens": ["auf", "hun\u00b7dert\u00b7tau\u00b7send", "Leid", "k\u00f6mt", "ein", "Tag", "end\u00b7lich", "her", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "CARD", "NN", "VVFIN", "ART", "NN", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "der alles Ach und Weh, Not, M\u00fche, Leid, Beschwer", "tokens": ["der", "al\u00b7les", "Ach", "und", "Weh", ",", "Not", ",", "M\u00fc\u00b7he", ",", "Leid", ",", "Be\u00b7schwer"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word"], "pos": ["ART", "PIAT", "NN", "KON", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "auf einmal uns benimt. Ihr, G\u00f6tter, habts verliehen,", "tokens": ["auf", "ein\u00b7mal", "uns", "be\u00b7nimt", ".", "Ihr", ",", "G\u00f6t\u00b7ter", ",", "habts", "ver\u00b7lie\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ADV", "PPER", "VVFIN", "$.", "PPER", "$,", "NN", "$,", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "da\u00df wir nun sehn vor uns ein neues Gl\u00fccke bl\u00fchen.", "tokens": ["da\u00df", "wir", "nun", "sehn", "vor", "uns", "ein", "neu\u00b7es", "Gl\u00fc\u00b7cke", "bl\u00fc\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VVINF", "APPR", "PPER", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der Weg ist \u00fcberhalb, es k\u00f6mt nicht ohngef\u00e4hr,", "tokens": ["Der", "Weg", "ist", "\u00fc\u00b7ber\u00b7halb", ",", "es", "k\u00f6mt", "nicht", "ohn\u00b7ge\u00b7f\u00e4hr", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "$,", "PPER", "VVFIN", "PTKNEG", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "da\u00df wir noch alle stehn und k\u00f6nnen nach Begehr", "tokens": ["da\u00df", "wir", "noch", "al\u00b7le", "stehn", "und", "k\u00f6n\u00b7nen", "nach", "Be\u00b7gehr"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "PIS", "VVINF", "KON", "VMFIN", "APPR", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "in unser Vaterland, das liebe, wieder ziehen.", "tokens": ["in", "un\u00b7ser", "Va\u00b7ter\u00b7land", ",", "das", "lie\u00b7be", ",", "wie\u00b7der", "zie\u00b7hen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "PDS", "VVFIN", "$,", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Sei, Bruder, froh mit uns und stell' uns an ein Fest.", "tokens": ["Sei", ",", "Bru\u00b7der", ",", "froh", "mit", "uns", "und", "stell'", "uns", "an", "ein", "Fest", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "$,", "NN", "$,", "ADJD", "APPR", "PPER", "KON", "VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Denn da\u00df uns auch f\u00fcr dich Gott heut ihm danken l\u00e4\u00dft,", "tokens": ["Denn", "da\u00df", "uns", "auch", "f\u00fcr", "dich", "Gott", "heut", "ihm", "dan\u00b7ken", "l\u00e4\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "APPR", "PPER", "NN", "ADV", "PPER", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "das tut er ihm zu Ehr' und dir und uns zu Gl\u00fccke.", "tokens": ["das", "tut", "er", "ihm", "zu", "Ehr'", "und", "dir", "und", "uns", "zu", "Gl\u00fc\u00b7cke", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "PPER", "APPR", "NN", "KON", "PPER", "KON", "PPER", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "So feire deinen Tag und schaff uns Lust genung.", "tokens": ["So", "fei\u00b7re", "dei\u00b7nen", "Tag", "und", "schaff", "uns", "Lust", "ge\u00b7nung", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "KON", "VVFIN", "PPER", "NN", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Greif hurtig in das Geld; es geht nunmehr zur\u00fccke.", "tokens": ["Greif", "hur\u00b7tig", "in", "das", "Geld", ";", "es", "geht", "nun\u00b7mehr", "zu\u00b7r\u00fc\u00b7cke", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADJD", "APPR", "ART", "NN", "$.", "PPER", "VVFIN", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Auf eine reiche Frau ist di\u00df der erste Sprung.", "tokens": ["Auf", "ei\u00b7ne", "rei\u00b7che", "Frau", "ist", "di\u00df", "der", "ers\u00b7te", "Sprung", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VAFIN", "PDS", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Auf hundert Ach und Weh, auf tausend Not und M\u00fchen,", "tokens": ["Auf", "hun\u00b7dert", "Ach", "und", "Weh", ",", "auf", "tau\u00b7send", "Not", "und", "M\u00fc\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "CARD", "NN", "KON", "NN", "$,", "APPR", "CARD", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "auf hunderttausend Leid k\u00f6mt ein Tag endlich her,", "tokens": ["auf", "hun\u00b7dert\u00b7tau\u00b7send", "Leid", "k\u00f6mt", "ein", "Tag", "end\u00b7lich", "her", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "CARD", "NN", "VVFIN", "ART", "NN", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "der alles Ach und Weh, Not, M\u00fche, Leid, Beschwer", "tokens": ["der", "al\u00b7les", "Ach", "und", "Weh", ",", "Not", ",", "M\u00fc\u00b7he", ",", "Leid", ",", "Be\u00b7schwer"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word"], "pos": ["ART", "PIAT", "NN", "KON", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "auf einmal uns benimt. Ihr, G\u00f6tter, habts verliehen,", "tokens": ["auf", "ein\u00b7mal", "uns", "be\u00b7nimt", ".", "Ihr", ",", "G\u00f6t\u00b7ter", ",", "habts", "ver\u00b7lie\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ADV", "PPER", "VVFIN", "$.", "PPER", "$,", "NN", "$,", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "da\u00df wir nun sehn vor uns ein neues Gl\u00fccke bl\u00fchen.", "tokens": ["da\u00df", "wir", "nun", "sehn", "vor", "uns", "ein", "neu\u00b7es", "Gl\u00fc\u00b7cke", "bl\u00fc\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VVINF", "APPR", "PPER", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der Weg ist \u00fcberhalb, es k\u00f6mt nicht ohngef\u00e4hr,", "tokens": ["Der", "Weg", "ist", "\u00fc\u00b7ber\u00b7halb", ",", "es", "k\u00f6mt", "nicht", "ohn\u00b7ge\u00b7f\u00e4hr", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "$,", "PPER", "VVFIN", "PTKNEG", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "da\u00df wir noch alle stehn und k\u00f6nnen nach Begehr", "tokens": ["da\u00df", "wir", "noch", "al\u00b7le", "stehn", "und", "k\u00f6n\u00b7nen", "nach", "Be\u00b7gehr"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "PIS", "VVINF", "KON", "VMFIN", "APPR", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "in unser Vaterland, das liebe, wieder ziehen.", "tokens": ["in", "un\u00b7ser", "Va\u00b7ter\u00b7land", ",", "das", "lie\u00b7be", ",", "wie\u00b7der", "zie\u00b7hen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "PDS", "VVFIN", "$,", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Sei, Bruder, froh mit uns und stell' uns an ein Fest.", "tokens": ["Sei", ",", "Bru\u00b7der", ",", "froh", "mit", "uns", "und", "stell'", "uns", "an", "ein", "Fest", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "$,", "NN", "$,", "ADJD", "APPR", "PPER", "KON", "VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Denn da\u00df uns auch f\u00fcr dich Gott heut ihm danken l\u00e4\u00dft,", "tokens": ["Denn", "da\u00df", "uns", "auch", "f\u00fcr", "dich", "Gott", "heut", "ihm", "dan\u00b7ken", "l\u00e4\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "APPR", "PPER", "NN", "ADV", "PPER", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "das tut er ihm zu Ehr' und dir und uns zu Gl\u00fccke.", "tokens": ["das", "tut", "er", "ihm", "zu", "Ehr'", "und", "dir", "und", "uns", "zu", "Gl\u00fc\u00b7cke", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "PPER", "APPR", "NN", "KON", "PPER", "KON", "PPER", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "So feire deinen Tag und schaff uns Lust genung.", "tokens": ["So", "fei\u00b7re", "dei\u00b7nen", "Tag", "und", "schaff", "uns", "Lust", "ge\u00b7nung", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "KON", "VVFIN", "PPER", "NN", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Greif hurtig in das Geld; es geht nunmehr zur\u00fccke.", "tokens": ["Greif", "hur\u00b7tig", "in", "das", "Geld", ";", "es", "geht", "nun\u00b7mehr", "zu\u00b7r\u00fc\u00b7cke", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADJD", "APPR", "ART", "NN", "$.", "PPER", "VVFIN", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Auf eine reiche Frau ist di\u00df der erste Sprung.", "tokens": ["Auf", "ei\u00b7ne", "rei\u00b7che", "Frau", "ist", "di\u00df", "der", "ers\u00b7te", "Sprung", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VAFIN", "PDS", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}