{"dta.poem.19624": {"metadata": {"author": {"name": "Meyer, Conrad Ferdinand", "birth": "N.A.", "death": "N.A."}, "title": "Das Auge des Blinden.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1882", "urn": "urn:nbn:de:kobv:b4-200905193933", "language": ["de:0.99"], "booktitle": "Meyer, Conrad Ferdinand: Gedichte. Leipzig, 1882."}, "poem": {"stanza.1": {"line.1": {"text": "Durch das Marktgedr\u00e4ng von Namur", "tokens": ["Durch", "das", "Markt\u00b7ge\u00b7dr\u00e4ng", "von", "Na\u00b7mur"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "APPR", "NN"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Stelzt ein narb'ger armer Kr\u00fcppel.", "tokens": ["Stelzt", "ein", "na\u00b7rb'\u00b7ger", "ar\u00b7mer", "Kr\u00fcp\u00b7pel", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "\u2014 \u201eLeute, bringt mich zu Don Juan!\u201c", "tokens": ["\u201e", "Leu\u00b7te", ",", "bringt", "mich", "zu", "Don", "Juan", "!", "\u201c"], "token_info": ["punct", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "$(", "NN", "$,", "VVFIN", "PPER", "APPR", "NE", "NE", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "\u2014 \u201eSchweigst du wohl, da ist Don Juan!\u201c", "tokens": ["\u201e", "Schweigst", "du", "wohl", ",", "da", "ist", "Don", "Juan", "!", "\u201c"], "token_info": ["punct", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "$(", "VVFIN", "PPER", "ADV", "$,", "ADV", "VAFIN", "NE", "NE", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "\u201eschweigst du wohl, da ist Don Juan!\u201c", "tokens": ["\u201e", "schweigst", "du", "wohl", ",", "da", "ist", "Don", "Juan", "!", "\u201c"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VVFIN", "PPER", "ADV", "$,", "ADV", "VAFIN", "NE", "NE", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "In des Volkes Gasse reitet", "tokens": ["In", "des", "Vol\u00b7kes", "Gas\u00b7se", "rei\u00b7tet"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Ein Gespenst am hellen Tage:", "tokens": ["Ein", "Ge\u00b7spenst", "am", "hel\u00b7len", "Ta\u00b7ge", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Don Juan der Oesterreicher \u2014", "tokens": ["Don", "Juan", "der", "O\u00b7es\u00b7ter\u00b7rei\u00b7cher"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "ART", "NN", "$("], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.3": {"line.1": {"text": "Don Juan der Oesterreicher,", "tokens": ["Don", "Juan", "der", "O\u00b7es\u00b7ter\u00b7rei\u00b7cher", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "ART", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Der im Wein das Gift getrunken", "tokens": ["Der", "im", "Wein", "das", "Gift", "ge\u00b7trun\u00b7ken"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "APPRART", "NN", "ART", "NN", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "K\u00f6nig Philipps, seines Bruders,", "tokens": ["K\u00f6\u00b7nig", "Phi\u00b7lipps", ",", "sei\u00b7nes", "Bru\u00b7ders", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und Don Juan kennt den M\u00f6rder.", "tokens": ["Und", "Don", "Juan", "kennt", "den", "M\u00f6r\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "NE", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Seinen M\u00f6rder kennt Don Juan,", "tokens": ["Sei\u00b7nen", "M\u00f6r\u00b7der", "kennt", "Don", "Juan", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "NE", "NE", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Auch den armen Kr\u00fcppel kennt er,", "tokens": ["Auch", "den", "ar\u00b7men", "Kr\u00fcp\u00b7pel", "kennt", "er", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "VVFIN", "PPER", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Der den B\u00fcgel ihm betastet,", "tokens": ["Der", "den", "B\u00fc\u00b7gel", "ihm", "be\u00b7tas\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Der die Hand ihm deckt mit K\u00fcssen \u2014", "tokens": ["Der", "die", "Hand", "ihm", "deckt", "mit", "K\u00fcs\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "PPER", "VVFIN", "APPR", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Der ihm deckt die Hand mit K\u00fcssen:", "tokens": ["Der", "ihm", "deckt", "die", "Hand", "mit", "K\u00fcs\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVFIN", "ART", "NN", "APPR", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "\u201ebin zerfetzt wie eine Fahne!", "tokens": ["\u201e", "bin", "zer\u00b7fetzt", "wie", "ei\u00b7ne", "Fah\u00b7ne", "!"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VAFIN", "VVPP", "KOKOM", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wohne jetzt in Barcelona \u2014", "tokens": ["Woh\u00b7ne", "jetzt", "in", "Bar\u00b7ce\u00b7lo\u00b7na"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "APPR", "NE", "$("], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Braves Volk, bei meiner Ehre!", "tokens": ["Bra\u00b7ves", "Volk", ",", "bei", "mei\u00b7ner", "Eh\u00b7re", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Braves Volk, bei meiner Ehre:", "tokens": ["Bra\u00b7ves", "Volk", ",", "bei", "mei\u00b7ner", "Eh\u00b7re", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "\u201ealter, leere dieses Glas mir!\u201c", "tokens": ["\u201e", "al\u00b7ter", ",", "lee\u00b7re", "die\u00b7ses", "Glas", "mir", "!", "\u201c"], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADJA", "$,", "ADJA", "PDAT", "NN", "PPER", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "\u201ealter, kanntest du Don Juan?\u201c", "tokens": ["\u201e", "al\u00b7ter", ",", "kann\u00b7test", "du", "Don", "Juan", "?", "\u201c"], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADJA", "$,", "VVFIN", "PPER", "NE", "NE", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "\u201esprich uns immer von Don Juan!\u201c", "tokens": ["\u201e", "sprich", "uns", "im\u00b7mer", "von", "Don", "Juan", "!", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VVIMP", "PPER", "ADV", "APPR", "NE", "NE", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Immer sprech' ich von Don Juan!", "tokens": ["Im\u00b7mer", "sprech'", "ich", "von", "Don", "Juan", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "NE", "NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "In den Schenken an dem Hafen", "tokens": ["In", "den", "Schen\u00b7ken", "an", "dem", "Ha\u00b7fen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Gab ich tausendmal zum Besten", "tokens": ["Gab", "ich", "tau\u00b7send\u00b7mal", "zum", "Bes\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "APPRART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Die Victoria von Lepanto!", "tokens": ["Die", "Vic\u00b7to\u00b7ria", "von", "Le\u00b7pan\u00b7to", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Die Victoria von Lepanto", "tokens": ["Die", "Vic\u00b7to\u00b7ria", "von", "Le\u00b7pan\u00b7to"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Gab ich tausendmal zum Besten ...", "tokens": ["Gab", "ich", "tau\u00b7send\u00b7mal", "zum", "Bes\u00b7ten", "..."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "APPRART", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Hergestelzt bin ich nach Flandern", "tokens": ["Her\u00b7ge\u00b7stelzt", "bin", "ich", "nach", "Flan\u00b7dern"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVPP", "VAFIN", "PPER", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Zu dem Abgott meines Lebens!", "tokens": ["Zu", "dem", "Ab\u00b7gott", "mei\u00b7nes", "Le\u00b7bens", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "O Du Freude meines Lebens!", "tokens": ["O", "Du", "Freu\u00b7de", "mei\u00b7nes", "Le\u00b7bens", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "NN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sohn des Kaisers! Kind des Gl\u00fcckes!", "tokens": ["Sohn", "des", "Kai\u00b7sers", "!", "Kind", "des", "Gl\u00fc\u00b7ckes", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "$.", "NN", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Deines Volkes Held und Liebling!", "tokens": ["Dei\u00b7nes", "Vol\u00b7kes", "Held", "und", "Lieb\u00b7ling", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "NN", "KON", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ruhmgekr\u00f6nter junger Feldherr!", "tokens": ["Ruhm\u00b7ge\u00b7kr\u00f6n\u00b7ter", "jun\u00b7ger", "Feld\u00b7herr", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Ruhmgekr\u00f6nter junger Feldherr", "tokens": ["Ruhm\u00b7ge\u00b7kr\u00f6n\u00b7ter", "jun\u00b7ger", "Feld\u00b7herr"], "token_info": ["word", "word", "word"], "pos": ["NN", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Mit den goldnen Ringelhaaren,", "tokens": ["Mit", "den", "gold\u00b7nen", "Rin\u00b7gel\u00b7haa\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Mit den strahlend blauen Augen,", "tokens": ["Mit", "den", "strah\u00b7lend", "blau\u00b7en", "Au\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJD", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Eia sch\u00f6ner Engel Gottes!", "tokens": ["Ei\u00b7a", "sch\u00f6\u00b7ner", "En\u00b7gel", "Got\u00b7tes", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Eia sch\u00f6ner Engel Gottes ...\u201c", "tokens": ["Ei\u00b7a", "sch\u00f6\u00b7ner", "En\u00b7gel", "Got\u00b7tes", "...", "\u201c"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "ADJA", "NN", "NN", "$(", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Durch die Menge die des Todes", "tokens": ["Durch", "die", "Men\u00b7ge", "die", "des", "To\u00b7des"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ART", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Bild betrachtet, geht ein Schauder.", "tokens": ["Bild", "be\u00b7trach\u00b7tet", ",", "geht", "ein", "Schau\u00b7der", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VVPP", "$,", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Juan der gespenstig bleiche,", "tokens": ["Juan", "der", "ge\u00b7spens\u00b7tig", "blei\u00b7che", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "ART", "ADJD", "VVFIN", "$,"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}}, "stanza.12": {"line.1": {"text": "Juan der gespenstig bleiche", "tokens": ["Juan", "der", "ge\u00b7spens\u00b7tig", "blei\u00b7che"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "ART", "ADJD", "ADJA"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.2": {"text": "Sucht erstaunt das Aug des Kr\u00fcppels \u2014", "tokens": ["Sucht", "er\u00b7staunt", "das", "Aug", "des", "Kr\u00fcp\u00b7pels"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "ART", "NN", "ART", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Ist es trunken? Loht's im Wahnsinn?", "tokens": ["Ist", "es", "trun\u00b7ken", "?", "Loht's", "im", "Wahn\u00b7sinn", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADJD", "$.", "NE", "APPRART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Es ist leer. Es ist erloschen.", "tokens": ["Es", "ist", "leer", ".", "Es", "ist", "er\u00b7lo\u00b7schen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "$.", "PPER", "VAFIN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Es ist leer. Es ist erloschen.", "tokens": ["Es", "ist", "leer", ".", "Es", "ist", "er\u00b7lo\u00b7schen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "$.", "PPER", "VAFIN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Don Juans zerst\u00f6rte Jugend", "tokens": ["Don", "Ju\u00b7ans", "zer\u00b7st\u00f6r\u00b7te", "Ju\u00b7gend"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "NE", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Bl\u00fcht in eines Blinden Auge", "tokens": ["Bl\u00fcht", "in", "ei\u00b7nes", "Blin\u00b7den", "Au\u00b7ge"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Fort in unversehrter Sch\u00f6nheit.", "tokens": ["Fort", "in", "un\u00b7ver\u00b7sehr\u00b7ter", "Sch\u00f6n\u00b7heit", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}}}}