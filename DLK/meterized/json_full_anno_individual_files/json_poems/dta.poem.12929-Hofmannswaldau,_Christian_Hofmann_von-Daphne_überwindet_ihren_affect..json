{"dta.poem.12929": {"metadata": {"author": {"name": "Hofmannswaldau, Christian Hofmann von", "birth": "N.A.", "death": "N.A."}, "title": "Daphne \u00fcberwindet ihren affect.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1710", "urn": "urn:nbn:de:kobv:b4-20284-0", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Als Thyrsis sich den guckguck reiten lie\u00df", "tokens": ["Als", "Thyr\u00b7sis", "sich", "den", "guck\u00b7guck", "rei\u00b7ten", "lie\u00df"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "NE", "PRF", "ART", "NN", "VVFIN", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Die muntre Sylvia zu lieben,", "tokens": ["Die", "mun\u00b7tre", "Syl\u00b7via", "zu", "lie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NE", "PTKZU", "VVINF", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Wie konnte Daphnen das betr\u00fcben!", "tokens": ["Wie", "konn\u00b7te", "Daph\u00b7nen", "das", "be\u00b7tr\u00fc\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "NN", "ART", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Es trieb die traurigkeit sie in das paradies,", "tokens": ["Es", "trieb", "die", "trau\u00b7rig\u00b7keit", "sie", "in", "das", "pa\u00b7ra\u00b7dies", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und stie\u00df am ufer ihr die w\u00f6rter von dem mund:", "tokens": ["Und", "stie\u00df", "am", "u\u00b7fer", "ihr", "die", "w\u00f6r\u00b7ter", "von", "dem", "mund", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPRART", "NN", "PPER", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Abtr\u00fcnniger, verlogner, falscher hund!", "tokens": ["Ab\u00b7tr\u00fcn\u00b7ni\u00b7ger", ",", "ver\u00b7log\u00b7ner", ",", "fal\u00b7scher", "hund", "!"], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "ADJA", "$,", "ADJA", "NN", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.7": {"text": "Machst du nach so viel theuren schw\u00fcren,", "tokens": ["Machst", "du", "nach", "so", "viel", "theu\u00b7ren", "schw\u00fc\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ADV", "PIAT", "ADJA", "VVINF", "$,"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.8": {"text": "Dir kein gewissen nicht, mich hinters licht zu f\u00fchren?", "tokens": ["Dir", "kein", "ge\u00b7wis\u00b7sen", "nicht", ",", "mich", "hin\u00b7ters", "licht", "zu", "f\u00fch\u00b7ren", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PIAT", "VAPP", "PTKNEG", "$,", "PPER", "ADV", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "So reisse dieser strom mich aus der angst und schande!", "tokens": ["So", "reis\u00b7se", "die\u00b7ser", "strom", "mich", "aus", "der", "angst", "und", "schan\u00b7de", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PDS", "VVFIN", "PRF", "APPR", "ART", "NN", "KON", "ADJA", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Hiermit erhob sie sich, der fu\u00df war schon am strande,", "tokens": ["Hier\u00b7mit", "er\u00b7hob", "sie", "sich", ",", "der", "fu\u00df", "war", "schon", "am", "stran\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "$,", "PRELS", "PTKVZ", "VAFIN", "ADV", "APPRART", "ADJA", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Und zum absprung ausgestreckt;", "tokens": ["Und", "zum", "ab\u00b7sprung", "aus\u00b7ge\u00b7streckt", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.12": {"text": "Doch als der nahe tod ein grausen ihr erweckt,", "tokens": ["Doch", "als", "der", "na\u00b7he", "tod", "ein", "grau\u00b7sen", "ihr", "er\u00b7weckt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "ADJA", "NN", "ART", "ADJA", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "So zog sie zitternde den zarten fu\u00df zur\u00fccke,", "tokens": ["So", "zog", "sie", "zit\u00b7tern\u00b7de", "den", "zar\u00b7ten", "fu\u00df", "zu\u00b7r\u00fc\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "VVFIN", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Und rief: Bin ich nicht tumm? es sind zu gutem gl\u00fccke", "tokens": ["Und", "rief", ":", "Bin", "ich", "nicht", "tumm", "?", "es", "sind", "zu", "gu\u00b7tem", "gl\u00fc\u00b7cke"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "$.", "VAFIN", "PPER", "PTKNEG", "ADJD", "$.", "PPER", "VAFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Ja noch viel hirten da,", "tokens": ["Ja", "noch", "viel", "hir\u00b7ten", "da", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "ADV", "ADV", "VVFIN", "ADV", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.16": {"text": "K\u00fc\u00dft Thyrsis gleich itzund die Sylvia;", "tokens": ["K\u00fc\u00dft", "Thyr\u00b7sis", "gleich", "it\u00b7zund", "die", "Syl\u00b7via", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "ADV", "ADV", "ART", "NE", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.17": {"text": "Es kan vor mich noch hundert buhler geben,", "tokens": ["Es", "kan", "vor", "mich", "noch", "hun\u00b7dert", "buh\u00b7ler", "ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPR", "PPER", "ADV", "CARD", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.18": {"text": "Ich aber habe doch mehr nicht als nur ein leben.", "tokens": ["Ich", "a\u00b7ber", "ha\u00b7be", "doch", "mehr", "nicht", "als", "nur", "ein", "le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VAFIN", "ADV", "ADV", "PTKNEG", "KOKOM", "ADV", "ART", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}