{"textgrid.poem.47175": {"metadata": {"author": {"name": "R\u00fcckert, Friedrich", "birth": "N.A.", "death": "N.A."}, "title": "1L: Meinem Vater mu\u00df ich's danken,", "genre": "verse", "period": "N.A.", "pub_year": 1827, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Meinem Vater mu\u00df ich's danken,", "tokens": ["Mei\u00b7nem", "Va\u00b7ter", "mu\u00df", "ich's", "dan\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VMFIN", "PIS", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Der nunmehr im Grabe ruht,", "tokens": ["Der", "nun\u00b7mehr", "im", "Gra\u00b7be", "ruht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPRART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df er nie die k\u00fchnen Ranken", "tokens": ["Da\u00df", "er", "nie", "die", "k\u00fch\u00b7nen", "Ran\u00b7ken"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Stutzte meinem Jugendmut.", "tokens": ["Stutz\u00b7te", "mei\u00b7nem", "Ju\u00b7gend\u00b7mut", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Ihm im Grabe mu\u00df ich's danken,", "tokens": ["Ihm", "im", "Gra\u00b7be", "mu\u00df", "ich's", "dan\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPRART", "NN", "VMFIN", "PIS", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Da\u00df er meine Poesie", "tokens": ["Da\u00df", "er", "mei\u00b7ne", "Poe\u00b7sie"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PPOSAT", "NN"], "meter": "+-+---", "measure": "unknown.measure.di"}, "line.3": {"text": "Nie begriff und gleichwohl Schranken", "tokens": ["Nie", "be\u00b7griff", "und", "gleich\u00b7wohl", "Schran\u00b7ken"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "KON", "ADV", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Des Verbots ihr setzte nie.", "tokens": ["Des", "Ver\u00b7bots", "ihr", "setz\u00b7te", "nie", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPER", "VVFIN", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Zwar ich w\u00fcrd' es auch ihm danken,", "tokens": ["Zwar", "ich", "w\u00fcrd'", "es", "auch", "ihm", "dan\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VAFIN", "PPER", "ADV", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "H\u00e4tt' er Schranken ihr gesetzt;", "tokens": ["H\u00e4tt'", "er", "Schran\u00b7ken", "ihr", "ge\u00b7setzt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "PPER", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Denn statt unfruchtbarer Ranken", "tokens": ["Denn", "statt", "un\u00b7frucht\u00b7ba\u00b7rer", "Ran\u00b7ken"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPR", "ADJA", "NN"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.4": {"text": "Tr\u00fcg' ich andre Fr\u00fcchte jetzt.", "tokens": ["Tr\u00fcg'", "ich", "and\u00b7re", "Fr\u00fcch\u00b7te", "jetzt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJA", "NN", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Doch nun sei auf seinem Grabe", "tokens": ["Doch", "nun", "sei", "auf", "sei\u00b7nem", "Gra\u00b7be"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VAFIN", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ihm zum Opfer hingestreut", "tokens": ["Ihm", "zum", "Op\u00b7fer", "hin\u00b7ge\u00b7streut"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "APPRART", "NN", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Meine beste Liedergabe,", "tokens": ["Mei\u00b7ne", "bes\u00b7te", "Lie\u00b7der\u00b7ga\u00b7be", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wie sie jeder Lenz erneut; \u2013", "tokens": ["Wie", "sie", "je\u00b7der", "Lenz", "er\u00b7neut", ";", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWAV", "PPER", "PIAT", "NN", "VVFIN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Der an meine Sendung glaubte,", "tokens": ["Der", "an", "mei\u00b7ne", "Sen\u00b7dung", "glaub\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Deren Zweck er nicht verstand,", "tokens": ["De\u00b7ren", "Zweck", "er", "nicht", "ver\u00b7stand", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "NN", "PPER", "PTKNEG", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Dem es nicht den Glauben raubte,", "tokens": ["Dem", "es", "nicht", "den", "Glau\u00b7ben", "raub\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "PTKNEG", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Da\u00df sie keinen Glauben fand.", "tokens": ["Da\u00df", "sie", "kei\u00b7nen", "Glau\u00b7ben", "fand", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Da\u00df ich fr\u00fch die Lorbeerkrone", "tokens": ["Da\u00df", "ich", "fr\u00fch", "die", "Lor\u00b7beer\u00b7kro\u00b7ne"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADJD", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Nicht ersungen, geht mir nah'", "tokens": ["Nicht", "er\u00b7sun\u00b7gen", ",", "geht", "mir", "nah'"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PTKNEG", "VVPP", "$,", "VVFIN", "PPER", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Darum nur, da\u00df er dem Sohne", "tokens": ["Da\u00b7rum", "nur", ",", "da\u00df", "er", "dem", "Soh\u00b7ne"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PAV", "ADV", "$,", "KOUS", "PPER", "ART", "NN"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.4": {"text": "Sie nicht auf der Scheitel sah.", "tokens": ["Sie", "nicht", "auf", "der", "Schei\u00b7tel", "sah", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKNEG", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.7": {"line.1": {"text": "Sollt' ich sie noch sp\u00e4t ersingen,", "tokens": ["Sollt'", "ich", "sie", "noch", "sp\u00e4t", "er\u00b7sin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PPER", "ADV", "ADJD", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "W\u00e4re das mein sch\u00f6nster Lohn,", "tokens": ["W\u00e4\u00b7re", "das", "mein", "sch\u00f6ns\u00b7ter", "Lohn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PDS", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df du Totenopfer bringen", "tokens": ["Da\u00df", "du", "To\u00b7ten\u00b7op\u00b7fer", "brin\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PPER", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "S\u00e4hest den bekr\u00e4nzten Sohn.", "tokens": ["S\u00e4\u00b7hest", "den", "be\u00b7kr\u00e4nz\u00b7ten", "Sohn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Meinem Vater mu\u00df ich's danken,", "tokens": ["Mei\u00b7nem", "Va\u00b7ter", "mu\u00df", "ich's", "dan\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VMFIN", "PIS", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Der nunmehr im Grabe ruht,", "tokens": ["Der", "nun\u00b7mehr", "im", "Gra\u00b7be", "ruht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPRART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df er nie die k\u00fchnen Ranken", "tokens": ["Da\u00df", "er", "nie", "die", "k\u00fch\u00b7nen", "Ran\u00b7ken"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Stutzte meinem Jugendmut.", "tokens": ["Stutz\u00b7te", "mei\u00b7nem", "Ju\u00b7gend\u00b7mut", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Ihm im Grabe mu\u00df ich's danken,", "tokens": ["Ihm", "im", "Gra\u00b7be", "mu\u00df", "ich's", "dan\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPRART", "NN", "VMFIN", "PIS", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Da\u00df er meine Poesie", "tokens": ["Da\u00df", "er", "mei\u00b7ne", "Poe\u00b7sie"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PPOSAT", "NN"], "meter": "+-+---", "measure": "unknown.measure.di"}, "line.3": {"text": "Nie begriff und gleichwohl Schranken", "tokens": ["Nie", "be\u00b7griff", "und", "gleich\u00b7wohl", "Schran\u00b7ken"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "KON", "ADV", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Des Verbots ihr setzte nie.", "tokens": ["Des", "Ver\u00b7bots", "ihr", "setz\u00b7te", "nie", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPER", "VVFIN", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Zwar ich w\u00fcrd' es auch ihm danken,", "tokens": ["Zwar", "ich", "w\u00fcrd'", "es", "auch", "ihm", "dan\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VAFIN", "PPER", "ADV", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "H\u00e4tt' er Schranken ihr gesetzt;", "tokens": ["H\u00e4tt'", "er", "Schran\u00b7ken", "ihr", "ge\u00b7setzt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "PPER", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Denn statt unfruchtbarer Ranken", "tokens": ["Denn", "statt", "un\u00b7frucht\u00b7ba\u00b7rer", "Ran\u00b7ken"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPR", "ADJA", "NN"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.4": {"text": "Tr\u00fcg' ich andre Fr\u00fcchte jetzt.", "tokens": ["Tr\u00fcg'", "ich", "and\u00b7re", "Fr\u00fcch\u00b7te", "jetzt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJA", "NN", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Doch nun sei auf seinem Grabe", "tokens": ["Doch", "nun", "sei", "auf", "sei\u00b7nem", "Gra\u00b7be"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VAFIN", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ihm zum Opfer hingestreut", "tokens": ["Ihm", "zum", "Op\u00b7fer", "hin\u00b7ge\u00b7streut"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "APPRART", "NN", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Meine beste Liedergabe,", "tokens": ["Mei\u00b7ne", "bes\u00b7te", "Lie\u00b7der\u00b7ga\u00b7be", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wie sie jeder Lenz erneut; \u2013", "tokens": ["Wie", "sie", "je\u00b7der", "Lenz", "er\u00b7neut", ";", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWAV", "PPER", "PIAT", "NN", "VVFIN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Der an meine Sendung glaubte,", "tokens": ["Der", "an", "mei\u00b7ne", "Sen\u00b7dung", "glaub\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Deren Zweck er nicht verstand,", "tokens": ["De\u00b7ren", "Zweck", "er", "nicht", "ver\u00b7stand", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "NN", "PPER", "PTKNEG", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Dem es nicht den Glauben raubte,", "tokens": ["Dem", "es", "nicht", "den", "Glau\u00b7ben", "raub\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "PTKNEG", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Da\u00df sie keinen Glauben fand.", "tokens": ["Da\u00df", "sie", "kei\u00b7nen", "Glau\u00b7ben", "fand", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Da\u00df ich fr\u00fch die Lorbeerkrone", "tokens": ["Da\u00df", "ich", "fr\u00fch", "die", "Lor\u00b7beer\u00b7kro\u00b7ne"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADJD", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Nicht ersungen, geht mir nah'", "tokens": ["Nicht", "er\u00b7sun\u00b7gen", ",", "geht", "mir", "nah'"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PTKNEG", "VVPP", "$,", "VVFIN", "PPER", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Darum nur, da\u00df er dem Sohne", "tokens": ["Da\u00b7rum", "nur", ",", "da\u00df", "er", "dem", "Soh\u00b7ne"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PAV", "ADV", "$,", "KOUS", "PPER", "ART", "NN"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.4": {"text": "Sie nicht auf der Scheitel sah.", "tokens": ["Sie", "nicht", "auf", "der", "Schei\u00b7tel", "sah", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKNEG", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.14": {"line.1": {"text": "Sollt' ich sie noch sp\u00e4t ersingen,", "tokens": ["Sollt'", "ich", "sie", "noch", "sp\u00e4t", "er\u00b7sin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PPER", "ADV", "ADJD", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "W\u00e4re das mein sch\u00f6nster Lohn,", "tokens": ["W\u00e4\u00b7re", "das", "mein", "sch\u00f6ns\u00b7ter", "Lohn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PDS", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df du Totenopfer bringen", "tokens": ["Da\u00df", "du", "To\u00b7ten\u00b7op\u00b7fer", "brin\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PPER", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "S\u00e4hest den bekr\u00e4nzten Sohn.", "tokens": ["S\u00e4\u00b7hest", "den", "be\u00b7kr\u00e4nz\u00b7ten", "Sohn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}