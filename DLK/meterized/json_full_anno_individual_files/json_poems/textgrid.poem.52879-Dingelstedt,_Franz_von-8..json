{"textgrid.poem.52879": {"metadata": {"author": {"name": "Dingelstedt, Franz von", "birth": "N.A.", "death": "N.A."}, "title": "8.", "genre": "verse", "period": "N.A.", "pub_year": 1847, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Kamerad, wen f\u00e4hrst du? \u2013 \u00bbDen Minister.\u00ab \u2013", "tokens": ["Ka\u00b7me\u00b7rad", ",", "wen", "f\u00e4hrst", "du", "?", "\u2013", "\u00bb", "Den", "Mi\u00b7nis\u00b7ter", ".", "\u00ab", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "punct", "punct", "punct", "word", "word", "punct", "punct", "punct"], "pos": ["NN", "$,", "PWS", "VVFIN", "PPER", "$.", "$(", "$(", "ART", "NN", "$.", "$(", "$("], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Und darum so barsch, so stolz getan?", "tokens": ["Und", "da\u00b7rum", "so", "barsch", ",", "so", "stolz", "ge\u00b7tan", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PAV", "ADV", "ADJD", "$,", "ADV", "ADJD", "VVPP", "$."], "meter": "--+-+-+-+", "measure": "anapaest.init"}, "line.3": {"text": "Den hab' ich schon lang auf meinem Register,", "tokens": ["Den", "hab'", "ich", "schon", "lang", "auf", "mei\u00b7nem", "Re\u00b7gis\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PPER", "ADV", "ADJD", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+--+-", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Soll auch mit n\u00e4chstem sein St\u00e4ndchen ha'n!", "tokens": ["Soll", "auch", "mit", "n\u00e4chs\u00b7tem", "sein", "St\u00e4nd\u00b7chen", "ha'n", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "APPR", "ADJA", "PPOSAT", "NN", "VVINF", "$."], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}}, "stanza.2": {"line.1": {"text": "Da stehen die schmucken, stattlichen Tiere", "tokens": ["Da", "ste\u00b7hen", "die", "schmu\u00b7cken", ",", "statt\u00b7li\u00b7chen", "Tie\u00b7re"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "VVINF", "$,", "ADJA", "NN"], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Vielleicht schon viele Stunden lang,", "tokens": ["Viel\u00b7leicht", "schon", "vie\u00b7le", "Stun\u00b7den", "lang", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PIAT", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sie h\u00e4ngen die K\u00f6pfe alle viere", "tokens": ["Sie", "h\u00e4n\u00b7gen", "die", "K\u00f6p\u00b7fe", "al\u00b7le", "vie\u00b7re"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "PIAT", "PIS"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Und scharren im Schnee und zerren am Strang.", "tokens": ["Und", "schar\u00b7ren", "im", "Schnee", "und", "zer\u00b7ren", "am", "Strang", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPRART", "NN", "KON", "VVFIN", "APPRART", "NN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}}, "stanza.3": {"line.1": {"text": "Den Grobian droben auf hohem Bocke,", "tokens": ["Den", "Gro\u00b7bi\u00b7an", "dro\u00b7ben", "auf", "ho\u00b7hem", "Bo\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Um den tut mir das Warten nicht leid,", "tokens": ["Um", "den", "tut", "mir", "das", "War\u00b7ten", "nicht", "leid", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "ART", "NN", "PPER", "ART", "NN", "PTKNEG", "ADJD", "$,"], "meter": "--+--+--+", "measure": "anapaest.tri.plus"}, "line.3": {"text": "Der sitzt warm in seinem verbr\u00e4mten Rocke,", "tokens": ["Der", "sitzt", "warm", "in", "sei\u00b7nem", "ver\u00b7br\u00e4m\u00b7ten", "Ro\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADJD", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Aber die G\u00e4ule haben kein Kleid,", "tokens": ["A\u00b7ber", "die", "G\u00e4u\u00b7le", "ha\u00b7ben", "kein", "Kleid", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VAFIN", "PIAT", "NN", "$,"], "meter": "+--+-+--+", "measure": "iambic.tetra.invert"}}, "stanza.4": {"line.1": {"text": "Keinen Pelz, in grimmiger K\u00e4lte labend,", "tokens": ["Kei\u00b7nen", "Pelz", ",", "in", "grim\u00b7mi\u00b7ger", "K\u00e4l\u00b7te", "la\u00b7bend", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "$,", "APPR", "ADJA", "NN", "VVPP", "$,"], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.2": {"text": "Und innerlich keinen Branntewein.", "tokens": ["Und", "in\u00b7ner\u00b7lich", "kei\u00b7nen", "Brann\u00b7te\u00b7wein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "PIAT", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Ich sollte nur einmal heute abend", "tokens": ["Ich", "soll\u00b7te", "nur", "ein\u00b7mal", "heu\u00b7te", "a\u00b7bend"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ADV", "ADV", "ADV", "VVPP"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Einer von denen vier Schimmeln sein!", "tokens": ["Ei\u00b7ner", "von", "de\u00b7nen", "vier", "Schim\u00b7meln", "sein", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "APPR", "PRELS", "CARD", "NN", "VAINF", "$."], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}}, "stanza.5": {"line.1": {"text": "Ich wollte mich wehren, ich wollte dich lehren,", "tokens": ["Ich", "woll\u00b7te", "mich", "weh\u00b7ren", ",", "ich", "woll\u00b7te", "dich", "leh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PRF", "VVINF", "$,", "PPER", "VMFIN", "PRF", "VVINF", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.2": {"text": "Herr Exzellenz mit dem Podagra,", "tokens": ["Herr", "Ex\u00b7zel\u00b7lenz", "mit", "dem", "Po\u00b7da\u00b7gra", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Du solltest Gottes Gesch\u00f6pfe ehren", "tokens": ["Du", "soll\u00b7test", "Got\u00b7tes", "Ge\u00b7sch\u00f6p\u00b7fe", "eh\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "NN", "NN", "VVINF"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Und deinesgleichen ... Hallelujah!", "tokens": ["Und", "dei\u00b7nes\u00b7glei\u00b7chen", "...", "Hal\u00b7le\u00b7lu\u00b7jah", "!"], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["KON", "PPOSAT", "$(", "ITJ", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.6": {"line.1": {"text": "Dort sitzt er noch bei seinem Herrn Vetter,", "tokens": ["Dort", "sitzt", "er", "noch", "bei", "sei\u00b7nem", "Herrn", "Vet\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPR", "PPOSAT", "NN", "NE", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "W\u00fchlt in Karten und w\u00fchlt in Geld,", "tokens": ["W\u00fchlt", "in", "Kar\u00b7ten", "und", "w\u00fchlt", "in", "Geld", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "NN", "KON", "VVFIN", "APPR", "NN", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.3": {"text": "Und l\u00e4\u00dft die Tiere in Sturm und Wetter", "tokens": ["Und", "l\u00e4\u00dft", "die", "Tie\u00b7re", "in", "Sturm", "und", "Wet\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ART", "NN", "APPR", "NN", "KON", "NN"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Frieren, so lang' es Gott gef\u00e4llt.", "tokens": ["Frie\u00b7ren", ",", "so", "lang'", "es", "Gott", "ge\u00b7f\u00e4llt", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADV", "ADV", "PPER", "NN", "VVPP", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.7": {"line.1": {"text": "Ich rate dir, la\u00df die Karten ruhen", "tokens": ["Ich", "ra\u00b7te", "dir", ",", "la\u00df", "die", "Kar\u00b7ten", "ru\u00b7hen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "$,", "VVIMP", "ART", "NN", "VVINF"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Und h\u00fcte dich fein, Ministerlein,", "tokens": ["Und", "h\u00fc\u00b7te", "dich", "fein", ",", "Mi\u00b7nis\u00b7ter\u00b7lein", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADJD", "$,", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Du hast es mit vier Hengsten zu tuen,", "tokens": ["Du", "hast", "es", "mit", "vier", "Hengs\u00b7ten", "zu", "tu\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "APPR", "CARD", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Bedenk, da\u00df das keine B\u00fcrger sein!", "tokens": ["Be\u00b7denk", ",", "da\u00df", "das", "kei\u00b7ne", "B\u00fcr\u00b7ger", "sein", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KOUS", "ART", "PIAT", "NN", "VAINF", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.8": {"line.1": {"text": "Kamerad, wen f\u00e4hrst du? \u2013 \u00bbDen Minister.\u00ab \u2013", "tokens": ["Ka\u00b7me\u00b7rad", ",", "wen", "f\u00e4hrst", "du", "?", "\u2013", "\u00bb", "Den", "Mi\u00b7nis\u00b7ter", ".", "\u00ab", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "punct", "punct", "punct", "word", "word", "punct", "punct", "punct"], "pos": ["NN", "$,", "PWS", "VVFIN", "PPER", "$.", "$(", "$(", "ART", "NN", "$.", "$(", "$("], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Und darum so barsch, so stolz getan?", "tokens": ["Und", "da\u00b7rum", "so", "barsch", ",", "so", "stolz", "ge\u00b7tan", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PAV", "ADV", "ADJD", "$,", "ADV", "ADJD", "VVPP", "$."], "meter": "--+-+-+-+", "measure": "anapaest.init"}, "line.3": {"text": "Den hab' ich schon lang auf meinem Register,", "tokens": ["Den", "hab'", "ich", "schon", "lang", "auf", "mei\u00b7nem", "Re\u00b7gis\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PPER", "ADV", "ADJD", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+--+-", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Soll auch mit n\u00e4chstem sein St\u00e4ndchen ha'n!", "tokens": ["Soll", "auch", "mit", "n\u00e4chs\u00b7tem", "sein", "St\u00e4nd\u00b7chen", "ha'n", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "APPR", "ADJA", "PPOSAT", "NN", "VVINF", "$."], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}}, "stanza.9": {"line.1": {"text": "Da stehen die schmucken, stattlichen Tiere", "tokens": ["Da", "ste\u00b7hen", "die", "schmu\u00b7cken", ",", "statt\u00b7li\u00b7chen", "Tie\u00b7re"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "VVINF", "$,", "ADJA", "NN"], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Vielleicht schon viele Stunden lang,", "tokens": ["Viel\u00b7leicht", "schon", "vie\u00b7le", "Stun\u00b7den", "lang", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PIAT", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sie h\u00e4ngen die K\u00f6pfe alle viere", "tokens": ["Sie", "h\u00e4n\u00b7gen", "die", "K\u00f6p\u00b7fe", "al\u00b7le", "vie\u00b7re"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "PIAT", "PIS"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Und scharren im Schnee und zerren am Strang.", "tokens": ["Und", "schar\u00b7ren", "im", "Schnee", "und", "zer\u00b7ren", "am", "Strang", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPRART", "NN", "KON", "VVFIN", "APPRART", "NN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}}, "stanza.10": {"line.1": {"text": "Den Grobian droben auf hohem Bocke,", "tokens": ["Den", "Gro\u00b7bi\u00b7an", "dro\u00b7ben", "auf", "ho\u00b7hem", "Bo\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Um den tut mir das Warten nicht leid,", "tokens": ["Um", "den", "tut", "mir", "das", "War\u00b7ten", "nicht", "leid", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "ART", "NN", "PPER", "ART", "NN", "PTKNEG", "ADJD", "$,"], "meter": "--+--+--+", "measure": "anapaest.tri.plus"}, "line.3": {"text": "Der sitzt warm in seinem verbr\u00e4mten Rocke,", "tokens": ["Der", "sitzt", "warm", "in", "sei\u00b7nem", "ver\u00b7br\u00e4m\u00b7ten", "Ro\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADJD", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Aber die G\u00e4ule haben kein Kleid,", "tokens": ["A\u00b7ber", "die", "G\u00e4u\u00b7le", "ha\u00b7ben", "kein", "Kleid", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VAFIN", "PIAT", "NN", "$,"], "meter": "+--+-+--+", "measure": "iambic.tetra.invert"}}, "stanza.11": {"line.1": {"text": "Keinen Pelz, in grimmiger K\u00e4lte labend,", "tokens": ["Kei\u00b7nen", "Pelz", ",", "in", "grim\u00b7mi\u00b7ger", "K\u00e4l\u00b7te", "la\u00b7bend", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "$,", "APPR", "ADJA", "NN", "VVPP", "$,"], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.2": {"text": "Und innerlich keinen Branntewein.", "tokens": ["Und", "in\u00b7ner\u00b7lich", "kei\u00b7nen", "Brann\u00b7te\u00b7wein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "PIAT", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Ich sollte nur einmal heute abend", "tokens": ["Ich", "soll\u00b7te", "nur", "ein\u00b7mal", "heu\u00b7te", "a\u00b7bend"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ADV", "ADV", "ADV", "VVPP"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Einer von denen vier Schimmeln sein!", "tokens": ["Ei\u00b7ner", "von", "de\u00b7nen", "vier", "Schim\u00b7meln", "sein", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "APPR", "PRELS", "CARD", "NN", "VAINF", "$."], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}}, "stanza.12": {"line.1": {"text": "Ich wollte mich wehren, ich wollte dich lehren,", "tokens": ["Ich", "woll\u00b7te", "mich", "weh\u00b7ren", ",", "ich", "woll\u00b7te", "dich", "leh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PRF", "VVINF", "$,", "PPER", "VMFIN", "PRF", "VVINF", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.2": {"text": "Herr Exzellenz mit dem Podagra,", "tokens": ["Herr", "Ex\u00b7zel\u00b7lenz", "mit", "dem", "Po\u00b7da\u00b7gra", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Du solltest Gottes Gesch\u00f6pfe ehren", "tokens": ["Du", "soll\u00b7test", "Got\u00b7tes", "Ge\u00b7sch\u00f6p\u00b7fe", "eh\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "NN", "NN", "VVINF"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Und deinesgleichen ... Hallelujah!", "tokens": ["Und", "dei\u00b7nes\u00b7glei\u00b7chen", "...", "Hal\u00b7le\u00b7lu\u00b7jah", "!"], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["KON", "PPOSAT", "$(", "ITJ", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.13": {"line.1": {"text": "Dort sitzt er noch bei seinem Herrn Vetter,", "tokens": ["Dort", "sitzt", "er", "noch", "bei", "sei\u00b7nem", "Herrn", "Vet\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPR", "PPOSAT", "NN", "NE", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "W\u00fchlt in Karten und w\u00fchlt in Geld,", "tokens": ["W\u00fchlt", "in", "Kar\u00b7ten", "und", "w\u00fchlt", "in", "Geld", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "NN", "KON", "VVFIN", "APPR", "NN", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.3": {"text": "Und l\u00e4\u00dft die Tiere in Sturm und Wetter", "tokens": ["Und", "l\u00e4\u00dft", "die", "Tie\u00b7re", "in", "Sturm", "und", "Wet\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ART", "NN", "APPR", "NN", "KON", "NN"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Frieren, so lang' es Gott gef\u00e4llt.", "tokens": ["Frie\u00b7ren", ",", "so", "lang'", "es", "Gott", "ge\u00b7f\u00e4llt", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADV", "ADV", "PPER", "NN", "VVPP", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.14": {"line.1": {"text": "Ich rate dir, la\u00df die Karten ruhen", "tokens": ["Ich", "ra\u00b7te", "dir", ",", "la\u00df", "die", "Kar\u00b7ten", "ru\u00b7hen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "$,", "VVIMP", "ART", "NN", "VVINF"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Und h\u00fcte dich fein, Ministerlein,", "tokens": ["Und", "h\u00fc\u00b7te", "dich", "fein", ",", "Mi\u00b7nis\u00b7ter\u00b7lein", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADJD", "$,", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Du hast es mit vier Hengsten zu tuen,", "tokens": ["Du", "hast", "es", "mit", "vier", "Hengs\u00b7ten", "zu", "tu\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "APPR", "CARD", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Bedenk, da\u00df das keine B\u00fcrger sein!", "tokens": ["Be\u00b7denk", ",", "da\u00df", "das", "kei\u00b7ne", "B\u00fcr\u00b7ger", "sein", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KOUS", "ART", "PIAT", "NN", "VAINF", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}}}}