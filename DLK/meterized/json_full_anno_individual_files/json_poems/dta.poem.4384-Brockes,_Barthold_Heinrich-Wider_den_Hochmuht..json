{"dta.poem.4384": {"metadata": {"author": {"name": "Brockes, Barthold Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "Wider den Hochmuht.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1743", "urn": "urn:nbn:de:kobv:b4-20083-6", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Da\u00df die Begier, zu viel zu wissen, dem Satan als ein", "tokens": ["Da\u00df", "die", "Be\u00b7gier", ",", "zu", "viel", "zu", "wis\u00b7sen", ",", "dem", "Sa\u00b7tan", "als", "ein"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "$,", "PTKA", "PIS", "PTKZU", "VVINF", "$,", "ART", "NN", "KOKOM", "ART"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.2": {"text": "Mittel dienet,", "tokens": ["Mit\u00b7tel", "die\u00b7net", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVFIN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "Die ersten Eltern zu verf\u00fchren, ist unserer Betrachtung", "tokens": ["Die", "ers\u00b7ten", "El\u00b7tern", "zu", "ver\u00b7f\u00fch\u00b7ren", ",", "ist", "un\u00b7se\u00b7rer", "Be\u00b7trach\u00b7tung"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "PTKZU", "VVINF", "$,", "VAFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+--+-+-+-", "measure": "iambic.septa.relaxed"}, "line.4": {"text": "wehrt.", "tokens": ["wehrt", "."], "token_info": ["word", "punct"], "pos": ["VVFIN", "$."], "meter": "+", "measure": "single.up"}, "line.5": {"text": "Wer wei\u00df, ob ers nicht noch gebraucht? Es scheint, sobald", "tokens": ["Wer", "wei\u00df", ",", "ob", "ers", "nicht", "noch", "ge\u00b7braucht", "?", "Es", "scheint", ",", "so\u00b7bald"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word"], "pos": ["PWS", "VVFIN", "$,", "KOUS", "PIS", "PTKNEG", "ADV", "VVPP", "$.", "PPER", "VVFIN", "$,", "KOUS"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "man sich erk\u00fchnet,", "tokens": ["man", "sich", "er\u00b7k\u00fch\u00b7net", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PIS", "PRF", "VVFIN", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.7": {"text": "Des Geistes Kr\u00e4fte zu vergr\u00f6ssern, (da wir, was GOtt uns", "tokens": ["Des", "Geis\u00b7tes", "Kr\u00e4f\u00b7te", "zu", "ver\u00b7gr\u00f6s\u00b7sern", ",", "(", "da", "wir", ",", "was", "Gott", "uns"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "NN", "PTKZU", "VVINF", "$,", "$(", "KOUS", "PPER", "$,", "PWS", "NN", "PPER"], "meter": "-+-+-+-+-+++-+", "measure": "unknown.measure.octa.plus"}, "line.8": {"text": "hier beschehrt,", "tokens": ["hier", "be\u00b7schehrt", ","], "token_info": ["word", "word", "punct"], "pos": ["ADV", "VVPP", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.9": {"text": "Dadurch vers\u00e4umen zu geniessen) da\u00df blo\u00df allein die Sucht", "tokens": ["Da\u00b7durch", "ver\u00b7s\u00e4u\u00b7men", "zu", "ge\u00b7nies\u00b7sen", ")", "da\u00df", "blo\u00df", "al\u00b7lein", "die", "Sucht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PAV", "VVINF", "PTKZU", "VVINF", "$(", "KOUS", "ADV", "ADV", "ART", "NN"], "meter": "-+-+-+-+--+-+-+", "measure": "iambic.septa.relaxed"}, "line.10": {"text": "zu wissen", "tokens": ["zu", "wis\u00b7sen"], "token_info": ["word", "word"], "pos": ["PTKZU", "VVINF"], "meter": "-+-", "measure": "amphibrach.single"}, "line.11": {"text": "An allem unsern Ungl\u00fcck schuld. Indem wir, f\u00fcr den", "tokens": ["An", "al\u00b7lem", "un\u00b7sern", "Un\u00b7gl\u00fcck", "schuld", ".", "In\u00b7dem", "wir", ",", "f\u00fcr", "den"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["APPR", "PIS", "PPOSAT", "NN", "ADJD", "$.", "KOUS", "PPER", "$,", "APPR", "ART"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Geist allein,", "tokens": ["Geist", "al\u00b7lein", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "ADV", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.13": {"text": "Um das, was ausser unsern Schranken, zu fassen nur", "tokens": ["Um", "das", ",", "was", "aus\u00b7ser", "un\u00b7sern", "Schran\u00b7ken", ",", "zu", "fas\u00b7sen", "nur"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUI", "PDS", "$,", "PRELS", "APPR", "PPOSAT", "NN", "$,", "PTKZU", "VVINF", "ADV"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.14": {"text": "besorget seyn;", "tokens": ["be\u00b7sor\u00b7get", "seyn", ";"], "token_info": ["word", "word", "punct"], "pos": ["VVPP", "VAINF", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.15": {"text": "Wird, nebst der Kraft der Gottheit Werke zu kennen, uns", "tokens": ["Wird", ",", "nebst", "der", "Kraft", "der", "Got\u00b7theit", "Wer\u00b7ke", "zu", "ken\u00b7nen", ",", "uns"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["VAFIN", "$,", "APPR", "ART", "NN", "ART", "NN", "NN", "PTKZU", "VVINF", "$,", "PPER"], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.16": {"text": "Gott selbst entrissen.", "tokens": ["Gott", "selbst", "ent\u00b7ris\u00b7sen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ADV", "VVINF", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.17": {"text": "Wer kann bewundern? Wer geniessen? Wer kann GOtt", "tokens": ["Wer", "kann", "be\u00b7wun\u00b7dern", "?", "Wer", "ge\u00b7nies\u00b7sen", "?", "Wer", "kann", "Gott"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["PWS", "VMFIN", "VVINF", "$.", "PWS", "VVPP", "$.", "PWS", "VMFIN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "danken? wenn der Geist", "tokens": ["dan\u00b7ken", "?", "wenn", "der", "Geist"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["VVINF", "$.", "KOUS", "ART", "NN"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.19": {"text": "Best\u00e4ndig mit sich selbst besch\u00e4ftigt, sich seiner wahren", "tokens": ["Be\u00b7st\u00e4n\u00b7dig", "mit", "sich", "selbst", "be\u00b7sch\u00e4f\u00b7tigt", ",", "sich", "sei\u00b7ner", "wah\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADJD", "APPR", "PRF", "ADV", "VVPP", "$,", "PRF", "PPOSAT", "ADJA"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.20": {"text": "Pflicht entrei\u00dft,", "tokens": ["Pflicht", "ent\u00b7rei\u00dft", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVFIN", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.21": {"text": "Die in des Sch\u00f6pfers Ehr\u2019 allein besteht, wozu wir blo\u00df", "tokens": ["Die", "in", "des", "Sch\u00f6p\u00b7fers", "Ehr'", "al\u00b7lein", "be\u00b7steht", ",", "wo\u00b7zu", "wir", "blo\u00df"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "APPR", "ART", "NN", "NN", "ADV", "VVFIN", "$,", "PWAV", "PPER", "ADV"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.22": {"text": "gemacht?", "tokens": ["ge\u00b7macht", "?"], "token_info": ["word", "punct"], "pos": ["VVPP", "$."], "meter": "-+", "measure": "iambic.single"}}, "stanza.2": {"line.1": {"text": "Wir lassen auf dem hohen Weg, den wir uns bahnen,", "tokens": ["Wir", "las\u00b7sen", "auf", "dem", "ho\u00b7hen", "Weg", ",", "den", "wir", "uns", "bah\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "ADJA", "NN", "$,", "PRELS", "PPER", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "aus der Acht", "tokens": ["aus", "der", "Acht"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ART", "CARD"], "meter": "+-+", "measure": "trochaic.di"}, "line.3": {"text": "Des Sch\u00f6pfers weise Macht und Liebe. Wir wollen stets", "tokens": ["Des", "Sch\u00f6p\u00b7fers", "wei\u00b7se", "Macht", "und", "Lie\u00b7be", ".", "Wir", "wol\u00b7len", "stets"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "ADJA", "NN", "KON", "NN", "$.", "PPER", "VMFIN", "ADV"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "das Wissen h\u00e4ufen,", "tokens": ["das", "Wis\u00b7sen", "h\u00e4u\u00b7fen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.5": {"text": "Und, was uns wirklich unbegreiflich, des Sch\u00f6pfers weise", "tokens": ["Und", ",", "was", "uns", "wirk\u00b7lich", "un\u00b7be\u00b7greif\u00b7lich", ",", "des", "Sch\u00f6p\u00b7fers", "wei\u00b7se"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "$,", "PRELS", "PPER", "ADJD", "ADJD", "$,", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "Macht begreifen.", "tokens": ["Macht", "be\u00b7grei\u00b7fen", "."], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVINF", "$."], "meter": "+-+-", "measure": "trochaic.di"}}, "stanza.3": {"line.1": {"text": "Uns scheinet der Verstand geschenkt, was uns der Sch\u00f6pfer", "tokens": ["Uns", "schei\u00b7net", "der", "Ver\u00b7stand", "ge\u00b7schenkt", ",", "was", "uns", "der", "Sch\u00f6p\u00b7fer"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "VVPP", "$,", "PRELS", "PPER", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "wollen g\u00f6nnen,", "tokens": ["wol\u00b7len", "g\u00f6n\u00b7nen", ","], "token_info": ["word", "word", "punct"], "pos": ["VMFIN", "VVINF", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "Blo\u00df im vern\u00fcnftigen Genu\u00df, und im Bewundern zu er-", "tokens": ["Blo\u00df", "im", "ver\u00b7n\u00fcnf\u00b7ti\u00b7gen", "Ge\u00b7nu\u00df", ",", "und", "im", "Be\u00b7wun\u00b7dern", "zu", "er"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "APPRART", "ADJA", "NN", "$,", "KON", "APPRART", "NN", "APPR", "TRUNC"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.4": {"text": "kennen.", "tokens": ["ken\u00b7nen", "."], "token_info": ["word", "punct"], "pos": ["VVINF", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.5": {"text": "So aber sieht man uns recht str\u00e4flich den angewies\u2019nen", "tokens": ["So", "a\u00b7ber", "sieht", "man", "uns", "recht", "str\u00e4f\u00b7lich", "den", "an\u00b7ge\u00b7wies'\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "VVFIN", "PIS", "PPER", "ADV", "ADJD", "ART", "ADJA"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "Weg verlassen,", "tokens": ["Weg", "ver\u00b7las\u00b7sen", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVPP", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.7": {"text": "Um die verborgne Spur der Dinge, und wie sie GOtt gewirkt,", "tokens": ["Um", "die", "ver\u00b7borg\u00b7ne", "Spur", "der", "Din\u00b7ge", ",", "und", "wie", "sie", "Gott", "ge\u00b7wirkt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "ART", "ADJA", "NN", "ART", "NN", "$,", "KON", "PWAV", "PPER", "NN", "VVPP", "$,"], "meter": "-+-+-+-+--+-+-+", "measure": "iambic.septa.relaxed"}, "line.8": {"text": "zu fassen.", "tokens": ["zu", "fas\u00b7sen", "."], "token_info": ["word", "word", "punct"], "pos": ["PTKZU", "VVINF", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.9": {"text": "Es scheinet wahr, und mehr als glaublich, da\u00df, wenn ein", "tokens": ["Es", "schei\u00b7net", "wahr", ",", "und", "mehr", "als", "glaub\u00b7lich", ",", "da\u00df", ",", "wenn", "ein"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["PPER", "VVFIN", "PTKVZ", "$,", "KON", "PIAT", "KOKOM", "ADJD", "$,", "KOUS", "$,", "KOUS", "ART"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Pferd sein Futter fri\u00dft,", "tokens": ["Pferd", "sein", "Fut\u00b7ter", "fri\u00dft", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.11": {"text": "Es fast vern\u00fcnftiger geschehe, als wie vom Menschen,", "tokens": ["Es", "fast", "ver\u00b7n\u00fcnf\u00b7ti\u00b7ger", "ge\u00b7sche\u00b7he", ",", "als", "wie", "vom", "Men\u00b7schen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADJD", "VVFIN", "$,", "KOUS", "KOKOM", "APPRART", "NN", "$,"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.12": {"text": "wenn er i\u00dft.", "tokens": ["wenn", "er", "i\u00dft", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.13": {"text": "Denn hat es nicht so scharfe Geister, als wir; so sind sie auch", "tokens": ["Denn", "hat", "es", "nicht", "so", "schar\u00b7fe", "Geis\u00b7ter", ",", "als", "wir", ";", "so", "sind", "sie", "auch"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "PPER", "PTKNEG", "ADV", "ADJA", "NN", "$,", "KOUS", "PPER", "$.", "ADV", "VAFIN", "PPER", "ADV"], "meter": "-+-+-+-+--+-+-+", "measure": "iambic.septa.relaxed"}, "line.14": {"text": "hingegen", "tokens": ["hin\u00b7ge\u00b7gen"], "token_info": ["word"], "pos": ["ADV"], "meter": "-+-", "measure": "amphibrach.single"}, "line.15": {"text": "So unvern\u00fcnftig nicht zerstreut, als unsre, die, ohn\u2019 Ueber-", "tokens": ["So", "un\u00b7ver\u00b7n\u00fcnf\u00b7tig", "nicht", "zer\u00b7streut", ",", "als", "uns\u00b7re", ",", "die", ",", "ohn'", "Ue\u00b7ber"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["ADV", "ADJD", "PTKNEG", "VVPP", "$,", "KOUS", "PPOSAT", "$,", "PRELS", "$,", "KOUI", "TRUNC"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.16": {"text": "legen,", "tokens": ["le\u00b7gen", ","], "token_info": ["word", "punct"], "pos": ["VVINF", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.17": {"text": "Indem sie stets was anders denken, was sie geniessen nicht", "tokens": ["In\u00b7dem", "sie", "stets", "was", "an\u00b7ders", "den\u00b7ken", ",", "was", "sie", "ge\u00b7nies\u00b7sen", "nicht"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "PWS", "ADV", "VVINF", "$,", "PRELS", "PPER", "VVPP", "PTKNEG"], "meter": "-+-+-+-+--+-+-+", "measure": "iambic.septa.relaxed"}, "line.18": {"text": "erwegen.", "tokens": ["er\u00b7we\u00b7gen", "."], "token_info": ["word", "punct"], "pos": ["VVFIN", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.19": {"text": "Da es unwidersprechlich wahr, da\u00df unser Auge gar nichts", "tokens": ["Da", "es", "un\u00b7wi\u00b7der\u00b7sprech\u00b7lich", "wahr", ",", "da\u00df", "un\u00b7ser", "Au\u00b7ge", "gar", "nichts"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADJD", "PTKVZ", "$,", "KOUS", "PPOSAT", "NN", "ADV", "PIS"], "meter": "-----+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.20": {"text": "sieht,", "tokens": ["sieht", ","], "token_info": ["word", "punct"], "pos": ["VVFIN", "$,"], "meter": "+", "measure": "single.up"}, "line.21": {"text": "Und unsre Ohren nichts vernehmen, wenn unser denkendes", "tokens": ["Und", "uns\u00b7re", "Oh\u00b7ren", "nichts", "ver\u00b7neh\u00b7men", ",", "wenn", "un\u00b7ser", "den\u00b7ken\u00b7des"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "PIS", "VVINF", "$,", "KOUS", "PPOSAT", "NN"], "meter": "-+-+-+-+--+-+-+", "measure": "iambic.septa.relaxed"}, "line.22": {"text": "Gem\u00fcht", "tokens": ["Ge\u00b7m\u00fcht"], "token_info": ["word"], "pos": ["NN"], "meter": "-+", "measure": "iambic.single"}, "line.23": {"text": "Mit anderm Vorwurf sich besch\u00e4ftigt. Die Leidenschaf-", "tokens": ["Mit", "an\u00b7derm", "Vor\u00b7wurf", "sich", "be\u00b7sch\u00e4f\u00b7tigt", ".", "Die", "Lei\u00b7den\u00b7schaf"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "PIS", "NN", "PRF", "VVPP", "$.", "ART", "TRUNC"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.24": {"text": "ten helfen zwar", "tokens": ["ten", "hel\u00b7fen", "zwar"], "token_info": ["word", "word", "word"], "pos": ["FM", "VVFIN", "ADV"], "meter": "-+-+", "measure": "iambic.di"}, "line.25": {"text": "Die Geister gleichfalls zu zerstreuen, und von den Sinnen", "tokens": ["Die", "Geis\u00b7ter", "gleich\u00b7falls", "zu", "zer\u00b7streu\u00b7en", ",", "und", "von", "den", "Sin\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADV", "PTKZU", "VVINF", "$,", "KON", "APPR", "ART", "NN"], "meter": "-+-+-+-+-++-+-", "measure": "unknown.measure.septa"}, "line.26": {"text": "abzuziehn.", "tokens": ["ab\u00b7zu\u00b7ziehn", "."], "token_info": ["word", "punct"], "pos": ["VVIZU", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.27": {"text": "Allein die Wissens-Sucht, da wir, was wir doch nicht", "tokens": ["Al\u00b7lein", "die", "Wis\u00b7sens\u00b7Sucht", ",", "da", "wir", ",", "was", "wir", "doch", "nicht"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "$,", "KOUS", "PPER", "$,", "PRELS", "PPER", "ADV", "PTKNEG"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "begreifen sollen,", "tokens": ["be\u00b7grei\u00b7fen", "sol\u00b7len", ","], "token_info": ["word", "word", "punct"], "pos": ["VVINF", "VMFIN", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.29": {"text": "Jm Geistlichen und Weltlichen, ergr\u00fcbeln und begreifen", "tokens": ["Jm", "Geist\u00b7li\u00b7chen", "und", "Welt\u00b7li\u00b7chen", ",", "er\u00b7gr\u00fc\u00b7beln", "und", "be\u00b7grei\u00b7fen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPRART", "NN", "KON", "NN", "$,", "VVINF", "KON", "VVINF"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.30": {"text": "wollen,", "tokens": ["wol\u00b7len", ","], "token_info": ["word", "punct"], "pos": ["VMFIN", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.31": {"text": "Hat noch die allergr\u00f6\u00dfte Schuld. Wie viele sieht man", "tokens": ["Hat", "noch", "die", "al\u00b7ler\u00b7gr\u00f6\u00df\u00b7te", "Schuld", ".", "Wie", "vie\u00b7le", "sieht", "man"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "ART", "ADJA", "NN", "$.", "PWAV", "PIS", "VVFIN", "PIS"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "sich bem\u00fchn,", "tokens": ["sich", "be\u00b7m\u00fchn", ","], "token_info": ["word", "word", "punct"], "pos": ["PRF", "VVINF", "$,"], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.4": {"line.1": {"text": "Geheimnisse der Schrift zu fassen, und selbe deutlich zu", "tokens": ["Ge\u00b7heim\u00b7nis\u00b7se", "der", "Schrift", "zu", "fas\u00b7sen", ",", "und", "sel\u00b7be", "deut\u00b7lich", "zu"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "ART", "NN", "PTKZU", "VVINF", "$,", "KON", "ADJA", "ADJD", "PTKZU"], "meter": "-+-+-+-+--+-+-+", "measure": "iambic.septa.relaxed"}, "line.2": {"text": "erkl\u00e4ren,", "tokens": ["er\u00b7kl\u00e4\u00b7ren", ","], "token_info": ["word", "punct"], "pos": ["VVINF", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.3": {"text": "Die doch, wenn sie Erkl\u00e4rung f\u00e4hig, gar nicht Geheim-", "tokens": ["Die", "doch", ",", "wenn", "sie", "Er\u00b7kl\u00e4\u00b7rung", "f\u00e4\u00b7hig", ",", "gar", "nicht", "Ge\u00b7heim"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADV", "$,", "KOUS", "PPER", "NN", "ADJD", "$,", "ADV", "PTKNEG", "TRUNC"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "nisse mehr w\u00e4ren.", "tokens": ["nis\u00b7se", "mehr", "w\u00e4\u00b7ren", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VAFIN", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.5": {"text": "Inzwischen lassen sie die Wunder von GOttes Lieb\u2019 und", "tokens": ["I\u00b7nzwi\u00b7schen", "las\u00b7sen", "sie", "die", "Wun\u00b7der", "von", "Got\u00b7tes", "Lieb'", "und"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "APPR", "NN", "NN", "KON"], "meter": "+--+-+-+--+-+-", "measure": "iambic.hexa.invert"}, "line.6": {"text": "weisen Macht,", "tokens": ["wei\u00b7sen", "Macht", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.7": {"text": "In welchen sie doch gleichsam schwimmen, recht unver-", "tokens": ["In", "wel\u00b7chen", "sie", "doch", "gleich\u00b7sam", "schwim\u00b7men", ",", "recht", "un\u00b7ver"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "PWAT", "PPER", "ADV", "ADJD", "VVINF", "$,", "ADV", "TRUNC"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.8": {"text": "n\u00fcnftig aus der Acht.", "tokens": ["n\u00fcnf\u00b7tig", "aus", "der", "Acht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "ART", "CARD", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.5": {"line.1": {"text": "Gott hat uns auf die Welt gesetzt, um Seine Ehre zu", "tokens": ["Gott", "hat", "uns", "auf", "die", "Welt", "ge\u00b7setzt", ",", "um", "Sei\u00b7ne", "Eh\u00b7re", "zu"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "VAFIN", "PPER", "APPR", "ART", "NN", "VVPP", "$,", "KOUI", "PPOSAT", "NN", "PTKZU"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.2": {"text": "erheben,", "tokens": ["er\u00b7he\u00b7ben", ","], "token_info": ["word", "punct"], "pos": ["VVINF", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.3": {"text": "Er hat uns ungez\u00e4hltes Gutes, zur Lust und zum Genu\u00df,", "tokens": ["Er", "hat", "uns", "un\u00b7ge\u00b7z\u00e4hl\u00b7tes", "Gu\u00b7tes", ",", "zur", "Lust", "und", "zum", "Ge\u00b7nu\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADJA", "NN", "$,", "APPRART", "NN", "KON", "APPRART", "NN", "$,"], "meter": "-+-+-+-+--+-+-+", "measure": "iambic.septa.relaxed"}, "line.4": {"text": "gegeben.", "tokens": ["ge\u00b7ge\u00b7ben", "."], "token_info": ["word", "punct"], "pos": ["VVPP", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.5": {"text": "Wir aber achten dieses nichts. Der Geist fliegt in die", "tokens": ["Wir", "a\u00b7ber", "ach\u00b7ten", "die\u00b7ses", "nichts", ".", "Der", "Geist", "fliegt", "in", "die"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "VVFIN", "PDAT", "PIS", "$.", "ART", "NN", "VVFIN", "APPR", "ART"], "meter": "-+-+-+-+-+-++", "measure": "unknown.measure.septa"}, "line.6": {"text": "H\u00f6h', wir schweben", "tokens": ["H\u00f6h'", ",", "wir", "schwe\u00b7ben"], "token_info": ["word", "punct", "word", "word"], "pos": ["NN", "$,", "PPER", "VVFIN"], "meter": "+-+-", "measure": "trochaic.di"}, "line.7": {"text": "Aus unserm angewies\u2019nen Ort in einen andern, und ver-", "tokens": ["Aus", "un\u00b7serm", "an\u00b7ge\u00b7wies'\u00b7nen", "Ort", "in", "ei\u00b7nen", "an\u00b7dern", ",", "und", "ver"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "APPR", "ART", "ADJA", "$,", "KON", "TRUNC"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.8": {"text": "gessen,", "tokens": ["ges\u00b7sen", ","], "token_info": ["word", "punct"], "pos": ["VVPP", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.9": {"text": "In unserm aufgeblas\u2019nen Flug, des Sch\u00f6pfers Ordnung", "tokens": ["In", "un\u00b7serm", "auf\u00b7ge\u00b7blas'\u00b7nen", "Flug", ",", "des", "Sch\u00f6p\u00b7fers", "Ord\u00b7nung"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$,", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "zu ermessen,", "tokens": ["zu", "er\u00b7mes\u00b7sen", ","], "token_info": ["word", "word", "punct"], "pos": ["PTKZU", "VVINF", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.11": {"text": "Die uns zur Richtschnur dienen sollte, und zwar, ohn\u2019", "tokens": ["Die", "uns", "zur", "Richt\u00b7schnur", "die\u00b7nen", "soll\u00b7te", ",", "und", "zwar", ",", "ohn'"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word"], "pos": ["ART", "PPER", "APPRART", "NN", "VVINF", "VMFIN", "$,", "KON", "ADV", "$,", "KOUI"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.12": {"text": "Ausnahm, ganz allein.", "tokens": ["Aus\u00b7nahm", ",", "ganz", "al\u00b7lein", "."], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "$,", "ADV", "ADV", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.13": {"text": "Gott will uns hier auf Erden haben, wir wollen nicht", "tokens": ["Gott", "will", "uns", "hier", "auf", "Er\u00b7den", "ha\u00b7ben", ",", "wir", "wol\u00b7len", "nicht"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "VMFIN", "PPER", "ADV", "APPR", "NN", "VAFIN", "$,", "PPER", "VMFIN", "PTKNEG"], "meter": "+--+-+-+--+-+", "measure": "iambic.hexa.invert"}, "line.14": {"text": "auf Erden seyn.", "tokens": ["auf", "Er\u00b7den", "seyn", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "VAINF", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.15": {"text": "Der Geist verschm\u00e4ht das uns von GOtt allhier geg\u00f6n-", "tokens": ["Der", "Geist", "ver\u00b7schm\u00e4ht", "das", "uns", "von", "Gott", "all\u00b7hier", "ge\u00b7g\u00f6n"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ART", "PPER", "APPR", "NN", "ADV", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "nete Vergn\u00fcgen,", "tokens": ["ne\u00b7te", "Ver\u00b7gn\u00fc\u00b7gen", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$,"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.17": {"text": "Und sucht, auf seine Weis\u2019, ihm Fl\u00fcgel (k\u00f6nnt\u2019 er) selbst", "tokens": ["Und", "sucht", ",", "auf", "sei\u00b7ne", "Weis'", ",", "ihm", "Fl\u00fc\u00b7gel", "(", "k\u00f6nnt'", "er", ")", "selbst"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word"], "pos": ["KON", "VVFIN", "$,", "APPR", "PPOSAT", "NN", "$,", "PPER", "NN", "$(", "VMFIN", "PPER", "$(", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "\u00fcber GOtt zu fliegen.", "tokens": ["\u00fc\u00b7ber", "Gott", "zu", "flie\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PTKZU", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.6": {"line.1": {"text": "Ach, m\u00f6gten wir doch unsre Pflicht, und in derselben", "tokens": ["Ach", ",", "m\u00f6g\u00b7ten", "wir", "doch", "uns\u00b7re", "Pflicht", ",", "und", "in", "der\u00b7sel\u00b7ben"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ITJ", "$,", "VMFIN", "PPER", "ADV", "PPOSAT", "NN", "$,", "KON", "APPR", "PDAT"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Gottes Willen,", "tokens": ["Got\u00b7tes", "Wil\u00b7len", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "NN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "Jm angewies\u2019nen Brauch des Geistes, und nicht der Wis-", "tokens": ["Jm", "an\u00b7ge\u00b7wies'\u00b7nen", "Brauch", "des", "Geis\u00b7tes", ",", "und", "nicht", "der", "Wis"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPRART", "ADJA", "NN", "ART", "NN", "$,", "KON", "PTKNEG", "ART", "TRUNC"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "sens-Sucht, erf\u00fcllen!", "tokens": ["sens\u00b7Sucht", ",", "er\u00b7f\u00fcl\u00b7len", "!"], "token_info": ["word", "punct", "word", "punct"], "pos": ["VVPP", "$,", "VVINF", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.7": {"line.1": {"text": "Ach, la\u00dft, den in der Sucht zu wissen versteckten Hoch-", "tokens": ["Ach", ",", "la\u00dft", ",", "den", "in", "der", "Sucht", "zu", "wis\u00b7sen", "ver\u00b7steck\u00b7ten", "Hoch"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ITJ", "$,", "VVFIN", "$,", "PRELS", "APPR", "ART", "NN", "PTKZU", "VVINF", "VVFIN", "TRUNC"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "muht doch nicht mehr", "tokens": ["muht", "doch", "nicht", "mehr"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "PTKNEG", "ADV"], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "Euch den Genu\u00df von GOttes Gaben, und in demselben", "tokens": ["Euch", "den", "Ge\u00b7nu\u00df", "von", "Got\u00b7tes", "Ga\u00b7ben", ",", "und", "in", "dem\u00b7sel\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "ART", "NN", "APPR", "NN", "NN", "$,", "KON", "APPR", "PDAT"], "meter": "+--+-+-+--+-+-", "measure": "iambic.hexa.invert"}, "line.4": {"text": "Gottes Ehr',", "tokens": ["Got\u00b7tes", "Ehr'", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "NN", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.5": {"text": "So str\u00e4flich, wie bishero, rauben! Bez\u00e4hmt solch str\u00e4fli-", "tokens": ["So", "str\u00e4f\u00b7lich", ",", "wie", "bis\u00b7he\u00b7ro", ",", "rau\u00b7ben", "!", "Be\u00b7z\u00e4hmt", "solch", "str\u00e4f\u00b7li"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["ADV", "ADJD", "$,", "PWAV", "ADV", "$,", "VVINF", "$.", "VVFIN", "PIAT", "TRUNC"], "meter": "-+--+--+--+-+-", "measure": "amphibrach.tetra.plus"}, "line.6": {"text": "ches Erk\u00fchnen,", "tokens": ["ches", "Er\u00b7k\u00fch\u00b7nen", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$,"], "meter": "--+-", "measure": "anapaest.init"}, "line.7": {"text": "Und lasset eurer ersten Eltern Exempel, euch zur Lehre,", "tokens": ["Und", "las\u00b7set", "eu\u00b7rer", "ers\u00b7ten", "El\u00b7tern", "Ex\u00b7em\u00b7pel", ",", "euch", "zur", "Leh\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "ADJA", "NN", "NN", "$,", "PPER", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-+--+-", "measure": "iambic.septa.relaxed"}, "line.8": {"text": "dienen!", "tokens": ["die\u00b7nen", "!"], "token_info": ["word", "punct"], "pos": ["VVINF", "$."], "meter": "+-", "measure": "trochaic.single"}}}}}