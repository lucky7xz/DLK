{"dta.poem.7782": {"metadata": {"author": {"name": "Bodmer, Johann Jacob", "birth": "N.A.", "death": "N.A."}, "title": "Die Geschichte des Davids,  \n K\u00f6nigs in Juda.", "genre": "Lyrik; Prosa", "period": "N.A.", "pub_year": "1743", "urn": "urn:nbn:de:kobv:b4-200905198429", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Jmmittelst, da\u00df wir nun zu Bersaba so waren,", "tokens": ["Jm\u00b7mit\u00b7telst", ",", "da\u00df", "wir", "nun", "zu", "Ber\u00b7sa\u00b7ba", "so", "wa\u00b7ren", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "PPER", "ADV", "APPR", "NE", "ADV", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Kam Saul auch zu uns hin, das Joel kaum erfahren,", "tokens": ["Kam", "Saul", "auch", "zu", "uns", "hin", ",", "das", "Joel", "kaum", "er\u00b7fah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "ADV", "APPR", "PPER", "PTKVZ", "$,", "PRELS", "NE", "ADV", "VVINF", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.3": {"text": "Da kam er selbst zu uns, und that ihm diese Ehr,", "tokens": ["Da", "kam", "er", "selbst", "zu", "uns", ",", "und", "that", "ihm", "die\u00b7se", "Ehr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPR", "PPER", "$,", "KON", "VVFIN", "PPER", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Doch wan\u0303 mans recht bedacht wars um die Tochter mehr.", "tokens": ["Doch", "wa\u00f1", "mans", "recht", "be\u00b7dacht", "wars", "um", "die", "Toch\u00b7ter", "mehr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PIS", "ADJD", "VVPP", "VAFIN", "APPR", "ART", "NN", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Saul, dem des Richters Lob schon war f\u00fcr Ohren kommen,", "tokens": ["Saul", ",", "dem", "des", "Rich\u00b7ters", "Lob", "schon", "war", "f\u00fcr", "Oh\u00b7ren", "kom\u00b7men", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PRELS", "ART", "NN", "NN", "ADV", "VAFIN", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Hat zwar, wie sichs geb\u00fchrt, die Ehre angenommen,", "tokens": ["Hat", "zwar", ",", "wie", "sichs", "ge\u00b7b\u00fchrt", ",", "die", "Eh\u00b7re", "an\u00b7ge\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "$,", "PWAV", "PIS", "VVPP", "$,", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Doch scheut er ihn dabey, sein Stand macht ihn erh\u00f6ht,", "tokens": ["Doch", "scheut", "er", "ihn", "da\u00b7bey", ",", "sein", "Stand", "macht", "ihn", "er\u00b7h\u00f6ht", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PPER", "PAV", "$,", "PPOSAT", "NN", "VVFIN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Sein Ruff der macht ihn klein, und seine Ehr verweht.", "tokens": ["Sein", "Ruff", "der", "macht", "ihn", "klein", ",", "und", "sei\u00b7ne", "Ehr", "ver\u00b7weht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ART", "VVFIN", "PPER", "ADJD", "$,", "KON", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Es f\u00fcgte sich nun so, da\u00df der Meholathiter", "tokens": ["Es", "f\u00fcg\u00b7te", "sich", "nun", "so", ",", "da\u00df", "der", "Me\u00b7ho\u00b7la\u00b7thi\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PRF", "ADV", "ADV", "$,", "KOUS", "ART", "NN"], "meter": "-+--+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.10": {"text": "Jm Garten bey mir war, und Joel, der durchs Gitter", "tokens": ["Jm", "Gar\u00b7ten", "bey", "mir", "war", ",", "und", "Joel", ",", "der", "durchs", "Git\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["APPRART", "NN", "APPR", "PPER", "VAFIN", "$,", "KON", "NE", "$,", "PRELS", "APPRART", "NN"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.11": {"text": "Nahm unser Thun in Acht, versp\u00fcret wohl so viel,", "tokens": ["Nahm", "un\u00b7ser", "Thun", "in", "Acht", ",", "ver\u00b7sp\u00fc\u00b7ret", "wohl", "so", "viel", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "APPR", "CARD", "$,", "VVFIN", "ADV", "ADV", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Da\u00df man nicht Adriel so feind ist, als er will.", "tokens": ["Da\u00df", "man", "nicht", "Ad\u00b7riel", "so", "feind", "ist", ",", "als", "er", "will", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PTKNEG", "NN", "ADV", "ADJD", "VAFIN", "$,", "KOUS", "PPER", "VMFIN", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.13": {"text": "Die\u00df bringt ihm Eifersucht, die\u00df bl\u00e4set seine Liebe,", "tokens": ["Die\u00df", "bringt", "ihm", "Ei\u00b7fer\u00b7sucht", ",", "die\u00df", "bl\u00e4\u00b7set", "sei\u00b7ne", "Lie\u00b7be", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "NN", "$,", "PDS", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Er schleichet hinter her, weil ihn die Rache triebe,", "tokens": ["Er", "schlei\u00b7chet", "hin\u00b7ter", "her", ",", "weil", "ihn", "die", "Ra\u00b7che", "trie\u00b7be", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PTKVZ", "$,", "KOUS", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Und h\u00f6ret alles an, was Adriel mir sagt,", "tokens": ["Und", "h\u00f6\u00b7ret", "al\u00b7les", "an", ",", "was", "Ad\u00b7riel", "mir", "sagt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIS", "PTKVZ", "$,", "PRELS", "NE", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.16": {"text": "Der \u00fcber seine T\u00fcck und lose Schalckheit klagt.", "tokens": ["Der", "\u00fc\u00b7ber", "sei\u00b7ne", "T\u00fcck", "und", "lo\u00b7se", "Schalck\u00b7heit", "klagt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "PPOSAT", "NN", "KON", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Ich gab mit weidlich auf, und sprach von seinen R\u00e4ncken,", "tokens": ["Ich", "gab", "mit", "weid\u00b7lich", "auf", ",", "und", "sprach", "von", "sei\u00b7nen", "R\u00e4n\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ADJD", "PTKVZ", "$,", "KON", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Und konnt ich, da\u00df er uns so nah, unm\u00f6glich dencken,", "tokens": ["Und", "konnt", "ich", ",", "da\u00df", "er", "uns", "so", "nah", ",", "un\u00b7m\u00f6g\u00b7lich", "den\u00b7cken", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "$,", "KOUS", "PPER", "PPER", "ADV", "ADJD", "$,", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Und ob uns Ada gleich schon \u00f6ffters winckte zu,", "tokens": ["Und", "ob", "uns", "A\u00b7da", "gleich", "schon", "\u00f6ff\u00b7ters", "win\u00b7ck\u00b7te", "zu", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "NE", "ADV", "ADV", "ADV", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.20": {"text": "Erriethen wir doch nicht, warum sie solches thu.", "tokens": ["Er\u00b7rie\u00b7then", "wir", "doch", "nicht", ",", "wa\u00b7rum", "sie", "sol\u00b7ches", "thu", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "PTKNEG", "$,", "PWAV", "PPER", "PIS", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Indem schau ich mich um, ja wie mir wurd zu Muthe,", "tokens": ["In\u00b7dem", "schau", "ich", "mich", "um", ",", "ja", "wie", "mir", "wurd", "zu", "Mu\u00b7the", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "PPER", "PRF", "PTKVZ", "$,", "ADV", "KOKOM", "PPER", "VAFIN", "APPR", "NN", "$,"], "meter": "+-+--+++-+-+-", "measure": "trochaic.septa.relaxed"}, "line.22": {"text": "Ja wie mir wurd zu Sinn, als ich die Ungl\u00fccks-Fluthe", "tokens": ["Ja", "wie", "mir", "wurd", "zu", "Sinn", ",", "als", "ich", "die", "Un\u00b7gl\u00fccks\u00b7Flu\u00b7the"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PTKANT", "PWAV", "PPER", "VAFIN", "APPR", "NN", "$,", "KOUS", "PPER", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Mit gr\u00e4\u00dflichem Gesicht so nahe sah bey mir,", "tokens": ["Mit", "gr\u00e4\u00df\u00b7li\u00b7chem", "Ge\u00b7sicht", "so", "na\u00b7he", "sah", "bey", "mir", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ADV", "ADJD", "VVFIN", "APPR", "PPER", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Das wei\u00df ich selbst noch nicht, und kans nicht sagen dir.", "tokens": ["Das", "wei\u00df", "ich", "selbst", "noch", "nicht", ",", "und", "kans", "nicht", "sa\u00b7gen", "dir", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADV", "ADV", "PTKNEG", "$,", "KON", "VMFIN", "PTKNEG", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Ich bliebe gleichsam todt und ohn ein Wort gesprochen", "tokens": ["Ich", "blie\u00b7be", "gleich\u00b7sam", "todt", "und", "ohn", "ein", "Wort", "ge\u00b7spro\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADJD", "ADJD", "KON", "APPR", "ART", "NN", "VVPP"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Lief ich, gleich wann ich h\u00e4tt was greuliches verbrochen,", "tokens": ["Lief", "ich", ",", "gleich", "wann", "ich", "h\u00e4tt", "was", "greu\u00b7li\u00b7ches", "ver\u00b7bro\u00b7chen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "ADV", "PWAV", "PPER", "VAFIN", "PIS", "ADJA", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Von ihm nach Ada zu, doch Adriel blieb stehn,", "tokens": ["Von", "ihm", "nach", "A\u00b7da", "zu", ",", "doch", "Ad\u00b7riel", "blieb", "stehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "APPR", "NE", "PTKVZ", "$,", "ADV", "NE", "VVFIN", "VVINF", "$,"], "meter": "+-+----+--+", "measure": "iambic.tetra.chol"}, "line.28": {"text": "Und scheuete sich nicht, ihn tapfer anzusehn.", "tokens": ["Und", "scheu\u00b7e\u00b7te", "sich", "nicht", ",", "ihn", "tap\u00b7fer", "an\u00b7zu\u00b7sehn", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "PTKNEG", "$,", "PPER", "ADJD", "VVIZU", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Ist das, fieng Joel an, die Ehr, die mir geb\u00fchret?", "tokens": ["Ist", "das", ",", "fi\u00b7eng", "Joel", "an", ",", "die", "Ehr", ",", "die", "mir", "ge\u00b7b\u00fch\u00b7ret", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "PDS", "$,", "VVFIN", "NE", "PTKVZ", "$,", "ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$."], "meter": "-+---+-+-+-+-", "measure": "dactylic.init"}, "line.30": {"text": "Nein, sprache Adriel, weil du bisher gef\u00fchret", "tokens": ["Nein", ",", "spra\u00b7che", "Ad\u00b7riel", ",", "weil", "du", "bis\u00b7her", "ge\u00b7f\u00fch\u00b7ret"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PTKANT", "$,", "VVFIN", "NE", "$,", "KOUS", "PPER", "ADV", "VVPP"], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.31": {"text": "Dein Amt mit S\u00fcnd und Spott, ist dieses viel zu schlecht,", "tokens": ["Dein", "Amt", "mit", "S\u00fcnd", "und", "Spott", ",", "ist", "die\u00b7ses", "viel", "zu", "schlecht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "NN", "KON", "NN", "$,", "VAFIN", "PDS", "ADV", "PTKA", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Da\u00df man dich so beschreibt, denn wer das Recht so schw\u00e4cht,", "tokens": ["Da\u00df", "man", "dich", "so", "be\u00b7schreibt", ",", "denn", "wer", "das", "Recht", "so", "schw\u00e4cht", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PRF", "ADV", "VVFIN", "$,", "KON", "PWS", "ART", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "Gleichwie du thust, den sollt man billich anderst finden.", "tokens": ["Gleich\u00b7wie", "du", "thust", ",", "den", "sollt", "man", "bil\u00b7lich", "an\u00b7derst", "fin\u00b7den", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "$,", "ART", "VMFIN", "PIS", "ADJD", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "Du h\u00e4uffest Jsrael die Straff mit deinen S\u00fcnden,", "tokens": ["Du", "h\u00e4uf\u00b7fest", "Js\u00b7rael", "die", "Straff", "mit", "dei\u00b7nen", "S\u00fcn\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NE", "ART", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.35": {"text": "Und wird man in die L\u00e4ng nicht sitzen dazu still,", "tokens": ["Und", "wird", "man", "in", "die", "L\u00e4ng", "nicht", "sit\u00b7zen", "da\u00b7zu", "still", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PIS", "APPR", "ART", "NN", "PTKNEG", "VVFIN", "PAV", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "Der n\u00fczt uns nicht, der da das Recht nicht f\u00fchren will.", "tokens": ["Der", "n\u00fczt", "uns", "nicht", ",", "der", "da", "das", "Recht", "nicht", "f\u00fch\u00b7ren", "will", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "PTKNEG", "$,", "PRELS", "ADV", "ART", "NN", "PTKNEG", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}