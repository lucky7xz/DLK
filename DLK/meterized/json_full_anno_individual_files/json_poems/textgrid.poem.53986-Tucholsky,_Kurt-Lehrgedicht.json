{"textgrid.poem.53986": {"metadata": {"author": {"name": "Tucholsky, Kurt", "birth": "N.A.", "death": "N.A."}, "title": "Lehrgedicht", "genre": "verse", "period": "N.A.", "pub_year": 1912, "urn": "N.A.", "language": ["de:0.71", "cy:0.28"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wenn du mal gar nicht weiter wei\u00dft,", "tokens": ["Wenn", "du", "mal", "gar", "nicht", "wei\u00b7ter", "wei\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "PTKNEG", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "dann sag: Mythos.", "tokens": ["dann", "sag", ":", "My\u00b7thos", "."], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["ADV", "VVFIN", "$.", "NE", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "Wenn dir der Faden der Logik rei\u00dft,", "tokens": ["Wenn", "dir", "der", "Fa\u00b7den", "der", "Lo\u00b7gik", "rei\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "dann sag: Logos.", "tokens": ["dann", "sag", ":", "Lo\u00b7gos", "."], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["ADV", "VVFIN", "$.", "NE", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.5": {"text": "Und hast du nichts in deiner Tasse,", "tokens": ["Und", "hast", "du", "nichts", "in", "dei\u00b7ner", "Tas\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "PIS", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "dann erz\u00e4hl was vom tiefen Geheimnis der Rasse.", "tokens": ["dann", "er\u00b7z\u00e4hl", "was", "vom", "tie\u00b7fen", "Ge\u00b7heim\u00b7nis", "der", "Ras\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PWS", "APPRART", "ADJA", "NN", "ART", "NN", "$."], "meter": "--+--+--+--+-", "measure": "anapaest.tetra.plus"}, "line.7": {"text": "So erreichst du, da\u00df keiner, wie er auch giert,", "tokens": ["So", "er\u00b7reichst", "du", ",", "da\u00df", "kei\u00b7ner", ",", "wie", "er", "auch", "giert", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "KOUS", "PIS", "$,", "PWAV", "PPER", "ADV", "VVFIN", "$,"], "meter": "--+--+-+--+", "measure": "anapaest.di.plus"}, "line.8": {"text": "dich je kontrolliert.", "tokens": ["dich", "je", "kont\u00b7rol\u00b7liert", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADJD", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.2": {"line.1": {"text": "Willst du diskret die Leute angeilen,", "tokens": ["Willst", "du", "dis\u00b7kret", "die", "Leu\u00b7te", "an\u00b7gei\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "VVFIN", "ART", "NN", "VVPP", "$,"], "meter": "---+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "dann sag: Eros.", "tokens": ["dann", "sag", ":", "E\u00b7ros", "."], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["ADV", "VVFIN", "$.", "NE", "$."], "meter": "-+--", "measure": "dactylic.init"}, "line.3": {"text": "Sehr viel Bildung verleiht deinen Zeilen:", "tokens": ["Sehr", "viel", "Bil\u00b7dung", "ver\u00b7leiht", "dei\u00b7nen", "Zei\u00b7len", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "VVFIN", "PPOSAT", "NN", "$."], "meter": "+-+--+--+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Dionysos.", "tokens": ["Di\u00b7o\u00b7ny\u00b7sos", "."], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.5": {"text": "Aber am meisten tun dir bieten", "tokens": ["A\u00b7ber", "am", "meis\u00b7ten", "tun", "dir", "bie\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPRART", "PIS", "VVFIN", "PPER", "VVINF"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.6": {"text": "die katholischen Requisiten.", "tokens": ["die", "ka\u00b7tho\u00b7li\u00b7schen", "Re\u00b7qui\u00b7si\u00b7ten", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.7": {"text": "Tu fromm \u2013 du brauchst es gar nicht zu sein.", "tokens": ["Tu", "fromm", "\u2013", "du", "brauchst", "es", "gar", "nicht", "zu", "sein", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "$(", "PPER", "VVFIN", "PPER", "ADV", "PTKNEG", "PTKZU", "VAINF", "$."], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.8": {"text": "Sie fallen drauf rein.", "tokens": ["Sie", "fal\u00b7len", "drauf", "rein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PAV", "PTKVZ", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}}, "stanza.3": {"line.1": {"text": "Machs wie die Literatur-Attach\u00e9s:", "tokens": ["Machs", "wie", "die", "Li\u00b7te\u00b7ra\u00b7tur\u00b7At\u00b7ta\u00b7ch\u00e9s", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "KOKOM", "ART", "NN", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.2": {"text": "nimm ein Diarium.", "tokens": ["nimm", "ein", "Di\u00b7a\u00b7ri\u00b7um", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVIMP", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Die Hauptsache eines guten Essays", "tokens": ["Die", "Haupt\u00b7sa\u00b7che", "ei\u00b7nes", "gu\u00b7ten", "Es\u00b7says"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "ADJA", "NN"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "ist das Vokabularium.", "tokens": ["ist", "das", "Vo\u00b7ka\u00b7bu\u00b7la\u00b7ri\u00b7um", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.5": {"text": "Eros und Mythos hats immer gegeben,", "tokens": ["E\u00b7ros", "und", "My\u00b7thos", "hats", "im\u00b7mer", "ge\u00b7ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "NN", "VAFIN", "ADV", "VVPP", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "doch noch nie so viele, die von ihnen leben . . .", "tokens": ["doch", "noch", "nie", "so", "vie\u00b7le", ",", "die", "von", "ih\u00b7nen", "le\u00b7ben", ".", ".", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["ADV", "ADV", "ADV", "ADV", "PIS", "$,", "PRELS", "APPR", "PPER", "VVINF", "$.", "$.", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.7": {"text": "So kommst du spielend \u2013 immer schmuse du nur! \u2013", "tokens": ["So", "kommst", "du", "spie\u00b7lend", "\u2013", "im\u00b7mer", "schmu\u00b7se", "du", "nur", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "$(", "ADV", "VVFIN", "PPER", "ADV", "$.", "$("], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.8": {"text": "in die feinere deutsche Literatur.", "tokens": ["in", "die", "fei\u00b7ne\u00b7re", "deut\u00b7sche", "Li\u00b7te\u00b7ra\u00b7tur", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "ADJA", "NN", "$."], "meter": "--+--+-+--+", "measure": "anapaest.di.plus"}}, "stanza.4": {"line.1": {"text": "Wenn du mal gar nicht weiter wei\u00dft,", "tokens": ["Wenn", "du", "mal", "gar", "nicht", "wei\u00b7ter", "wei\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "PTKNEG", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "dann sag: Mythos.", "tokens": ["dann", "sag", ":", "My\u00b7thos", "."], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["ADV", "VVFIN", "$.", "NE", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "Wenn dir der Faden der Logik rei\u00dft,", "tokens": ["Wenn", "dir", "der", "Fa\u00b7den", "der", "Lo\u00b7gik", "rei\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "dann sag: Logos.", "tokens": ["dann", "sag", ":", "Lo\u00b7gos", "."], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["ADV", "VVFIN", "$.", "NE", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.5": {"text": "Und hast du nichts in deiner Tasse,", "tokens": ["Und", "hast", "du", "nichts", "in", "dei\u00b7ner", "Tas\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "PIS", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "dann erz\u00e4hl was vom tiefen Geheimnis der Rasse.", "tokens": ["dann", "er\u00b7z\u00e4hl", "was", "vom", "tie\u00b7fen", "Ge\u00b7heim\u00b7nis", "der", "Ras\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PWS", "APPRART", "ADJA", "NN", "ART", "NN", "$."], "meter": "--+--+--+--+-", "measure": "anapaest.tetra.plus"}, "line.7": {"text": "So erreichst du, da\u00df keiner, wie er auch giert,", "tokens": ["So", "er\u00b7reichst", "du", ",", "da\u00df", "kei\u00b7ner", ",", "wie", "er", "auch", "giert", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "KOUS", "PIS", "$,", "PWAV", "PPER", "ADV", "VVFIN", "$,"], "meter": "--+--+-+--+", "measure": "anapaest.di.plus"}, "line.8": {"text": "dich je kontrolliert.", "tokens": ["dich", "je", "kont\u00b7rol\u00b7liert", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADJD", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.5": {"line.1": {"text": "Willst du diskret die Leute angeilen,", "tokens": ["Willst", "du", "dis\u00b7kret", "die", "Leu\u00b7te", "an\u00b7gei\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "VVFIN", "ART", "NN", "VVPP", "$,"], "meter": "---+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "dann sag: Eros.", "tokens": ["dann", "sag", ":", "E\u00b7ros", "."], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["ADV", "VVFIN", "$.", "NE", "$."], "meter": "-+--", "measure": "dactylic.init"}, "line.3": {"text": "Sehr viel Bildung verleiht deinen Zeilen:", "tokens": ["Sehr", "viel", "Bil\u00b7dung", "ver\u00b7leiht", "dei\u00b7nen", "Zei\u00b7len", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "VVFIN", "PPOSAT", "NN", "$."], "meter": "+-+--+--+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Dionysos.", "tokens": ["Di\u00b7o\u00b7ny\u00b7sos", "."], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.5": {"text": "Aber am meisten tun dir bieten", "tokens": ["A\u00b7ber", "am", "meis\u00b7ten", "tun", "dir", "bie\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPRART", "PIS", "VVFIN", "PPER", "VVINF"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.6": {"text": "die katholischen Requisiten.", "tokens": ["die", "ka\u00b7tho\u00b7li\u00b7schen", "Re\u00b7qui\u00b7si\u00b7ten", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.7": {"text": "Tu fromm \u2013 du brauchst es gar nicht zu sein.", "tokens": ["Tu", "fromm", "\u2013", "du", "brauchst", "es", "gar", "nicht", "zu", "sein", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "$(", "PPER", "VVFIN", "PPER", "ADV", "PTKNEG", "PTKZU", "VAINF", "$."], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.8": {"text": "Sie fallen drauf rein.", "tokens": ["Sie", "fal\u00b7len", "drauf", "rein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PAV", "PTKVZ", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}}, "stanza.6": {"line.1": {"text": "Machs wie die Literatur-Attach\u00e9s:", "tokens": ["Machs", "wie", "die", "Li\u00b7te\u00b7ra\u00b7tur\u00b7At\u00b7ta\u00b7ch\u00e9s", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "KOKOM", "ART", "NN", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.2": {"text": "nimm ein Diarium.", "tokens": ["nimm", "ein", "Di\u00b7a\u00b7ri\u00b7um", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVIMP", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Die Hauptsache eines guten Essays", "tokens": ["Die", "Haupt\u00b7sa\u00b7che", "ei\u00b7nes", "gu\u00b7ten", "Es\u00b7says"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "ADJA", "NN"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "ist das Vokabularium.", "tokens": ["ist", "das", "Vo\u00b7ka\u00b7bu\u00b7la\u00b7ri\u00b7um", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.5": {"text": "Eros und Mythos hats immer gegeben,", "tokens": ["E\u00b7ros", "und", "My\u00b7thos", "hats", "im\u00b7mer", "ge\u00b7ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "NN", "VAFIN", "ADV", "VVPP", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "doch noch nie so viele, die von ihnen leben . . .", "tokens": ["doch", "noch", "nie", "so", "vie\u00b7le", ",", "die", "von", "ih\u00b7nen", "le\u00b7ben", ".", ".", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["ADV", "ADV", "ADV", "ADV", "PIS", "$,", "PRELS", "APPR", "PPER", "VVINF", "$.", "$.", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.7": {"text": "So kommst du spielend \u2013 immer schmuse du nur! \u2013", "tokens": ["So", "kommst", "du", "spie\u00b7lend", "\u2013", "im\u00b7mer", "schmu\u00b7se", "du", "nur", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "$(", "ADV", "VVFIN", "PPER", "ADV", "$.", "$("], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.8": {"text": "in die feinere deutsche Literatur.", "tokens": ["in", "die", "fei\u00b7ne\u00b7re", "deut\u00b7sche", "Li\u00b7te\u00b7ra\u00b7tur", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "ADJA", "NN", "$."], "meter": "--+--+-+--+", "measure": "anapaest.di.plus"}}}}}