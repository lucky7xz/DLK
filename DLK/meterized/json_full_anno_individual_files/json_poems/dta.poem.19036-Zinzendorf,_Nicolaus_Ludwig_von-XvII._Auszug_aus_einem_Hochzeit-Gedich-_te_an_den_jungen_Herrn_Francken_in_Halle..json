{"dta.poem.19036": {"metadata": {"author": {"name": "Zinzendorf, Nicolaus Ludwig von", "birth": "N.A.", "death": "N.A."}, "title": "XvII.  Auszug aus einem Hochzeit-Gedich-  \n te an den jungen Herrn Francken in  \n Halle.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1735", "urn": "urn:nbn:de:kobv:b4-20688-6", "language": ["de:0.99"], "booktitle": "Zinzendorf, Nicolaus Ludwig von: Teutscher Gedichte Erster Theil. Herrnhuth, 1735."}, "poem": {"stanza.1": {"line.1": {"text": "Nach vielen unbequemen Stunden,", "tokens": ["Nach", "vie\u00b7len", "un\u00b7be\u00b7que\u00b7men", "Stun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Nach jenes langen Winters Plag,", "tokens": ["Nach", "je\u00b7nes", "lan\u00b7gen", "Win\u00b7ters", "Plag", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Hast du ein lieblichs Lo\u00df gefunden,", "tokens": ["Hast", "du", "ein", "lieb\u00b7lichs", "Lo\u00df", "ge\u00b7fun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und siehest einen Sommer-Tag;", "tokens": ["Und", "sie\u00b7hest", "ei\u00b7nen", "Som\u00b7mer\u00b7Tag", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Nach Kranckheits-Noth", "tokens": ["Nach", "Kranck\u00b7heits\u00b7Noth"], "token_info": ["word", "word"], "pos": ["APPR", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.6": {"text": "Entweicht der Tod,", "tokens": ["Ent\u00b7weicht", "der", "Tod", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "Und durch der Auferstehung Krafft", "tokens": ["Und", "durch", "der", "Auf\u00b7er\u00b7ste\u00b7hung", "Krafft"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Empf\u00e4ngst du neuen Lebens-Safft.", "tokens": ["Emp\u00b7f\u00e4ngst", "du", "neu\u00b7en", "Le\u00b7bens\u00b7\u00b7S\u00b7afft", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJA", "NN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.2": {"line.1": {"text": "Wie s\u00fc\u00df ist doch des HErren Liebe!", "tokens": ["Wie", "s\u00fc\u00df", "ist", "doch", "des", "Her\u00b7ren", "Lie\u00b7be", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VAFIN", "ADV", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wie unerforschlich ist sein Rath!", "tokens": ["Wie", "un\u00b7er\u00b7for\u00b7schlich", "ist", "sein", "Rath", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VAFIN", "PPOSAT", "NN", "$."], "meter": "-+-++--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Wie m\u00e4chtig seines Zuges Triebe!", "tokens": ["Wie", "m\u00e4ch\u00b7tig", "sei\u00b7nes", "Zu\u00b7ges", "Trie\u00b7be", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wie w\u00fcrcksam seiner H\u00e4nde That!", "tokens": ["Wie", "w\u00fcrck\u00b7sam", "sei\u00b7ner", "H\u00e4n\u00b7de", "That", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Dich st\u00f6st der HErr", "tokens": ["Dich", "st\u00f6st", "der", "Herr"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.6": {"text": "Nicht ferne von des Vaters Hau\u00df", "tokens": ["Nicht", "fer\u00b7ne", "von", "des", "Va\u00b7ters", "Hau\u00df"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PTKNEG", "ADV", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "In eine reiche Erndte aus.", "tokens": ["In", "ei\u00b7ne", "rei\u00b7che", "Ernd\u00b7te", "aus", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Nur mich, das \u00e4rmste seiner Kinder,", "tokens": ["Nur", "mich", ",", "das", "\u00e4rms\u00b7te", "sei\u00b7ner", "Kin\u00b7der", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "$,", "ART", "ADJA", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Mich seinen matten S\u00e4ugeling,", "tokens": ["Mich", "sei\u00b7nen", "mat\u00b7ten", "S\u00e4u\u00b7ge\u00b7ling", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mich heist der holde Freund der S\u00fcnder", "tokens": ["Mich", "heist", "der", "hol\u00b7de", "Freund", "der", "S\u00fcn\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Bey nah ein unbeqvemes Ding.", "tokens": ["Bey", "nah", "ein", "un\u00b7be\u00b7qve\u00b7mes", "Ding", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJD", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ich nahe kaum", "tokens": ["Ich", "na\u00b7he", "kaum"], "token_info": ["word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV"], "meter": "-+-+", "measure": "iambic.di"}, "line.6": {"text": "Zum engen Raum,", "tokens": ["Zum", "en\u00b7gen", "Raum", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "Und auf die schmale Pforte zu,", "tokens": ["Und", "auf", "die", "schma\u00b7le", "Pfor\u00b7te", "zu", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "So unterbricht er mir die Ruh.", "tokens": ["So", "un\u00b7ter\u00b7bricht", "er", "mir", "die", "Ruh", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Wohlan, es ist ja seine Weise,", "tokens": ["Wo\u00b7hlan", ",", "es", "ist", "ja", "sei\u00b7ne", "Wei\u00b7se", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PPER", "VAFIN", "ADV", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Er w\u00fcrckt, wir sind nur Handwercks-Zeug:", "tokens": ["Er", "w\u00fcrckt", ",", "wir", "sind", "nur", "Handwercks\u00b7Zeug", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VAFIN", "ADV", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Er zieh mich nur gemach und leise,", "tokens": ["Er", "zieh", "mich", "nur", "ge\u00b7mach", "und", "lei\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ADV", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Denn ich bin gar ein schwacher Zweig;", "tokens": ["Denn", "ich", "bin", "gar", "ein", "schwa\u00b7cher", "Zweig", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Soll solch ein Rei\u00df", "tokens": ["Soll", "solch", "ein", "Rei\u00df"], "token_info": ["word", "word", "word", "word"], "pos": ["VMFIN", "PIAT", "ART", "NN"], "meter": "+--+", "measure": "iambic.di.chol"}, "line.6": {"text": "Zu seinem Prei\u00df", "tokens": ["Zu", "sei\u00b7nem", "Prei\u00df"], "token_info": ["word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "Mit Fruchten angef\u00fcllet seyn,", "tokens": ["Mit", "Fruch\u00b7ten", "an\u00b7ge\u00b7f\u00fcl\u00b7let", "seyn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVPP", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "So pfropf ers in sich selber ein.", "tokens": ["So", "pfropf", "ers", "in", "sich", "sel\u00b7ber", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "APPR", "PRF", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Wie komm ich nur auf solche Sachen?", "tokens": ["Wie", "komm", "ich", "nur", "auf", "sol\u00b7che", "Sa\u00b7chen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "ADV", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Was schreib ich \u00f6ffentlich davon?", "tokens": ["Was", "schreib", "ich", "\u00f6f\u00b7fent\u00b7lich", "da\u00b7von", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ADJD", "PAV", "$."], "meter": "-+--+-++", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Das ist ja nur der Welt ihr Lachen,", "tokens": ["Das", "ist", "ja", "nur", "der", "Welt", "ihr", "La\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "ADV", "ART", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Das lieset Jsmael mit Hohn.", "tokens": ["Das", "lie\u00b7set", "Js\u00b7mael", "mit", "Hohn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "NE", "APPR", "NN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.5": {"text": "Ist wahr? Allein", "tokens": ["Ist", "wahr", "?", "Al\u00b7lein"], "token_info": ["word", "word", "punct", "word"], "pos": ["VAFIN", "ADJD", "$.", "ADV"], "meter": "-+-+", "measure": "iambic.di"}, "line.6": {"text": "Jetzt kan es seyn,", "tokens": ["Jetzt", "kan", "es", "seyn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "VAINF", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "Da\u00df man sich laut erg\u00f6tzen mag;", "tokens": ["Da\u00df", "man", "sich", "laut", "er\u00b7g\u00f6t\u00b7zen", "mag", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PRF", "ADJD", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Dann heute ist ein Hochzeit-Tag.", "tokens": ["Dann", "heu\u00b7te", "ist", "ein", "Hoch\u00b7zeit\u00b7Tag", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VAFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Stimmt aber auch der Freund der Seelen", "tokens": ["Stimmt", "a\u00b7ber", "auch", "der", "Freund", "der", "See\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "ADV", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Mit diesem ihren Vorsatz ein,", "tokens": ["Mit", "die\u00b7sem", "ih\u00b7ren", "Vor\u00b7satz", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da\u00df sie sich anderw\u00e4rts verm\u00e4hlen,", "tokens": ["Da\u00df", "sie", "sich", "an\u00b7der\u00b7w\u00e4rts", "ver\u00b7m\u00e4h\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Sie, die schon lange feine seyn?", "tokens": ["Sie", ",", "die", "schon", "lan\u00b7ge", "fei\u00b7ne", "seyn", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PRELS", "ADV", "ADV", "ADJA", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Es scheint fast nicht;", "tokens": ["Es", "scheint", "fast", "nicht", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PTKNEG", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.6": {"text": "Di\u00df reine Licht", "tokens": ["Di\u00df", "rei\u00b7ne", "Licht"], "token_info": ["word", "word", "word"], "pos": ["PDS", "ADJA", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "Ha\u00dft alles frembden Feuers Pracht,", "tokens": ["Ha\u00dft", "al\u00b7les", "fremb\u00b7den", "Feu\u00b7ers", "Pracht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Das sich zu seinem Altar macht.", "tokens": ["Das", "sich", "zu", "sei\u00b7nem", "Al\u00b7tar", "macht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PRF", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Und viele liebe GOttes-Kinder", "tokens": ["Und", "vie\u00b7le", "lie\u00b7be", "Got\u00b7tes\u00b7Kin\u00b7der"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Vermeynen dieses eben auch,", "tokens": ["Ver\u00b7mey\u00b7nen", "die\u00b7ses", "e\u00b7ben", "auch", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PDAT", "ADV", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der Liebe unserm Uberwinder", "tokens": ["Der", "Lie\u00b7be", "un\u00b7serm", "U\u00b7ber\u00b7win\u00b7der"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Mi\u00dffalle dieser Welt-Gebrauch;", "tokens": ["Mi\u00df\u00b7fal\u00b7le", "die\u00b7ser", "Welt\u00b7Ge\u00b7brauch", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PDAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wo man sich noch", "tokens": ["Wo", "man", "sich", "noch"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "PIS", "PRF", "ADV"], "meter": "-+-+", "measure": "iambic.di"}, "line.6": {"text": "Ein ander Joch,", "tokens": ["Ein", "an\u00b7der", "Joch", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "+--+", "measure": "iambic.di.chol"}, "line.7": {"text": "Zu ihrer Liebes-B\u00fcrd und Plag,", "tokens": ["Zu", "ih\u00b7rer", "Lie\u00b7bes\u00b7B\u00fcrd", "und", "Plag", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Auf seine Schultern binden mag.", "tokens": ["Auf", "sei\u00b7ne", "Schul\u00b7tern", "bin\u00b7den", "mag."], "token_info": ["word", "word", "word", "word", "abbreviation"], "pos": ["APPR", "PPOSAT", "NN", "VVINF", "VMFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Da\u00df unsrer Seelen Hut und Wache", "tokens": ["Da\u00df", "uns\u00b7rer", "See\u00b7len", "Hut", "und", "Wa\u00b7che"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPOSAT", "NN", "NN", "KON", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Beym Ehestand verdoppelt wird,", "tokens": ["Beym", "E\u00b7hes\u00b7tand", "ver\u00b7dop\u00b7pelt", "wird", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ist eine ausgemachte Sache,", "tokens": ["Ist", "ei\u00b7ne", "aus\u00b7ge\u00b7mach\u00b7te", "Sa\u00b7che", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und wird darinnen sehr geirrt.", "tokens": ["Und", "wird", "da\u00b7rin\u00b7nen", "sehr", "ge\u00b7irrt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Man machet sich", "tokens": ["Man", "ma\u00b7chet", "sich"], "token_info": ["word", "word", "word"], "pos": ["PIS", "VVFIN", "PRF"], "meter": "-+-+", "measure": "iambic.di"}, "line.6": {"text": "Gemeiniglich", "tokens": ["Ge\u00b7mei\u00b7nig\u00b7lich"], "token_info": ["word"], "pos": ["NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "Die Ehe gar zum leichten Ding,", "tokens": ["Die", "E\u00b7he", "gar", "zum", "leich\u00b7ten", "Ding", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Und ihre M\u00fche scheint gering.", "tokens": ["Und", "ih\u00b7re", "M\u00fc\u00b7he", "scheint", "ge\u00b7ring", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Drum wenn man wei\u00dflich \u00fcberleget,", "tokens": ["Drum", "wenn", "man", "wei\u00df\u00b7lich", "\u00fc\u00b7ber\u00b7le\u00b7get", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "KOUS", "PIS", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wie Mangel, Creutz und mancher Dampf", "tokens": ["Wie", "Man\u00b7gel", ",", "Creutz", "und", "man\u00b7cher", "Dampf"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWAV", "NN", "$,", "NN", "KON", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sich mit der Eh zugleich erreget,", "tokens": ["Sich", "mit", "der", "Eh", "zu\u00b7gleich", "er\u00b7re\u00b7get", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "ART", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und wie, in diesem schweren Kampf,", "tokens": ["Und", "wie", ",", "in", "die\u00b7sem", "schwe\u00b7ren", "Kampf", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "$,", "APPR", "PDAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Manch l\u00fcstern Lamm", "tokens": ["Manch", "l\u00fcs\u00b7tern", "Lamm"], "token_info": ["word", "word", "word"], "pos": ["PIAT", "ADJA", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.6": {"text": "Den Br\u00e4utigam", "tokens": ["Den", "Br\u00e4u\u00b7ti\u00b7gam"], "token_info": ["word", "word"], "pos": ["ART", "NE"], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "Verschertzt mit samt der Jungfrauschafft,", "tokens": ["Ver\u00b7schertzt", "mit", "samt", "der", "Jung\u00b7frausc\u00b7hafft", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "APPR", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Indem es sich ins Fleisch vergafft:", "tokens": ["In\u00b7dem", "es", "sich", "ins", "Fleisch", "ver\u00b7gafft", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "So m\u00f6chte man sich wohl bedencken,", "tokens": ["So", "m\u00f6ch\u00b7te", "man", "sich", "wohl", "be\u00b7den\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PIS", "PRF", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Obs kein verwegner Handel sey,", "tokens": ["Obs", "kein", "ver\u00b7weg\u00b7ner", "Han\u00b7del", "sey", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PIAT", "ADJA", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sich also leichtlich wegzuschencken.", "tokens": ["Sich", "al\u00b7so", "leicht\u00b7lich", "weg\u00b7zu\u00b7schen\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PRF", "ADV", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Gewi\u00df, ich stimme Paulo bey;", "tokens": ["Ge\u00b7wi\u00df", ",", "ich", "stim\u00b7me", "Pau\u00b7lo", "bey", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PPER", "VVFIN", "NE", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die beste Eh", "tokens": ["Die", "bes\u00b7te", "Eh"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.6": {"text": "Halt ich vor Weh,", "tokens": ["Halt", "ich", "vor", "Weh", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "APPR", "NN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "Es sey der Mann denn Christi Braut,", "tokens": ["Es", "sey", "der", "Mann", "denn", "Chris\u00b7ti", "Braut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "KON", "NE", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Und auch das Weib dem HErrn vertraut.", "tokens": ["Und", "auch", "das", "Weib", "dem", "Herrn", "ver\u00b7traut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Auf diese Weise la\u00df ichs gelten,", "tokens": ["Auf", "die\u00b7se", "Wei\u00b7se", "la\u00df", "ichs", "gel\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "VVFIN", "PIS", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df du dir eine Braut erlie\u00dft,", "tokens": ["Da\u00df", "du", "dir", "ei\u00b7ne", "Braut", "er\u00b7lie\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wenn Christus dir vor tausend Welten", "tokens": ["Wenn", "Chris\u00b7tus", "dir", "vor", "tau\u00b7send", "Wel\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "NE", "PPER", "APPR", "CARD", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und vor dir selbst am liebsten ist,", "tokens": ["Und", "vor", "dir", "selbst", "am", "liebs\u00b7ten", "ist", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPER", "ADV", "PTKA", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und ist dein Weib", "tokens": ["Und", "ist", "dein", "Weib"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VAFIN", "PPOSAT", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.6": {"text": "Ein Glied am Leib", "tokens": ["Ein", "Glied", "am", "Leib"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "APPRART", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "Des Br\u00e4utigams; so lieb es dann", "tokens": ["Des", "Br\u00e4u\u00b7ti\u00b7gams", ";", "so", "lieb", "es", "dann"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NE", "$.", "ADV", "ADJD", "PPER", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Allein in Jhm, denn Er ist Mann.", "tokens": ["Al\u00b7lein", "in", "Jhm", ",", "denn", "Er", "ist", "Mann", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPER", "$,", "KON", "PPER", "VAFIN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "So darffst du denn auch wenig sorgen,", "tokens": ["So", "darffst", "du", "denn", "auch", "we\u00b7nig", "sor\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ADV", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wie lange sie bey dir verweilt;", "tokens": ["Wie", "lan\u00b7ge", "sie", "bey", "dir", "ver\u00b7weilt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "PPER", "APPR", "PPER", "VVFIN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "Vielmehr da heute oder morgen", "tokens": ["Viel\u00b7mehr", "da", "heu\u00b7te", "o\u00b7der", "mor\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "ADV", "KON", "ADV"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die Ehgeh\u00fclffin heimwarts eilt,", "tokens": ["Die", "Eh\u00b7ge\u00b7h\u00fclf\u00b7fin", "heim\u00b7warts", "eilt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "So dringt dein Sinn,", "tokens": ["So", "dringt", "dein", "Sinn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.6": {"text": "Zugleich dahin,", "tokens": ["Zu\u00b7gleich", "da\u00b7hin", ","], "token_info": ["word", "word", "punct"], "pos": ["ADV", "PAV", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "Wo sie beym rechten Schatze ruht,", "tokens": ["Wo", "sie", "beym", "rech\u00b7ten", "Schat\u00b7ze", "ruht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "APPRART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Und h\u00e4lt es ihm und ihr zu gut.", "tokens": ["Und", "h\u00e4lt", "es", "ihm", "und", "ihr", "zu", "gut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PPER", "KON", "PPER", "PTKA", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Sie l\u00e4st sichs ebenfalls gefallen,", "tokens": ["Sie", "l\u00e4st", "sichs", "e\u00b7ben\u00b7falls", "ge\u00b7fal\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wenn JEsus ihr verlobter Freund,", "tokens": ["Wenn", "Je\u00b7sus", "ihr", "ver\u00b7lob\u00b7ter", "Freund", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mit dem sie, vor den andern allen,", "tokens": ["Mit", "dem", "sie", ",", "vor", "den", "an\u00b7dern", "al\u00b7len", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "$,", "APPR", "ART", "ADJA", "PIAT", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Es hertzlich gut und redlich meynt,", "tokens": ["Es", "hertz\u00b7lich", "gut", "und", "red\u00b7lich", "meynt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "ADJD", "KON", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Den lieben Mann,", "tokens": ["Den", "lie\u00b7ben", "Mann", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.6": {"text": "Der sie gewann,", "tokens": ["Der", "sie", "ge\u00b7wann", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVFIN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "Aus dieses Lebens rauher Lufft", "tokens": ["Aus", "die\u00b7ses", "Le\u00b7bens", "rau\u00b7her", "Lufft"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PDAT", "NN", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "In seine stille H\u00fctte rufft.", "tokens": ["In", "sei\u00b7ne", "stil\u00b7le", "H\u00fct\u00b7te", "rufft", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Nur will gar viel darzu geh\u00f6ren", "tokens": ["Nur", "will", "gar", "viel", "dar\u00b7zu", "ge\u00b7h\u00f6\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "ADV", "PIS", "PAV", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "In dieser Fassung fest zu stehn:", "tokens": ["In", "die\u00b7ser", "Fas\u00b7sung", "fest", "zu", "stehn", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Man l\u00e4st sich durch das Fleisch beth\u00f6ren", "tokens": ["Man", "l\u00e4st", "sich", "durch", "das", "Fleisch", "be\u00b7th\u00f6\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "PRF", "APPR", "ART", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "In g\u00f6ldne Fesseln einzugehn,", "tokens": ["In", "g\u00f6ld\u00b7ne", "Fes\u00b7seln", "ein\u00b7zu\u00b7gehn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVIZU", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Man meynt dabey:", "tokens": ["Man", "meynt", "da\u00b7bey", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PAV", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.6": {"text": "Wie starck man sey?", "tokens": ["Wie", "starck", "man", "sey", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PIS", "VAFIN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "Und wann man sich verstricket hat;", "tokens": ["Und", "wann", "man", "sich", "ver\u00b7stri\u00b7cket", "hat", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PIS", "PRF", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "So ist die Reue gern zu spat.", "tokens": ["So", "ist", "die", "Reu\u00b7e", "gern", "zu", "spat", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "ADV", "PTKZU", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "Drum ists ein sonderlicher Seegen,", "tokens": ["Drum", "ists", "ein", "son\u00b7der\u00b7li\u00b7cher", "See\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wen, in der Grund-verderbten Welt,", "tokens": ["Wen", ",", "in", "der", "Grun\u00b7dver\u00b7derb\u00b7ten", "Welt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "$,", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der HErr in seinen schlechten Wegen", "tokens": ["Der", "Herr", "in", "sei\u00b7nen", "schlech\u00b7ten", "We\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und in dem rechten Glei\u00df erh\u00e4lt.", "tokens": ["Und", "in", "dem", "rech\u00b7ten", "Glei\u00df", "er\u00b7h\u00e4lt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wenn einige", "tokens": ["Wenn", "ei\u00b7ni\u00b7ge"], "token_info": ["word", "word"], "pos": ["KOUS", "PIS"], "meter": "-+-+", "measure": "iambic.di"}, "line.6": {"text": "In ihrer Eh", "tokens": ["In", "ih\u00b7rer", "Eh"], "token_info": ["word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "So ehrlich sind und unbefleckt,", "tokens": ["So", "ehr\u00b7lich", "sind", "und", "un\u00b7be\u00b7fleckt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VAFIN", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Da\u00df sie der Br\u00e4utgam einst nicht schreckt.", "tokens": ["Da\u00df", "sie", "der", "Br\u00e4ut\u00b7gam", "einst", "nicht", "schreckt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NE", "ADV", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "Da\u00df Ehen so bestehen k\u00f6nnen,", "tokens": ["Da\u00df", "E\u00b7hen", "so", "be\u00b7ste\u00b7hen", "k\u00f6n\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "ADV", "VVINF", "VMINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Mu\u00df ewig eine Wahrheit seyn.", "tokens": ["Mu\u00df", "e\u00b7wig", "ei\u00b7ne", "Wahr\u00b7heit", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADJD", "ART", "NN", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Paul darff sie Ehrenw\u00fcrdig nennen.", "tokens": ["Paul", "darff", "sie", "Eh\u00b7ren\u00b7w\u00fcr\u00b7dig", "nen\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VMFIN", "PPER", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Das stimmte ja nicht \u00fcberein;", "tokens": ["Das", "stimm\u00b7te", "ja", "nicht", "\u00fc\u00b7be\u00b7re\u00b7in", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "PTKNEG", "PTKVZ", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.5": {"text": "Wenn einge Lust", "tokens": ["Wenn", "ein\u00b7ge", "Lust"], "token_info": ["word", "word", "word"], "pos": ["KOUS", "ADJA", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.6": {"text": "Gott unbewust,", "tokens": ["Gott", "un\u00b7be\u00b7wust", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "ADJD", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "Und die nicht in sein Reich geh\u00f6r,", "tokens": ["Und", "die", "nicht", "in", "sein", "Reich", "ge\u00b7h\u00f6r", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "PTKNEG", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Jm Ehestand erlaubet w\u00e4r.", "tokens": ["Jm", "E\u00b7hes\u00b7tand", "er\u00b7lau\u00b7bet", "w\u00e4r", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.17": {"line.1": {"text": "Es wird zwar Fleisch vom Fleisch gebohren,", "tokens": ["Es", "wird", "zwar", "Fleisch", "vom", "Fleisch", "ge\u00b7boh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "NN", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und das aus GOttes weisem Rath,", "tokens": ["Und", "das", "aus", "Got\u00b7tes", "wei\u00b7sem", "Rath", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "APPR", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der, eh der Mensch sein Bild verlohren,", "tokens": ["Der", ",", "eh", "der", "Mensch", "sein", "Bild", "ver\u00b7loh\u00b7ren", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "KOUS", "ART", "NN", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Jhm schon ein Weib erbauet hat:", "tokens": ["Jhm", "schon", "ein", "Weib", "er\u00b7bau\u00b7et", "hat", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ART", "NN", "VVFIN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die L\u00fcsternheit", "tokens": ["Die", "L\u00fcs\u00b7tern\u00b7heit"], "token_info": ["word", "word"], "pos": ["ART", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.6": {"text": "Drang nach der Zeit", "tokens": ["Drang", "nach", "der", "Zeit"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "APPR", "ART", "NN"], "meter": "+--+", "measure": "iambic.di.chol"}, "line.7": {"text": "Auch auf die liebe Ehe an,", "tokens": ["Auch", "auf", "die", "lie\u00b7be", "E\u00b7he", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Und machte sie ihr unterthan.", "tokens": ["Und", "mach\u00b7te", "sie", "ihr", "un\u00b7ter\u00b7than", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PPER", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.18": {"line.1": {"text": "In denen drauf gefolgten Tagen,", "tokens": ["In", "de\u00b7nen", "drauf", "ge\u00b7folg\u00b7ten", "Ta\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PAV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wards endlich so wie ietzt bestellt;", "tokens": ["Wards", "end\u00b7lich", "so", "wie", "ietzt", "be\u00b7stellt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "KOKOM", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da sich die Kinder GOttes wagen", "tokens": ["Da", "sich", "die", "Kin\u00b7der", "Got\u00b7tes", "wa\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PRF", "ART", "NN", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "In das Gedr\u00e4nge dieser Welt.", "tokens": ["In", "das", "Ge\u00b7dr\u00e4n\u00b7ge", "die\u00b7ser", "Welt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PDAT", "NN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.5": {"text": "Sie trauen sich", "tokens": ["Sie", "trau\u00b7en", "sich"], "token_info": ["word", "word", "word"], "pos": ["PPER", "VVFIN", "PRF"], "meter": "-+-+", "measure": "iambic.di"}, "line.6": {"text": "Gar sonderlich,", "tokens": ["Gar", "son\u00b7der\u00b7lich", ","], "token_info": ["word", "word", "punct"], "pos": ["ADV", "ADJD", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "Und gehen mit der Lust zum Tantz;", "tokens": ["Und", "ge\u00b7hen", "mit", "der", "Lust", "zum", "Tantz", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "So kommen sie um ihren Crantz.", "tokens": ["So", "kom\u00b7men", "sie", "um", "ih\u00b7ren", "Crantz", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.19": {"line.1": {"text": "Da mengen sich die Kinder GOttes", "tokens": ["Da", "men\u00b7gen", "sich", "die", "Kin\u00b7der", "Got\u00b7tes"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PRF", "ART", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "In allen Koth der Eitelkeit,", "tokens": ["In", "al\u00b7len", "Koth", "der", "Ei\u00b7tel\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und sch\u00e4men sich des kleinen Spottes ", "tokens": ["Und", "sch\u00e4\u00b7men", "sich", "des", "klei\u00b7nen", "Spot\u00b7tes"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PRF", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "In dieser kurtzen Pr\u00fcfungs-Zeit.", "tokens": ["In", "die\u00b7ser", "kurt\u00b7zen", "Pr\u00fc\u00b7fungs\u00b7Zeit", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Das war nun auch", "tokens": ["Das", "war", "nun", "auch"], "token_info": ["word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "ADV", "ADV"], "meter": "-+-+", "measure": "iambic.di"}, "line.6": {"text": "Vor Alters Brauch,", "tokens": ["Vor", "Al\u00b7ters", "Brauch", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "NN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "Da sah sich GOttes Eigenthum,", "tokens": ["Da", "sah", "sich", "Got\u00b7tes", "Ei\u00b7gen\u00b7thum", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Nach T\u00f6chtern dieser Erden um.", "tokens": ["Nach", "T\u00f6ch\u00b7tern", "die\u00b7ser", "Er\u00b7den", "um", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PDAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.20": {"line.1": {"text": "Allein, wie ist es abgelauffen?", "tokens": ["Al\u00b7lein", ",", "wie", "ist", "es", "ab\u00b7ge\u00b7lauf\u00b7fen", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PWAV", "VAFIN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Das w\u00e4hrte bis die S\u00fcnd-Fluth kam,", "tokens": ["Das", "w\u00e4hr\u00b7te", "bis", "die", "S\u00fcn\u00b7dFluth", "kam", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und diesen angesteckten Hauffen", "tokens": ["Und", "die\u00b7sen", "an\u00b7ge\u00b7steck\u00b7ten", "Hauf\u00b7fen"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PDAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Jm Eifer von der Erde nahm.", "tokens": ["Jm", "Ei\u00b7fer", "von", "der", "Er\u00b7de", "nahm", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Da sahe man", "tokens": ["Da", "sa\u00b7he", "man"], "token_info": ["word", "word", "word"], "pos": ["ADV", "VVFIN", "PIS"], "meter": "-+--", "measure": "dactylic.init"}, "line.6": {"text": "Mit Schrecken an,", "tokens": ["Mit", "Schre\u00b7cken", "an", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "PTKVZ", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "Wie sich der Liebes-Geist erwie\u00df,", "tokens": ["Wie", "sich", "der", "Lie\u00b7bes\u00b7Geist", "er\u00b7wie\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PRF", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Und seine Ehre niemand lie\u00df.", "tokens": ["Und", "sei\u00b7ne", "Eh\u00b7re", "nie\u00b7mand", "lie\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "PIS", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.21": {"line.1": {"text": "Die Bo\u00dfheit bricht zu unsern Zeiten,", "tokens": ["Die", "Bo\u00df\u00b7heit", "bricht", "zu", "un\u00b7sern", "Zei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Als eine S\u00fcndfluth, da herein;", "tokens": ["Als", "ei\u00b7ne", "S\u00fcnd\u00b7fluth", ",", "da", "her\u00b7ein", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "$,", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die Welt ist voll von b\u00f6sen Leuten;", "tokens": ["Die", "Welt", "ist", "voll", "von", "b\u00f6\u00b7sen", "Leu\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Weil viele unerfahren seyn,", "tokens": ["Weil", "vie\u00b7le", "un\u00b7er\u00b7fah\u00b7ren", "seyn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ADJD", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Was Hurerey,", "tokens": ["Was", "Hu\u00b7re\u00b7rey", ","], "token_info": ["word", "word", "punct"], "pos": ["PWS", "NN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.6": {"text": "Was Ehe sey", "tokens": ["Was", "E\u00b7he", "sey"], "token_info": ["word", "word", "word"], "pos": ["PWS", "NN", "VAFIN"], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "Und sich, als nach der Thiere Art,", "tokens": ["Und", "sich", ",", "als", "nach", "der", "Thie\u00b7re", "Art", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "$,", "KOUS", "APPR", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Das eine mit dem andern paart.", "tokens": ["Das", "ei\u00b7ne", "mit", "dem", "an\u00b7dern", "paart", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ART", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.22": {"line.1": {"text": "Drum, die ihr aus dem h\u00f6chsten Wesen,", "tokens": ["Drum", ",", "die", "ihr", "aus", "dem", "h\u00f6chs\u00b7ten", "We\u00b7sen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "$,", "PRELS", "PPER", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und aus dem Geist gebohren seyd,", "tokens": ["Und", "aus", "dem", "Geist", "ge\u00b7boh\u00b7ren", "seyd", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die sich der HErr zur Braut erlesen,", "tokens": ["Die", "sich", "der", "Herr", "zur", "Braut", "er\u00b7le\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "ART", "NN", "APPRART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Verbindet euch zu dieser Zeit;", "tokens": ["Ver\u00b7bin\u00b7det", "euch", "zu", "die\u00b7ser", "Zeit", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "PDAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Folgt nah und fern", "tokens": ["Folgt", "nah", "und", "fern"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "ADJD", "KON", "ADJD"], "meter": "-+-+", "measure": "iambic.di"}, "line.6": {"text": "Dem Jacobs-Stern;", "tokens": ["Dem", "Ja\u00b7cobs\u00b7S\u00b7tern", ";"], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.7": {"text": "Und wie euch der beruffen hat,", "tokens": ["Und", "wie", "euch", "der", "be\u00b7ruf\u00b7fen", "hat", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPER", "ART", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "So wandelt, nicht nach eurem Rath.", "tokens": ["So", "wan\u00b7delt", ",", "nicht", "nach", "eu\u00b7rem", "Rath", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "PTKNEG", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.23": {"line.1": {"text": "Seyd ihr, dem Lamme nachzueilen,", "tokens": ["Seyd", "ihr", ",", "dem", "Lam\u00b7me", "nach\u00b7zu\u00b7ei\u00b7len", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAIMP", "PPER", "$,", "ART", "NN", "VVIZU", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Voll obenher entflammter Brunst,", "tokens": ["Voll", "o\u00b7ben\u00b7her", "ent\u00b7flamm\u00b7ter", "Brunst", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und denckt euch nimmermehr zu theilen:", "tokens": ["Und", "denckt", "euch", "nim\u00b7mer\u00b7mehr", "zu", "thei\u00b7len", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "So lernet diese edle Kunst,", "tokens": ["So", "ler\u00b7net", "die\u00b7se", "ed\u00b7le", "Kunst", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PDAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und lernt dabey.", "tokens": ["Und", "lernt", "da\u00b7bey", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PAV", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.6": {"text": "Was Demuth sey,", "tokens": ["Was", "De\u00b7muth", "sey", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PWS", "NN", "VAFIN", "$,"], "meter": "-+--", "measure": "dactylic.init"}, "line.7": {"text": "Die richtet keinen frembden Knecht,", "tokens": ["Die", "rich\u00b7tet", "kei\u00b7nen", "fremb\u00b7den", "Knecht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "So werdet ihr dem Freunde recht.", "tokens": ["So", "wer\u00b7det", "ihr", "dem", "Freun\u00b7de", "recht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.24": {"line.1": {"text": "Und ihr, die GOttes weiser Wille", "tokens": ["Und", "ihr", ",", "die", "Got\u00b7tes", "wei\u00b7ser", "Wil\u00b7le"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "PPER", "$,", "ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ins Eheband beschlossen hat,", "tokens": ["Ins", "E\u00b7he\u00b7band", "be\u00b7schlos\u00b7sen", "hat", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Bestrebet euch nach wahrer Stille,", "tokens": ["Be\u00b7stre\u00b7bet", "euch", "nach", "wah\u00b7rer", "Stil\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und fragt des HErren Wort um Rath.", "tokens": ["Und", "fragt", "des", "Her\u00b7ren", "Wort", "um", "Rath", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ein Ehe-Mann", "tokens": ["Ein", "E\u00b7he\u00b7Mann"], "token_info": ["word", "word"], "pos": ["ART", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.6": {"text": "Ist \u00fcbler dran,", "tokens": ["Ist", "\u00fcb\u00b7ler", "dran", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "ADJA", "PAV", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "Denn Christi Freygelassener,", "tokens": ["Denn", "Chris\u00b7ti", "Frey\u00b7ge\u00b7las\u00b7se\u00b7ner", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "NE", "NN", "$,"], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}, "line.8": {"text": "Und eine Ehe-Frau hats schwer.", "tokens": ["Und", "ei\u00b7ne", "E\u00b7he\u00b7Frau", "hats", "schwer", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VAFIN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.25": {"line.1": {"text": "Das mu\u00df euch aber nicht verhindern", "tokens": ["Das", "mu\u00df", "euch", "a\u00b7ber", "nicht", "ver\u00b7hin\u00b7dern"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VMFIN", "PPER", "ADV", "PTKNEG", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Jm keuschen Kampfe treu zu seyn:", "tokens": ["Jm", "keu\u00b7schen", "Kamp\u00b7fe", "treu", "zu", "seyn", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "ADJD", "PTKZU", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sprecht, gleich den wohlgezognen Kindern,", "tokens": ["Sprecht", ",", "gleich", "den", "wohl\u00b7ge\u00b7zog\u00b7nen", "Kin\u00b7dern", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Fein offt ins Vaters Hause ein,", "tokens": ["Fein", "offt", "ins", "Va\u00b7ters", "Hau\u00b7se", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "APPRART", "NN", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und bittet ihn", "tokens": ["Und", "bit\u00b7tet", "ihn"], "token_info": ["word", "word", "word"], "pos": ["KON", "VVFIN", "PPER"], "meter": "-+-+", "measure": "iambic.di"}, "line.6": {"text": "Euch selbst zu ziehn,", "tokens": ["Euch", "selbst", "zu", "ziehn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "Damit der Geist, trotz Fleisch und Welt,", "tokens": ["Da\u00b7mit", "der", "Geist", ",", "trotz", "Fleisch", "und", "Welt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "NN", "$,", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Der Keuschheit Sieg und Crantz erh\u00e4lt.", "tokens": ["Der", "Keuschheit", "Sieg", "und", "Crantz", "er\u00b7h\u00e4lt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "KON", "NE", "VVFIN", "$."], "meter": "-++-+-+", "measure": "unknown.measure.tetra"}}, "stanza.26": {"line.1": {"text": "Der Mann sey GOttes Bild und Ehre,", "tokens": ["Der", "Mann", "sey", "Got\u00b7tes", "Bild", "und", "Eh\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "NN", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Das Weib des Mannes Ehren-Cron,", "tokens": ["Das", "Weib", "des", "Man\u00b7nes", "Eh\u00b7ren\u00b7Cron", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der Mann erbaue, be\u00dfre, lehre.", "tokens": ["Der", "Mann", "er\u00b7bau\u00b7e", ",", "be\u00df\u00b7re", ",", "leh\u00b7re", "."], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "VVFIN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Das Weib wei\u00df offt vielmehr davon;", "tokens": ["Das", "Weib", "wei\u00df", "offt", "viel\u00b7mehr", "da\u00b7von", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "ADV", "PAV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Allein ihr Sinn", "tokens": ["Al\u00b7lein", "ihr", "Sinn"], "token_info": ["word", "word", "word"], "pos": ["ADV", "PPOSAT", "NN"], "meter": "---+", "measure": "unknown.measure.single"}, "line.6": {"text": "Geht nur dahin,", "tokens": ["Geht", "nur", "da\u00b7hin", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PAV", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "Wie sie im sanfften stillen Geist", "tokens": ["Wie", "sie", "im", "sanff\u00b7ten", "stil\u00b7len", "Geist"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "APPRART", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Sich ihrem Ruff gem\u00e4\u00df erweist.", "tokens": ["Sich", "ih\u00b7rem", "Ruff", "ge\u00b7m\u00e4\u00df", "er\u00b7weist", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "PPOSAT", "NN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.27": {"line.1": {"text": "Das w\u00e4re, m\u00f6chte einer sagen,", "tokens": ["Das", "w\u00e4\u00b7re", ",", "m\u00f6ch\u00b7te", "ei\u00b7ner", "sa\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "$,", "VMFIN", "PIS", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wohl alles gut und wohl bestellt;", "tokens": ["Wohl", "al\u00b7les", "gut", "und", "wohl", "be\u00b7stellt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "ADJD", "KON", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Alleine, wenn wir weiter fragen:", "tokens": ["Al\u00b7lei\u00b7ne", ",", "wenn", "wir", "wei\u00b7ter", "fra\u00b7gen", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wies um die Leibes-Fr\u00fcchte h\u00e4lt?", "tokens": ["Wies", "um", "die", "Lei\u00b7bes\u00b7Fr\u00fcch\u00b7te", "h\u00e4lt", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Das Fleisch ist todt,", "tokens": ["Das", "Fleisch", "ist", "todt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.6": {"text": "Ein Greul vor GOtt.", "tokens": ["Ein", "Greul", "vor", "Gott", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "H\u00f6rt Paulum, der spricht freudig drein:", "tokens": ["H\u00f6rt", "Pau\u00b7lum", ",", "der", "spricht", "freu\u00b7dig", "drein", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "NE", "$,", "PRELS", "VVFIN", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Da\u00df unsre Kinder heilig seyn.", "tokens": ["Da\u00df", "uns\u00b7re", "Kin\u00b7der", "hei\u00b7lig", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.28": {"line.1": {"text": "Giebt einem nun der Sch\u00f6pffer Erben;", "tokens": ["Giebt", "ei\u00b7nem", "nun", "der", "Sch\u00f6pf\u00b7fer", "Er\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADV", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die zieh man ihm, nicht Menschen auf,", "tokens": ["Die", "zieh", "man", "ihm", ",", "nicht", "Men\u00b7schen", "auf", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PIS", "PPER", "$,", "PTKNEG", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Man lerne sie ihm leben, sterben,", "tokens": ["Man", "ler\u00b7ne", "sie", "ihm", "le\u00b7ben", ",", "ster\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "PPER", "VVINF", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und zeig in seinem eignen Lauff:", "tokens": ["Und", "zeig", "in", "sei\u00b7nem", "eig\u00b7nen", "Lauff", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wie man die Zeit", "tokens": ["Wie", "man", "die", "Zeit"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "PIS", "ART", "NN"], "meter": "+--+", "measure": "iambic.di.chol"}, "line.6": {"text": "Zur Ewigkeit", "tokens": ["Zur", "E\u00b7wig\u00b7keit"], "token_info": ["word", "word"], "pos": ["APPRART", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "Beschleunigen, und seinen Fu\u00df", "tokens": ["Be\u00b7schleu\u00b7ni\u00b7gen", ",", "und", "sei\u00b7nen", "Fu\u00df"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "KON", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Auf GOttes Wege richten mu\u00df.", "tokens": ["Auf", "Got\u00b7tes", "We\u00b7ge", "rich\u00b7ten", "mu\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.29": {"line.1": {"text": "Wenn viele so gesinnet w\u00e4ren,", "tokens": ["Wenn", "vie\u00b7le", "so", "ge\u00b7sin\u00b7net", "w\u00e4\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ADV", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Verbliebe manches Aergerni\u00df,", "tokens": ["Ver\u00b7blie\u00b7be", "man\u00b7ches", "A\u00b7er\u00b7ger\u00b7ni\u00df", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Damit die Menschen sich beschweren;", "tokens": ["Da\u00b7mit", "die", "Men\u00b7schen", "sich", "be\u00b7schwe\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "NN", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "So siegeten wir gantz gewi\u00df.", "tokens": ["So", "sie\u00b7ge\u00b7ten", "wir", "gantz", "ge\u00b7wi\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ADV", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.5": {"text": "Der Welt Gebrauch", "tokens": ["Der", "Welt", "Ge\u00b7brauch"], "token_info": ["word", "word", "word"], "pos": ["ART", "NN", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.6": {"text": "Ist immer auch:", "tokens": ["Ist", "im\u00b7mer", "auch", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "Genau auff Jsrael zu schaun;", "tokens": ["Ge\u00b7nau", "auff", "Js\u00b7rael", "zu", "schaun", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "NE", "PTKZU", "VVINF", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.8": {"text": "Wie w\u00fcrd\u2019 ein solch Exempel baun?", "tokens": ["Wie", "w\u00fcrd'", "ein", "solch", "Ex\u00b7em\u00b7pel", "baun", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "ART", "PIAT", "NN", "VVINF", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.30": {"line.1": {"text": "Und die sich an die Ehe stossen,", "tokens": ["Und", "die", "sich", "an", "die", "E\u00b7he", "stos\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "PRF", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Weil sie so wenig Ehen sehn,", "tokens": ["Weil", "sie", "so", "we\u00b7nig", "E\u00b7hen", "sehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PIAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die, weil sie erst aus GOtt geflossen,", "tokens": ["Die", ",", "weil", "sie", "erst", "aus", "Gott", "ge\u00b7flos\u00b7sen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "KOUS", "PPER", "ADV", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Auch wiederum zu GOtte gehn,", "tokens": ["Auch", "wie\u00b7de\u00b7rum", "zu", "Got\u00b7te", "gehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die fiengen dann", "tokens": ["Die", "fi\u00b7en\u00b7gen", "dann"], "token_info": ["word", "word", "word"], "pos": ["PDS", "VVFIN", "ADV"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.6": {"text": "Vermuthlich an,", "tokens": ["Ver\u00b7muth\u00b7lich", "an", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJD", "PTKVZ", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "Wenn es sich anders zeigete,", "tokens": ["Wenn", "es", "sich", "an\u00b7ders", "zei\u00b7ge\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Und lobten solche keusche Eh.", "tokens": ["Und", "lob\u00b7ten", "sol\u00b7che", "keu\u00b7sche", "Eh", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.31": {"line.1": {"text": "Erlaube mir, hier abzubrechen,", "tokens": ["Er\u00b7lau\u00b7be", "mir", ",", "hier", "ab\u00b7zu\u00b7bre\u00b7chen", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "ADV", "VVIZU", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Herr Br\u00e4utigam, und nur mit Dir,", "tokens": ["Herr", "Br\u00e4u\u00b7ti\u00b7gam", ",", "und", "nur", "mit", "Dir", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "$,", "KON", "ADV", "APPR", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Noch ein Ermuntrungs-Wort zu sprechen,", "tokens": ["Noch", "ein", "Er\u00b7mun\u00b7trungs\u00b7Wort", "zu", "spre\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Du bist wohl gleiches Sinns mit mir?", "tokens": ["Du", "bist", "wohl", "glei\u00b7ches", "Sinns", "mit", "mir", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJA", "NN", "APPR", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Du wirst di\u00df Band,", "tokens": ["Du", "wirst", "di\u00df", "Band", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PDS", "NN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.6": {"text": "Das GOtt erkannt,", "tokens": ["Das", "Gott", "er\u00b7kannt", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "Euch beyden nutz und gut zu seyn,", "tokens": ["Euch", "bey\u00b7den", "nutz", "und", "gut", "zu", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PIAT", "NN", "KON", "ADJD", "PTKZU", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Des Lammes s\u00fcsser Liebe weyhn.", "tokens": ["Des", "Lam\u00b7mes", "s\u00fcs\u00b7ser", "Lie\u00b7be", "weyhn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.32": {"line.1": {"text": "So wird des erstgebohrnen Nahme,", "tokens": ["So", "wird", "des", "erst\u00b7ge\u00b7bohr\u00b7nen", "Nah\u00b7me", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Auch \u00fcber eurer Liebe ruhn,", "tokens": ["Auch", "\u00fc\u00b7ber", "eu\u00b7rer", "Lie\u00b7be", "ruhn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und euer ihm geweyhter Saame,", "tokens": ["Und", "eu\u00b7er", "ihm", "ge\u00b7weyh\u00b7ter", "Saa\u00b7me", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "PPER", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wird nach des HErren Weise thun.", "tokens": ["Wird", "nach", "des", "Her\u00b7ren", "Wei\u00b7se", "thun", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "ART", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Dann werdet ihr,", "tokens": ["Dann", "wer\u00b7det", "ihr", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.6": {"text": "So dort als hier,", "tokens": ["So", "dort", "als", "hier", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "KOKOM", "ADV", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "In JEsu Liebe nimmer matt,", "tokens": ["In", "Je\u00b7su", "Lie\u00b7be", "nim\u00b7mer", "matt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "NN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Und einst in reiner Wollust satt.", "tokens": ["Und", "einst", "in", "rei\u00b7ner", "Wol\u00b7lust", "satt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "ADJA", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}