{"textgrid.poem.46992": {"metadata": {"author": {"name": "R\u00fcckert, Friedrich", "birth": "N.A.", "death": "N.A."}, "title": "Auf das M\u00e4dchen aus Potsdam, Prochaska", "genre": "verse", "period": "N.A.", "pub_year": 1827, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ich m\u00fc\u00dfte mich sch\u00e4men, ein Mann zu hei\u00dfen,", "tokens": ["Ich", "m\u00fc\u00df\u00b7te", "mich", "sch\u00e4\u00b7men", ",", "ein", "Mann", "zu", "hei\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PRF", "VVINF", "$,", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Wenn ich nicht k\u00f6nnte f\u00fchren das Eisen,", "tokens": ["Wenn", "ich", "nicht", "k\u00f6nn\u00b7te", "f\u00fch\u00b7ren", "das", "Ei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "VMFIN", "VVINF", "ART", "NN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Und wollte Weibern es g\u00f6nnen,", "tokens": ["Und", "woll\u00b7te", "Wei\u00b7bern", "es", "g\u00f6n\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "NN", "PPER", "VVINF", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Da\u00df sie f\u00fchren es k\u00f6nnen!", "tokens": ["Da\u00df", "sie", "f\u00fch\u00b7ren", "es", "k\u00f6n\u00b7nen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "PPER", "VMFIN", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}}, "stanza.2": {"line.1": {"text": "Wer ist der Gesell, so fein und jung?", "tokens": ["Wer", "ist", "der", "Ge\u00b7sell", ",", "so", "fein", "und", "jung", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ART", "NN", "$,", "ADV", "ADJD", "KON", "ADJD", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Doch f\u00fchrt er das Eisen mit gutem Schwung.", "tokens": ["Doch", "f\u00fchrt", "er", "das", "Ei\u00b7sen", "mit", "gu\u00b7tem", "Schwung", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ART", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Wer steckt unter der Maske?", "tokens": ["Wer", "steckt", "un\u00b7ter", "der", "Mas\u00b7ke", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+---+-", "measure": "dactylic.init"}, "line.4": {"text": "Eine Jungfrau, hei\u00dft ", "tokens": ["Ei\u00b7ne", "Jung\u00b7frau", ",", "hei\u00dft"], "token_info": ["word", "word", "punct", "word"], "pos": ["ART", "NN", "$,", "VVFIN"], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.3": {"line.1": {"text": "Wie merkten wir's nur nicht lange schon", "tokens": ["Wie", "merk\u00b7ten", "wir's", "nur", "nicht", "lan\u00b7ge", "schon"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "VVFIN", "PIS", "ADV", "PTKNEG", "ADV", "ADV"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Am glatten Kinn, am feineren Ton?", "tokens": ["Am", "glat\u00b7ten", "Kinn", ",", "am", "fei\u00b7ne\u00b7ren", "Ton", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "$,", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Doch unter den m\u00e4nnlichen Thaten", "tokens": ["Doch", "un\u00b7ter", "den", "m\u00e4nn\u00b7li\u00b7chen", "Tha\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "ADJA", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Wer konnte das Weib erraten?", "tokens": ["Wer", "konn\u00b7te", "das", "Weib", "er\u00b7ra\u00b7ten", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "ART", "NN", "VVINF", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.4": {"line.1": {"text": "Aber es hat sie getroffen ein Schu\u00df!", "tokens": ["A\u00b7ber", "es", "hat", "sie", "ge\u00b7trof\u00b7fen", "ein", "Schu\u00df", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "PPER", "VVPP", "ART", "NN", "$."], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.2": {"text": "Jetzt sagt sie's selber, weil sie mu\u00df.", "tokens": ["Jetzt", "sagt", "sie's", "sel\u00b7ber", ",", "weil", "sie", "mu\u00df", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "$,", "KOUS", "PPER", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wundarzt geh' beileibe", "tokens": ["Wund\u00b7arzt", "geh'", "bei\u00b7lei\u00b7be"], "token_info": ["word", "word", "word"], "pos": ["FM.la", "FM.la", "FM.la"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Nicht unsanft um mit dem Weibe!", "tokens": ["Nicht", "un\u00b7sanft", "um", "mit", "dem", "Wei\u00b7be", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADJD", "APPR", "APPR", "ART", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.5": {"line.1": {"text": "Zum Gl\u00fcck traf dich die Kugel nicht eh'r,", "tokens": ["Zum", "Gl\u00fcck", "traf", "dich", "die", "Ku\u00b7gel", "nicht", "eh'r", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PPER", "ART", "NN", "PTKNEG", "ADJD", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Als bist du dir hattest gn\u00fcgliche Ehr'", "tokens": ["Als", "bist", "du", "dir", "hat\u00b7test", "gn\u00fcg\u00b7li\u00b7che", "Ehr'"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "VAFIN", "PPER", "PPER", "VAFIN", "ADJA", "NN"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Erstritten in Mannesgeberden,", "tokens": ["Er\u00b7strit\u00b7ten", "in", "Man\u00b7nes\u00b7ge\u00b7ber\u00b7den", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "NN", "$,"], "meter": "-+--+-+--", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Jetzt kannst du ein Weib wieder werden.", "tokens": ["Jetzt", "kannst", "du", "ein", "Weib", "wie\u00b7der", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ART", "NN", "ADV", "VAINF", "$."], "meter": "-+-+++-+-", "measure": "unknown.measure.penta"}}, "stanza.6": {"line.1": {"text": "Doch ich m\u00fc\u00dfte mich sch\u00e4men, ein Mann zu hei\u00dfen,", "tokens": ["Doch", "ich", "m\u00fc\u00df\u00b7te", "mich", "sch\u00e4\u00b7men", ",", "ein", "Mann", "zu", "hei\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VMFIN", "PRF", "VVINF", "$,", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "--+--+--+-+-", "measure": "anapaest.tri.plus"}, "line.2": {"text": "Wenn ich nicht wollte k\u00f6nnen f\u00fchren das Eisen,", "tokens": ["Wenn", "ich", "nicht", "woll\u00b7te", "k\u00f6n\u00b7nen", "f\u00fch\u00b7ren", "das", "Ei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "VMFIN", "VMFIN", "VVINF", "ART", "NN", "$,"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Und wollte Weibern es g\u00f6nnen,", "tokens": ["Und", "woll\u00b7te", "Wei\u00b7bern", "es", "g\u00f6n\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "NN", "PPER", "VVINF", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Da\u00df sie f\u00fchren es k\u00f6nnen!", "tokens": ["Da\u00df", "sie", "f\u00fch\u00b7ren", "es", "k\u00f6n\u00b7nen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "PPER", "VMFIN", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}}, "stanza.7": {"line.1": {"text": "Ich m\u00fc\u00dfte mich sch\u00e4men, ein Mann zu hei\u00dfen,", "tokens": ["Ich", "m\u00fc\u00df\u00b7te", "mich", "sch\u00e4\u00b7men", ",", "ein", "Mann", "zu", "hei\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PRF", "VVINF", "$,", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Wenn ich nicht k\u00f6nnte f\u00fchren das Eisen,", "tokens": ["Wenn", "ich", "nicht", "k\u00f6nn\u00b7te", "f\u00fch\u00b7ren", "das", "Ei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "VMFIN", "VVINF", "ART", "NN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Und wollte Weibern es g\u00f6nnen,", "tokens": ["Und", "woll\u00b7te", "Wei\u00b7bern", "es", "g\u00f6n\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "NN", "PPER", "VVINF", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Da\u00df sie f\u00fchren es k\u00f6nnen!", "tokens": ["Da\u00df", "sie", "f\u00fch\u00b7ren", "es", "k\u00f6n\u00b7nen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "PPER", "VMFIN", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}}, "stanza.8": {"line.1": {"text": "Wer ist der Gesell, so fein und jung?", "tokens": ["Wer", "ist", "der", "Ge\u00b7sell", ",", "so", "fein", "und", "jung", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ART", "NN", "$,", "ADV", "ADJD", "KON", "ADJD", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Doch f\u00fchrt er das Eisen mit gutem Schwung.", "tokens": ["Doch", "f\u00fchrt", "er", "das", "Ei\u00b7sen", "mit", "gu\u00b7tem", "Schwung", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ART", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Wer steckt unter der Maske?", "tokens": ["Wer", "steckt", "un\u00b7ter", "der", "Mas\u00b7ke", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+---+-", "measure": "dactylic.init"}, "line.4": {"text": "Eine Jungfrau, hei\u00dft ", "tokens": ["Ei\u00b7ne", "Jung\u00b7frau", ",", "hei\u00dft"], "token_info": ["word", "word", "punct", "word"], "pos": ["ART", "NN", "$,", "VVFIN"], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.9": {"line.1": {"text": "Wie merkten wir's nur nicht lange schon", "tokens": ["Wie", "merk\u00b7ten", "wir's", "nur", "nicht", "lan\u00b7ge", "schon"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "VVFIN", "PIS", "ADV", "PTKNEG", "ADV", "ADV"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Am glatten Kinn, am feineren Ton?", "tokens": ["Am", "glat\u00b7ten", "Kinn", ",", "am", "fei\u00b7ne\u00b7ren", "Ton", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "$,", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Doch unter den m\u00e4nnlichen Thaten", "tokens": ["Doch", "un\u00b7ter", "den", "m\u00e4nn\u00b7li\u00b7chen", "Tha\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "ADJA", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Wer konnte das Weib erraten?", "tokens": ["Wer", "konn\u00b7te", "das", "Weib", "er\u00b7ra\u00b7ten", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "ART", "NN", "VVINF", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.10": {"line.1": {"text": "Aber es hat sie getroffen ein Schu\u00df!", "tokens": ["A\u00b7ber", "es", "hat", "sie", "ge\u00b7trof\u00b7fen", "ein", "Schu\u00df", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "PPER", "VVPP", "ART", "NN", "$."], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.2": {"text": "Jetzt sagt sie's selber, weil sie mu\u00df.", "tokens": ["Jetzt", "sagt", "sie's", "sel\u00b7ber", ",", "weil", "sie", "mu\u00df", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "$,", "KOUS", "PPER", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wundarzt geh' beileibe", "tokens": ["Wund\u00b7arzt", "geh'", "bei\u00b7lei\u00b7be"], "token_info": ["word", "word", "word"], "pos": ["FM.la", "FM.la", "FM.la"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Nicht unsanft um mit dem Weibe!", "tokens": ["Nicht", "un\u00b7sanft", "um", "mit", "dem", "Wei\u00b7be", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADJD", "APPR", "APPR", "ART", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.11": {"line.1": {"text": "Zum Gl\u00fcck traf dich die Kugel nicht eh'r,", "tokens": ["Zum", "Gl\u00fcck", "traf", "dich", "die", "Ku\u00b7gel", "nicht", "eh'r", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PPER", "ART", "NN", "PTKNEG", "ADJD", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Als bist du dir hattest gn\u00fcgliche Ehr'", "tokens": ["Als", "bist", "du", "dir", "hat\u00b7test", "gn\u00fcg\u00b7li\u00b7che", "Ehr'"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "VAFIN", "PPER", "PPER", "VAFIN", "ADJA", "NN"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Erstritten in Mannesgeberden,", "tokens": ["Er\u00b7strit\u00b7ten", "in", "Man\u00b7nes\u00b7ge\u00b7ber\u00b7den", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "NN", "$,"], "meter": "-+--+-+--", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Jetzt kannst du ein Weib wieder werden.", "tokens": ["Jetzt", "kannst", "du", "ein", "Weib", "wie\u00b7der", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ART", "NN", "ADV", "VAINF", "$."], "meter": "-+-+++-+-", "measure": "unknown.measure.penta"}}, "stanza.12": {"line.1": {"text": "Doch ich m\u00fc\u00dfte mich sch\u00e4men, ein Mann zu hei\u00dfen,", "tokens": ["Doch", "ich", "m\u00fc\u00df\u00b7te", "mich", "sch\u00e4\u00b7men", ",", "ein", "Mann", "zu", "hei\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VMFIN", "PRF", "VVINF", "$,", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "--+--+--+-+-", "measure": "anapaest.tri.plus"}, "line.2": {"text": "Wenn ich nicht wollte k\u00f6nnen f\u00fchren das Eisen,", "tokens": ["Wenn", "ich", "nicht", "woll\u00b7te", "k\u00f6n\u00b7nen", "f\u00fch\u00b7ren", "das", "Ei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "VMFIN", "VMFIN", "VVINF", "ART", "NN", "$,"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Und wollte Weibern es g\u00f6nnen,", "tokens": ["Und", "woll\u00b7te", "Wei\u00b7bern", "es", "g\u00f6n\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "NN", "PPER", "VVINF", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Da\u00df sie f\u00fchren es k\u00f6nnen!", "tokens": ["Da\u00df", "sie", "f\u00fch\u00b7ren", "es", "k\u00f6n\u00b7nen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "PPER", "VMFIN", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}}}}}