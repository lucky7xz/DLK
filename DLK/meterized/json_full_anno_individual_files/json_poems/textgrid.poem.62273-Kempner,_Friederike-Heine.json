{"textgrid.poem.62273": {"metadata": {"author": {"name": "Kempner, Friederike", "birth": "N.A.", "death": "N.A."}, "title": "Heine", "genre": "verse", "period": "N.A.", "pub_year": 1868, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Als er f\u00fcr's \u00bbJunge Deutschland\u00ab stritt", "tokens": ["Als", "er", "f\u00fcr's", "\u00bb", "Jun\u00b7ge", "Deutschland", "\u00ab", "stritt"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word"], "pos": ["KOUS", "PPER", "NE", "$(", "ADJA", "NN", "$(", "VVFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Und man ihn nicht in Deutschland litt,", "tokens": ["Und", "man", "ihn", "nicht", "in", "Deutschland", "litt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "PPER", "PTKNEG", "APPR", "NE", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Da mu\u00dft' er nach Frankreich geh'n \u2013", "tokens": ["Da", "mu\u00dft'", "er", "nach", "Fran\u00b7kreich", "geh'n", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "APPR", "NE", "VVPP", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Er konnte nicht in L\u00fcften steh'n \u2013", "tokens": ["Er", "konn\u00b7te", "nicht", "in", "L\u00fcf\u00b7ten", "steh'n", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PTKNEG", "APPR", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Doch in der Fremde schrieb er nieder", "tokens": ["Doch", "in", "der", "Frem\u00b7de", "schrieb", "er", "nie\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "VVFIN", "PPER", "PTKVZ"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Das goldne, deutsche Buch der Lieder.", "tokens": ["Das", "gold\u00b7ne", ",", "deut\u00b7sche", "Buch", "der", "Lie\u00b7der", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "ADJA", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Doch, was man lebend ihm versag't,", "tokens": ["Doch", ",", "was", "man", "le\u00b7bend", "ihm", "ver\u00b7sag't", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "PRELS", "PIS", "ADJD", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Heimat, Gott sei es geklagt \u2013", "tokens": ["Die", "Hei\u00b7mat", ",", "Gott", "sei", "es", "ge\u00b7klagt", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "NN", "VAFIN", "PPER", "VVPP", "$("], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "In fremder Erde ruht sein Herz:", "tokens": ["In", "frem\u00b7der", "Er\u00b7de", "ruht", "sein", "Herz", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Das s\u00fchne man im Bild von Erz,", "tokens": ["Das", "s\u00fch\u00b7ne", "man", "im", "Bild", "von", "Erz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PIS", "APPRART", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Zum Lorleifelsen soll es reichen", "tokens": ["Zum", "Lor\u00b7lei\u00b7fel\u00b7sen", "soll", "es", "rei\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "VMFIN", "PPER", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Und seiner Lorleisch\u00f6nheit gleichen.", "tokens": ["Und", "sei\u00b7ner", "Lor\u00b7lei\u00b7sch\u00f6n\u00b7heit", "glei\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Er braucht des Denkmals freilich nicht,", "tokens": ["Er", "braucht", "des", "Denk\u00b7mals", "frei\u00b7lich", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADV", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das sch\u00f6nste Mal ist sein Gedicht,", "tokens": ["Das", "sch\u00f6ns\u00b7te", "Mal", "ist", "sein", "Ge\u00b7dicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Es liest und liebt's die ganze Welt,", "tokens": ["Es", "liest", "und", "liebt's", "die", "gan\u00b7ze", "Welt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der Landmann singt's auf freiem Feld,", "tokens": ["Der", "Land\u00b7mann", "singt's", "auf", "frei\u00b7em", "Feld", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wir brauchen es zum Eigentume,", "tokens": ["Wir", "brau\u00b7chen", "es", "zum", "Ei\u00b7gen\u00b7tu\u00b7me", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Zu Deutschlands unbestritt'nem Ruhme!", "tokens": ["Zu", "Deutschlands", "un\u00b7be\u00b7stritt'\u00b7nem", "Ruh\u00b7me", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Als er f\u00fcr's \u00bbJunge Deutschland\u00ab stritt", "tokens": ["Als", "er", "f\u00fcr's", "\u00bb", "Jun\u00b7ge", "Deutschland", "\u00ab", "stritt"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word"], "pos": ["KOUS", "PPER", "NE", "$(", "ADJA", "NN", "$(", "VVFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Und man ihn nicht in Deutschland litt,", "tokens": ["Und", "man", "ihn", "nicht", "in", "Deutschland", "litt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "PPER", "PTKNEG", "APPR", "NE", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Da mu\u00dft' er nach Frankreich geh'n \u2013", "tokens": ["Da", "mu\u00dft'", "er", "nach", "Fran\u00b7kreich", "geh'n", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "APPR", "NE", "VVPP", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Er konnte nicht in L\u00fcften steh'n \u2013", "tokens": ["Er", "konn\u00b7te", "nicht", "in", "L\u00fcf\u00b7ten", "steh'n", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PTKNEG", "APPR", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Doch in der Fremde schrieb er nieder", "tokens": ["Doch", "in", "der", "Frem\u00b7de", "schrieb", "er", "nie\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "VVFIN", "PPER", "PTKVZ"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Das goldne, deutsche Buch der Lieder.", "tokens": ["Das", "gold\u00b7ne", ",", "deut\u00b7sche", "Buch", "der", "Lie\u00b7der", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "ADJA", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Doch, was man lebend ihm versag't,", "tokens": ["Doch", ",", "was", "man", "le\u00b7bend", "ihm", "ver\u00b7sag't", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "PRELS", "PIS", "ADJD", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Heimat, Gott sei es geklagt \u2013", "tokens": ["Die", "Hei\u00b7mat", ",", "Gott", "sei", "es", "ge\u00b7klagt", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "NN", "VAFIN", "PPER", "VVPP", "$("], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "In fremder Erde ruht sein Herz:", "tokens": ["In", "frem\u00b7der", "Er\u00b7de", "ruht", "sein", "Herz", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Das s\u00fchne man im Bild von Erz,", "tokens": ["Das", "s\u00fch\u00b7ne", "man", "im", "Bild", "von", "Erz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PIS", "APPRART", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Zum Lorleifelsen soll es reichen", "tokens": ["Zum", "Lor\u00b7lei\u00b7fel\u00b7sen", "soll", "es", "rei\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "VMFIN", "PPER", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Und seiner Lorleisch\u00f6nheit gleichen.", "tokens": ["Und", "sei\u00b7ner", "Lor\u00b7lei\u00b7sch\u00f6n\u00b7heit", "glei\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Er braucht des Denkmals freilich nicht,", "tokens": ["Er", "braucht", "des", "Denk\u00b7mals", "frei\u00b7lich", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADV", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das sch\u00f6nste Mal ist sein Gedicht,", "tokens": ["Das", "sch\u00f6ns\u00b7te", "Mal", "ist", "sein", "Ge\u00b7dicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Es liest und liebt's die ganze Welt,", "tokens": ["Es", "liest", "und", "liebt's", "die", "gan\u00b7ze", "Welt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der Landmann singt's auf freiem Feld,", "tokens": ["Der", "Land\u00b7mann", "singt's", "auf", "frei\u00b7em", "Feld", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wir brauchen es zum Eigentume,", "tokens": ["Wir", "brau\u00b7chen", "es", "zum", "Ei\u00b7gen\u00b7tu\u00b7me", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Zu Deutschlands unbestritt'nem Ruhme!", "tokens": ["Zu", "Deutschlands", "un\u00b7be\u00b7stritt'\u00b7nem", "Ruh\u00b7me", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}}}}