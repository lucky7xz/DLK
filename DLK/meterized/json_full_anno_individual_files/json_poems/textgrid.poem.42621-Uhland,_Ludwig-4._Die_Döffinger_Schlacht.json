{"textgrid.poem.42621": {"metadata": {"author": {"name": "Uhland, Ludwig", "birth": "N.A.", "death": "N.A."}, "title": "4. Die D\u00f6ffinger Schlacht", "genre": "verse", "period": "N.A.", "pub_year": 1824, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Am Ruheplatz der Toten, da pflegt es still zu sein,", "tokens": ["Am", "Ru\u00b7he\u00b7platz", "der", "To\u00b7ten", ",", "da", "pflegt", "es", "still", "zu", "sein", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "$,", "ADV", "VVFIN", "PPER", "ADJD", "PTKZU", "VAINF", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Man h\u00f6rt nur leises Beten bei Kreuz und Leichenstein;", "tokens": ["Man", "h\u00f6rt", "nur", "lei\u00b7ses", "Be\u00b7ten", "bei", "Kreuz", "und", "Lei\u00b7chen\u00b7stein", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ADV", "ADJA", "NN", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Zu D\u00f6ffingen war's anders, dort scholl den ganzen Tag", "tokens": ["Zu", "D\u00f6f\u00b7fin\u00b7gen", "wa\u00b7r's", "an\u00b7ders", ",", "dort", "scholl", "den", "gan\u00b7zen", "Tag"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "VAFIN", "ADV", "$,", "ADV", "ADJD", "ART", "ADJA", "NN"], "meter": "-++-+-+--+-+-+", "measure": "iambic.septa.relaxed"}, "line.4": {"text": "Der feste Kirchhof wider von Kampfruf, Sto\u00df und Schlag.", "tokens": ["Der", "fes\u00b7te", "Kirch\u00b7hof", "wi\u00b7der", "von", "Kampf\u00b7ruf", ",", "Sto\u00df", "und", "Schlag", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "APPR", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.2": {"line.1": {"text": "Die St\u00e4dter sind gekommen, der Bauer hat sein Gut", "tokens": ["Die", "St\u00e4d\u00b7ter", "sind", "ge\u00b7kom\u00b7men", ",", "der", "Bau\u00b7er", "hat", "sein", "Gut"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "VVPP", "$,", "ART", "NN", "VAFIN", "PPOSAT", "NN"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Zum festen Ort gefl\u00fcchtet und h\u00e4lt's in tapfrer Hut;", "tokens": ["Zum", "fes\u00b7ten", "Ort", "ge\u00b7fl\u00fcch\u00b7tet", "und", "h\u00e4lt's", "in", "tapf\u00b7rer", "Hut", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "VVPP", "KON", "VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Mit Spie\u00df und Karst und Sense treibt er den Angriff ab,", "tokens": ["Mit", "Spie\u00df", "und", "Karst", "und", "Sen\u00b7se", "treibt", "er", "den", "An\u00b7griff", "ab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "KON", "NN", "VVFIN", "PPER", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Wer tot zu Boden sinket, hat hier nicht weit ins Grab.", "tokens": ["Wer", "tot", "zu", "Bo\u00b7den", "sin\u00b7ket", ",", "hat", "hier", "nicht", "weit", "ins", "Grab", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADJD", "APPR", "NN", "VVFIN", "$,", "VAFIN", "ADV", "PTKNEG", "ADJD", "APPRART", "NN", "$."], "meter": "-+-+-+----+-+", "measure": "unknown.measure.penta"}}, "stanza.3": {"line.1": {"text": "Graf Eberhard der Greiner vernahm der Seinen Not,", "tokens": ["Graf", "E\u00b7ber\u00b7hard", "der", "Grei\u00b7ner", "ver\u00b7nahm", "der", "Sei\u00b7nen", "Not", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "ART", "NN", "VVFIN", "ART", "PPOSAT", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Schon kommt er angezogen mit starkem Aufgebot,", "tokens": ["Schon", "kommt", "er", "an\u00b7ge\u00b7zo\u00b7gen", "mit", "star\u00b7kem", "Auf\u00b7ge\u00b7bot", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "VVPP", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Schon ist um ihn versammelt der besten Ritter Kern,", "tokens": ["Schon", "ist", "um", "ihn", "ver\u00b7sam\u00b7melt", "der", "bes\u00b7ten", "Rit\u00b7ter", "Kern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "APPR", "PPER", "VVFIN", "ART", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Vom edeln L\u00f6wenbunde die Grafen und die Herrn.", "tokens": ["Vom", "e\u00b7deln", "L\u00f6\u00b7wen\u00b7bun\u00b7de", "die", "Gra\u00b7fen", "und", "die", "Herrn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "ART", "NN", "KON", "ART", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.4": {"line.1": {"text": "Da kommt ein reis'ger Bote vom Wolf von Wunnenstein:", "tokens": ["Da", "kommt", "ein", "reis'\u00b7ger", "Bo\u00b7te", "vom", "Wolf", "von", "Wun\u00b7nen\u00b7stein", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "APPRART", "NE", "APPR", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "\u00bbmein Herr mit seinem Banner will Euch zu Dienste sein.\u00ab", "tokens": ["\u00bb", "mein", "Herr", "mit", "sei\u00b7nem", "Ban\u00b7ner", "will", "Euch", "zu", "Diens\u00b7te", "sein", ".", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPOSAT", "NN", "APPR", "PPOSAT", "NN", "VMFIN", "PPER", "APPR", "NN", "VAINF", "$.", "$("], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Der stolze Graf entgegnet: \u00bbIch hab sein nicht begehrt,", "tokens": ["Der", "stol\u00b7ze", "Graf", "ent\u00b7geg\u00b7net", ":", "\u00bb", "Ich", "hab", "sein", "nicht", "be\u00b7gehrt", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$.", "$(", "PPER", "VAFIN", "PPOSAT", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Er hat umsonst die M\u00fcnze, die ich ihm einst verehrt.\u00ab", "tokens": ["Er", "hat", "um\u00b7sonst", "die", "M\u00fcn\u00b7ze", ",", "die", "ich", "ihm", "einst", "ver\u00b7ehrt", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ART", "NN", "$,", "PRELS", "PPER", "PPER", "ADV", "VVPP", "$.", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.5": {"line.1": {"text": "Bald sieht Herr Ulrich dr\u00fcben der St\u00e4dte Scharen stehn,", "tokens": ["Bald", "sieht", "Herr", "Ul\u00b7rich", "dr\u00fc\u00b7ben", "der", "St\u00e4d\u00b7te", "Scha\u00b7ren", "stehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NN", "NE", "ADV", "ART", "NN", "NN", "VVINF", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Von Reutlingen, von Augsburg, von Ulm die Banner wehn,", "tokens": ["Von", "Reut\u00b7lin\u00b7gen", ",", "von", "Augs\u00b7burg", ",", "von", "Ulm", "die", "Ban\u00b7ner", "wehn", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "$,", "APPR", "NE", "$,", "APPR", "NE", "ART", "NN", "VVINF", "$,"], "meter": "--+--+--+-+-+", "measure": "anapaest.tri.plus"}, "line.3": {"text": "Da brennt ihn seine Narbe, da g\u00e4rt der alte Groll:", "tokens": ["Da", "brennt", "ihn", "sei\u00b7ne", "Nar\u00b7be", ",", "da", "g\u00e4rt", "der", "al\u00b7te", "Groll", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPOSAT", "NN", "$,", "ADV", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "\u00bbich wei\u00df, ihr \u00dcberm\u00fct'gen, wovon der Kamm euch schwoll.\u00ab", "tokens": ["\u00bb", "ich", "wei\u00df", ",", "ihr", "\u00dc\u00b7ber\u00b7m\u00fct'\u00b7gen", ",", "wo\u00b7von", "der", "Kamm", "euch", "schwoll", ".", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPER", "VVFIN", "$,", "PPOSAT", "NN", "$,", "PWAV", "ART", "NN", "PPER", "ADJD", "$.", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.6": {"line.1": {"text": "Er sprengt zu seinem Vater: \u00bbHeut zahl ich alte Schuld,", "tokens": ["Er", "sprengt", "zu", "sei\u00b7nem", "Va\u00b7ter", ":", "\u00bb", "Heut", "zahl", "ich", "al\u00b7te", "Schuld", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN", "$.", "$(", "ADV", "VVFIN", "PPER", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Will's Gott, erwerb ich wieder die v\u00e4terliche Huld!", "tokens": ["Will's", "Gott", ",", "er\u00b7werb", "ich", "wie\u00b7der", "die", "v\u00e4\u00b7ter\u00b7li\u00b7che", "Huld", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "VVFIN", "PPER", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Nicht darf ich mit dir speisen auf ", "tokens": ["Nicht", "darf", "ich", "mit", "dir", "spei\u00b7sen", "auf"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PTKNEG", "VMFIN", "PPER", "APPR", "PPER", "VVFIN", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Doch darf ich mit dir schlagen auf ", "tokens": ["Doch", "darf", "ich", "mit", "dir", "schla\u00b7gen", "auf"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VMFIN", "PPER", "APPR", "PPER", "VVFIN", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Sie steigen von den Gaulen, die Herrn vom L\u00f6wenbund,", "tokens": ["Sie", "stei\u00b7gen", "von", "den", "Gau\u00b7len", ",", "die", "Herrn", "vom", "L\u00f6\u00b7wen\u00b7bund", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "$,", "ART", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Sie st\u00fcrzen auf die Feinde, tun sich als L\u00f6wen kund.", "tokens": ["Sie", "st\u00fcr\u00b7zen", "auf", "die", "Fein\u00b7de", ",", "tun", "sich", "als", "L\u00f6\u00b7wen", "kund", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "$,", "VVFIN", "PRF", "KOUS", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Hei! wie der L\u00f6we Ulrich so grimmig tobt und w\u00fcrgt!", "tokens": ["Hei", "!", "wie", "der", "L\u00f6\u00b7we", "Ul\u00b7rich", "so", "grim\u00b7mig", "tobt", "und", "w\u00fcrgt", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "PWAV", "ART", "NE", "NE", "ADV", "ADJD", "VVFIN", "KON", "VVFIN", "$."], "meter": "+--+--+-+-+-+", "measure": "dactylic.di.plus"}, "line.4": {"text": "Er will die Schuld bezahlen, er hat sein Wort verb\u00fcrgt.", "tokens": ["Er", "will", "die", "Schuld", "be\u00b7zah\u00b7len", ",", "er", "hat", "sein", "Wort", "ver\u00b7b\u00fcrgt", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "NN", "VVINF", "$,", "PPER", "VAFIN", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.8": {"line.1": {"text": "Wen tr\u00e4gt man aus dem Kampfe, dort auf den Eichenstumpf?", "tokens": ["Wen", "tr\u00e4gt", "man", "aus", "dem", "Kamp\u00b7fe", ",", "dort", "auf", "den", "Ei\u00b7chen\u00b7stumpf", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PIS", "APPR", "ART", "NN", "$,", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "\u00bbgott sei mir S\u00fcnder gn\u00e4dig!\u00ab \u2013 er st\u00f6hnt's, er r\u00f6chelt's dumpf.", "tokens": ["\u00bb", "gott", "sei", "mir", "S\u00fcn\u00b7der", "gn\u00e4\u00b7dig", "!", "\u00ab", "\u2013", "er", "st\u00f6hnt's", ",", "er", "r\u00f6\u00b7chelt's", "dumpf", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "VAFIN", "PPER", "NN", "ADJD", "$.", "$(", "$(", "PPER", "VVFIN", "$,", "PPER", "VVFIN", "ADJD", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "O k\u00f6nigliche Eiche, dich hat der Blitz zerspellt!", "tokens": ["O", "k\u00f6\u00b7nig\u00b7li\u00b7che", "Ei\u00b7che", ",", "dich", "hat", "der", "Blitz", "zer\u00b7spellt", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$,", "PPER", "VAFIN", "ART", "NN", "VVPP", "$."], "meter": "+-+--+--+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.4": {"text": "O Ulrich, tapfrer Ritter, dich hat das Schwert gef\u00e4llt!", "tokens": ["O", "Ul\u00b7rich", ",", "tapf\u00b7rer", "Rit\u00b7ter", ",", "dich", "hat", "das", "Schwert", "ge\u00b7f\u00e4llt", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "ADJA", "NN", "$,", "PPER", "VAFIN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.9": {"line.1": {"text": "Da ruft der alte Recke, den nichts ersch\u00fcttern kann:", "tokens": ["Da", "ruft", "der", "al\u00b7te", "Re\u00b7cke", ",", "den", "nichts", "er\u00b7sch\u00fct\u00b7tern", "kann", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "$,", "PRELS", "PIS", "VVINF", "VMFIN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "\u00bberschreckt nicht! der gefallen, ist wie ein andrer Mann.", "tokens": ["\u00bb", "er\u00b7schreckt", "nicht", "!", "der", "ge\u00b7fal\u00b7len", ",", "ist", "wie", "ein", "an\u00b7drer", "Mann", "."], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PTKNEG", "$.", "ART", "VVPP", "$,", "VAFIN", "KOKOM", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Schlagt drein! Die Feinde fliehen!\u00ab \u2013 er ruft's mit Donnerlaut;", "tokens": ["Schlagt", "drein", "!", "Die", "Fein\u00b7de", "flie\u00b7hen", "!", "\u00ab", "\u2013", "er", "ruft's", "mit", "Don\u00b7ner\u00b7laut", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "$.", "ART", "NN", "VVINF", "$.", "$(", "$(", "PPER", "VVFIN", "APPR", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Wie rauscht sein Bart im Winde! hei, wie der Eber haut!", "tokens": ["Wie", "rauscht", "sein", "Bart", "im", "Win\u00b7de", "!", "hei", ",", "wie", "der", "E\u00b7ber", "haut", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPOSAT", "NN", "APPRART", "NN", "$.", "PTKVZ", "$,", "PWAV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.10": {"line.1": {"text": "Die St\u00e4dter han vernommen das seltsam list'ge Wort.", "tokens": ["Die", "St\u00e4d\u00b7ter", "han", "ver\u00b7nom\u00b7men", "das", "selt\u00b7sam", "list'\u00b7ge", "Wort", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVPP", "ART", "ADJD", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "\u00bbwer flieht?\u00ab so fragen alle, schon wankt es hier und dort.", "tokens": ["\u00bb", "wer", "flieht", "?", "\u00ab", "so", "fra\u00b7gen", "al\u00b7le", ",", "schon", "wankt", "es", "hier", "und", "dort", "."], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "VVFIN", "$.", "$(", "ADV", "VVFIN", "PIS", "$,", "ADV", "VVFIN", "PPER", "ADV", "KON", "ADV", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Das Wort hat sie ergriffen gleich einem Zauberlied,", "tokens": ["Das", "Wort", "hat", "sie", "er\u00b7grif\u00b7fen", "gleich", "ei\u00b7nem", "Zau\u00b7berl\u00b7ied", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "VVPP", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Der Graf und seine Ritter durchbrechen Glied auf Glied.", "tokens": ["Der", "Graf", "und", "sei\u00b7ne", "Rit\u00b7ter", "durch\u00b7bre\u00b7chen", "Glied", "auf", "Glied", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "PPOSAT", "NN", "ADJA", "NN", "APPR", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.11": {"line.1": {"text": "Was glei\u00dft und gl\u00e4nzt da droben und zuckt wie Wetterschein?", "tokens": ["Was", "glei\u00dft", "und", "gl\u00e4nzt", "da", "dro\u00b7ben", "und", "zuckt", "wie", "Wet\u00b7ter\u00b7schein", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "KON", "VVFIN", "ADV", "ADV", "KON", "VVFIN", "KOKOM", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Das ist mit seinen Reitern der Wolf von Wunnenstein.", "tokens": ["Das", "ist", "mit", "sei\u00b7nen", "Rei\u00b7tern", "der", "Wolf", "von", "Wun\u00b7nen\u00b7stein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "APPR", "PPOSAT", "NN", "ART", "NE", "APPR", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Er wirft sich auf die St\u00e4dter, er sprengt sich weite Bucht,", "tokens": ["Er", "wirft", "sich", "auf", "die", "St\u00e4d\u00b7ter", ",", "er", "sprengt", "sich", "wei\u00b7te", "Bucht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "ART", "NN", "$,", "PPER", "VVFIN", "PRF", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Da ist der Sieg entschieden, der Feind in wilder Flucht.", "tokens": ["Da", "ist", "der", "Sieg", "ent\u00b7schie\u00b7den", ",", "der", "Feind", "in", "wil\u00b7der", "Flucht", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "VVPP", "$,", "ART", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.12": {"line.1": {"text": "Im Erntemond geschah es, bei Gott, ein hei\u00dfer Tag!", "tokens": ["Im", "Ern\u00b7te\u00b7mond", "ge\u00b7schah", "es", ",", "bei", "Gott", ",", "ein", "hei\u00b7\u00dfer", "Tag", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PPER", "$,", "APPR", "NN", "$,", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Was da der edeln Garben auf allen Feldern lag!", "tokens": ["Was", "da", "der", "e\u00b7deln", "Gar\u00b7ben", "auf", "al\u00b7len", "Fel\u00b7dern", "lag", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "ART", "ADJA", "NN", "APPR", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Wie auch so mancher Schnitter die Arme sinken l\u00e4\u00dft!", "tokens": ["Wie", "auch", "so", "man\u00b7cher", "Schnit\u00b7ter", "die", "Ar\u00b7me", "sin\u00b7ken", "l\u00e4\u00dft", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "ADV", "PIAT", "NN", "ART", "NN", "VVINF", "VVFIN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Wohl halten diese Ritter ein blutig Sichelfest.", "tokens": ["Wohl", "hal\u00b7ten", "die\u00b7se", "Rit\u00b7ter", "ein", "blu\u00b7tig", "Si\u00b7chel\u00b7fest", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PDAT", "NN", "ART", "ADJD", "NE", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.13": {"line.1": {"text": "Noch lange traf der Bauer, der hinterm Pfluge ging,", "tokens": ["Noch", "lan\u00b7ge", "traf", "der", "Bau\u00b7er", ",", "der", "hin\u00b7term", "Pflu\u00b7ge", "ging", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "ART", "NN", "$,", "PRELS", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Auf rost'ge Degenklinge, Speereisen, Panzerring,", "tokens": ["Auf", "rost'\u00b7ge", "De\u00b7gen\u00b7klin\u00b7ge", ",", "Spee\u00b7rei\u00b7sen", ",", "Pan\u00b7zer\u00b7ring", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Und als man eine Linde zers\u00e4gt und niederstreckt,", "tokens": ["Und", "als", "man", "ei\u00b7ne", "Lin\u00b7de", "zer\u00b7s\u00e4gt", "und", "nie\u00b7der\u00b7streckt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PIS", "ART", "NE", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Zeigt sich darin ein Harnisch und ein Geripp versteckt.", "tokens": ["Zeigt", "sich", "da\u00b7rin", "ein", "Har\u00b7nisch", "und", "ein", "Ge\u00b7ripp", "ver\u00b7steckt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "PAV", "ART", "NN", "KON", "ART", "NN", "VVPP", "$."], "meter": "+-+--+--+-+-+", "measure": "trochaic.hexa.relaxed"}}, "stanza.14": {"line.1": {"text": "Als nun die Schlacht geschlagen und Sieg geblasen war,", "tokens": ["Als", "nun", "die", "Schlacht", "ge\u00b7schla\u00b7gen", "und", "Sieg", "ge\u00b7bla\u00b7sen", "war", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "VVPP", "KON", "NN", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Da reicht der alte Greiner dem Wolf die Rechte dar:", "tokens": ["Da", "reicht", "der", "al\u00b7te", "Grei\u00b7ner", "dem", "Wolf", "die", "Rech\u00b7te", "dar", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "ART", "NE", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "\u00bbhab Dank, du tapfrer Degen, und reit mit mir nach Haus!", "tokens": ["\u00bb", "hab", "Dank", ",", "du", "tapf\u00b7rer", "De\u00b7gen", ",", "und", "reit", "mit", "mir", "nach", "Haus", "!"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VAFIN", "NN", "$,", "PPER", "ADJA", "NN", "$,", "KON", "NN", "APPR", "PPER", "APPR", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Da\u00df wir uns g\u00fctlich pflegen nach diesem harten Strau\u00df.\u00ab", "tokens": ["Da\u00df", "wir", "uns", "g\u00fct\u00b7lich", "pfle\u00b7gen", "nach", "die\u00b7sem", "har\u00b7ten", "Strau\u00df", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PPER", "PRF", "ADJD", "VVFIN", "APPR", "PDAT", "ADJA", "NE", "$.", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.15": {"line.1": {"text": "\u00bbhei!\u00ab spricht der Wolf mit Lachen, \u00bbgefiel Euch dieser Schwank?", "tokens": ["\u00bb", "hei", "!", "\u00ab", "spricht", "der", "Wolf", "mit", "La\u00b7chen", ",", "\u00bb", "ge\u00b7fiel", "Euch", "die\u00b7ser", "Schwank", "?"], "token_info": ["punct", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PTKVZ", "$.", "$(", "VVFIN", "ART", "NE", "APPR", "NN", "$,", "$(", "VVFIN", "PPER", "PDAT", "NN", "$."], "meter": "+--+-+--+-+-+", "measure": "iambic.hexa.invert"}, "line.2": {"text": "Ich stritt aus Ha\u00df der St\u00e4dte und nicht um Euren Dank.", "tokens": ["Ich", "stritt", "aus", "Ha\u00df", "der", "St\u00e4d\u00b7te", "und", "nicht", "um", "Eu\u00b7ren", "Dank", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "ART", "NN", "KON", "PTKNEG", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Gut Nacht und Gl\u00fcck zur Reise! es steht im alten Recht.\u00ab", "tokens": ["Gut", "Nacht", "und", "Gl\u00fcck", "zur", "Rei\u00b7se", "!", "es", "steht", "im", "al\u00b7ten", "Recht", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADJD", "NN", "KON", "NN", "APPRART", "NN", "$.", "PPER", "VVFIN", "APPRART", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Er spricht's und jagt von dannen mit Ritter und mit Knecht.", "tokens": ["Er", "spricht's", "und", "jagt", "von", "dan\u00b7nen", "mit", "Rit\u00b7ter", "und", "mit", "Knecht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "APPR", "ADV", "APPR", "NN", "KON", "APPR", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.16": {"line.1": {"text": "Zu D\u00f6ffingen im Dorfe, da hat der Graf die Nacht", "tokens": ["Zu", "D\u00f6f\u00b7fin\u00b7gen", "im", "Dor\u00b7fe", ",", "da", "hat", "der", "Graf", "die", "Nacht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "APPRART", "NN", "$,", "ADV", "VAFIN", "ART", "NN", "ART", "NN"], "meter": "-++--+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Bei seines Ulrichs Leiche, des einz'gen Sohns, verbracht.", "tokens": ["Bei", "sei\u00b7nes", "Ul\u00b7richs", "Lei\u00b7che", ",", "des", "einz'\u00b7gen", "Sohns", ",", "ver\u00b7bracht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$,", "ART", "ADJA", "NN", "$,", "VVPP", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Er kniet zur Bahre nieder, verh\u00fcllet sein Gesicht;", "tokens": ["Er", "kniet", "zur", "Bah\u00b7re", "nie\u00b7der", ",", "ver\u00b7h\u00fcl\u00b7let", "sein", "Ge\u00b7sicht", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "PTKVZ", "$,", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Ob er vielleicht im stillen geweint, man wei\u00df es nicht.", "tokens": ["Ob", "er", "viel\u00b7leicht", "im", "stil\u00b7len", "ge\u00b7weint", ",", "man", "wei\u00df", "es", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "APPRART", "ADJA", "VVPP", "$,", "PIS", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "---+-+--+-+-+", "measure": "iambic.penta.relaxed"}}, "stanza.17": {"line.1": {"text": "Des Morgens mit dem Fr\u00fchsten steigt Eberhard zu Ro\u00df,", "tokens": ["Des", "Mor\u00b7gens", "mit", "dem", "Fr\u00fchs\u00b7ten", "steigt", "E\u00b7ber\u00b7hard", "zu", "Ro\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "ART", "NN", "VVFIN", "NE", "APPR", "NN", "$,"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Gen Stuttgart f\u00e4hrt er wieder mit seinem reis'gen Tro\u00df,", "tokens": ["Gen", "Stutt\u00b7gart", "f\u00e4hrt", "er", "wie\u00b7der", "mit", "sei\u00b7nem", "reis'\u00b7gen", "Tro\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "VVFIN", "PPER", "ADV", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Da kommt des Wegs gelaufen der Zuffenhauser Hirt;", "tokens": ["Da", "kommt", "des", "Wegs", "ge\u00b7lau\u00b7fen", "der", "Zuf\u00b7fen\u00b7hau\u00b7ser", "Hirt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "VVPP", "ART", "NN", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "\u00bbdem Mann ist's tr\u00fcb zumute, was der uns bringen wird?\u00ab", "tokens": ["\u00bb", "dem", "Mann", "ist's", "tr\u00fcb", "zu\u00b7mu\u00b7te", ",", "was", "der", "uns", "brin\u00b7gen", "wird", "?", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ART", "NN", "VAFIN", "ADJD", "VVFIN", "$,", "PRELS", "ART", "PPER", "VVINF", "VAFIN", "$.", "$("], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.18": {"line.1": {"text": "\u00bbich bring Euch b\u00f6se Kunde, n\u00e4cht ist in unsern Trieb", "tokens": ["\u00bb", "ich", "bring", "Euch", "b\u00f6\u00b7se", "Kun\u00b7de", ",", "n\u00e4cht", "ist", "in", "un\u00b7sern", "Trieb"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["$(", "PPER", "VVFIN", "PPER", "ADJA", "NN", "$,", "ADJD", "VAFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Der glei\u00dfend' Wolf gefallen, er nahm, soviel ihm lieb.\u00ab", "tokens": ["Der", "glei\u00b7\u00dfend'", "Wolf", "ge\u00b7fal\u00b7len", ",", "er", "nahm", ",", "so\u00b7viel", "ihm", "lieb", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["ART", "ADJA", "NE", "VVPP", "$,", "PPER", "VVFIN", "$,", "KOUS", "PPER", "ADJD", "$.", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Da lacht der alte Greiner in seinen grauen Bart:", "tokens": ["Da", "lacht", "der", "al\u00b7te", "Grei\u00b7ner", "in", "sei\u00b7nen", "grau\u00b7en", "Bart", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "\u00bbdas W\u00f6lflein holt sich Kochfleisch, das ist des W\u00f6lfleins Art.\u00ab", "tokens": ["\u00bb", "das", "W\u00f6lf\u00b7lein", "holt", "sich", "Koch\u00b7fleisch", ",", "das", "ist", "des", "W\u00f6lf\u00b7leins", "Art", ".", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ART", "NN", "VVFIN", "PRF", "NE", "$,", "PDS", "VAFIN", "ART", "NN", "NN", "$.", "$("], "meter": "-+-+-++-+-+-+", "measure": "unknown.measure.septa"}}, "stanza.19": {"line.1": {"text": "Sie reiten r\u00fcstig f\u00fcrder, sie sehn aus gr\u00fcnem Tal", "tokens": ["Sie", "rei\u00b7ten", "r\u00fcs\u00b7tig", "f\u00fcr\u00b7der", ",", "sie", "sehn", "aus", "gr\u00fc\u00b7nem", "Tal"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADJD", "PTKVZ", "$,", "PPER", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+-+----+-+-+", "measure": "unknown.measure.penta"}, "line.2": {"text": "Das Schlo\u00df von Stuttgart ragen, es gl\u00e4nzt im Morgenstrahl,", "tokens": ["Das", "Schlo\u00df", "von", "Stutt\u00b7gart", "ra\u00b7gen", ",", "es", "gl\u00e4nzt", "im", "Mor\u00b7gen\u00b7strahl", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NE", "VVFIN", "$,", "PPER", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Da kommt des Wegs geritten ein schmucker Edelknecht;", "tokens": ["Da", "kommt", "des", "Wegs", "ge\u00b7rit\u00b7ten", "ein", "schmu\u00b7cker", "E\u00b7del\u00b7knecht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "VVPP", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "\u00bbder Knab will mich bed\u00fcnken, als ob er Gutes br\u00e4cht.\u00ab", "tokens": ["\u00bb", "der", "Knab", "will", "mich", "be\u00b7d\u00fcn\u00b7ken", ",", "als", "ob", "er", "Gu\u00b7tes", "br\u00e4cht", ".", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ART", "NN", "VMFIN", "PRF", "VVINF", "$,", "KOKOM", "KOUS", "PPER", "NN", "VVFIN", "$.", "$("], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.20": {"line.1": {"text": "\u00bbich bring Euch frohe M\u00e4re: Gl\u00fcck zum Urenkelein!", "tokens": ["\u00bb", "ich", "bring", "Euch", "fro\u00b7he", "M\u00e4\u00b7re", ":", "Gl\u00fcck", "zum", "Ur\u00b7en\u00b7kel\u00b7ein", "!"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "PPER", "ADJA", "NN", "$.", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.2": {"text": "Antonia hat geboren ein Kn\u00e4blein, hold und fein.\u00ab", "tokens": ["An\u00b7to\u00b7nia", "hat", "ge\u00b7bo\u00b7ren", "ein", "Kn\u00e4\u00b7blein", ",", "hold", "und", "fein", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["NE", "VAFIN", "VVPP", "ART", "NN", "$,", "ADJD", "KON", "ADJD", "$.", "$("], "meter": "+--+-+--+-+-+", "measure": "iambic.hexa.invert"}, "line.3": {"text": "Da hebt er hoch die H\u00e4nde, der ritterliche Greis:", "tokens": ["Da", "hebt", "er", "hoch", "die", "H\u00e4n\u00b7de", ",", "der", "rit\u00b7ter\u00b7li\u00b7che", "Greis", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "ART", "NN", "$,", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "\u00bbder Fink hat wieder Samen, dem Herrn sei Dank und Preis!\u00ab", "tokens": ["\u00bb", "der", "Fink", "hat", "wie\u00b7der", "Sa\u00b7men", ",", "dem", "Herrn", "sei", "Dank", "und", "Preis", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ART", "NN", "VAFIN", "ADV", "NN", "$,", "ART", "NN", "VAFIN", "NN", "KON", "NN", "$.", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.21": {"line.1": {"text": "Am Ruheplatz der Toten, da pflegt es still zu sein,", "tokens": ["Am", "Ru\u00b7he\u00b7platz", "der", "To\u00b7ten", ",", "da", "pflegt", "es", "still", "zu", "sein", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "$,", "ADV", "VVFIN", "PPER", "ADJD", "PTKZU", "VAINF", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Man h\u00f6rt nur leises Beten bei Kreuz und Leichenstein;", "tokens": ["Man", "h\u00f6rt", "nur", "lei\u00b7ses", "Be\u00b7ten", "bei", "Kreuz", "und", "Lei\u00b7chen\u00b7stein", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ADV", "ADJA", "NN", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Zu D\u00f6ffingen war's anders, dort scholl den ganzen Tag", "tokens": ["Zu", "D\u00f6f\u00b7fin\u00b7gen", "wa\u00b7r's", "an\u00b7ders", ",", "dort", "scholl", "den", "gan\u00b7zen", "Tag"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "VAFIN", "ADV", "$,", "ADV", "ADJD", "ART", "ADJA", "NN"], "meter": "-++-+-+--+-+-+", "measure": "iambic.septa.relaxed"}, "line.4": {"text": "Der feste Kirchhof wider von Kampfruf, Sto\u00df und Schlag.", "tokens": ["Der", "fes\u00b7te", "Kirch\u00b7hof", "wi\u00b7der", "von", "Kampf\u00b7ruf", ",", "Sto\u00df", "und", "Schlag", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "APPR", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.22": {"line.1": {"text": "Die St\u00e4dter sind gekommen, der Bauer hat sein Gut", "tokens": ["Die", "St\u00e4d\u00b7ter", "sind", "ge\u00b7kom\u00b7men", ",", "der", "Bau\u00b7er", "hat", "sein", "Gut"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "VVPP", "$,", "ART", "NN", "VAFIN", "PPOSAT", "NN"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Zum festen Ort gefl\u00fcchtet und h\u00e4lt's in tapfrer Hut;", "tokens": ["Zum", "fes\u00b7ten", "Ort", "ge\u00b7fl\u00fcch\u00b7tet", "und", "h\u00e4lt's", "in", "tapf\u00b7rer", "Hut", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "VVPP", "KON", "VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Mit Spie\u00df und Karst und Sense treibt er den Angriff ab,", "tokens": ["Mit", "Spie\u00df", "und", "Karst", "und", "Sen\u00b7se", "treibt", "er", "den", "An\u00b7griff", "ab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "KON", "NN", "VVFIN", "PPER", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Wer tot zu Boden sinket, hat hier nicht weit ins Grab.", "tokens": ["Wer", "tot", "zu", "Bo\u00b7den", "sin\u00b7ket", ",", "hat", "hier", "nicht", "weit", "ins", "Grab", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADJD", "APPR", "NN", "VVFIN", "$,", "VAFIN", "ADV", "PTKNEG", "ADJD", "APPRART", "NN", "$."], "meter": "-+-+-+----+-+", "measure": "unknown.measure.penta"}}, "stanza.23": {"line.1": {"text": "Graf Eberhard der Greiner vernahm der Seinen Not,", "tokens": ["Graf", "E\u00b7ber\u00b7hard", "der", "Grei\u00b7ner", "ver\u00b7nahm", "der", "Sei\u00b7nen", "Not", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "ART", "NN", "VVFIN", "ART", "PPOSAT", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Schon kommt er angezogen mit starkem Aufgebot,", "tokens": ["Schon", "kommt", "er", "an\u00b7ge\u00b7zo\u00b7gen", "mit", "star\u00b7kem", "Auf\u00b7ge\u00b7bot", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "VVPP", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Schon ist um ihn versammelt der besten Ritter Kern,", "tokens": ["Schon", "ist", "um", "ihn", "ver\u00b7sam\u00b7melt", "der", "bes\u00b7ten", "Rit\u00b7ter", "Kern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "APPR", "PPER", "VVFIN", "ART", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Vom edeln L\u00f6wenbunde die Grafen und die Herrn.", "tokens": ["Vom", "e\u00b7deln", "L\u00f6\u00b7wen\u00b7bun\u00b7de", "die", "Gra\u00b7fen", "und", "die", "Herrn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "ART", "NN", "KON", "ART", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.24": {"line.1": {"text": "Da kommt ein reis'ger Bote vom Wolf von Wunnenstein:", "tokens": ["Da", "kommt", "ein", "reis'\u00b7ger", "Bo\u00b7te", "vom", "Wolf", "von", "Wun\u00b7nen\u00b7stein", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "APPRART", "NE", "APPR", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "\u00bbmein Herr mit seinem Banner will Euch zu Dienste sein.\u00ab", "tokens": ["\u00bb", "mein", "Herr", "mit", "sei\u00b7nem", "Ban\u00b7ner", "will", "Euch", "zu", "Diens\u00b7te", "sein", ".", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPOSAT", "NN", "APPR", "PPOSAT", "NN", "VMFIN", "PPER", "APPR", "NN", "VAINF", "$.", "$("], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Der stolze Graf entgegnet: \u00bbIch hab sein nicht begehrt,", "tokens": ["Der", "stol\u00b7ze", "Graf", "ent\u00b7geg\u00b7net", ":", "\u00bb", "Ich", "hab", "sein", "nicht", "be\u00b7gehrt", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$.", "$(", "PPER", "VAFIN", "PPOSAT", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Er hat umsonst die M\u00fcnze, die ich ihm einst verehrt.\u00ab", "tokens": ["Er", "hat", "um\u00b7sonst", "die", "M\u00fcn\u00b7ze", ",", "die", "ich", "ihm", "einst", "ver\u00b7ehrt", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ART", "NN", "$,", "PRELS", "PPER", "PPER", "ADV", "VVPP", "$.", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.25": {"line.1": {"text": "Bald sieht Herr Ulrich dr\u00fcben der St\u00e4dte Scharen stehn,", "tokens": ["Bald", "sieht", "Herr", "Ul\u00b7rich", "dr\u00fc\u00b7ben", "der", "St\u00e4d\u00b7te", "Scha\u00b7ren", "stehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NN", "NE", "ADV", "ART", "NN", "NN", "VVINF", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Von Reutlingen, von Augsburg, von Ulm die Banner wehn,", "tokens": ["Von", "Reut\u00b7lin\u00b7gen", ",", "von", "Augs\u00b7burg", ",", "von", "Ulm", "die", "Ban\u00b7ner", "wehn", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "$,", "APPR", "NE", "$,", "APPR", "NE", "ART", "NN", "VVINF", "$,"], "meter": "--+--+--+-+-+", "measure": "anapaest.tri.plus"}, "line.3": {"text": "Da brennt ihn seine Narbe, da g\u00e4rt der alte Groll:", "tokens": ["Da", "brennt", "ihn", "sei\u00b7ne", "Nar\u00b7be", ",", "da", "g\u00e4rt", "der", "al\u00b7te", "Groll", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPOSAT", "NN", "$,", "ADV", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "\u00bbich wei\u00df, ihr \u00dcberm\u00fct'gen, wovon der Kamm euch schwoll.\u00ab", "tokens": ["\u00bb", "ich", "wei\u00df", ",", "ihr", "\u00dc\u00b7ber\u00b7m\u00fct'\u00b7gen", ",", "wo\u00b7von", "der", "Kamm", "euch", "schwoll", ".", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPER", "VVFIN", "$,", "PPOSAT", "NN", "$,", "PWAV", "ART", "NN", "PPER", "ADJD", "$.", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.26": {"line.1": {"text": "Er sprengt zu seinem Vater: \u00bbHeut zahl ich alte Schuld,", "tokens": ["Er", "sprengt", "zu", "sei\u00b7nem", "Va\u00b7ter", ":", "\u00bb", "Heut", "zahl", "ich", "al\u00b7te", "Schuld", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN", "$.", "$(", "ADV", "VVFIN", "PPER", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Will's Gott, erwerb ich wieder die v\u00e4terliche Huld!", "tokens": ["Will's", "Gott", ",", "er\u00b7werb", "ich", "wie\u00b7der", "die", "v\u00e4\u00b7ter\u00b7li\u00b7che", "Huld", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "VVFIN", "PPER", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Nicht darf ich mit dir speisen auf ", "tokens": ["Nicht", "darf", "ich", "mit", "dir", "spei\u00b7sen", "auf"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PTKNEG", "VMFIN", "PPER", "APPR", "PPER", "VVFIN", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Doch darf ich mit dir schlagen auf ", "tokens": ["Doch", "darf", "ich", "mit", "dir", "schla\u00b7gen", "auf"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VMFIN", "PPER", "APPR", "PPER", "VVFIN", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.27": {"line.1": {"text": "Sie steigen von den Gaulen, die Herrn vom L\u00f6wenbund,", "tokens": ["Sie", "stei\u00b7gen", "von", "den", "Gau\u00b7len", ",", "die", "Herrn", "vom", "L\u00f6\u00b7wen\u00b7bund", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "$,", "ART", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Sie st\u00fcrzen auf die Feinde, tun sich als L\u00f6wen kund.", "tokens": ["Sie", "st\u00fcr\u00b7zen", "auf", "die", "Fein\u00b7de", ",", "tun", "sich", "als", "L\u00f6\u00b7wen", "kund", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "$,", "VVFIN", "PRF", "KOUS", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Hei! wie der L\u00f6we Ulrich so grimmig tobt und w\u00fcrgt!", "tokens": ["Hei", "!", "wie", "der", "L\u00f6\u00b7we", "Ul\u00b7rich", "so", "grim\u00b7mig", "tobt", "und", "w\u00fcrgt", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "PWAV", "ART", "NE", "NE", "ADV", "ADJD", "VVFIN", "KON", "VVFIN", "$."], "meter": "+--+--+-+-+-+", "measure": "dactylic.di.plus"}, "line.4": {"text": "Er will die Schuld bezahlen, er hat sein Wort verb\u00fcrgt.", "tokens": ["Er", "will", "die", "Schuld", "be\u00b7zah\u00b7len", ",", "er", "hat", "sein", "Wort", "ver\u00b7b\u00fcrgt", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "NN", "VVINF", "$,", "PPER", "VAFIN", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.28": {"line.1": {"text": "Wen tr\u00e4gt man aus dem Kampfe, dort auf den Eichenstumpf?", "tokens": ["Wen", "tr\u00e4gt", "man", "aus", "dem", "Kamp\u00b7fe", ",", "dort", "auf", "den", "Ei\u00b7chen\u00b7stumpf", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PIS", "APPR", "ART", "NN", "$,", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "\u00bbgott sei mir S\u00fcnder gn\u00e4dig!\u00ab \u2013 er st\u00f6hnt's, er r\u00f6chelt's dumpf.", "tokens": ["\u00bb", "gott", "sei", "mir", "S\u00fcn\u00b7der", "gn\u00e4\u00b7dig", "!", "\u00ab", "\u2013", "er", "st\u00f6hnt's", ",", "er", "r\u00f6\u00b7chelt's", "dumpf", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "VAFIN", "PPER", "NN", "ADJD", "$.", "$(", "$(", "PPER", "VVFIN", "$,", "PPER", "VVFIN", "ADJD", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "O k\u00f6nigliche Eiche, dich hat der Blitz zerspellt!", "tokens": ["O", "k\u00f6\u00b7nig\u00b7li\u00b7che", "Ei\u00b7che", ",", "dich", "hat", "der", "Blitz", "zer\u00b7spellt", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$,", "PPER", "VAFIN", "ART", "NN", "VVPP", "$."], "meter": "+-+--+--+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.4": {"text": "O Ulrich, tapfrer Ritter, dich hat das Schwert gef\u00e4llt!", "tokens": ["O", "Ul\u00b7rich", ",", "tapf\u00b7rer", "Rit\u00b7ter", ",", "dich", "hat", "das", "Schwert", "ge\u00b7f\u00e4llt", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "ADJA", "NN", "$,", "PPER", "VAFIN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.29": {"line.1": {"text": "Da ruft der alte Recke, den nichts ersch\u00fcttern kann:", "tokens": ["Da", "ruft", "der", "al\u00b7te", "Re\u00b7cke", ",", "den", "nichts", "er\u00b7sch\u00fct\u00b7tern", "kann", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "$,", "PRELS", "PIS", "VVINF", "VMFIN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "\u00bberschreckt nicht! der gefallen, ist wie ein andrer Mann.", "tokens": ["\u00bb", "er\u00b7schreckt", "nicht", "!", "der", "ge\u00b7fal\u00b7len", ",", "ist", "wie", "ein", "an\u00b7drer", "Mann", "."], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PTKNEG", "$.", "ART", "VVPP", "$,", "VAFIN", "KOKOM", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Schlagt drein! Die Feinde fliehen!\u00ab \u2013 er ruft's mit Donnerlaut;", "tokens": ["Schlagt", "drein", "!", "Die", "Fein\u00b7de", "flie\u00b7hen", "!", "\u00ab", "\u2013", "er", "ruft's", "mit", "Don\u00b7ner\u00b7laut", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "$.", "ART", "NN", "VVINF", "$.", "$(", "$(", "PPER", "VVFIN", "APPR", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Wie rauscht sein Bart im Winde! hei, wie der Eber haut!", "tokens": ["Wie", "rauscht", "sein", "Bart", "im", "Win\u00b7de", "!", "hei", ",", "wie", "der", "E\u00b7ber", "haut", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPOSAT", "NN", "APPRART", "NN", "$.", "PTKVZ", "$,", "PWAV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.30": {"line.1": {"text": "Die St\u00e4dter han vernommen das seltsam list'ge Wort.", "tokens": ["Die", "St\u00e4d\u00b7ter", "han", "ver\u00b7nom\u00b7men", "das", "selt\u00b7sam", "list'\u00b7ge", "Wort", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVPP", "ART", "ADJD", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "\u00bbwer flieht?\u00ab so fragen alle, schon wankt es hier und dort.", "tokens": ["\u00bb", "wer", "flieht", "?", "\u00ab", "so", "fra\u00b7gen", "al\u00b7le", ",", "schon", "wankt", "es", "hier", "und", "dort", "."], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "VVFIN", "$.", "$(", "ADV", "VVFIN", "PIS", "$,", "ADV", "VVFIN", "PPER", "ADV", "KON", "ADV", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Das Wort hat sie ergriffen gleich einem Zauberlied,", "tokens": ["Das", "Wort", "hat", "sie", "er\u00b7grif\u00b7fen", "gleich", "ei\u00b7nem", "Zau\u00b7berl\u00b7ied", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "VVPP", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Der Graf und seine Ritter durchbrechen Glied auf Glied.", "tokens": ["Der", "Graf", "und", "sei\u00b7ne", "Rit\u00b7ter", "durch\u00b7bre\u00b7chen", "Glied", "auf", "Glied", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "PPOSAT", "NN", "ADJA", "NN", "APPR", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.31": {"line.1": {"text": "Was glei\u00dft und gl\u00e4nzt da droben und zuckt wie Wetterschein?", "tokens": ["Was", "glei\u00dft", "und", "gl\u00e4nzt", "da", "dro\u00b7ben", "und", "zuckt", "wie", "Wet\u00b7ter\u00b7schein", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "KON", "VVFIN", "ADV", "ADV", "KON", "VVFIN", "KOKOM", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Das ist mit seinen Reitern der Wolf von Wunnenstein.", "tokens": ["Das", "ist", "mit", "sei\u00b7nen", "Rei\u00b7tern", "der", "Wolf", "von", "Wun\u00b7nen\u00b7stein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "APPR", "PPOSAT", "NN", "ART", "NE", "APPR", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Er wirft sich auf die St\u00e4dter, er sprengt sich weite Bucht,", "tokens": ["Er", "wirft", "sich", "auf", "die", "St\u00e4d\u00b7ter", ",", "er", "sprengt", "sich", "wei\u00b7te", "Bucht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "ART", "NN", "$,", "PPER", "VVFIN", "PRF", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Da ist der Sieg entschieden, der Feind in wilder Flucht.", "tokens": ["Da", "ist", "der", "Sieg", "ent\u00b7schie\u00b7den", ",", "der", "Feind", "in", "wil\u00b7der", "Flucht", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "VVPP", "$,", "ART", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.32": {"line.1": {"text": "Im Erntemond geschah es, bei Gott, ein hei\u00dfer Tag!", "tokens": ["Im", "Ern\u00b7te\u00b7mond", "ge\u00b7schah", "es", ",", "bei", "Gott", ",", "ein", "hei\u00b7\u00dfer", "Tag", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PPER", "$,", "APPR", "NN", "$,", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Was da der edeln Garben auf allen Feldern lag!", "tokens": ["Was", "da", "der", "e\u00b7deln", "Gar\u00b7ben", "auf", "al\u00b7len", "Fel\u00b7dern", "lag", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "ART", "ADJA", "NN", "APPR", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Wie auch so mancher Schnitter die Arme sinken l\u00e4\u00dft!", "tokens": ["Wie", "auch", "so", "man\u00b7cher", "Schnit\u00b7ter", "die", "Ar\u00b7me", "sin\u00b7ken", "l\u00e4\u00dft", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "ADV", "PIAT", "NN", "ART", "NN", "VVINF", "VVFIN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Wohl halten diese Ritter ein blutig Sichelfest.", "tokens": ["Wohl", "hal\u00b7ten", "die\u00b7se", "Rit\u00b7ter", "ein", "blu\u00b7tig", "Si\u00b7chel\u00b7fest", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PDAT", "NN", "ART", "ADJD", "NE", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.33": {"line.1": {"text": "Noch lange traf der Bauer, der hinterm Pfluge ging,", "tokens": ["Noch", "lan\u00b7ge", "traf", "der", "Bau\u00b7er", ",", "der", "hin\u00b7term", "Pflu\u00b7ge", "ging", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "ART", "NN", "$,", "PRELS", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Auf rost'ge Degenklinge, Speereisen, Panzerring,", "tokens": ["Auf", "rost'\u00b7ge", "De\u00b7gen\u00b7klin\u00b7ge", ",", "Spee\u00b7rei\u00b7sen", ",", "Pan\u00b7zer\u00b7ring", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Und als man eine Linde zers\u00e4gt und niederstreckt,", "tokens": ["Und", "als", "man", "ei\u00b7ne", "Lin\u00b7de", "zer\u00b7s\u00e4gt", "und", "nie\u00b7der\u00b7streckt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PIS", "ART", "NE", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Zeigt sich darin ein Harnisch und ein Geripp versteckt.", "tokens": ["Zeigt", "sich", "da\u00b7rin", "ein", "Har\u00b7nisch", "und", "ein", "Ge\u00b7ripp", "ver\u00b7steckt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "PAV", "ART", "NN", "KON", "ART", "NN", "VVPP", "$."], "meter": "+-+--+--+-+-+", "measure": "trochaic.hexa.relaxed"}}, "stanza.34": {"line.1": {"text": "Als nun die Schlacht geschlagen und Sieg geblasen war,", "tokens": ["Als", "nun", "die", "Schlacht", "ge\u00b7schla\u00b7gen", "und", "Sieg", "ge\u00b7bla\u00b7sen", "war", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "VVPP", "KON", "NN", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Da reicht der alte Greiner dem Wolf die Rechte dar:", "tokens": ["Da", "reicht", "der", "al\u00b7te", "Grei\u00b7ner", "dem", "Wolf", "die", "Rech\u00b7te", "dar", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "ART", "NE", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "\u00bbhab Dank, du tapfrer Degen, und reit mit mir nach Haus!", "tokens": ["\u00bb", "hab", "Dank", ",", "du", "tapf\u00b7rer", "De\u00b7gen", ",", "und", "reit", "mit", "mir", "nach", "Haus", "!"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VAFIN", "NN", "$,", "PPER", "ADJA", "NN", "$,", "KON", "NN", "APPR", "PPER", "APPR", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Da\u00df wir uns g\u00fctlich pflegen nach diesem harten Strau\u00df.\u00ab", "tokens": ["Da\u00df", "wir", "uns", "g\u00fct\u00b7lich", "pfle\u00b7gen", "nach", "die\u00b7sem", "har\u00b7ten", "Strau\u00df", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PPER", "PRF", "ADJD", "VVFIN", "APPR", "PDAT", "ADJA", "NE", "$.", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.35": {"line.1": {"text": "\u00bbhei!\u00ab spricht der Wolf mit Lachen, \u00bbgefiel Euch dieser Schwank?", "tokens": ["\u00bb", "hei", "!", "\u00ab", "spricht", "der", "Wolf", "mit", "La\u00b7chen", ",", "\u00bb", "ge\u00b7fiel", "Euch", "die\u00b7ser", "Schwank", "?"], "token_info": ["punct", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PTKVZ", "$.", "$(", "VVFIN", "ART", "NE", "APPR", "NN", "$,", "$(", "VVFIN", "PPER", "PDAT", "NN", "$."], "meter": "+--+-+--+-+-+", "measure": "iambic.hexa.invert"}, "line.2": {"text": "Ich stritt aus Ha\u00df der St\u00e4dte und nicht um Euren Dank.", "tokens": ["Ich", "stritt", "aus", "Ha\u00df", "der", "St\u00e4d\u00b7te", "und", "nicht", "um", "Eu\u00b7ren", "Dank", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "ART", "NN", "KON", "PTKNEG", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Gut Nacht und Gl\u00fcck zur Reise! es steht im alten Recht.\u00ab", "tokens": ["Gut", "Nacht", "und", "Gl\u00fcck", "zur", "Rei\u00b7se", "!", "es", "steht", "im", "al\u00b7ten", "Recht", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADJD", "NN", "KON", "NN", "APPRART", "NN", "$.", "PPER", "VVFIN", "APPRART", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Er spricht's und jagt von dannen mit Ritter und mit Knecht.", "tokens": ["Er", "spricht's", "und", "jagt", "von", "dan\u00b7nen", "mit", "Rit\u00b7ter", "und", "mit", "Knecht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "APPR", "ADV", "APPR", "NN", "KON", "APPR", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.36": {"line.1": {"text": "Zu D\u00f6ffingen im Dorfe, da hat der Graf die Nacht", "tokens": ["Zu", "D\u00f6f\u00b7fin\u00b7gen", "im", "Dor\u00b7fe", ",", "da", "hat", "der", "Graf", "die", "Nacht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "APPRART", "NN", "$,", "ADV", "VAFIN", "ART", "NN", "ART", "NN"], "meter": "-++--+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Bei seines Ulrichs Leiche, des einz'gen Sohns, verbracht.", "tokens": ["Bei", "sei\u00b7nes", "Ul\u00b7richs", "Lei\u00b7che", ",", "des", "einz'\u00b7gen", "Sohns", ",", "ver\u00b7bracht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$,", "ART", "ADJA", "NN", "$,", "VVPP", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Er kniet zur Bahre nieder, verh\u00fcllet sein Gesicht;", "tokens": ["Er", "kniet", "zur", "Bah\u00b7re", "nie\u00b7der", ",", "ver\u00b7h\u00fcl\u00b7let", "sein", "Ge\u00b7sicht", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "PTKVZ", "$,", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Ob er vielleicht im stillen geweint, man wei\u00df es nicht.", "tokens": ["Ob", "er", "viel\u00b7leicht", "im", "stil\u00b7len", "ge\u00b7weint", ",", "man", "wei\u00df", "es", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "APPRART", "ADJA", "VVPP", "$,", "PIS", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "---+-+--+-+-+", "measure": "iambic.penta.relaxed"}}, "stanza.37": {"line.1": {"text": "Des Morgens mit dem Fr\u00fchsten steigt Eberhard zu Ro\u00df,", "tokens": ["Des", "Mor\u00b7gens", "mit", "dem", "Fr\u00fchs\u00b7ten", "steigt", "E\u00b7ber\u00b7hard", "zu", "Ro\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "ART", "NN", "VVFIN", "NE", "APPR", "NN", "$,"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Gen Stuttgart f\u00e4hrt er wieder mit seinem reis'gen Tro\u00df,", "tokens": ["Gen", "Stutt\u00b7gart", "f\u00e4hrt", "er", "wie\u00b7der", "mit", "sei\u00b7nem", "reis'\u00b7gen", "Tro\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "VVFIN", "PPER", "ADV", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Da kommt des Wegs gelaufen der Zuffenhauser Hirt;", "tokens": ["Da", "kommt", "des", "Wegs", "ge\u00b7lau\u00b7fen", "der", "Zuf\u00b7fen\u00b7hau\u00b7ser", "Hirt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "VVPP", "ART", "NN", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "\u00bbdem Mann ist's tr\u00fcb zumute, was der uns bringen wird?\u00ab", "tokens": ["\u00bb", "dem", "Mann", "ist's", "tr\u00fcb", "zu\u00b7mu\u00b7te", ",", "was", "der", "uns", "brin\u00b7gen", "wird", "?", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ART", "NN", "VAFIN", "ADJD", "VVFIN", "$,", "PRELS", "ART", "PPER", "VVINF", "VAFIN", "$.", "$("], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.38": {"line.1": {"text": "\u00bbich bring Euch b\u00f6se Kunde, n\u00e4cht ist in unsern Trieb", "tokens": ["\u00bb", "ich", "bring", "Euch", "b\u00f6\u00b7se", "Kun\u00b7de", ",", "n\u00e4cht", "ist", "in", "un\u00b7sern", "Trieb"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["$(", "PPER", "VVFIN", "PPER", "ADJA", "NN", "$,", "ADJD", "VAFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Der glei\u00dfend' Wolf gefallen, er nahm, soviel ihm lieb.\u00ab", "tokens": ["Der", "glei\u00b7\u00dfend'", "Wolf", "ge\u00b7fal\u00b7len", ",", "er", "nahm", ",", "so\u00b7viel", "ihm", "lieb", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["ART", "ADJA", "NE", "VVPP", "$,", "PPER", "VVFIN", "$,", "KOUS", "PPER", "ADJD", "$.", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Da lacht der alte Greiner in seinen grauen Bart:", "tokens": ["Da", "lacht", "der", "al\u00b7te", "Grei\u00b7ner", "in", "sei\u00b7nen", "grau\u00b7en", "Bart", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "\u00bbdas W\u00f6lflein holt sich Kochfleisch, das ist des W\u00f6lfleins Art.\u00ab", "tokens": ["\u00bb", "das", "W\u00f6lf\u00b7lein", "holt", "sich", "Koch\u00b7fleisch", ",", "das", "ist", "des", "W\u00f6lf\u00b7leins", "Art", ".", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ART", "NN", "VVFIN", "PRF", "NE", "$,", "PDS", "VAFIN", "ART", "NN", "NN", "$.", "$("], "meter": "-+-+-++-+-+-+", "measure": "unknown.measure.septa"}}, "stanza.39": {"line.1": {"text": "Sie reiten r\u00fcstig f\u00fcrder, sie sehn aus gr\u00fcnem Tal", "tokens": ["Sie", "rei\u00b7ten", "r\u00fcs\u00b7tig", "f\u00fcr\u00b7der", ",", "sie", "sehn", "aus", "gr\u00fc\u00b7nem", "Tal"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADJD", "PTKVZ", "$,", "PPER", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+-+----+-+-+", "measure": "unknown.measure.penta"}, "line.2": {"text": "Das Schlo\u00df von Stuttgart ragen, es gl\u00e4nzt im Morgenstrahl,", "tokens": ["Das", "Schlo\u00df", "von", "Stutt\u00b7gart", "ra\u00b7gen", ",", "es", "gl\u00e4nzt", "im", "Mor\u00b7gen\u00b7strahl", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NE", "VVFIN", "$,", "PPER", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Da kommt des Wegs geritten ein schmucker Edelknecht;", "tokens": ["Da", "kommt", "des", "Wegs", "ge\u00b7rit\u00b7ten", "ein", "schmu\u00b7cker", "E\u00b7del\u00b7knecht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "VVPP", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "\u00bbder Knab will mich bed\u00fcnken, als ob er Gutes br\u00e4cht.\u00ab", "tokens": ["\u00bb", "der", "Knab", "will", "mich", "be\u00b7d\u00fcn\u00b7ken", ",", "als", "ob", "er", "Gu\u00b7tes", "br\u00e4cht", ".", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ART", "NN", "VMFIN", "PRF", "VVINF", "$,", "KOKOM", "KOUS", "PPER", "NN", "VVFIN", "$.", "$("], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.40": {"line.1": {"text": "\u00bbich bring Euch frohe M\u00e4re: Gl\u00fcck zum Urenkelein!", "tokens": ["\u00bb", "ich", "bring", "Euch", "fro\u00b7he", "M\u00e4\u00b7re", ":", "Gl\u00fcck", "zum", "Ur\u00b7en\u00b7kel\u00b7ein", "!"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "PPER", "ADJA", "NN", "$.", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.2": {"text": "Antonia hat geboren ein Kn\u00e4blein, hold und fein.\u00ab", "tokens": ["An\u00b7to\u00b7nia", "hat", "ge\u00b7bo\u00b7ren", "ein", "Kn\u00e4\u00b7blein", ",", "hold", "und", "fein", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["NE", "VAFIN", "VVPP", "ART", "NN", "$,", "ADJD", "KON", "ADJD", "$.", "$("], "meter": "+--+-+--+-+-+", "measure": "iambic.hexa.invert"}, "line.3": {"text": "Da hebt er hoch die H\u00e4nde, der ritterliche Greis:", "tokens": ["Da", "hebt", "er", "hoch", "die", "H\u00e4n\u00b7de", ",", "der", "rit\u00b7ter\u00b7li\u00b7che", "Greis", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "ART", "NN", "$,", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "\u00bbder Fink hat wieder Samen, dem Herrn sei Dank und Preis!\u00ab", "tokens": ["\u00bb", "der", "Fink", "hat", "wie\u00b7der", "Sa\u00b7men", ",", "dem", "Herrn", "sei", "Dank", "und", "Preis", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ART", "NN", "VAFIN", "ADV", "NN", "$,", "ART", "NN", "VAFIN", "NN", "KON", "NN", "$.", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}}}}