{"textgrid.poem.62918": {"metadata": {"author": {"name": "Pfeffel, Gottlieb Konrad", "birth": "N.A.", "death": "N.A."}, "title": "1L: Auf einer brittischen Fregatte,", "genre": "verse", "period": "N.A.", "pub_year": 1782, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Auf einer brittischen Fregatte,", "tokens": ["Auf", "ei\u00b7ner", "brit\u00b7ti\u00b7schen", "Fre\u00b7gat\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die Wanderer aus jedem Land", "tokens": ["Die", "Wan\u00b7de\u00b7rer", "aus", "je\u00b7dem", "Land"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Auf ihrer Fahrt vom Indusstrand", "tokens": ["Auf", "ih\u00b7rer", "Fahrt", "vom", "In\u00b7dus\u00b7strand"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Nach Canton eingenommen hatte,", "tokens": ["Nach", "Can\u00b7ton", "ein\u00b7ge\u00b7nom\u00b7men", "hat\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Gerieth ein Sohn des alten Theut", "tokens": ["Ge\u00b7rieth", "ein", "Sohn", "des", "al\u00b7ten", "Theut"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "ART", "NN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Mit einem Gallier in Streit", "tokens": ["Mit", "ei\u00b7nem", "Gal\u00b7lier", "in", "Streit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "APPR", "NN"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.7": {"text": "Des oft verw\u00fcnschten Apfels wegen,", "tokens": ["Des", "oft", "ver\u00b7w\u00fcnschten", "Ap\u00b7fels", "we\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJA", "NN", "APPR", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "Der Pestilenz und theure Zeit,", "tokens": ["Der", "Pes\u00b7ti\u00b7lenz", "und", "theu\u00b7re", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Symbole, Galgen, Kronen, Degen,", "tokens": ["Sym\u00b7bo\u00b7le", ",", "Gal\u00b7gen", ",", "Kro\u00b7nen", ",", "De\u00b7gen", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,"], "meter": "---+-+-+-", "measure": "unknown.measure.tri"}, "line.10": {"text": "Und Sch\u00fcrzen in die Welt gebracht.", "tokens": ["Und", "Sch\u00fcr\u00b7zen", "in", "die", "Welt", "ge\u00b7bracht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Der Deutsche sprach: auf unsern H\u00f6hen", "tokens": ["Der", "Deut\u00b7sche", "sprach", ":", "auf", "un\u00b7sern", "H\u00f6\u00b7hen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "$.", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Bey Borstdorf ist sie noch zu sehen,", "tokens": ["Bey", "Borst\u00b7dorf", "ist", "sie", "noch", "zu", "se\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VAFIN", "PPER", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Die Frucht. Der weise Franzmann lacht:", "tokens": ["Die", "Frucht", ".", "Der", "wei\u00b7se", "Franz\u00b7mann", "lacht", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$.", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Pardon, wir nennen sie Renette,", "tokens": ["Par\u00b7don", ",", "wir", "nen\u00b7nen", "sie", "Re\u00b7net\u00b7te", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PPER", "VVFIN", "PPER", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "Und Frankreich ist ihr Vaterland.", "tokens": ["Und", "Fran\u00b7kreich", "ist", "ihr", "Va\u00b7ter\u00b7land", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "VAFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Die K\u00e4mpfer schrien um die Wette,", "tokens": ["Die", "K\u00e4mp\u00b7fer", "schri\u00b7en", "um", "die", "Wet\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.17": {"text": "Bis man zuletzt f\u00fcr dienlich fand,", "tokens": ["Bis", "man", "zu\u00b7letzt", "f\u00fcr", "dien\u00b7lich", "fand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "ADV", "APPR", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.18": {"text": "Dem Ausspruch zweener Jesuiten", "tokens": ["Dem", "Aus\u00b7spruch", "zwee\u00b7ner", "Je\u00b7su\u00b7i\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.19": {"text": "Aus Porto sich zu unterziehn.", "tokens": ["Aus", "Por\u00b7to", "sich", "zu", "un\u00b7ter\u00b7ziehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "PRF", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.20": {"text": "Ey! Freunde, rief der Lojoliten", "tokens": ["Ey", "!", "Freun\u00b7de", ",", "rief", "der", "Lo\u00b7jo\u00b7li\u00b7ten"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word"], "pos": ["NN", "$.", "NN", "$,", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.21": {"text": "Gelehrtes Paar, wo denkt ihr hin?", "tokens": ["Ge\u00b7lehr\u00b7tes", "Paar", ",", "wo", "denkt", "ihr", "hin", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "PWAV", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.22": {"text": "Ihr irrt, es war die Apfelsine,", "tokens": ["Ihr", "irrt", ",", "es", "war", "die", "Ap\u00b7fel\u00b7si\u00b7ne", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.23": {"text": "Das schw\u00f6ren wir beym Escobar.", "tokens": ["Das", "schw\u00f6\u00b7ren", "wir", "beym", "E\u00b7sco\u00b7bar", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "APPRART", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.24": {"text": "Ihr Herrn, sprach mit bescheidner Miene", "tokens": ["Ihr", "Herrn", ",", "sprach", "mit", "be\u00b7scheid\u00b7ner", "Mie\u00b7ne"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "$,", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.25": {"text": "Ein Proselyt aus Trankebar,", "tokens": ["Ein", "Pro\u00b7se\u00b7lyt", "aus", "Tran\u00b7ke\u00b7bar", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.26": {"text": "Mich d\u00fcnkt, ich habe wo gelesen,", "tokens": ["Mich", "d\u00fcnkt", ",", "ich", "ha\u00b7be", "wo", "ge\u00b7le\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VAFIN", "PWAV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.27": {"text": "Es sey die Kokosnu\u00df gewesen.", "tokens": ["Es", "sey", "die", "Ko\u00b7kos\u00b7nu\u00df", "ge\u00b7we\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "VAPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.28": {"text": "Hier bi\u00df der alte Schifskaplan,", "tokens": ["Hier", "bi\u00df", "der", "al\u00b7te", "Schifs\u00b7ka\u00b7plan", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.29": {"text": "Vom Punsch erhitzt, mit wilden Blicken", "tokens": ["Vom", "Pun\u00b7sch", "er\u00b7hitzt", ",", "mit", "wil\u00b7den", "Bli\u00b7cken"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPRART", "NN", "VVFIN", "$,", "APPR", "ADJA", "NN"], "meter": "--+-+-+-+-", "measure": "anapaest.init"}, "line.30": {"text": "Sein krummes Pfeifenrohr in St\u00fccken,", "tokens": ["Sein", "krum\u00b7mes", "Pfei\u00b7fen\u00b7rohr", "in", "St\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.31": {"text": "Und spie es in den Ocean.", "tokens": ["Und", "spie", "es", "in", "den", "O\u00b7cean", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.32": {"text": "Nein, l\u00e4nger ists nicht auszustehen,", "tokens": ["Nein", ",", "l\u00e4n\u00b7ger", "ists", "nicht", "aus\u00b7zu\u00b7ste\u00b7hen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "ADJD", "VAFIN", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.33": {"text": "Wer wird die Bibel so verdrehen?", "tokens": ["Wer", "wird", "die", "Bi\u00b7bel", "so", "ver\u00b7dre\u00b7hen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ART", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.34": {"text": "Rief er: es ist ja sonnenklar,", "tokens": ["Rief", "er", ":", "es", "ist", "ja", "son\u00b7nen\u00b7klar", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$.", "PPER", "VAFIN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Auf einer brittischen Fregatte,", "tokens": ["Auf", "ei\u00b7ner", "brit\u00b7ti\u00b7schen", "Fre\u00b7gat\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die Wanderer aus jedem Land", "tokens": ["Die", "Wan\u00b7de\u00b7rer", "aus", "je\u00b7dem", "Land"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Auf ihrer Fahrt vom Indusstrand", "tokens": ["Auf", "ih\u00b7rer", "Fahrt", "vom", "In\u00b7dus\u00b7strand"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Nach Canton eingenommen hatte,", "tokens": ["Nach", "Can\u00b7ton", "ein\u00b7ge\u00b7nom\u00b7men", "hat\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Gerieth ein Sohn des alten Theut", "tokens": ["Ge\u00b7rieth", "ein", "Sohn", "des", "al\u00b7ten", "Theut"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "ART", "NN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Mit einem Gallier in Streit", "tokens": ["Mit", "ei\u00b7nem", "Gal\u00b7lier", "in", "Streit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "APPR", "NN"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.7": {"text": "Des oft verw\u00fcnschten Apfels wegen,", "tokens": ["Des", "oft", "ver\u00b7w\u00fcnschten", "Ap\u00b7fels", "we\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJA", "NN", "APPR", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "Der Pestilenz und theure Zeit,", "tokens": ["Der", "Pes\u00b7ti\u00b7lenz", "und", "theu\u00b7re", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Symbole, Galgen, Kronen, Degen,", "tokens": ["Sym\u00b7bo\u00b7le", ",", "Gal\u00b7gen", ",", "Kro\u00b7nen", ",", "De\u00b7gen", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,"], "meter": "---+-+-+-", "measure": "unknown.measure.tri"}, "line.10": {"text": "Und Sch\u00fcrzen in die Welt gebracht.", "tokens": ["Und", "Sch\u00fcr\u00b7zen", "in", "die", "Welt", "ge\u00b7bracht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Der Deutsche sprach: auf unsern H\u00f6hen", "tokens": ["Der", "Deut\u00b7sche", "sprach", ":", "auf", "un\u00b7sern", "H\u00f6\u00b7hen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "$.", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Bey Borstdorf ist sie noch zu sehen,", "tokens": ["Bey", "Borst\u00b7dorf", "ist", "sie", "noch", "zu", "se\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VAFIN", "PPER", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Die Frucht. Der weise Franzmann lacht:", "tokens": ["Die", "Frucht", ".", "Der", "wei\u00b7se", "Franz\u00b7mann", "lacht", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$.", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Pardon, wir nennen sie Renette,", "tokens": ["Par\u00b7don", ",", "wir", "nen\u00b7nen", "sie", "Re\u00b7net\u00b7te", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PPER", "VVFIN", "PPER", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "Und Frankreich ist ihr Vaterland.", "tokens": ["Und", "Fran\u00b7kreich", "ist", "ihr", "Va\u00b7ter\u00b7land", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "VAFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Die K\u00e4mpfer schrien um die Wette,", "tokens": ["Die", "K\u00e4mp\u00b7fer", "schri\u00b7en", "um", "die", "Wet\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.17": {"text": "Bis man zuletzt f\u00fcr dienlich fand,", "tokens": ["Bis", "man", "zu\u00b7letzt", "f\u00fcr", "dien\u00b7lich", "fand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "ADV", "APPR", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.18": {"text": "Dem Ausspruch zweener Jesuiten", "tokens": ["Dem", "Aus\u00b7spruch", "zwee\u00b7ner", "Je\u00b7su\u00b7i\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.19": {"text": "Aus Porto sich zu unterziehn.", "tokens": ["Aus", "Por\u00b7to", "sich", "zu", "un\u00b7ter\u00b7ziehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "PRF", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.20": {"text": "Ey! Freunde, rief der Lojoliten", "tokens": ["Ey", "!", "Freun\u00b7de", ",", "rief", "der", "Lo\u00b7jo\u00b7li\u00b7ten"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word"], "pos": ["NN", "$.", "NN", "$,", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.21": {"text": "Gelehrtes Paar, wo denkt ihr hin?", "tokens": ["Ge\u00b7lehr\u00b7tes", "Paar", ",", "wo", "denkt", "ihr", "hin", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "PWAV", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.22": {"text": "Ihr irrt, es war die Apfelsine,", "tokens": ["Ihr", "irrt", ",", "es", "war", "die", "Ap\u00b7fel\u00b7si\u00b7ne", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.23": {"text": "Das schw\u00f6ren wir beym Escobar.", "tokens": ["Das", "schw\u00f6\u00b7ren", "wir", "beym", "E\u00b7sco\u00b7bar", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "APPRART", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.24": {"text": "Ihr Herrn, sprach mit bescheidner Miene", "tokens": ["Ihr", "Herrn", ",", "sprach", "mit", "be\u00b7scheid\u00b7ner", "Mie\u00b7ne"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "$,", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.25": {"text": "Ein Proselyt aus Trankebar,", "tokens": ["Ein", "Pro\u00b7se\u00b7lyt", "aus", "Tran\u00b7ke\u00b7bar", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.26": {"text": "Mich d\u00fcnkt, ich habe wo gelesen,", "tokens": ["Mich", "d\u00fcnkt", ",", "ich", "ha\u00b7be", "wo", "ge\u00b7le\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VAFIN", "PWAV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.27": {"text": "Es sey die Kokosnu\u00df gewesen.", "tokens": ["Es", "sey", "die", "Ko\u00b7kos\u00b7nu\u00df", "ge\u00b7we\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "VAPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.28": {"text": "Hier bi\u00df der alte Schifskaplan,", "tokens": ["Hier", "bi\u00df", "der", "al\u00b7te", "Schifs\u00b7ka\u00b7plan", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.29": {"text": "Vom Punsch erhitzt, mit wilden Blicken", "tokens": ["Vom", "Pun\u00b7sch", "er\u00b7hitzt", ",", "mit", "wil\u00b7den", "Bli\u00b7cken"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPRART", "NN", "VVFIN", "$,", "APPR", "ADJA", "NN"], "meter": "--+-+-+-+-", "measure": "anapaest.init"}, "line.30": {"text": "Sein krummes Pfeifenrohr in St\u00fccken,", "tokens": ["Sein", "krum\u00b7mes", "Pfei\u00b7fen\u00b7rohr", "in", "St\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.31": {"text": "Und spie es in den Ocean.", "tokens": ["Und", "spie", "es", "in", "den", "O\u00b7cean", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.32": {"text": "Nein, l\u00e4nger ists nicht auszustehen,", "tokens": ["Nein", ",", "l\u00e4n\u00b7ger", "ists", "nicht", "aus\u00b7zu\u00b7ste\u00b7hen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "ADJD", "VAFIN", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.33": {"text": "Wer wird die Bibel so verdrehen?", "tokens": ["Wer", "wird", "die", "Bi\u00b7bel", "so", "ver\u00b7dre\u00b7hen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ART", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.34": {"text": "Rief er: es ist ja sonnenklar,", "tokens": ["Rief", "er", ":", "es", "ist", "ja", "son\u00b7nen\u00b7klar", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$.", "PPER", "VAFIN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}