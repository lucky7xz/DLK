{"textgrid.poem.57493": {"metadata": {"author": {"name": "Gottsched, Johann Christoph", "birth": "N.A.", "death": "N.A."}, "title": "Antwort an die Frau D. Volkmanninn", "genre": "verse", "period": "N.A.", "pub_year": 1733, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Hat neulich lauter Stolz in meiner Brust emp\u00f6rt.", "tokens": ["Hat", "neu\u00b7lich", "lau\u00b7ter", "Stolz", "in", "mei\u00b7ner", "Brust", "em\u00b7p\u00f6rt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PIAT", "NN", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wie trotzte nicht mein Herz, als ich dein Blatt gelesen?", "tokens": ["Wie", "trotz\u00b7te", "nicht", "mein", "Herz", ",", "als", "ich", "dein", "Blatt", "ge\u00b7le\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PTKNEG", "PPOSAT", "NN", "$,", "KOUS", "PPER", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ich bin ja, sprach der Mund, was ", "tokens": ["Ich", "bin", "ja", ",", "sprach", "der", "Mund", ",", "was"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["PPER", "VAFIN", "ADV", "$,", "VVFIN", "ART", "NN", "$,", "PWS"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Ich bin, was ", "tokens": ["Ich", "bin", ",", "was"], "token_info": ["word", "word", "punct", "word"], "pos": ["PPER", "VAFIN", "$,", "PWS"], "meter": "-+-", "measure": "amphibrach.single"}, "line.5": {"text": "Ja, Gottsched steht nun auch in jener Dichter Schaar,", "tokens": ["Ja", ",", "Gott\u00b7sched", "steht", "nun", "auch", "in", "je\u00b7ner", "Dich\u00b7ter", "Schaar", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "NE", "VVFIN", "ADV", "ADV", "APPR", "PDAT", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Dadurch sich Deutschlands Ruhm so hoch empor geschwungen,", "tokens": ["Da\u00b7durch", "sich", "Deutschlands", "Ruhm", "so", "hoch", "em\u00b7por", "ge\u00b7schwun\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PRF", "NE", "NN", "ADV", "ADJD", "PTKVZ", "VVPP", "$,"], "meter": "--+-+-+-+-+-", "measure": "anapaest.init"}, "line.7": {"text": "Wenn sie Athen und Rom den Vorzug abgesungen.", "tokens": ["Wenn", "sie", "A\u00b7then", "und", "Rom", "den", "Vor\u00b7zug", "ab\u00b7ge\u00b7sun\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NE", "KON", "NE", "ART", "NN", "VVPP", "$."], "meter": "+-+--+-+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.8": {"text": "Hier hat kein Zweifel statt. ", "tokens": ["Hier", "hat", "kein", "Zwei\u00b7fel", "statt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "Und selbst so herrlich singt, von ", "tokens": ["Und", "selbst", "so", "herr\u00b7lich", "singt", ",", "von"], "token_info": ["word", "word", "word", "word", "word", "punct", "word"], "pos": ["KON", "ADV", "ADV", "ADJD", "VVFIN", "$,", "APPR"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.10": {"text": "Der Musen Schwester ist, vergleicht ja deine Fr\u00fcchte", "tokens": ["Der", "Mu\u00b7sen", "Schwes\u00b7ter", "ist", ",", "ver\u00b7gleicht", "ja", "dei\u00b7ne", "Fr\u00fcch\u00b7te"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "NN", "VAFIN", "$,", "VVFIN", "ADV", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Mit der Vollkommenheit der herrlichsten Gedichte.", "tokens": ["Mit", "der", "Voll\u00b7kom\u00b7men\u00b7heit", "der", "herr\u00b7lichs\u00b7ten", "Ge\u00b7dich\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+---+-", "measure": "unknown.measure.penta"}}, "stanza.2": {"line.1": {"text": "Die Nase hub sich schon; ich trug des Haupt empor.", "tokens": ["Die", "Na\u00b7se", "hub", "sich", "schon", ";", "ich", "trug", "des", "Haupt", "em\u00b7por", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PRF", "ADV", "$.", "PPER", "VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Inde\u00df kam die Vernunft, und sagte mir ins Ohr:", "tokens": ["In\u00b7de\u00df", "kam", "die", "Ver\u00b7nunft", ",", "und", "sag\u00b7te", "mir", "ins", "Ohr", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ART", "NN", "$,", "KON", "VVFIN", "PPER", "APPRART", "NN", "$."], "meter": "--+--+-+-+-+", "measure": "anapaest.di.plus"}, "line.3": {"text": "Gemach, betrogner Geist! du must dich besser kennen,", "tokens": ["Ge\u00b7mach", ",", "be\u00b7trog\u00b7ner", "Geist", "!", "du", "must", "dich", "bes\u00b7ser", "ken\u00b7nen", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "ADJA", "NN", "$.", "PPER", "VMFIN", "PRF", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Als Schm\u00e4uchler, die zum Scherz dich einen Dichter nennen.", "tokens": ["Als", "Schm\u00e4uch\u00b7ler", ",", "die", "zum", "Scherz", "dich", "ei\u00b7nen", "Dich\u00b7ter", "nen\u00b7nen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "$,", "PRELS", "APPRART", "NN", "PPER", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wie sonst ein steiles Rohr den schwachen Nacken neigt,", "tokens": ["Wie", "sonst", "ein", "stei\u00b7les", "Rohr", "den", "schwa\u00b7chen", "Na\u00b7cken", "neigt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "ART", "ADJA", "NN", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wenn die bewegte Luft den stolzen Gipfel beugt", "tokens": ["Wenn", "die", "be\u00b7weg\u00b7te", "Luft", "den", "stol\u00b7zen", "Gip\u00b7fel", "beugt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "NN", "ART", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und ihn zur Erden dr\u00fcckt: so schlug die\u00df Wort mich nieder,", "tokens": ["Und", "ihn", "zur", "Er\u00b7den", "dr\u00fcckt", ":", "so", "schlug", "die\u00df", "Wort", "mich", "nie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "APPRART", "NN", "VVFIN", "$.", "ADV", "VVFIN", "PDS", "NN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und meine Eitelkeit verschwand allm\u00e4hlich wieder.", "tokens": ["Und", "mei\u00b7ne", "Ei\u00b7tel\u00b7keit", "ver\u00b7schwand", "all\u00b7m\u00e4h\u00b7lich", "wie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "ADJD", "ADV", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Nur eins, o Dichterinn! hat mich bisher gereut,", "tokens": ["Nur", "eins", ",", "o", "Dich\u00b7te\u00b7rinn", "!", "hat", "mich", "bis\u00b7her", "ge\u00b7reut", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "$,", "FM", "NN", "$.", "VAFIN", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Da\u00df meines letzten Reims verw\u00fcnschte Dunkelheit", "tokens": ["Da\u00df", "mei\u00b7nes", "letz\u00b7ten", "Reims", "ver\u00b7w\u00fcnschte", "Dun\u00b7kel\u00b7heit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPOSAT", "ADJA", "NN", "ADJA", "NN"], "meter": "-+-+-+-++-+", "measure": "unknown.measure.hexa"}, "line.3": {"text": "Dir den Verdacht erweckt, als h\u00e4tt ich mich vergessen,", "tokens": ["Dir", "den", "Ver\u00b7dacht", "er\u00b7weckt", ",", "als", "h\u00e4tt", "ich", "mich", "ver\u00b7ges\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "VVPP", "$,", "KOKOM", "VAFIN", "PPER", "PRF", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und dir, zur Ungeb\u00fchr, ein Laster beygemessen;", "tokens": ["Und", "dir", ",", "zur", "Un\u00b7ge\u00b7b\u00fchr", ",", "ein", "Las\u00b7ter", "bey\u00b7ge\u00b7mes\u00b7sen", ";"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "$,", "APPRART", "NN", "$,", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ein Laster, dessen Spur ich nie an dir gesehn,", "tokens": ["Ein", "Las\u00b7ter", ",", "des\u00b7sen", "Spur", "ich", "nie", "an", "dir", "ge\u00b7sehn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELAT", "NN", "PPER", "ADV", "APPR", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Das du so sehr geha\u00dft, als selten wo geschehn:", "tokens": ["Das", "du", "so", "sehr", "ge\u00b7ha\u00dft", ",", "als", "sel\u00b7ten", "wo", "ge\u00b7schehn", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "ADV", "VVPP", "$,", "KOUS", "ADJA", "PWAV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Indem du stets geglaubt, der Musen keuscher Orden", "tokens": ["In\u00b7dem", "du", "stets", "ge\u00b7glaubt", ",", "der", "Mu\u00b7sen", "keu\u00b7scher", "Or\u00b7den"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "VVPP", "$,", "ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Sey niemals der Gewalt der Liebe zinsbar worden.", "tokens": ["Sey", "nie\u00b7mals", "der", "Ge\u00b7walt", "der", "Lie\u00b7be", "zins\u00b7bar", "wor\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "ART", "NN", "ADJD", "VAPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Nein, Werthe! glaub es nicht. So sehr es dir auch scheint,", "tokens": ["Nein", ",", "Wert\u00b7he", "!", "glaub", "es", "nicht", ".", "So", "sehr", "es", "dir", "auch", "scheint", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "NN", "$.", "VVFIN", "PPER", "PTKNEG", "$.", "ADV", "ADV", "PPER", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "So wenig hat dein Knecht es neulich so gemeynt.", "tokens": ["So", "we\u00b7nig", "hat", "dein", "Knecht", "es", "neu\u00b7lich", "so", "ge\u00b7meynt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VAFIN", "PPOSAT", "NN", "PPER", "ADV", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Sprich selber, kann ein Vers nicht ohne Schuld entz\u00fccken?", "tokens": ["Sprich", "sel\u00b7ber", ",", "kann", "ein", "Vers", "nicht", "oh\u00b7ne", "Schuld", "ent\u00b7z\u00fc\u00b7cken", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ADV", "$,", "VMFIN", "ART", "NN", "PTKNEG", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Kann ", "tokens": ["Kann"], "token_info": ["word"], "pos": ["VMFIN"], "meter": "+", "measure": "single.up"}, "line.13": {"text": "Und nimmt die Poesie nicht tausend Herzen ein,", "tokens": ["Und", "nimmt", "die", "Poe\u00b7sie", "nicht", "tau\u00b7send", "Her\u00b7zen", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "PTKNEG", "CARD", "NN", "PTKVZ", "$,"], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.14": {"text": "Die gleichwohl nicht verliebt, viel minder unkeusch seyn?", "tokens": ["Die", "gleich\u00b7wohl", "nicht", "ver\u00b7liebt", ",", "viel", "min\u00b7der", "un\u00b7keusch", "seyn", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "PTKNEG", "VVPP", "$,", "ADV", "ADV", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Ich weis, du giebst mir recht; was willst du mich denn qu\u00e4len?", "tokens": ["Ich", "weis", ",", "du", "giebst", "mir", "recht", ";", "was", "willst", "du", "mich", "denn", "qu\u00e4\u00b7len", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKVZ", "$,", "PPER", "VVFIN", "PPER", "ADJD", "$.", "PWS", "VMFIN", "PPER", "PRF", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Was klagst du \u00fcber mich? Was hebst du an zu schm\u00e4hlen?", "tokens": ["Was", "klagst", "du", "\u00fc\u00b7ber", "mich", "?", "Was", "hebst", "du", "an", "zu", "schm\u00e4h\u00b7len", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "APPR", "PPER", "$.", "PWS", "VVFIN", "PPER", "PTKVZ", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Was hat dein Diener Schuld, wenn Geist und Feder irrt,", "tokens": ["Was", "hat", "dein", "Die\u00b7ner", "Schuld", ",", "wenn", "Geist", "und", "Fe\u00b7der", "irrt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPOSAT", "NN", "NN", "$,", "KOUS", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Da\u00df ohngef\u00e4hr ein Reim ein wenig dunkel wird?", "tokens": ["Da\u00df", "ohn\u00b7ge\u00b7f\u00e4hr", "ein", "Reim", "ein", "we\u00b7nig", "dun\u00b7kel", "wird", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJD", "ART", "NN", "ART", "PIS", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Was hab ich wider Zucht und Ehrbarkeit verbrochen?", "tokens": ["Was", "hab", "ich", "wi\u00b7der", "Zucht", "und", "Ehr\u00b7bar\u00b7keit", "ver\u00b7bro\u00b7chen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "APPR", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Hab ich wohl je zu dir ein arges Wort gesprochen?", "tokens": ["Hab", "ich", "wohl", "je", "zu", "dir", "ein", "ar\u00b7ges", "Wort", "ge\u00b7spro\u00b7chen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "ADV", "APPR", "PPER", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "F\u00fcrwahr! ich schw\u00f6re drauf, seit dem du mich gekannt,", "tokens": ["F\u00fcr\u00b7wahr", "!", "ich", "schw\u00f6\u00b7re", "drauf", ",", "seit", "dem", "du", "mich", "ge\u00b7kannt", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "PPER", "VVFIN", "PTKVZ", "$,", "APPR", "PRELS", "PPER", "PRF", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Hast du mich selber wohl den Z\u00fcchtigen genannt.", "tokens": ["Hast", "du", "mich", "sel\u00b7ber", "wohl", "den", "Z\u00fcch\u00b7ti\u00b7gen", "ge\u00b7nannt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PRF", "ADV", "ADV", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "So lieblich du auch warst, hab ich mich doch beschieden,", "tokens": ["So", "lieb\u00b7lich", "du", "auch", "warst", ",", "hab", "ich", "mich", "doch", "be\u00b7schie\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "ADV", "VAFIN", "$,", "VAFIN", "PPER", "PRF", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Und allen freyen Scherz der jungen Welt gemieden:", "tokens": ["Und", "al\u00b7len", "frey\u00b7en", "Scherz", "der", "jun\u00b7gen", "Welt", "ge\u00b7mie\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "ADJA", "NN", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Und hab ich was versehn, so ist der Fehler klar,", "tokens": ["Und", "hab", "ich", "was", "ver\u00b7sehn", ",", "so", "ist", "der", "Feh\u00b7ler", "klar", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "PIS", "VVINF", "$,", "ADV", "VAFIN", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Da\u00df ich an deiner Hand fast gar zu bl\u00f6de war.", "tokens": ["Da\u00df", "ich", "an", "dei\u00b7ner", "Hand", "fast", "gar", "zu", "bl\u00f6\u00b7de", "war", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PPOSAT", "NN", "ADV", "ADV", "APPR", "ADJA", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Wie konntest du nun j\u00fcngst so scharf mit mir verfahren?", "tokens": ["Wie", "konn\u00b7test", "du", "nun", "j\u00fcngst", "so", "scharf", "mit", "mir", "ver\u00b7fah\u00b7ren", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "PPER", "ADV", "ADV", "ADV", "ADJD", "APPR", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Wie konntest du doch nicht Verweis und Eifer sparen?", "tokens": ["Wie", "konn\u00b7test", "du", "doch", "nicht", "Ver\u00b7weis", "und", "Ei\u00b7fer", "spa\u00b7ren", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "PPER", "ADV", "PTKNEG", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Wiewohl du z\u00fcrnst nicht mehr. Auch ich bin schon vers\u00f6hnt.", "tokens": ["Wie\u00b7wohl", "du", "z\u00fcrnst", "nicht", "mehr", ".", "Auch", "ich", "bin", "schon", "ver\u00b7s\u00f6hnt", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "PTKNEG", "ADV", "$.", "ADV", "PPER", "VAFIN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der Himmel hat bereits dein keusches Haupt gekr\u00f6nt.", "tokens": ["Der", "Him\u00b7mel", "hat", "be\u00b7reits", "dein", "keu\u00b7sches", "Haupt", "ge\u00b7kr\u00f6nt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "PPOSAT", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Dein ", "tokens": ["Dein"], "token_info": ["word"], "pos": ["PPOSAT"], "meter": "+", "measure": "single.up"}, "line.4": {"text": "Und schmecket auch bey dir die Kraft der ersten Liebe.", "tokens": ["Und", "schme\u00b7cket", "auch", "bey", "dir", "die", "Kraft", "der", "ers\u00b7ten", "Lie\u00b7be", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "APPR", "PPER", "ART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.5": {"text": "Was mir das Gl\u00fcck bestimmt, ist mir noch unbewu\u00dft:", "tokens": ["Was", "mir", "das", "Gl\u00fcck", "be\u00b7stimmt", ",", "ist", "mir", "noch", "un\u00b7be\u00b7wu\u00dft", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ART", "NN", "VVPP", "$,", "VAFIN", "PPER", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Man \u00e4rndtet nicht so bald des Ehstands reine Lust,", "tokens": ["Man", "\u00e4rnd\u00b7tet", "nicht", "so", "bald", "des", "Eh\u00b7stands", "rei\u00b7ne", "Lust", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PTKNEG", "ADV", "ADV", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Wenn uns ein fremdes Land die Staffeln zu dem Gl\u00fccke", "tokens": ["Wenn", "uns", "ein", "frem\u00b7des", "Land", "die", "Staf\u00b7feln", "zu", "dem", "Gl\u00fc\u00b7cke"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "ART", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Mit Noth betreten l\u00e4\u00dft. Man weiset uns zur\u00fccke.", "tokens": ["Mit", "Noth", "be\u00b7tre\u00b7ten", "l\u00e4\u00dft", ".", "Man", "wei\u00b7set", "uns", "zu\u00b7r\u00fc\u00b7cke", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVINF", "VVFIN", "$.", "PIS", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Die Kinder gehen vor; ein Fremder mag nur gehn,", "tokens": ["Die", "Kin\u00b7der", "ge\u00b7hen", "vor", ";", "ein", "Frem\u00b7der", "mag", "nur", "gehn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "$.", "ART", "NN", "VMFIN", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Und ewig in der Zahl der Exspectanten stehn.", "tokens": ["Und", "e\u00b7wig", "in", "der", "Zahl", "der", "Ex\u00b7spect\u00b7an\u00b7ten", "stehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "APPR", "ART", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Doch was? K\u00f6mmt Zeit, k\u00f6mmt Rath! Kann Gottsched noch nicht lieben:", "tokens": ["Doch", "was", "?", "K\u00f6mmt", "Zeit", ",", "k\u00f6mmt", "Rath", "!", "Kann", "Gott\u00b7sched", "noch", "nicht", "lie\u00b7ben", ":"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "$.", "NN", "NN", "$,", "VVFIN", "NN", "$.", "VMFIN", "NE", "ADV", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "So mag er sich inde\u00df in guten K\u00fcnsten \u00fcben.", "tokens": ["So", "mag", "er", "sich", "in\u00b7de\u00df", "in", "gu\u00b7ten", "K\u00fcns\u00b7ten", "\u00fc\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PRF", "ADV", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Hier dringt sich ein Geschenk zu deiner werthen Hand.", "tokens": ["Hier", "dringt", "sich", "ein", "Ge\u00b7schenk", "zu", "dei\u00b7ner", "wert\u00b7hen", "Hand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "ART", "NN", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wer weis, ob ich die Zeit nicht \u00fcbel angewandt;", "tokens": ["Wer", "weis", ",", "ob", "ich", "die", "Zeit", "nicht", "\u00fc\u00b7bel", "an\u00b7ge\u00b7wandt", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PTKVZ", "$,", "KOUS", "PPER", "ART", "NN", "PTKNEG", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ein seltsam Ketzerbuch im Deutschen auszudr\u00fccken?", "tokens": ["Ein", "selt\u00b7sam", "Ket\u00b7zer\u00b7buch", "im", "Deut\u00b7schen", "aus\u00b7zu\u00b7dr\u00fc\u00b7cken", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "APPRART", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wie gl\u00fccklich es geschehn, das wirst du selbst erblicken.", "tokens": ["Wie", "gl\u00fcck\u00b7lich", "es", "ge\u00b7schehn", ",", "das", "wirst", "du", "selbst", "er\u00b7bli\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "PPER", "VVPP", "$,", "PDS", "VAFIN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Allein entdecke mirs, wenn das, was ich gesetzt,", "tokens": ["Al\u00b7lein", "ent\u00b7de\u00b7cke", "mirs", ",", "wenn", "das", ",", "was", "ich", "ge\u00b7setzt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NE", "$,", "KOUS", "PDS", "$,", "PWS", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Durch seinen Uebelklang dein zartes Ohr verletzt.", "tokens": ["Durch", "sei\u00b7nen", "Ue\u00b7bel\u00b7klang", "dein", "zar\u00b7tes", "Ohr", "ver\u00b7letzt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PPOSAT", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Verh\u00f6hle mir nur nichts, vergi\u00df die Kunst zu loben;", "tokens": ["Ver\u00b7h\u00f6h\u00b7le", "mir", "nur", "nichts", ",", "ver\u00b7gi\u00df", "die", "Kunst", "zu", "lo\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "PIS", "$,", "VVIMP", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Ich hab es dir nur blo\u00df zum pr\u00fcfen aufgehoben.", "tokens": ["Ich", "hab", "es", "dir", "nur", "blo\u00df", "zum", "pr\u00fc\u00b7fen", "auf\u00b7ge\u00b7ho\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "PPER", "ADV", "ADV", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Noch liegt ein schlechter Vers von meiner Art dabey:", "tokens": ["Noch", "liegt", "ein", "schlech\u00b7ter", "Vers", "von", "mei\u00b7ner", "Art", "da\u00b7bey", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "PAV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Er\u00f6ffne mir zugleich, was dessen Fehler sey.", "tokens": ["Er\u00b7\u00f6ff\u00b7ne", "mir", "zu\u00b7gleich", ",", "was", "des\u00b7sen", "Feh\u00b7ler", "sey", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "$,", "PWS", "PDS", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Mein Freund, den du begr\u00fc\u00dft, empfiehlt sich deiner G\u00fcte,", "tokens": ["Mein", "Freund", ",", "den", "du", "be\u00b7gr\u00fc\u00dft", ",", "emp\u00b7fiehlt", "sich", "dei\u00b7ner", "G\u00fc\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PRELS", "PPER", "VVPP", "$,", "VVFIN", "PRF", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und hat noch, wie zuvor sein ehrliches Gem\u00fcthe.", "tokens": ["Und", "hat", "noch", ",", "wie", "zu\u00b7vor", "sein", "ehr\u00b7li\u00b7ches", "Ge\u00b7m\u00fc\u00b7the", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "$,", "PWAV", "ADV", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Er liebet noch, wie wir, die edle Poesie;", "tokens": ["Er", "lie\u00b7bet", "noch", ",", "wie", "wir", ",", "die", "ed\u00b7le", "Poe\u00b7sie", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "PWAV", "PPER", "$,", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Verlangst du den Beweis, wohlan, sein Blatt ist hie.", "tokens": ["Ver\u00b7langst", "du", "den", "Be\u00b7weis", ",", "wo\u00b7hlan", ",", "sein", "Blatt", "ist", "hie", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "$,", "PWAV", "$,", "PPOSAT", "NN", "VAFIN", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Ich gr\u00fcsse deinen Schatz, und willst du mich verbinden,", "tokens": ["Ich", "gr\u00fcs\u00b7se", "dei\u00b7nen", "Schatz", ",", "und", "willst", "du", "mich", "ver\u00b7bin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "$,", "KON", "VMFIN", "PPER", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "So schreibe mir nur bald von deinem Wohlbefinden.", "tokens": ["So", "schrei\u00b7be", "mir", "nur", "bald", "von", "dei\u00b7nem", "Wohl\u00b7be\u00b7fin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Hat neulich lauter Stolz in meiner Brust emp\u00f6rt.", "tokens": ["Hat", "neu\u00b7lich", "lau\u00b7ter", "Stolz", "in", "mei\u00b7ner", "Brust", "em\u00b7p\u00f6rt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PIAT", "NN", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wie trotzte nicht mein Herz, als ich dein Blatt gelesen?", "tokens": ["Wie", "trotz\u00b7te", "nicht", "mein", "Herz", ",", "als", "ich", "dein", "Blatt", "ge\u00b7le\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PTKNEG", "PPOSAT", "NN", "$,", "KOUS", "PPER", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ich bin ja, sprach der Mund, was ", "tokens": ["Ich", "bin", "ja", ",", "sprach", "der", "Mund", ",", "was"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["PPER", "VAFIN", "ADV", "$,", "VVFIN", "ART", "NN", "$,", "PWS"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Ich bin, was ", "tokens": ["Ich", "bin", ",", "was"], "token_info": ["word", "word", "punct", "word"], "pos": ["PPER", "VAFIN", "$,", "PWS"], "meter": "-+-", "measure": "amphibrach.single"}, "line.5": {"text": "Ja, Gottsched steht nun auch in jener Dichter Schaar,", "tokens": ["Ja", ",", "Gott\u00b7sched", "steht", "nun", "auch", "in", "je\u00b7ner", "Dich\u00b7ter", "Schaar", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "NE", "VVFIN", "ADV", "ADV", "APPR", "PDAT", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Dadurch sich Deutschlands Ruhm so hoch empor geschwungen,", "tokens": ["Da\u00b7durch", "sich", "Deutschlands", "Ruhm", "so", "hoch", "em\u00b7por", "ge\u00b7schwun\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PRF", "NE", "NN", "ADV", "ADJD", "PTKVZ", "VVPP", "$,"], "meter": "--+-+-+-+-+-", "measure": "anapaest.init"}, "line.7": {"text": "Wenn sie Athen und Rom den Vorzug abgesungen.", "tokens": ["Wenn", "sie", "A\u00b7then", "und", "Rom", "den", "Vor\u00b7zug", "ab\u00b7ge\u00b7sun\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NE", "KON", "NE", "ART", "NN", "VVPP", "$."], "meter": "+-+--+-+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.8": {"text": "Hier hat kein Zweifel statt. ", "tokens": ["Hier", "hat", "kein", "Zwei\u00b7fel", "statt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "Und selbst so herrlich singt, von ", "tokens": ["Und", "selbst", "so", "herr\u00b7lich", "singt", ",", "von"], "token_info": ["word", "word", "word", "word", "word", "punct", "word"], "pos": ["KON", "ADV", "ADV", "ADJD", "VVFIN", "$,", "APPR"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.10": {"text": "Der Musen Schwester ist, vergleicht ja deine Fr\u00fcchte", "tokens": ["Der", "Mu\u00b7sen", "Schwes\u00b7ter", "ist", ",", "ver\u00b7gleicht", "ja", "dei\u00b7ne", "Fr\u00fcch\u00b7te"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "NN", "VAFIN", "$,", "VVFIN", "ADV", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Mit der Vollkommenheit der herrlichsten Gedichte.", "tokens": ["Mit", "der", "Voll\u00b7kom\u00b7men\u00b7heit", "der", "herr\u00b7lichs\u00b7ten", "Ge\u00b7dich\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+---+-", "measure": "unknown.measure.penta"}}, "stanza.8": {"line.1": {"text": "Die Nase hub sich schon; ich trug des Haupt empor.", "tokens": ["Die", "Na\u00b7se", "hub", "sich", "schon", ";", "ich", "trug", "des", "Haupt", "em\u00b7por", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PRF", "ADV", "$.", "PPER", "VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Inde\u00df kam die Vernunft, und sagte mir ins Ohr:", "tokens": ["In\u00b7de\u00df", "kam", "die", "Ver\u00b7nunft", ",", "und", "sag\u00b7te", "mir", "ins", "Ohr", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ART", "NN", "$,", "KON", "VVFIN", "PPER", "APPRART", "NN", "$."], "meter": "--+--+-+-+-+", "measure": "anapaest.di.plus"}, "line.3": {"text": "Gemach, betrogner Geist! du must dich besser kennen,", "tokens": ["Ge\u00b7mach", ",", "be\u00b7trog\u00b7ner", "Geist", "!", "du", "must", "dich", "bes\u00b7ser", "ken\u00b7nen", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "ADJA", "NN", "$.", "PPER", "VMFIN", "PRF", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Als Schm\u00e4uchler, die zum Scherz dich einen Dichter nennen.", "tokens": ["Als", "Schm\u00e4uch\u00b7ler", ",", "die", "zum", "Scherz", "dich", "ei\u00b7nen", "Dich\u00b7ter", "nen\u00b7nen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "$,", "PRELS", "APPRART", "NN", "PPER", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wie sonst ein steiles Rohr den schwachen Nacken neigt,", "tokens": ["Wie", "sonst", "ein", "stei\u00b7les", "Rohr", "den", "schwa\u00b7chen", "Na\u00b7cken", "neigt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "ART", "ADJA", "NN", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wenn die bewegte Luft den stolzen Gipfel beugt", "tokens": ["Wenn", "die", "be\u00b7weg\u00b7te", "Luft", "den", "stol\u00b7zen", "Gip\u00b7fel", "beugt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "NN", "ART", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und ihn zur Erden dr\u00fcckt: so schlug die\u00df Wort mich nieder,", "tokens": ["Und", "ihn", "zur", "Er\u00b7den", "dr\u00fcckt", ":", "so", "schlug", "die\u00df", "Wort", "mich", "nie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "APPRART", "NN", "VVFIN", "$.", "ADV", "VVFIN", "PDS", "NN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und meine Eitelkeit verschwand allm\u00e4hlich wieder.", "tokens": ["Und", "mei\u00b7ne", "Ei\u00b7tel\u00b7keit", "ver\u00b7schwand", "all\u00b7m\u00e4h\u00b7lich", "wie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "ADJD", "ADV", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Nur eins, o Dichterinn! hat mich bisher gereut,", "tokens": ["Nur", "eins", ",", "o", "Dich\u00b7te\u00b7rinn", "!", "hat", "mich", "bis\u00b7her", "ge\u00b7reut", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "$,", "FM", "NN", "$.", "VAFIN", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Da\u00df meines letzten Reims verw\u00fcnschte Dunkelheit", "tokens": ["Da\u00df", "mei\u00b7nes", "letz\u00b7ten", "Reims", "ver\u00b7w\u00fcnschte", "Dun\u00b7kel\u00b7heit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPOSAT", "ADJA", "NN", "ADJA", "NN"], "meter": "-+-+-+-++-+", "measure": "unknown.measure.hexa"}, "line.3": {"text": "Dir den Verdacht erweckt, als h\u00e4tt ich mich vergessen,", "tokens": ["Dir", "den", "Ver\u00b7dacht", "er\u00b7weckt", ",", "als", "h\u00e4tt", "ich", "mich", "ver\u00b7ges\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "VVPP", "$,", "KOKOM", "VAFIN", "PPER", "PRF", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und dir, zur Ungeb\u00fchr, ein Laster beygemessen;", "tokens": ["Und", "dir", ",", "zur", "Un\u00b7ge\u00b7b\u00fchr", ",", "ein", "Las\u00b7ter", "bey\u00b7ge\u00b7mes\u00b7sen", ";"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "$,", "APPRART", "NN", "$,", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ein Laster, dessen Spur ich nie an dir gesehn,", "tokens": ["Ein", "Las\u00b7ter", ",", "des\u00b7sen", "Spur", "ich", "nie", "an", "dir", "ge\u00b7sehn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELAT", "NN", "PPER", "ADV", "APPR", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Das du so sehr geha\u00dft, als selten wo geschehn:", "tokens": ["Das", "du", "so", "sehr", "ge\u00b7ha\u00dft", ",", "als", "sel\u00b7ten", "wo", "ge\u00b7schehn", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "ADV", "VVPP", "$,", "KOUS", "ADJA", "PWAV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Indem du stets geglaubt, der Musen keuscher Orden", "tokens": ["In\u00b7dem", "du", "stets", "ge\u00b7glaubt", ",", "der", "Mu\u00b7sen", "keu\u00b7scher", "Or\u00b7den"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "VVPP", "$,", "ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Sey niemals der Gewalt der Liebe zinsbar worden.", "tokens": ["Sey", "nie\u00b7mals", "der", "Ge\u00b7walt", "der", "Lie\u00b7be", "zins\u00b7bar", "wor\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "ART", "NN", "ADJD", "VAPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Nein, Werthe! glaub es nicht. So sehr es dir auch scheint,", "tokens": ["Nein", ",", "Wert\u00b7he", "!", "glaub", "es", "nicht", ".", "So", "sehr", "es", "dir", "auch", "scheint", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "NN", "$.", "VVFIN", "PPER", "PTKNEG", "$.", "ADV", "ADV", "PPER", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "So wenig hat dein Knecht es neulich so gemeynt.", "tokens": ["So", "we\u00b7nig", "hat", "dein", "Knecht", "es", "neu\u00b7lich", "so", "ge\u00b7meynt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VAFIN", "PPOSAT", "NN", "PPER", "ADV", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Sprich selber, kann ein Vers nicht ohne Schuld entz\u00fccken?", "tokens": ["Sprich", "sel\u00b7ber", ",", "kann", "ein", "Vers", "nicht", "oh\u00b7ne", "Schuld", "ent\u00b7z\u00fc\u00b7cken", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ADV", "$,", "VMFIN", "ART", "NN", "PTKNEG", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Kann ", "tokens": ["Kann"], "token_info": ["word"], "pos": ["VMFIN"], "meter": "+", "measure": "single.up"}, "line.13": {"text": "Und nimmt die Poesie nicht tausend Herzen ein,", "tokens": ["Und", "nimmt", "die", "Poe\u00b7sie", "nicht", "tau\u00b7send", "Her\u00b7zen", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "PTKNEG", "CARD", "NN", "PTKVZ", "$,"], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.14": {"text": "Die gleichwohl nicht verliebt, viel minder unkeusch seyn?", "tokens": ["Die", "gleich\u00b7wohl", "nicht", "ver\u00b7liebt", ",", "viel", "min\u00b7der", "un\u00b7keusch", "seyn", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "PTKNEG", "VVPP", "$,", "ADV", "ADV", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Ich weis, du giebst mir recht; was willst du mich denn qu\u00e4len?", "tokens": ["Ich", "weis", ",", "du", "giebst", "mir", "recht", ";", "was", "willst", "du", "mich", "denn", "qu\u00e4\u00b7len", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKVZ", "$,", "PPER", "VVFIN", "PPER", "ADJD", "$.", "PWS", "VMFIN", "PPER", "PRF", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Was klagst du \u00fcber mich? Was hebst du an zu schm\u00e4hlen?", "tokens": ["Was", "klagst", "du", "\u00fc\u00b7ber", "mich", "?", "Was", "hebst", "du", "an", "zu", "schm\u00e4h\u00b7len", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "APPR", "PPER", "$.", "PWS", "VVFIN", "PPER", "PTKVZ", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Was hat dein Diener Schuld, wenn Geist und Feder irrt,", "tokens": ["Was", "hat", "dein", "Die\u00b7ner", "Schuld", ",", "wenn", "Geist", "und", "Fe\u00b7der", "irrt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPOSAT", "NN", "NN", "$,", "KOUS", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Da\u00df ohngef\u00e4hr ein Reim ein wenig dunkel wird?", "tokens": ["Da\u00df", "ohn\u00b7ge\u00b7f\u00e4hr", "ein", "Reim", "ein", "we\u00b7nig", "dun\u00b7kel", "wird", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJD", "ART", "NN", "ART", "PIS", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Was hab ich wider Zucht und Ehrbarkeit verbrochen?", "tokens": ["Was", "hab", "ich", "wi\u00b7der", "Zucht", "und", "Ehr\u00b7bar\u00b7keit", "ver\u00b7bro\u00b7chen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "APPR", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Hab ich wohl je zu dir ein arges Wort gesprochen?", "tokens": ["Hab", "ich", "wohl", "je", "zu", "dir", "ein", "ar\u00b7ges", "Wort", "ge\u00b7spro\u00b7chen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "ADV", "APPR", "PPER", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "F\u00fcrwahr! ich schw\u00f6re drauf, seit dem du mich gekannt,", "tokens": ["F\u00fcr\u00b7wahr", "!", "ich", "schw\u00f6\u00b7re", "drauf", ",", "seit", "dem", "du", "mich", "ge\u00b7kannt", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "PPER", "VVFIN", "PTKVZ", "$,", "APPR", "PRELS", "PPER", "PRF", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Hast du mich selber wohl den Z\u00fcchtigen genannt.", "tokens": ["Hast", "du", "mich", "sel\u00b7ber", "wohl", "den", "Z\u00fcch\u00b7ti\u00b7gen", "ge\u00b7nannt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PRF", "ADV", "ADV", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "So lieblich du auch warst, hab ich mich doch beschieden,", "tokens": ["So", "lieb\u00b7lich", "du", "auch", "warst", ",", "hab", "ich", "mich", "doch", "be\u00b7schie\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "ADV", "VAFIN", "$,", "VAFIN", "PPER", "PRF", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Und allen freyen Scherz der jungen Welt gemieden:", "tokens": ["Und", "al\u00b7len", "frey\u00b7en", "Scherz", "der", "jun\u00b7gen", "Welt", "ge\u00b7mie\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "ADJA", "NN", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Und hab ich was versehn, so ist der Fehler klar,", "tokens": ["Und", "hab", "ich", "was", "ver\u00b7sehn", ",", "so", "ist", "der", "Feh\u00b7ler", "klar", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "PIS", "VVINF", "$,", "ADV", "VAFIN", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Da\u00df ich an deiner Hand fast gar zu bl\u00f6de war.", "tokens": ["Da\u00df", "ich", "an", "dei\u00b7ner", "Hand", "fast", "gar", "zu", "bl\u00f6\u00b7de", "war", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PPOSAT", "NN", "ADV", "ADV", "APPR", "ADJA", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Wie konntest du nun j\u00fcngst so scharf mit mir verfahren?", "tokens": ["Wie", "konn\u00b7test", "du", "nun", "j\u00fcngst", "so", "scharf", "mit", "mir", "ver\u00b7fah\u00b7ren", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "PPER", "ADV", "ADV", "ADV", "ADJD", "APPR", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Wie konntest du doch nicht Verweis und Eifer sparen?", "tokens": ["Wie", "konn\u00b7test", "du", "doch", "nicht", "Ver\u00b7weis", "und", "Ei\u00b7fer", "spa\u00b7ren", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "PPER", "ADV", "PTKNEG", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.10": {"line.1": {"text": "Wiewohl du z\u00fcrnst nicht mehr. Auch ich bin schon vers\u00f6hnt.", "tokens": ["Wie\u00b7wohl", "du", "z\u00fcrnst", "nicht", "mehr", ".", "Auch", "ich", "bin", "schon", "ver\u00b7s\u00f6hnt", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "PTKNEG", "ADV", "$.", "ADV", "PPER", "VAFIN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der Himmel hat bereits dein keusches Haupt gekr\u00f6nt.", "tokens": ["Der", "Him\u00b7mel", "hat", "be\u00b7reits", "dein", "keu\u00b7sches", "Haupt", "ge\u00b7kr\u00f6nt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "PPOSAT", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Dein ", "tokens": ["Dein"], "token_info": ["word"], "pos": ["PPOSAT"], "meter": "+", "measure": "single.up"}, "line.4": {"text": "Und schmecket auch bey dir die Kraft der ersten Liebe.", "tokens": ["Und", "schme\u00b7cket", "auch", "bey", "dir", "die", "Kraft", "der", "ers\u00b7ten", "Lie\u00b7be", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "APPR", "PPER", "ART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.5": {"text": "Was mir das Gl\u00fcck bestimmt, ist mir noch unbewu\u00dft:", "tokens": ["Was", "mir", "das", "Gl\u00fcck", "be\u00b7stimmt", ",", "ist", "mir", "noch", "un\u00b7be\u00b7wu\u00dft", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ART", "NN", "VVPP", "$,", "VAFIN", "PPER", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Man \u00e4rndtet nicht so bald des Ehstands reine Lust,", "tokens": ["Man", "\u00e4rnd\u00b7tet", "nicht", "so", "bald", "des", "Eh\u00b7stands", "rei\u00b7ne", "Lust", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PTKNEG", "ADV", "ADV", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Wenn uns ein fremdes Land die Staffeln zu dem Gl\u00fccke", "tokens": ["Wenn", "uns", "ein", "frem\u00b7des", "Land", "die", "Staf\u00b7feln", "zu", "dem", "Gl\u00fc\u00b7cke"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "ART", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Mit Noth betreten l\u00e4\u00dft. Man weiset uns zur\u00fccke.", "tokens": ["Mit", "Noth", "be\u00b7tre\u00b7ten", "l\u00e4\u00dft", ".", "Man", "wei\u00b7set", "uns", "zu\u00b7r\u00fc\u00b7cke", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVINF", "VVFIN", "$.", "PIS", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Die Kinder gehen vor; ein Fremder mag nur gehn,", "tokens": ["Die", "Kin\u00b7der", "ge\u00b7hen", "vor", ";", "ein", "Frem\u00b7der", "mag", "nur", "gehn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "$.", "ART", "NN", "VMFIN", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Und ewig in der Zahl der Exspectanten stehn.", "tokens": ["Und", "e\u00b7wig", "in", "der", "Zahl", "der", "Ex\u00b7spect\u00b7an\u00b7ten", "stehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "APPR", "ART", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Doch was? K\u00f6mmt Zeit, k\u00f6mmt Rath! Kann Gottsched noch nicht lieben:", "tokens": ["Doch", "was", "?", "K\u00f6mmt", "Zeit", ",", "k\u00f6mmt", "Rath", "!", "Kann", "Gott\u00b7sched", "noch", "nicht", "lie\u00b7ben", ":"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "$.", "NN", "NN", "$,", "VVFIN", "NN", "$.", "VMFIN", "NE", "ADV", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "So mag er sich inde\u00df in guten K\u00fcnsten \u00fcben.", "tokens": ["So", "mag", "er", "sich", "in\u00b7de\u00df", "in", "gu\u00b7ten", "K\u00fcns\u00b7ten", "\u00fc\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PRF", "ADV", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.11": {"line.1": {"text": "Hier dringt sich ein Geschenk zu deiner werthen Hand.", "tokens": ["Hier", "dringt", "sich", "ein", "Ge\u00b7schenk", "zu", "dei\u00b7ner", "wert\u00b7hen", "Hand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "ART", "NN", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wer weis, ob ich die Zeit nicht \u00fcbel angewandt;", "tokens": ["Wer", "weis", ",", "ob", "ich", "die", "Zeit", "nicht", "\u00fc\u00b7bel", "an\u00b7ge\u00b7wandt", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PTKVZ", "$,", "KOUS", "PPER", "ART", "NN", "PTKNEG", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ein seltsam Ketzerbuch im Deutschen auszudr\u00fccken?", "tokens": ["Ein", "selt\u00b7sam", "Ket\u00b7zer\u00b7buch", "im", "Deut\u00b7schen", "aus\u00b7zu\u00b7dr\u00fc\u00b7cken", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "APPRART", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wie gl\u00fccklich es geschehn, das wirst du selbst erblicken.", "tokens": ["Wie", "gl\u00fcck\u00b7lich", "es", "ge\u00b7schehn", ",", "das", "wirst", "du", "selbst", "er\u00b7bli\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "PPER", "VVPP", "$,", "PDS", "VAFIN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Allein entdecke mirs, wenn das, was ich gesetzt,", "tokens": ["Al\u00b7lein", "ent\u00b7de\u00b7cke", "mirs", ",", "wenn", "das", ",", "was", "ich", "ge\u00b7setzt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NE", "$,", "KOUS", "PDS", "$,", "PWS", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Durch seinen Uebelklang dein zartes Ohr verletzt.", "tokens": ["Durch", "sei\u00b7nen", "Ue\u00b7bel\u00b7klang", "dein", "zar\u00b7tes", "Ohr", "ver\u00b7letzt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PPOSAT", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Verh\u00f6hle mir nur nichts, vergi\u00df die Kunst zu loben;", "tokens": ["Ver\u00b7h\u00f6h\u00b7le", "mir", "nur", "nichts", ",", "ver\u00b7gi\u00df", "die", "Kunst", "zu", "lo\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "PIS", "$,", "VVIMP", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Ich hab es dir nur blo\u00df zum pr\u00fcfen aufgehoben.", "tokens": ["Ich", "hab", "es", "dir", "nur", "blo\u00df", "zum", "pr\u00fc\u00b7fen", "auf\u00b7ge\u00b7ho\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "PPER", "ADV", "ADV", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.12": {"line.1": {"text": "Noch liegt ein schlechter Vers von meiner Art dabey:", "tokens": ["Noch", "liegt", "ein", "schlech\u00b7ter", "Vers", "von", "mei\u00b7ner", "Art", "da\u00b7bey", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "PAV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Er\u00f6ffne mir zugleich, was dessen Fehler sey.", "tokens": ["Er\u00b7\u00f6ff\u00b7ne", "mir", "zu\u00b7gleich", ",", "was", "des\u00b7sen", "Feh\u00b7ler", "sey", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "$,", "PWS", "PDS", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Mein Freund, den du begr\u00fc\u00dft, empfiehlt sich deiner G\u00fcte,", "tokens": ["Mein", "Freund", ",", "den", "du", "be\u00b7gr\u00fc\u00dft", ",", "emp\u00b7fiehlt", "sich", "dei\u00b7ner", "G\u00fc\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PRELS", "PPER", "VVPP", "$,", "VVFIN", "PRF", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und hat noch, wie zuvor sein ehrliches Gem\u00fcthe.", "tokens": ["Und", "hat", "noch", ",", "wie", "zu\u00b7vor", "sein", "ehr\u00b7li\u00b7ches", "Ge\u00b7m\u00fc\u00b7the", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "$,", "PWAV", "ADV", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Er liebet noch, wie wir, die edle Poesie;", "tokens": ["Er", "lie\u00b7bet", "noch", ",", "wie", "wir", ",", "die", "ed\u00b7le", "Poe\u00b7sie", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "PWAV", "PPER", "$,", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Verlangst du den Beweis, wohlan, sein Blatt ist hie.", "tokens": ["Ver\u00b7langst", "du", "den", "Be\u00b7weis", ",", "wo\u00b7hlan", ",", "sein", "Blatt", "ist", "hie", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "$,", "PWAV", "$,", "PPOSAT", "NN", "VAFIN", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Ich gr\u00fcsse deinen Schatz, und willst du mich verbinden,", "tokens": ["Ich", "gr\u00fcs\u00b7se", "dei\u00b7nen", "Schatz", ",", "und", "willst", "du", "mich", "ver\u00b7bin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "$,", "KON", "VMFIN", "PPER", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "So schreibe mir nur bald von deinem Wohlbefinden.", "tokens": ["So", "schrei\u00b7be", "mir", "nur", "bald", "von", "dei\u00b7nem", "Wohl\u00b7be\u00b7fin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}