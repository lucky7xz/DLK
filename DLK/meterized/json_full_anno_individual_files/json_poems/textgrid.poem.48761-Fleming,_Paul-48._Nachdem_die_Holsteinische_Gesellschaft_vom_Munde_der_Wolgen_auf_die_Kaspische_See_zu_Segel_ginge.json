{"textgrid.poem.48761": {"metadata": {"author": {"name": "Fleming, Paul", "birth": "N.A.", "death": "N.A."}, "title": "48. Nachdem die Holsteinische Gesellschaft vom Munde der Wolgen auf die Kaspische See zu Segel ginge", "genre": "verse", "period": "N.A.", "pub_year": 1624, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ihr Nymfen auf der ", "tokens": ["Ihr", "Nym\u00b7fen", "auf", "der"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "APPR", "ART"], "meter": "-+-+-", "measure": "iambic.di"}, "line.2": {"text": "des salzichten Hyrkans, dem ihr durch manchen Ku\u00df", "tokens": ["des", "sal\u00b7zich\u00b7ten", "Hyr\u00b7kans", ",", "dem", "ihr", "durch", "man\u00b7chen", "Ku\u00df"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "PRELS", "PPER", "APPR", "PIAT", "NN"], "meter": "--+--+-+-+-+", "measure": "anapaest.di.plus"}, "line.3": {"text": "aus so viel M\u00fcnden hier entbietet euren Gru\u00df,", "tokens": ["aus", "so", "viel", "M\u00fcn\u00b7den", "hier", "ent\u00b7bie\u00b7tet", "eu\u00b7ren", "Gru\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "PIAT", "NN", "ADV", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.4": {"text": "habt Dank f\u00fcr euren Schutz, ihr edlen Rutheninnen,", "tokens": ["habt", "Dank", "f\u00fcr", "eu\u00b7ren", "Schutz", ",", "ihr", "ed\u00b7len", "Ru\u00b7then\u00b7in\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "APPR", "PPOSAT", "NN", "$,", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "den ihr uns nun so weit und fast von euren Br\u00fcnnen", "tokens": ["den", "ihr", "uns", "nun", "so", "weit", "und", "fast", "von", "eu\u00b7ren", "Br\u00fcn\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "PRF", "ADV", "ADV", "ADJD", "KON", "ADV", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "bis hieher habt getan, und du auch, teurer Flu\u00df,", "tokens": ["bis", "hie\u00b7her", "habt", "ge\u00b7tan", ",", "und", "du", "auch", ",", "teu\u00b7rer", "Flu\u00df", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PAV", "VAFIN", "VVPP", "$,", "KON", "PPER", "ADV", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "dem unser ", "tokens": ["dem", "un\u00b7ser"], "token_info": ["word", "word"], "pos": ["ART", "PPOSAT"], "meter": "-+-", "measure": "amphibrach.single"}, "line.4": {"text": "nim, was die ", "tokens": ["nim", ",", "was", "die"], "token_info": ["word", "punct", "word", "word"], "pos": ["PTKVZ", "$,", "PRELS", "ART"], "meter": "+--", "measure": "dactylic.init"}}, "stanza.3": {"line.1": {"text": "Hier, da der geile Pan die Syrinx noch umgreift,", "tokens": ["Hier", ",", "da", "der", "gei\u00b7le", "Pan", "die", "Sy\u00b7rinx", "noch", "um\u00b7greift", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "ART", "ADJA", "NN", "ART", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "da der und der Silen nach mancher Bulschaft pfeift", "tokens": ["da", "der", "und", "der", "Si\u00b7len", "nach", "man\u00b7cher", "Bul\u00b7schaft", "pfeift"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "KON", "ART", "NN", "APPR", "PIAT", "NN", "VVFIN"], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "durch Rohr und holen Schilf, da m\u00fcssen wir uns wenden.", "tokens": ["durch", "Rohr", "und", "ho\u00b7len", "Schilf", ",", "da", "m\u00fcs\u00b7sen", "wir", "uns", "wen\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "VVFIN", "NE", "$,", "KOUS", "VMFIN", "PPER", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Bringt Doris, die ihr ehrt und gro\u00dfe Mutter nennt,", "tokens": ["Bringt", "Do\u00b7ris", ",", "die", "ihr", "ehrt", "und", "gro\u00b7\u00dfe", "Mut\u00b7ter", "nennt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "$,", "PRELS", "PPER", "VVFIN", "KON", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "wie sie uns hinschwimmt vor, so wieder vor ", "tokens": ["wie", "sie", "uns", "hin\u00b7schwimmt", "vor", ",", "so", "wie\u00b7der", "vor"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWAV", "PPER", "PPER", "VVFIN", "PTKVZ", "$,", "ADV", "ADV", "APPR"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "so sollt ihr unsern Dank auch tragen weg mit H\u00e4nden.", "tokens": ["so", "sollt", "ihr", "un\u00b7sern", "Dank", "auch", "tra\u00b7gen", "weg", "mit", "H\u00e4n\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PPOSAT", "NN", "ADV", "VVFIN", "ADV", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Ihr Nymfen auf der ", "tokens": ["Ihr", "Nym\u00b7fen", "auf", "der"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "APPR", "ART"], "meter": "-+-+-", "measure": "iambic.di"}, "line.2": {"text": "des salzichten Hyrkans, dem ihr durch manchen Ku\u00df", "tokens": ["des", "sal\u00b7zich\u00b7ten", "Hyr\u00b7kans", ",", "dem", "ihr", "durch", "man\u00b7chen", "Ku\u00df"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "PRELS", "PPER", "APPR", "PIAT", "NN"], "meter": "--+--+-+-+-+", "measure": "anapaest.di.plus"}, "line.3": {"text": "aus so viel M\u00fcnden hier entbietet euren Gru\u00df,", "tokens": ["aus", "so", "viel", "M\u00fcn\u00b7den", "hier", "ent\u00b7bie\u00b7tet", "eu\u00b7ren", "Gru\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "PIAT", "NN", "ADV", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.4": {"text": "habt Dank f\u00fcr euren Schutz, ihr edlen Rutheninnen,", "tokens": ["habt", "Dank", "f\u00fcr", "eu\u00b7ren", "Schutz", ",", "ihr", "ed\u00b7len", "Ru\u00b7then\u00b7in\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "APPR", "PPOSAT", "NN", "$,", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "den ihr uns nun so weit und fast von euren Br\u00fcnnen", "tokens": ["den", "ihr", "uns", "nun", "so", "weit", "und", "fast", "von", "eu\u00b7ren", "Br\u00fcn\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "PRF", "ADV", "ADV", "ADJD", "KON", "ADV", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "bis hieher habt getan, und du auch, teurer Flu\u00df,", "tokens": ["bis", "hie\u00b7her", "habt", "ge\u00b7tan", ",", "und", "du", "auch", ",", "teu\u00b7rer", "Flu\u00df", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PAV", "VAFIN", "VVPP", "$,", "KON", "PPER", "ADV", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "dem unser ", "tokens": ["dem", "un\u00b7ser"], "token_info": ["word", "word"], "pos": ["ART", "PPOSAT"], "meter": "-+-", "measure": "amphibrach.single"}, "line.4": {"text": "nim, was die ", "tokens": ["nim", ",", "was", "die"], "token_info": ["word", "punct", "word", "word"], "pos": ["PTKVZ", "$,", "PRELS", "ART"], "meter": "+--", "measure": "dactylic.init"}}, "stanza.7": {"line.1": {"text": "Hier, da der geile Pan die Syrinx noch umgreift,", "tokens": ["Hier", ",", "da", "der", "gei\u00b7le", "Pan", "die", "Sy\u00b7rinx", "noch", "um\u00b7greift", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "ART", "ADJA", "NN", "ART", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "da der und der Silen nach mancher Bulschaft pfeift", "tokens": ["da", "der", "und", "der", "Si\u00b7len", "nach", "man\u00b7cher", "Bul\u00b7schaft", "pfeift"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "KON", "ART", "NN", "APPR", "PIAT", "NN", "VVFIN"], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "durch Rohr und holen Schilf, da m\u00fcssen wir uns wenden.", "tokens": ["durch", "Rohr", "und", "ho\u00b7len", "Schilf", ",", "da", "m\u00fcs\u00b7sen", "wir", "uns", "wen\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "VVFIN", "NE", "$,", "KOUS", "VMFIN", "PPER", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "Bringt Doris, die ihr ehrt und gro\u00dfe Mutter nennt,", "tokens": ["Bringt", "Do\u00b7ris", ",", "die", "ihr", "ehrt", "und", "gro\u00b7\u00dfe", "Mut\u00b7ter", "nennt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "$,", "PRELS", "PPER", "VVFIN", "KON", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "wie sie uns hinschwimmt vor, so wieder vor ", "tokens": ["wie", "sie", "uns", "hin\u00b7schwimmt", "vor", ",", "so", "wie\u00b7der", "vor"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWAV", "PPER", "PPER", "VVFIN", "PTKVZ", "$,", "ADV", "ADV", "APPR"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "so sollt ihr unsern Dank auch tragen weg mit H\u00e4nden.", "tokens": ["so", "sollt", "ihr", "un\u00b7sern", "Dank", "auch", "tra\u00b7gen", "weg", "mit", "H\u00e4n\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PPOSAT", "NN", "ADV", "VVFIN", "ADV", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}