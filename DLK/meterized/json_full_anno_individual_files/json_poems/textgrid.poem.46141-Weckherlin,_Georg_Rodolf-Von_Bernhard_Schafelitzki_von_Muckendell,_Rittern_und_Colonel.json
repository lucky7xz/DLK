{"textgrid.poem.46141": {"metadata": {"author": {"name": "Weckherlin, Georg Rodolf", "birth": "N.A.", "death": "N.A."}, "title": "Von Bernhard Schafelitzki von Muckendell, Rittern und Colonel", "genre": "verse", "period": "N.A.", "pub_year": 1618, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Sing fort mein mund und schweig nicht still,", "tokens": ["Sing", "fort", "mein", "mund", "und", "schweig", "nicht", "still", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "PPOSAT", "NN", "KON", "VVFIN", "PTKNEG", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "damit ich mein gel\u00fcbd erf\u00fcll", "tokens": ["da\u00b7mit", "ich", "mein", "ge\u00b7l\u00fcbd", "er\u00b7f\u00fcll"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "und sing des jungen helden namen,", "tokens": ["und", "sing", "des", "jun\u00b7gen", "hel\u00b7den", "na\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "der durch manch k\u00fchne ritters that", "tokens": ["der", "durch", "manch", "k\u00fch\u00b7ne", "rit\u00b7ters", "that"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "PIAT", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "der faust schon oft bezeuget hat,", "tokens": ["der", "faust", "schon", "oft", "be\u00b7zeu\u00b7get", "hat", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ADV", "VVFIN", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "da\u00df er von der halbg\u00f6tter samen.", "tokens": ["da\u00df", "er", "von", "der", "halb\u00b7g\u00f6t\u00b7ter", "sa\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ART", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Sein angenehmes angesicht", "tokens": ["Sein", "an\u00b7ge\u00b7neh\u00b7mes", "an\u00b7ge\u00b7sicht"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "kan mit lieb zeugendem bericht", "tokens": ["kan", "mit", "lieb", "zeu\u00b7gen\u00b7dem", "be\u00b7richt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VMFIN", "APPR", "ADJD", "ADJA", "NN"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.3": {"text": "der menschen angesicht vern\u00fcgen,", "tokens": ["der", "men\u00b7schen", "an\u00b7ge\u00b7sicht", "ver\u00b7n\u00fc\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVPP", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.4": {"text": "und wer ansicht des leibs gestalt,", "tokens": ["und", "wer", "an\u00b7sicht", "des", "leibs", "ge\u00b7stalt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VVFIN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "der spricht, er hab vil mehr gewalt", "tokens": ["der", "spricht", ",", "er", "hab", "vil", "mehr", "ge\u00b7walt"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "VVFIN", "$,", "PPER", "VAFIN", "ADV", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "zu lieben wol, dan wol zu kriegen.", "tokens": ["zu", "lie\u00b7ben", "wol", ",", "dan", "wol", "zu", "krie\u00b7gen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "ADV", "$,", "ADV", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Doch wohnet Amor nur allein", "tokens": ["Doch", "woh\u00b7net", "A\u00b7mor", "nur", "al\u00b7lein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "NE", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "in seiner augen klarem schein", "tokens": ["in", "sei\u00b7ner", "au\u00b7gen", "kla\u00b7rem", "schein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "und kan ihm nicht das herz betr\u00fcben;", "tokens": ["und", "kan", "ihm", "nicht", "das", "herz", "be\u00b7tr\u00fc\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "PTKNEG", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "dan Mars selbs ist in seiner brust,", "tokens": ["dan", "Mars", "selbs", "ist", "in", "sei\u00b7ner", "brust", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "ADV", "VAFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "der macht, da\u00df er vil gr\u00f6\u00dfern lust", "tokens": ["der", "macht", ",", "da\u00df", "er", "vil", "gr\u00f6\u00b7\u00dfern", "lust"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "VVFIN", "$,", "KOUS", "PPER", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "zu kriegen, dan sich zu verlieben.", "tokens": ["zu", "krie\u00b7gen", ",", "dan", "sich", "zu", "ver\u00b7lie\u00b7ben", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "$,", "ADV", "PRF", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Eh von dem ersten zarten haar", "tokens": ["Eh", "von", "dem", "ers\u00b7ten", "zar\u00b7ten", "haar"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "ART", "ADJA", "ADJA", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "sein junges kin bedecket war,", "tokens": ["sein", "jun\u00b7ges", "kin", "be\u00b7de\u00b7cket", "war", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVFIN", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "sein leib mit eisen war bedecket;", "tokens": ["sein", "leib", "mit", "ei\u00b7sen", "war", "be\u00b7de\u00b7cket", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "VVPP", "VAFIN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "und seiner jungen faust probstreich", "tokens": ["und", "sei\u00b7ner", "jun\u00b7gen", "faust", "probs\u00b7treich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "hat schon vil k\u00f6rper wund und bleich", "tokens": ["hat", "schon", "vil", "k\u00f6r\u00b7per", "wund", "und", "bleich"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "ADV", "ADJD", "ADJD", "KON", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "f\u00fcr seinen f\u00fc\u00dfen ausgestrecket.", "tokens": ["f\u00fcr", "sei\u00b7nen", "f\u00fc\u00b7\u00dfen", "aus\u00b7ge\u00b7stre\u00b7cket", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Alsbald es frid in Niderland,", "tokens": ["Als\u00b7bald", "es", "frid", "in", "Ni\u00b7der\u00b7land", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "APPR", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "ist er, zu \u00fcben seine hand,", "tokens": ["ist", "er", ",", "zu", "\u00fc\u00b7ben", "sei\u00b7ne", "hand", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "$,", "PTKZU", "VVINF", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ligurien gleich zugeloffen;", "tokens": ["Li\u00b7gu\u00b7ri\u00b7en", "gleich", "zu\u00b7ge\u00b7lof\u00b7fen", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "da dan auf dem unsteten meer", "tokens": ["da", "dan", "auf", "dem", "un\u00b7ste\u00b7ten", "meer"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "APPR", "ART", "ADJA", "NN"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.5": {"text": "vil aus des wachsenden mons heer", "tokens": ["vil", "aus", "des", "wach\u00b7sen\u00b7den", "mons", "heer"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "durch ihn erschlagen und ersoffen.", "tokens": ["durch", "ihn", "er\u00b7schla\u00b7gen", "und", "er\u00b7sof\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVPP", "KON", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Hernach hat er auch seine macht", "tokens": ["Her\u00b7nach", "hat", "er", "auch", "sei\u00b7ne", "macht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "PPOSAT", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "in Istria in mancher schlacht", "tokens": ["in", "I\u00b7stria", "in", "man\u00b7cher", "schlacht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "NE", "APPR", "PIAT", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "mit solcher dapferkeit erwisen,", "tokens": ["mit", "sol\u00b7cher", "dap\u00b7fer\u00b7keit", "er\u00b7wi\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "da\u00df ab ihm die geschlagne feind,", "tokens": ["da\u00df", "ab", "ihm", "die", "ge\u00b7schlag\u00b7ne", "feind", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "wie seine wol besch\u00fctzte freind,", "tokens": ["wie", "sei\u00b7ne", "wol", "be\u00b7sch\u00fctz\u00b7te", "freind", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "ADV", "VVFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "sich selbs verwundrend ihn geprisen.", "tokens": ["sich", "selbs", "ver\u00b7wund\u00b7rend", "ihn", "ge\u00b7pri\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADV", "VVPP", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Und wan ihn schon das sinwel gl\u00fcck", "tokens": ["Und", "wan", "ihn", "schon", "das", "sin\u00b7wel", "gl\u00fcck"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "PPER", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "mit einem freindlichen anblick", "tokens": ["mit", "ei\u00b7nem", "freind\u00b7li\u00b7chen", "an\u00b7blick"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "nicht allzeit pfleget zu begr\u00fc\u00dfen,", "tokens": ["nicht", "all\u00b7zeit", "pfle\u00b7get", "zu", "be\u00b7gr\u00fc\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "VVFIN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "hat er doch einen solchen mut,", "tokens": ["hat", "er", "doch", "ei\u00b7nen", "sol\u00b7chen", "mut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ART", "PIAT", "NN", "$,"], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.5": {"text": "da\u00df er auch wol sein heldenblut,", "tokens": ["da\u00df", "er", "auch", "wol", "sein", "hel\u00b7den\u00b7blut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "den sig zu kaufen, ein darf b\u00fc\u00dfen.", "tokens": ["den", "sig", "zu", "kau\u00b7fen", ",", "ein", "darf", "b\u00fc\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "PTKZU", "VVINF", "$,", "ART", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Wie Hannibal hat er die reis", "tokens": ["Wie", "Han\u00b7ni\u00b7bal", "hat", "er", "die", "reis"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "NE", "VAFIN", "PPER", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "f\u00fcr sein volk mit vil list und schwei\u00df", "tokens": ["f\u00fcr", "sein", "volk", "mit", "vil", "list", "und", "schwei\u00df"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "APPR", "PIAT", "NN", "KON", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "k\u00fchn \u00fcber das geb\u00fcrg erfunden.", "tokens": ["k\u00fchn", "\u00fc\u00b7ber", "das", "ge\u00b7b\u00fcrg", "er\u00b7fun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "er f\u00f6rchtet sich f\u00fcr keinem tod,", "tokens": ["er", "f\u00f6rch\u00b7tet", "sich", "f\u00fcr", "kei\u00b7nem", "tod", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "er wei\u00df f\u00fcr sich von keiner not,", "tokens": ["er", "wei\u00df", "f\u00fcr", "sich", "von", "kei\u00b7ner", "not", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PRF", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "er ist auch sigreich \u00fcberwunden.", "tokens": ["er", "ist", "auch", "sig\u00b7reich", "\u00fc\u00b7berw\u00b7un\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Darum mag wol der weise rat", "tokens": ["Da\u00b7rum", "mag", "wol", "der", "wei\u00b7se", "rat"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PAV", "VMFIN", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "der einig-doppelt-sch\u00f6nen stat", "tokens": ["der", "ei\u00b7nig\u00b7dop\u00b7pel\u00b7tsch\u00f6\u00b7nen", "stat"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "ihn, wie er thut, wol liebend ehren:", "tokens": ["ihn", ",", "wie", "er", "thut", ",", "wol", "lie\u00b7bend", "eh\u00b7ren", ":"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PWAV", "PPER", "VVFIN", "$,", "ADV", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "dan warlich sein verstand und schwert", "tokens": ["dan", "war\u00b7lich", "sein", "ver\u00b7stand", "und", "schwert"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "VAINF", "VVFIN", "KON", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "seind alles ruhms und gl\u00fccks so wert,", "tokens": ["seind", "al\u00b7les", "ruhms", "und", "gl\u00fccks", "so", "wert", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIAT", "NN", "KON", "ADV", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "da\u00df niemand sie kan gnug vermehren.", "tokens": ["da\u00df", "nie\u00b7mand", "sie", "kan", "gnug", "ver\u00b7meh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPER", "VMFIN", "ADV", "VVINF", "$."], "meter": "-+-++--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.10": {"line.1": {"text": "Sing fort mein mund und schweig nicht still,", "tokens": ["Sing", "fort", "mein", "mund", "und", "schweig", "nicht", "still", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "PPOSAT", "NN", "KON", "VVFIN", "PTKNEG", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "damit ich mein gel\u00fcbd erf\u00fcll", "tokens": ["da\u00b7mit", "ich", "mein", "ge\u00b7l\u00fcbd", "er\u00b7f\u00fcll"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "und sing des jungen helden namen,", "tokens": ["und", "sing", "des", "jun\u00b7gen", "hel\u00b7den", "na\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "der durch manch k\u00fchne ritters that", "tokens": ["der", "durch", "manch", "k\u00fch\u00b7ne", "rit\u00b7ters", "that"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "PIAT", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "der faust schon oft bezeuget hat,", "tokens": ["der", "faust", "schon", "oft", "be\u00b7zeu\u00b7get", "hat", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ADV", "VVFIN", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "da\u00df er von der halbg\u00f6tter samen.", "tokens": ["da\u00df", "er", "von", "der", "halb\u00b7g\u00f6t\u00b7ter", "sa\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ART", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Sein angenehmes angesicht", "tokens": ["Sein", "an\u00b7ge\u00b7neh\u00b7mes", "an\u00b7ge\u00b7sicht"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "kan mit lieb zeugendem bericht", "tokens": ["kan", "mit", "lieb", "zeu\u00b7gen\u00b7dem", "be\u00b7richt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VMFIN", "APPR", "ADJD", "ADJA", "NN"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.3": {"text": "der menschen angesicht vern\u00fcgen,", "tokens": ["der", "men\u00b7schen", "an\u00b7ge\u00b7sicht", "ver\u00b7n\u00fc\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVPP", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.4": {"text": "und wer ansicht des leibs gestalt,", "tokens": ["und", "wer", "an\u00b7sicht", "des", "leibs", "ge\u00b7stalt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VVFIN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "der spricht, er hab vil mehr gewalt", "tokens": ["der", "spricht", ",", "er", "hab", "vil", "mehr", "ge\u00b7walt"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "VVFIN", "$,", "PPER", "VAFIN", "ADV", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "zu lieben wol, dan wol zu kriegen.", "tokens": ["zu", "lie\u00b7ben", "wol", ",", "dan", "wol", "zu", "krie\u00b7gen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "ADV", "$,", "ADV", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Doch wohnet Amor nur allein", "tokens": ["Doch", "woh\u00b7net", "A\u00b7mor", "nur", "al\u00b7lein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "NE", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "in seiner augen klarem schein", "tokens": ["in", "sei\u00b7ner", "au\u00b7gen", "kla\u00b7rem", "schein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "und kan ihm nicht das herz betr\u00fcben;", "tokens": ["und", "kan", "ihm", "nicht", "das", "herz", "be\u00b7tr\u00fc\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "PTKNEG", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "dan Mars selbs ist in seiner brust,", "tokens": ["dan", "Mars", "selbs", "ist", "in", "sei\u00b7ner", "brust", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "ADV", "VAFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "der macht, da\u00df er vil gr\u00f6\u00dfern lust", "tokens": ["der", "macht", ",", "da\u00df", "er", "vil", "gr\u00f6\u00b7\u00dfern", "lust"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "VVFIN", "$,", "KOUS", "PPER", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "zu kriegen, dan sich zu verlieben.", "tokens": ["zu", "krie\u00b7gen", ",", "dan", "sich", "zu", "ver\u00b7lie\u00b7ben", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "$,", "ADV", "PRF", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Eh von dem ersten zarten haar", "tokens": ["Eh", "von", "dem", "ers\u00b7ten", "zar\u00b7ten", "haar"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "ART", "ADJA", "ADJA", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "sein junges kin bedecket war,", "tokens": ["sein", "jun\u00b7ges", "kin", "be\u00b7de\u00b7cket", "war", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVFIN", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "sein leib mit eisen war bedecket;", "tokens": ["sein", "leib", "mit", "ei\u00b7sen", "war", "be\u00b7de\u00b7cket", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "VVPP", "VAFIN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "und seiner jungen faust probstreich", "tokens": ["und", "sei\u00b7ner", "jun\u00b7gen", "faust", "probs\u00b7treich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "hat schon vil k\u00f6rper wund und bleich", "tokens": ["hat", "schon", "vil", "k\u00f6r\u00b7per", "wund", "und", "bleich"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "ADV", "ADJD", "ADJD", "KON", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "f\u00fcr seinen f\u00fc\u00dfen ausgestrecket.", "tokens": ["f\u00fcr", "sei\u00b7nen", "f\u00fc\u00b7\u00dfen", "aus\u00b7ge\u00b7stre\u00b7cket", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Alsbald es frid in Niderland,", "tokens": ["Als\u00b7bald", "es", "frid", "in", "Ni\u00b7der\u00b7land", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "APPR", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "ist er, zu \u00fcben seine hand,", "tokens": ["ist", "er", ",", "zu", "\u00fc\u00b7ben", "sei\u00b7ne", "hand", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "$,", "PTKZU", "VVINF", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ligurien gleich zugeloffen;", "tokens": ["Li\u00b7gu\u00b7ri\u00b7en", "gleich", "zu\u00b7ge\u00b7lof\u00b7fen", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "da dan auf dem unsteten meer", "tokens": ["da", "dan", "auf", "dem", "un\u00b7ste\u00b7ten", "meer"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "APPR", "ART", "ADJA", "NN"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.5": {"text": "vil aus des wachsenden mons heer", "tokens": ["vil", "aus", "des", "wach\u00b7sen\u00b7den", "mons", "heer"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "durch ihn erschlagen und ersoffen.", "tokens": ["durch", "ihn", "er\u00b7schla\u00b7gen", "und", "er\u00b7sof\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVPP", "KON", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "Hernach hat er auch seine macht", "tokens": ["Her\u00b7nach", "hat", "er", "auch", "sei\u00b7ne", "macht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "PPOSAT", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "in Istria in mancher schlacht", "tokens": ["in", "I\u00b7stria", "in", "man\u00b7cher", "schlacht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "NE", "APPR", "PIAT", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "mit solcher dapferkeit erwisen,", "tokens": ["mit", "sol\u00b7cher", "dap\u00b7fer\u00b7keit", "er\u00b7wi\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "da\u00df ab ihm die geschlagne feind,", "tokens": ["da\u00df", "ab", "ihm", "die", "ge\u00b7schlag\u00b7ne", "feind", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "wie seine wol besch\u00fctzte freind,", "tokens": ["wie", "sei\u00b7ne", "wol", "be\u00b7sch\u00fctz\u00b7te", "freind", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "ADV", "VVFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "sich selbs verwundrend ihn geprisen.", "tokens": ["sich", "selbs", "ver\u00b7wund\u00b7rend", "ihn", "ge\u00b7pri\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADV", "VVPP", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "Und wan ihn schon das sinwel gl\u00fcck", "tokens": ["Und", "wan", "ihn", "schon", "das", "sin\u00b7wel", "gl\u00fcck"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "PPER", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "mit einem freindlichen anblick", "tokens": ["mit", "ei\u00b7nem", "freind\u00b7li\u00b7chen", "an\u00b7blick"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "nicht allzeit pfleget zu begr\u00fc\u00dfen,", "tokens": ["nicht", "all\u00b7zeit", "pfle\u00b7get", "zu", "be\u00b7gr\u00fc\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "VVFIN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "hat er doch einen solchen mut,", "tokens": ["hat", "er", "doch", "ei\u00b7nen", "sol\u00b7chen", "mut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ART", "PIAT", "NN", "$,"], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.5": {"text": "da\u00df er auch wol sein heldenblut,", "tokens": ["da\u00df", "er", "auch", "wol", "sein", "hel\u00b7den\u00b7blut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "den sig zu kaufen, ein darf b\u00fc\u00dfen.", "tokens": ["den", "sig", "zu", "kau\u00b7fen", ",", "ein", "darf", "b\u00fc\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "PTKZU", "VVINF", "$,", "ART", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.17": {"line.1": {"text": "Wie Hannibal hat er die reis", "tokens": ["Wie", "Han\u00b7ni\u00b7bal", "hat", "er", "die", "reis"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "NE", "VAFIN", "PPER", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "f\u00fcr sein volk mit vil list und schwei\u00df", "tokens": ["f\u00fcr", "sein", "volk", "mit", "vil", "list", "und", "schwei\u00df"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "APPR", "PIAT", "NN", "KON", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "k\u00fchn \u00fcber das geb\u00fcrg erfunden.", "tokens": ["k\u00fchn", "\u00fc\u00b7ber", "das", "ge\u00b7b\u00fcrg", "er\u00b7fun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "er f\u00f6rchtet sich f\u00fcr keinem tod,", "tokens": ["er", "f\u00f6rch\u00b7tet", "sich", "f\u00fcr", "kei\u00b7nem", "tod", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "er wei\u00df f\u00fcr sich von keiner not,", "tokens": ["er", "wei\u00df", "f\u00fcr", "sich", "von", "kei\u00b7ner", "not", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PRF", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "er ist auch sigreich \u00fcberwunden.", "tokens": ["er", "ist", "auch", "sig\u00b7reich", "\u00fc\u00b7berw\u00b7un\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.18": {"line.1": {"text": "Darum mag wol der weise rat", "tokens": ["Da\u00b7rum", "mag", "wol", "der", "wei\u00b7se", "rat"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PAV", "VMFIN", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "der einig-doppelt-sch\u00f6nen stat", "tokens": ["der", "ei\u00b7nig\u00b7dop\u00b7pel\u00b7tsch\u00f6\u00b7nen", "stat"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "ihn, wie er thut, wol liebend ehren:", "tokens": ["ihn", ",", "wie", "er", "thut", ",", "wol", "lie\u00b7bend", "eh\u00b7ren", ":"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PWAV", "PPER", "VVFIN", "$,", "ADV", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "dan warlich sein verstand und schwert", "tokens": ["dan", "war\u00b7lich", "sein", "ver\u00b7stand", "und", "schwert"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "VAINF", "VVFIN", "KON", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "seind alles ruhms und gl\u00fccks so wert,", "tokens": ["seind", "al\u00b7les", "ruhms", "und", "gl\u00fccks", "so", "wert", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIAT", "NN", "KON", "ADV", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "da\u00df niemand sie kan gnug vermehren.", "tokens": ["da\u00df", "nie\u00b7mand", "sie", "kan", "gnug", "ver\u00b7meh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPER", "VMFIN", "ADV", "VVINF", "$."], "meter": "-+-++--+-", "measure": "iambic.tetra.relaxed"}}}}}