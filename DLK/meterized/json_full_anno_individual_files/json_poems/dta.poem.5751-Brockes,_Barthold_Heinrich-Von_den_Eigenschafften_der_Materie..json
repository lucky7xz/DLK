{"dta.poem.5751": {"metadata": {"author": {"name": "Brockes, Barthold Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "Von den Eigenschafften der  \n Materie.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1730", "urn": "urn:nbn:de:kobv:b4-20087-5", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Von Unerm\u00e4\u00dflichkeit, Unendlichkeit,", "tokens": ["Von", "Un\u00b7er\u00b7m\u00e4\u00df\u00b7lich\u00b7keit", ",", "Un\u00b7end\u00b7lich\u00b7keit", ","], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Mu\u00df billig nur mit Schen gesprochen seyn.", "tokens": ["Mu\u00df", "bil\u00b7lig", "nur", "mit", "Schen", "ge\u00b7spro\u00b7chen", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADJD", "ADV", "APPR", "NN", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Die Ehre, die Beschaffenheit,", "tokens": ["Die", "Eh\u00b7re", ",", "die", "Be\u00b7schaf\u00b7fen\u00b7heit", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Geb\u00fchrt der GOTTHEIT blos allein.", "tokens": ["Ge\u00b7b\u00fchrt", "der", "GoT\u00b7T\u00b7HEIT", "blos", "al\u00b7lein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "ART", "NN", "ADV", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Doch m\u00fcssen sich die W\u00f6rter brauchen lassen", "tokens": ["Doch", "m\u00fcs\u00b7sen", "sich", "die", "W\u00f6r\u00b7ter", "brau\u00b7chen", "las\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VMFIN", "PRF", "ART", "NN", "VVINF", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "In Dingen, welche wir nicht fassen.", "tokens": ["In", "Din\u00b7gen", ",", "wel\u00b7che", "wir", "nicht", "fas\u00b7sen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "PRELS", "PPER", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Cartesius l\u00e4sst uns in seinen weisen Lehren", "tokens": ["Car\u00b7te\u00b7sius", "l\u00e4sst", "uns", "in", "sei\u00b7nen", "wei\u00b7sen", "Leh\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "PPER", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.8": {"text": "Ein Wort, das ", "tokens": ["Ein", "Wort", ",", "das"], "token_info": ["word", "word", "punct", "word"], "pos": ["ART", "NN", "$,", "PRELS"], "meter": "-+-", "measure": "amphibrach.single"}, "line.9": {"text": "Hiedurch wird aller Stolz verbannt.", "tokens": ["Hie\u00b7durch", "wird", "al\u00b7ler", "Stolz", "ver\u00b7bannt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "PIAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Denn endlich mu\u00df doch unser Geist bekennen:", "tokens": ["Denn", "end\u00b7lich", "mu\u00df", "doch", "un\u00b7ser", "Geist", "be\u00b7ken\u00b7nen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VMFIN", "ADV", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "Da\u00df man die Welt mit Recht nicht eingeschr\u00e4nckt kan nennen.", "tokens": ["Da\u00df", "man", "die", "Welt", "mit", "Recht", "nicht", "ein\u00b7ge\u00b7schr\u00e4nckt", "kan", "nen\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ART", "NN", "APPR", "NN", "PTKNEG", "VVPP", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Wird sie von uns nun sonder Gr\u00e4ntz\u2019 erkannt;", "tokens": ["Wird", "sie", "von", "uns", "nun", "son\u00b7der", "Gr\u00e4nt\u00b7z'", "er\u00b7kannt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPR", "PPER", "ADV", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.13": {"text": "Sinckt unsre Schwach-und Unvollkommenheit", "tokens": ["Sinckt", "uns\u00b7re", "Schwach\u00b7\u00b7und", "Un\u00b7voll\u00b7kom\u00b7men\u00b7heit"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "So gleich in die ", "tokens": ["So", "gleich", "in", "die"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ADV", "APPR", "ART"], "meter": "-+-+", "measure": "iambic.di"}, "line.15": {"text": "Von welchen beyden Schl\u00fcssen:", "tokens": ["Von", "wel\u00b7chen", "bey\u00b7den", "Schl\u00fcs\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PWAT", "PIAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.16": {"text": "Wir beyde doch vermeiden m\u00fcssen.", "tokens": ["Wir", "bey\u00b7de", "doch", "ver\u00b7mei\u00b7den", "m\u00fcs\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PIS", "ADV", "VVINF", "VMINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}