{"textgrid.poem.24646": {"metadata": {"author": {"name": "Hunold, Christian Friedrich", "birth": "N.A.", "death": "N.A."}, "title": "1L: Kommt/ T\u00f6chter Salems/ kommt/ und schaut mein Leiden an/", "genre": "verse", "period": "N.A.", "pub_year": 1701, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Kommt/ T\u00f6chter Salems/ kommt/ und schaut mein Leiden an/", "tokens": ["Kommt", "/", "T\u00f6ch\u00b7ter", "Sa\u00b7lems", "/", "kommt", "/", "und", "schaut", "mein", "Lei\u00b7den", "an", "/"], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$(", "NN", "NE", "$(", "VVFIN", "$(", "KON", "VVFIN", "PPOSAT", "NN", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und wenn nicht euer Hertz von Eisen/ Stahl und Steinen/", "tokens": ["Und", "wenn", "nicht", "eu\u00b7er", "Hertz", "von", "Ei\u00b7sen", "/", "Stahl", "und", "Stei\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PTKNEG", "PPOSAT", "NN", "APPR", "NN", "$(", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "So seuffzet auch mit mir/ helfft eurer Schwester weinen/", "tokens": ["So", "seuff\u00b7zet", "auch", "mit", "mir", "/", "helfft", "eu\u00b7rer", "Schwes\u00b7ter", "wei\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "APPR", "PPER", "$(", "VVFIN", "PPOSAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Weil ihr der Himmel hat im Zorne weh gethan.", "tokens": ["Weil", "ihr", "der", "Him\u00b7mel", "hat", "im", "Zor\u00b7ne", "weh", "ge\u00b7than", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VAFIN", "APPRART", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Mich hat des H\u00f6chsten Hand im Grimme wund geschlagen/", "tokens": ["Mich", "hat", "des", "H\u00f6chs\u00b7ten", "Hand", "im", "Grim\u00b7me", "wund", "ge\u00b7schla\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "APPRART", "NN", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Drum kommt und helffet mir den Schmertzen mit beklagen.", "tokens": ["Drum", "kommt", "und", "helf\u00b7fet", "mir", "den", "Schmert\u00b7zen", "mit", "be\u00b7kla\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "KON", "VVFIN", "PPER", "ART", "NN", "APPR", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Schaut meines Tempels Pracht/ wie solcher sich verstellt.", "tokens": ["Schaut", "mei\u00b7nes", "Tem\u00b7pels", "Pracht", "/", "wie", "sol\u00b7cher", "sich", "ver\u00b7stellt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "NN", "$(", "KOKOM", "PIAT", "PRF", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ich reisse Gold und Schmuck von dem bekr\u00f6nten Haare:", "tokens": ["Ich", "reis\u00b7se", "Gold", "und", "Schmuck", "von", "dem", "be\u00b7kr\u00f6n\u00b7ten", "Haa\u00b7re", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "KON", "NN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Denn selbst mein Heiligthum liegt auf der Todten-Bahre/", "tokens": ["Denn", "selbst", "mein", "Hei\u00b7lig\u00b7thum", "liegt", "auf", "der", "Tod\u00b7ten\u00b7Bah\u00b7re", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PPOSAT", "NN", "VVFIN", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Mein Kirchen-Pfeiler bricht/ mein Bet-Altar zerf\u00e4llt/", "tokens": ["Mein", "Kir\u00b7chen\u00b7Pfei\u00b7ler", "bricht", "/", "mein", "Bet\u00b7Al\u00b7tar", "zer\u00b7f\u00e4llt", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "$(", "PPOSAT", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Man h\u00f6ret itzo nichts in meines Tempels Hallen/", "tokens": ["Man", "h\u00f6\u00b7ret", "it\u00b7zo", "nichts", "in", "mei\u00b7nes", "Tem\u00b7pels", "Hal\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ADV", "PIS", "APPR", "PPOSAT", "NN", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Als vieler Klagen Hall verdoppelt wiederschallen.", "tokens": ["Als", "vie\u00b7ler", "Kla\u00b7gen", "Hall", "ver\u00b7dop\u00b7pelt", "wie\u00b7der\u00b7schal\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "NN", "NE", "VVPP", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Mein Halleluja kehrt sich in Eleison/", "tokens": ["Mein", "Hal\u00b7le\u00b7lu\u00b7ja", "kehrt", "sich", "in", "E\u00b7lei\u00b7son", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PRF", "APPR", "NE", "$("], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Mein frohes S\u00e4itenspiel verwandelt sich in Heulen/", "tokens": ["Mein", "fro\u00b7hes", "S\u00e4i\u00b7ten\u00b7spiel", "ver\u00b7wan\u00b7delt", "sich", "in", "Heu\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVFIN", "PRF", "APPR", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Gebet und Sang mu\u00df sich in Ach und Weh zertheilen/", "tokens": ["Ge\u00b7bet", "und", "Sang", "mu\u00df", "sich", "in", "Ach", "und", "Weh", "zer\u00b7thei\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VMFIN", "PRF", "APPR", "NN", "KON", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Auf meinem Chore klingt ein steter Klage-Thon.", "tokens": ["Auf", "mei\u00b7nem", "Cho\u00b7re", "klingt", "ein", "ste\u00b7ter", "Kla\u00b7ge\u00b7Thon", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und wie soll nicht das Leid durch meine Geister dringen/", "tokens": ["Und", "wie", "soll", "nicht", "das", "Leid", "durch", "mei\u00b7ne", "Geis\u00b7ter", "drin\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "VMFIN", "PTKNEG", "ART", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Weil ich statt ", "tokens": ["Weil", "ich", "statt"], "token_info": ["word", "word", "word"], "pos": ["KOUS", "PPER", "VVFIN"], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.4": {"line.1": {"text": "Ich lege Boy und Flor nicht nach Gewohnheit an/", "tokens": ["Ich", "le\u00b7ge", "Boy", "und", "Flor", "nicht", "nach", "Ge\u00b7wohn\u00b7heit", "an", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NE", "KON", "NN", "PTKNEG", "APPR", "NN", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ich weine nicht zum Staat/ ich klage nicht zum Scheine:", "tokens": ["Ich", "wei\u00b7ne", "nicht", "zum", "Staat", "/", "ich", "kla\u00b7ge", "nicht", "zum", "Schei\u00b7ne", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "APPRART", "NN", "$(", "PPER", "VVFIN", "PTKNEG", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Denn ein so grosser Fall zerqvetschet Marck und Beine.", "tokens": ["Denn", "ein", "so", "gros\u00b7ser", "Fall", "zer\u00b7qvet\u00b7schet", "Marck", "und", "Bei\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADV", "ADJA", "NN", "VVFIN", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Es ist nun fast um mich und um mein Heil gethan;", "tokens": ["Es", "ist", "nun", "fast", "um", "mich", "und", "um", "mein", "Heil", "ge\u00b7than", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "APPR", "PPER", "KON", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Weil meine Hanna todt/ die durch ihr stetes Beten/", "tokens": ["Weil", "mei\u00b7ne", "Han\u00b7na", "todt", "/", "die", "durch", "ihr", "ste\u00b7tes", "Be\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "ADJD", "$(", "ART", "APPR", "PPOSAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Bey manchem Ungl\u00fccks-Sturm ist vor den Ri\u00df getreten.", "tokens": ["Bey", "man\u00b7chem", "Un\u00b7gl\u00fccks\u00b7Sturm", "ist", "vor", "den", "Ri\u00df", "ge\u00b7tre\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VAFIN", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Und da ich mehr von Ihr zu r\u00fchmen willens bin/", "tokens": ["Und", "da", "ich", "mehr", "von", "Ihr", "zu", "r\u00fch\u00b7men", "wil\u00b7lens", "bin", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "APPR", "PPER", "PTKZU", "VVINF", "NN", "VAFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Will mich/ wie Nioben/ der Jammer fast entseelen.", "tokens": ["Will", "mich", "/", "wie", "Ni\u00b7o\u00b7ben", "/", "der", "Jam\u00b7mer", "fast", "ent\u00b7see\u00b7len", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "$(", "KOKOM", "NE", "$(", "ART", "NN", "ADV", "VVINF", "$."], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.3": {"text": "Der Mund erstarret schon/ ich kan nichts mehr erzehlen/", "tokens": ["Der", "Mund", "er\u00b7star\u00b7ret", "schon", "/", "ich", "kan", "nichts", "mehr", "er\u00b7zeh\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "$(", "PPER", "VMFIN", "PIS", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und weis/ als Todte/ nur auf", "tokens": ["Und", "weis", "/", "als", "Tod\u00b7te", "/", "nur", "auf"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["KON", "PTKVZ", "$(", "KOUS", "NN", "$(", "ADV", "APPR"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.5": {"text": "Die stummen ", "tokens": ["Die", "stum\u00b7men"], "token_info": ["word", "word"], "pos": ["ART", "ADJA"], "meter": "-+-", "measure": "amphibrach.single"}, "line.6": {"text": "Was ich und was mit mir ein jeder hilfft beklagen:", "tokens": ["Was", "ich", "und", "was", "mit", "mir", "ein", "je\u00b7der", "hilfft", "be\u00b7kla\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "KON", "PWS", "APPR", "PPER", "ART", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Schaut her/ wie um den Sarg nichts als nur", "tokens": ["Schaut", "her", "/", "wie", "um", "den", "Sarg", "nichts", "als", "nur"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PTKVZ", "$(", "KOKOM", "APPR", "ART", "NN", "PIS", "KOKOM", "ADV"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Die uns ein Zeugni\u00df giebt vom rechten Tugend-Triebe:", "tokens": ["Die", "uns", "ein", "Zeug\u00b7ni\u00df", "giebt", "vom", "rech\u00b7ten", "Tu\u00b7gen\u00b7dTrie\u00b7be", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ART", "NN", "VVFIN", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "In dessen Circkel ist der Mittel-Punct der Liebe/", "tokens": ["In", "des\u00b7sen", "Cir\u00b7ckel", "ist", "der", "Mit\u00b7tel\u00b7Punct", "der", "Lie\u00b7be", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELAT", "NN", "VAFIN", "ART", "NN", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Weil von/ durch und zu ihr die \u00e4chte Tugend geht.", "tokens": ["Weil", "von", "/", "durch", "und", "zu", "ihr", "die", "\u00e4ch\u00b7te", "Tu\u00b7gend", "geht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "$(", "APPR", "KON", "APPR", "PPER", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Drum weil die Liebe selbst zum letzten Dienst erkohren/", "tokens": ["Drum", "weil", "die", "Lie\u00b7be", "selbst", "zum", "letz\u00b7ten", "Dienst", "er\u00b7koh\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "KOUS", "ART", "NN", "ADV", "APPRART", "ADJA", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "So sieht man/ da\u00df mein Land was Liebes hat verlohren.", "tokens": ["So", "sieht", "man", "/", "da\u00df", "mein", "Land", "was", "Lie\u00b7bes", "hat", "ver\u00b7loh\u00b7ren", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "$(", "KOUS", "PPOSAT", "NN", "PWS", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Der aber liebet recht/ der", "tokens": ["Der", "a\u00b7ber", "lie\u00b7bet", "recht", "/", "der"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["ART", "ADV", "VVFIN", "ADJD", "$(", "ART"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Die", "tokens": ["Die"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}, "line.3": {"text": "Wie jener", "tokens": ["Wie", "je\u00b7ner"], "token_info": ["word", "word"], "pos": ["PWAV", "PDS"], "meter": "-+-", "measure": "amphibrach.single"}, "line.4": {"text": "Der von dem Paradie\u00df den sch\u00f6nen Rahmen tr\u00e4gt/", "tokens": ["Der", "von", "dem", "Pa\u00b7ra\u00b7die\u00df", "den", "sch\u00f6\u00b7nen", "Rah\u00b7men", "tr\u00e4gt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "ART", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Als welchem die Natur l\u00e4\u00dft keine F\u00fcsse geben/", "tokens": ["Als", "wel\u00b7chem", "die", "Na\u00b7tur", "l\u00e4\u00dft", "kei\u00b7ne", "F\u00fcs\u00b7se", "ge\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRELS", "ART", "NN", "VVFIN", "PIAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Da\u00df er im Himmel soll/ nicht auf der Erden/ leben.", "tokens": ["Da\u00df", "er", "im", "Him\u00b7mel", "soll", "/", "nicht", "auf", "der", "Er\u00b7den", "/", "le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "PPER", "APPRART", "NN", "VMFIN", "$(", "PTKNEG", "APPR", "ART", "NN", "$(", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "Glaub'/ Hoffnung/ Tugend", "tokens": ["Glaub'", "/", "Hoff\u00b7nung", "/", "Tu\u00b7gend"], "token_info": ["word", "punct", "word", "punct", "word"], "pos": ["NN", "$(", "NN", "$(", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.2": {"text": "Da\u00df unsrer Gr\u00e4fin Geist/ weil er vom Himmel kommen/", "tokens": ["Da\u00df", "uns\u00b7rer", "Gr\u00e4\u00b7fin", "Geist", "/", "weil", "er", "vom", "Him\u00b7mel", "kom\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "NN", "$(", "KOUS", "PPER", "APPRART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Nicht leicht was irdisches an sich hat angenommen.", "tokens": ["Nicht", "leicht", "was", "ir\u00b7di\u00b7sches", "an", "sich", "hat", "an\u00b7ge\u00b7nom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADJD", "PWS", "ADJA", "APPR", "PRF", "VAFIN", "VVPP", "$."], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Und weil ihr Lieben frey von Fremden Feuer war/", "tokens": ["Und", "weil", "ihr", "Lie\u00b7ben", "frey", "von", "Frem\u00b7den", "Feu\u00b7er", "war", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPOSAT", "ADJA", "NN", "APPR", "NN", "NN", "VAFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Hat man die Seltenheit um destomehr verehret/", "tokens": ["Hat", "man", "die", "Sel\u00b7ten\u00b7heit", "um", "des\u00b7to\u00b7mehr", "ver\u00b7eh\u00b7ret", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "ART", "NN", "APPR", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Da Stand und Sch\u00f6nheit hat derselben Pracht vermehret.", "tokens": ["Da", "Stand", "und", "Sch\u00f6n\u00b7heit", "hat", "der\u00b7sel\u00b7ben", "Pracht", "ver\u00b7meh\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "NN", "VAFIN", "PDAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Ob solcher Liebe Glut nun gleich zum Himmel geht/", "tokens": ["Ob", "sol\u00b7cher", "Lie\u00b7be", "Glut", "nun", "gleich", "zum", "Him\u00b7mel", "geht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "NN", "NN", "ADV", "ADV", "APPRART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Auch ihrem Jesu nur die Glaubens-Lampe brennet/", "tokens": ["Auch", "ih\u00b7rem", "Je\u00b7su", "nur", "die", "Glau\u00b7bens\u00b7Lam\u00b7pe", "bren\u00b7net", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NE", "ADV", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wird doch das Hertze nicht vom Nechsten abgetrennet/", "tokens": ["Wird", "doch", "das", "Hert\u00b7ze", "nicht", "vom", "Nechs\u00b7ten", "ab\u00b7ge\u00b7tren\u00b7net", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PDS", "VVFIN", "PTKNEG", "APPRART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Mit welchem es nechst Gott in treuer Liebe steht:", "tokens": ["Mit", "wel\u00b7chem", "es", "nechst", "Gott", "in", "treu\u00b7er", "Lie\u00b7be", "steht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "VVFIN", "NN", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Denn wer die Liebe nicht mit Menschen wei\u00df zu \u00fcben/", "tokens": ["Denn", "wer", "die", "Lie\u00b7be", "nicht", "mit", "Men\u00b7schen", "wei\u00df", "zu", "\u00fc\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ART", "NN", "PTKNEG", "APPR", "NN", "VVFIN", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wie kan der seinen Gott/ den er nicht siehet/ lieben?", "tokens": ["Wie", "kan", "der", "sei\u00b7nen", "Gott", "/", "den", "er", "nicht", "sie\u00b7het", "/", "lie\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PWAV", "VMFIN", "ART", "PPOSAT", "NN", "$(", "PRELS", "PPER", "PTKNEG", "VVFIN", "$(", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.10": {"line.1": {"text": "Der Himmels-Liebe k\u00f6mmt fast Ehe-Liebe bey/", "tokens": ["Der", "Him\u00b7mels\u00b7Lie\u00b7be", "k\u00f6mmt", "fast", "E\u00b7he\u00b7Lie\u00b7be", "bey", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "NN", "APPR", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Indem derselben Glut/ wenn Tugend sie entz\u00fcndet/", "tokens": ["In\u00b7dem", "der\u00b7sel\u00b7ben", "Glut", "/", "wenn", "Tu\u00b7gend", "sie", "ent\u00b7z\u00fcn\u00b7det", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDAT", "NN", "$(", "KOUS", "NN", "PPER", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Auch mit dem Lebens-Licht im Tode nicht verschwindet:", "tokens": ["Auch", "mit", "dem", "Le\u00b7bens\u00b7Licht", "im", "To\u00b7de", "nicht", "ver\u00b7schwin\u00b7det", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "APPRART", "NN", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Denn in der Asche glimmt noch Glut von ihrer Treu.", "tokens": ["Denn", "in", "der", "A\u00b7sche", "glimmt", "noch", "Glut", "von", "ih\u00b7rer", "Treu", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVFIN", "ADV", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Gleichwie der Tod nur kan bey denen Turtel-Tauben", "tokens": ["Gleich\u00b7wie", "der", "Tod", "nur", "kan", "bey", "de\u00b7nen", "Tur\u00b7tel\u00b7Tau\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "ADV", "VMFIN", "APPR", "PRELS", "NN"], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Das Leben/ aber nicht die treue Liebe/ rauben.", "tokens": ["Das", "Le\u00b7ben", "/", "a\u00b7ber", "nicht", "die", "treu\u00b7e", "Lie\u00b7be", "/", "rau\u00b7ben", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "$(", "ADV", "PTKNEG", "ART", "ADJA", "NN", "$(", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.11": {"line.1": {"text": "Selbst Dero Eh-gemahl bezeugt aus treuer Pflicht/", "tokens": ["Selbst", "De\u00b7ro", "Eh\u00b7ge\u00b7mahl", "be\u00b7zeugt", "aus", "treu\u00b7er", "Pflicht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PDS", "NN", "VVFIN", "APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Da\u00df solche Liebe nie bey ihr hat aufgeh\u00f6ret.", "tokens": ["Da\u00df", "sol\u00b7che", "Lie\u00b7be", "nie", "bey", "ihr", "hat", "auf\u00b7ge\u00b7h\u00f6\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "NN", "ADV", "APPR", "PPER", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Bi\u00df da\u00df sich durch den Tod das Feuer hat verzehret.", "tokens": ["Bi\u00df", "da\u00df", "sich", "durch", "den", "Tod", "das", "Feu\u00b7er", "hat", "ver\u00b7zeh\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "KOUS", "PRF", "APPR", "ART", "NN", "ART", "NN", "VAFIN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Er glaubt/ die Glut verlescht auch in dem Grabe nicht:", "tokens": ["Er", "glaubt", "/", "die", "Glut", "ver\u00b7lescht", "auch", "in", "dem", "Gra\u00b7be", "nicht", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$(", "ART", "NN", "VVFIN", "ADV", "APPR", "ART", "NN", "PTKNEG", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Drum weil nach Palmen-Art sie gleiche Liebe hegen/", "tokens": ["Drum", "weil", "nach", "Pal\u00b7men\u00b7Art", "sie", "glei\u00b7che", "Lie\u00b7be", "he\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "KOUS", "APPR", "NN", "PPER", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Soll man sie auch im Tod in eine H\u00f6le", "tokens": ["Soll", "man", "sie", "auch", "im", "Tod", "in", "ei\u00b7ne", "H\u00f6\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "PIS", "PPER", "ADV", "APPRART", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.12": {"line.1": {"text": "Der Ehe-Liebe folgt die Mutter-Liebe nach.", "tokens": ["Der", "E\u00b7he\u00b7Lie\u00b7be", "folgt", "die", "Mut\u00b7ter\u00b7Lie\u00b7be", "nach", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Hier pflegt die Liebe denn mehr ab-als auf-zu steigen/", "tokens": ["Hier", "pflegt", "die", "Lie\u00b7be", "denn", "mehr", "ab\u00b7als", "auf\u00b7zu", "stei\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ADV", "PIAT", "NN", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und sich mit gr\u00f6ster Lust den Kindern zuzuneigen/", "tokens": ["Und", "sich", "mit", "gr\u00f6s\u00b7ter", "Lust", "den", "Kin\u00b7dern", "zu\u00b7zu\u00b7nei\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "APPR", "ADJA", "NN", "ART", "NN", "VVIZU", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Drum flieht sie keine M\u00fch und scheut kein Ungemach/", "tokens": ["Drum", "flieht", "sie", "kei\u00b7ne", "M\u00fch", "und", "scheut", "kein", "Un\u00b7ge\u00b7mach", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "PIAT", "NN", "KON", "VVFIN", "PIAT", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Da\u00df sie denselben m\u00f6g' im Auferziehen n\u00fctzen/", "tokens": ["Da\u00df", "sie", "den\u00b7sel\u00b7ben", "m\u00f6g'", "im", "Auf\u00b7er\u00b7zie\u00b7hen", "n\u00fct\u00b7zen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PDS", "VMFIN", "APPRART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und einer Henne gleich die jungen K\u00fcchlein sch\u00fctzen.", "tokens": ["Und", "ei\u00b7ner", "Hen\u00b7ne", "gleich", "die", "jun\u00b7gen", "K\u00fcch\u00b7lein", "sch\u00fct\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ADV", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.13": {"line.1": {"text": "Hier tr\u00e4gt die Gr\u00e4fin auch mit Ruhm den Prei\u00df davon.", "tokens": ["Hier", "tr\u00e4gt", "die", "Gr\u00e4\u00b7fin", "auch", "mit", "Ruhm", "den", "Prei\u00df", "da\u00b7von", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ADV", "APPR", "NN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wie eine Muschel kan die sch\u00f6nste Perl erzeugen/", "tokens": ["Wie", "ei\u00b7ne", "Mu\u00b7schel", "kan", "die", "sch\u00f6ns\u00b7te", "Perl", "er\u00b7zeu\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "VMFIN", "ART", "ADJA", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wenn alle Nahrungs-Krafft sich darff zu einer neigen;", "tokens": ["Wenn", "al\u00b7le", "Nah\u00b7rungs\u00b7Krafft", "sich", "darff", "zu", "ei\u00b7ner", "nei\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "NN", "PRF", "PAV", "APPR", "PIS", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So war ihr gleichfalls auch der Hochgebohrne Sohn/", "tokens": ["So", "war", "ihr", "gleich\u00b7falls", "auch", "der", "Hoch\u00b7ge\u00b7bohr\u00b7ne", "Sohn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ADV", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Den sie alleine hat f\u00fcrtrefflich wohl gepflogen/", "tokens": ["Den", "sie", "al\u00b7lei\u00b7ne", "hat", "f\u00fcr\u00b7treff\u00b7lich", "wohl", "ge\u00b7pflo\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "VAFIN", "ADJD", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und durch Gebet und Flei\u00df so herrlich auferzogen.", "tokens": ["Und", "durch", "Ge\u00b7bet", "und", "Flei\u00df", "so", "herr\u00b7lich", "auf\u00b7er\u00b7zo\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "KON", "NN", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.14": {"line.1": {"text": "De\u00dfwegen klagt Er auch/ da\u00df seine Zierd und Lust", "tokens": ["De\u00df\u00b7we\u00b7gen", "klagt", "Er", "auch", "/", "da\u00df", "sei\u00b7ne", "Zierd", "und", "Lust"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "PPER", "ADV", "$(", "KOUS", "PPOSAT", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Gleich einer Rosen f\u00e4llt;", "tokens": ["Gleich", "ei\u00b7ner", "Ro\u00b7sen", "f\u00e4llt", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Den die Durchlauchtigste", "tokens": ["Den", "die", "Durch\u00b7lauch\u00b7tigs\u00b7te"], "token_info": ["word", "word", "word"], "pos": ["ART", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Der Kindes-Kinder", "tokens": ["Der", "Kin\u00b7des\u00b7Kin\u00b7der"], "token_info": ["word", "word"], "pos": ["ART", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.5": {"text": "Da\u00df sie nicht weiter soll dergleichen Wartung laben/", "tokens": ["Da\u00df", "sie", "nicht", "wei\u00b7ter", "soll", "derg\u00b7lei\u00b7chen", "War\u00b7tung", "la\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "ADV", "VMFIN", "PIS", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wovon sie h\u00f6chst-vergn\u00fcgt viel Wachsthum w\u00fcrden haben.", "tokens": ["Wo\u00b7von", "sie", "h\u00f6chst\u00b7ver\u00b7gn\u00fcgt", "viel", "Wach\u00b7sthum", "w\u00fcr\u00b7den", "ha\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VVFIN", "PIAT", "NN", "VAFIN", "VAINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.15": {"line.1": {"text": "Doch mu\u00df die Liebe noch bey Christen weiter gehn/", "tokens": ["Doch", "mu\u00df", "die", "Lie\u00b7be", "noch", "bey", "Chris\u00b7ten", "wei\u00b7ter", "gehn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ART", "NN", "ADV", "APPR", "NN", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und mu\u00df auch ihre Frucht an fremde Leute zahlen/", "tokens": ["Und", "mu\u00df", "auch", "ih\u00b7re", "Frucht", "an", "frem\u00b7de", "Leu\u00b7te", "zah\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ADV", "PPOSAT", "NN", "APPR", "ADJA", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Doch nicht den Heyden gleich mit ihren Gaben pralen", "tokens": ["Doch", "nicht", "den", "Hey\u00b7den", "gleich", "mit", "ih\u00b7ren", "Ga\u00b7ben", "pra\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PTKNEG", "ART", "NN", "ADV", "APPR", "PPOSAT", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Bey solcher G\u00fcte kan kein Mangel nicht entstehn/", "tokens": ["Bey", "sol\u00b7cher", "G\u00fc\u00b7te", "kan", "kein", "Man\u00b7gel", "nicht", "ent\u00b7stehn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VMFIN", "PIAT", "NN", "PTKNEG", "VVINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wenn man aus Liebe gleich/ um andern nur zu n\u00fctzen/", "tokens": ["Wenn", "man", "aus", "Lie\u00b7be", "gleich", "/", "um", "an\u00b7dern", "nur", "zu", "n\u00fct\u00b7zen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "APPR", "NN", "ADV", "$(", "APPR", "PIS", "ADV", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "L\u00e4\u00dft wie ein Pelican/", "tokens": ["L\u00e4\u00dft", "wie", "ein", "Pe\u00b7li\u00b7can", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KOKOM", "ART", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.16": {"line.1": {"text": "Zu Zeugen stehen dar Hof/ ", "tokens": ["Zu", "Zeu\u00b7gen", "ste\u00b7hen", "dar", "Hof", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PTKVZ", "NN", "$("], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Die sie/ als ein Magnet/", "tokens": ["Die", "sie", "/", "als", "ein", "Mag\u00b7net", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "$(", "KOUS", "ART", "NN", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Und f\u00fcr derselben Heil stets Sorge hat gepflogen/", "tokens": ["Und", "f\u00fcr", "der\u00b7sel\u00b7ben", "Heil", "stets", "Sor\u00b7ge", "hat", "ge\u00b7pflo\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PDAT", "NN", "ADV", "NN", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Drum stunde Schwartzburg stets im h\u00f6chst-begl\u00fcckten Stand/", "tokens": ["Drum", "stun\u00b7de", "Schwartz\u00b7burg", "stets", "im", "h\u00f6chst\u00b7be\u00b7gl\u00fcck\u00b7ten", "Stand", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ADJA", "NN", "ADV", "APPRART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Bi\u00df da\u00df sein Baum verdorrt/ der Nutzen hat gegeben/", "tokens": ["Bi\u00df", "da\u00df", "sein", "Baum", "ver\u00b7dorrt", "/", "der", "Nut\u00b7zen", "hat", "ge\u00b7ge\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "KOUS", "PPOSAT", "NN", "VVPP", "$(", "ART", "NN", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und nur noch oben pflegt zu bl\u00fchen und zu leben.", "tokens": ["Und", "nur", "noch", "o\u00b7ben", "pflegt", "zu", "bl\u00fc\u00b7hen", "und", "zu", "le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "ADV", "VVFIN", "PTKZU", "VVINF", "KON", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.17": {"line.1": {"text": "Meint aber nicht/ da\u00df hier des Lobes Grentzen sind/", "tokens": ["Meint", "a\u00b7ber", "nicht", "/", "da\u00df", "hier", "des", "Lo\u00b7bes", "Grent\u00b7zen", "sind", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PTKNEG", "$(", "KOUS", "ADV", "ART", "NN", "NN", "VAFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und da\u00df/ nachdem man viel von Ihrem Ruhm geprie\u00dfen/", "tokens": ["Und", "da\u00df", "/", "nach\u00b7dem", "man", "viel", "von", "Ih\u00b7rem", "Ruhm", "ge\u00b7prie\u00b7\u00dfen", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "$(", "KOUS", "PIS", "ADV", "APPR", "PPOSAT", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die vielen Tugenden hier ihren Reihen schlie\u00dfen:", "tokens": ["Die", "vie\u00b7len", "Tu\u00b7gen\u00b7den", "hier", "ih\u00b7ren", "Rei\u00b7hen", "schlie\u00b7\u00dfen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "ADV", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ach nein! weil man noch viel an ihr zu loben sindt.", "tokens": ["Ach", "nein", "!", "weil", "man", "noch", "viel", "an", "ihr", "zu", "lo\u00b7ben", "sindt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKANT", "$.", "KOUS", "PIS", "ADV", "ADV", "APPR", "PPER", "PTKZU", "VVINF", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Schaut/ wie viel Tugenden noch hier im Leide stehen/", "tokens": ["Schaut", "/", "wie", "viel", "Tu\u00b7gen\u00b7den", "noch", "hier", "im", "Lei\u00b7de", "ste\u00b7hen", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$(", "KOKOM", "PIAT", "NN", "ADV", "ADV", "APPRART", "NN", "VVFIN", "$("], "meter": "++-+-+-+-+-+-", "measure": "unknown.measure.septa"}, "line.6": {"text": "Und wie viel K\u00fcnste selbst mit ihr zu Grabe gehen.", "tokens": ["Und", "wie", "viel", "K\u00fcns\u00b7te", "selbst", "mit", "ihr", "zu", "Gra\u00b7be", "ge\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PIAT", "NN", "ADV", "APPR", "PPER", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.18": {"line.1": {"text": "Es wei\u00df mein Priester-Volck und der Gelehrten Schaar/", "tokens": ["Es", "wei\u00df", "mein", "Pries\u00b7ter\u00b7Volck", "und", "der", "Ge\u00b7lehr\u00b7ten", "Schaar", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "KON", "ART", "NN", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wie Ihr erlauchter Geist die Schrift wohl kunt ergr\u00fcnden;", "tokens": ["Wie", "Ihr", "er\u00b7lauch\u00b7ter", "Geist", "die", "Schrift", "wohl", "kunt", "er\u00b7gr\u00fcn\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "ADJA", "NN", "ART", "NN", "ADV", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wie Ihre Klugheit stets hat wissen Rath zu finden;", "tokens": ["Wie", "Ih\u00b7re", "Klug\u00b7heit", "stets", "hat", "wis\u00b7sen", "Rath", "zu", "fin\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "NN", "ADV", "VAFIN", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wie Ihre Poesie recht zu bewundern war;", "tokens": ["Wie", "Ih\u00b7re", "Poe\u00b7sie", "recht", "zu", "be\u00b7wun\u00b7dern", "war", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "NN", "ADJD", "PTKZU", "VVINF", "VAFIN", "$."], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Wie Kunst und Tugend hier zusammen streiten wollte/", "tokens": ["Wie", "Kunst", "und", "Tu\u00b7gend", "hier", "zu\u00b7sam\u00b7men", "strei\u00b7ten", "woll\u00b7te", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "KON", "NN", "ADV", "ADV", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wer unter Ihnen doch den Vorzug haben sollte.", "tokens": ["Wer", "un\u00b7ter", "Ih\u00b7nen", "doch", "den", "Vor\u00b7zug", "ha\u00b7ben", "soll\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "PPER", "ADV", "ART", "NN", "VAINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.19": {"line.1": {"text": "Schaut/ wie viel Strahlen hier von denen Lichtern gehn/", "tokens": ["Schaut", "/", "wie", "viel", "Strah\u00b7len", "hier", "von", "de\u00b7nen", "Lich\u00b7tern", "gehn", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$(", "KOKOM", "PIAT", "NN", "ADV", "APPR", "PRELS", "NN", "VVINF", "$("], "meter": "++-+-+-+-+-+", "measure": "unknown.measure.septa"}, "line.2": {"text": "Damit die Nacht nicht kan den Ehren-Prunck verdunckeln;", "tokens": ["Da\u00b7mit", "die", "Nacht", "nicht", "kan", "den", "Eh\u00b7ren\u00b7Prunck", "ver\u00b7dun\u00b7ckeln", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "NN", "PTKNEG", "VMFIN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Doch pflegt der Gr\u00e4fin Nuhm unendlich mehr zu funckeln.", "tokens": ["Doch", "pflegt", "der", "Gr\u00e4\u00b7fin", "Nuhm", "un\u00b7end\u00b7lich", "mehr", "zu", "fun\u00b7ckeln", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "NN", "ADJD", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und da im gr\u00f6sten Glantz viel Kronen", "tokens": ["Und", "da", "im", "gr\u00f6s\u00b7ten", "Glantz", "viel", "Kro\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "APPRART", "ADJA", "NN", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "So wollen selbige mit klaren Worten sagen:", "tokens": ["So", "wol\u00b7len", "sel\u00b7bi\u00b7ge", "mit", "kla\u00b7ren", "Wor\u00b7ten", "sa\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ADV", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Sie sey vielf\u00e4ltig werth/ dergleichen Schmuck zu tragen.", "tokens": ["Sie", "sey", "viel\u00b7f\u00e4l\u00b7tig", "werth", "/", "derg\u00b7lei\u00b7chen", "Schmuck", "zu", "tra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "ADJD", "$(", "PIS", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.20": {"line.1": {"text": "Wenn alles Silber-Zeug", "tokens": ["Wenn", "al\u00b7les", "Sil\u00b7ber\u00b7Zeug"], "token_info": ["word", "word", "word"], "pos": ["KOUS", "PIS", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Und sich das schwartze Tuch", "tokens": ["Und", "sich", "das", "schwart\u00b7ze", "Tuch"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PRF", "ART", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "So w\u00e4r es nicht genug Sie w\u00fcrdig zu verehren;", "tokens": ["So", "w\u00e4r", "es", "nicht", "ge\u00b7nug", "Sie", "w\u00fcr\u00b7dig", "zu", "ver\u00b7eh\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PTKNEG", "ADV", "PPER", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "W\u00e4r auch die theure Cron an Steinen noch so schwer/", "tokens": ["W\u00e4r", "auch", "die", "theu\u00b7re", "Cron", "an", "Stei\u00b7nen", "noch", "so", "schwer", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "ADJA", "NN", "APPR", "NN", "ADV", "ADV", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die von dem Sarge pflegt mit Schimmer vorzublicken/", "tokens": ["Die", "von", "dem", "Sar\u00b7ge", "pflegt", "mit", "Schim\u00b7mer", "vor\u00b7zu\u00b7bli\u00b7cken", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "VVFIN", "APPR", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "So w\u00e4r sie doch zu leicht/ Sie w\u00fcrdigst auszuschm\u00fccken.", "tokens": ["So", "w\u00e4r", "sie", "doch", "zu", "leicht", "/", "Sie", "w\u00fcr\u00b7digst", "aus\u00b7zu\u00b7schm\u00fc\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "PTKA", "ADJD", "$(", "PPER", "VAFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.21": {"line.1": {"text": "Wer so ein Tugend-Bild zu schildern sich bem\u00fcht/", "tokens": ["Wer", "so", "ein", "Tu\u00b7gen\u00b7dBild", "zu", "schil\u00b7dern", "sich", "be\u00b7m\u00fcht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "ART", "NN", "PTKZU", "VVFIN", "PRF", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Dem geht es/ gleichwie dem/ der in die Sonne schauet/", "tokens": ["Dem", "geht", "es", "/", "gleich\u00b7wie", "dem", "/", "der", "in", "die", "Son\u00b7ne", "schau\u00b7et", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "$(", "KON", "ART", "$(", "ART", "APPR", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und dieses g\u00f6ldne Licht zu mahlen sich getrauet/", "tokens": ["Und", "die\u00b7ses", "g\u00f6ld\u00b7ne", "Licht", "zu", "mah\u00b7len", "sich", "ge\u00b7trau\u00b7et", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDAT", "ADJA", "NN", "PTKZU", "VVINF", "PRF", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Alleine halb-verblendt mit Schimpfs zur\u00fccke sieht.", "tokens": ["Al\u00b7lei\u00b7ne", "halb\u00b7ver\u00b7blendt", "mit", "Schimpfs", "zu\u00b7r\u00fc\u00b7cke", "sieht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "APPR", "NN", "VVFIN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Drum wie der Sonnen Glantz sich nicht kan bilden lassen/", "tokens": ["Drum", "wie", "der", "Son\u00b7nen", "Glantz", "sich", "nicht", "kan", "bil\u00b7den", "las\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "KOKOM", "ART", "NN", "NN", "PRF", "PTKNEG", "VMFIN", "VVINF", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "So kan der Gr\u00e4fin Lob auch keine Bildung fassen.", "tokens": ["So", "kan", "der", "Gr\u00e4\u00b7fin", "Lob", "auch", "kei\u00b7ne", "Bil\u00b7dung", "fas\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "NN", "NN", "ADV", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.22": {"line.1": {"text": "Wer sonsten von dem Ruhm erhabner Leute singt/", "tokens": ["Wer", "sons\u00b7ten", "von", "dem", "Ruhm", "er\u00b7hab\u00b7ner", "Leu\u00b7te", "singt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "APPR", "ART", "NN", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Pflegt meist aus falschen Thon sein Singen anzufangen/", "tokens": ["Pflegt", "meist", "aus", "fal\u00b7schen", "Thon", "sein", "Sin\u00b7gen", "an\u00b7zu\u00b7fan\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ADV", "APPR", "ADJA", "NN", "PPOSAT", "NN", "VVIZU", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Bi\u00df er sich endlich hat in solchem \u00fcbergangen/", "tokens": ["Bi\u00df", "er", "sich", "end\u00b7lich", "hat", "in", "sol\u00b7chem", "\u00fc\u00b7ber\u00b7gan\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ADV", "VAFIN", "APPR", "PIAT", "ADJA", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Da\u00df es/ zu Schimpfs und Spott/ verstimmt am Ende klingt;", "tokens": ["Da\u00df", "es", "/", "zu", "Schimpfs", "und", "Spott", "/", "ver\u00b7stimmt", "am", "En\u00b7de", "klingt", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$(", "APPR", "NN", "KON", "NN", "$(", "VVFIN", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Allein so Freund als Feind/ so Lieb als Neid gestehet/", "tokens": ["Al\u00b7lein", "so", "Freund", "als", "Feind", "/", "so", "Lieb", "als", "Neid", "ge\u00b7ste\u00b7het", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "NN", "KOUS", "NN", "$(", "ADV", "NN", "KOUS", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Da\u00df unser Gr\u00e4fin Lob weit \u00fcber alles gehet.", "tokens": ["Da\u00df", "un\u00b7ser", "Gr\u00e4\u00b7fin", "Lob", "weit", "\u00fc\u00b7ber", "al\u00b7les", "ge\u00b7het", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "NN", "ADJD", "APPR", "PIS", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.23": {"line.1": {"text": "Es r\u00fchmt der Zeiten Ruff l\u00e4ngst Ihren Tugend-Pracht;", "tokens": ["Es", "r\u00fchmt", "der", "Zei\u00b7ten", "Ruff", "l\u00e4ngst", "Ih\u00b7ren", "Tu\u00b7gen\u00b7dPracht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "NN", "ADV", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Doch dringt die ", "tokens": ["Doch", "dringt", "die"], "token_info": ["word", "word", "word"], "pos": ["KON", "VVFIN", "ART"], "meter": "-+-", "measure": "amphibrach.single"}, "line.3": {"text": "Vor welcher Gottheit auch die schwartz-bew\u00f6lckten D\u00fcffte", "tokens": ["Vor", "wel\u00b7cher", "Got\u00b7theit", "auch", "die", "schwartz\u00b7be\u00b7w\u00f6lck\u00b7ten", "D\u00fcff\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PWAT", "NN", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Sich haben aufgekl\u00e4hrt/ und ihr den Weg gemacht:", "tokens": ["Sich", "ha\u00b7ben", "auf\u00b7ge\u00b7kl\u00e4hrt", "/", "und", "ihr", "den", "Weg", "ge\u00b7macht", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "VAFIN", "VVPP", "$(", "KON", "PPER", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "So lange solche nun wird \u00e4chtes Lob erh\u00f6hen/", "tokens": ["So", "lan\u00b7ge", "sol\u00b7che", "nun", "wird", "\u00e4ch\u00b7tes", "Lob", "er\u00b7h\u00f6\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PIAT", "ADV", "VAFIN", "ADJA", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wird Dero Nahme nicht durch ihre Hand vergehen.", "tokens": ["Wird", "De\u00b7ro", "Nah\u00b7me", "nicht", "durch", "ih\u00b7re", "Hand", "ver\u00b7ge\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PDS", "NN", "PTKNEG", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.24": {"line.1": {"text": "Jedoch die Liebe wird Ihr l\u00e4nger dienstbar seyn:", "tokens": ["Je\u00b7doch", "die", "Lie\u00b7be", "wird", "Ihr", "l\u00e4n\u00b7ger", "dienst\u00b7bar", "seyn", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VAFIN", "PPER", "ADJD", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wenn Glaub und Hoffnung einst wird in der Welt vergehen/", "tokens": ["Wenn", "Glaub", "und", "Hoff\u00b7nung", "einst", "wird", "in", "der", "Welt", "ver\u00b7ge\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "NN", "ADV", "VAFIN", "APPR", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wird Sie die Liebe noch zur Ehr und Lust erh\u00f6hen.", "tokens": ["Wird", "Sie", "die", "Lie\u00b7be", "noch", "zur", "Ehr", "und", "Lust", "er\u00b7h\u00f6\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "NN", "ADV", "APPRART", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Sie strahlt auch schon durch Ihr mit ungemeinen Schein:", "tokens": ["Sie", "strahlt", "auch", "schon", "durch", "Ihr", "mit", "un\u00b7ge\u00b7mei\u00b7nen", "Schein", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "APPR", "PPER", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Sie hat das Lamm geliebt/", "tokens": ["Sie", "hat", "das", "Lamm", "ge\u00b7liebt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Den Gottes Lamm gestifft/ ein theures Mitglied worden.", "tokens": ["Den", "Got\u00b7tes", "Lamm", "ge\u00b7stifft", "/", "ein", "theu\u00b7res", "Mit\u00b7glied", "wor\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVPP", "$(", "ART", "ADJA", "NN", "VAPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.25": {"line.1": {"text": "Gott stellet nun mit Ihr des Lammes Hochzeit an.", "tokens": ["Gott", "stel\u00b7let", "nun", "mit", "Ihr", "des", "Lam\u00b7mes", "Hoch\u00b7zeit", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ADV", "APPR", "PPOSAT", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die Liebe kan das Lamm nun in der That genie\u00dfen/", "tokens": ["Die", "Lie\u00b7be", "kan", "das", "Lamm", "nun", "in", "der", "That", "ge\u00b7nie\u00b7\u00dfen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "ART", "NN", "ADV", "APPR", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Das blo\u00df die Hoffnung hier so freudig hat geprie\u00dfen:", "tokens": ["Das", "blo\u00df", "die", "Hoff\u00b7nung", "hier", "so", "freu\u00b7dig", "hat", "ge\u00b7prie\u00b7\u00dfen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "ART", "NN", "ADV", "ADV", "ADJD", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Es wird Ihr nun von Ihm auf ewig wohlgethan.", "tokens": ["Es", "wird", "Ihr", "nun", "von", "Ihm", "auf", "e\u00b7wig", "wohl\u00b7ge\u00b7than", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "APPR", "PPER", "APPR", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Allein Ihr Wohlseyn will uns nichts/ als Weh/ geb\u00e4hren/", "tokens": ["Al\u00b7lein", "Ihr", "Wohl\u00b7seyn", "will", "uns", "nichts", "/", "als", "Weh", "/", "ge\u00b7b\u00e4h\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "VMFIN", "PPER", "PIS", "$(", "KOUS", "NN", "$(", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und Ihr Verlust erpre\u00dft von uns viel tausend Z\u00e4hren.", "tokens": ["Und", "Ihr", "Ver\u00b7lust", "er\u00b7pre\u00dft", "von", "uns", "viel", "tau\u00b7send", "Z\u00e4h\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "APPR", "PPER", "ADV", "CARD", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.26": {"line.1": {"text": "Drum hemmt mein Schwartzburg auch die milden Thr\u00e4nen nicht/", "tokens": ["Drum", "hemmt", "mein", "Schwartz\u00b7burg", "auch", "die", "mil\u00b7den", "Thr\u00e4\u00b7nen", "nicht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPOSAT", "NN", "ADV", "ART", "ADJA", "NN", "PTKNEG", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Weil ihm das theure Rei\u00df von Barby ist entrissen:", "tokens": ["Weil", "ihm", "das", "theu\u00b7re", "Rei\u00df", "von", "Bar\u00b7by", "ist", "ent\u00b7ris\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "APPR", "NE", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und weil mit Ihm der Stamm ist g\u00e4ntzlich umgeschmissen/", "tokens": ["Und", "weil", "mit", "Ihm", "der", "Stamm", "ist", "g\u00e4ntz\u00b7lich", "um\u00b7ge\u00b7schmis\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "APPR", "PPER", "ART", "NN", "VAFIN", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Sieht man wie Barby selbst f\u00fcr Leid sein Wappen bricht:", "tokens": ["Sieht", "man", "wie", "Bar\u00b7by", "selbst", "f\u00fcr", "Leid", "sein", "Wap\u00b7pen", "bricht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "KOKOM", "NE", "ADV", "APPR", "NN", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Drum k\u00f6nnen wir mit Recht die Kleider auch zerreissen/", "tokens": ["Drum", "k\u00f6n\u00b7nen", "wir", "mit", "Recht", "die", "Klei\u00b7der", "auch", "zer\u00b7reis\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VMFIN", "PPER", "APPR", "NN", "ART", "NN", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und Schwartzburg seinen Schmuck f\u00fcr Wehmuth von sich schmeissen.", "tokens": ["Und", "Schwartz\u00b7burg", "sei\u00b7nen", "Schmuck", "f\u00fcr", "Weh\u00b7muth", "von", "sich", "schmeis\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "PPOSAT", "NN", "APPR", "NN", "APPR", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.27": {"line.1": {"text": "Ach qvillet/ Z\u00e4hren/ qvillt! ergie\u00df dich/ Thr\u00e4nen-Bach!", "tokens": ["Ach", "qvil\u00b7let", "/", "Z\u00e4h\u00b7ren", "/", "qvillt", "!", "er\u00b7gie\u00df", "dich", "/", "Thr\u00e4\u00b7nen\u00b7Bach", "!"], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ITJ", "VVFIN", "$(", "NN", "$(", "VVFIN", "$.", "VVFIN", "PPER", "$(", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ob ich gleich schon so viel der Thr\u00e4nen Fluht vergossen/", "tokens": ["Ob", "ich", "gleich", "schon", "so", "viel", "der", "Thr\u00e4\u00b7nen", "Fluht", "ver\u00b7gos\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "ADV", "ADV", "ART", "NN", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Da\u00df fast der Lebens-Geist mit ihnen fortgeflossen/", "tokens": ["Da\u00df", "fast", "der", "Le\u00b7bens\u00b7Geist", "mit", "ih\u00b7nen", "fort\u00b7ge\u00b7flos\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "APPR", "PPER", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und ich nichts sprechen kan/ als lauter Weh und Ach!", "tokens": ["Und", "ich", "nichts", "spre\u00b7chen", "kan", "/", "als", "lau\u00b7ter", "Weh", "und", "Ach", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "PIS", "VVINF", "VMFIN", "$(", "KOKOM", "PIAT", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ja weil die Kirche nichts f\u00fcr Jammer mehr kan sagen/", "tokens": ["Ja", "weil", "die", "Kir\u00b7che", "nichts", "f\u00fcr", "Jam\u00b7mer", "mehr", "kan", "sa\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "KOUS", "ART", "NN", "PIS", "APPR", "NN", "ADV", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "So helfft/ ihr Schulen/ auch den Jammer mit beklagen.", "tokens": ["So", "helfft", "/", "ihr", "Schu\u00b7len", "/", "auch", "den", "Jam\u00b7mer", "mit", "be\u00b7kla\u00b7gen", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$(", "PPOSAT", "NN", "$(", "ADV", "ART", "NN", "APPR", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.28": {"line.1": {"text": "Kommt/ T\u00f6chter Salems/ kommt/ und schaut mein Leiden an/", "tokens": ["Kommt", "/", "T\u00f6ch\u00b7ter", "Sa\u00b7lems", "/", "kommt", "/", "und", "schaut", "mein", "Lei\u00b7den", "an", "/"], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$(", "NN", "NE", "$(", "VVFIN", "$(", "KON", "VVFIN", "PPOSAT", "NN", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und wenn nicht euer Hertz von Eisen/ Stahl und Steinen/", "tokens": ["Und", "wenn", "nicht", "eu\u00b7er", "Hertz", "von", "Ei\u00b7sen", "/", "Stahl", "und", "Stei\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PTKNEG", "PPOSAT", "NN", "APPR", "NN", "$(", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "So seuffzet auch mit mir/ helfft eurer Schwester weinen/", "tokens": ["So", "seuff\u00b7zet", "auch", "mit", "mir", "/", "helfft", "eu\u00b7rer", "Schwes\u00b7ter", "wei\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "APPR", "PPER", "$(", "VVFIN", "PPOSAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Weil ihr der Himmel hat im Zorne weh gethan.", "tokens": ["Weil", "ihr", "der", "Him\u00b7mel", "hat", "im", "Zor\u00b7ne", "weh", "ge\u00b7than", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VAFIN", "APPRART", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Mich hat des H\u00f6chsten Hand im Grimme wund geschlagen/", "tokens": ["Mich", "hat", "des", "H\u00f6chs\u00b7ten", "Hand", "im", "Grim\u00b7me", "wund", "ge\u00b7schla\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "APPRART", "NN", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Drum kommt und helffet mir den Schmertzen mit beklagen.", "tokens": ["Drum", "kommt", "und", "helf\u00b7fet", "mir", "den", "Schmert\u00b7zen", "mit", "be\u00b7kla\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "KON", "VVFIN", "PPER", "ART", "NN", "APPR", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.29": {"line.1": {"text": "Schaut meines Tempels Pracht/ wie solcher sich verstellt.", "tokens": ["Schaut", "mei\u00b7nes", "Tem\u00b7pels", "Pracht", "/", "wie", "sol\u00b7cher", "sich", "ver\u00b7stellt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "NN", "$(", "KOKOM", "PIAT", "PRF", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ich reisse Gold und Schmuck von dem bekr\u00f6nten Haare:", "tokens": ["Ich", "reis\u00b7se", "Gold", "und", "Schmuck", "von", "dem", "be\u00b7kr\u00f6n\u00b7ten", "Haa\u00b7re", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "KON", "NN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Denn selbst mein Heiligthum liegt auf der Todten-Bahre/", "tokens": ["Denn", "selbst", "mein", "Hei\u00b7lig\u00b7thum", "liegt", "auf", "der", "Tod\u00b7ten\u00b7Bah\u00b7re", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PPOSAT", "NN", "VVFIN", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Mein Kirchen-Pfeiler bricht/ mein Bet-Altar zerf\u00e4llt/", "tokens": ["Mein", "Kir\u00b7chen\u00b7Pfei\u00b7ler", "bricht", "/", "mein", "Bet\u00b7Al\u00b7tar", "zer\u00b7f\u00e4llt", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "$(", "PPOSAT", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Man h\u00f6ret itzo nichts in meines Tempels Hallen/", "tokens": ["Man", "h\u00f6\u00b7ret", "it\u00b7zo", "nichts", "in", "mei\u00b7nes", "Tem\u00b7pels", "Hal\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ADV", "PIS", "APPR", "PPOSAT", "NN", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Als vieler Klagen Hall verdoppelt wiederschallen.", "tokens": ["Als", "vie\u00b7ler", "Kla\u00b7gen", "Hall", "ver\u00b7dop\u00b7pelt", "wie\u00b7der\u00b7schal\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "NN", "NE", "VVPP", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.30": {"line.1": {"text": "Mein Halleluja kehrt sich in Eleison/", "tokens": ["Mein", "Hal\u00b7le\u00b7lu\u00b7ja", "kehrt", "sich", "in", "E\u00b7lei\u00b7son", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PRF", "APPR", "NE", "$("], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Mein frohes S\u00e4itenspiel verwandelt sich in Heulen/", "tokens": ["Mein", "fro\u00b7hes", "S\u00e4i\u00b7ten\u00b7spiel", "ver\u00b7wan\u00b7delt", "sich", "in", "Heu\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVFIN", "PRF", "APPR", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Gebet und Sang mu\u00df sich in Ach und Weh zertheilen/", "tokens": ["Ge\u00b7bet", "und", "Sang", "mu\u00df", "sich", "in", "Ach", "und", "Weh", "zer\u00b7thei\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VMFIN", "PRF", "APPR", "NN", "KON", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Auf meinem Chore klingt ein steter Klage-Thon.", "tokens": ["Auf", "mei\u00b7nem", "Cho\u00b7re", "klingt", "ein", "ste\u00b7ter", "Kla\u00b7ge\u00b7Thon", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und wie soll nicht das Leid durch meine Geister dringen/", "tokens": ["Und", "wie", "soll", "nicht", "das", "Leid", "durch", "mei\u00b7ne", "Geis\u00b7ter", "drin\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "VMFIN", "PTKNEG", "ART", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Weil ich statt ", "tokens": ["Weil", "ich", "statt"], "token_info": ["word", "word", "word"], "pos": ["KOUS", "PPER", "VVFIN"], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.31": {"line.1": {"text": "Ich lege Boy und Flor nicht nach Gewohnheit an/", "tokens": ["Ich", "le\u00b7ge", "Boy", "und", "Flor", "nicht", "nach", "Ge\u00b7wohn\u00b7heit", "an", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NE", "KON", "NN", "PTKNEG", "APPR", "NN", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ich weine nicht zum Staat/ ich klage nicht zum Scheine:", "tokens": ["Ich", "wei\u00b7ne", "nicht", "zum", "Staat", "/", "ich", "kla\u00b7ge", "nicht", "zum", "Schei\u00b7ne", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "APPRART", "NN", "$(", "PPER", "VVFIN", "PTKNEG", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Denn ein so grosser Fall zerqvetschet Marck und Beine.", "tokens": ["Denn", "ein", "so", "gros\u00b7ser", "Fall", "zer\u00b7qvet\u00b7schet", "Marck", "und", "Bei\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADV", "ADJA", "NN", "VVFIN", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Es ist nun fast um mich und um mein Heil gethan;", "tokens": ["Es", "ist", "nun", "fast", "um", "mich", "und", "um", "mein", "Heil", "ge\u00b7than", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "APPR", "PPER", "KON", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Weil meine Hanna todt/ die durch ihr stetes Beten/", "tokens": ["Weil", "mei\u00b7ne", "Han\u00b7na", "todt", "/", "die", "durch", "ihr", "ste\u00b7tes", "Be\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "ADJD", "$(", "ART", "APPR", "PPOSAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Bey manchem Ungl\u00fccks-Sturm ist vor den Ri\u00df getreten.", "tokens": ["Bey", "man\u00b7chem", "Un\u00b7gl\u00fccks\u00b7Sturm", "ist", "vor", "den", "Ri\u00df", "ge\u00b7tre\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VAFIN", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.32": {"line.1": {"text": "Und da ich mehr von Ihr zu r\u00fchmen willens bin/", "tokens": ["Und", "da", "ich", "mehr", "von", "Ihr", "zu", "r\u00fch\u00b7men", "wil\u00b7lens", "bin", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "APPR", "PPER", "PTKZU", "VVINF", "NN", "VAFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Will mich/ wie Nioben/ der Jammer fast entseelen.", "tokens": ["Will", "mich", "/", "wie", "Ni\u00b7o\u00b7ben", "/", "der", "Jam\u00b7mer", "fast", "ent\u00b7see\u00b7len", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "$(", "KOKOM", "NE", "$(", "ART", "NN", "ADV", "VVINF", "$."], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.3": {"text": "Der Mund erstarret schon/ ich kan nichts mehr erzehlen/", "tokens": ["Der", "Mund", "er\u00b7star\u00b7ret", "schon", "/", "ich", "kan", "nichts", "mehr", "er\u00b7zeh\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "$(", "PPER", "VMFIN", "PIS", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und weis/ als Todte/ nur auf", "tokens": ["Und", "weis", "/", "als", "Tod\u00b7te", "/", "nur", "auf"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["KON", "PTKVZ", "$(", "KOUS", "NN", "$(", "ADV", "APPR"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.5": {"text": "Die stummen ", "tokens": ["Die", "stum\u00b7men"], "token_info": ["word", "word"], "pos": ["ART", "ADJA"], "meter": "-+-", "measure": "amphibrach.single"}, "line.6": {"text": "Was ich und was mit mir ein jeder hilfft beklagen:", "tokens": ["Was", "ich", "und", "was", "mit", "mir", "ein", "je\u00b7der", "hilfft", "be\u00b7kla\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "KON", "PWS", "APPR", "PPER", "ART", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.33": {"line.1": {"text": "Schaut her/ wie um den Sarg nichts als nur", "tokens": ["Schaut", "her", "/", "wie", "um", "den", "Sarg", "nichts", "als", "nur"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PTKVZ", "$(", "KOKOM", "APPR", "ART", "NN", "PIS", "KOKOM", "ADV"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Die uns ein Zeugni\u00df giebt vom rechten Tugend-Triebe:", "tokens": ["Die", "uns", "ein", "Zeug\u00b7ni\u00df", "giebt", "vom", "rech\u00b7ten", "Tu\u00b7gen\u00b7dTrie\u00b7be", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ART", "NN", "VVFIN", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "In dessen Circkel ist der Mittel-Punct der Liebe/", "tokens": ["In", "des\u00b7sen", "Cir\u00b7ckel", "ist", "der", "Mit\u00b7tel\u00b7Punct", "der", "Lie\u00b7be", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELAT", "NN", "VAFIN", "ART", "NN", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Weil von/ durch und zu ihr die \u00e4chte Tugend geht.", "tokens": ["Weil", "von", "/", "durch", "und", "zu", "ihr", "die", "\u00e4ch\u00b7te", "Tu\u00b7gend", "geht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "$(", "APPR", "KON", "APPR", "PPER", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Drum weil die Liebe selbst zum letzten Dienst erkohren/", "tokens": ["Drum", "weil", "die", "Lie\u00b7be", "selbst", "zum", "letz\u00b7ten", "Dienst", "er\u00b7koh\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "KOUS", "ART", "NN", "ADV", "APPRART", "ADJA", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "So sieht man/ da\u00df mein Land was Liebes hat verlohren.", "tokens": ["So", "sieht", "man", "/", "da\u00df", "mein", "Land", "was", "Lie\u00b7bes", "hat", "ver\u00b7loh\u00b7ren", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "$(", "KOUS", "PPOSAT", "NN", "PWS", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.34": {"line.1": {"text": "Der aber liebet recht/ der", "tokens": ["Der", "a\u00b7ber", "lie\u00b7bet", "recht", "/", "der"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["ART", "ADV", "VVFIN", "ADJD", "$(", "ART"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Die", "tokens": ["Die"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}, "line.3": {"text": "Wie jener", "tokens": ["Wie", "je\u00b7ner"], "token_info": ["word", "word"], "pos": ["PWAV", "PDS"], "meter": "-+-", "measure": "amphibrach.single"}, "line.4": {"text": "Der von dem Paradie\u00df den sch\u00f6nen Rahmen tr\u00e4gt/", "tokens": ["Der", "von", "dem", "Pa\u00b7ra\u00b7die\u00df", "den", "sch\u00f6\u00b7nen", "Rah\u00b7men", "tr\u00e4gt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "ART", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Als welchem die Natur l\u00e4\u00dft keine F\u00fcsse geben/", "tokens": ["Als", "wel\u00b7chem", "die", "Na\u00b7tur", "l\u00e4\u00dft", "kei\u00b7ne", "F\u00fcs\u00b7se", "ge\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRELS", "ART", "NN", "VVFIN", "PIAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Da\u00df er im Himmel soll/ nicht auf der Erden/ leben.", "tokens": ["Da\u00df", "er", "im", "Him\u00b7mel", "soll", "/", "nicht", "auf", "der", "Er\u00b7den", "/", "le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "PPER", "APPRART", "NN", "VMFIN", "$(", "PTKNEG", "APPR", "ART", "NN", "$(", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.35": {"line.1": {"text": "Glaub'/ Hoffnung/ Tugend", "tokens": ["Glaub'", "/", "Hoff\u00b7nung", "/", "Tu\u00b7gend"], "token_info": ["word", "punct", "word", "punct", "word"], "pos": ["NN", "$(", "NN", "$(", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.2": {"text": "Da\u00df unsrer Gr\u00e4fin Geist/ weil er vom Himmel kommen/", "tokens": ["Da\u00df", "uns\u00b7rer", "Gr\u00e4\u00b7fin", "Geist", "/", "weil", "er", "vom", "Him\u00b7mel", "kom\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "NN", "$(", "KOUS", "PPER", "APPRART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Nicht leicht was irdisches an sich hat angenommen.", "tokens": ["Nicht", "leicht", "was", "ir\u00b7di\u00b7sches", "an", "sich", "hat", "an\u00b7ge\u00b7nom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADJD", "PWS", "ADJA", "APPR", "PRF", "VAFIN", "VVPP", "$."], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Und weil ihr Lieben frey von Fremden Feuer war/", "tokens": ["Und", "weil", "ihr", "Lie\u00b7ben", "frey", "von", "Frem\u00b7den", "Feu\u00b7er", "war", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPOSAT", "ADJA", "NN", "APPR", "NN", "NN", "VAFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Hat man die Seltenheit um destomehr verehret/", "tokens": ["Hat", "man", "die", "Sel\u00b7ten\u00b7heit", "um", "des\u00b7to\u00b7mehr", "ver\u00b7eh\u00b7ret", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "ART", "NN", "APPR", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Da Stand und Sch\u00f6nheit hat derselben Pracht vermehret.", "tokens": ["Da", "Stand", "und", "Sch\u00f6n\u00b7heit", "hat", "der\u00b7sel\u00b7ben", "Pracht", "ver\u00b7meh\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "NN", "VAFIN", "PDAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.36": {"line.1": {"text": "Ob solcher Liebe Glut nun gleich zum Himmel geht/", "tokens": ["Ob", "sol\u00b7cher", "Lie\u00b7be", "Glut", "nun", "gleich", "zum", "Him\u00b7mel", "geht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "NN", "NN", "ADV", "ADV", "APPRART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Auch ihrem Jesu nur die Glaubens-Lampe brennet/", "tokens": ["Auch", "ih\u00b7rem", "Je\u00b7su", "nur", "die", "Glau\u00b7bens\u00b7Lam\u00b7pe", "bren\u00b7net", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NE", "ADV", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wird doch das Hertze nicht vom Nechsten abgetrennet/", "tokens": ["Wird", "doch", "das", "Hert\u00b7ze", "nicht", "vom", "Nechs\u00b7ten", "ab\u00b7ge\u00b7tren\u00b7net", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PDS", "VVFIN", "PTKNEG", "APPRART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Mit welchem es nechst Gott in treuer Liebe steht:", "tokens": ["Mit", "wel\u00b7chem", "es", "nechst", "Gott", "in", "treu\u00b7er", "Lie\u00b7be", "steht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "VVFIN", "NN", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Denn wer die Liebe nicht mit Menschen wei\u00df zu \u00fcben/", "tokens": ["Denn", "wer", "die", "Lie\u00b7be", "nicht", "mit", "Men\u00b7schen", "wei\u00df", "zu", "\u00fc\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ART", "NN", "PTKNEG", "APPR", "NN", "VVFIN", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wie kan der seinen Gott/ den er nicht siehet/ lieben?", "tokens": ["Wie", "kan", "der", "sei\u00b7nen", "Gott", "/", "den", "er", "nicht", "sie\u00b7het", "/", "lie\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PWAV", "VMFIN", "ART", "PPOSAT", "NN", "$(", "PRELS", "PPER", "PTKNEG", "VVFIN", "$(", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.37": {"line.1": {"text": "Der Himmels-Liebe k\u00f6mmt fast Ehe-Liebe bey/", "tokens": ["Der", "Him\u00b7mels\u00b7Lie\u00b7be", "k\u00f6mmt", "fast", "E\u00b7he\u00b7Lie\u00b7be", "bey", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "NN", "APPR", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Indem derselben Glut/ wenn Tugend sie entz\u00fcndet/", "tokens": ["In\u00b7dem", "der\u00b7sel\u00b7ben", "Glut", "/", "wenn", "Tu\u00b7gend", "sie", "ent\u00b7z\u00fcn\u00b7det", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDAT", "NN", "$(", "KOUS", "NN", "PPER", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Auch mit dem Lebens-Licht im Tode nicht verschwindet:", "tokens": ["Auch", "mit", "dem", "Le\u00b7bens\u00b7Licht", "im", "To\u00b7de", "nicht", "ver\u00b7schwin\u00b7det", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "APPRART", "NN", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Denn in der Asche glimmt noch Glut von ihrer Treu.", "tokens": ["Denn", "in", "der", "A\u00b7sche", "glimmt", "noch", "Glut", "von", "ih\u00b7rer", "Treu", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVFIN", "ADV", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Gleichwie der Tod nur kan bey denen Turtel-Tauben", "tokens": ["Gleich\u00b7wie", "der", "Tod", "nur", "kan", "bey", "de\u00b7nen", "Tur\u00b7tel\u00b7Tau\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "ADV", "VMFIN", "APPR", "PRELS", "NN"], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Das Leben/ aber nicht die treue Liebe/ rauben.", "tokens": ["Das", "Le\u00b7ben", "/", "a\u00b7ber", "nicht", "die", "treu\u00b7e", "Lie\u00b7be", "/", "rau\u00b7ben", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "$(", "ADV", "PTKNEG", "ART", "ADJA", "NN", "$(", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.38": {"line.1": {"text": "Selbst Dero Eh-gemahl bezeugt aus treuer Pflicht/", "tokens": ["Selbst", "De\u00b7ro", "Eh\u00b7ge\u00b7mahl", "be\u00b7zeugt", "aus", "treu\u00b7er", "Pflicht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PDS", "NN", "VVFIN", "APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Da\u00df solche Liebe nie bey ihr hat aufgeh\u00f6ret.", "tokens": ["Da\u00df", "sol\u00b7che", "Lie\u00b7be", "nie", "bey", "ihr", "hat", "auf\u00b7ge\u00b7h\u00f6\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "NN", "ADV", "APPR", "PPER", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Bi\u00df da\u00df sich durch den Tod das Feuer hat verzehret.", "tokens": ["Bi\u00df", "da\u00df", "sich", "durch", "den", "Tod", "das", "Feu\u00b7er", "hat", "ver\u00b7zeh\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "KOUS", "PRF", "APPR", "ART", "NN", "ART", "NN", "VAFIN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Er glaubt/ die Glut verlescht auch in dem Grabe nicht:", "tokens": ["Er", "glaubt", "/", "die", "Glut", "ver\u00b7lescht", "auch", "in", "dem", "Gra\u00b7be", "nicht", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$(", "ART", "NN", "VVFIN", "ADV", "APPR", "ART", "NN", "PTKNEG", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Drum weil nach Palmen-Art sie gleiche Liebe hegen/", "tokens": ["Drum", "weil", "nach", "Pal\u00b7men\u00b7Art", "sie", "glei\u00b7che", "Lie\u00b7be", "he\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "KOUS", "APPR", "NN", "PPER", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Soll man sie auch im Tod in eine H\u00f6le", "tokens": ["Soll", "man", "sie", "auch", "im", "Tod", "in", "ei\u00b7ne", "H\u00f6\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "PIS", "PPER", "ADV", "APPRART", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.39": {"line.1": {"text": "Der Ehe-Liebe folgt die Mutter-Liebe nach.", "tokens": ["Der", "E\u00b7he\u00b7Lie\u00b7be", "folgt", "die", "Mut\u00b7ter\u00b7Lie\u00b7be", "nach", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Hier pflegt die Liebe denn mehr ab-als auf-zu steigen/", "tokens": ["Hier", "pflegt", "die", "Lie\u00b7be", "denn", "mehr", "ab\u00b7als", "auf\u00b7zu", "stei\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ADV", "PIAT", "NN", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und sich mit gr\u00f6ster Lust den Kindern zuzuneigen/", "tokens": ["Und", "sich", "mit", "gr\u00f6s\u00b7ter", "Lust", "den", "Kin\u00b7dern", "zu\u00b7zu\u00b7nei\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "APPR", "ADJA", "NN", "ART", "NN", "VVIZU", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Drum flieht sie keine M\u00fch und scheut kein Ungemach/", "tokens": ["Drum", "flieht", "sie", "kei\u00b7ne", "M\u00fch", "und", "scheut", "kein", "Un\u00b7ge\u00b7mach", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "PIAT", "NN", "KON", "VVFIN", "PIAT", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Da\u00df sie denselben m\u00f6g' im Auferziehen n\u00fctzen/", "tokens": ["Da\u00df", "sie", "den\u00b7sel\u00b7ben", "m\u00f6g'", "im", "Auf\u00b7er\u00b7zie\u00b7hen", "n\u00fct\u00b7zen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PDS", "VMFIN", "APPRART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und einer Henne gleich die jungen K\u00fcchlein sch\u00fctzen.", "tokens": ["Und", "ei\u00b7ner", "Hen\u00b7ne", "gleich", "die", "jun\u00b7gen", "K\u00fcch\u00b7lein", "sch\u00fct\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ADV", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.40": {"line.1": {"text": "Hier tr\u00e4gt die Gr\u00e4fin auch mit Ruhm den Prei\u00df davon.", "tokens": ["Hier", "tr\u00e4gt", "die", "Gr\u00e4\u00b7fin", "auch", "mit", "Ruhm", "den", "Prei\u00df", "da\u00b7von", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ADV", "APPR", "NN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wie eine Muschel kan die sch\u00f6nste Perl erzeugen/", "tokens": ["Wie", "ei\u00b7ne", "Mu\u00b7schel", "kan", "die", "sch\u00f6ns\u00b7te", "Perl", "er\u00b7zeu\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "VMFIN", "ART", "ADJA", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wenn alle Nahrungs-Krafft sich darff zu einer neigen;", "tokens": ["Wenn", "al\u00b7le", "Nah\u00b7rungs\u00b7Krafft", "sich", "darff", "zu", "ei\u00b7ner", "nei\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "NN", "PRF", "PAV", "APPR", "PIS", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So war ihr gleichfalls auch der Hochgebohrne Sohn/", "tokens": ["So", "war", "ihr", "gleich\u00b7falls", "auch", "der", "Hoch\u00b7ge\u00b7bohr\u00b7ne", "Sohn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ADV", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Den sie alleine hat f\u00fcrtrefflich wohl gepflogen/", "tokens": ["Den", "sie", "al\u00b7lei\u00b7ne", "hat", "f\u00fcr\u00b7treff\u00b7lich", "wohl", "ge\u00b7pflo\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "VAFIN", "ADJD", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und durch Gebet und Flei\u00df so herrlich auferzogen.", "tokens": ["Und", "durch", "Ge\u00b7bet", "und", "Flei\u00df", "so", "herr\u00b7lich", "auf\u00b7er\u00b7zo\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "KON", "NN", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.41": {"line.1": {"text": "De\u00dfwegen klagt Er auch/ da\u00df seine Zierd und Lust", "tokens": ["De\u00df\u00b7we\u00b7gen", "klagt", "Er", "auch", "/", "da\u00df", "sei\u00b7ne", "Zierd", "und", "Lust"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "PPER", "ADV", "$(", "KOUS", "PPOSAT", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Gleich einer Rosen f\u00e4llt;", "tokens": ["Gleich", "ei\u00b7ner", "Ro\u00b7sen", "f\u00e4llt", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Den die Durchlauchtigste", "tokens": ["Den", "die", "Durch\u00b7lauch\u00b7tigs\u00b7te"], "token_info": ["word", "word", "word"], "pos": ["ART", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Der Kindes-Kinder", "tokens": ["Der", "Kin\u00b7des\u00b7Kin\u00b7der"], "token_info": ["word", "word"], "pos": ["ART", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.5": {"text": "Da\u00df sie nicht weiter soll dergleichen Wartung laben/", "tokens": ["Da\u00df", "sie", "nicht", "wei\u00b7ter", "soll", "derg\u00b7lei\u00b7chen", "War\u00b7tung", "la\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "ADV", "VMFIN", "PIS", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wovon sie h\u00f6chst-vergn\u00fcgt viel Wachsthum w\u00fcrden haben.", "tokens": ["Wo\u00b7von", "sie", "h\u00f6chst\u00b7ver\u00b7gn\u00fcgt", "viel", "Wach\u00b7sthum", "w\u00fcr\u00b7den", "ha\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VVFIN", "PIAT", "NN", "VAFIN", "VAINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.42": {"line.1": {"text": "Doch mu\u00df die Liebe noch bey Christen weiter gehn/", "tokens": ["Doch", "mu\u00df", "die", "Lie\u00b7be", "noch", "bey", "Chris\u00b7ten", "wei\u00b7ter", "gehn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ART", "NN", "ADV", "APPR", "NN", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und mu\u00df auch ihre Frucht an fremde Leute zahlen/", "tokens": ["Und", "mu\u00df", "auch", "ih\u00b7re", "Frucht", "an", "frem\u00b7de", "Leu\u00b7te", "zah\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ADV", "PPOSAT", "NN", "APPR", "ADJA", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Doch nicht den Heyden gleich mit ihren Gaben pralen", "tokens": ["Doch", "nicht", "den", "Hey\u00b7den", "gleich", "mit", "ih\u00b7ren", "Ga\u00b7ben", "pra\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PTKNEG", "ART", "NN", "ADV", "APPR", "PPOSAT", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Bey solcher G\u00fcte kan kein Mangel nicht entstehn/", "tokens": ["Bey", "sol\u00b7cher", "G\u00fc\u00b7te", "kan", "kein", "Man\u00b7gel", "nicht", "ent\u00b7stehn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VMFIN", "PIAT", "NN", "PTKNEG", "VVINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wenn man aus Liebe gleich/ um andern nur zu n\u00fctzen/", "tokens": ["Wenn", "man", "aus", "Lie\u00b7be", "gleich", "/", "um", "an\u00b7dern", "nur", "zu", "n\u00fct\u00b7zen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "APPR", "NN", "ADV", "$(", "APPR", "PIS", "ADV", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "L\u00e4\u00dft wie ein Pelican/", "tokens": ["L\u00e4\u00dft", "wie", "ein", "Pe\u00b7li\u00b7can", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KOKOM", "ART", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.43": {"line.1": {"text": "Zu Zeugen stehen dar Hof/ ", "tokens": ["Zu", "Zeu\u00b7gen", "ste\u00b7hen", "dar", "Hof", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PTKVZ", "NN", "$("], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Die sie/ als ein Magnet/", "tokens": ["Die", "sie", "/", "als", "ein", "Mag\u00b7net", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "$(", "KOUS", "ART", "NN", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Und f\u00fcr derselben Heil stets Sorge hat gepflogen/", "tokens": ["Und", "f\u00fcr", "der\u00b7sel\u00b7ben", "Heil", "stets", "Sor\u00b7ge", "hat", "ge\u00b7pflo\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PDAT", "NN", "ADV", "NN", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Drum stunde Schwartzburg stets im h\u00f6chst-begl\u00fcckten Stand/", "tokens": ["Drum", "stun\u00b7de", "Schwartz\u00b7burg", "stets", "im", "h\u00f6chst\u00b7be\u00b7gl\u00fcck\u00b7ten", "Stand", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ADJA", "NN", "ADV", "APPRART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Bi\u00df da\u00df sein Baum verdorrt/ der Nutzen hat gegeben/", "tokens": ["Bi\u00df", "da\u00df", "sein", "Baum", "ver\u00b7dorrt", "/", "der", "Nut\u00b7zen", "hat", "ge\u00b7ge\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "KOUS", "PPOSAT", "NN", "VVPP", "$(", "ART", "NN", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und nur noch oben pflegt zu bl\u00fchen und zu leben.", "tokens": ["Und", "nur", "noch", "o\u00b7ben", "pflegt", "zu", "bl\u00fc\u00b7hen", "und", "zu", "le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "ADV", "VVFIN", "PTKZU", "VVINF", "KON", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.44": {"line.1": {"text": "Meint aber nicht/ da\u00df hier des Lobes Grentzen sind/", "tokens": ["Meint", "a\u00b7ber", "nicht", "/", "da\u00df", "hier", "des", "Lo\u00b7bes", "Grent\u00b7zen", "sind", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PTKNEG", "$(", "KOUS", "ADV", "ART", "NN", "NN", "VAFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und da\u00df/ nachdem man viel von Ihrem Ruhm geprie\u00dfen/", "tokens": ["Und", "da\u00df", "/", "nach\u00b7dem", "man", "viel", "von", "Ih\u00b7rem", "Ruhm", "ge\u00b7prie\u00b7\u00dfen", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "$(", "KOUS", "PIS", "ADV", "APPR", "PPOSAT", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die vielen Tugenden hier ihren Reihen schlie\u00dfen:", "tokens": ["Die", "vie\u00b7len", "Tu\u00b7gen\u00b7den", "hier", "ih\u00b7ren", "Rei\u00b7hen", "schlie\u00b7\u00dfen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "ADV", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ach nein! weil man noch viel an ihr zu loben sindt.", "tokens": ["Ach", "nein", "!", "weil", "man", "noch", "viel", "an", "ihr", "zu", "lo\u00b7ben", "sindt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKANT", "$.", "KOUS", "PIS", "ADV", "ADV", "APPR", "PPER", "PTKZU", "VVINF", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Schaut/ wie viel Tugenden noch hier im Leide stehen/", "tokens": ["Schaut", "/", "wie", "viel", "Tu\u00b7gen\u00b7den", "noch", "hier", "im", "Lei\u00b7de", "ste\u00b7hen", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$(", "KOKOM", "PIAT", "NN", "ADV", "ADV", "APPRART", "NN", "VVFIN", "$("], "meter": "++-+-+-+-+-+-", "measure": "unknown.measure.septa"}, "line.6": {"text": "Und wie viel K\u00fcnste selbst mit ihr zu Grabe gehen.", "tokens": ["Und", "wie", "viel", "K\u00fcns\u00b7te", "selbst", "mit", "ihr", "zu", "Gra\u00b7be", "ge\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PIAT", "NN", "ADV", "APPR", "PPER", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.45": {"line.1": {"text": "Es wei\u00df mein Priester-Volck und der Gelehrten Schaar/", "tokens": ["Es", "wei\u00df", "mein", "Pries\u00b7ter\u00b7Volck", "und", "der", "Ge\u00b7lehr\u00b7ten", "Schaar", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "KON", "ART", "NN", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wie Ihr erlauchter Geist die Schrift wohl kunt ergr\u00fcnden;", "tokens": ["Wie", "Ihr", "er\u00b7lauch\u00b7ter", "Geist", "die", "Schrift", "wohl", "kunt", "er\u00b7gr\u00fcn\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "ADJA", "NN", "ART", "NN", "ADV", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wie Ihre Klugheit stets hat wissen Rath zu finden;", "tokens": ["Wie", "Ih\u00b7re", "Klug\u00b7heit", "stets", "hat", "wis\u00b7sen", "Rath", "zu", "fin\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "NN", "ADV", "VAFIN", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wie Ihre Poesie recht zu bewundern war;", "tokens": ["Wie", "Ih\u00b7re", "Poe\u00b7sie", "recht", "zu", "be\u00b7wun\u00b7dern", "war", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "NN", "ADJD", "PTKZU", "VVINF", "VAFIN", "$."], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Wie Kunst und Tugend hier zusammen streiten wollte/", "tokens": ["Wie", "Kunst", "und", "Tu\u00b7gend", "hier", "zu\u00b7sam\u00b7men", "strei\u00b7ten", "woll\u00b7te", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "KON", "NN", "ADV", "ADV", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wer unter Ihnen doch den Vorzug haben sollte.", "tokens": ["Wer", "un\u00b7ter", "Ih\u00b7nen", "doch", "den", "Vor\u00b7zug", "ha\u00b7ben", "soll\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "PPER", "ADV", "ART", "NN", "VAINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.46": {"line.1": {"text": "Schaut/ wie viel Strahlen hier von denen Lichtern gehn/", "tokens": ["Schaut", "/", "wie", "viel", "Strah\u00b7len", "hier", "von", "de\u00b7nen", "Lich\u00b7tern", "gehn", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$(", "KOKOM", "PIAT", "NN", "ADV", "APPR", "PRELS", "NN", "VVINF", "$("], "meter": "++-+-+-+-+-+", "measure": "unknown.measure.septa"}, "line.2": {"text": "Damit die Nacht nicht kan den Ehren-Prunck verdunckeln;", "tokens": ["Da\u00b7mit", "die", "Nacht", "nicht", "kan", "den", "Eh\u00b7ren\u00b7Prunck", "ver\u00b7dun\u00b7ckeln", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "NN", "PTKNEG", "VMFIN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Doch pflegt der Gr\u00e4fin Nuhm unendlich mehr zu funckeln.", "tokens": ["Doch", "pflegt", "der", "Gr\u00e4\u00b7fin", "Nuhm", "un\u00b7end\u00b7lich", "mehr", "zu", "fun\u00b7ckeln", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "NN", "ADJD", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und da im gr\u00f6sten Glantz viel Kronen", "tokens": ["Und", "da", "im", "gr\u00f6s\u00b7ten", "Glantz", "viel", "Kro\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "APPRART", "ADJA", "NN", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "So wollen selbige mit klaren Worten sagen:", "tokens": ["So", "wol\u00b7len", "sel\u00b7bi\u00b7ge", "mit", "kla\u00b7ren", "Wor\u00b7ten", "sa\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ADV", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Sie sey vielf\u00e4ltig werth/ dergleichen Schmuck zu tragen.", "tokens": ["Sie", "sey", "viel\u00b7f\u00e4l\u00b7tig", "werth", "/", "derg\u00b7lei\u00b7chen", "Schmuck", "zu", "tra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "ADJD", "$(", "PIS", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.47": {"line.1": {"text": "Wenn alles Silber-Zeug", "tokens": ["Wenn", "al\u00b7les", "Sil\u00b7ber\u00b7Zeug"], "token_info": ["word", "word", "word"], "pos": ["KOUS", "PIS", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Und sich das schwartze Tuch", "tokens": ["Und", "sich", "das", "schwart\u00b7ze", "Tuch"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PRF", "ART", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "So w\u00e4r es nicht genug Sie w\u00fcrdig zu verehren;", "tokens": ["So", "w\u00e4r", "es", "nicht", "ge\u00b7nug", "Sie", "w\u00fcr\u00b7dig", "zu", "ver\u00b7eh\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PTKNEG", "ADV", "PPER", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "W\u00e4r auch die theure Cron an Steinen noch so schwer/", "tokens": ["W\u00e4r", "auch", "die", "theu\u00b7re", "Cron", "an", "Stei\u00b7nen", "noch", "so", "schwer", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "ADJA", "NN", "APPR", "NN", "ADV", "ADV", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die von dem Sarge pflegt mit Schimmer vorzublicken/", "tokens": ["Die", "von", "dem", "Sar\u00b7ge", "pflegt", "mit", "Schim\u00b7mer", "vor\u00b7zu\u00b7bli\u00b7cken", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "VVFIN", "APPR", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "So w\u00e4r sie doch zu leicht/ Sie w\u00fcrdigst auszuschm\u00fccken.", "tokens": ["So", "w\u00e4r", "sie", "doch", "zu", "leicht", "/", "Sie", "w\u00fcr\u00b7digst", "aus\u00b7zu\u00b7schm\u00fc\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "PTKA", "ADJD", "$(", "PPER", "VAFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.48": {"line.1": {"text": "Wer so ein Tugend-Bild zu schildern sich bem\u00fcht/", "tokens": ["Wer", "so", "ein", "Tu\u00b7gen\u00b7dBild", "zu", "schil\u00b7dern", "sich", "be\u00b7m\u00fcht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "ART", "NN", "PTKZU", "VVFIN", "PRF", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Dem geht es/ gleichwie dem/ der in die Sonne schauet/", "tokens": ["Dem", "geht", "es", "/", "gleich\u00b7wie", "dem", "/", "der", "in", "die", "Son\u00b7ne", "schau\u00b7et", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "$(", "KON", "ART", "$(", "ART", "APPR", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und dieses g\u00f6ldne Licht zu mahlen sich getrauet/", "tokens": ["Und", "die\u00b7ses", "g\u00f6ld\u00b7ne", "Licht", "zu", "mah\u00b7len", "sich", "ge\u00b7trau\u00b7et", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDAT", "ADJA", "NN", "PTKZU", "VVINF", "PRF", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Alleine halb-verblendt mit Schimpfs zur\u00fccke sieht.", "tokens": ["Al\u00b7lei\u00b7ne", "halb\u00b7ver\u00b7blendt", "mit", "Schimpfs", "zu\u00b7r\u00fc\u00b7cke", "sieht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "APPR", "NN", "VVFIN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Drum wie der Sonnen Glantz sich nicht kan bilden lassen/", "tokens": ["Drum", "wie", "der", "Son\u00b7nen", "Glantz", "sich", "nicht", "kan", "bil\u00b7den", "las\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "KOKOM", "ART", "NN", "NN", "PRF", "PTKNEG", "VMFIN", "VVINF", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "So kan der Gr\u00e4fin Lob auch keine Bildung fassen.", "tokens": ["So", "kan", "der", "Gr\u00e4\u00b7fin", "Lob", "auch", "kei\u00b7ne", "Bil\u00b7dung", "fas\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "NN", "NN", "ADV", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.49": {"line.1": {"text": "Wer sonsten von dem Ruhm erhabner Leute singt/", "tokens": ["Wer", "sons\u00b7ten", "von", "dem", "Ruhm", "er\u00b7hab\u00b7ner", "Leu\u00b7te", "singt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "APPR", "ART", "NN", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Pflegt meist aus falschen Thon sein Singen anzufangen/", "tokens": ["Pflegt", "meist", "aus", "fal\u00b7schen", "Thon", "sein", "Sin\u00b7gen", "an\u00b7zu\u00b7fan\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ADV", "APPR", "ADJA", "NN", "PPOSAT", "NN", "VVIZU", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Bi\u00df er sich endlich hat in solchem \u00fcbergangen/", "tokens": ["Bi\u00df", "er", "sich", "end\u00b7lich", "hat", "in", "sol\u00b7chem", "\u00fc\u00b7ber\u00b7gan\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ADV", "VAFIN", "APPR", "PIAT", "ADJA", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Da\u00df es/ zu Schimpfs und Spott/ verstimmt am Ende klingt;", "tokens": ["Da\u00df", "es", "/", "zu", "Schimpfs", "und", "Spott", "/", "ver\u00b7stimmt", "am", "En\u00b7de", "klingt", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$(", "APPR", "NN", "KON", "NN", "$(", "VVFIN", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Allein so Freund als Feind/ so Lieb als Neid gestehet/", "tokens": ["Al\u00b7lein", "so", "Freund", "als", "Feind", "/", "so", "Lieb", "als", "Neid", "ge\u00b7ste\u00b7het", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "NN", "KOUS", "NN", "$(", "ADV", "NN", "KOUS", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Da\u00df unser Gr\u00e4fin Lob weit \u00fcber alles gehet.", "tokens": ["Da\u00df", "un\u00b7ser", "Gr\u00e4\u00b7fin", "Lob", "weit", "\u00fc\u00b7ber", "al\u00b7les", "ge\u00b7het", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "NN", "ADJD", "APPR", "PIS", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.50": {"line.1": {"text": "Es r\u00fchmt der Zeiten Ruff l\u00e4ngst Ihren Tugend-Pracht;", "tokens": ["Es", "r\u00fchmt", "der", "Zei\u00b7ten", "Ruff", "l\u00e4ngst", "Ih\u00b7ren", "Tu\u00b7gen\u00b7dPracht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "NN", "ADV", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Doch dringt die ", "tokens": ["Doch", "dringt", "die"], "token_info": ["word", "word", "word"], "pos": ["KON", "VVFIN", "ART"], "meter": "-+-", "measure": "amphibrach.single"}, "line.3": {"text": "Vor welcher Gottheit auch die schwartz-bew\u00f6lckten D\u00fcffte", "tokens": ["Vor", "wel\u00b7cher", "Got\u00b7theit", "auch", "die", "schwartz\u00b7be\u00b7w\u00f6lck\u00b7ten", "D\u00fcff\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PWAT", "NN", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Sich haben aufgekl\u00e4hrt/ und ihr den Weg gemacht:", "tokens": ["Sich", "ha\u00b7ben", "auf\u00b7ge\u00b7kl\u00e4hrt", "/", "und", "ihr", "den", "Weg", "ge\u00b7macht", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "VAFIN", "VVPP", "$(", "KON", "PPER", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "So lange solche nun wird \u00e4chtes Lob erh\u00f6hen/", "tokens": ["So", "lan\u00b7ge", "sol\u00b7che", "nun", "wird", "\u00e4ch\u00b7tes", "Lob", "er\u00b7h\u00f6\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PIAT", "ADV", "VAFIN", "ADJA", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wird Dero Nahme nicht durch ihre Hand vergehen.", "tokens": ["Wird", "De\u00b7ro", "Nah\u00b7me", "nicht", "durch", "ih\u00b7re", "Hand", "ver\u00b7ge\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PDS", "NN", "PTKNEG", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.51": {"line.1": {"text": "Jedoch die Liebe wird Ihr l\u00e4nger dienstbar seyn:", "tokens": ["Je\u00b7doch", "die", "Lie\u00b7be", "wird", "Ihr", "l\u00e4n\u00b7ger", "dienst\u00b7bar", "seyn", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VAFIN", "PPER", "ADJD", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wenn Glaub und Hoffnung einst wird in der Welt vergehen/", "tokens": ["Wenn", "Glaub", "und", "Hoff\u00b7nung", "einst", "wird", "in", "der", "Welt", "ver\u00b7ge\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "NN", "ADV", "VAFIN", "APPR", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wird Sie die Liebe noch zur Ehr und Lust erh\u00f6hen.", "tokens": ["Wird", "Sie", "die", "Lie\u00b7be", "noch", "zur", "Ehr", "und", "Lust", "er\u00b7h\u00f6\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "NN", "ADV", "APPRART", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Sie strahlt auch schon durch Ihr mit ungemeinen Schein:", "tokens": ["Sie", "strahlt", "auch", "schon", "durch", "Ihr", "mit", "un\u00b7ge\u00b7mei\u00b7nen", "Schein", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "APPR", "PPER", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Sie hat das Lamm geliebt/", "tokens": ["Sie", "hat", "das", "Lamm", "ge\u00b7liebt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Den Gottes Lamm gestifft/ ein theures Mitglied worden.", "tokens": ["Den", "Got\u00b7tes", "Lamm", "ge\u00b7stifft", "/", "ein", "theu\u00b7res", "Mit\u00b7glied", "wor\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVPP", "$(", "ART", "ADJA", "NN", "VAPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.52": {"line.1": {"text": "Gott stellet nun mit Ihr des Lammes Hochzeit an.", "tokens": ["Gott", "stel\u00b7let", "nun", "mit", "Ihr", "des", "Lam\u00b7mes", "Hoch\u00b7zeit", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ADV", "APPR", "PPOSAT", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die Liebe kan das Lamm nun in der That genie\u00dfen/", "tokens": ["Die", "Lie\u00b7be", "kan", "das", "Lamm", "nun", "in", "der", "That", "ge\u00b7nie\u00b7\u00dfen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "ART", "NN", "ADV", "APPR", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Das blo\u00df die Hoffnung hier so freudig hat geprie\u00dfen:", "tokens": ["Das", "blo\u00df", "die", "Hoff\u00b7nung", "hier", "so", "freu\u00b7dig", "hat", "ge\u00b7prie\u00b7\u00dfen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "ART", "NN", "ADV", "ADV", "ADJD", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Es wird Ihr nun von Ihm auf ewig wohlgethan.", "tokens": ["Es", "wird", "Ihr", "nun", "von", "Ihm", "auf", "e\u00b7wig", "wohl\u00b7ge\u00b7than", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "APPR", "PPER", "APPR", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Allein Ihr Wohlseyn will uns nichts/ als Weh/ geb\u00e4hren/", "tokens": ["Al\u00b7lein", "Ihr", "Wohl\u00b7seyn", "will", "uns", "nichts", "/", "als", "Weh", "/", "ge\u00b7b\u00e4h\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "VMFIN", "PPER", "PIS", "$(", "KOUS", "NN", "$(", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und Ihr Verlust erpre\u00dft von uns viel tausend Z\u00e4hren.", "tokens": ["Und", "Ihr", "Ver\u00b7lust", "er\u00b7pre\u00dft", "von", "uns", "viel", "tau\u00b7send", "Z\u00e4h\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "APPR", "PPER", "ADV", "CARD", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.53": {"line.1": {"text": "Drum hemmt mein Schwartzburg auch die milden Thr\u00e4nen nicht/", "tokens": ["Drum", "hemmt", "mein", "Schwartz\u00b7burg", "auch", "die", "mil\u00b7den", "Thr\u00e4\u00b7nen", "nicht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPOSAT", "NN", "ADV", "ART", "ADJA", "NN", "PTKNEG", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Weil ihm das theure Rei\u00df von Barby ist entrissen:", "tokens": ["Weil", "ihm", "das", "theu\u00b7re", "Rei\u00df", "von", "Bar\u00b7by", "ist", "ent\u00b7ris\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "APPR", "NE", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und weil mit Ihm der Stamm ist g\u00e4ntzlich umgeschmissen/", "tokens": ["Und", "weil", "mit", "Ihm", "der", "Stamm", "ist", "g\u00e4ntz\u00b7lich", "um\u00b7ge\u00b7schmis\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "APPR", "PPER", "ART", "NN", "VAFIN", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Sieht man wie Barby selbst f\u00fcr Leid sein Wappen bricht:", "tokens": ["Sieht", "man", "wie", "Bar\u00b7by", "selbst", "f\u00fcr", "Leid", "sein", "Wap\u00b7pen", "bricht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "KOKOM", "NE", "ADV", "APPR", "NN", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Drum k\u00f6nnen wir mit Recht die Kleider auch zerreissen/", "tokens": ["Drum", "k\u00f6n\u00b7nen", "wir", "mit", "Recht", "die", "Klei\u00b7der", "auch", "zer\u00b7reis\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VMFIN", "PPER", "APPR", "NN", "ART", "NN", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und Schwartzburg seinen Schmuck f\u00fcr Wehmuth von sich schmeissen.", "tokens": ["Und", "Schwartz\u00b7burg", "sei\u00b7nen", "Schmuck", "f\u00fcr", "Weh\u00b7muth", "von", "sich", "schmeis\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "PPOSAT", "NN", "APPR", "NN", "APPR", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.54": {"line.1": {"text": "Ach qvillet/ Z\u00e4hren/ qvillt! ergie\u00df dich/ Thr\u00e4nen-Bach!", "tokens": ["Ach", "qvil\u00b7let", "/", "Z\u00e4h\u00b7ren", "/", "qvillt", "!", "er\u00b7gie\u00df", "dich", "/", "Thr\u00e4\u00b7nen\u00b7Bach", "!"], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ITJ", "VVFIN", "$(", "NN", "$(", "VVFIN", "$.", "VVFIN", "PPER", "$(", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ob ich gleich schon so viel der Thr\u00e4nen Fluht vergossen/", "tokens": ["Ob", "ich", "gleich", "schon", "so", "viel", "der", "Thr\u00e4\u00b7nen", "Fluht", "ver\u00b7gos\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "ADV", "ADV", "ART", "NN", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Da\u00df fast der Lebens-Geist mit ihnen fortgeflossen/", "tokens": ["Da\u00df", "fast", "der", "Le\u00b7bens\u00b7Geist", "mit", "ih\u00b7nen", "fort\u00b7ge\u00b7flos\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "APPR", "PPER", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und ich nichts sprechen kan/ als lauter Weh und Ach!", "tokens": ["Und", "ich", "nichts", "spre\u00b7chen", "kan", "/", "als", "lau\u00b7ter", "Weh", "und", "Ach", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "PIS", "VVINF", "VMFIN", "$(", "KOKOM", "PIAT", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ja weil die Kirche nichts f\u00fcr Jammer mehr kan sagen/", "tokens": ["Ja", "weil", "die", "Kir\u00b7che", "nichts", "f\u00fcr", "Jam\u00b7mer", "mehr", "kan", "sa\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "KOUS", "ART", "NN", "PIS", "APPR", "NN", "ADV", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "So helfft/ ihr Schulen/ auch den Jammer mit beklagen.", "tokens": ["So", "helfft", "/", "ihr", "Schu\u00b7len", "/", "auch", "den", "Jam\u00b7mer", "mit", "be\u00b7kla\u00b7gen", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$(", "PPOSAT", "NN", "$(", "ADV", "ART", "NN", "APPR", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}