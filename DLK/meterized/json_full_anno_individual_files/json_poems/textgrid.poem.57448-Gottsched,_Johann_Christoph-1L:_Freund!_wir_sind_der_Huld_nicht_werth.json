{"textgrid.poem.57448": {"metadata": {"author": {"name": "Gottsched, Johann Christoph", "birth": "N.A.", "death": "N.A."}, "title": "1L: Freund! wir sind der Huld nicht werth", "genre": "verse", "period": "N.A.", "pub_year": 1733, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Freund! wir sind der Huld nicht werth", "tokens": ["Freund", "!", "wir", "sind", "der", "Huld", "nicht", "werth"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "$.", "PPER", "VAFIN", "ART", "NN", "PTKNEG", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Die das Gl\u00fcck uns schon beschert,", "tokens": ["Die", "das", "Gl\u00fcck", "uns", "schon", "be\u00b7schert", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "PPER", "ADV", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ph\u00f6bus schenckt uns grosse Dichter,", "tokens": ["Ph\u00f6\u00b7bus", "schenckt", "uns", "gros\u00b7se", "Dich\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Aber wir sind Midas-Richter,", "tokens": ["A\u00b7ber", "wir", "sind", "Mi\u00b7das\u00b7Rich\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "H\u00f6ren offt den Waldgott Pan", "tokens": ["H\u00f6\u00b7ren", "offt", "den", "Wald\u00b7gott", "Pan"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "ART", "NN", "NE"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Lieber als die Musen an.", "tokens": ["Lie\u00b7ber", "als", "die", "Mu\u00b7sen", "an", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "KOKOM", "ART", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Opitz, Dach, und Gryph, und Rist,", "tokens": ["O\u00b7pitz", ",", "Dach", ",", "und", "Gry\u00b7ph", ",", "und", "Rist", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "NN", "$,", "KON", "NN", "$,", "KON", "NN", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Flemming, Schoch und Tscherning ist", "tokens": ["Flem\u00b7ming", ",", "Schoch", "und", "Tscher\u00b7ning", "ist"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NE", "$,", "NN", "KON", "NE", "VAFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Voll von Ph\u00f6bus Geist gewesen:", "tokens": ["Voll", "von", "Ph\u00f6\u00b7bus", "Geist", "ge\u00b7we\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "NE", "NN", "VAPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Aber sprich, wer mag sie lesen?", "tokens": ["A\u00b7ber", "sprich", ",", "wer", "mag", "sie", "le\u00b7sen", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "$,", "PWS", "VMFIN", "PPER", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Sprich, wem ist ihr hoher Stand", "tokens": ["Sprich", ",", "wem", "ist", "ihr", "ho\u00b7her", "Stand"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVIMP", "$,", "PWS", "VAFIN", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "In Apollens Huld bekannt?", "tokens": ["In", "A\u00b7pol\u00b7lens", "Huld", "be\u00b7kannt", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "NE", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Les' ich unsern Kindermann,", "tokens": ["Les'", "ich", "un\u00b7sern", "Kin\u00b7der\u00b7mann", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Stimm ich Gerhards Oden an,", "tokens": ["Stimm", "ich", "Ger\u00b7hards", "O\u00b7den", "an", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "NE", "NE", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "H\u00f6r ich einen Abschatz nennen:", "tokens": ["H\u00f6r", "ich", "ei\u00b7nen", "Ab\u00b7schatz", "nen\u00b7nen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "ART", "NN", "VVINF", "$."], "meter": "+-+-+---", "measure": "unknown.measure.tri"}, "line.4": {"text": "O so will mein Geist entbrennen,", "tokens": ["O", "so", "will", "mein", "Geist", "ent\u00b7bren\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "VMFIN", "PPOSAT", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Z\u00fcrnend, da\u00df die Deutsche Welt", "tokens": ["Z\u00fcr\u00b7nend", ",", "da\u00df", "die", "Deut\u00b7sche", "Welt"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["VVPP", "$,", "KOUS", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Sie nicht mehr in Ehren h\u00e4lt.", "tokens": ["Sie", "nicht", "mehr", "in", "Eh\u00b7ren", "h\u00e4lt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKNEG", "ADV", "APPR", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Muntrer Weidner, wo bleibst du?", "tokens": ["Mun\u00b7trer", "Weid\u00b7ner", ",", "wo", "bleibst", "du", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "PWAV", "VVFIN", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Du geh\u00f6rst gewi\u00df dazu,", "tokens": ["Du", "ge\u00b7h\u00f6rst", "ge\u00b7wi\u00df", "da\u00b7zu", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PAV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Da du uns mit Deutscher Zungen", "tokens": ["Da", "du", "uns", "mit", "Deut\u00b7scher", "Zun\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PRF", "APPR", "ADJA", "NN"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.4": {"text": "Flaccus Lieder vorgesungen,", "tokens": ["Flac\u00b7cus", "Lie\u00b7der", "vor\u00b7ge\u00b7sun\u00b7gen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Jenes R\u00f6mers, dessen Kiel", "tokens": ["Je\u00b7nes", "R\u00f6\u00b7mers", ",", "des\u00b7sen", "Kiel"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["PDAT", "NN", "$,", "PRELAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Roms August so wohl gefiel.", "tokens": ["Roms", "Au\u00b7gust", "so", "wohl", "ge\u00b7fiel", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "ADV", "ADV", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Niemahls h\u00f6rte dich M\u00e4cen,", "tokens": ["Nie\u00b7mahls", "h\u00f6r\u00b7te", "dich", "M\u00e4\u00b7cen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "G\u00f6ttlicher Horatz! so sch\u00f6n", "tokens": ["G\u00f6tt\u00b7li\u00b7cher", "Ho\u00b7ratz", "!", "so", "sch\u00f6n"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["NE", "NE", "$.", "ADV", "ADJD"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.9": {"text": "In der R\u00f6mer Mundart singen,", "tokens": ["In", "der", "R\u00f6\u00b7mer", "Mund\u00b7art", "sin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.10": {"text": "Als hier Weidners Oden klingen:", "tokens": ["Als", "hier", "Weid\u00b7ners", "O\u00b7den", "klin\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ADJA", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.11": {"text": "Weidners Oden, die so rein,", "tokens": ["Weid\u00b7ners", "O\u00b7den", ",", "die", "so", "rein", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "PRELS", "ADV", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.12": {"text": "Geistreich, hoch und edel seyn.", "tokens": ["Geist\u00b7reich", ",", "hoch", "und", "e\u00b7del", "seyn", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "ADJD", "KON", "ADJD", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Kommt, ihr Weisen, kommt hervor,", "tokens": ["Kommt", ",", "ihr", "Wei\u00b7sen", ",", "kommt", "her\u00b7vor", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PPOSAT", "NN", "$,", "VVFIN", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Widerlegt den Pythagor,", "tokens": ["Wi\u00b7der\u00b7legt", "den", "Py\u00b7tha\u00b7gor", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NE", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "La\u00dft den Irrthum seiner Lehren", "tokens": ["La\u00dft", "den", "Irr\u00b7thum", "sei\u00b7ner", "Leh\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVIMP", "ART", "NN", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Von der Seelen Wandrung h\u00f6ren,", "tokens": ["Von", "der", "See\u00b7len", "Wand\u00b7rung", "h\u00f6\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Doch umsonst! weil Flaccus Geist", "tokens": ["Doch", "um\u00b7sonst", "!", "weil", "Flac\u00b7cus", "Geist"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["KON", "ADV", "$.", "KOUS", "NE", "NN"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.6": {"text": "Sich in Weidnern zwiefach weist.", "tokens": ["Sich", "in", "Weid\u00b7nern", "zwie\u00b7fach", "weist", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "NN", "ADJD", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Schn\u00f6des Deutschland, sch\u00e4me dich,", "tokens": ["Schn\u00f6\u00b7des", "Deutschland", ",", "sch\u00e4\u00b7me", "dich", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "VVFIN", "PPER", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Da\u00df dergleichen Geister sich", "tokens": ["Da\u00df", "derg\u00b7lei\u00b7chen", "Geis\u00b7ter", "sich"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PIS", "NN", "PRF"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Allgemach bey dir verlieren;", "tokens": ["All\u00b7ge\u00b7mach", "bey", "dir", "ver\u00b7lie\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPER", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Denn sie sind kaum mehr zu sp\u00fcren:", "tokens": ["Denn", "sie", "sind", "kaum", "mehr", "zu", "sp\u00fc\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "ADV", "ADV", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Seit dich Welschlands Schwulst bestrickt,", "tokens": ["Seit", "dich", "Wel\u00b7schlands", "Schwulst", "be\u00b7strickt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "PIAT", "NN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Und dir Witz und Sinn verr\u00fcckt.", "tokens": ["Und", "dir", "Witz", "und", "Sinn", "ver\u00b7r\u00fcckt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "NN", "KON", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Himmel hilf! was seh ich hier?", "tokens": ["Him\u00b7mel", "hilf", "!", "was", "seh", "ich", "hier", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKVZ", "$.", "PWS", "VVFIN", "PPER", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Steht nicht ein Pallast vor mir,", "tokens": ["Steht", "nicht", "ein", "Pal\u00b7last", "vor", "mir", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "ART", "NN", "APPR", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Welchem Diamantne Seulen", "tokens": ["Wel\u00b7chem", "Di\u00b7a\u00b7mant\u00b7ne", "Seu\u00b7len"], "token_info": ["word", "word", "word"], "pos": ["PWAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Grund und Festigkeit ertheilen,", "tokens": ["Grund", "und", "Fes\u00b7tig\u00b7keit", "er\u00b7thei\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Dessen Boden Marmorstein,", "tokens": ["Des\u00b7sen", "Bo\u00b7den", "Mar\u00b7mor\u00b7stein", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PDAT", "NN", "NE", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Sims und Dach Saphir mu\u00df seyn.", "tokens": ["Sims", "und", "Dach", "Sa\u00b7phir", "mu\u00df", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "NN", "NE", "VMFIN", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Warlich Bau und Pracht ist stoltz!", "tokens": ["War\u00b7lich", "Bau", "und", "Pracht", "ist", "stoltz", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "KON", "NN", "VAFIN", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "W\u00e4nde von Cypressen-Holtz,", "tokens": ["W\u00e4n\u00b7de", "von", "Cy\u00b7pres\u00b7sen\u00b7Holtz", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPR", "NE", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Thurn und Thore von Topasen,", "tokens": ["Thurn", "und", "Tho\u00b7re", "von", "To\u00b7pa\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "NN", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Rings umher Smaragdne Rasen,", "tokens": ["Rings", "um\u00b7her", "Sma\u00b7ragd\u00b7ne", "Ra\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PTKVZ", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Voller Schmeltz und Chrysolith,", "tokens": ["Vol\u00b7ler", "Sch\u00b7meltz", "und", "Chry\u00b7so\u00b7lith", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "KON", "NE", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.6": {"text": "Der an statt der Blumen bl\u00fcht.", "tokens": ["Der", "an", "statt", "der", "Blu\u00b7men", "bl\u00fcht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.9": {"line.1": {"text": "Macht mir nicht die Zauber-Kunst", "tokens": ["Macht", "mir", "nicht", "die", "Zau\u00b7ber\u00b7Kunst"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "PPER", "PTKNEG", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Durch Verblendung blauen Dunst?", "tokens": ["Durch", "Ver\u00b7blen\u00b7dung", "blau\u00b7en", "Dunst", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Nein! die Phantasey der Dichter", "tokens": ["Nein", "!", "die", "Phan\u00b7ta\u00b7sey", "der", "Dich\u00b7ter"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["PTKANT", "$.", "ART", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Tr\u00fcgt mir Geist und Augenlichter,", "tokens": ["Tr\u00fcgt", "mir", "Geist", "und", "Au\u00b7gen\u00b7lich\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Zeigt und stellt so wunderbar", "tokens": ["Zeigt", "und", "stellt", "so", "wun\u00b7der\u00b7bar"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "KON", "VVFIN", "ADV", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Ein Poetisch Lufft-Schlo\u00df dar.", "tokens": ["Ein", "Poe\u00b7tisch", "Lufft\u00b7Schlo\u00df", "dar", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "PTKVZ", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.10": {"line.1": {"text": "Blo\u00df die Tyber und der Po", "tokens": ["Blo\u00df", "die", "Ty\u00b7ber", "und", "der", "Po"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "KON", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Blenden unsre Deutsche so,", "tokens": ["Blen\u00b7den", "uns\u00b7re", "Deut\u00b7sche", "so", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df der Bach der Castalinnen,", "tokens": ["Da\u00df", "der", "Bach", "der", "Cas\u00b7ta\u00b7lin\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Viel zu ruhig scheint zu rinnen:", "tokens": ["Viel", "zu", "ru\u00b7hig", "scheint", "zu", "rin\u00b7nen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKA", "ADJD", "VVFIN", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Wenn sie sich um den Marin", "tokens": ["Wenn", "sie", "sich", "um", "den", "Ma\u00b7rin"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PRF", "APPR", "ART", "NN"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.6": {"text": "Mehr als den Virgil bem\u00fchn.", "tokens": ["Mehr", "als", "den", "Vir\u00b7gil", "be\u00b7m\u00fchn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "KOKOM", "ART", "NN", "VVINF", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.11": {"line.1": {"text": "Freunde, was bezaubert euch?", "tokens": ["Freun\u00b7de", ",", "was", "be\u00b7zau\u00b7bert", "euch", "?"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PWS", "VVFIN", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Werdet doch den Griechen gleich,", "tokens": ["Wer\u00b7det", "doch", "den", "Grie\u00b7chen", "gleich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Folgt der alten R\u00f6mer Th\u00f6nen,", "tokens": ["Folgt", "der", "al\u00b7ten", "R\u00f6\u00b7mer", "Th\u00f6\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Nicht Italiens Sirenen,", "tokens": ["Nicht", "I\u00b7ta\u00b7li\u00b7ens", "Si\u00b7re\u00b7nen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PTKNEG", "NE", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Die durch ihrer Hoheit Schein", "tokens": ["Die", "durch", "ih\u00b7rer", "Ho\u00b7heit", "Schein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "PPOSAT", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Der Vernunfft ein Fallbret seyn.", "tokens": ["Der", "Ver\u00b7nunfft", "ein", "Fall\u00b7bret", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Weg mit Gold und Elfenbein,", "tokens": ["Weg", "mit", "Gold", "und", "El\u00b7fen\u00b7bein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Nectar, Muscateller-Wein,", "tokens": ["Nec\u00b7tar", ",", "Mus\u00b7ca\u00b7tel\u00b7ler\u00b7Wein", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Mosch, Zibeth und Amber-Kuchen,", "tokens": ["Mosch", ",", "Zi\u00b7beth", "und", "Am\u00b7ber\u00b7Ku\u00b7chen", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Hofmannswaldau mag sie suchen,", "tokens": ["Hof\u00b7manns\u00b7wal\u00b7dau", "mag", "sie", "su\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Lohensteins Geruch und Art", "tokens": ["Lo\u00b7hen\u00b7steins", "Ge\u00b7ruch", "und", "Art"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "NN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Sey der Biesam vorgespart!", "tokens": ["Sey", "der", "Bie\u00b7sam", "vor\u00b7ge\u00b7spart", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Neukirch! du hast wohl verdient,", "tokens": ["Neu\u00b7kirch", "!", "du", "hast", "wohl", "ver\u00b7dient", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "PPER", "VAFIN", "ADV", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Da\u00df dein Lorber ewig gr\u00fcnt,", "tokens": ["Da\u00df", "dein", "Lor\u00b7ber", "e\u00b7wig", "gr\u00fcnt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "ADJD", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Du entgiengst den leeren Schrancken", "tokens": ["Du", "ent\u00b7giengst", "den", "lee\u00b7ren", "Schran\u00b7cken"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ubersteigender Gedancken,", "tokens": ["U\u00b7bers\u00b7tei\u00b7gen\u00b7der", "Ge\u00b7dan\u00b7cken", ","], "token_info": ["word", "word", "punct"], "pos": ["APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Suchtst und fandst die alte Spur", "tokens": ["Suchtst", "und", "fandst", "die", "al\u00b7te", "Spur"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "KON", "VVFIN", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Der Vernunfft und der Natur.", "tokens": ["Der", "Ver\u00b7nunfft", "und", "der", "Na\u00b7tur", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "Folgt, ihr Br\u00fcder! folgt ihm nach,", "tokens": ["Folgt", ",", "ihr", "Br\u00fc\u00b7der", "!", "folgt", "ihm", "nach", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PPOSAT", "NN", "$.", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Seht wie Canitz Lorbern brach,", "tokens": ["Seht", "wie", "Ca\u00b7nitz", "Lor\u00b7bern", "brach", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KOKOM", "NE", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Den uns Neukirch angewiesen,", "tokens": ["Den", "uns", "Neu\u00b7kirch", "an\u00b7ge\u00b7wie\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Als er den von Fuchs gepriesen:", "tokens": ["Als", "er", "den", "von", "Fuchs", "ge\u00b7prie\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "APPR", "NE", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Stimmt, wie G\u00fcnther l\u00e4ngst gethan,", "tokens": ["Stimmt", ",", "wie", "G\u00fcn\u00b7ther", "l\u00e4ngst", "ge\u00b7than", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PWAV", "NE", "ADV", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Ausgespielte Fl\u00f6ten an.", "tokens": ["Aus\u00b7ge\u00b7spiel\u00b7te", "Fl\u00f6\u00b7ten", "an", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.15": {"line.1": {"text": "Du, mein h\u00f6chstgeliebter M\u00e4y!", "tokens": ["Du", ",", "mein", "h\u00f6chst\u00b7ge\u00b7lieb\u00b7ter", "M\u00e4y", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PPOSAT", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Fliehst der Faunen Wald-Geschrey,", "tokens": ["Fliehst", "der", "Fau\u00b7nen", "Wald\u00b7Ge\u00b7schrey", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Kennst und liebst die reinen Th\u00f6ne", "tokens": ["Kennst", "und", "liebst", "die", "rei\u00b7nen", "Th\u00f6\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "KON", "VVFIN", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Kunst-ge\u00fcbter Musen-S\u00f6hne.", "tokens": ["Kunst\u00b7ge\u00b7\u00fcb\u00b7ter", "Mu\u00b7sen\u00b7S\u00f6h\u00b7ne", "."], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Sage doch, was mir gebricht,", "tokens": ["Sa\u00b7ge", "doch", ",", "was", "mir", "ge\u00b7bricht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "$,", "PWS", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Denn ich wei\u00df, du schmeichelst nicht!", "tokens": ["Denn", "ich", "wei\u00df", ",", "du", "schmei\u00b7chelst", "nicht", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "$,", "PPER", "VVFIN", "PTKNEG", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.16": {"line.1": {"text": "Freund! wir sind der Huld nicht werth", "tokens": ["Freund", "!", "wir", "sind", "der", "Huld", "nicht", "werth"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "$.", "PPER", "VAFIN", "ART", "NN", "PTKNEG", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Die das Gl\u00fcck uns schon beschert,", "tokens": ["Die", "das", "Gl\u00fcck", "uns", "schon", "be\u00b7schert", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "PPER", "ADV", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ph\u00f6bus schenckt uns grosse Dichter,", "tokens": ["Ph\u00f6\u00b7bus", "schenckt", "uns", "gros\u00b7se", "Dich\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Aber wir sind Midas-Richter,", "tokens": ["A\u00b7ber", "wir", "sind", "Mi\u00b7das\u00b7Rich\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "H\u00f6ren offt den Waldgott Pan", "tokens": ["H\u00f6\u00b7ren", "offt", "den", "Wald\u00b7gott", "Pan"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "ART", "NN", "NE"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Lieber als die Musen an.", "tokens": ["Lie\u00b7ber", "als", "die", "Mu\u00b7sen", "an", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "KOKOM", "ART", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.17": {"line.1": {"text": "Opitz, Dach, und Gryph, und Rist,", "tokens": ["O\u00b7pitz", ",", "Dach", ",", "und", "Gry\u00b7ph", ",", "und", "Rist", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "NN", "$,", "KON", "NN", "$,", "KON", "NN", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Flemming, Schoch und Tscherning ist", "tokens": ["Flem\u00b7ming", ",", "Schoch", "und", "Tscher\u00b7ning", "ist"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NE", "$,", "NN", "KON", "NE", "VAFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Voll von Ph\u00f6bus Geist gewesen:", "tokens": ["Voll", "von", "Ph\u00f6\u00b7bus", "Geist", "ge\u00b7we\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "NE", "NN", "VAPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Aber sprich, wer mag sie lesen?", "tokens": ["A\u00b7ber", "sprich", ",", "wer", "mag", "sie", "le\u00b7sen", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "$,", "PWS", "VMFIN", "PPER", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Sprich, wem ist ihr hoher Stand", "tokens": ["Sprich", ",", "wem", "ist", "ihr", "ho\u00b7her", "Stand"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVIMP", "$,", "PWS", "VAFIN", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "In Apollens Huld bekannt?", "tokens": ["In", "A\u00b7pol\u00b7lens", "Huld", "be\u00b7kannt", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "NE", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.18": {"line.1": {"text": "Les' ich unsern Kindermann,", "tokens": ["Les'", "ich", "un\u00b7sern", "Kin\u00b7der\u00b7mann", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Stimm ich Gerhards Oden an,", "tokens": ["Stimm", "ich", "Ger\u00b7hards", "O\u00b7den", "an", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "NE", "NE", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "H\u00f6r ich einen Abschatz nennen:", "tokens": ["H\u00f6r", "ich", "ei\u00b7nen", "Ab\u00b7schatz", "nen\u00b7nen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "ART", "NN", "VVINF", "$."], "meter": "+-+-+---", "measure": "unknown.measure.tri"}, "line.4": {"text": "O so will mein Geist entbrennen,", "tokens": ["O", "so", "will", "mein", "Geist", "ent\u00b7bren\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "VMFIN", "PPOSAT", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Z\u00fcrnend, da\u00df die Deutsche Welt", "tokens": ["Z\u00fcr\u00b7nend", ",", "da\u00df", "die", "Deut\u00b7sche", "Welt"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["VVPP", "$,", "KOUS", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Sie nicht mehr in Ehren h\u00e4lt.", "tokens": ["Sie", "nicht", "mehr", "in", "Eh\u00b7ren", "h\u00e4lt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKNEG", "ADV", "APPR", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.19": {"line.1": {"text": "Muntrer Weidner, wo bleibst du?", "tokens": ["Mun\u00b7trer", "Weid\u00b7ner", ",", "wo", "bleibst", "du", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "PWAV", "VVFIN", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Du geh\u00f6rst gewi\u00df dazu,", "tokens": ["Du", "ge\u00b7h\u00f6rst", "ge\u00b7wi\u00df", "da\u00b7zu", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PAV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Da du uns mit Deutscher Zungen", "tokens": ["Da", "du", "uns", "mit", "Deut\u00b7scher", "Zun\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PRF", "APPR", "ADJA", "NN"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.4": {"text": "Flaccus Lieder vorgesungen,", "tokens": ["Flac\u00b7cus", "Lie\u00b7der", "vor\u00b7ge\u00b7sun\u00b7gen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Jenes R\u00f6mers, dessen Kiel", "tokens": ["Je\u00b7nes", "R\u00f6\u00b7mers", ",", "des\u00b7sen", "Kiel"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["PDAT", "NN", "$,", "PRELAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Roms August so wohl gefiel.", "tokens": ["Roms", "Au\u00b7gust", "so", "wohl", "ge\u00b7fiel", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "ADV", "ADV", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Niemahls h\u00f6rte dich M\u00e4cen,", "tokens": ["Nie\u00b7mahls", "h\u00f6r\u00b7te", "dich", "M\u00e4\u00b7cen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "G\u00f6ttlicher Horatz! so sch\u00f6n", "tokens": ["G\u00f6tt\u00b7li\u00b7cher", "Ho\u00b7ratz", "!", "so", "sch\u00f6n"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["NE", "NE", "$.", "ADV", "ADJD"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.9": {"text": "In der R\u00f6mer Mundart singen,", "tokens": ["In", "der", "R\u00f6\u00b7mer", "Mund\u00b7art", "sin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.10": {"text": "Als hier Weidners Oden klingen:", "tokens": ["Als", "hier", "Weid\u00b7ners", "O\u00b7den", "klin\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ADJA", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.11": {"text": "Weidners Oden, die so rein,", "tokens": ["Weid\u00b7ners", "O\u00b7den", ",", "die", "so", "rein", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "PRELS", "ADV", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.12": {"text": "Geistreich, hoch und edel seyn.", "tokens": ["Geist\u00b7reich", ",", "hoch", "und", "e\u00b7del", "seyn", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "ADJD", "KON", "ADJD", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.20": {"line.1": {"text": "Kommt, ihr Weisen, kommt hervor,", "tokens": ["Kommt", ",", "ihr", "Wei\u00b7sen", ",", "kommt", "her\u00b7vor", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PPOSAT", "NN", "$,", "VVFIN", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Widerlegt den Pythagor,", "tokens": ["Wi\u00b7der\u00b7legt", "den", "Py\u00b7tha\u00b7gor", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NE", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "La\u00dft den Irrthum seiner Lehren", "tokens": ["La\u00dft", "den", "Irr\u00b7thum", "sei\u00b7ner", "Leh\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVIMP", "ART", "NN", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Von der Seelen Wandrung h\u00f6ren,", "tokens": ["Von", "der", "See\u00b7len", "Wand\u00b7rung", "h\u00f6\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Doch umsonst! weil Flaccus Geist", "tokens": ["Doch", "um\u00b7sonst", "!", "weil", "Flac\u00b7cus", "Geist"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["KON", "ADV", "$.", "KOUS", "NE", "NN"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.6": {"text": "Sich in Weidnern zwiefach weist.", "tokens": ["Sich", "in", "Weid\u00b7nern", "zwie\u00b7fach", "weist", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "NN", "ADJD", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.21": {"line.1": {"text": "Schn\u00f6des Deutschland, sch\u00e4me dich,", "tokens": ["Schn\u00f6\u00b7des", "Deutschland", ",", "sch\u00e4\u00b7me", "dich", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "VVFIN", "PPER", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Da\u00df dergleichen Geister sich", "tokens": ["Da\u00df", "derg\u00b7lei\u00b7chen", "Geis\u00b7ter", "sich"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PIS", "NN", "PRF"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Allgemach bey dir verlieren;", "tokens": ["All\u00b7ge\u00b7mach", "bey", "dir", "ver\u00b7lie\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPER", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Denn sie sind kaum mehr zu sp\u00fcren:", "tokens": ["Denn", "sie", "sind", "kaum", "mehr", "zu", "sp\u00fc\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "ADV", "ADV", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Seit dich Welschlands Schwulst bestrickt,", "tokens": ["Seit", "dich", "Wel\u00b7schlands", "Schwulst", "be\u00b7strickt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "PIAT", "NN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Und dir Witz und Sinn verr\u00fcckt.", "tokens": ["Und", "dir", "Witz", "und", "Sinn", "ver\u00b7r\u00fcckt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "NN", "KON", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.22": {"line.1": {"text": "Himmel hilf! was seh ich hier?", "tokens": ["Him\u00b7mel", "hilf", "!", "was", "seh", "ich", "hier", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKVZ", "$.", "PWS", "VVFIN", "PPER", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Steht nicht ein Pallast vor mir,", "tokens": ["Steht", "nicht", "ein", "Pal\u00b7last", "vor", "mir", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "ART", "NN", "APPR", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Welchem Diamantne Seulen", "tokens": ["Wel\u00b7chem", "Di\u00b7a\u00b7mant\u00b7ne", "Seu\u00b7len"], "token_info": ["word", "word", "word"], "pos": ["PWAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Grund und Festigkeit ertheilen,", "tokens": ["Grund", "und", "Fes\u00b7tig\u00b7keit", "er\u00b7thei\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Dessen Boden Marmorstein,", "tokens": ["Des\u00b7sen", "Bo\u00b7den", "Mar\u00b7mor\u00b7stein", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PDAT", "NN", "NE", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Sims und Dach Saphir mu\u00df seyn.", "tokens": ["Sims", "und", "Dach", "Sa\u00b7phir", "mu\u00df", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "NN", "NE", "VMFIN", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.23": {"line.1": {"text": "Warlich Bau und Pracht ist stoltz!", "tokens": ["War\u00b7lich", "Bau", "und", "Pracht", "ist", "stoltz", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "KON", "NN", "VAFIN", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "W\u00e4nde von Cypressen-Holtz,", "tokens": ["W\u00e4n\u00b7de", "von", "Cy\u00b7pres\u00b7sen\u00b7Holtz", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPR", "NE", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Thurn und Thore von Topasen,", "tokens": ["Thurn", "und", "Tho\u00b7re", "von", "To\u00b7pa\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "NN", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Rings umher Smaragdne Rasen,", "tokens": ["Rings", "um\u00b7her", "Sma\u00b7ragd\u00b7ne", "Ra\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PTKVZ", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Voller Schmeltz und Chrysolith,", "tokens": ["Vol\u00b7ler", "Sch\u00b7meltz", "und", "Chry\u00b7so\u00b7lith", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "KON", "NE", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.6": {"text": "Der an statt der Blumen bl\u00fcht.", "tokens": ["Der", "an", "statt", "der", "Blu\u00b7men", "bl\u00fcht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.24": {"line.1": {"text": "Macht mir nicht die Zauber-Kunst", "tokens": ["Macht", "mir", "nicht", "die", "Zau\u00b7ber\u00b7Kunst"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "PPER", "PTKNEG", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Durch Verblendung blauen Dunst?", "tokens": ["Durch", "Ver\u00b7blen\u00b7dung", "blau\u00b7en", "Dunst", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Nein! die Phantasey der Dichter", "tokens": ["Nein", "!", "die", "Phan\u00b7ta\u00b7sey", "der", "Dich\u00b7ter"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["PTKANT", "$.", "ART", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Tr\u00fcgt mir Geist und Augenlichter,", "tokens": ["Tr\u00fcgt", "mir", "Geist", "und", "Au\u00b7gen\u00b7lich\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Zeigt und stellt so wunderbar", "tokens": ["Zeigt", "und", "stellt", "so", "wun\u00b7der\u00b7bar"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "KON", "VVFIN", "ADV", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Ein Poetisch Lufft-Schlo\u00df dar.", "tokens": ["Ein", "Poe\u00b7tisch", "Lufft\u00b7Schlo\u00df", "dar", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "PTKVZ", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.25": {"line.1": {"text": "Blo\u00df die Tyber und der Po", "tokens": ["Blo\u00df", "die", "Ty\u00b7ber", "und", "der", "Po"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "KON", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Blenden unsre Deutsche so,", "tokens": ["Blen\u00b7den", "uns\u00b7re", "Deut\u00b7sche", "so", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df der Bach der Castalinnen,", "tokens": ["Da\u00df", "der", "Bach", "der", "Cas\u00b7ta\u00b7lin\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Viel zu ruhig scheint zu rinnen:", "tokens": ["Viel", "zu", "ru\u00b7hig", "scheint", "zu", "rin\u00b7nen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKA", "ADJD", "VVFIN", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Wenn sie sich um den Marin", "tokens": ["Wenn", "sie", "sich", "um", "den", "Ma\u00b7rin"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PRF", "APPR", "ART", "NN"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.6": {"text": "Mehr als den Virgil bem\u00fchn.", "tokens": ["Mehr", "als", "den", "Vir\u00b7gil", "be\u00b7m\u00fchn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "KOKOM", "ART", "NN", "VVINF", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.26": {"line.1": {"text": "Freunde, was bezaubert euch?", "tokens": ["Freun\u00b7de", ",", "was", "be\u00b7zau\u00b7bert", "euch", "?"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PWS", "VVFIN", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Werdet doch den Griechen gleich,", "tokens": ["Wer\u00b7det", "doch", "den", "Grie\u00b7chen", "gleich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Folgt der alten R\u00f6mer Th\u00f6nen,", "tokens": ["Folgt", "der", "al\u00b7ten", "R\u00f6\u00b7mer", "Th\u00f6\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Nicht Italiens Sirenen,", "tokens": ["Nicht", "I\u00b7ta\u00b7li\u00b7ens", "Si\u00b7re\u00b7nen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PTKNEG", "NE", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Die durch ihrer Hoheit Schein", "tokens": ["Die", "durch", "ih\u00b7rer", "Ho\u00b7heit", "Schein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "PPOSAT", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Der Vernunfft ein Fallbret seyn.", "tokens": ["Der", "Ver\u00b7nunfft", "ein", "Fall\u00b7bret", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.27": {"line.1": {"text": "Weg mit Gold und Elfenbein,", "tokens": ["Weg", "mit", "Gold", "und", "El\u00b7fen\u00b7bein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Nectar, Muscateller-Wein,", "tokens": ["Nec\u00b7tar", ",", "Mus\u00b7ca\u00b7tel\u00b7ler\u00b7Wein", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Mosch, Zibeth und Amber-Kuchen,", "tokens": ["Mosch", ",", "Zi\u00b7beth", "und", "Am\u00b7ber\u00b7Ku\u00b7chen", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Hofmannswaldau mag sie suchen,", "tokens": ["Hof\u00b7manns\u00b7wal\u00b7dau", "mag", "sie", "su\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Lohensteins Geruch und Art", "tokens": ["Lo\u00b7hen\u00b7steins", "Ge\u00b7ruch", "und", "Art"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "NN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Sey der Biesam vorgespart!", "tokens": ["Sey", "der", "Bie\u00b7sam", "vor\u00b7ge\u00b7spart", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.28": {"line.1": {"text": "Neukirch! du hast wohl verdient,", "tokens": ["Neu\u00b7kirch", "!", "du", "hast", "wohl", "ver\u00b7dient", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "PPER", "VAFIN", "ADV", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Da\u00df dein Lorber ewig gr\u00fcnt,", "tokens": ["Da\u00df", "dein", "Lor\u00b7ber", "e\u00b7wig", "gr\u00fcnt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "ADJD", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Du entgiengst den leeren Schrancken", "tokens": ["Du", "ent\u00b7giengst", "den", "lee\u00b7ren", "Schran\u00b7cken"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ubersteigender Gedancken,", "tokens": ["U\u00b7bers\u00b7tei\u00b7gen\u00b7der", "Ge\u00b7dan\u00b7cken", ","], "token_info": ["word", "word", "punct"], "pos": ["APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Suchtst und fandst die alte Spur", "tokens": ["Suchtst", "und", "fandst", "die", "al\u00b7te", "Spur"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "KON", "VVFIN", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Der Vernunfft und der Natur.", "tokens": ["Der", "Ver\u00b7nunfft", "und", "der", "Na\u00b7tur", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.29": {"line.1": {"text": "Folgt, ihr Br\u00fcder! folgt ihm nach,", "tokens": ["Folgt", ",", "ihr", "Br\u00fc\u00b7der", "!", "folgt", "ihm", "nach", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PPOSAT", "NN", "$.", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Seht wie Canitz Lorbern brach,", "tokens": ["Seht", "wie", "Ca\u00b7nitz", "Lor\u00b7bern", "brach", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KOKOM", "NE", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Den uns Neukirch angewiesen,", "tokens": ["Den", "uns", "Neu\u00b7kirch", "an\u00b7ge\u00b7wie\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Als er den von Fuchs gepriesen:", "tokens": ["Als", "er", "den", "von", "Fuchs", "ge\u00b7prie\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "APPR", "NE", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Stimmt, wie G\u00fcnther l\u00e4ngst gethan,", "tokens": ["Stimmt", ",", "wie", "G\u00fcn\u00b7ther", "l\u00e4ngst", "ge\u00b7than", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PWAV", "NE", "ADV", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Ausgespielte Fl\u00f6ten an.", "tokens": ["Aus\u00b7ge\u00b7spiel\u00b7te", "Fl\u00f6\u00b7ten", "an", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.30": {"line.1": {"text": "Du, mein h\u00f6chstgeliebter M\u00e4y!", "tokens": ["Du", ",", "mein", "h\u00f6chst\u00b7ge\u00b7lieb\u00b7ter", "M\u00e4y", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PPOSAT", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Fliehst der Faunen Wald-Geschrey,", "tokens": ["Fliehst", "der", "Fau\u00b7nen", "Wald\u00b7Ge\u00b7schrey", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Kennst und liebst die reinen Th\u00f6ne", "tokens": ["Kennst", "und", "liebst", "die", "rei\u00b7nen", "Th\u00f6\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "KON", "VVFIN", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Kunst-ge\u00fcbter Musen-S\u00f6hne.", "tokens": ["Kunst\u00b7ge\u00b7\u00fcb\u00b7ter", "Mu\u00b7sen\u00b7S\u00f6h\u00b7ne", "."], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Sage doch, was mir gebricht,", "tokens": ["Sa\u00b7ge", "doch", ",", "was", "mir", "ge\u00b7bricht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "$,", "PWS", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Denn ich wei\u00df, du schmeichelst nicht!", "tokens": ["Denn", "ich", "wei\u00df", ",", "du", "schmei\u00b7chelst", "nicht", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "$,", "PPER", "VVFIN", "PTKNEG", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}