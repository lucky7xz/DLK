{"dta.poem.11993": {"metadata": {"author": {"name": "R\u00fcckert, Friedrich", "birth": "N.A.", "death": "N.A."}, "title": "13.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1839", "urn": "urn:nbn:de:kobv:b4-200905195119", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Das Menschlichste an uns, das Sprechen und das Denken,", "tokens": ["Das", "Menschlichs\u00b7te", "an", "uns", ",", "das", "Spre\u00b7chen", "und", "das", "Den\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPER", "$,", "ART", "NN", "KON", "ART", "NN", "$,"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "La\u00df es entschlossen uns ins G\u00f6ttliche versenken.", "tokens": ["La\u00df", "es", "ent\u00b7schlos\u00b7sen", "uns", "ins", "G\u00f6tt\u00b7li\u00b7che", "ver\u00b7sen\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "VVFIN", "PPER", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Die Seel' hat nicht zuvor gesprochen und gedacht,", "tokens": ["Die", "Seel'", "hat", "nicht", "zu\u00b7vor", "ge\u00b7spro\u00b7chen", "und", "ge\u00b7dacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PTKNEG", "ADV", "VVPP", "KON", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Eh dies Bed\u00fcrfnis ihr die Leiblichkeit gebracht.", "tokens": ["Eh", "dies", "Be\u00b7d\u00fcrf\u00b7nis", "ihr", "die", "Leib\u00b7lich\u00b7keit", "ge\u00b7bracht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDS", "NN", "PPER", "ART", "NN", "VVPP", "$."], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}}, "stanza.3": {"line.1": {"text": "Und mit der Leiblichkeit wird sie entgehn den Schranken", "tokens": ["Und", "mit", "der", "Leib\u00b7lich\u00b7keit", "wird", "sie", "ent\u00b7gehn", "den", "Schran\u00b7ken"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "VAFIN", "PPER", "VVFIN", "ART", "NN"], "meter": "-+-+-+---+-+-", "measure": "unknown.measure.penta"}, "line.2": {"text": "Verworrner Worte und verworrnerer Gedanken.", "tokens": ["Ver\u00b7worr\u00b7ner", "Wor\u00b7te", "und", "ver\u00b7worr\u00b7ne\u00b7rer", "Ge\u00b7dan\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "KON", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Sie wird die Wesenheit der Ding' in Gott erkennen,", "tokens": ["Sie", "wird", "die", "We\u00b7sen\u00b7heit", "der", "Ding'", "in", "Gott", "er\u00b7ken\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "ART", "NN", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Nicht mit zweideutigen Bezeichnungen benennen.", "tokens": ["Nicht", "mit", "zwei\u00b7deu\u00b7ti\u00b7gen", "Be\u00b7zeich\u00b7nun\u00b7gen", "be\u00b7nen\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Das Denken bleibt ihr, das das Ganze ganz erkennt,", "tokens": ["Das", "Den\u00b7ken", "bleibt", "ihr", ",", "das", "das", "Gan\u00b7ze", "ganz", "er\u00b7kennt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "$,", "PRELS", "ART", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Nicht das Gest\u00fcckte, das zusammensetzt und trennt.", "tokens": ["Nicht", "das", "Ge\u00b7st\u00fcck\u00b7te", ",", "das", "zu\u00b7sam\u00b7men\u00b7setzt", "und", "trennt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ART", "NN", "$,", "PRELS", "ADV", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Schon jeden Augenblick, wo du dich hier versenkest", "tokens": ["Schon", "je\u00b7den", "Au\u00b7gen\u00b7blick", ",", "wo", "du", "dich", "hier", "ver\u00b7sen\u00b7kest"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "PIAT", "NN", "$,", "PWAV", "PPER", "PRF", "ADV", "VVFIN"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Ins H\u00f6chste, f\u00fchlst du da\u00df du h\u00f6h'res thust als denkest.", "tokens": ["Ins", "H\u00f6chs\u00b7te", ",", "f\u00fchlst", "du", "da\u00df", "du", "h\u00f6h'\u00b7res", "thust", "als", "den\u00b7kest", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "$,", "VVFIN", "PPER", "KOUS", "PPER", "ADJA", "VVFIN", "KOKOM", "VVFIN", "$."], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}}}}}