{"textgrid.poem.32579": {"metadata": {"author": {"name": "Wieland, Christoph Martin", "birth": "N.A.", "death": "N.A."}, "title": "Eine Anekdote aus dem Olymp", "genre": "verse", "period": "N.A.", "pub_year": 1773, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Das dreimal Drei der Musenschar,", "tokens": ["Das", "drei\u00b7mal", "Drei", "der", "Mu\u00b7sen\u00b7schar", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "CARD", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "die heilge Vier der sch\u00f6nen Horen,", "tokens": ["die", "heil\u00b7ge", "Vier", "der", "sch\u00f6\u00b7nen", "Ho\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "die Grazien im goldnen Haar,", "tokens": ["die", "Gra\u00b7zi\u00b7en", "im", "gold\u00b7nen", "Haar", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "und Bacchus und Apoll, mit Amorn und mit Floren,", "tokens": ["und", "Bac\u00b7chus", "und", "A\u00b7poll", ",", "mit", "A\u00b7morn", "und", "mit", "Flo\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "KON", "NN", "$,", "APPR", "NE", "KON", "APPR", "NN", "$,"], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.5": {"text": "fr\u00fchst\u00fcckten s\u00e4mtlich bei Auroren", "tokens": ["fr\u00fch\u00b7st\u00fcck\u00b7ten", "s\u00e4mt\u00b7lich", "bei", "Au\u00b7ro\u00b7ren"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "ADJD", "APPR", "NE"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "am ersten Tag im Januar.", "tokens": ["am", "ers\u00b7ten", "Tag", "im", "Ja\u00b7nu\u00b7ar", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Merkur, der nicht erwartet war,", "tokens": ["Mer\u00b7kur", ",", "der", "nicht", "er\u00b7war\u00b7tet", "war", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PRELS", "PTKNEG", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "kam aus des Luftmeers d\u00fcnnen Wogen", "tokens": ["kam", "aus", "des", "Luft\u00b7meers", "d\u00fcn\u00b7nen", "Wo\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "\u00e0 la Montgolfier geflogen,", "tokens": ["\u00e0", "la", "Mont\u00b7gol\u00b7fier", "ge\u00b7flo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["FM", "FM", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "und, \u00bbFriede\u00ab, sprach er, \u00bbsei mit Euch!", "tokens": ["und", ",", "\u00bb", "Frie\u00b7de", "\u00ab", ",", "sprach", "er", ",", "\u00bb", "sei", "mit", "Euch", "!"], "token_info": ["word", "punct", "punct", "word", "punct", "punct", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["KON", "$,", "$(", "NN", "$(", "$,", "VVFIN", "PPER", "$,", "$(", "VAFIN", "APPR", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Euch G\u00f6ttervolk im Himmelreich,", "tokens": ["Euch", "G\u00f6t\u00b7ter\u00b7volk", "im", "Him\u00b7mel\u00b7reich", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "zu nichts als ewger Lust erzogen,", "tokens": ["zu", "nichts", "als", "ew\u00b7ger", "Lust", "er\u00b7zo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "KOKOM", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "sind freilich alle Tage gleich.", "tokens": ["sind", "frei\u00b7lich", "al\u00b7le", "Ta\u00b7ge", "gleich", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PIAT", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Allein, dort unten auf der Erden", "tokens": ["Al\u00b7lein", ",", "dort", "un\u00b7ten", "auf", "der", "Er\u00b7den"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "$,", "ADV", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "ist heut der erste Januar;", "tokens": ["ist", "heut", "der", "ers\u00b7te", "Ja\u00b7nu\u00b7ar", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "der pflegt daselbst gar sonderbar", "tokens": ["der", "pflegt", "da\u00b7selbst", "gar", "son\u00b7der\u00b7bar"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "VVFIN", "PAV", "ADV", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "von Gro\u00df und Klein chommiert zu werden,", "tokens": ["von", "Gro\u00df", "und", "Klein", "chom\u00b7miert", "zu", "wer\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "KON", "NE", "NE", "PTKZU", "VAINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "denn heute gilt's f\u00fcrs ganze Jahr.", "tokens": ["denn", "heu\u00b7te", "gilt's", "f\u00fcrs", "gan\u00b7ze", "Jahr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Die Leute die was zu geben haben", "tokens": ["Die", "Leu\u00b7te", "die", "was", "zu", "ge\u00b7ben", "ha\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "PIS", "PTKZU", "VVINF", "VAFIN"], "meter": "-+-++-+-+-", "measure": "unknown.measure.penta"}, "line.14": {"text": "beschenken einander mit kleinen Gaben;", "tokens": ["be\u00b7schen\u00b7ken", "ein\u00b7an\u00b7der", "mit", "klei\u00b7nen", "Ga\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "APPR", "ADJA", "NN", "$."], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.15": {"text": "doch, wer nicht schwer am Seckel tr\u00e4gt,", "tokens": ["doch", ",", "wer", "nicht", "schwer", "am", "Se\u00b7ckel", "tr\u00e4gt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PWS", "PTKNEG", "ADJD", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "und lieber ihn sich f\u00fcllen lie\u00dfe,", "tokens": ["und", "lie\u00b7ber", "ihn", "sich", "f\u00fcl\u00b7len", "lie\u00b7\u00dfe", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PPER", "PRF", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.17": {"text": "schleicht tiefgeb\u00fcckt heran und legt", "tokens": ["schleicht", "tief\u00b7ge\u00b7b\u00fcckt", "he\u00b7ran", "und", "legt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADJD", "PTKVZ", "KON", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.18": {"text": "in Demut \u2013 ", "tokens": ["in", "De\u00b7mut", "\u2013"], "token_info": ["word", "word", "punct"], "pos": ["APPR", "NN", "$("], "meter": "-+-", "measure": "amphibrach.single"}}, "stanza.3": {"line.1": {"text": "Ihr, denen's an Gaben nicht gebricht,", "tokens": ["Ihr", ",", "de\u00b7nen's", "an", "Ga\u00b7ben", "nicht", "ge\u00b7bricht", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PRELS", "APPR", "NN", "PTKNEG", "VVFIN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Wohlan, ihr lieblichen G\u00f6ttinnen,", "tokens": ["Wo\u00b7hlan", ",", "ihr", "lieb\u00b7li\u00b7chen", "G\u00f6t\u00b7tin\u00b7nen", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "erinnert euch die sch\u00f6ne Pflicht", "tokens": ["e\u00b7rin\u00b7nert", "euch", "die", "sch\u00f6\u00b7ne", "Pflicht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "der Dankbarkeit und Liebe nicht,", "tokens": ["der", "Dank\u00b7bar\u00b7keit", "und", "Lie\u00b7be", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "auf Gaben f\u00fcr eine F\u00fcrstin zu sinnen", "tokens": ["auf", "Ga\u00b7ben", "f\u00fcr", "ei\u00b7ne", "F\u00fcrs\u00b7tin", "zu", "sin\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "APPR", "ART", "NN", "PTKZU", "VVINF"], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "die, eure Freundschaft zu gewinnen,", "tokens": ["die", ",", "eu\u00b7re", "Freund\u00b7schaft", "zu", "ge\u00b7win\u00b7nen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "PPOSAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "euch stets die sch\u00f6nsten Kr\u00e4nze flicht?", "tokens": ["euch", "stets", "die", "sch\u00f6ns\u00b7ten", "Kr\u00e4n\u00b7ze", "flicht", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "die Erste eurer Priesterinnen!\u00ab", "tokens": ["die", "Ers\u00b7te", "eu\u00b7rer", "Pries\u00b7te\u00b7rin\u00b7nen", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "ADJA", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Die Damen in Aurorens Saal,", "tokens": ["Die", "Da\u00b7men", "in", "Au\u00b7ro\u00b7rens", "Saal", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NE", "NE", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.2": {"text": "indem sie ihren Nektar schl\u00fcrfen", "tokens": ["in\u00b7dem", "sie", "ih\u00b7ren", "Nek\u00b7tar", "schl\u00fcr\u00b7fen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "besch\u00e4ftigt, denk ich, mit Entw\u00fcrfen", "tokens": ["be\u00b7sch\u00e4f\u00b7tigt", ",", "denk", "ich", ",", "mit", "Ent\u00b7w\u00fcr\u00b7fen"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word"], "pos": ["VVPP", "$,", "VVFIN", "PPER", "$,", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "von Putz zum n\u00e4chsten G\u00f6tter-Bal,", "tokens": ["von", "Putz", "zum", "n\u00e4chs\u00b7ten", "G\u00f6t\u00b7ter\u00b7Bal", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "entschuldigen sich allzumal.", "tokens": ["ent\u00b7schul\u00b7di\u00b7gen", "sich", "all\u00b7zu\u00b7mal", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "\u00bbwas k\u00f6nnt Olympia bed\u00fcrfen?", "tokens": ["\u00bb", "was", "k\u00f6nnt", "O\u00b7lym\u00b7pia", "be\u00b7d\u00fcr\u00b7fen", "?"], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "VVFIN", "NE", "VVINF", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.7": {"text": "Hat Mutter Natur von Kindheit an", "tokens": ["Hat", "Mut\u00b7ter", "Na\u00b7tur", "von", "Kind\u00b7heit", "an"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "NN", "NN", "APPR", "NN", "APPR"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "nicht alles schon f\u00fcr Sie getan?", "tokens": ["nicht", "al\u00b7les", "schon", "f\u00fcr", "Sie", "ge\u00b7tan", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "PIS", "ADV", "APPR", "PPER", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "ihr Bestes nicht an Ihr verspendet?", "tokens": ["ihr", "Bes\u00b7tes", "nicht", "an", "Ihr", "ver\u00b7spen\u00b7det", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PTKNEG", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Hat nicht Ihr eigner Genius", "tokens": ["Hat", "nicht", "Ihr", "eig\u00b7ner", "Ge\u00b7nius"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "PTKNEG", "PPOSAT", "ADJA", "NN"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.11": {"text": "die Arbeit der Natur vollendet?", "tokens": ["die", "Ar\u00b7beit", "der", "Na\u00b7tur", "voll\u00b7en\u00b7det", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Und macht was mancher Mann auf us", "tokens": ["Und", "macht", "was", "man\u00b7cher", "Mann", "auf", "us"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PIS", "PIAT", "NN", "APPR", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "wohl unbegriffen lassen mu\u00df", "tokens": ["wohl", "un\u00b7be\u00b7grif\u00b7fen", "las\u00b7sen", "mu\u00df"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ADJD", "VVINF", "VMFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "nicht t\u00e4glich noch Ihr Flei\u00df sich eigen?", "tokens": ["nicht", "t\u00e4g\u00b7lich", "noch", "Ihr", "Flei\u00df", "sich", "ei\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADJD", "ADV", "PPOSAT", "NN", "PRF", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "Jedoch, zu allem \u00dcberflu\u00df,", "tokens": ["Je\u00b7doch", ",", "zu", "al\u00b7lem", "\u00dc\u00b7berf\u00b7lu\u00df", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "APPR", "PIS", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "und blo\u00df den guten Willen zu zeigen,", "tokens": ["und", "blo\u00df", "den", "gu\u00b7ten", "Wil\u00b7len", "zu", "zei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "ADJA", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.17": {"text": "da, lieber Herr Merkurius,", "tokens": ["da", ",", "lie\u00b7ber", "Herr", "Mer\u00b7ku\u00b7rius", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "ADV", "NN", "NE", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.18": {"text": "pack er, was wir von unsern Dingen", "tokens": ["pack", "er", ",", "was", "wir", "von", "un\u00b7sern", "Din\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "$,", "PRELS", "PPER", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.19": {"text": "in aller Eil zusammenbringen,", "tokens": ["in", "al\u00b7ler", "Eil", "zu\u00b7sam\u00b7men\u00b7brin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.20": {"text": "h\u00fcbsch sauber auf, dann flieg er frisch", "tokens": ["h\u00fcbsch", "sau\u00b7ber", "auf", ",", "dann", "flieg", "er", "frisch"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADJD", "ADJD", "PTKVZ", "$,", "ADV", "VVFIN", "PPER", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.21": {"text": "und leg's der F\u00fcrstin auf den Tisch.", "tokens": ["und", "leg's", "der", "F\u00fcrs\u00b7tin", "auf", "den", "Tisch", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.22": {"text": "Nur sei er honett, Herr Seelenzwinger,", "tokens": ["Nur", "sei", "er", "ho\u00b7nett", ",", "Herr", "See\u00b7len\u00b7zwin\u00b7ger", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "$,", "NN", "NN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.23": {"text": "und mach er keine krumme Finger!\u00ab", "tokens": ["und", "mach", "er", "kei\u00b7ne", "krum\u00b7me", "Fin\u00b7ger", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "PPER", "PIAT", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Jetzt ging's, mit einer Schw\u00e4rmerei", "tokens": ["Jetzt", "ging's", ",", "mit", "ei\u00b7ner", "Schw\u00e4r\u00b7me\u00b7rei"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "$,", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "die man von ihnen nur vor zwei", "tokens": ["die", "man", "von", "ih\u00b7nen", "nur", "vor", "zwei"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "PIS", "APPR", "PPER", "ADV", "APPR", "CARD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Minuten nicht vermutet h\u00e4tte,", "tokens": ["Mi\u00b7nu\u00b7ten", "nicht", "ver\u00b7mu\u00b7tet", "h\u00e4t\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PTKNEG", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "an ein Begaben in die Wette.", "tokens": ["an", "ein", "Be\u00b7ga\u00b7ben", "in", "die", "Wet\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Die Pieriden, als ihrer Neun,", "tokens": ["Die", "Pie\u00b7ri\u00b7den", ",", "als", "ih\u00b7rer", "Neun", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "KOUS", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "wollen, wie billig, die ersten sein.", "tokens": ["wol\u00b7len", ",", "wie", "bil\u00b7lig", ",", "die", "ers\u00b7ten", "sein", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VMFIN", "$,", "PWAV", "ADJD", "$,", "ART", "ADJA", "VAINF", "$."], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.3": {"text": "Man mu\u00dfte nach ihrem Gewimmel denken", "tokens": ["Man", "mu\u00df\u00b7te", "nach", "ih\u00b7rem", "Ge\u00b7wim\u00b7mel", "den\u00b7ken"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VMFIN", "APPR", "PPOSAT", "NN", "VVINF"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "sie h\u00e4tten gewaltig viel zu schenken.", "tokens": ["sie", "h\u00e4t\u00b7ten", "ge\u00b7wal\u00b7tig", "viel", "zu", "schen\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Doch, da sie ihren ganzen Kram", "tokens": ["Doch", ",", "da", "sie", "ih\u00b7ren", "gan\u00b7zen", "Kram"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "$,", "KOUS", "PPER", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "durchsucht, bestunden sie mit Scham.", "tokens": ["durch\u00b7sucht", ",", "be\u00b7stun\u00b7den", "sie", "mit", "Scham", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "VVFIN", "PPER", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Sie selber hatten schon vor Jahren", "tokens": ["Sie", "sel\u00b7ber", "hat\u00b7ten", "schon", "vor", "Jah\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "VAFIN", "ADV", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "der F\u00fcrstin in die sie vergeistert waren", "tokens": ["der", "F\u00fcrs\u00b7tin", "in", "die", "sie", "ver\u00b7geis\u00b7tert", "wa\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "PRELS", "PPER", "VVPP", "VAFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "mit allem was der Musensitz", "tokens": ["mit", "al\u00b7lem", "was", "der", "Mu\u00b7sen\u00b7sitz"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PIS", "PWS", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "hervorbringt an Geschmack und Witz,", "tokens": ["her\u00b7vor\u00b7bringt", "an", "Ge\u00b7schmack", "und", "Witz", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "(ohn auf die Zukunft was zu sparen)", "tokens": ["(", "ohn", "auf", "die", "Zu\u00b7kunft", "was", "zu", "spa\u00b7ren", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "APPR", "ART", "NN", "PIS", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "mit jedem Talent und jedem Trieb", "tokens": ["mit", "je\u00b7dem", "Ta\u00b7lent", "und", "je\u00b7dem", "Trieb"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PIAT", "NN", "KON", "PIAT", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.13": {"text": "der es entwickelt, so reich versehen,", "tokens": ["der", "es", "ent\u00b7wi\u00b7ckelt", ",", "so", "reich", "ver\u00b7se\u00b7hen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVPP", "$,", "ADV", "ADJD", "VVPP", "$,"], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}, "line.14": {"text": "da\u00df nun den guten alten Feen", "tokens": ["da\u00df", "nun", "den", "gu\u00b7ten", "al\u00b7ten", "Feen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "ART", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "nichts mehr zu geben \u00fcbrig blieb.", "tokens": ["nichts", "mehr", "zu", "ge\u00b7ben", "\u00fcb\u00b7rig", "blieb", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "PIS", "PTKZU", "VVINF", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Apoll, auf den sie um Beistand sahn,", "tokens": ["A\u00b7poll", ",", "auf", "den", "sie", "um", "Bei\u00b7stand", "sahn", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "APPR", "PRELS", "PPER", "APPR", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "nahm ihrer sich aus Mitleid an.", "tokens": ["nahm", "ih\u00b7rer", "sich", "aus", "Mit\u00b7leid", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "PRF", "APPR", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "\u00bbich selber w\u00fc\u00dfte, bei meinem Leben!\u00ab", "tokens": ["\u00bb", "ich", "sel\u00b7ber", "w\u00fc\u00df\u00b7te", ",", "bei", "mei\u00b7nem", "Le\u00b7ben", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPER", "ADV", "VVFIN", "$,", "APPR", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "sprach er, \u00bbOlympien nichts zu geben", "tokens": ["sprach", "er", ",", "\u00bb", "O\u00b7lym\u00b7pien", "nichts", "zu", "ge\u00b7ben"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "$,", "$(", "NE", "PIS", "PTKZU", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "das Sie nicht besser h\u00e4tt \u2013 Allein,", "tokens": ["das", "Sie", "nicht", "bes\u00b7ser", "h\u00e4tt", "\u2013", "Al\u00b7lein", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "PPER", "PTKNEG", "ADJD", "VAFIN", "$(", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "betreffend die Herrn und Fr\u00e4ulein fein,", "tokens": ["be\u00b7tref\u00b7fend", "die", "Herrn", "und", "Fr\u00e4u\u00b7lein", "fein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ART", "NN", "KON", "NN", "ADJD", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "die Ihr als Commensalen dienen,", "tokens": ["die", "Ihr", "als", "Com\u00b7men\u00b7sa\u00b7len", "die\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "KOUS", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "(doch nichts f\u00fcr ungut!) bei manchen von ihnen", "tokens": ["(", "doch", "nichts", "f\u00fcr", "un\u00b7gut", "!", ")", "bei", "man\u00b7chen", "von", "ih\u00b7nen"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word"], "pos": ["$(", "ADV", "PIS", "APPR", "ADJD", "$.", "$(", "APPR", "PIAT", "APPR", "PPER"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "mag dies der Fall nicht immer sein.", "tokens": ["mag", "dies", "der", "Fall", "nicht", "im\u00b7mer", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PDS", "ART", "NN", "PTKNEG", "ADV", "VAINF", "$."], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.10": {"text": "Drum d\u00e4cht ich wir schickten insgemein", "tokens": ["Drum", "d\u00e4cht", "ich", "wir", "schick\u00b7ten", "ins\u00b7ge\u00b7mein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "PPER", "PPER", "VVFIN", "ADV"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.11": {"text": "zur Notdurft der Dipnosophisten,", "tokens": ["zur", "Not\u00b7durft", "der", "Dip\u00b7no\u00b7so\u00b7phis\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "$,"], "meter": "-+---+-+-", "measure": "dactylic.init"}, "line.12": {"text": "die unsre F\u00fcrstin in Ihrer Pfalz", "tokens": ["die", "uns\u00b7re", "F\u00fcrs\u00b7tin", "in", "Ih\u00b7rer", "Pfalz"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "PPOSAT", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.13": {"text": "bei Tafel zu amusieren gel\u00fcsten,", "tokens": ["bei", "Ta\u00b7fel", "zu", "a\u00b7mu\u00b7sie\u00b7ren", "ge\u00b7l\u00fcs\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PTKZU", "VVINF", "VVPP", "$,"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.14": {"text": "Ihr einen Zentner \u2013 Attisch Salz.\u00ab", "tokens": ["Ihr", "ei\u00b7nen", "Zent\u00b7ner", "\u2013", "At\u00b7tisch", "Salz", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["PPER", "ART", "NN", "$(", "NE", "NE", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "\u00bbder Einfall hat sich traun! gewaschen\u00ab,", "tokens": ["\u00bb", "der", "Ein\u00b7fall", "hat", "sich", "traun", "!", "ge\u00b7wa\u00b7schen", "\u00ab", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "punct", "punct"], "pos": ["$(", "ART", "NN", "VAFIN", "PRF", "VVINF", "$.", "ADJA", "$(", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "f\u00e4llt Bacchus, der Freudengeber, ein:", "tokens": ["f\u00e4llt", "Bac\u00b7chus", ",", "der", "Freu\u00b7den\u00b7ge\u00b7ber", ",", "ein", ":"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["VVFIN", "NE", "$,", "ART", "NN", "$,", "PTKVZ", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "\u00bbich selber lege dreihundert Flaschen", "tokens": ["\u00bb", "ich", "sel\u00b7ber", "le\u00b7ge", "drei\u00b7hun\u00b7dert", "Fla\u00b7schen"], "token_info": ["punct", "word", "word", "word", "word", "word"], "pos": ["$(", "PPER", "ADV", "VVFIN", "CARD", "NN"], "meter": "-+---+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "dazu, von meinem besten Wein;", "tokens": ["da\u00b7zu", ",", "von", "mei\u00b7nem", "bes\u00b7ten", "Wein", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "$,", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "die Herren werden im Einfall-Haschen", "tokens": ["die", "Her\u00b7ren", "wer\u00b7den", "im", "Ein\u00b7fall\u00b7Ha\u00b7schen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "APPRART", "NN"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "dabei nur desto prompter sein.", "tokens": ["da\u00b7bei", "nur", "des\u00b7to", "promp\u00b7ter", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ADV", "ADV", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Was auch die Kammerherren sagen,", "tokens": ["Was", "auch", "die", "Kam\u00b7mer\u00b7her\u00b7ren", "sa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "der Wein gibt Witz und st\u00e4rkt den Magen.\u00ab", "tokens": ["der", "Wein", "gibt", "Witz", "und", "st\u00e4rkt", "den", "Ma\u00b7gen", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "VVFIN", "NN", "KON", "VVFIN", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Jetzt traf die Grazien die Reih:", "tokens": ["Jetzt", "traf", "die", "Gra\u00b7zi\u00b7en", "die", "Reih", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die fanden, ohne sich lang im Busen", "tokens": ["Die", "fan\u00b7den", ",", "oh\u00b7ne", "sich", "lang", "im", "Bu\u00b7sen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "$,", "KOUI", "PRF", "ADJD", "APPRART", "NN"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "zu krabbeln, da\u00df der Fall der Musen", "tokens": ["zu", "krab\u00b7beln", ",", "da\u00df", "der", "Fall", "der", "Mu\u00b7sen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PTKZU", "VVINF", "$,", "KOUS", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "just auch ihr eigner casus sei.", "tokens": ["just", "auch", "ihr", "eig\u00b7ner", "ca\u00b7sus", "sei", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPOSAT", "ADJA", "NE", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "\u00bbwas wir nicht selbst an Sie verschwendet,", "tokens": ["\u00bb", "was", "wir", "nicht", "selbst", "an", "Sie", "ver\u00b7schwen\u00b7det", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "PPER", "PTKNEG", "ADV", "APPR", "PPER", "VVFIN", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.6": {"text": "das\u00ab, sagten sie, \u00bbhat Sie uns, so fein", "tokens": ["das", "\u00ab", ",", "sag\u00b7ten", "sie", ",", "\u00bb", "hat", "Sie", "uns", ",", "so", "fein"], "token_info": ["word", "punct", "punct", "word", "word", "punct", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "$(", "$,", "VVFIN", "PPER", "$,", "$(", "VAFIN", "PPER", "PPER", "$,", "ADV", "ADJD"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "da\u00df man Ihr's gern verzeiht, entwendet:", "tokens": ["da\u00df", "man", "Ih\u00b7r's", "gern", "ver\u00b7zeiht", ",", "ent\u00b7wen\u00b7det", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "PIS", "PIS", "ADV", "VVFIN", "$,", "VVPP", "$."], "meter": "+-+---+-+-", "measure": "unknown.measure.tetra"}, "line.8": {"text": "Wir k\u00f6nnten leicht gen\u00f6tigt sein", "tokens": ["Wir", "k\u00f6nn\u00b7ten", "leicht", "ge\u00b7n\u00f6\u00b7tigt", "sein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ADJD", "VVPP", "VAINF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "am Ende gar heut oder morgen,", "tokens": ["am", "En\u00b7de", "gar", "heut", "o\u00b7der", "mor\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADV", "ADV", "KON", "ADV", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "anstatt zu geben, bei Ihr zu borgen.\u00ab", "tokens": ["an\u00b7statt", "zu", "ge\u00b7ben", ",", "bei", "Ihr", "zu", "bor\u00b7gen", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUI", "PTKZU", "VVINF", "$,", "APPR", "PPER", "PTKZU", "VVINF", "$.", "$("], "meter": "+--+-+--+-", "measure": "iambic.tetra.invert"}}, "stanza.10": {"line.1": {"text": "\u00bbauf diesen Fall\u00ab, f\u00e4llt Amor ein,", "tokens": ["\u00bb", "auf", "die\u00b7sen", "Fall", "\u00ab", ",", "f\u00e4llt", "A\u00b7mor", "ein", ","], "token_info": ["punct", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "PDAT", "NN", "$(", "$,", "VVFIN", "NE", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u00bbist euch kein bessrer Rat zu geben", "tokens": ["\u00bb", "ist", "euch", "kein", "bess\u00b7rer", "Rat", "zu", "ge\u00b7ben"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "VAFIN", "PPER", "PIAT", "ADJA", "NN", "PTKZU", "VVINF"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.3": {"text": "als Tag und Nacht Sie zu umschweben,", "tokens": ["als", "Tag", "und", "Nacht", "Sie", "zu", "um\u00b7schwe\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "NN", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "und, ohne zu merkliches Bestreben,", "tokens": ["und", ",", "oh\u00b7ne", "zu", "merk\u00b7li\u00b7ches", "Be\u00b7stre\u00b7ben", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUI", "APPR", "ADJA", "NN", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "die Pfade von Ihrem sch\u00f6nen Leben", "tokens": ["die", "Pfa\u00b7de", "von", "Ih\u00b7rem", "sch\u00f6\u00b7nen", "Le\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "mit euern Rosen, als spro\u00dften sie eben", "tokens": ["mit", "eu\u00b7ern", "Ro\u00b7sen", ",", "als", "spro\u00df\u00b7ten", "sie", "e\u00b7ben"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "$,", "KOUS", "VVFIN", "PPER", "ADV"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "von selbst hervor, zu \u00fcberstreun.\u00ab", "tokens": ["von", "selbst", "her\u00b7vor", ",", "zu", "\u00fc\u00b7bers\u00b7treun", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["APPR", "ADV", "PTKVZ", "$,", "PTKZU", "VVINF", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Die Rede gefiel den Dirnen wohl,", "tokens": ["Die", "Re\u00b7de", "ge\u00b7fiel", "den", "Dir\u00b7nen", "wohl", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "ADV", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "und man beschlo\u00df, ein K\u00f6rbchen voll", "tokens": ["und", "man", "be\u00b7schlo\u00df", ",", "ein", "K\u00f6rb\u00b7chen", "voll"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "PIS", "VVFIN", "$,", "ART", "NN", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "sogleich Merkuren mit zugeben.", "tokens": ["sog\u00b7leich", "Mer\u00b7ku\u00b7ren", "mit", "zu\u00b7ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "APPR", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "\u00bbnoch eins\u00ab, sprach Ph\u00f6bus, \u00bbf\u00e4llt mir bei;", "tokens": ["\u00bb", "noch", "eins", "\u00ab", ",", "sprach", "Ph\u00f6\u00b7bus", ",", "\u00bb", "f\u00e4llt", "mir", "bei", ";"], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "PIS", "$(", "$,", "VVFIN", "NE", "$,", "$(", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "sag Ihren Leib- und Mund-Poeten,", "tokens": ["sag", "Ih\u00b7ren", "Leib", "und", "Mun\u00b7dPo\u00b7e\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "TRUNC", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "wir h\u00e4tten uns die Kuppelei", "tokens": ["wir", "h\u00e4t\u00b7ten", "uns", "die", "Kup\u00b7pe\u00b7lei"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PPER", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "von ", "tokens": ["von"], "token_info": ["word"], "pos": ["APPR"], "meter": "-", "measure": "single.down"}, "line.8": {"text": "f\u00fcr ein und allemal verbeten.\u00ab", "tokens": ["f\u00fcr", "ein", "und", "al\u00b7le\u00b7mal", "ver\u00b7be\u00b7ten", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "ART", "KON", "ADV", "VVFIN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "\u00bbich\u00ab, sprach jetzt Flora, \u00bbhabe mir,", "tokens": ["\u00bb", "ich", "\u00ab", ",", "sprach", "jetzt", "Flo\u00b7ra", ",", "\u00bb", "ha\u00b7be", "mir", ","], "token_info": ["punct", "word", "punct", "punct", "word", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["$(", "PPER", "$(", "$,", "VVFIN", "ADV", "NN", "$,", "$(", "VAFIN", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Olympien meine Dienstbegier", "tokens": ["O\u00b7lym\u00b7pien", "mei\u00b7ne", "Dienst\u00b7be\u00b7gier"], "token_info": ["word", "word", "word"], "pos": ["NE", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "zu zeigen, Ihren Hain erw\u00e4hlt,", "tokens": ["zu", "zei\u00b7gen", ",", "Ih\u00b7ren", "Hain", "er\u00b7w\u00e4hlt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "$,", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "wo freilich dies und das noch fehlt.", "tokens": ["wo", "frei\u00b7lich", "dies", "und", "das", "noch", "fehlt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "PDS", "KON", "PDS", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ma\u00dfregeln hab ich schon genommen,", "tokens": ["Ma\u00df\u00b7re\u00b7geln", "hab", "ich", "schon", "ge\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "la\u00dft mir nur erst den Fr\u00fchling kommen!\u00ab", "tokens": ["la\u00dft", "mir", "nur", "erst", "den", "Fr\u00fch\u00b7ling", "kom\u00b7men", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVIMP", "PPER", "ADV", "ADV", "ART", "NN", "VVINF", "$.", "$("], "meter": "---+-+-+-", "measure": "unknown.measure.tri"}}, "stanza.13": {"line.1": {"text": "Die H\u00f6ren stimmten im Chorus ein", "tokens": ["Die", "H\u00f6\u00b7ren", "stimm\u00b7ten", "im", "Cho\u00b7rus", "ein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "APPRART", "NN", "ART"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "und alle G\u00f6ttinnen und G\u00f6tter", "tokens": ["und", "al\u00b7le", "G\u00f6t\u00b7tin\u00b7nen", "und", "G\u00f6t\u00b7ter"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PIAT", "NN", "KON", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "gelobten Ihr, nebst sch\u00f6nem Wetter", "tokens": ["ge\u00b7lob\u00b7ten", "Ihr", ",", "nebst", "sch\u00f6\u00b7nem", "Wet\u00b7ter"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "PPER", "$,", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "und ewgem ", "tokens": ["und", "ew\u00b7gem"], "token_info": ["word", "word"], "pos": ["KON", "ADJA"], "meter": "-+-", "measure": "amphibrach.single"}, "line.5": {"text": "zu dichten, zu w\u00fcrken und zu wachen", "tokens": ["zu", "dich\u00b7ten", ",", "zu", "w\u00fcr\u00b7ken", "und", "zu", "wa\u00b7chen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "$,", "PTKZU", "VVINF", "KON", "PTKZU", "VVINF"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "um Ihren auserw\u00e4hlten Hain", "tokens": ["um", "Ih\u00b7ren", "au\u00b7ser\u00b7w\u00e4hl\u00b7ten", "Hain"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "zu einem Paradies zu machen.", "tokens": ["zu", "ei\u00b7nem", "Pa\u00b7ra\u00b7dies", "zu", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "\u00bbwas mich betrifft, so hab ich zwar\u00ab,", "tokens": ["\u00bb", "was", "mich", "be\u00b7tr\u00b7ifft", ",", "so", "hab", "ich", "zwar", "\u00ab", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PWS", "PPER", "VVFIN", "$,", "ADV", "VAFIN", "PPER", "ADV", "$(", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "sprach jetzt der Liebesgott, \u00bbf\u00fcrwahr,", "tokens": ["sprach", "jetzt", "der", "Lie\u00b7bes\u00b7gott", ",", "\u00bb", "f\u00fcr\u00b7wahr", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "$,", "$(", "ADV", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.3": {"text": "mich wenig Ihrer Gunst zu r\u00fchmen.", "tokens": ["mich", "we\u00b7nig", "Ih\u00b7rer", "Gunst", "zu", "r\u00fch\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "PPOSAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Denn ich verscho\u00df an Ihrem Stolz", "tokens": ["Denn", "ich", "ver\u00b7scho\u00df", "an", "Ih\u00b7rem", "Stolz"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "vergebens manchen sch\u00f6nen Bolz.", "tokens": ["ver\u00b7ge\u00b7bens", "man\u00b7chen", "sch\u00f6\u00b7nen", "Bolz", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Dagegen ist mein Bruder Hymen", "tokens": ["Da\u00b7ge\u00b7gen", "ist", "mein", "Bru\u00b7der", "Hy\u00b7men"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PAV", "VAFIN", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "f\u00fcr gro\u00dfe unverdiente Huld", "tokens": ["f\u00fcr", "gro\u00b7\u00dfe", "un\u00b7ver\u00b7dien\u00b7te", "Huld"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "um desto mehr in Ihrer Schuld.", "tokens": ["um", "des\u00b7to", "mehr", "in", "Ih\u00b7rer", "Schuld", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "ADV", "ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Doch, brotzen w\u00fcrde mir \u00fcbel ziemen.", "tokens": ["Doch", ",", "brot\u00b7zen", "w\u00fcr\u00b7de", "mir", "\u00fc\u00b7bel", "zie\u00b7men", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "VVINF", "VAFIN", "PPER", "ADJD", "VVINF", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "Gern halt ich Ihren Schl\u00e4gen still,", "tokens": ["Gern", "halt", "ich", "Ih\u00b7ren", "Schl\u00e4\u00b7gen", "still", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "und, wenn Sie meines Diensts nicht will,", "tokens": ["und", ",", "wenn", "Sie", "mei\u00b7nes", "Diensts", "nicht", "will", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "PPER", "PPOSAT", "NN", "PTKNEG", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "so ist mir's doch schon viel Genu\u00df", "tokens": ["so", "ist", "mir's", "doch", "schon", "viel", "Ge\u00b7nu\u00df"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "NE", "ADV", "ADV", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "da\u00df Sie Sich lieben lassen mu\u00df.", "tokens": ["da\u00df", "Sie", "Sich", "lie\u00b7ben", "las\u00b7sen", "mu\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "VVINF", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "(das kann der Herr ins Ohr Ihr sagen.)\u00ab", "tokens": ["(", "das", "kann", "der", "Herr", "ins", "Ohr", "Ihr", "sa\u00b7gen", ".", ")", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["$(", "PDS", "VMFIN", "ART", "NN", "APPRART", "NN", "PPER", "VVINF", "$.", "$(", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "Mit allem was man ihm aufgetragen", "tokens": ["Mit", "al\u00b7lem", "was", "man", "ihm", "auf\u00b7ge\u00b7tra\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PIS", "PWS", "PIS", "PPER", "VVPP"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "bepackt, war Herr Merkurius", "tokens": ["be\u00b7packt", ",", "war", "Herr", "Mer\u00b7ku\u00b7rius"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["VVPP", "$,", "VAFIN", "NN", "NE"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "in seinen A\u00ebrostatischen Wagen", "tokens": ["in", "sei\u00b7nen", "A\u00b7\u00ebro\u00b7sta\u00b7ti\u00b7schen", "Wa\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "zu steigen eben im Begriff:", "tokens": ["zu", "stei\u00b7gen", "e\u00b7ben", "im", "Be\u00b7griff", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVFIN", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "als, keuchend, mit einem gro\u00dfen Ranzen", "tokens": ["als", ",", "keu\u00b7chend", ",", "mit", "ei\u00b7nem", "gro\u00b7\u00dfen", "Ran\u00b7zen"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "$,", "VVPP", "$,", "APPR", "ART", "ADJA", "NN"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "voll teutscher Zitronen und Pomeranzen,", "tokens": ["voll", "teut\u00b7scher", "Zit\u00b7ro\u00b7nen", "und", "Po\u00b7me\u00b7ran\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADJA", "NN", "KON", "NN", "$,"], "meter": "-+-++--+-+-", "measure": "iambic.penta.relaxed"}, "line.7": {"text": "Pomona in den Weg ihm lief.", "tokens": ["Po\u00b7mo\u00b7na", "in", "den", "Weg", "ihm", "lief", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ART", "NN", "PPER", "VVFIN", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.8": {"text": "\u00bbein einzig Wort, Herr Vetter\u00ab, rief", "tokens": ["\u00bb", "ein", "ein\u00b7zig", "Wort", ",", "Herr", "Vet\u00b7ter", "\u00ab", ",", "rief"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "punct", "punct", "word"], "pos": ["$(", "ART", "ADJD", "NN", "$,", "NN", "NN", "$(", "$,", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "die gute Frau: \u00bbbring er, ich bitt,", "tokens": ["die", "gu\u00b7te", "Frau", ":", "\u00bb", "bring", "er", ",", "ich", "bitt", ","], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$.", "$(", "VVFIN", "PPER", "$,", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "der F\u00fcrstin diese Fr\u00fcchte mit;", "tokens": ["der", "F\u00fcrs\u00b7tin", "die\u00b7se", "Fr\u00fcch\u00b7te", "mit", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PDAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Sie sind von meiner eignen Zucht,", "tokens": ["Sie", "sind", "von", "mei\u00b7ner", "eig\u00b7nen", "Zucht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "sind gut (halb Teutschland hat's versucht)", "tokens": ["sind", "gut", "(", "halb", "Teutschland", "hat's", "ver\u00b7sucht", ")"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "$(", "ADJD", "NN", "VAFIN", "VVPP", "$("], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.13": {"text": "und gehn, so helf mir Sankt Walpurg!", "tokens": ["und", "gehn", ",", "so", "helf", "mir", "Sankt", "Wal\u00b7purg", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVINF", "$,", "ADV", "VVFIN", "PPER", "VVFIN", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "von London bis nach Petersburg:", "tokens": ["von", "Lon\u00b7don", "bis", "nach", "Pe\u00b7ters\u00b7burg", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "ADV", "APPR", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "sind, ohne Ruhmred, extrafein,", "tokens": ["sind", ",", "oh\u00b7ne", "Ruhm\u00b7red", ",", "ext\u00b7ra\u00b7fein", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["VAFIN", "$,", "KOUI", "NN", "$,", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "gesund und wohlfeil oben drein;", "tokens": ["ge\u00b7sund", "und", "wohl\u00b7feil", "o\u00b7ben", "drein", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "KON", "ADJD", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "zw\u00f6lf K\u00f6rbchen (trotz dem leidigen Schweitzer!)", "tokens": ["zw\u00f6lf", "K\u00f6rb\u00b7chen", "(", "trotz", "dem", "lei\u00b7di\u00b7gen", "Schweit\u00b7zer", "!", ")"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["CARD", "NN", "$(", "APPR", "ART", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.18": {"text": "vier Gulden nur und drei\u00dfig Kreuzer!\u00ab", "tokens": ["vier", "Gul\u00b7den", "nur", "und", "drei\u00b7\u00dfig", "Kreu\u00b7zer", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["CARD", "NN", "ADV", "KON", "CARD", "NN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "Merkur nimmt ihr die K\u00f6rbchen ab,", "tokens": ["Mer\u00b7kur", "nimmt", "ihr", "die", "K\u00f6rb\u00b7chen", "ab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "und sinkt zum Erdenball hinab.", "tokens": ["und", "sinkt", "zum", "Er\u00b7den\u00b7ball", "hin\u00b7ab", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPRART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und hier ist auch mein M\u00e4rchen gar,", "tokens": ["Und", "hier", "ist", "auch", "mein", "M\u00e4r\u00b7chen", "gar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "ADV", "PPOSAT", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Im \u00fcbrigen, Prost das neue Jahr!", "tokens": ["Im", "\u00fcb\u00b7ri\u00b7gen", ",", "Prost", "das", "neu\u00b7e", "Jahr", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "$,", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.17": {"line.1": {"text": "Das dreimal Drei der Musenschar,", "tokens": ["Das", "drei\u00b7mal", "Drei", "der", "Mu\u00b7sen\u00b7schar", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "CARD", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "die heilge Vier der sch\u00f6nen Horen,", "tokens": ["die", "heil\u00b7ge", "Vier", "der", "sch\u00f6\u00b7nen", "Ho\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "die Grazien im goldnen Haar,", "tokens": ["die", "Gra\u00b7zi\u00b7en", "im", "gold\u00b7nen", "Haar", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "und Bacchus und Apoll, mit Amorn und mit Floren,", "tokens": ["und", "Bac\u00b7chus", "und", "A\u00b7poll", ",", "mit", "A\u00b7morn", "und", "mit", "Flo\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "KON", "NN", "$,", "APPR", "NE", "KON", "APPR", "NN", "$,"], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.5": {"text": "fr\u00fchst\u00fcckten s\u00e4mtlich bei Auroren", "tokens": ["fr\u00fch\u00b7st\u00fcck\u00b7ten", "s\u00e4mt\u00b7lich", "bei", "Au\u00b7ro\u00b7ren"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "ADJD", "APPR", "NE"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "am ersten Tag im Januar.", "tokens": ["am", "ers\u00b7ten", "Tag", "im", "Ja\u00b7nu\u00b7ar", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.18": {"line.1": {"text": "Merkur, der nicht erwartet war,", "tokens": ["Mer\u00b7kur", ",", "der", "nicht", "er\u00b7war\u00b7tet", "war", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PRELS", "PTKNEG", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "kam aus des Luftmeers d\u00fcnnen Wogen", "tokens": ["kam", "aus", "des", "Luft\u00b7meers", "d\u00fcn\u00b7nen", "Wo\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "\u00e0 la Montgolfier geflogen,", "tokens": ["\u00e0", "la", "Mont\u00b7gol\u00b7fier", "ge\u00b7flo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["FM", "FM", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "und, \u00bbFriede\u00ab, sprach er, \u00bbsei mit Euch!", "tokens": ["und", ",", "\u00bb", "Frie\u00b7de", "\u00ab", ",", "sprach", "er", ",", "\u00bb", "sei", "mit", "Euch", "!"], "token_info": ["word", "punct", "punct", "word", "punct", "punct", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["KON", "$,", "$(", "NN", "$(", "$,", "VVFIN", "PPER", "$,", "$(", "VAFIN", "APPR", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Euch G\u00f6ttervolk im Himmelreich,", "tokens": ["Euch", "G\u00f6t\u00b7ter\u00b7volk", "im", "Him\u00b7mel\u00b7reich", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "zu nichts als ewger Lust erzogen,", "tokens": ["zu", "nichts", "als", "ew\u00b7ger", "Lust", "er\u00b7zo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "KOKOM", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "sind freilich alle Tage gleich.", "tokens": ["sind", "frei\u00b7lich", "al\u00b7le", "Ta\u00b7ge", "gleich", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PIAT", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Allein, dort unten auf der Erden", "tokens": ["Al\u00b7lein", ",", "dort", "un\u00b7ten", "auf", "der", "Er\u00b7den"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "$,", "ADV", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "ist heut der erste Januar;", "tokens": ["ist", "heut", "der", "ers\u00b7te", "Ja\u00b7nu\u00b7ar", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "der pflegt daselbst gar sonderbar", "tokens": ["der", "pflegt", "da\u00b7selbst", "gar", "son\u00b7der\u00b7bar"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "VVFIN", "PAV", "ADV", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "von Gro\u00df und Klein chommiert zu werden,", "tokens": ["von", "Gro\u00df", "und", "Klein", "chom\u00b7miert", "zu", "wer\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "KON", "NE", "NE", "PTKZU", "VAINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "denn heute gilt's f\u00fcrs ganze Jahr.", "tokens": ["denn", "heu\u00b7te", "gilt's", "f\u00fcrs", "gan\u00b7ze", "Jahr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Die Leute die was zu geben haben", "tokens": ["Die", "Leu\u00b7te", "die", "was", "zu", "ge\u00b7ben", "ha\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "PIS", "PTKZU", "VVINF", "VAFIN"], "meter": "-+-++-+-+-", "measure": "unknown.measure.penta"}, "line.14": {"text": "beschenken einander mit kleinen Gaben;", "tokens": ["be\u00b7schen\u00b7ken", "ein\u00b7an\u00b7der", "mit", "klei\u00b7nen", "Ga\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "APPR", "ADJA", "NN", "$."], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.15": {"text": "doch, wer nicht schwer am Seckel tr\u00e4gt,", "tokens": ["doch", ",", "wer", "nicht", "schwer", "am", "Se\u00b7ckel", "tr\u00e4gt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PWS", "PTKNEG", "ADJD", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "und lieber ihn sich f\u00fcllen lie\u00dfe,", "tokens": ["und", "lie\u00b7ber", "ihn", "sich", "f\u00fcl\u00b7len", "lie\u00b7\u00dfe", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PPER", "PRF", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.17": {"text": "schleicht tiefgeb\u00fcckt heran und legt", "tokens": ["schleicht", "tief\u00b7ge\u00b7b\u00fcckt", "he\u00b7ran", "und", "legt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADJD", "PTKVZ", "KON", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.18": {"text": "in Demut \u2013 ", "tokens": ["in", "De\u00b7mut", "\u2013"], "token_info": ["word", "word", "punct"], "pos": ["APPR", "NN", "$("], "meter": "-+-", "measure": "amphibrach.single"}}, "stanza.19": {"line.1": {"text": "Ihr, denen's an Gaben nicht gebricht,", "tokens": ["Ihr", ",", "de\u00b7nen's", "an", "Ga\u00b7ben", "nicht", "ge\u00b7bricht", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PRELS", "APPR", "NN", "PTKNEG", "VVFIN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Wohlan, ihr lieblichen G\u00f6ttinnen,", "tokens": ["Wo\u00b7hlan", ",", "ihr", "lieb\u00b7li\u00b7chen", "G\u00f6t\u00b7tin\u00b7nen", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "erinnert euch die sch\u00f6ne Pflicht", "tokens": ["e\u00b7rin\u00b7nert", "euch", "die", "sch\u00f6\u00b7ne", "Pflicht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "der Dankbarkeit und Liebe nicht,", "tokens": ["der", "Dank\u00b7bar\u00b7keit", "und", "Lie\u00b7be", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "auf Gaben f\u00fcr eine F\u00fcrstin zu sinnen", "tokens": ["auf", "Ga\u00b7ben", "f\u00fcr", "ei\u00b7ne", "F\u00fcrs\u00b7tin", "zu", "sin\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "APPR", "ART", "NN", "PTKZU", "VVINF"], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "die, eure Freundschaft zu gewinnen,", "tokens": ["die", ",", "eu\u00b7re", "Freund\u00b7schaft", "zu", "ge\u00b7win\u00b7nen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "PPOSAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "euch stets die sch\u00f6nsten Kr\u00e4nze flicht?", "tokens": ["euch", "stets", "die", "sch\u00f6ns\u00b7ten", "Kr\u00e4n\u00b7ze", "flicht", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "die Erste eurer Priesterinnen!\u00ab", "tokens": ["die", "Ers\u00b7te", "eu\u00b7rer", "Pries\u00b7te\u00b7rin\u00b7nen", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "ADJA", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.20": {"line.1": {"text": "Die Damen in Aurorens Saal,", "tokens": ["Die", "Da\u00b7men", "in", "Au\u00b7ro\u00b7rens", "Saal", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NE", "NE", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.2": {"text": "indem sie ihren Nektar schl\u00fcrfen", "tokens": ["in\u00b7dem", "sie", "ih\u00b7ren", "Nek\u00b7tar", "schl\u00fcr\u00b7fen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "besch\u00e4ftigt, denk ich, mit Entw\u00fcrfen", "tokens": ["be\u00b7sch\u00e4f\u00b7tigt", ",", "denk", "ich", ",", "mit", "Ent\u00b7w\u00fcr\u00b7fen"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word"], "pos": ["VVPP", "$,", "VVFIN", "PPER", "$,", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "von Putz zum n\u00e4chsten G\u00f6tter-Bal,", "tokens": ["von", "Putz", "zum", "n\u00e4chs\u00b7ten", "G\u00f6t\u00b7ter\u00b7Bal", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "entschuldigen sich allzumal.", "tokens": ["ent\u00b7schul\u00b7di\u00b7gen", "sich", "all\u00b7zu\u00b7mal", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "\u00bbwas k\u00f6nnt Olympia bed\u00fcrfen?", "tokens": ["\u00bb", "was", "k\u00f6nnt", "O\u00b7lym\u00b7pia", "be\u00b7d\u00fcr\u00b7fen", "?"], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "VVFIN", "NE", "VVINF", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.7": {"text": "Hat Mutter Natur von Kindheit an", "tokens": ["Hat", "Mut\u00b7ter", "Na\u00b7tur", "von", "Kind\u00b7heit", "an"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "NN", "NN", "APPR", "NN", "APPR"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "nicht alles schon f\u00fcr Sie getan?", "tokens": ["nicht", "al\u00b7les", "schon", "f\u00fcr", "Sie", "ge\u00b7tan", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "PIS", "ADV", "APPR", "PPER", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "ihr Bestes nicht an Ihr verspendet?", "tokens": ["ihr", "Bes\u00b7tes", "nicht", "an", "Ihr", "ver\u00b7spen\u00b7det", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PTKNEG", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Hat nicht Ihr eigner Genius", "tokens": ["Hat", "nicht", "Ihr", "eig\u00b7ner", "Ge\u00b7nius"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "PTKNEG", "PPOSAT", "ADJA", "NN"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.11": {"text": "die Arbeit der Natur vollendet?", "tokens": ["die", "Ar\u00b7beit", "der", "Na\u00b7tur", "voll\u00b7en\u00b7det", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Und macht was mancher Mann auf us", "tokens": ["Und", "macht", "was", "man\u00b7cher", "Mann", "auf", "us"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PIS", "PIAT", "NN", "APPR", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "wohl unbegriffen lassen mu\u00df", "tokens": ["wohl", "un\u00b7be\u00b7grif\u00b7fen", "las\u00b7sen", "mu\u00df"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ADJD", "VVINF", "VMFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "nicht t\u00e4glich noch Ihr Flei\u00df sich eigen?", "tokens": ["nicht", "t\u00e4g\u00b7lich", "noch", "Ihr", "Flei\u00df", "sich", "ei\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADJD", "ADV", "PPOSAT", "NN", "PRF", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "Jedoch, zu allem \u00dcberflu\u00df,", "tokens": ["Je\u00b7doch", ",", "zu", "al\u00b7lem", "\u00dc\u00b7berf\u00b7lu\u00df", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "APPR", "PIS", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "und blo\u00df den guten Willen zu zeigen,", "tokens": ["und", "blo\u00df", "den", "gu\u00b7ten", "Wil\u00b7len", "zu", "zei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "ADJA", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.17": {"text": "da, lieber Herr Merkurius,", "tokens": ["da", ",", "lie\u00b7ber", "Herr", "Mer\u00b7ku\u00b7rius", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "ADV", "NN", "NE", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.18": {"text": "pack er, was wir von unsern Dingen", "tokens": ["pack", "er", ",", "was", "wir", "von", "un\u00b7sern", "Din\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "$,", "PRELS", "PPER", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.19": {"text": "in aller Eil zusammenbringen,", "tokens": ["in", "al\u00b7ler", "Eil", "zu\u00b7sam\u00b7men\u00b7brin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.20": {"text": "h\u00fcbsch sauber auf, dann flieg er frisch", "tokens": ["h\u00fcbsch", "sau\u00b7ber", "auf", ",", "dann", "flieg", "er", "frisch"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADJD", "ADJD", "PTKVZ", "$,", "ADV", "VVFIN", "PPER", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.21": {"text": "und leg's der F\u00fcrstin auf den Tisch.", "tokens": ["und", "leg's", "der", "F\u00fcrs\u00b7tin", "auf", "den", "Tisch", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.22": {"text": "Nur sei er honett, Herr Seelenzwinger,", "tokens": ["Nur", "sei", "er", "ho\u00b7nett", ",", "Herr", "See\u00b7len\u00b7zwin\u00b7ger", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "$,", "NN", "NN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.23": {"text": "und mach er keine krumme Finger!\u00ab", "tokens": ["und", "mach", "er", "kei\u00b7ne", "krum\u00b7me", "Fin\u00b7ger", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "PPER", "PIAT", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.21": {"line.1": {"text": "Jetzt ging's, mit einer Schw\u00e4rmerei", "tokens": ["Jetzt", "ging's", ",", "mit", "ei\u00b7ner", "Schw\u00e4r\u00b7me\u00b7rei"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "$,", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "die man von ihnen nur vor zwei", "tokens": ["die", "man", "von", "ih\u00b7nen", "nur", "vor", "zwei"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "PIS", "APPR", "PPER", "ADV", "APPR", "CARD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Minuten nicht vermutet h\u00e4tte,", "tokens": ["Mi\u00b7nu\u00b7ten", "nicht", "ver\u00b7mu\u00b7tet", "h\u00e4t\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PTKNEG", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "an ein Begaben in die Wette.", "tokens": ["an", "ein", "Be\u00b7ga\u00b7ben", "in", "die", "Wet\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.22": {"line.1": {"text": "Die Pieriden, als ihrer Neun,", "tokens": ["Die", "Pie\u00b7ri\u00b7den", ",", "als", "ih\u00b7rer", "Neun", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "KOUS", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "wollen, wie billig, die ersten sein.", "tokens": ["wol\u00b7len", ",", "wie", "bil\u00b7lig", ",", "die", "ers\u00b7ten", "sein", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VMFIN", "$,", "PWAV", "ADJD", "$,", "ART", "ADJA", "VAINF", "$."], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.3": {"text": "Man mu\u00dfte nach ihrem Gewimmel denken", "tokens": ["Man", "mu\u00df\u00b7te", "nach", "ih\u00b7rem", "Ge\u00b7wim\u00b7mel", "den\u00b7ken"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VMFIN", "APPR", "PPOSAT", "NN", "VVINF"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "sie h\u00e4tten gewaltig viel zu schenken.", "tokens": ["sie", "h\u00e4t\u00b7ten", "ge\u00b7wal\u00b7tig", "viel", "zu", "schen\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Doch, da sie ihren ganzen Kram", "tokens": ["Doch", ",", "da", "sie", "ih\u00b7ren", "gan\u00b7zen", "Kram"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "$,", "KOUS", "PPER", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "durchsucht, bestunden sie mit Scham.", "tokens": ["durch\u00b7sucht", ",", "be\u00b7stun\u00b7den", "sie", "mit", "Scham", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "VVFIN", "PPER", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Sie selber hatten schon vor Jahren", "tokens": ["Sie", "sel\u00b7ber", "hat\u00b7ten", "schon", "vor", "Jah\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "VAFIN", "ADV", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "der F\u00fcrstin in die sie vergeistert waren", "tokens": ["der", "F\u00fcrs\u00b7tin", "in", "die", "sie", "ver\u00b7geis\u00b7tert", "wa\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "PRELS", "PPER", "VVPP", "VAFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "mit allem was der Musensitz", "tokens": ["mit", "al\u00b7lem", "was", "der", "Mu\u00b7sen\u00b7sitz"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PIS", "PWS", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "hervorbringt an Geschmack und Witz,", "tokens": ["her\u00b7vor\u00b7bringt", "an", "Ge\u00b7schmack", "und", "Witz", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "(ohn auf die Zukunft was zu sparen)", "tokens": ["(", "ohn", "auf", "die", "Zu\u00b7kunft", "was", "zu", "spa\u00b7ren", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "APPR", "ART", "NN", "PIS", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "mit jedem Talent und jedem Trieb", "tokens": ["mit", "je\u00b7dem", "Ta\u00b7lent", "und", "je\u00b7dem", "Trieb"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PIAT", "NN", "KON", "PIAT", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.13": {"text": "der es entwickelt, so reich versehen,", "tokens": ["der", "es", "ent\u00b7wi\u00b7ckelt", ",", "so", "reich", "ver\u00b7se\u00b7hen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVPP", "$,", "ADV", "ADJD", "VVPP", "$,"], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}, "line.14": {"text": "da\u00df nun den guten alten Feen", "tokens": ["da\u00df", "nun", "den", "gu\u00b7ten", "al\u00b7ten", "Feen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "ART", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "nichts mehr zu geben \u00fcbrig blieb.", "tokens": ["nichts", "mehr", "zu", "ge\u00b7ben", "\u00fcb\u00b7rig", "blieb", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "PIS", "PTKZU", "VVINF", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.23": {"line.1": {"text": "Apoll, auf den sie um Beistand sahn,", "tokens": ["A\u00b7poll", ",", "auf", "den", "sie", "um", "Bei\u00b7stand", "sahn", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "APPR", "PRELS", "PPER", "APPR", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "nahm ihrer sich aus Mitleid an.", "tokens": ["nahm", "ih\u00b7rer", "sich", "aus", "Mit\u00b7leid", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "PRF", "APPR", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "\u00bbich selber w\u00fc\u00dfte, bei meinem Leben!\u00ab", "tokens": ["\u00bb", "ich", "sel\u00b7ber", "w\u00fc\u00df\u00b7te", ",", "bei", "mei\u00b7nem", "Le\u00b7ben", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPER", "ADV", "VVFIN", "$,", "APPR", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "sprach er, \u00bbOlympien nichts zu geben", "tokens": ["sprach", "er", ",", "\u00bb", "O\u00b7lym\u00b7pien", "nichts", "zu", "ge\u00b7ben"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "$,", "$(", "NE", "PIS", "PTKZU", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "das Sie nicht besser h\u00e4tt \u2013 Allein,", "tokens": ["das", "Sie", "nicht", "bes\u00b7ser", "h\u00e4tt", "\u2013", "Al\u00b7lein", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "PPER", "PTKNEG", "ADJD", "VAFIN", "$(", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "betreffend die Herrn und Fr\u00e4ulein fein,", "tokens": ["be\u00b7tref\u00b7fend", "die", "Herrn", "und", "Fr\u00e4u\u00b7lein", "fein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ART", "NN", "KON", "NN", "ADJD", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "die Ihr als Commensalen dienen,", "tokens": ["die", "Ihr", "als", "Com\u00b7men\u00b7sa\u00b7len", "die\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "KOUS", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "(doch nichts f\u00fcr ungut!) bei manchen von ihnen", "tokens": ["(", "doch", "nichts", "f\u00fcr", "un\u00b7gut", "!", ")", "bei", "man\u00b7chen", "von", "ih\u00b7nen"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word"], "pos": ["$(", "ADV", "PIS", "APPR", "ADJD", "$.", "$(", "APPR", "PIAT", "APPR", "PPER"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "mag dies der Fall nicht immer sein.", "tokens": ["mag", "dies", "der", "Fall", "nicht", "im\u00b7mer", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PDS", "ART", "NN", "PTKNEG", "ADV", "VAINF", "$."], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.10": {"text": "Drum d\u00e4cht ich wir schickten insgemein", "tokens": ["Drum", "d\u00e4cht", "ich", "wir", "schick\u00b7ten", "ins\u00b7ge\u00b7mein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "PPER", "PPER", "VVFIN", "ADV"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.11": {"text": "zur Notdurft der Dipnosophisten,", "tokens": ["zur", "Not\u00b7durft", "der", "Dip\u00b7no\u00b7so\u00b7phis\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "$,"], "meter": "-+---+-+-", "measure": "dactylic.init"}, "line.12": {"text": "die unsre F\u00fcrstin in Ihrer Pfalz", "tokens": ["die", "uns\u00b7re", "F\u00fcrs\u00b7tin", "in", "Ih\u00b7rer", "Pfalz"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "PPOSAT", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.13": {"text": "bei Tafel zu amusieren gel\u00fcsten,", "tokens": ["bei", "Ta\u00b7fel", "zu", "a\u00b7mu\u00b7sie\u00b7ren", "ge\u00b7l\u00fcs\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PTKZU", "VVINF", "VVPP", "$,"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.14": {"text": "Ihr einen Zentner \u2013 Attisch Salz.\u00ab", "tokens": ["Ihr", "ei\u00b7nen", "Zent\u00b7ner", "\u2013", "At\u00b7tisch", "Salz", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["PPER", "ART", "NN", "$(", "NE", "NE", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.24": {"line.1": {"text": "\u00bbder Einfall hat sich traun! gewaschen\u00ab,", "tokens": ["\u00bb", "der", "Ein\u00b7fall", "hat", "sich", "traun", "!", "ge\u00b7wa\u00b7schen", "\u00ab", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "punct", "punct"], "pos": ["$(", "ART", "NN", "VAFIN", "PRF", "VVINF", "$.", "ADJA", "$(", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "f\u00e4llt Bacchus, der Freudengeber, ein:", "tokens": ["f\u00e4llt", "Bac\u00b7chus", ",", "der", "Freu\u00b7den\u00b7ge\u00b7ber", ",", "ein", ":"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["VVFIN", "NE", "$,", "ART", "NN", "$,", "PTKVZ", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "\u00bbich selber lege dreihundert Flaschen", "tokens": ["\u00bb", "ich", "sel\u00b7ber", "le\u00b7ge", "drei\u00b7hun\u00b7dert", "Fla\u00b7schen"], "token_info": ["punct", "word", "word", "word", "word", "word"], "pos": ["$(", "PPER", "ADV", "VVFIN", "CARD", "NN"], "meter": "-+---+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "dazu, von meinem besten Wein;", "tokens": ["da\u00b7zu", ",", "von", "mei\u00b7nem", "bes\u00b7ten", "Wein", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "$,", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "die Herren werden im Einfall-Haschen", "tokens": ["die", "Her\u00b7ren", "wer\u00b7den", "im", "Ein\u00b7fall\u00b7Ha\u00b7schen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "APPRART", "NN"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "dabei nur desto prompter sein.", "tokens": ["da\u00b7bei", "nur", "des\u00b7to", "promp\u00b7ter", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ADV", "ADV", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Was auch die Kammerherren sagen,", "tokens": ["Was", "auch", "die", "Kam\u00b7mer\u00b7her\u00b7ren", "sa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "der Wein gibt Witz und st\u00e4rkt den Magen.\u00ab", "tokens": ["der", "Wein", "gibt", "Witz", "und", "st\u00e4rkt", "den", "Ma\u00b7gen", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "VVFIN", "NN", "KON", "VVFIN", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.25": {"line.1": {"text": "Jetzt traf die Grazien die Reih:", "tokens": ["Jetzt", "traf", "die", "Gra\u00b7zi\u00b7en", "die", "Reih", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die fanden, ohne sich lang im Busen", "tokens": ["Die", "fan\u00b7den", ",", "oh\u00b7ne", "sich", "lang", "im", "Bu\u00b7sen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "$,", "KOUI", "PRF", "ADJD", "APPRART", "NN"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "zu krabbeln, da\u00df der Fall der Musen", "tokens": ["zu", "krab\u00b7beln", ",", "da\u00df", "der", "Fall", "der", "Mu\u00b7sen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PTKZU", "VVINF", "$,", "KOUS", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "just auch ihr eigner casus sei.", "tokens": ["just", "auch", "ihr", "eig\u00b7ner", "ca\u00b7sus", "sei", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPOSAT", "ADJA", "NE", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "\u00bbwas wir nicht selbst an Sie verschwendet,", "tokens": ["\u00bb", "was", "wir", "nicht", "selbst", "an", "Sie", "ver\u00b7schwen\u00b7det", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "PPER", "PTKNEG", "ADV", "APPR", "PPER", "VVFIN", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.6": {"text": "das\u00ab, sagten sie, \u00bbhat Sie uns, so fein", "tokens": ["das", "\u00ab", ",", "sag\u00b7ten", "sie", ",", "\u00bb", "hat", "Sie", "uns", ",", "so", "fein"], "token_info": ["word", "punct", "punct", "word", "word", "punct", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "$(", "$,", "VVFIN", "PPER", "$,", "$(", "VAFIN", "PPER", "PPER", "$,", "ADV", "ADJD"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "da\u00df man Ihr's gern verzeiht, entwendet:", "tokens": ["da\u00df", "man", "Ih\u00b7r's", "gern", "ver\u00b7zeiht", ",", "ent\u00b7wen\u00b7det", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "PIS", "PIS", "ADV", "VVFIN", "$,", "VVPP", "$."], "meter": "+-+---+-+-", "measure": "unknown.measure.tetra"}, "line.8": {"text": "Wir k\u00f6nnten leicht gen\u00f6tigt sein", "tokens": ["Wir", "k\u00f6nn\u00b7ten", "leicht", "ge\u00b7n\u00f6\u00b7tigt", "sein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ADJD", "VVPP", "VAINF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "am Ende gar heut oder morgen,", "tokens": ["am", "En\u00b7de", "gar", "heut", "o\u00b7der", "mor\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADV", "ADV", "KON", "ADV", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "anstatt zu geben, bei Ihr zu borgen.\u00ab", "tokens": ["an\u00b7statt", "zu", "ge\u00b7ben", ",", "bei", "Ihr", "zu", "bor\u00b7gen", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUI", "PTKZU", "VVINF", "$,", "APPR", "PPER", "PTKZU", "VVINF", "$.", "$("], "meter": "+--+-+--+-", "measure": "iambic.tetra.invert"}}, "stanza.26": {"line.1": {"text": "\u00bbauf diesen Fall\u00ab, f\u00e4llt Amor ein,", "tokens": ["\u00bb", "auf", "die\u00b7sen", "Fall", "\u00ab", ",", "f\u00e4llt", "A\u00b7mor", "ein", ","], "token_info": ["punct", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "PDAT", "NN", "$(", "$,", "VVFIN", "NE", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u00bbist euch kein bessrer Rat zu geben", "tokens": ["\u00bb", "ist", "euch", "kein", "bess\u00b7rer", "Rat", "zu", "ge\u00b7ben"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "VAFIN", "PPER", "PIAT", "ADJA", "NN", "PTKZU", "VVINF"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.3": {"text": "als Tag und Nacht Sie zu umschweben,", "tokens": ["als", "Tag", "und", "Nacht", "Sie", "zu", "um\u00b7schwe\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "NN", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "und, ohne zu merkliches Bestreben,", "tokens": ["und", ",", "oh\u00b7ne", "zu", "merk\u00b7li\u00b7ches", "Be\u00b7stre\u00b7ben", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUI", "APPR", "ADJA", "NN", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "die Pfade von Ihrem sch\u00f6nen Leben", "tokens": ["die", "Pfa\u00b7de", "von", "Ih\u00b7rem", "sch\u00f6\u00b7nen", "Le\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "mit euern Rosen, als spro\u00dften sie eben", "tokens": ["mit", "eu\u00b7ern", "Ro\u00b7sen", ",", "als", "spro\u00df\u00b7ten", "sie", "e\u00b7ben"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "$,", "KOUS", "VVFIN", "PPER", "ADV"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "von selbst hervor, zu \u00fcberstreun.\u00ab", "tokens": ["von", "selbst", "her\u00b7vor", ",", "zu", "\u00fc\u00b7bers\u00b7treun", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["APPR", "ADV", "PTKVZ", "$,", "PTKZU", "VVINF", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.27": {"line.1": {"text": "Die Rede gefiel den Dirnen wohl,", "tokens": ["Die", "Re\u00b7de", "ge\u00b7fiel", "den", "Dir\u00b7nen", "wohl", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "ADV", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "und man beschlo\u00df, ein K\u00f6rbchen voll", "tokens": ["und", "man", "be\u00b7schlo\u00df", ",", "ein", "K\u00f6rb\u00b7chen", "voll"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "PIS", "VVFIN", "$,", "ART", "NN", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "sogleich Merkuren mit zugeben.", "tokens": ["sog\u00b7leich", "Mer\u00b7ku\u00b7ren", "mit", "zu\u00b7ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "APPR", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "\u00bbnoch eins\u00ab, sprach Ph\u00f6bus, \u00bbf\u00e4llt mir bei;", "tokens": ["\u00bb", "noch", "eins", "\u00ab", ",", "sprach", "Ph\u00f6\u00b7bus", ",", "\u00bb", "f\u00e4llt", "mir", "bei", ";"], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "PIS", "$(", "$,", "VVFIN", "NE", "$,", "$(", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "sag Ihren Leib- und Mund-Poeten,", "tokens": ["sag", "Ih\u00b7ren", "Leib", "und", "Mun\u00b7dPo\u00b7e\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "TRUNC", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "wir h\u00e4tten uns die Kuppelei", "tokens": ["wir", "h\u00e4t\u00b7ten", "uns", "die", "Kup\u00b7pe\u00b7lei"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PPER", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "von ", "tokens": ["von"], "token_info": ["word"], "pos": ["APPR"], "meter": "-", "measure": "single.down"}, "line.8": {"text": "f\u00fcr ein und allemal verbeten.\u00ab", "tokens": ["f\u00fcr", "ein", "und", "al\u00b7le\u00b7mal", "ver\u00b7be\u00b7ten", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "ART", "KON", "ADV", "VVFIN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.28": {"line.1": {"text": "\u00bbich\u00ab, sprach jetzt Flora, \u00bbhabe mir,", "tokens": ["\u00bb", "ich", "\u00ab", ",", "sprach", "jetzt", "Flo\u00b7ra", ",", "\u00bb", "ha\u00b7be", "mir", ","], "token_info": ["punct", "word", "punct", "punct", "word", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["$(", "PPER", "$(", "$,", "VVFIN", "ADV", "NN", "$,", "$(", "VAFIN", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Olympien meine Dienstbegier", "tokens": ["O\u00b7lym\u00b7pien", "mei\u00b7ne", "Dienst\u00b7be\u00b7gier"], "token_info": ["word", "word", "word"], "pos": ["NE", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "zu zeigen, Ihren Hain erw\u00e4hlt,", "tokens": ["zu", "zei\u00b7gen", ",", "Ih\u00b7ren", "Hain", "er\u00b7w\u00e4hlt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "$,", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "wo freilich dies und das noch fehlt.", "tokens": ["wo", "frei\u00b7lich", "dies", "und", "das", "noch", "fehlt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "PDS", "KON", "PDS", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ma\u00dfregeln hab ich schon genommen,", "tokens": ["Ma\u00df\u00b7re\u00b7geln", "hab", "ich", "schon", "ge\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "la\u00dft mir nur erst den Fr\u00fchling kommen!\u00ab", "tokens": ["la\u00dft", "mir", "nur", "erst", "den", "Fr\u00fch\u00b7ling", "kom\u00b7men", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVIMP", "PPER", "ADV", "ADV", "ART", "NN", "VVINF", "$.", "$("], "meter": "---+-+-+-", "measure": "unknown.measure.tri"}}, "stanza.29": {"line.1": {"text": "Die H\u00f6ren stimmten im Chorus ein", "tokens": ["Die", "H\u00f6\u00b7ren", "stimm\u00b7ten", "im", "Cho\u00b7rus", "ein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "APPRART", "NN", "ART"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "und alle G\u00f6ttinnen und G\u00f6tter", "tokens": ["und", "al\u00b7le", "G\u00f6t\u00b7tin\u00b7nen", "und", "G\u00f6t\u00b7ter"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PIAT", "NN", "KON", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "gelobten Ihr, nebst sch\u00f6nem Wetter", "tokens": ["ge\u00b7lob\u00b7ten", "Ihr", ",", "nebst", "sch\u00f6\u00b7nem", "Wet\u00b7ter"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "PPER", "$,", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "und ewgem ", "tokens": ["und", "ew\u00b7gem"], "token_info": ["word", "word"], "pos": ["KON", "ADJA"], "meter": "-+-", "measure": "amphibrach.single"}, "line.5": {"text": "zu dichten, zu w\u00fcrken und zu wachen", "tokens": ["zu", "dich\u00b7ten", ",", "zu", "w\u00fcr\u00b7ken", "und", "zu", "wa\u00b7chen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "$,", "PTKZU", "VVINF", "KON", "PTKZU", "VVINF"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "um Ihren auserw\u00e4hlten Hain", "tokens": ["um", "Ih\u00b7ren", "au\u00b7ser\u00b7w\u00e4hl\u00b7ten", "Hain"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "zu einem Paradies zu machen.", "tokens": ["zu", "ei\u00b7nem", "Pa\u00b7ra\u00b7dies", "zu", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.30": {"line.1": {"text": "\u00bbwas mich betrifft, so hab ich zwar\u00ab,", "tokens": ["\u00bb", "was", "mich", "be\u00b7tr\u00b7ifft", ",", "so", "hab", "ich", "zwar", "\u00ab", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PWS", "PPER", "VVFIN", "$,", "ADV", "VAFIN", "PPER", "ADV", "$(", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "sprach jetzt der Liebesgott, \u00bbf\u00fcrwahr,", "tokens": ["sprach", "jetzt", "der", "Lie\u00b7bes\u00b7gott", ",", "\u00bb", "f\u00fcr\u00b7wahr", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "$,", "$(", "ADV", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.3": {"text": "mich wenig Ihrer Gunst zu r\u00fchmen.", "tokens": ["mich", "we\u00b7nig", "Ih\u00b7rer", "Gunst", "zu", "r\u00fch\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "PPOSAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Denn ich verscho\u00df an Ihrem Stolz", "tokens": ["Denn", "ich", "ver\u00b7scho\u00df", "an", "Ih\u00b7rem", "Stolz"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "vergebens manchen sch\u00f6nen Bolz.", "tokens": ["ver\u00b7ge\u00b7bens", "man\u00b7chen", "sch\u00f6\u00b7nen", "Bolz", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Dagegen ist mein Bruder Hymen", "tokens": ["Da\u00b7ge\u00b7gen", "ist", "mein", "Bru\u00b7der", "Hy\u00b7men"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PAV", "VAFIN", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "f\u00fcr gro\u00dfe unverdiente Huld", "tokens": ["f\u00fcr", "gro\u00b7\u00dfe", "un\u00b7ver\u00b7dien\u00b7te", "Huld"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "um desto mehr in Ihrer Schuld.", "tokens": ["um", "des\u00b7to", "mehr", "in", "Ih\u00b7rer", "Schuld", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "ADV", "ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Doch, brotzen w\u00fcrde mir \u00fcbel ziemen.", "tokens": ["Doch", ",", "brot\u00b7zen", "w\u00fcr\u00b7de", "mir", "\u00fc\u00b7bel", "zie\u00b7men", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "VVINF", "VAFIN", "PPER", "ADJD", "VVINF", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "Gern halt ich Ihren Schl\u00e4gen still,", "tokens": ["Gern", "halt", "ich", "Ih\u00b7ren", "Schl\u00e4\u00b7gen", "still", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "und, wenn Sie meines Diensts nicht will,", "tokens": ["und", ",", "wenn", "Sie", "mei\u00b7nes", "Diensts", "nicht", "will", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "PPER", "PPOSAT", "NN", "PTKNEG", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "so ist mir's doch schon viel Genu\u00df", "tokens": ["so", "ist", "mir's", "doch", "schon", "viel", "Ge\u00b7nu\u00df"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "NE", "ADV", "ADV", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "da\u00df Sie Sich lieben lassen mu\u00df.", "tokens": ["da\u00df", "Sie", "Sich", "lie\u00b7ben", "las\u00b7sen", "mu\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "VVINF", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "(das kann der Herr ins Ohr Ihr sagen.)\u00ab", "tokens": ["(", "das", "kann", "der", "Herr", "ins", "Ohr", "Ihr", "sa\u00b7gen", ".", ")", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["$(", "PDS", "VMFIN", "ART", "NN", "APPRART", "NN", "PPER", "VVINF", "$.", "$(", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.31": {"line.1": {"text": "Mit allem was man ihm aufgetragen", "tokens": ["Mit", "al\u00b7lem", "was", "man", "ihm", "auf\u00b7ge\u00b7tra\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PIS", "PWS", "PIS", "PPER", "VVPP"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "bepackt, war Herr Merkurius", "tokens": ["be\u00b7packt", ",", "war", "Herr", "Mer\u00b7ku\u00b7rius"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["VVPP", "$,", "VAFIN", "NN", "NE"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "in seinen A\u00ebrostatischen Wagen", "tokens": ["in", "sei\u00b7nen", "A\u00b7\u00ebro\u00b7sta\u00b7ti\u00b7schen", "Wa\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "zu steigen eben im Begriff:", "tokens": ["zu", "stei\u00b7gen", "e\u00b7ben", "im", "Be\u00b7griff", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVFIN", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "als, keuchend, mit einem gro\u00dfen Ranzen", "tokens": ["als", ",", "keu\u00b7chend", ",", "mit", "ei\u00b7nem", "gro\u00b7\u00dfen", "Ran\u00b7zen"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "$,", "VVPP", "$,", "APPR", "ART", "ADJA", "NN"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "voll teutscher Zitronen und Pomeranzen,", "tokens": ["voll", "teut\u00b7scher", "Zit\u00b7ro\u00b7nen", "und", "Po\u00b7me\u00b7ran\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADJA", "NN", "KON", "NN", "$,"], "meter": "-+-++--+-+-", "measure": "iambic.penta.relaxed"}, "line.7": {"text": "Pomona in den Weg ihm lief.", "tokens": ["Po\u00b7mo\u00b7na", "in", "den", "Weg", "ihm", "lief", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ART", "NN", "PPER", "VVFIN", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.8": {"text": "\u00bbein einzig Wort, Herr Vetter\u00ab, rief", "tokens": ["\u00bb", "ein", "ein\u00b7zig", "Wort", ",", "Herr", "Vet\u00b7ter", "\u00ab", ",", "rief"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "punct", "punct", "word"], "pos": ["$(", "ART", "ADJD", "NN", "$,", "NN", "NN", "$(", "$,", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "die gute Frau: \u00bbbring er, ich bitt,", "tokens": ["die", "gu\u00b7te", "Frau", ":", "\u00bb", "bring", "er", ",", "ich", "bitt", ","], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$.", "$(", "VVFIN", "PPER", "$,", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "der F\u00fcrstin diese Fr\u00fcchte mit;", "tokens": ["der", "F\u00fcrs\u00b7tin", "die\u00b7se", "Fr\u00fcch\u00b7te", "mit", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PDAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Sie sind von meiner eignen Zucht,", "tokens": ["Sie", "sind", "von", "mei\u00b7ner", "eig\u00b7nen", "Zucht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "sind gut (halb Teutschland hat's versucht)", "tokens": ["sind", "gut", "(", "halb", "Teutschland", "hat's", "ver\u00b7sucht", ")"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "$(", "ADJD", "NN", "VAFIN", "VVPP", "$("], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.13": {"text": "und gehn, so helf mir Sankt Walpurg!", "tokens": ["und", "gehn", ",", "so", "helf", "mir", "Sankt", "Wal\u00b7purg", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVINF", "$,", "ADV", "VVFIN", "PPER", "VVFIN", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "von London bis nach Petersburg:", "tokens": ["von", "Lon\u00b7don", "bis", "nach", "Pe\u00b7ters\u00b7burg", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "ADV", "APPR", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "sind, ohne Ruhmred, extrafein,", "tokens": ["sind", ",", "oh\u00b7ne", "Ruhm\u00b7red", ",", "ext\u00b7ra\u00b7fein", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["VAFIN", "$,", "KOUI", "NN", "$,", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "gesund und wohlfeil oben drein;", "tokens": ["ge\u00b7sund", "und", "wohl\u00b7feil", "o\u00b7ben", "drein", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "KON", "ADJD", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "zw\u00f6lf K\u00f6rbchen (trotz dem leidigen Schweitzer!)", "tokens": ["zw\u00f6lf", "K\u00f6rb\u00b7chen", "(", "trotz", "dem", "lei\u00b7di\u00b7gen", "Schweit\u00b7zer", "!", ")"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["CARD", "NN", "$(", "APPR", "ART", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.18": {"text": "vier Gulden nur und drei\u00dfig Kreuzer!\u00ab", "tokens": ["vier", "Gul\u00b7den", "nur", "und", "drei\u00b7\u00dfig", "Kreu\u00b7zer", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["CARD", "NN", "ADV", "KON", "CARD", "NN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.32": {"line.1": {"text": "Merkur nimmt ihr die K\u00f6rbchen ab,", "tokens": ["Mer\u00b7kur", "nimmt", "ihr", "die", "K\u00f6rb\u00b7chen", "ab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "und sinkt zum Erdenball hinab.", "tokens": ["und", "sinkt", "zum", "Er\u00b7den\u00b7ball", "hin\u00b7ab", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPRART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und hier ist auch mein M\u00e4rchen gar,", "tokens": ["Und", "hier", "ist", "auch", "mein", "M\u00e4r\u00b7chen", "gar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "ADV", "PPOSAT", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Im \u00fcbrigen, Prost das neue Jahr!", "tokens": ["Im", "\u00fcb\u00b7ri\u00b7gen", ",", "Prost", "das", "neu\u00b7e", "Jahr", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "$,", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}}}}