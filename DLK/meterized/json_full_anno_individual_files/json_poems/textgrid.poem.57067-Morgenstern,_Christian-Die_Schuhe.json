{"textgrid.poem.57067": {"metadata": {"author": {"name": "Morgenstern, Christian", "birth": "N.A.", "death": "N.A."}, "title": "Die Schuhe", "genre": "verse", "period": "N.A.", "pub_year": 1892, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Man sieht sehr h\u00e4ufig unrecht tun,", "tokens": ["Man", "sieht", "sehr", "h\u00e4u\u00b7fig", "un\u00b7recht", "tun", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ADV", "ADJD", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "doch selten \u00f6fter als den Schuhn.", "tokens": ["doch", "sel\u00b7ten", "\u00f6f\u00b7ter", "als", "den", "Schuhn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ADV", "KOUS", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Man wei\u00df, da\u00df sie nach ewgen Normen", "tokens": ["Man", "wei\u00df", ",", "da\u00df", "sie", "nach", "ew\u00b7gen", "Nor\u00b7men"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "$,", "KOUS", "PPER", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "die Form der F\u00fc\u00dfe treu umformen.", "tokens": ["die", "Form", "der", "F\u00fc\u00b7\u00dfe", "treu", "um\u00b7for\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Die Sohlen scheinen auszuschweifen,", "tokens": ["Die", "Soh\u00b7len", "schei\u00b7nen", "aus\u00b7zu\u00b7schwei\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "VVIZU", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "bis sie am Ballen sich begreifen.", "tokens": ["bis", "sie", "am", "Bal\u00b7len", "sich", "be\u00b7grei\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPRART", "NN", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Ein jeder merkt: es ist ein Paar.", "tokens": ["Ein", "je\u00b7der", "merkt", ":", "es", "ist", "ein", "Paar", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VVFIN", "$.", "PPER", "VAFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Nur M\u00e4gden wird dies niemals klar.", "tokens": ["Nur", "M\u00e4g\u00b7den", "wird", "dies", "nie\u00b7mals", "klar", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "VAFIN", "PDS", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Sie setzen Stiefel (wo auch immer)", "tokens": ["Sie", "set\u00b7zen", "Stie\u00b7fel", "(", "wo", "auch", "im\u00b7mer", ")"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "$(", "PWAV", "ADV", "ADV", "$("], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "einander abgekehrt vors Zimmer.", "tokens": ["ein\u00b7an\u00b7der", "ab\u00b7ge\u00b7kehrt", "vors", "Zim\u00b7mer", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVPP", "APPRART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Was m\u00fcssen solche Schuhe leiden!", "tokens": ["Was", "m\u00fcs\u00b7sen", "sol\u00b7che", "Schu\u00b7he", "lei\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sie sind so flei\u00dfig, so bescheiden;", "tokens": ["Sie", "sind", "so", "flei\u00b7\u00dfig", ",", "so", "be\u00b7schei\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "$,", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "sie wollen nichts auf dieser Welt,", "tokens": ["sie", "wol\u00b7len", "nichts", "auf", "die\u00b7ser", "Welt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PIS", "APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "als da\u00df man sie zusammen stellt,", "tokens": ["als", "da\u00df", "man", "sie", "zu\u00b7sam\u00b7men", "stellt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOKOM", "KOUS", "PIS", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "nicht auseinanderstrebend wie", "tokens": ["nicht", "aus\u00b7ein\u00b7an\u00b7der\u00b7stre\u00b7bend", "wie"], "token_info": ["word", "word", "word"], "pos": ["PTKNEG", "VVPP", "KOKOM"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "das unvern\u00fcnftig bl\u00f6de Vieh!", "tokens": ["das", "un\u00b7ver\u00b7n\u00fcnf\u00b7tig", "bl\u00f6\u00b7de", "Vieh", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "O Ihr Marie, Sophie, Therese \u2013", "tokens": ["O", "Ihr", "Ma\u00b7rie", ",", "So\u00b7phie", ",", "The\u00b7re\u00b7se", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NE", "PPOSAT", "NN", "$,", "NE", "$,", "NN", "$("], "meter": "+-+-+-+--", "measure": "unknown.measure.tetra"}, "line.2": {"text": "der Satan wird euch einst, der b\u00f6se,", "tokens": ["der", "Sa\u00b7tan", "wird", "euch", "einst", ",", "der", "b\u00f6\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "ADV", "$,", "ART", "ADJA", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "die Stiefel anziehn, wenn es hei\u00dft,", "tokens": ["die", "Stie\u00b7fel", "an\u00b7ziehn", ",", "wenn", "es", "hei\u00dft", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVIZU", "$,", "KOUS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "hinweg zu gehn als seliger Geist!", "tokens": ["hin\u00b7weg", "zu", "gehn", "als", "se\u00b7li\u00b7ger", "Geist", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKZU", "VVINF", "KOKOM", "ADJA", "NN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.11": {"line.1": {"text": "Dann werdet ihr voll Wehgeheule", "tokens": ["Dann", "wer\u00b7det", "ihr", "voll", "Weh\u00b7ge\u00b7heu\u00b7le"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "das Schicksal teilen jener Eule,", "tokens": ["das", "Schick\u00b7sal", "tei\u00b7len", "je\u00b7ner", "Eu\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "die, als zwei Hasen nach sie flog,", "tokens": ["die", ",", "als", "zwei", "Ha\u00b7sen", "nach", "sie", "flog", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "KOUS", "CARD", "NN", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "und pl\u00f6tzlich jeder seitw\u00e4rts bog,", "tokens": ["und", "pl\u00f6tz\u00b7lich", "je\u00b7der", "seit\u00b7w\u00e4rts", "bog", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "PIS", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "der eine links, der andre rechts,", "tokens": ["der", "ei\u00b7ne", "links", ",", "der", "and\u00b7re", "rechts", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ART", "ADV", "$,", "PRELS", "PIS", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Wie Puppen, mitten durchges\u00e4gte,", "tokens": ["Wie", "Pup\u00b7pen", ",", "mit\u00b7ten", "durch\u00b7ge\u00b7s\u00e4g\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "NN", "$,", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "so werdet ihr alsdann, ihr M\u00e4gde,", "tokens": ["so", "wer\u00b7det", "ihr", "als\u00b7dann", ",", "ihr", "M\u00e4g\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "$,", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "bei Engeln halb und halb bei Teufeln", "tokens": ["bei", "En\u00b7geln", "halb", "und", "halb", "bei", "Teu\u00b7feln"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "ADJD", "KON", "ADJD", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "von niegestillten Tr\u00e4nen tr\u00e4ufeln,", "tokens": ["von", "nie\u00b7ge\u00b7still\u00b7ten", "Tr\u00e4\u00b7nen", "tr\u00e4u\u00b7feln", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "der H\u00f6lle ein willkommner Spott", "tokens": ["der", "H\u00f6l\u00b7le", "ein", "will\u00b7komm\u00b7ner", "Spott"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "und peinlich selbst dem lieben Gott.", "tokens": ["und", "pein\u00b7lich", "selbst", "dem", "lie\u00b7ben", "Gott", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.17": {"line.1": {"text": "Man sieht sehr h\u00e4ufig unrecht tun,", "tokens": ["Man", "sieht", "sehr", "h\u00e4u\u00b7fig", "un\u00b7recht", "tun", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ADV", "ADJD", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "doch selten \u00f6fter als den Schuhn.", "tokens": ["doch", "sel\u00b7ten", "\u00f6f\u00b7ter", "als", "den", "Schuhn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ADV", "KOUS", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.18": {"line.1": {"text": "Man wei\u00df, da\u00df sie nach ewgen Normen", "tokens": ["Man", "wei\u00df", ",", "da\u00df", "sie", "nach", "ew\u00b7gen", "Nor\u00b7men"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "$,", "KOUS", "PPER", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "die Form der F\u00fc\u00dfe treu umformen.", "tokens": ["die", "Form", "der", "F\u00fc\u00b7\u00dfe", "treu", "um\u00b7for\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.19": {"line.1": {"text": "Die Sohlen scheinen auszuschweifen,", "tokens": ["Die", "Soh\u00b7len", "schei\u00b7nen", "aus\u00b7zu\u00b7schwei\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "VVIZU", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "bis sie am Ballen sich begreifen.", "tokens": ["bis", "sie", "am", "Bal\u00b7len", "sich", "be\u00b7grei\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPRART", "NN", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.20": {"line.1": {"text": "Ein jeder merkt: es ist ein Paar.", "tokens": ["Ein", "je\u00b7der", "merkt", ":", "es", "ist", "ein", "Paar", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VVFIN", "$.", "PPER", "VAFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Nur M\u00e4gden wird dies niemals klar.", "tokens": ["Nur", "M\u00e4g\u00b7den", "wird", "dies", "nie\u00b7mals", "klar", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "VAFIN", "PDS", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.21": {"line.1": {"text": "Sie setzen Stiefel (wo auch immer)", "tokens": ["Sie", "set\u00b7zen", "Stie\u00b7fel", "(", "wo", "auch", "im\u00b7mer", ")"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "$(", "PWAV", "ADV", "ADV", "$("], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "einander abgekehrt vors Zimmer.", "tokens": ["ein\u00b7an\u00b7der", "ab\u00b7ge\u00b7kehrt", "vors", "Zim\u00b7mer", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVPP", "APPRART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.22": {"line.1": {"text": "Was m\u00fcssen solche Schuhe leiden!", "tokens": ["Was", "m\u00fcs\u00b7sen", "sol\u00b7che", "Schu\u00b7he", "lei\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sie sind so flei\u00dfig, so bescheiden;", "tokens": ["Sie", "sind", "so", "flei\u00b7\u00dfig", ",", "so", "be\u00b7schei\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "$,", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.23": {"line.1": {"text": "sie wollen nichts auf dieser Welt,", "tokens": ["sie", "wol\u00b7len", "nichts", "auf", "die\u00b7ser", "Welt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PIS", "APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "als da\u00df man sie zusammen stellt,", "tokens": ["als", "da\u00df", "man", "sie", "zu\u00b7sam\u00b7men", "stellt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOKOM", "KOUS", "PIS", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.24": {"line.1": {"text": "nicht auseinanderstrebend wie", "tokens": ["nicht", "aus\u00b7ein\u00b7an\u00b7der\u00b7stre\u00b7bend", "wie"], "token_info": ["word", "word", "word"], "pos": ["PTKNEG", "VVPP", "KOKOM"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "das unvern\u00fcnftig bl\u00f6de Vieh!", "tokens": ["das", "un\u00b7ver\u00b7n\u00fcnf\u00b7tig", "bl\u00f6\u00b7de", "Vieh", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.25": {"line.1": {"text": "O Ihr Marie, Sophie, Therese \u2013", "tokens": ["O", "Ihr", "Ma\u00b7rie", ",", "So\u00b7phie", ",", "The\u00b7re\u00b7se", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NE", "PPOSAT", "NN", "$,", "NE", "$,", "NN", "$("], "meter": "+-+-+-+--", "measure": "unknown.measure.tetra"}, "line.2": {"text": "der Satan wird euch einst, der b\u00f6se,", "tokens": ["der", "Sa\u00b7tan", "wird", "euch", "einst", ",", "der", "b\u00f6\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "ADV", "$,", "ART", "ADJA", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.26": {"line.1": {"text": "die Stiefel anziehn, wenn es hei\u00dft,", "tokens": ["die", "Stie\u00b7fel", "an\u00b7ziehn", ",", "wenn", "es", "hei\u00dft", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVIZU", "$,", "KOUS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "hinweg zu gehn als seliger Geist!", "tokens": ["hin\u00b7weg", "zu", "gehn", "als", "se\u00b7li\u00b7ger", "Geist", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKZU", "VVINF", "KOKOM", "ADJA", "NN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.27": {"line.1": {"text": "Dann werdet ihr voll Wehgeheule", "tokens": ["Dann", "wer\u00b7det", "ihr", "voll", "Weh\u00b7ge\u00b7heu\u00b7le"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "das Schicksal teilen jener Eule,", "tokens": ["das", "Schick\u00b7sal", "tei\u00b7len", "je\u00b7ner", "Eu\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.28": {"line.1": {"text": "die, als zwei Hasen nach sie flog,", "tokens": ["die", ",", "als", "zwei", "Ha\u00b7sen", "nach", "sie", "flog", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "KOUS", "CARD", "NN", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "und pl\u00f6tzlich jeder seitw\u00e4rts bog,", "tokens": ["und", "pl\u00f6tz\u00b7lich", "je\u00b7der", "seit\u00b7w\u00e4rts", "bog", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "PIS", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.29": {"line.1": {"text": "der eine links, der andre rechts,", "tokens": ["der", "ei\u00b7ne", "links", ",", "der", "and\u00b7re", "rechts", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ART", "ADV", "$,", "PRELS", "PIS", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.30": {"line.1": {"text": "Wie Puppen, mitten durchges\u00e4gte,", "tokens": ["Wie", "Pup\u00b7pen", ",", "mit\u00b7ten", "durch\u00b7ge\u00b7s\u00e4g\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "NN", "$,", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "so werdet ihr alsdann, ihr M\u00e4gde,", "tokens": ["so", "wer\u00b7det", "ihr", "als\u00b7dann", ",", "ihr", "M\u00e4g\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "$,", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.31": {"line.1": {"text": "bei Engeln halb und halb bei Teufeln", "tokens": ["bei", "En\u00b7geln", "halb", "und", "halb", "bei", "Teu\u00b7feln"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "ADJD", "KON", "ADJD", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "von niegestillten Tr\u00e4nen tr\u00e4ufeln,", "tokens": ["von", "nie\u00b7ge\u00b7still\u00b7ten", "Tr\u00e4\u00b7nen", "tr\u00e4u\u00b7feln", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.32": {"line.1": {"text": "der H\u00f6lle ein willkommner Spott", "tokens": ["der", "H\u00f6l\u00b7le", "ein", "will\u00b7komm\u00b7ner", "Spott"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "und peinlich selbst dem lieben Gott.", "tokens": ["und", "pein\u00b7lich", "selbst", "dem", "lie\u00b7ben", "Gott", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}