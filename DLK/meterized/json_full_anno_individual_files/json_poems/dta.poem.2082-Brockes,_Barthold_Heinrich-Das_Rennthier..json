{"dta.poem.2082": {"metadata": {"author": {"name": "Brockes, Barthold Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "Das Rennthier.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1748", "urn": "urn:nbn:de:kobv:b4-200905198553", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Welch ein rasches Thier ist die\u00df! Welch ein pr\u00e4chti-", "tokens": ["Welch", "ein", "ra\u00b7sches", "Thier", "ist", "die\u00df", "!", "Welch", "ein", "pr\u00e4ch\u00b7ti"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PIAT", "ART", "ADJA", "NN", "VAFIN", "PDS", "$.", "PIAT", "ART", "TRUNC"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "ges Geweih", "tokens": ["ges", "Ge\u00b7weih"], "token_info": ["word", "word"], "pos": ["ADJA", "NN"], "meter": "--+", "measure": "anapaest.init"}, "line.3": {"text": "Tr\u00e4gt es, \u00fcberall gezackt! Wie ein Pferd ist es bem\u00e4hnet,", "tokens": ["Tr\u00e4gt", "es", ",", "\u00fc\u00b7be\u00b7rall", "ge\u00b7zackt", "!", "Wie", "ein", "Pferd", "ist", "es", "be\u00b7m\u00e4h\u00b7net", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "ADV", "VVPP", "$.", "PWAV", "ART", "NN", "VAFIN", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+--+-+-+-", "measure": "trochaic.septa.relaxed"}, "line.4": {"text": "Einem Kalbe gleicht sein Haupt. Einige sind wild und", "tokens": ["Ei\u00b7nem", "Kal\u00b7be", "gleicht", "sein", "Haupt", ".", "Ei\u00b7ni\u00b7ge", "sind", "wild", "und"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PPOSAT", "NN", "$.", "PIS", "VAFIN", "ADJD", "KON"], "meter": "+-+-+-+-+--+-", "measure": "hexameter"}, "line.5": {"text": "frey,", "tokens": ["frey", ","], "token_info": ["word", "punct"], "pos": ["ADJD", "$,"], "meter": "+", "measure": "single.up"}, "line.6": {"text": "Andere sind uns zum Dienst zahm und sonderbar ge-", "tokens": ["An\u00b7de\u00b7re", "sind", "uns", "zum", "Dienst", "zahm", "und", "son\u00b7der\u00b7bar", "ge"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VAFIN", "PPER", "APPRART", "NN", "ADJD", "KON", "ADJD", "TRUNC"], "meter": "-+-++-++-+-+-", "measure": "unknown.measure.septa"}, "line.7": {"text": "wehnet.", "tokens": ["weh\u00b7net", "."], "token_info": ["word", "punct"], "pos": ["VVFIN", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.8": {"text": "Dieses Thier zu unterhalten, sind die Kosten gar nicht", "tokens": ["Die\u00b7ses", "Thier", "zu", "un\u00b7ter\u00b7hal\u00b7ten", ",", "sind", "die", "Kos\u00b7ten", "gar", "nicht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PDAT", "NN", "PTKZU", "VVINF", "$,", "VAFIN", "ART", "NN", "ADV", "PTKNEG"], "meter": "+-+-+-+-+-+--+", "measure": "iambic.septa.chol"}, "line.9": {"text": "gro\u00df,", "tokens": ["gro\u00df", ","], "token_info": ["word", "punct"], "pos": ["ADJD", "$,"], "meter": "-", "measure": "single.down"}, "line.10": {"text": "Denn es kratzt zu seiner Nahrung ein verworfnes wei\u00dfes", "tokens": ["Denn", "es", "kratzt", "zu", "sei\u00b7ner", "Nah\u00b7rung", "ein", "ver\u00b7worf\u00b7nes", "wei\u00b7\u00dfes"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "APPR", "PPOSAT", "NN", "ART", "ADJA", "ADJA"], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}, "line.11": {"text": "Moos,", "tokens": ["Moos", ","], "token_info": ["word", "punct"], "pos": ["NN", "$,"], "meter": "+", "measure": "single.up"}, "line.12": {"text": "Das in \u00f6den Feldern w\u00e4chst, selber unterm Schnee", "tokens": ["Das", "in", "\u00f6\u00b7den", "Fel\u00b7dern", "w\u00e4chst", ",", "sel\u00b7ber", "un\u00b7term", "Schnee"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PDS", "APPR", "ADJA", "NN", "VVFIN", "$,", "ADV", "APPRART", "NN"], "meter": "--+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.13": {"text": "herf\u00fcr:", "tokens": ["her\u00b7f\u00fcr", ":"], "token_info": ["word", "punct"], "pos": ["ADV", "$."], "meter": "-+", "measure": "iambic.single"}, "line.14": {"text": "Und dennoch sind Fleisch und Haut, Knochen, Sehnen,", "tokens": ["Und", "den\u00b7noch", "sind", "Fleisch", "und", "Haut", ",", "Kno\u00b7chen", ",", "Seh\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "NN", "KON", "NN", "$,", "NN", "$,", "NN", "$,"], "meter": "-+--+-++-+-", "measure": "iambic.penta.relaxed"}, "line.15": {"text": "Milch und Haar", "tokens": ["Milch", "und", "Haar"], "token_info": ["word", "word", "word"], "pos": ["NN", "KON", "NN"], "meter": "+-+", "measure": "trochaic.di"}, "line.16": {"text": "Allesammt dem Menschen n\u00fctzlich. So wird auch in", "tokens": ["Al\u00b7le\u00b7sammt", "dem", "Men\u00b7schen", "n\u00fctz\u00b7lich", ".", "So", "wird", "auch", "in"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ADJD", "$.", "ADV", "VAFIN", "ADV", "APPR"], "meter": "+-+-+-+--+-+", "measure": "trochaic.hexa.relaxed"}, "line.17": {"text": "diesem Thier", "tokens": ["die\u00b7sem", "Thier"], "token_info": ["word", "word"], "pos": ["PDAT", "NN"], "meter": "+-+", "measure": "trochaic.di"}, "line.18": {"text": "Seines Sch\u00f6pfers Weisheit, Allmacht, sammt der Huld,", "tokens": ["Sei\u00b7nes", "Sch\u00f6p\u00b7fers", "Weis\u00b7heit", ",", "All\u00b7macht", ",", "sammt", "der", "Huld", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "NN", "$,", "NN", "$,", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.19": {"text": "uns offenbar.", "tokens": ["uns", "of\u00b7fen\u00b7bar", "."], "token_info": ["word", "word", "punct"], "pos": ["PPER", "ADJD", "$."], "meter": "-+-+", "measure": "iambic.di"}}}}}