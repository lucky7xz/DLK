{"textgrid.poem.52072": {"metadata": {"author": {"name": "Czepko von Reigersfeld, Daniel", "birth": "N.A.", "death": "N.A."}, "title": "3.", "genre": "verse", "period": "N.A.", "pub_year": 1632, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Du hast ja nichts gelernt, als Flecke mit den Z\u00e4hnen,", "tokens": ["Du", "hast", "ja", "nichts", "ge\u00b7lernt", ",", "als", "Fle\u00b7cke", "mit", "den", "Z\u00e4h\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "PIS", "VVPP", "$,", "KOUS", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die von den A\u00e4\u00dfern seyn, auff Stieffelbrete dehnen:", "tokens": ["Die", "von", "den", "A\u00b7\u00e4\u00b7\u00dfern", "seyn", ",", "auff", "Stief\u00b7fel\u00b7bre\u00b7te", "deh\u00b7nen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "VAINF", "$,", "APPR", "NN", "VVINF", "$."], "meter": "-+-+--+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Itzt baustu Ha\u00fcser auff und kauffest G\u00fctter dir,", "tokens": ["Itzt", "baus\u00b7tu", "Ha\u00fc\u00b7ser", "auff", "und", "kauf\u00b7fest", "G\u00fct\u00b7ter", "dir", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NN", "APPR", "KON", "VVFIN", "NN", "PPER", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der du vor kurtzer Zeit kaum hattest Brod und Bier.", "tokens": ["Der", "du", "vor", "kurt\u00b7zer", "Zeit", "kaum", "hat\u00b7test", "Brod", "und", "Bier", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "ADJA", "NN", "ADV", "VAFIN", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Alsbald der Seiger schl\u00e4gt, so mu\u00df der Junge lauffen,", "tokens": ["Als\u00b7bald", "der", "Sei\u00b7ger", "schl\u00e4gt", ",", "so", "mu\u00df", "der", "Jun\u00b7ge", "lauf\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVFIN", "$,", "ADV", "VMFIN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und, wo der beste Wein, dir deinen Tischtrunck kauffen,", "tokens": ["Und", ",", "wo", "der", "bes\u00b7te", "Wein", ",", "dir", "dei\u00b7nen", "Tischtrunck", "kauf\u00b7fen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "PWAV", "ART", "ADJA", "NN", "$,", "PPER", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Was zu der Mahlzeit sol, das mu\u00df ein Haselhun,", "tokens": ["Was", "zu", "der", "Mahl\u00b7zeit", "sol", ",", "das", "mu\u00df", "ein", "Ha\u00b7sel\u00b7hun", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "ART", "NN", "VMFIN", "$,", "PDS", "VMFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der Lachs Forellen Tracht, kein Polnscher Ochse thun.", "tokens": ["Der", "Lachs", "Fo\u00b7rel\u00b7len", "Tracht", ",", "kein", "Poln\u00b7scher", "O\u00b7chse", "thun", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "NN", "$,", "PIAT", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Der P\u00f6fel f\u00e4ngt dich an, da, wo du gehst, zu ehren,", "tokens": ["Der", "P\u00f6\u00b7fel", "f\u00e4ngt", "dich", "an", ",", "da", ",", "wo", "du", "gehst", ",", "zu", "eh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "PTKVZ", "$,", "KOUS", "$,", "PWAV", "PPER", "VVFIN", "$,", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ich wei\u00df nicht was er sol von einem Ammte h\u00f6ren,", "tokens": ["Ich", "wei\u00df", "nicht", "was", "er", "sol", "von", "ei\u00b7nem", "Amm\u00b7te", "h\u00f6\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "PWS", "PPER", "VMFIN", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Das Gl\u00fccke hat dich schon so weit bekannt gemacht,", "tokens": ["Das", "Gl\u00fc\u00b7cke", "hat", "dich", "schon", "so", "weit", "be\u00b7kannt", "ge\u00b7macht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "ADV", "ADV", "ADJD", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Da\u00df auch Ein Erbar Rath auff dich wil seyn bedacht.", "tokens": ["Da\u00df", "auch", "Ein", "Er\u00b7bar", "Rath", "auff", "dich", "wil", "seyn", "be\u00b7dacht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "NN", "APPR", "PPER", "VMFIN", "PPOSAT", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Was hilfft michs, da\u00df ich bin den Musen nachgezogen,", "tokens": ["Was", "hilfft", "michs", ",", "da\u00df", "ich", "bin", "den", "Mu\u00b7sen", "nach\u00b7ge\u00b7zo\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PIS", "$,", "KOUS", "PPER", "VAFIN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die Eltern sind um Gold, und ich um M\u00fch betrogen.", "tokens": ["Die", "El\u00b7tern", "sind", "um", "Gold", ",", "und", "ich", "um", "M\u00fch", "be\u00b7tro\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "APPR", "NN", "$,", "KON", "PPER", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Es ist umbsonst sein Gl\u00fcck in K\u00fcnsten fliehen an,", "tokens": ["Es", "ist", "um\u00b7bsonst", "sein", "Gl\u00fcck", "in", "K\u00fcns\u00b7ten", "flie\u00b7hen", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "PPOSAT", "NN", "APPR", "NN", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wann einem Schuster dis der Leisten geben kann.", "tokens": ["Wann", "ei\u00b7nem", "Schus\u00b7ter", "dis", "der", "Leis\u00b7ten", "ge\u00b7ben", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "PDS", "ART", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Du hast ja nichts gelernt, als Flecke mit den Z\u00e4hnen,", "tokens": ["Du", "hast", "ja", "nichts", "ge\u00b7lernt", ",", "als", "Fle\u00b7cke", "mit", "den", "Z\u00e4h\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "PIS", "VVPP", "$,", "KOUS", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die von den A\u00e4\u00dfern seyn, auff Stieffelbrete dehnen:", "tokens": ["Die", "von", "den", "A\u00b7\u00e4\u00b7\u00dfern", "seyn", ",", "auff", "Stief\u00b7fel\u00b7bre\u00b7te", "deh\u00b7nen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "VAINF", "$,", "APPR", "NN", "VVINF", "$."], "meter": "-+-+--+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Itzt baustu Ha\u00fcser auff und kauffest G\u00fctter dir,", "tokens": ["Itzt", "baus\u00b7tu", "Ha\u00fc\u00b7ser", "auff", "und", "kauf\u00b7fest", "G\u00fct\u00b7ter", "dir", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NN", "APPR", "KON", "VVFIN", "NN", "PPER", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der du vor kurtzer Zeit kaum hattest Brod und Bier.", "tokens": ["Der", "du", "vor", "kurt\u00b7zer", "Zeit", "kaum", "hat\u00b7test", "Brod", "und", "Bier", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "ADJA", "NN", "ADV", "VAFIN", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Alsbald der Seiger schl\u00e4gt, so mu\u00df der Junge lauffen,", "tokens": ["Als\u00b7bald", "der", "Sei\u00b7ger", "schl\u00e4gt", ",", "so", "mu\u00df", "der", "Jun\u00b7ge", "lauf\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVFIN", "$,", "ADV", "VMFIN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und, wo der beste Wein, dir deinen Tischtrunck kauffen,", "tokens": ["Und", ",", "wo", "der", "bes\u00b7te", "Wein", ",", "dir", "dei\u00b7nen", "Tischtrunck", "kauf\u00b7fen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "PWAV", "ART", "ADJA", "NN", "$,", "PPER", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Was zu der Mahlzeit sol, das mu\u00df ein Haselhun,", "tokens": ["Was", "zu", "der", "Mahl\u00b7zeit", "sol", ",", "das", "mu\u00df", "ein", "Ha\u00b7sel\u00b7hun", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "ART", "NN", "VMFIN", "$,", "PDS", "VMFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der Lachs Forellen Tracht, kein Polnscher Ochse thun.", "tokens": ["Der", "Lachs", "Fo\u00b7rel\u00b7len", "Tracht", ",", "kein", "Poln\u00b7scher", "O\u00b7chse", "thun", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "NN", "$,", "PIAT", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Der P\u00f6fel f\u00e4ngt dich an, da, wo du gehst, zu ehren,", "tokens": ["Der", "P\u00f6\u00b7fel", "f\u00e4ngt", "dich", "an", ",", "da", ",", "wo", "du", "gehst", ",", "zu", "eh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "PTKVZ", "$,", "KOUS", "$,", "PWAV", "PPER", "VVFIN", "$,", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ich wei\u00df nicht was er sol von einem Ammte h\u00f6ren,", "tokens": ["Ich", "wei\u00df", "nicht", "was", "er", "sol", "von", "ei\u00b7nem", "Amm\u00b7te", "h\u00f6\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "PWS", "PPER", "VMFIN", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Das Gl\u00fccke hat dich schon so weit bekannt gemacht,", "tokens": ["Das", "Gl\u00fc\u00b7cke", "hat", "dich", "schon", "so", "weit", "be\u00b7kannt", "ge\u00b7macht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "ADV", "ADV", "ADJD", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Da\u00df auch Ein Erbar Rath auff dich wil seyn bedacht.", "tokens": ["Da\u00df", "auch", "Ein", "Er\u00b7bar", "Rath", "auff", "dich", "wil", "seyn", "be\u00b7dacht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "NN", "APPR", "PPER", "VMFIN", "PPOSAT", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "Was hilfft michs, da\u00df ich bin den Musen nachgezogen,", "tokens": ["Was", "hilfft", "michs", ",", "da\u00df", "ich", "bin", "den", "Mu\u00b7sen", "nach\u00b7ge\u00b7zo\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PIS", "$,", "KOUS", "PPER", "VAFIN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die Eltern sind um Gold, und ich um M\u00fch betrogen.", "tokens": ["Die", "El\u00b7tern", "sind", "um", "Gold", ",", "und", "ich", "um", "M\u00fch", "be\u00b7tro\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "APPR", "NN", "$,", "KON", "PPER", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Es ist umbsonst sein Gl\u00fcck in K\u00fcnsten fliehen an,", "tokens": ["Es", "ist", "um\u00b7bsonst", "sein", "Gl\u00fcck", "in", "K\u00fcns\u00b7ten", "flie\u00b7hen", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "PPOSAT", "NN", "APPR", "NN", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wann einem Schuster dis der Leisten geben kann.", "tokens": ["Wann", "ei\u00b7nem", "Schus\u00b7ter", "dis", "der", "Leis\u00b7ten", "ge\u00b7ben", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "PDS", "ART", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}