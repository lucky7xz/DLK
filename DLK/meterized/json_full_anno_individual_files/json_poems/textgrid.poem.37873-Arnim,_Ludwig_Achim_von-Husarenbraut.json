{"textgrid.poem.37873": {"metadata": {"author": {"name": "Arnim, Ludwig Achim von", "birth": "N.A.", "death": "N.A."}, "title": "Husarenbraut", "genre": "verse", "period": "N.A.", "pub_year": 1806, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wir Preussisch Husaren, wann kriegen wir Geld?", "tokens": ["Wir", "Preus\u00b7sisch", "Hu\u00b7sa\u00b7ren", ",", "wann", "krie\u00b7gen", "wir", "Geld", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "NN", "$,", "PWAV", "VVFIN", "PPER", "NN", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.2": {"text": "Wir m\u00fcssen marschiren ins weite Feld,", "tokens": ["Wir", "m\u00fcs\u00b7sen", "mar\u00b7schi\u00b7ren", "ins", "wei\u00b7te", "Feld", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "VVINF", "APPRART", "ADJA", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Wir m\u00fcssen marschiren dem Feind entgegen,", "tokens": ["Wir", "m\u00fcs\u00b7sen", "mar\u00b7schi\u00b7ren", "dem", "Feind", "ent\u00b7ge\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "VVINF", "ART", "NN", "PTKVZ", "$,"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Damit wir ihm heute den Pa\u00df noch verlegen.", "tokens": ["Da\u00b7mit", "wir", "ihm", "heu\u00b7te", "den", "Pa\u00df", "noch", "ver\u00b7le\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "ADV", "ART", "NN", "ADV", "VVINF", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}}, "stanza.2": {"line.1": {"text": "Wir haben ein Gl\u00f6cklein, das lautet so hell,", "tokens": ["Wir", "ha\u00b7ben", "ein", "Gl\u00f6c\u00b7klein", ",", "das", "lau\u00b7tet", "so", "hell", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "$,", "PDS", "VVFIN", "ADV", "ADJD", "$,"], "meter": "-+--++-+--+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Das ist \u00fcberzogen mit gelbem Fell,", "tokens": ["Das", "ist", "\u00fc\u00b7berz\u00b7o\u00b7gen", "mit", "gel\u00b7bem", "Fell", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Und wenn ich das Gl\u00f6cklein nur l\u00e4uten geh\u00f6rt,", "tokens": ["Und", "wenn", "ich", "das", "Gl\u00f6c\u00b7klein", "nur", "l\u00e4u\u00b7ten", "ge\u00b7h\u00f6rt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ART", "NN", "ADV", "VVINF", "VVFIN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "So hei\u00dft es: Husaren, auf euere Pferd!", "tokens": ["So", "hei\u00dft", "es", ":", "Hu\u00b7sa\u00b7ren", ",", "auf", "eu\u00b7e\u00b7re", "Pferd", "!"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$.", "NN", "$,", "APPR", "PPOSAT", "NN", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}}, "stanza.3": {"line.1": {"text": "Wir haben ein Br\u00e4utlein uns auserw\u00e4hlt,", "tokens": ["Wir", "ha\u00b7ben", "ein", "Br\u00e4ut\u00b7lein", "uns", "au\u00b7ser\u00b7w\u00e4hlt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "PPER", "VVPP", "$,"], "meter": "-+-+---+-+", "measure": "zehnsilber"}, "line.2": {"text": "Das lebet und schwebet ins weite Feld,", "tokens": ["Das", "le\u00b7bet", "und", "schwe\u00b7bet", "ins", "wei\u00b7te", "Feld", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "KON", "VVFIN", "APPRART", "ADJA", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Das Br\u00e4utlein, das wird die Standarte genannt,", "tokens": ["Das", "Br\u00e4ut\u00b7lein", ",", "das", "wird", "die", "Stand\u00b7ar\u00b7te", "ge\u00b7nannt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PDS", "VAFIN", "ART", "NN", "VVPP", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "Das ist uns Husaren sehr wohl bekannt.", "tokens": ["Das", "ist", "uns", "Hu\u00b7sa\u00b7ren", "sehr", "wohl", "be\u00b7kannt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "NN", "ADV", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Und als dann die Schlacht vor\u00fcber war,", "tokens": ["Und", "als", "dann", "die", "Schlacht", "vor\u00b7\u00fc\u00b7ber", "war", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ADV", "ART", "NN", "ADV", "VAFIN", "$,"], "meter": "--+-+-+-+", "measure": "anapaest.init"}, "line.2": {"text": "Da einer den andern wohl sterben sah!", "tokens": ["Da", "ei\u00b7ner", "den", "an\u00b7dern", "wohl", "ster\u00b7ben", "sah", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ART", "ADJA", "ADV", "VVINF", "VVFIN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Schrie einer zum andern: Ach! Jammer, Angst und Noth,", "tokens": ["Schrie", "ei\u00b7ner", "zum", "an\u00b7dern", ":", "Ach", "!", "Jam\u00b7mer", ",", "Angst", "und", "Noth", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "ART", "APPRART", "ADJA", "$.", "ITJ", "$.", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Mein lieber Kamerad ist geblieben todt.", "tokens": ["Mein", "lie\u00b7ber", "Ka\u00b7me\u00b7rad", "ist", "ge\u00b7blie\u00b7ben", "todt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VAFIN", "VVPP", "ADJD", "$."], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}}, "stanza.5": {"line.1": {"text": "Das Gl\u00f6cklein es klinget nicht eben so hell,", "tokens": ["Das", "Gl\u00f6c\u00b7klein", "es", "klin\u00b7get", "nicht", "e\u00b7ben", "so", "hell", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPER", "VVFIN", "PTKNEG", "ADV", "ADV", "ADJD", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "Denn ihm ist zerschossen sein gelbliges Fell,", "tokens": ["Denn", "ihm", "ist", "zer\u00b7schos\u00b7sen", "sein", "gel\u00b7bli\u00b7ges", "Fell", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "VVPP", "VAINF", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.3": {"text": "Das silberne Br\u00e4utlein ist uns doch geblieben,", "tokens": ["Das", "sil\u00b7ber\u00b7ne", "Br\u00e4ut\u00b7lein", "ist", "uns", "doch", "ge\u00b7blie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "PPER", "ADV", "VVPP", "$,"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Es thuet uns winken, was hilft das Betr\u00fcben.", "tokens": ["Es", "thu\u00b7et", "uns", "win\u00b7ken", ",", "was", "hilft", "das", "Be\u00b7tr\u00fc\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "VVFIN", "$,", "PWS", "VVFIN", "ART", "NN", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}}, "stanza.6": {"line.1": {"text": "Wer sich in Preussischen Dienst will begeben,", "tokens": ["Wer", "sich", "in", "Preus\u00b7si\u00b7schen", "Dienst", "will", "be\u00b7ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PRF", "APPR", "ADJA", "NN", "VMFIN", "VVINF", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Der mu\u00df sich sein Lebtag kein Weibchen nicht nehmen:", "tokens": ["Der", "mu\u00df", "sich", "sein", "Leb\u00b7tag", "kein", "Weib\u00b7chen", "nicht", "neh\u00b7men", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PRF", "PPOSAT", "NN", "PIAT", "NN", "PTKNEG", "VVINF", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.3": {"text": "Er mu\u00df sich nicht f\u00fcrchten vor Hagel und Wind,", "tokens": ["Er", "mu\u00df", "sich", "nicht", "f\u00fcrch\u00b7ten", "vor", "Ha\u00b7gel", "und", "Wind", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PRF", "PTKNEG", "VVFIN", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "Best\u00e4ndig verbleiben und bleiben geschwind.", "tokens": ["Be\u00b7st\u00e4n\u00b7dig", "ver\u00b7blei\u00b7ben", "und", "blei\u00b7ben", "ge\u00b7schwind", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVINF", "KON", "VVFIN", "ADJD", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}}, "stanza.7": {"line.1": {"text": "Wir Preussisch Husaren, wann kriegen wir Geld?", "tokens": ["Wir", "Preus\u00b7sisch", "Hu\u00b7sa\u00b7ren", ",", "wann", "krie\u00b7gen", "wir", "Geld", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "NN", "$,", "PWAV", "VVFIN", "PPER", "NN", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.2": {"text": "Wir m\u00fcssen marschiren ins weite Feld,", "tokens": ["Wir", "m\u00fcs\u00b7sen", "mar\u00b7schi\u00b7ren", "ins", "wei\u00b7te", "Feld", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "VVINF", "APPRART", "ADJA", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Wir m\u00fcssen marschiren dem Feind entgegen,", "tokens": ["Wir", "m\u00fcs\u00b7sen", "mar\u00b7schi\u00b7ren", "dem", "Feind", "ent\u00b7ge\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "VVINF", "ART", "NN", "PTKVZ", "$,"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Damit wir ihm heute den Pa\u00df noch verlegen.", "tokens": ["Da\u00b7mit", "wir", "ihm", "heu\u00b7te", "den", "Pa\u00df", "noch", "ver\u00b7le\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "ADV", "ART", "NN", "ADV", "VVINF", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}}, "stanza.8": {"line.1": {"text": "Wir haben ein Gl\u00f6cklein, das lautet so hell,", "tokens": ["Wir", "ha\u00b7ben", "ein", "Gl\u00f6c\u00b7klein", ",", "das", "lau\u00b7tet", "so", "hell", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "$,", "PDS", "VVFIN", "ADV", "ADJD", "$,"], "meter": "-+--++-+--+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Das ist \u00fcberzogen mit gelbem Fell,", "tokens": ["Das", "ist", "\u00fc\u00b7berz\u00b7o\u00b7gen", "mit", "gel\u00b7bem", "Fell", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Und wenn ich das Gl\u00f6cklein nur l\u00e4uten geh\u00f6rt,", "tokens": ["Und", "wenn", "ich", "das", "Gl\u00f6c\u00b7klein", "nur", "l\u00e4u\u00b7ten", "ge\u00b7h\u00f6rt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ART", "NN", "ADV", "VVINF", "VVFIN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "So hei\u00dft es: Husaren, auf euere Pferd!", "tokens": ["So", "hei\u00dft", "es", ":", "Hu\u00b7sa\u00b7ren", ",", "auf", "eu\u00b7e\u00b7re", "Pferd", "!"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$.", "NN", "$,", "APPR", "PPOSAT", "NN", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}}, "stanza.9": {"line.1": {"text": "Wir haben ein Br\u00e4utlein uns auserw\u00e4hlt,", "tokens": ["Wir", "ha\u00b7ben", "ein", "Br\u00e4ut\u00b7lein", "uns", "au\u00b7ser\u00b7w\u00e4hlt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "PPER", "VVPP", "$,"], "meter": "-+-+---+-+", "measure": "zehnsilber"}, "line.2": {"text": "Das lebet und schwebet ins weite Feld,", "tokens": ["Das", "le\u00b7bet", "und", "schwe\u00b7bet", "ins", "wei\u00b7te", "Feld", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "KON", "VVFIN", "APPRART", "ADJA", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Das Br\u00e4utlein, das wird die Standarte genannt,", "tokens": ["Das", "Br\u00e4ut\u00b7lein", ",", "das", "wird", "die", "Stand\u00b7ar\u00b7te", "ge\u00b7nannt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PDS", "VAFIN", "ART", "NN", "VVPP", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "Das ist uns Husaren sehr wohl bekannt.", "tokens": ["Das", "ist", "uns", "Hu\u00b7sa\u00b7ren", "sehr", "wohl", "be\u00b7kannt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "NN", "ADV", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.10": {"line.1": {"text": "Und als dann die Schlacht vor\u00fcber war,", "tokens": ["Und", "als", "dann", "die", "Schlacht", "vor\u00b7\u00fc\u00b7ber", "war", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ADV", "ART", "NN", "ADV", "VAFIN", "$,"], "meter": "--+-+-+-+", "measure": "anapaest.init"}, "line.2": {"text": "Da einer den andern wohl sterben sah!", "tokens": ["Da", "ei\u00b7ner", "den", "an\u00b7dern", "wohl", "ster\u00b7ben", "sah", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ART", "ADJA", "ADV", "VVINF", "VVFIN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Schrie einer zum andern: Ach! Jammer, Angst und Noth,", "tokens": ["Schrie", "ei\u00b7ner", "zum", "an\u00b7dern", ":", "Ach", "!", "Jam\u00b7mer", ",", "Angst", "und", "Noth", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "ART", "APPRART", "ADJA", "$.", "ITJ", "$.", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Mein lieber Kamerad ist geblieben todt.", "tokens": ["Mein", "lie\u00b7ber", "Ka\u00b7me\u00b7rad", "ist", "ge\u00b7blie\u00b7ben", "todt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VAFIN", "VVPP", "ADJD", "$."], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}}, "stanza.11": {"line.1": {"text": "Das Gl\u00f6cklein es klinget nicht eben so hell,", "tokens": ["Das", "Gl\u00f6c\u00b7klein", "es", "klin\u00b7get", "nicht", "e\u00b7ben", "so", "hell", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPER", "VVFIN", "PTKNEG", "ADV", "ADV", "ADJD", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "Denn ihm ist zerschossen sein gelbliges Fell,", "tokens": ["Denn", "ihm", "ist", "zer\u00b7schos\u00b7sen", "sein", "gel\u00b7bli\u00b7ges", "Fell", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "VVPP", "VAINF", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.3": {"text": "Das silberne Br\u00e4utlein ist uns doch geblieben,", "tokens": ["Das", "sil\u00b7ber\u00b7ne", "Br\u00e4ut\u00b7lein", "ist", "uns", "doch", "ge\u00b7blie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "PPER", "ADV", "VVPP", "$,"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Es thuet uns winken, was hilft das Betr\u00fcben.", "tokens": ["Es", "thu\u00b7et", "uns", "win\u00b7ken", ",", "was", "hilft", "das", "Be\u00b7tr\u00fc\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "VVFIN", "$,", "PWS", "VVFIN", "ART", "NN", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}}, "stanza.12": {"line.1": {"text": "Wer sich in Preussischen Dienst will begeben,", "tokens": ["Wer", "sich", "in", "Preus\u00b7si\u00b7schen", "Dienst", "will", "be\u00b7ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PRF", "APPR", "ADJA", "NN", "VMFIN", "VVINF", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Der mu\u00df sich sein Lebtag kein Weibchen nicht nehmen:", "tokens": ["Der", "mu\u00df", "sich", "sein", "Leb\u00b7tag", "kein", "Weib\u00b7chen", "nicht", "neh\u00b7men", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PRF", "PPOSAT", "NN", "PIAT", "NN", "PTKNEG", "VVINF", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.3": {"text": "Er mu\u00df sich nicht f\u00fcrchten vor Hagel und Wind,", "tokens": ["Er", "mu\u00df", "sich", "nicht", "f\u00fcrch\u00b7ten", "vor", "Ha\u00b7gel", "und", "Wind", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PRF", "PTKNEG", "VVFIN", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "Best\u00e4ndig verbleiben und bleiben geschwind.", "tokens": ["Be\u00b7st\u00e4n\u00b7dig", "ver\u00b7blei\u00b7ben", "und", "blei\u00b7ben", "ge\u00b7schwind", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVINF", "KON", "VVFIN", "ADJD", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}}}}}