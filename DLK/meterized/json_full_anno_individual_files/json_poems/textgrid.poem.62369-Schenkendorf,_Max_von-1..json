{"textgrid.poem.62369": {"metadata": {"author": {"name": "Schenkendorf, Max von", "birth": "N.A.", "death": "N.A."}, "title": "1.", "genre": "verse", "period": "N.A.", "pub_year": 1800, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Honiglippe, Rosenmund,", "tokens": ["Ho\u00b7ni\u00b7glip\u00b7pe", ",", "Ro\u00b7sen\u00b7mund", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "K\u00fcsse mich zu jeder Stund'!", "tokens": ["K\u00fcs\u00b7se", "mich", "zu", "je\u00b7der", "Stund'", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "APPR", "PIAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Arme weich und wonniglich,", "tokens": ["Ar\u00b7me", "weich", "und", "won\u00b7nig\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "KON", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Liebesketten, bindet mich.", "tokens": ["Lie\u00b7bes\u00b7ket\u00b7ten", ",", "bin\u00b7det", "mich", "."], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Dunkel ist das Felsenthal", "tokens": ["Dun\u00b7kel", "ist", "das", "Fel\u00b7sen\u00b7thal"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJD", "VAFIN", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Und der Steg ist schwank und schmal;", "tokens": ["Und", "der", "Steg", "ist", "schwank", "und", "schmal", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VAFIN", "ADJD", "KON", "ADJD", "$."], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.3": {"text": "Doch du leuchtest mir so gern,", "tokens": ["Doch", "du", "leuch\u00b7test", "mir", "so", "gern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPER", "ADV", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Himmelsfunken, Augenstern.", "tokens": ["Him\u00b7mels\u00b7fun\u00b7ken", ",", "Au\u00b7gens\u00b7tern", "."], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$."], "meter": "+-+-+--", "measure": "unknown.measure.tri"}}, "stanza.3": {"line.1": {"text": "Athem, Rede, Druck und Ku\u00df,", "tokens": ["A\u00b7them", ",", "Re\u00b7de", ",", "Druck", "und", "Ku\u00df", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Aller Wonnen Ueberflu\u00df,", "tokens": ["Al\u00b7ler", "Won\u00b7nen", "Ue\u00b7berf\u00b7lu\u00df", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Engelseele, G\u00f6tterleib,", "tokens": ["En\u00b7gel\u00b7see\u00b7le", ",", "G\u00f6t\u00b7ter\u00b7leib", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NE", "$,", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Mein das allersch\u00f6nste Weib.", "tokens": ["Mein", "das", "al\u00b7ler\u00b7sch\u00f6ns\u00b7te", "Weib", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Alles, alles das war mein;", "tokens": ["Al\u00b7les", ",", "al\u00b7les", "das", "war", "mein", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "$,", "PIS", "PDS", "VAFIN", "PPOSAT", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Mu\u00df nun so verlassen sein!", "tokens": ["Mu\u00df", "nun", "so", "ver\u00b7las\u00b7sen", "sein", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "ADV", "VVPP", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "S\u00e4nk' ich blutend in der Schlacht,", "tokens": ["S\u00e4nk'", "ich", "blu\u00b7tend", "in", "der", "Schlacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Niemand h\u00e4tte meiner Acht!", "tokens": ["Nie\u00b7mand", "h\u00e4t\u00b7te", "mei\u00b7ner", "Acht", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "PPOSAT", "CARD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Wanke nicht mein guter Muth,", "tokens": ["Wan\u00b7ke", "nicht", "mein", "gu\u00b7ter", "Muth", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Lust am Leben, leichtes Blut,", "tokens": ["Lust", "am", "Le\u00b7ben", ",", "leich\u00b7tes", "Blut", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "APPRART", "NN", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df der Schmerz mich nicht verzehrt,", "tokens": ["Da\u00df", "der", "Schmerz", "mich", "nicht", "ver\u00b7zehrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "PPER", "PTKNEG", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Eh' mein Himmel wiederkehrt.", "tokens": ["Eh'", "mein", "Him\u00b7mel", "wie\u00b7der\u00b7kehrt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Ach, ich bin so bla\u00df und krank,", "tokens": ["Ach", ",", "ich", "bin", "so", "bla\u00df", "und", "krank", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "PPER", "VAFIN", "ADV", "ADJD", "KON", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "W\u00fc\u00dfte wol dem Arzte Dank!", "tokens": ["W\u00fc\u00df\u00b7te", "wol", "dem", "Arz\u00b7te", "Dank", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Honiglippe, Rosenmund,", "tokens": ["Ho\u00b7ni\u00b7glip\u00b7pe", ",", "Ro\u00b7sen\u00b7mund", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Sprich, wann machst du mich gesund?", "tokens": ["Sprich", ",", "wann", "machst", "du", "mich", "ge\u00b7sund", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "$,", "PWAV", "VVFIN", "PPER", "PRF", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Honiglippe, Rosenmund,", "tokens": ["Ho\u00b7ni\u00b7glip\u00b7pe", ",", "Ro\u00b7sen\u00b7mund", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "K\u00fcsse mich zu jeder Stund'!", "tokens": ["K\u00fcs\u00b7se", "mich", "zu", "je\u00b7der", "Stund'", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "APPR", "PIAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Arme weich und wonniglich,", "tokens": ["Ar\u00b7me", "weich", "und", "won\u00b7nig\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "KON", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Liebesketten, bindet mich.", "tokens": ["Lie\u00b7bes\u00b7ket\u00b7ten", ",", "bin\u00b7det", "mich", "."], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Dunkel ist das Felsenthal", "tokens": ["Dun\u00b7kel", "ist", "das", "Fel\u00b7sen\u00b7thal"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJD", "VAFIN", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Und der Steg ist schwank und schmal;", "tokens": ["Und", "der", "Steg", "ist", "schwank", "und", "schmal", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VAFIN", "ADJD", "KON", "ADJD", "$."], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.3": {"text": "Doch du leuchtest mir so gern,", "tokens": ["Doch", "du", "leuch\u00b7test", "mir", "so", "gern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPER", "ADV", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Himmelsfunken, Augenstern.", "tokens": ["Him\u00b7mels\u00b7fun\u00b7ken", ",", "Au\u00b7gens\u00b7tern", "."], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$."], "meter": "+-+-+--", "measure": "unknown.measure.tri"}}, "stanza.9": {"line.1": {"text": "Athem, Rede, Druck und Ku\u00df,", "tokens": ["A\u00b7them", ",", "Re\u00b7de", ",", "Druck", "und", "Ku\u00df", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Aller Wonnen Ueberflu\u00df,", "tokens": ["Al\u00b7ler", "Won\u00b7nen", "Ue\u00b7berf\u00b7lu\u00df", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Engelseele, G\u00f6tterleib,", "tokens": ["En\u00b7gel\u00b7see\u00b7le", ",", "G\u00f6t\u00b7ter\u00b7leib", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NE", "$,", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Mein das allersch\u00f6nste Weib.", "tokens": ["Mein", "das", "al\u00b7ler\u00b7sch\u00f6ns\u00b7te", "Weib", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Alles, alles das war mein;", "tokens": ["Al\u00b7les", ",", "al\u00b7les", "das", "war", "mein", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "$,", "PIS", "PDS", "VAFIN", "PPOSAT", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Mu\u00df nun so verlassen sein!", "tokens": ["Mu\u00df", "nun", "so", "ver\u00b7las\u00b7sen", "sein", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "ADV", "VVPP", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "S\u00e4nk' ich blutend in der Schlacht,", "tokens": ["S\u00e4nk'", "ich", "blu\u00b7tend", "in", "der", "Schlacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Niemand h\u00e4tte meiner Acht!", "tokens": ["Nie\u00b7mand", "h\u00e4t\u00b7te", "mei\u00b7ner", "Acht", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "PPOSAT", "CARD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Wanke nicht mein guter Muth,", "tokens": ["Wan\u00b7ke", "nicht", "mein", "gu\u00b7ter", "Muth", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Lust am Leben, leichtes Blut,", "tokens": ["Lust", "am", "Le\u00b7ben", ",", "leich\u00b7tes", "Blut", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "APPRART", "NN", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df der Schmerz mich nicht verzehrt,", "tokens": ["Da\u00df", "der", "Schmerz", "mich", "nicht", "ver\u00b7zehrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "PPER", "PTKNEG", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Eh' mein Himmel wiederkehrt.", "tokens": ["Eh'", "mein", "Him\u00b7mel", "wie\u00b7der\u00b7kehrt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Ach, ich bin so bla\u00df und krank,", "tokens": ["Ach", ",", "ich", "bin", "so", "bla\u00df", "und", "krank", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "PPER", "VAFIN", "ADV", "ADJD", "KON", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "W\u00fc\u00dfte wol dem Arzte Dank!", "tokens": ["W\u00fc\u00df\u00b7te", "wol", "dem", "Arz\u00b7te", "Dank", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Honiglippe, Rosenmund,", "tokens": ["Ho\u00b7ni\u00b7glip\u00b7pe", ",", "Ro\u00b7sen\u00b7mund", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Sprich, wann machst du mich gesund?", "tokens": ["Sprich", ",", "wann", "machst", "du", "mich", "ge\u00b7sund", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "$,", "PWAV", "VVFIN", "PPER", "PRF", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}