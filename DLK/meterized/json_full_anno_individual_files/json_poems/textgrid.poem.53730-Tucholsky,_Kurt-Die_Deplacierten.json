{"textgrid.poem.53730": {"metadata": {"author": {"name": "Tucholsky, Kurt", "birth": "N.A.", "death": "N.A."}, "title": "Die Deplacierten", "genre": "verse", "period": "N.A.", "pub_year": 1912, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Uns haben sie, glaub ich, falsch geboren.", "tokens": ["Uns", "ha\u00b7ben", "sie", ",", "glaub", "ich", ",", "falsch", "ge\u00b7bo\u00b7ren", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "$,", "VVFIN", "PPER", "$,", "ADJD", "VVPP", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Von wegen Ort und wegen Zeit", "tokens": ["Von", "we\u00b7gen", "Ort", "und", "we\u00b7gen", "Zeit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "APPR", "NN", "KON", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "sind wir vertattert und verloren", "tokens": ["sind", "wir", "ver\u00b7tat\u00b7tert", "und", "ver\u00b7lo\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "VVPP", "KON", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "und fluchen unsrer Einsamkeit.", "tokens": ["und", "flu\u00b7chen", "uns\u00b7rer", "Ein\u00b7sam\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Warum, Mama, grad an der Panke?", "tokens": ["Wa\u00b7rum", ",", "Ma\u00b7ma", ",", "grad", "an", "der", "Pan\u00b7ke", "?"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$,", "NN", "$,", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Warum nicht f\u00fcnfzig Jahr zur\u00fcck?", "tokens": ["Wa\u00b7rum", "nicht", "f\u00fcnf\u00b7zig", "Jahr", "zu\u00b7r\u00fcck", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PTKNEG", "CARD", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wie schlecht placiert wuchs der Gedanke", "tokens": ["Wie", "schlecht", "pla\u00b7ciert", "wuchs", "der", "Ge\u00b7dan\u00b7ke"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADJD", "VVFIN", "VVFIN", "ART", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "zu euerm jungen Liebesgl\u00fcck!", "tokens": ["zu", "eu\u00b7erm", "jun\u00b7gen", "Lie\u00b7bes\u00b7gl\u00fcck", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Warum nicht lieber auf den Sunda\u2013", "tokens": ["Wa\u00b7rum", "nicht", "lie\u00b7ber", "auf", "den", "Sun\u00b7da", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PTKNEG", "ADV", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Eil\u00e4ndchen 1810?", "tokens": ["Ei\u00b7l\u00e4nd\u00b7chen", "1810", "?"], "token_info": ["word", "number", "punct"], "pos": ["NN", "CARD", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.3": {"text": "Doch hier und heut? Das ist kein Wunder \u2013", "tokens": ["Doch", "hier", "und", "heut", "?", "Das", "ist", "kein", "Wun\u00b7der", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "KON", "ADV", "$.", "PDS", "VAFIN", "PIAT", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "das kann ja nicht in Ordnung gehn!", "tokens": ["das", "kann", "ja", "nicht", "in", "Ord\u00b7nung", "gehn", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "ADV", "PTKNEG", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Warum nicht in Australien hausend?", "tokens": ["Wa\u00b7rum", "nicht", "in", "Aust\u00b7ra\u00b7li\u00b7en", "hau\u00b7send", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PTKNEG", "APPR", "NN", "VVPP", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Warum nicht F\u00fcrst von Erzerum?", "tokens": ["Wa\u00b7rum", "nicht", "F\u00fcrst", "von", "Er\u00b7ze\u00b7rum", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PTKNEG", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Warum nicht erst im Jahr Zweitausend?", "tokens": ["Wa\u00b7rum", "nicht", "erst", "im", "Jahr", "Zweit\u00b7au\u00b7send", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PTKNEG", "ADV", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Weshalb? Wieso? Woher? Warum?", "tokens": ["We\u00b7shalb", "?", "Wie\u00b7so", "?", "Wo\u00b7her", "?", "Wa\u00b7rum", "?"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PWAV", "$.", "PWAV", "$.", "PWAV", "$.", "PWAV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Der Weltkrieg. Lebensgro\u00dfe Zeiten.", "tokens": ["Der", "Welt\u00b7krieg", ".", "Le\u00b7bens\u00b7gro\u00b7\u00dfe", "Zei\u00b7ten", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$.", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Der Bankkommis als Offizier.", "tokens": ["Der", "Bank\u00b7kom\u00b7mis", "als", "Of\u00b7fi\u00b7zier", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "KOUS", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Brotkarten. Morde. Grenzen. Pleiten.", "tokens": ["Brot\u00b7kar\u00b7ten", ".", "Mor\u00b7de", ".", "Gren\u00b7zen", ".", "Plei\u00b7ten", "."], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$.", "NN", "$.", "NN", "$.", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und alles ausgerechnet wir.", "tokens": ["Und", "al\u00b7les", "aus\u00b7ge\u00b7rech\u00b7net", "wir", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Schraub hoch dein Karma wie die Inder.", "tokens": ["Schraub", "hoch", "dein", "Kar\u00b7ma", "wie", "die", "In\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "PPOSAT", "NN", "KOKOM", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Bleibt auch f\u00fcr uns nur noch Verzicht:", "tokens": ["Bleibt", "auch", "f\u00fcr", "uns", "nur", "noch", "Ver\u00b7zicht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "PPER", "ADV", "ADV", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wenn meine und sie kriegt mal Kinder \u2013", "tokens": ["Wenn", "mei\u00b7ne", "und", "sie", "kriegt", "mal", "Kin\u00b7der", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "KON", "PPER", "VVFIN", "ADV", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "in Deutschland darf sie nicht.", "tokens": ["in", "Deutschland", "darf", "sie", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VMFIN", "PPER", "PTKNEG", "$."], "meter": "+---+", "measure": "dactylic.init"}}, "stanza.7": {"line.1": {"text": "Uns haben sie, glaub ich, falsch geboren.", "tokens": ["Uns", "ha\u00b7ben", "sie", ",", "glaub", "ich", ",", "falsch", "ge\u00b7bo\u00b7ren", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "$,", "VVFIN", "PPER", "$,", "ADJD", "VVPP", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Von wegen Ort und wegen Zeit", "tokens": ["Von", "we\u00b7gen", "Ort", "und", "we\u00b7gen", "Zeit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "APPR", "NN", "KON", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "sind wir vertattert und verloren", "tokens": ["sind", "wir", "ver\u00b7tat\u00b7tert", "und", "ver\u00b7lo\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "VVPP", "KON", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "und fluchen unsrer Einsamkeit.", "tokens": ["und", "flu\u00b7chen", "uns\u00b7rer", "Ein\u00b7sam\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Warum, Mama, grad an der Panke?", "tokens": ["Wa\u00b7rum", ",", "Ma\u00b7ma", ",", "grad", "an", "der", "Pan\u00b7ke", "?"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$,", "NN", "$,", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Warum nicht f\u00fcnfzig Jahr zur\u00fcck?", "tokens": ["Wa\u00b7rum", "nicht", "f\u00fcnf\u00b7zig", "Jahr", "zu\u00b7r\u00fcck", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PTKNEG", "CARD", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wie schlecht placiert wuchs der Gedanke", "tokens": ["Wie", "schlecht", "pla\u00b7ciert", "wuchs", "der", "Ge\u00b7dan\u00b7ke"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADJD", "VVFIN", "VVFIN", "ART", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "zu euerm jungen Liebesgl\u00fcck!", "tokens": ["zu", "eu\u00b7erm", "jun\u00b7gen", "Lie\u00b7bes\u00b7gl\u00fcck", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Warum nicht lieber auf den Sunda\u2013", "tokens": ["Wa\u00b7rum", "nicht", "lie\u00b7ber", "auf", "den", "Sun\u00b7da", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PTKNEG", "ADV", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Eil\u00e4ndchen 1810?", "tokens": ["Ei\u00b7l\u00e4nd\u00b7chen", "1810", "?"], "token_info": ["word", "number", "punct"], "pos": ["NN", "CARD", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.3": {"text": "Doch hier und heut? Das ist kein Wunder \u2013", "tokens": ["Doch", "hier", "und", "heut", "?", "Das", "ist", "kein", "Wun\u00b7der", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "KON", "ADV", "$.", "PDS", "VAFIN", "PIAT", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "das kann ja nicht in Ordnung gehn!", "tokens": ["das", "kann", "ja", "nicht", "in", "Ord\u00b7nung", "gehn", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "ADV", "PTKNEG", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Warum nicht in Australien hausend?", "tokens": ["Wa\u00b7rum", "nicht", "in", "Aust\u00b7ra\u00b7li\u00b7en", "hau\u00b7send", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PTKNEG", "APPR", "NN", "VVPP", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Warum nicht F\u00fcrst von Erzerum?", "tokens": ["Wa\u00b7rum", "nicht", "F\u00fcrst", "von", "Er\u00b7ze\u00b7rum", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PTKNEG", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Warum nicht erst im Jahr Zweitausend?", "tokens": ["Wa\u00b7rum", "nicht", "erst", "im", "Jahr", "Zweit\u00b7au\u00b7send", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PTKNEG", "ADV", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Weshalb? Wieso? Woher? Warum?", "tokens": ["We\u00b7shalb", "?", "Wie\u00b7so", "?", "Wo\u00b7her", "?", "Wa\u00b7rum", "?"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PWAV", "$.", "PWAV", "$.", "PWAV", "$.", "PWAV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Der Weltkrieg. Lebensgro\u00dfe Zeiten.", "tokens": ["Der", "Welt\u00b7krieg", ".", "Le\u00b7bens\u00b7gro\u00b7\u00dfe", "Zei\u00b7ten", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$.", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Der Bankkommis als Offizier.", "tokens": ["Der", "Bank\u00b7kom\u00b7mis", "als", "Of\u00b7fi\u00b7zier", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "KOUS", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Brotkarten. Morde. Grenzen. Pleiten.", "tokens": ["Brot\u00b7kar\u00b7ten", ".", "Mor\u00b7de", ".", "Gren\u00b7zen", ".", "Plei\u00b7ten", "."], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$.", "NN", "$.", "NN", "$.", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und alles ausgerechnet wir.", "tokens": ["Und", "al\u00b7les", "aus\u00b7ge\u00b7rech\u00b7net", "wir", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Schraub hoch dein Karma wie die Inder.", "tokens": ["Schraub", "hoch", "dein", "Kar\u00b7ma", "wie", "die", "In\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "PPOSAT", "NN", "KOKOM", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Bleibt auch f\u00fcr uns nur noch Verzicht:", "tokens": ["Bleibt", "auch", "f\u00fcr", "uns", "nur", "noch", "Ver\u00b7zicht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "PPER", "ADV", "ADV", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wenn meine und sie kriegt mal Kinder \u2013", "tokens": ["Wenn", "mei\u00b7ne", "und", "sie", "kriegt", "mal", "Kin\u00b7der", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "KON", "PPER", "VVFIN", "ADV", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "in Deutschland darf sie nicht.", "tokens": ["in", "Deutschland", "darf", "sie", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VMFIN", "PPER", "PTKNEG", "$."], "meter": "+---+", "measure": "dactylic.init"}}}}}