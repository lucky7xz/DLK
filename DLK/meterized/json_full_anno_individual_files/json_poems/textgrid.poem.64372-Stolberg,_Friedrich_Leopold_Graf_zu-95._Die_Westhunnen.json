{"textgrid.poem.64372": {"metadata": {"author": {"name": "Stolberg, Friedrich Leopold Graf zu", "birth": "N.A.", "death": "N.A."}, "title": "95. Die Westhunnen", "genre": "verse", "period": "N.A.", "pub_year": 1793, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Bei meiner Mutter Asche, das duld' ich nicht!", "tokens": ["Bei", "mei\u00b7ner", "Mut\u00b7ter", "A\u00b7sche", ",", "das", "duld'", "ich", "nicht", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NN", "$,", "PDS", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Ihr sollt nicht Franken nennen der V\u00f6lker und", "tokens": ["Ihr", "sollt", "nicht", "Fran\u00b7ken", "nen\u00b7nen", "der", "V\u00f6l\u00b7ker", "und"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PTKNEG", "NN", "VVFIN", "ART", "NN", "KON"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Der Zeiten Abschaum! nennt Westhunnen,", "tokens": ["Der", "Zei\u00b7ten", "Ab\u00b7schaum", "!", "nennt", "West\u00b7hun\u00b7nen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$.", "VVFIN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Dann noch besch\u00f6nigend, ihre Horden,", "tokens": ["Dann", "noch", "be\u00b7sch\u00f6\u00b7ni\u00b7gend", ",", "ih\u00b7re", "Hor\u00b7den", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVPP", "$,", "PPOSAT", "NN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.2": {"line.1": {"text": "Und ihre Millionen daheim; ich sp\u00e4h'", "tokens": ["Und", "ih\u00b7re", "Mil\u00b7lion\u00b7en", "da\u00b7heim", ";", "ich", "sp\u00e4h'"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "PTKVZ", "$.", "PPER", "VVFIN"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Umsonst nach Namen ihr Pand\u00e4monium", "tokens": ["Um\u00b7sonst", "nach", "Na\u00b7men", "ihr", "Pan\u00b7d\u00e4\u00b7mo\u00b7ni\u00b7um"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "NN", "PPOSAT", "NN"], "meter": "+--+--+-+-+", "measure": "dactylic.di.plus"}, "line.3": {"text": "Zu nennen, wo der Frevler Rotte", "tokens": ["Zu", "nen\u00b7nen", ",", "wo", "der", "Frev\u00b7ler", "Rot\u00b7te"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PTKZU", "VVINF", "$,", "PWAV", "ART", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Herrschet und kreucht, und vor Buben zittert,", "tokens": ["Herr\u00b7schet", "und", "kreucht", ",", "und", "vor", "Bu\u00b7ben", "zit\u00b7tert", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KON", "VVFIN", "$,", "KON", "APPR", "NN", "VVFIN", "$,"], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}}, "stanza.3": {"line.1": {"text": "Des Ew'gen h\u00f6hnend! Tief aus des Lasters und", "tokens": ["Des", "Ew'\u00b7gen", "h\u00f6h\u00b7nend", "!", "Tief", "aus", "des", "Las\u00b7ters", "und"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVPP", "$.", "ADJD", "APPR", "ART", "NN", "KON"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Der L\u00e4st'rung Hefen sch\u00f6pften die W\u00fctenden", "tokens": ["Der", "L\u00e4st'\u00b7rung", "He\u00b7fen", "sch\u00f6pf\u00b7ten", "die", "W\u00fc\u00b7ten\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "NN", "VVFIN", "ART", "NN"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Den langgemischten Trank, und reichten", "tokens": ["Den", "lang\u00b7ge\u00b7mischten", "Trank", ",", "und", "reich\u00b7ten"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "KON", "VVFIN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Taumel und Tollheit dem eitlen Volke,", "tokens": ["Tau\u00b7mel", "und", "Toll\u00b7heit", "dem", "eit\u00b7len", "Vol\u00b7ke", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "ART", "ADJA", "NN", "$,"], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}}, "stanza.4": {"line.1": {"text": "Das reif dem Fluche war! und Europa sah", "tokens": ["Das", "reif", "dem", "Flu\u00b7che", "war", "!", "und", "Eu\u00b7ro\u00b7pa", "sah"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PDS", "VVFIN", "ART", "NN", "VAFIN", "$.", "KON", "NE", "VVFIN"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.2": {"text": "Es saufen! und \u2013 o Schmach! \u2013 es gel\u00fcstete", "tokens": ["Es", "sau\u00b7fen", "!", "und", "\u2013", "o", "Schmach", "!", "\u2013", "es", "ge\u00b7l\u00fcs\u00b7te\u00b7te"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct", "punct", "word", "word"], "pos": ["PPER", "VVFIN", "$.", "KON", "$(", "FM", "NN", "$.", "$(", "PPER", "VVFIN"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Des Tranks auch Deutsche! Seine D\u00fcfte", "tokens": ["Des", "Tranks", "auch", "Deut\u00b7sche", "!", "Sei\u00b7ne", "D\u00fcf\u00b7te"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "ADV", "NN", "$.", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Dunsten umher wie des Sumpfes Pesthauch.", "tokens": ["Duns\u00b7ten", "um\u00b7her", "wie", "des", "Sump\u00b7fes", "Pest\u00b7hauch", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKVZ", "KOKOM", "ART", "NN", "NN", "$."], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}}, "stanza.5": {"line.1": {"text": "Wer dieses Duftes sog, es erscheinet flugs", "tokens": ["Wer", "die\u00b7ses", "Duf\u00b7tes", "sog", ",", "es", "er\u00b7schei\u00b7net", "flugs"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWS", "PDAT", "NN", "VVFIN", "$,", "PPER", "VVFIN", "ADV"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Das Schwarze wei\u00df ihm! Tugend, Erbarmen sind", "tokens": ["Das", "Schwar\u00b7ze", "wei\u00df", "ihm", "!", "Tu\u00b7gend", ",", "Er\u00b7bar\u00b7men", "sind"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PPER", "$.", "NN", "$,", "NN", "VAFIN"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Ihm Namen; Eide, Schaum der Woge;", "tokens": ["Ihm", "Na\u00b7men", ";", "Ei\u00b7de", ",", "Schaum", "der", "Wo\u00b7ge", ";"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "$.", "NN", "$,", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "L\u00e4sterung Witz, und nur Unsinn Weisheit.", "tokens": ["L\u00e4s\u00b7te\u00b7rung", "Witz", ",", "und", "nur", "Un\u00b7sinn", "Weis\u00b7heit", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "$,", "KON", "ADV", "NN", "NN", "$."], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}}, "stanza.6": {"line.1": {"text": "Des Ernstes Freunden, Freunden der Wahrheit und", "tokens": ["Des", "Erns\u00b7tes", "Freun\u00b7den", ",", "Freun\u00b7den", "der", "Wahr\u00b7heit", "und"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "NN", "ART", "NN", "KON"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Der wahren Freude, war seit Jahrhunderten", "tokens": ["Der", "wah\u00b7ren", "Freu\u00b7de", ",", "war", "seit", "Jahr\u00b7hun\u00b7der\u00b7ten"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "VAFIN", "APPR", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Das eitle Volk und seine Babel", "tokens": ["Das", "eit\u00b7le", "Volk", "und", "sei\u00b7ne", "Ba\u00b7bel"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "KON", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Warnender R\u00fcg' und des Mitleids Vorwurf.", "tokens": ["War\u00b7nen\u00b7der", "R\u00fcg'", "und", "des", "Mit\u00b7leids", "Vor\u00b7wurf", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "KON", "ART", "NN", "NN", "$."], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}}, "stanza.7": {"line.1": {"text": "Wie hat die zarte L\u00fcstlin sich schamlos nun", "tokens": ["Wie", "hat", "die", "zar\u00b7te", "L\u00fcst\u00b7lin", "sich", "scham\u00b7los", "nun"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "VAFIN", "ART", "ADJA", "NN", "PRF", "ADJD", "ADV"], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Hoch aufgesch\u00fcrzet! Triefet von Blut! auch noch", "tokens": ["Hoch", "auf\u00b7ge\u00b7sch\u00fcr\u00b7zet", "!", "Trie\u00b7fet", "von", "Blut", "!", "auch", "noch"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["ADJD", "VVPP", "$.", "VVFIN", "APPR", "NN", "$.", "ADV", "ADV"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Bewundert? Nicht allein der Unzucht,", "tokens": ["Be\u00b7wun\u00b7dert", "?", "Nicht", "al\u00b7lein", "der", "Un\u00b7zucht", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$.", "PTKNEG", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Feil auch dem Raube, des Mords Gespielin!", "tokens": ["Feil", "auch", "dem", "Rau\u00b7be", ",", "des", "Mords", "Ge\u00b7spie\u00b7lin", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ART", "NN", "$,", "ART", "NN", "NN", "$."], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}}, "stanza.8": {"line.1": {"text": "Mit trunknem Wahnsinn stimmt sie ein Liedchen an,", "tokens": ["Mit", "trunk\u00b7nem", "Wahn\u00b7sinn", "stimmt", "sie", "ein", "Lied\u00b7chen", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "PPER", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Und Millionen stimmen ins Liedchen ein,", "tokens": ["Und", "Mil\u00b7lion\u00b7en", "stim\u00b7men", "ins", "Lied\u00b7chen", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "APPRART", "NN", "PTKVZ", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Und wo es t\u00f6nt, da sucht vergebens", "tokens": ["Und", "wo", "es", "t\u00f6nt", ",", "da", "sucht", "ver\u00b7ge\u00b7bens"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "PWAV", "PPER", "VVFIN", "$,", "ADV", "VVFIN", "ADV"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Rettung die Unschuld mit wunder Sohle;", "tokens": ["Ret\u00b7tung", "die", "Un\u00b7schuld", "mit", "wun\u00b7der", "Soh\u00b7le", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "APPR", "ADJA", "NN", "$."], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}}, "stanza.9": {"line.1": {"text": "Denn Wut hat Fl\u00fcgel! War der Gesalbte nicht", "tokens": ["Denn", "Wut", "hat", "Fl\u00fc\u00b7gel", "!", "War", "der", "Ge\u00b7salb\u00b7te", "nicht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "NN", "VAFIN", "NN", "$.", "VAFIN", "ART", "NN", "PTKNEG"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Ihr fast entronnen? Dennoch ergriff auch ihn", "tokens": ["Ihr", "fast", "ent\u00b7ron\u00b7nen", "?", "Den\u00b7noch", "er\u00b7griff", "auch", "ihn"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "VVINF", "$.", "ADV", "VVFIN", "ADV", "PPER"], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Des Frevels Hand! sie, welche Gottes", "tokens": ["Des", "Fre\u00b7vels", "Hand", "!", "sie", ",", "wel\u00b7che", "Got\u00b7tes"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["ART", "NN", "NN", "$.", "PPER", "$,", "PWAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Priester am Fu\u00df des Altares w\u00fcrgte!", "tokens": ["Pries\u00b7ter", "am", "Fu\u00df", "des", "Al\u00b7ta\u00b7res", "w\u00fcrg\u00b7te", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPRART", "NN", "ART", "NN", "VVFIN", "$."], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}}, "stanza.10": {"line.1": {"text": "Dein h\u00e4tten Kannibalen, o Ludewig,", "tokens": ["Dein", "h\u00e4t\u00b7ten", "Kan\u00b7ni\u00b7ba\u00b7len", ",", "o", "Lu\u00b7de\u00b7wig", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,", "FM", "NE", "$,"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Geschonet! Dreimal huldigte Frankreich dir;", "tokens": ["Ge\u00b7scho\u00b7net", "!", "Drei\u00b7mal", "hul\u00b7dig\u00b7te", "Fran\u00b7kreich", "dir", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$.", "ADV", "VVFIN", "NE", "PPER", "$."], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Dreimal meineidig, l\u00f6scht es hei\u00dfen", "tokens": ["Drei\u00b7mal", "mei\u00b7nei\u00b7dig", ",", "l\u00f6scht", "es", "hei\u00b7\u00dfen"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "ADJD", "$,", "VVFIN", "PPER", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Durst nach dem Frevel im Blut der Unschuld.", "tokens": ["Durst", "nach", "dem", "Fre\u00b7vel", "im", "Blut", "der", "Un\u00b7schuld", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "APPRART", "NN", "ART", "NN", "$."], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}}, "stanza.11": {"line.1": {"text": "Nun freue deiner Freiheit, du Sklavin, dich!", "tokens": ["Nun", "freu\u00b7e", "dei\u00b7ner", "Frei\u00b7heit", ",", "du", "Skla\u00b7vin", ",", "dich", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "$,", "PPER", "NN", "$,", "PPER", "$."], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Wenn dich beim Schlangenhaare der Scherge fa\u00dft,", "tokens": ["Wenn", "dich", "beim", "Schlan\u00b7gen\u00b7haa\u00b7re", "der", "Scher\u00b7ge", "fa\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPRART", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Dann kniee vor der Freiheitsg\u00f6ttin,", "tokens": ["Dann", "kni\u00b7ee", "vor", "der", "Frei\u00b7heits\u00b7g\u00f6t\u00b7tin", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die dir in Marmor entgegenstarret.", "tokens": ["Die", "dir", "in", "Mar\u00b7mor", "ent\u00b7ge\u00b7gen\u00b7star\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.12": {"line.1": {"text": "Und wenn die blasse Wut der Verzweifelung", "tokens": ["Und", "wenn", "die", "blas\u00b7se", "Wut", "der", "Ver\u00b7zwei\u00b7fe\u00b7lung"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "ART", "ADJA", "NN", "ART", "NN"], "meter": "-+-+-+--+--", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Der ersten H\u00f6lle glimmende Asche dir", "tokens": ["Der", "ers\u00b7ten", "H\u00f6l\u00b7le", "glim\u00b7men\u00b7de", "A\u00b7sche", "dir"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "ADJA", "NN", "PPER"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Im Herzen aufhaucht, wenn des Lebens", "tokens": ["Im", "Her\u00b7zen", "auf\u00b7haucht", ",", "wenn", "des", "Le\u00b7bens"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPRART", "NN", "VVPP", "$,", "KOUS", "ART", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Elend auf ewigen Jammer deutet;", "tokens": ["E\u00b7lend", "auf", "e\u00b7wi\u00b7gen", "Jam\u00b7mer", "deu\u00b7tet", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}}, "stanza.13": {"line.1": {"text": "Geh zum entweihten Tempel, und st\u00fcrze dann", "tokens": ["Geh", "zum", "ent\u00b7weih\u00b7ten", "Tem\u00b7pel", ",", "und", "st\u00fcr\u00b7ze", "dann"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NE", "APPRART", "ADJA", "NN", "$,", "KON", "VVFIN", "ADV"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "In blut'gen Staub \u2013 du nanntest Vernunft sie \u2013 st\u00fcrz'", "tokens": ["In", "blut'\u00b7gen", "Staub", "\u2013", "du", "nann\u00b7test", "Ver\u00b7nunft", "sie", "\u2013", "st\u00fcrz'"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word"], "pos": ["APPR", "ADJA", "NN", "$(", "PPER", "VVFIN", "NN", "PPER", "$(", "VVFIN"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "In Staub dich vor der nackten Hure,", "tokens": ["In", "Staub", "dich", "vor", "der", "nack\u00b7ten", "Hu\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PRF", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Da\u00df sie dir nun und im Tode helfe! \u2013", "tokens": ["Da\u00df", "sie", "dir", "nun", "und", "im", "To\u00b7de", "hel\u00b7fe", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PPER", "PPER", "ADV", "KON", "APPRART", "NN", "VVFIN", "$.", "$("], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.14": {"line.1": {"text": "O Frankreich, ich bin Vater! doch fluch' ich nicht,", "tokens": ["O", "Fran\u00b7kreich", ",", "ich", "bin", "Va\u00b7ter", "!", "doch", "fluch'", "ich", "nicht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "PPER", "VAFIN", "NN", "$.", "ADV", "VVFIN", "PPER", "PTKNEG", "$,"], "meter": "+-+--+--+-+", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Wiewohl du br\u00fctest \u00fcber der Zukunft Pest;", "tokens": ["Wie\u00b7wohl", "du", "br\u00fc\u00b7test", "\u00fc\u00b7ber", "der", "Zu\u00b7kunft", "Pest", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "APPR", "ART", "NN", "NN", "$."], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Mein Herr und Gott, Er, den du l\u00e4sterst,", "tokens": ["Mein", "Herr", "und", "Gott", ",", "Er", ",", "den", "du", "l\u00e4s\u00b7terst", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "NN", "$,", "PPER", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "-+-++-+-+", "measure": "unknown.measure.penta"}, "line.4": {"text": "Lehrete segnen mich, nicht mich fluchen.", "tokens": ["Leh\u00b7re\u00b7te", "seg\u00b7nen", "mich", ",", "nicht", "mich", "flu\u00b7chen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "$,", "PTKNEG", "PPER", "VVINF", "$."], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}}, "stanza.15": {"line.1": {"text": "La\u00df siebenf\u00e4lt'gen Jammer dich b\u00e4ndigen,", "tokens": ["La\u00df", "sie\u00b7ben\u00b7f\u00e4lt'\u00b7gen", "Jam\u00b7mer", "dich", "b\u00e4n\u00b7di\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ADJA", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-++--", "measure": "unknown.measure.penta"}, "line.2": {"text": "Und h\u00fcll' in Sack und Asche dich! ob vielleicht \u2013", "tokens": ["Und", "h\u00fcll'", "in", "Sack", "und", "A\u00b7sche", "dich", "!", "ob", "viel\u00b7leicht", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ADJD", "APPR", "NN", "KON", "NN", "PPER", "$.", "KOUS", "ADV", "$("], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Die Rosse brausen schon und stampfen \u2013", "tokens": ["Die", "Ros\u00b7se", "brau\u00b7sen", "schon", "und", "stamp\u00b7fen", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "KON", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "R\u00fcckw\u00e4rts sich wende der Rache Wagen!", "tokens": ["R\u00fcck\u00b7w\u00e4rts", "sich", "wen\u00b7de", "der", "Ra\u00b7che", "Wa\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PRF", "VVFIN", "ART", "NN", "NN", "$."], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}}, "stanza.16": {"line.1": {"text": "Bei meiner Mutter Asche, das duld' ich nicht!", "tokens": ["Bei", "mei\u00b7ner", "Mut\u00b7ter", "A\u00b7sche", ",", "das", "duld'", "ich", "nicht", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NN", "$,", "PDS", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Ihr sollt nicht Franken nennen der V\u00f6lker und", "tokens": ["Ihr", "sollt", "nicht", "Fran\u00b7ken", "nen\u00b7nen", "der", "V\u00f6l\u00b7ker", "und"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PTKNEG", "NN", "VVFIN", "ART", "NN", "KON"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Der Zeiten Abschaum! nennt Westhunnen,", "tokens": ["Der", "Zei\u00b7ten", "Ab\u00b7schaum", "!", "nennt", "West\u00b7hun\u00b7nen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$.", "VVFIN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Dann noch besch\u00f6nigend, ihre Horden,", "tokens": ["Dann", "noch", "be\u00b7sch\u00f6\u00b7ni\u00b7gend", ",", "ih\u00b7re", "Hor\u00b7den", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVPP", "$,", "PPOSAT", "NN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.17": {"line.1": {"text": "Und ihre Millionen daheim; ich sp\u00e4h'", "tokens": ["Und", "ih\u00b7re", "Mil\u00b7lion\u00b7en", "da\u00b7heim", ";", "ich", "sp\u00e4h'"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "PTKVZ", "$.", "PPER", "VVFIN"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Umsonst nach Namen ihr Pand\u00e4monium", "tokens": ["Um\u00b7sonst", "nach", "Na\u00b7men", "ihr", "Pan\u00b7d\u00e4\u00b7mo\u00b7ni\u00b7um"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "NN", "PPOSAT", "NN"], "meter": "+--+--+-+-+", "measure": "dactylic.di.plus"}, "line.3": {"text": "Zu nennen, wo der Frevler Rotte", "tokens": ["Zu", "nen\u00b7nen", ",", "wo", "der", "Frev\u00b7ler", "Rot\u00b7te"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PTKZU", "VVINF", "$,", "PWAV", "ART", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Herrschet und kreucht, und vor Buben zittert,", "tokens": ["Herr\u00b7schet", "und", "kreucht", ",", "und", "vor", "Bu\u00b7ben", "zit\u00b7tert", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KON", "VVFIN", "$,", "KON", "APPR", "NN", "VVFIN", "$,"], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}}, "stanza.18": {"line.1": {"text": "Des Ew'gen h\u00f6hnend! Tief aus des Lasters und", "tokens": ["Des", "Ew'\u00b7gen", "h\u00f6h\u00b7nend", "!", "Tief", "aus", "des", "Las\u00b7ters", "und"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVPP", "$.", "ADJD", "APPR", "ART", "NN", "KON"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Der L\u00e4st'rung Hefen sch\u00f6pften die W\u00fctenden", "tokens": ["Der", "L\u00e4st'\u00b7rung", "He\u00b7fen", "sch\u00f6pf\u00b7ten", "die", "W\u00fc\u00b7ten\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "NN", "VVFIN", "ART", "NN"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Den langgemischten Trank, und reichten", "tokens": ["Den", "lang\u00b7ge\u00b7mischten", "Trank", ",", "und", "reich\u00b7ten"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "KON", "VVFIN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Taumel und Tollheit dem eitlen Volke,", "tokens": ["Tau\u00b7mel", "und", "Toll\u00b7heit", "dem", "eit\u00b7len", "Vol\u00b7ke", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "ART", "ADJA", "NN", "$,"], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}}, "stanza.19": {"line.1": {"text": "Das reif dem Fluche war! und Europa sah", "tokens": ["Das", "reif", "dem", "Flu\u00b7che", "war", "!", "und", "Eu\u00b7ro\u00b7pa", "sah"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PDS", "VVFIN", "ART", "NN", "VAFIN", "$.", "KON", "NE", "VVFIN"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.2": {"text": "Es saufen! und \u2013 o Schmach! \u2013 es gel\u00fcstete", "tokens": ["Es", "sau\u00b7fen", "!", "und", "\u2013", "o", "Schmach", "!", "\u2013", "es", "ge\u00b7l\u00fcs\u00b7te\u00b7te"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct", "punct", "word", "word"], "pos": ["PPER", "VVFIN", "$.", "KON", "$(", "FM", "NN", "$.", "$(", "PPER", "VVFIN"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Des Tranks auch Deutsche! Seine D\u00fcfte", "tokens": ["Des", "Tranks", "auch", "Deut\u00b7sche", "!", "Sei\u00b7ne", "D\u00fcf\u00b7te"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "ADV", "NN", "$.", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Dunsten umher wie des Sumpfes Pesthauch.", "tokens": ["Duns\u00b7ten", "um\u00b7her", "wie", "des", "Sump\u00b7fes", "Pest\u00b7hauch", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKVZ", "KOKOM", "ART", "NN", "NN", "$."], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}}, "stanza.20": {"line.1": {"text": "Wer dieses Duftes sog, es erscheinet flugs", "tokens": ["Wer", "die\u00b7ses", "Duf\u00b7tes", "sog", ",", "es", "er\u00b7schei\u00b7net", "flugs"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWS", "PDAT", "NN", "VVFIN", "$,", "PPER", "VVFIN", "ADV"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Das Schwarze wei\u00df ihm! Tugend, Erbarmen sind", "tokens": ["Das", "Schwar\u00b7ze", "wei\u00df", "ihm", "!", "Tu\u00b7gend", ",", "Er\u00b7bar\u00b7men", "sind"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PPER", "$.", "NN", "$,", "NN", "VAFIN"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Ihm Namen; Eide, Schaum der Woge;", "tokens": ["Ihm", "Na\u00b7men", ";", "Ei\u00b7de", ",", "Schaum", "der", "Wo\u00b7ge", ";"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "$.", "NN", "$,", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "L\u00e4sterung Witz, und nur Unsinn Weisheit.", "tokens": ["L\u00e4s\u00b7te\u00b7rung", "Witz", ",", "und", "nur", "Un\u00b7sinn", "Weis\u00b7heit", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "$,", "KON", "ADV", "NN", "NN", "$."], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}}, "stanza.21": {"line.1": {"text": "Des Ernstes Freunden, Freunden der Wahrheit und", "tokens": ["Des", "Erns\u00b7tes", "Freun\u00b7den", ",", "Freun\u00b7den", "der", "Wahr\u00b7heit", "und"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "NN", "ART", "NN", "KON"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Der wahren Freude, war seit Jahrhunderten", "tokens": ["Der", "wah\u00b7ren", "Freu\u00b7de", ",", "war", "seit", "Jahr\u00b7hun\u00b7der\u00b7ten"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "VAFIN", "APPR", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Das eitle Volk und seine Babel", "tokens": ["Das", "eit\u00b7le", "Volk", "und", "sei\u00b7ne", "Ba\u00b7bel"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "KON", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Warnender R\u00fcg' und des Mitleids Vorwurf.", "tokens": ["War\u00b7nen\u00b7der", "R\u00fcg'", "und", "des", "Mit\u00b7leids", "Vor\u00b7wurf", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "KON", "ART", "NN", "NN", "$."], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}}, "stanza.22": {"line.1": {"text": "Wie hat die zarte L\u00fcstlin sich schamlos nun", "tokens": ["Wie", "hat", "die", "zar\u00b7te", "L\u00fcst\u00b7lin", "sich", "scham\u00b7los", "nun"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "VAFIN", "ART", "ADJA", "NN", "PRF", "ADJD", "ADV"], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Hoch aufgesch\u00fcrzet! Triefet von Blut! auch noch", "tokens": ["Hoch", "auf\u00b7ge\u00b7sch\u00fcr\u00b7zet", "!", "Trie\u00b7fet", "von", "Blut", "!", "auch", "noch"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["ADJD", "VVPP", "$.", "VVFIN", "APPR", "NN", "$.", "ADV", "ADV"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Bewundert? Nicht allein der Unzucht,", "tokens": ["Be\u00b7wun\u00b7dert", "?", "Nicht", "al\u00b7lein", "der", "Un\u00b7zucht", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$.", "PTKNEG", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Feil auch dem Raube, des Mords Gespielin!", "tokens": ["Feil", "auch", "dem", "Rau\u00b7be", ",", "des", "Mords", "Ge\u00b7spie\u00b7lin", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ART", "NN", "$,", "ART", "NN", "NN", "$."], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}}, "stanza.23": {"line.1": {"text": "Mit trunknem Wahnsinn stimmt sie ein Liedchen an,", "tokens": ["Mit", "trunk\u00b7nem", "Wahn\u00b7sinn", "stimmt", "sie", "ein", "Lied\u00b7chen", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "PPER", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Und Millionen stimmen ins Liedchen ein,", "tokens": ["Und", "Mil\u00b7lion\u00b7en", "stim\u00b7men", "ins", "Lied\u00b7chen", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "APPRART", "NN", "PTKVZ", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Und wo es t\u00f6nt, da sucht vergebens", "tokens": ["Und", "wo", "es", "t\u00f6nt", ",", "da", "sucht", "ver\u00b7ge\u00b7bens"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "PWAV", "PPER", "VVFIN", "$,", "ADV", "VVFIN", "ADV"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Rettung die Unschuld mit wunder Sohle;", "tokens": ["Ret\u00b7tung", "die", "Un\u00b7schuld", "mit", "wun\u00b7der", "Soh\u00b7le", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "APPR", "ADJA", "NN", "$."], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}}, "stanza.24": {"line.1": {"text": "Denn Wut hat Fl\u00fcgel! War der Gesalbte nicht", "tokens": ["Denn", "Wut", "hat", "Fl\u00fc\u00b7gel", "!", "War", "der", "Ge\u00b7salb\u00b7te", "nicht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "NN", "VAFIN", "NN", "$.", "VAFIN", "ART", "NN", "PTKNEG"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Ihr fast entronnen? Dennoch ergriff auch ihn", "tokens": ["Ihr", "fast", "ent\u00b7ron\u00b7nen", "?", "Den\u00b7noch", "er\u00b7griff", "auch", "ihn"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "VVINF", "$.", "ADV", "VVFIN", "ADV", "PPER"], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Des Frevels Hand! sie, welche Gottes", "tokens": ["Des", "Fre\u00b7vels", "Hand", "!", "sie", ",", "wel\u00b7che", "Got\u00b7tes"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["ART", "NN", "NN", "$.", "PPER", "$,", "PWAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Priester am Fu\u00df des Altares w\u00fcrgte!", "tokens": ["Pries\u00b7ter", "am", "Fu\u00df", "des", "Al\u00b7ta\u00b7res", "w\u00fcrg\u00b7te", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPRART", "NN", "ART", "NN", "VVFIN", "$."], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}}, "stanza.25": {"line.1": {"text": "Dein h\u00e4tten Kannibalen, o Ludewig,", "tokens": ["Dein", "h\u00e4t\u00b7ten", "Kan\u00b7ni\u00b7ba\u00b7len", ",", "o", "Lu\u00b7de\u00b7wig", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,", "FM", "NE", "$,"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Geschonet! Dreimal huldigte Frankreich dir;", "tokens": ["Ge\u00b7scho\u00b7net", "!", "Drei\u00b7mal", "hul\u00b7dig\u00b7te", "Fran\u00b7kreich", "dir", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$.", "ADV", "VVFIN", "NE", "PPER", "$."], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Dreimal meineidig, l\u00f6scht es hei\u00dfen", "tokens": ["Drei\u00b7mal", "mei\u00b7nei\u00b7dig", ",", "l\u00f6scht", "es", "hei\u00b7\u00dfen"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "ADJD", "$,", "VVFIN", "PPER", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Durst nach dem Frevel im Blut der Unschuld.", "tokens": ["Durst", "nach", "dem", "Fre\u00b7vel", "im", "Blut", "der", "Un\u00b7schuld", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "APPRART", "NN", "ART", "NN", "$."], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}}, "stanza.26": {"line.1": {"text": "Nun freue deiner Freiheit, du Sklavin, dich!", "tokens": ["Nun", "freu\u00b7e", "dei\u00b7ner", "Frei\u00b7heit", ",", "du", "Skla\u00b7vin", ",", "dich", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "$,", "PPER", "NN", "$,", "PPER", "$."], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Wenn dich beim Schlangenhaare der Scherge fa\u00dft,", "tokens": ["Wenn", "dich", "beim", "Schlan\u00b7gen\u00b7haa\u00b7re", "der", "Scher\u00b7ge", "fa\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPRART", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Dann kniee vor der Freiheitsg\u00f6ttin,", "tokens": ["Dann", "kni\u00b7ee", "vor", "der", "Frei\u00b7heits\u00b7g\u00f6t\u00b7tin", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die dir in Marmor entgegenstarret.", "tokens": ["Die", "dir", "in", "Mar\u00b7mor", "ent\u00b7ge\u00b7gen\u00b7star\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.27": {"line.1": {"text": "Und wenn die blasse Wut der Verzweifelung", "tokens": ["Und", "wenn", "die", "blas\u00b7se", "Wut", "der", "Ver\u00b7zwei\u00b7fe\u00b7lung"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "ART", "ADJA", "NN", "ART", "NN"], "meter": "-+-+-+--+--", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Der ersten H\u00f6lle glimmende Asche dir", "tokens": ["Der", "ers\u00b7ten", "H\u00f6l\u00b7le", "glim\u00b7men\u00b7de", "A\u00b7sche", "dir"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "ADJA", "NN", "PPER"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Im Herzen aufhaucht, wenn des Lebens", "tokens": ["Im", "Her\u00b7zen", "auf\u00b7haucht", ",", "wenn", "des", "Le\u00b7bens"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPRART", "NN", "VVPP", "$,", "KOUS", "ART", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Elend auf ewigen Jammer deutet;", "tokens": ["E\u00b7lend", "auf", "e\u00b7wi\u00b7gen", "Jam\u00b7mer", "deu\u00b7tet", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}}, "stanza.28": {"line.1": {"text": "Geh zum entweihten Tempel, und st\u00fcrze dann", "tokens": ["Geh", "zum", "ent\u00b7weih\u00b7ten", "Tem\u00b7pel", ",", "und", "st\u00fcr\u00b7ze", "dann"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NE", "APPRART", "ADJA", "NN", "$,", "KON", "VVFIN", "ADV"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "In blut'gen Staub \u2013 du nanntest Vernunft sie \u2013 st\u00fcrz'", "tokens": ["In", "blut'\u00b7gen", "Staub", "\u2013", "du", "nann\u00b7test", "Ver\u00b7nunft", "sie", "\u2013", "st\u00fcrz'"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word"], "pos": ["APPR", "ADJA", "NN", "$(", "PPER", "VVFIN", "NN", "PPER", "$(", "VVFIN"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "In Staub dich vor der nackten Hure,", "tokens": ["In", "Staub", "dich", "vor", "der", "nack\u00b7ten", "Hu\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PRF", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Da\u00df sie dir nun und im Tode helfe! \u2013", "tokens": ["Da\u00df", "sie", "dir", "nun", "und", "im", "To\u00b7de", "hel\u00b7fe", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PPER", "PPER", "ADV", "KON", "APPRART", "NN", "VVFIN", "$.", "$("], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.29": {"line.1": {"text": "O Frankreich, ich bin Vater! doch fluch' ich nicht,", "tokens": ["O", "Fran\u00b7kreich", ",", "ich", "bin", "Va\u00b7ter", "!", "doch", "fluch'", "ich", "nicht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "PPER", "VAFIN", "NN", "$.", "ADV", "VVFIN", "PPER", "PTKNEG", "$,"], "meter": "+-+--+--+-+", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Wiewohl du br\u00fctest \u00fcber der Zukunft Pest;", "tokens": ["Wie\u00b7wohl", "du", "br\u00fc\u00b7test", "\u00fc\u00b7ber", "der", "Zu\u00b7kunft", "Pest", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "APPR", "ART", "NN", "NN", "$."], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Mein Herr und Gott, Er, den du l\u00e4sterst,", "tokens": ["Mein", "Herr", "und", "Gott", ",", "Er", ",", "den", "du", "l\u00e4s\u00b7terst", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "NN", "$,", "PPER", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "-+-++-+-+", "measure": "unknown.measure.penta"}, "line.4": {"text": "Lehrete segnen mich, nicht mich fluchen.", "tokens": ["Leh\u00b7re\u00b7te", "seg\u00b7nen", "mich", ",", "nicht", "mich", "flu\u00b7chen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "$,", "PTKNEG", "PPER", "VVINF", "$."], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}}, "stanza.30": {"line.1": {"text": "La\u00df siebenf\u00e4lt'gen Jammer dich b\u00e4ndigen,", "tokens": ["La\u00df", "sie\u00b7ben\u00b7f\u00e4lt'\u00b7gen", "Jam\u00b7mer", "dich", "b\u00e4n\u00b7di\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ADJA", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-++--", "measure": "unknown.measure.penta"}, "line.2": {"text": "Und h\u00fcll' in Sack und Asche dich! ob vielleicht \u2013", "tokens": ["Und", "h\u00fcll'", "in", "Sack", "und", "A\u00b7sche", "dich", "!", "ob", "viel\u00b7leicht", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ADJD", "APPR", "NN", "KON", "NN", "PPER", "$.", "KOUS", "ADV", "$("], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Die Rosse brausen schon und stampfen \u2013", "tokens": ["Die", "Ros\u00b7se", "brau\u00b7sen", "schon", "und", "stamp\u00b7fen", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "KON", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "R\u00fcckw\u00e4rts sich wende der Rache Wagen!", "tokens": ["R\u00fcck\u00b7w\u00e4rts", "sich", "wen\u00b7de", "der", "Ra\u00b7che", "Wa\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PRF", "VVFIN", "ART", "NN", "NN", "$."], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}}}}}