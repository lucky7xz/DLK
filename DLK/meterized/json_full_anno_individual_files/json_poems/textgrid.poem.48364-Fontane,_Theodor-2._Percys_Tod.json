{"textgrid.poem.48364": {"metadata": {"author": {"name": "Fontane, Theodor", "birth": "N.A.", "death": "N.A."}, "title": "2. Percys Tod", "genre": "verse", "period": "N.A.", "pub_year": 1858, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "\u00bbmein Dach ist der Himmel seit manchem Tag,", "tokens": ["\u00bb", "mein", "Dach", "ist", "der", "Him\u00b7mel", "seit", "man\u00b7chem", "Tag", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPOSAT", "NN", "VAFIN", "ART", "NN", "APPR", "PIAT", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Mein Lager zur Nacht des Waldes Streu:", "tokens": ["Mein", "La\u00b7ger", "zur", "Nacht", "des", "Wal\u00b7des", "Streu", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPRART", "NN", "ART", "NN", "NE", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Zu William Douglas will ich gehn,", "tokens": ["Zu", "Wil\u00b7li\u00b7am", "Doug\u00b7las", "will", "ich", "gehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "NE", "VMFIN", "PPER", "VVINF", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Sein Schlo\u00df ist fest, sein Herz ist treu.", "tokens": ["Sein", "Schlo\u00df", "ist", "fest", ",", "sein", "Herz", "ist", "treu", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADJD", "$,", "PPOSAT", "NN", "VAFIN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Als einst er floh, wie jetzt ich flieh',", "tokens": ["Als", "einst", "er", "floh", ",", "wie", "jetzt", "ich", "flieh'", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PPER", "VVFIN", "$,", "PWAV", "ADV", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da fand er Schutz am Herde mein:", "tokens": ["Da", "fand", "er", "Schutz", "am", "Her\u00b7de", "mein", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "NN", "APPRART", "NN", "PPOSAT", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die Douglas waren immer treu,", "tokens": ["Die", "Doug\u00b7las", "wa\u00b7ren", "im\u00b7mer", "treu", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Auch William Douglas mu\u00df es sein.\u00ab", "tokens": ["Auch", "Wil\u00b7li\u00b7am", "Doug\u00b7las", "mu\u00df", "es", "sein", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "NE", "NE", "VMFIN", "PPER", "VAINF", "$.", "$("], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.3": {"line.1": {"text": "Graf Percy spricht's. Sein m\u00fcdes Ro\u00df,", "tokens": ["Graf", "Per\u00b7cy", "spricht'", "s.", "Sein", "m\u00fc\u00b7des", "Ro\u00df", ","], "token_info": ["word", "word", "word", "abbreviation", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VVFIN", "VVIMP", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Er treibt es an mit Sporn und Schlag;", "tokens": ["Er", "treibt", "es", "an", "mit", "Sporn", "und", "Schlag", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Er reitet gen Lochleven-Schlo\u00df", "tokens": ["Er", "rei\u00b7tet", "gen", "Loch\u00b7le\u00b7ven\u00b7Schlo\u00df"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "NN"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.4": {"text": "Und h\u00e4lt davor am dritten Tag.", "tokens": ["Und", "h\u00e4lt", "da\u00b7vor", "am", "drit\u00b7ten", "Tag", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PAV", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Die Br\u00fccke rasselt niederw\u00e4rts,", "tokens": ["Die", "Br\u00fc\u00b7cke", "ras\u00b7selt", "nie\u00b7der\u00b7w\u00e4rts", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Graf Percy tritt zur Hall' hinein;", "tokens": ["Graf", "Per\u00b7cy", "tritt", "zur", "Hall'", "hin\u00b7ein", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VVFIN", "APPRART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Graf Douglas spricht: \u00bbWillkomm, willkomm!\u00ab", "tokens": ["Graf", "Doug\u00b7las", "spricht", ":", "\u00bb", "Will\u00b7komm", ",", "will\u00b7komm", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct", "word", "punct", "word", "punct", "punct"], "pos": ["NE", "NE", "VVFIN", "$.", "$(", "NE", "$,", "ADJD", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und reicht ihm Hand und reicht ihm Wein.", "tokens": ["Und", "reicht", "ihm", "Hand", "und", "reicht", "ihm", "Wein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "NN", "KON", "VVFIN", "PPER", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Es geht der Tag, die Monde gehn;", "tokens": ["Es", "geht", "der", "Tag", ",", "die", "Mon\u00b7de", "gehn", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Am Fenster r\u00fcttelt Herbsteswind,", "tokens": ["Am", "Fens\u00b7ter", "r\u00fct\u00b7telt", "Herbs\u00b7tes\u00b7wind", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Des Percy Herz wird bang und schwer,", "tokens": ["Des", "Per\u00b7cy", "Herz", "wird", "bang", "und", "schwer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VAFIN", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Er denkt an Weib und denkt an Kind.", "tokens": ["Er", "denkt", "an", "Weib", "und", "denkt", "an", "Kind", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "KON", "VVFIN", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Graf Douglas sitzt zu Seiten ihm", "tokens": ["Graf", "Doug\u00b7las", "sitzt", "zu", "Sei\u00b7ten", "ihm"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "NE", "VVFIN", "APPR", "NN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und ruft ihm zu: \u00bbWas tr\u00fcbt dich so?", "tokens": ["Und", "ruft", "ihm", "zu", ":", "\u00bb", "Was", "tr\u00fcbt", "dich", "so", "?"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PTKVZ", "$.", "$(", "PWS", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wir fahren morgen \u00fcber See,", "tokens": ["Wir", "fah\u00b7ren", "mor\u00b7gen", "\u00fc\u00b7ber", "See", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Lord Murray jagt bei Linlithgow.", "tokens": ["Lord", "Mur\u00b7ray", "jagt", "bei", "Lin\u00b7lith\u00b7gow", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "VVFIN", "APPR", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Und bist du krank, so heil' dein Herz", "tokens": ["Und", "bist", "du", "krank", ",", "so", "heil'", "dein", "Herz"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "PPER", "ADJD", "$,", "ADV", "ADJD", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Durch gr\u00fcnen Wald und raschen Ritt;", "tokens": ["Durch", "gr\u00fc\u00b7nen", "Wald", "und", "ra\u00b7schen", "Ritt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "KON", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Zudem, ich gab dem Lord mein Wort,", "tokens": ["Zu\u00b7dem", ",", "ich", "gab", "dem", "Lord", "mein", "Wort", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "$,", "PPER", "VVFIN", "ART", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Du w\u00e4rst dabei, du jagtest mit.\u00ab", "tokens": ["Du", "w\u00e4rst", "da\u00b7bei", ",", "du", "jag\u00b7test", "mit", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VAFIN", "PAV", "$,", "PPER", "VVFIN", "PTKVZ", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Der Douglas spricht's. Graf Percy drauf:", "tokens": ["Der", "Doug\u00b7las", "spricht'", "s.", "Graf", "Per\u00b7cy", "drauf", ":"], "token_info": ["word", "word", "word", "abbreviation", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "NE", "NE", "NE", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u00bbdu gabst dein Wort, \u2013 ich bin bereit!", "tokens": ["\u00bb", "du", "gabst", "dein", "Wort", ",", "\u2013", "ich", "bin", "be\u00b7reit", "!"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "PPOSAT", "NN", "$,", "$(", "PPER", "VAFIN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und ritt'st du bis zum heil'gen Grab,", "tokens": ["Und", "ritt'st", "du", "bis", "zum", "heil'\u00b7gen", "Grab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ich ritte mit an deiner Seit'.\u00ab", "tokens": ["Ich", "rit\u00b7te", "mit", "an", "dei\u00b7ner", "Seit'", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "APPR", "APPR", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Er spricht's und reicht ihm rasch die Hand;", "tokens": ["Er", "spricht's", "und", "reicht", "ihm", "rasch", "die", "Hand", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "PPER", "ADJD", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Rot wird des Douglas bleich Gesicht,", "tokens": ["Rot", "wird", "des", "Doug\u00b7las", "bleich", "Ge\u00b7sicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "ART", "NN", "ADJD", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Er senkt sein Aug' und geht hinaus.", "tokens": ["Er", "senkt", "sein", "Aug'", "und", "geht", "hin\u00b7aus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "KON", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Maria Douglas aber spricht:", "tokens": ["Ma\u00b7ria", "Doug\u00b7las", "a\u00b7ber", "spricht", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "ADV", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "\u00bbhab acht! mein Bruder spinnt Verrat;", "tokens": ["\u00bb", "hab", "acht", "!", "mein", "Bru\u00b7der", "spinnt", "Ver\u00b7rat", ";"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "VAFIN", "CARD", "$.", "PPOSAT", "NN", "VVFIN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Unstet seit lang' sein Auge rollt;", "tokens": ["Un\u00b7stet", "seit", "lang'", "sein", "Au\u00b7ge", "rollt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "NE", "PPOSAT", "NN", "VVFIN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Das macht, er hat verkauft die Treu',", "tokens": ["Das", "macht", ",", "er", "hat", "ver\u00b7kauft", "die", "Treu'", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "$,", "PPER", "VAFIN", "VVPP", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Verkauft um englisch S\u00fcndengold.", "tokens": ["Ver\u00b7kauft", "um", "eng\u00b7lisch", "S\u00fcn\u00b7den\u00b7gold", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ADJD", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Er f\u00fchrt dich nicht nach Linlithgow,", "tokens": ["Er", "f\u00fchrt", "dich", "nicht", "nach", "Lin\u00b7lith\u00b7gow", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKNEG", "APPR", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Er f\u00fchrt dich, wo Schlo\u00df Berwick ragt;", "tokens": ["Er", "f\u00fchrt", "dich", ",", "wo", "Schlo\u00df", "Ber\u00b7wick", "ragt", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$,", "PWAV", "NN", "NE", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Nach ", "tokens": ["Nach"], "token_info": ["word"], "pos": ["APPR"], "meter": "+", "measure": "single.up"}, "line.4": {"text": "Du bist es ", "tokens": ["Du", "bist", "es"], "token_info": ["word", "word", "word"], "pos": ["PPER", "VAFIN", "PPER"], "meter": "-+-", "measure": "amphibrach.single"}}, "stanza.12": {"line.1": {"text": "Bleib hier und sprich: \u203adu seiest krank!\u2039", "tokens": ["Bleib", "hier", "und", "sprich", ":", "\u203a", "du", "sei\u00b7est", "krank", "!", "\u2039"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct", "punct"], "pos": ["NN", "ADV", "KON", "ADJD", "$.", "$(", "PPER", "VAFIN", "ADJD", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So helf mit Gott ich dir hindurch", "tokens": ["So", "helf", "mit", "Gott", "ich", "dir", "hin\u00b7durch"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "APPR", "NN", "PPER", "PPER", "PAV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und f\u00fchr' dich, auf verborgnem Pfad,", "tokens": ["Und", "f\u00fchr'", "dich", ",", "auf", "ver\u00b7borg\u00b7nem", "Pfad", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Durch Wald und Nacht nach Edinburg.", "tokens": ["Durch", "Wald", "und", "Nacht", "nach", "E\u00b7din\u00b7burg", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "APPR", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Und bring' dich zu Lord Hamilton,", "tokens": ["Und", "bring'", "dich", "zu", "Lord", "Ha\u00b7mil\u00b7ton", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "APPR", "NN", "NE", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Das ist ein echter Schotten-Lord,", "tokens": ["Das", "ist", "ein", "ech\u00b7ter", "Schot\u00b7ten\u00b7\u00b7L\u00b7ord", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Der lie\u00df wohl lieber Land und Leib,", "tokens": ["Der", "lie\u00df", "wohl", "lie\u00b7ber", "Land", "und", "Leib", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "ADV", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Als da\u00df er lie\u00df von seinem Wort.\u00ab", "tokens": ["Als", "da\u00df", "er", "lie\u00df", "von", "sei\u00b7nem", "Wort", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "KOUS", "PPER", "VVFIN", "APPR", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Graf Percy h\u00f6rt's, sein Aug' wird feucht,", "tokens": ["Graf", "Per\u00b7cy", "h\u00f6rt's", ",", "sein", "Aug'", "wird", "feucht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VVFIN", "$,", "PPOSAT", "NN", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Er spricht: \u00bbSchwer trifft mich Gottes Hand,", "tokens": ["Er", "spricht", ":", "\u00bb", "Schwer", "trifft", "mich", "Got\u00b7tes", "Hand", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "$(", "ADJD", "VVFIN", "PPER", "NN", "NN", "$,"], "meter": "-+---+-+", "measure": "dactylic.init"}, "line.3": {"text": "So vielen Freunden bracht' ich Tod,", "tokens": ["So", "vie\u00b7len", "Freun\u00b7den", "bracht'", "ich", "Tod", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "VVFIN", "PPER", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Dem letzten bring' ich Schimpf und Schand'.", "tokens": ["Dem", "letz\u00b7ten", "bring'", "ich", "Schimpf", "und", "Schand'", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "PPER", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "Ich hab' gedacht: es sei vorbei,", "tokens": ["Ich", "hab'", "ge\u00b7dacht", ":", "es", "sei", "vor\u00b7bei", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVPP", "$.", "PPER", "VAFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und hab' gedacht: das Ma\u00df sei voll;", "tokens": ["Und", "hab'", "ge\u00b7dacht", ":", "das", "Ma\u00df", "sei", "voll", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "VVPP", "$.", "ART", "NN", "VAFIN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Weh mir, da\u00df Schlimmres nun als Tod", "tokens": ["Weh", "mir", ",", "da\u00df", "Schlimm\u00b7res", "nun", "als", "Tod"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "PPER", "$,", "KOUS", "NE", "ADV", "KOUS", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Auf Freundes Haupt ich laden soll.", "tokens": ["Auf", "Freun\u00b7des", "Haupt", "ich", "la\u00b7den", "soll", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "NN", "PPER", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "Die Treue bring' ich in Verdacht,", "tokens": ["Die", "Treu\u00b7e", "bring'", "ich", "in", "Ver\u00b7dacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sie sei nicht treu, sei falsches Spiel;", "tokens": ["Sie", "sei", "nicht", "treu", ",", "sei", "fal\u00b7sches", "Spiel", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKNEG", "ADJD", "$,", "VAFIN", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ich trage Fluch in jedes Haus \u2013", "tokens": ["Ich", "tra\u00b7ge", "Fluch", "in", "je\u00b7des", "Haus", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "APPR", "PIAT", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Es ist zuviel, es ist zuviel.", "tokens": ["Es", "ist", "zu\u00b7viel", ",", "es", "ist", "zu\u00b7viel", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIS", "$,", "PPER", "VAFIN", "PIS", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.17": {"line.1": {"text": "Und sprichst du auch: Hab acht, hab acht!", "tokens": ["Und", "sprichst", "du", "auch", ":", "Hab", "acht", ",", "hab", "acht", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "$.", "NN", "CARD", "$,", "VAFIN", "CARD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ich sprech' doch nur: Halt ein, halt ein!", "tokens": ["Ich", "sprech'", "doch", "nur", ":", "Halt", "ein", ",", "halt", "ein", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "$.", "VVIMP", "PTKVZ", "$,", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die Douglas waren immer treu,", "tokens": ["Die", "Doug\u00b7las", "wa\u00b7ren", "im\u00b7mer", "treu", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Auch William Douglas mu\u00df es sein.\u00ab", "tokens": ["Auch", "Wil\u00b7li\u00b7am", "Doug\u00b7las", "mu\u00df", "es", "sein", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "NE", "NE", "VMFIN", "PPER", "VAINF", "$.", "$("], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.18": {"line.1": {"text": "Graf Percy spricht's. Die Lady drauf:", "tokens": ["Graf", "Per\u00b7cy", "spricht'", "s.", "Die", "La\u00b7dy", "drauf", ":"], "token_info": ["word", "word", "word", "abbreviation", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VVFIN", "VVIMP", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u00bbund sch\u00e4tzest du mein Wort gering,", "tokens": ["\u00bb", "und", "sch\u00e4t\u00b7zest", "du", "mein", "Wort", "ge\u00b7ring", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KON", "VVFIN", "PPER", "PPOSAT", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Komm mit mir an den Leven-See,", "tokens": ["Komm", "mit", "mir", "an", "den", "Le\u00b7ven\u00b7See", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und schau hinein durch diesen Ring.", "tokens": ["Und", "schau", "hin\u00b7ein", "durch", "die\u00b7sen", "Ring", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "ADV", "APPR", "PDAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.19": {"line.1": {"text": "Den Ring mir meine Mutter gab,", "tokens": ["Den", "Ring", "mir", "mei\u00b7ne", "Mut\u00b7ter", "gab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPER", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die konnte Wind und Wald verstehn,", "tokens": ["Die", "konn\u00b7te", "Wind", "und", "Wald", "ver\u00b7stehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "NN", "KON", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und blickst du auf des Sees Grund,", "tokens": ["Und", "blickst", "du", "auf", "des", "Sees", "Grund", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-++", "measure": "unknown.measure.tetra"}, "line.4": {"text": "So wirst du deine Zukunft sehn.", "tokens": ["So", "wirst", "du", "dei\u00b7ne", "Zu\u00b7kunft", "sehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.20": {"line.1": {"text": "Komm mit, komm mit! und willst du nicht,", "tokens": ["Komm", "mit", ",", "komm", "mit", "!", "und", "willst", "du", "nicht", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "$,", "VVFIN", "PTKVZ", "$.", "KON", "VMFIN", "PPER", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und glaubst du nicht, Gefahr sei nah,", "tokens": ["Und", "glaubst", "du", "nicht", ",", "Ge\u00b7fahr", "sei", "nah", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PTKNEG", "$,", "NN", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So gib mir deinen Diener mit,", "tokens": ["So", "gib", "mir", "dei\u00b7nen", "Die\u00b7ner", "mit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVIMP", "PPER", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der mag dir sagen, was er sah.\u00ab", "tokens": ["Der", "mag", "dir", "sa\u00b7gen", ",", "was", "er", "sah", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["PDS", "VMFIN", "PPER", "VVINF", "$,", "PWS", "PPER", "VVFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.21": {"line.1": {"text": "James Swinnard mit der Lady ging,", "tokens": ["Ja\u00b7mes", "Swin\u00b7nard", "mit", "der", "La\u00b7dy", "ging", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Sie kamen an den Leven-See;", "tokens": ["Sie", "ka\u00b7men", "an", "den", "Le\u00b7ven\u00b7See", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "James Swinnard spricht: \u00bbDas sind von York", "tokens": ["Ja\u00b7mes", "Swin\u00b7nard", "spricht", ":", "\u00bb", "Das", "sind", "von", "Y\u00b7ork"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word"], "pos": ["NE", "NE", "VVFIN", "$.", "$(", "PDS", "VAFIN", "APPR", "NE"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "Die T\u00fcrme, die ich drunten seh'!", "tokens": ["Die", "T\u00fcr\u00b7me", ",", "die", "ich", "drun\u00b7ten", "seh'", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.22": {"line.1": {"text": "Doch, Lady, sprich, auf offnem Platz", "tokens": ["Doch", ",", "La\u00b7dy", ",", "sprich", ",", "auf", "off\u00b7nem", "Platz"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["KON", "$,", "NE", "$,", "ADJD", "$,", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Was soll von Brettern das Ger\u00fcst?\u00ab", "tokens": ["Was", "soll", "von", "Bret\u00b7tern", "das", "Ge\u00b7r\u00fcst", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWS", "VMFIN", "APPR", "NN", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "\u00bbdas ist der Altar, drauf dein Herr", "tokens": ["\u00bb", "das", "ist", "der", "Al\u00b7tar", ",", "drauf", "dein", "Herr"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["$(", "PDS", "VAFIN", "ART", "NN", "$,", "PAV", "PPOSAT", "NN"], "meter": "-+--++-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Zum letzten Mal den Heiland k\u00fc\u00dft.\u00ab", "tokens": ["Zum", "letz\u00b7ten", "Mal", "den", "Hei\u00b7land", "k\u00fc\u00dft", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPRART", "ADJA", "NN", "ART", "NN", "VVFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.23": {"line.1": {"text": "\u00bbund, Lady, sprich, wer steht dabei,", "tokens": ["\u00bb", "und", ",", "La\u00b7dy", ",", "sprich", ",", "wer", "steht", "da\u00b7bei", ","], "token_info": ["punct", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "KON", "$,", "NE", "$,", "ADJD", "$,", "PWS", "VVFIN", "PAV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Geh\u00fcllt in Mantel, schwarz und dicht?\u00ab", "tokens": ["Ge\u00b7h\u00fcllt", "in", "Man\u00b7tel", ",", "schwarz", "und", "dicht", "?", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "APPR", "NN", "$,", "ADJD", "KON", "ADJD", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "\u00bbdas ist von York der Lord-Wardein,", "tokens": ["\u00bb", "das", "ist", "von", "Y\u00b7ork", "der", "Lord\u00b7War\u00b7dein", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PDS", "VAFIN", "APPR", "NE", "ART", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Der deinem Herrn das St\u00e4bchen bricht.\u00ab", "tokens": ["Der", "dei\u00b7nem", "Herrn", "das", "St\u00e4b\u00b7chen", "bricht", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "PPOSAT", "NN", "ART", "NN", "VVFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.24": {"line.1": {"text": "\u00bbund, Lady, sprich, wer steht dabei,", "tokens": ["\u00bb", "und", ",", "La\u00b7dy", ",", "sprich", ",", "wer", "steht", "da\u00b7bei", ","], "token_info": ["punct", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "KON", "$,", "NE", "$,", "ADJD", "$,", "PWS", "VVFIN", "PAV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Geh\u00fcllt in Mantel, rot wie Blut?\u00ab", "tokens": ["Ge\u00b7h\u00fcllt", "in", "Man\u00b7tel", ",", "rot", "wie", "Blut", "?", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "APPR", "NN", "$,", "ADJD", "KOKOM", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "\u00bbdas ist von York der Meister Hans,", "tokens": ["\u00bb", "das", "ist", "von", "Y\u00b7ork", "der", "Meis\u00b7ter", "Hans", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PDS", "VAFIN", "APPR", "NE", "ART", "NN", "NE", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Der deinem Herrn das Letzte tut.\u00ab", "tokens": ["Der", "dei\u00b7nem", "Herrn", "das", "Letz\u00b7te", "tut", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "PPOSAT", "NN", "ART", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.25": {"line.1": {"text": "James Swinnard trat vor seinen Herrn,", "tokens": ["Ja\u00b7mes", "Swin\u00b7nard", "trat", "vor", "sei\u00b7nen", "Herrn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Er sah ihn an und weinte laut;", "tokens": ["Er", "sah", "ihn", "an", "und", "wein\u00b7te", "laut", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKVZ", "KON", "VVFIN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Er sprach: \u00bbBleib hier, mein teurer Lord,", "tokens": ["Er", "sprach", ":", "\u00bb", "Bleib", "hier", ",", "mein", "teu\u00b7rer", "Lord", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "$(", "NN", "ADV", "$,", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ich hab' nichts Gutes da geschaut.\u00ab", "tokens": ["Ich", "hab'", "nichts", "Gu\u00b7tes", "da", "ge\u00b7schaut", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VAFIN", "PIS", "NN", "ADV", "VVPP", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.26": {"line.1": {"text": "Er schwieg. Graf Percy aber schnell:", "tokens": ["Er", "schwieg", ".", "Graf", "Per\u00b7cy", "a\u00b7ber", "schnell", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "NE", "NE", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u00bbund kostet's Leben mir und Leib,", "tokens": ["\u00bb", "und", "kos\u00b7tet's", "Le\u00b7ben", "mir", "und", "Leib", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KON", "ADJA", "NN", "PPER", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ich bau' auf Mann und Manneswort", "tokens": ["Ich", "bau'", "auf", "Mann", "und", "Man\u00b7nes\u00b7wort"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und nicht auf Spuk und Zauberweib.", "tokens": ["Und", "nicht", "auf", "Spuk", "und", "Zau\u00b7ber\u00b7weib", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.27": {"line.1": {"text": "Und w\u00e4r's kein Spuk und w\u00fcrd' es wahr,", "tokens": ["Und", "w\u00e4r's", "kein", "Spuk", "und", "w\u00fcrd'", "es", "wahr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PIAT", "NN", "KON", "VAFIN", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ich spr\u00e4che doch: 's ist Trug und Schein,", "tokens": ["Ich", "spr\u00e4\u00b7che", "doch", ":", "'s", "ist", "Trug", "und", "Schein", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$.", "PPER", "VAFIN", "NN", "KON", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Die Douglas waren immer treu,", "tokens": ["Die", "Doug\u00b7las", "wa\u00b7ren", "im\u00b7mer", "treu", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Auch William Douglas mu\u00df es sein.\u00ab", "tokens": ["Auch", "Wil\u00b7li\u00b7am", "Doug\u00b7las", "mu\u00df", "es", "sein", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "NE", "NE", "VMFIN", "PPER", "VAINF", "$.", "$("], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.28": {"line.1": {"text": "Der Morgen kam, der Wind war gut,", "tokens": ["Der", "Mor\u00b7gen", "kam", ",", "der", "Wind", "war", "gut", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "ART", "NN", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Pfeife rief: an Bord, an Bord!", "tokens": ["Die", "Pfei\u00b7fe", "rief", ":", "an", "Bord", ",", "an", "Bord", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$.", "APPR", "NN", "$,", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Man stieg zu Schiff \u2013 James Swinnard auch,", "tokens": ["Man", "stieg", "zu", "Schiff", "\u2013", "Ja\u00b7mes", "Swin\u00b7nard", "auch", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "APPR", "NN", "$(", "NE", "NE", "ADV", "$,"], "meter": "-+-++-+-+", "measure": "unknown.measure.penta"}, "line.4": {"text": "Der lie\u00df kein Aug' von seinem Lord.", "tokens": ["Der", "lie\u00df", "kein", "Aug'", "von", "sei\u00b7nem", "Lord", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PIAT", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.29": {"line.1": {"text": "Und Douglas rief: \u00bbSetzt Segel bei,", "tokens": ["Und", "Doug\u00b7las", "rief", ":", "\u00bb", "Setzt", "Se\u00b7gel", "bei", ","], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["KON", "NE", "VVFIN", "$.", "$(", "VVFIN", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Kein Handbreit Linnen sei gespart!\u00ab", "tokens": ["Kein", "Hand\u00b7breit", "Lin\u00b7nen", "sei", "ge\u00b7spart", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PIAT", "NN", "NE", "VAFIN", "VVPP", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Hell lag die Sonn' auf Land und Meer,", "tokens": ["Hell", "lag", "die", "Sonn'", "auf", "Land", "und", "Meer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ART", "NN", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und rasch gen S\u00fcden ging die Fahrt.", "tokens": ["Und", "rasch", "gen", "S\u00fc\u00b7den", "ging", "die", "Fahrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "APPR", "NN", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.30": {"line.1": {"text": "Sie fuhren f\u00fcnfzig Meilen schon,", "tokens": ["Sie", "fuh\u00b7ren", "f\u00fcnf\u00b7zig", "Mei\u00b7len", "schon", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "CARD", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Percy aber ward's nicht froh,", "tokens": ["Der", "Per\u00b7cy", "a\u00b7ber", "ward's", "nicht", "froh", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "ADV", "VAFIN", "PTKNEG", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Er sprach: \u00bbJames Swinnard, frag' den Lord,", "tokens": ["Er", "sprach", ":", "\u00bb", "Ja\u00b7mes", "Swin\u00b7nard", ",", "frag'", "den", "Lord", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "$(", "NE", "NE", "$,", "VVIMP", "ART", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Wie weit es noch bis Linlithgow.\u00ab", "tokens": ["Wie", "weit", "es", "noch", "bis", "Lin\u00b7lith\u00b7gow", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWAV", "ADJD", "PPER", "ADV", "APPR", "NE", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.31": {"line.1": {"text": "James Swinnard vor Lord Douglas trat;", "tokens": ["Ja\u00b7mes", "Swin\u00b7nard", "vor", "Lord", "Doug\u00b7las", "trat", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "APPR", "NN", "NE", "VVFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Der lacht und spricht: \u00bbWir sind noch fern!", "tokens": ["Der", "lacht", "und", "spricht", ":", "\u00bb", "Wir", "sind", "noch", "fern", "!"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "KON", "VVFIN", "$.", "$(", "PPER", "VAFIN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ein Narr, wer sch\u00f6nen Worten traut,", "tokens": ["Ein", "Narr", ",", "wer", "sch\u00f6\u00b7nen", "Wor\u00b7ten", "traut", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PWS", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und nun empfiehl mich deinem Herrn.\u00ab", "tokens": ["Und", "nun", "emp\u00b7fiehl", "mich", "dei\u00b7nem", "Herrn", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.32": {"line.1": {"text": "Und wieder f\u00fcnfzig Meilen ging's,", "tokens": ["Und", "wie\u00b7der", "f\u00fcnf\u00b7zig", "Mei\u00b7len", "ging's", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "CARD", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Rings offne See, kein Land zu sehn,", "tokens": ["Rings", "off\u00b7ne", "See", ",", "kein", "Land", "zu", "sehn", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJA", "NN", "$,", "PIAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da trat Graf Percy selbst heran:", "tokens": ["Da", "trat", "Graf", "Per\u00b7cy", "selbst", "he\u00b7ran", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NE", "NE", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "\u00bbdouglas, sag' an, was soll geschehn!\u00ab", "tokens": ["\u00bb", "doug\u00b7las", ",", "sag'", "an", ",", "was", "soll", "ge\u00b7schehn", "!", "\u00ab"], "token_info": ["punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PDS", "$,", "VVFIN", "PTKVZ", "$,", "PWS", "VMFIN", "VVINF", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.33": {"line.1": {"text": "Der lacht und spricht: \u00bbSetz' dich zu Ro\u00df", "tokens": ["Der", "lacht", "und", "spricht", ":", "\u00bb", "Setz'", "dich", "zu", "Ro\u00df"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "KON", "VVFIN", "$.", "$(", "VVFIN", "PRF", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und spring' ins Meer und such' dein Gl\u00fcck,", "tokens": ["Und", "spring'", "ins", "Meer", "und", "such'", "dein", "Gl\u00fcck", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPRART", "NN", "KON", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und willst du noch nach Linlithgow,", "tokens": ["Und", "willst", "du", "noch", "nach", "Lin\u00b7lith\u00b7gow", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "ADV", "APPR", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So reit' den halben Weg zur\u00fcck.\u00ab", "tokens": ["So", "reit'", "den", "hal\u00b7ben", "Weg", "zu\u00b7r\u00fcck", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "PTKVZ", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.34": {"line.1": {"text": "Und wieder f\u00fcnfzig Meilen ging's \u2013", "tokens": ["Und", "wie\u00b7der", "f\u00fcnf\u00b7zig", "Mei\u00b7len", "ging's", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "CARD", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da blinkt's wie T\u00fcrme \u00fcber See,", "tokens": ["Da", "blinkt's", "wie", "T\u00fcr\u00b7me", "\u00fc\u00b7ber", "See", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "KOKOM", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Graf Percy spricht: \u00bbNun helf' mir Gott,", "tokens": ["Graf", "Per\u00b7cy", "spricht", ":", "\u00bb", "Nun", "hel\u00b7f'", "mir", "Gott", ","], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VVFIN", "$.", "$(", "ADV", "VVFIN", "PPER", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Das ist Stadt Berwick, was ich seh'!\u00ab", "tokens": ["Das", "ist", "Stadt", "Ber\u00b7wick", ",", "was", "ich", "seh'", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["PDS", "VAFIN", "NN", "NE", "$,", "PWS", "PPER", "VVFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.35": {"line.1": {"text": "Sie legten an bei Abendschein,", "tokens": ["Sie", "leg\u00b7ten", "an", "bei", "A\u00b7bend\u00b7schein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Fr\u00fchmorgens hat er fortgem\u00fc\u00dft.", "tokens": ["Fr\u00fch\u00b7mor\u00b7gens", "hat", "er", "fort\u00b7ge\u00b7m\u00fc\u00dft", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "VVFIN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Und als der dritte Morgen kam,", "tokens": ["Und", "als", "der", "drit\u00b7te", "Mor\u00b7gen", "kam", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Stand er in York am Blutger\u00fcst.", "tokens": ["Stand", "er", "in", "Y\u00b7ork", "am", "Blut\u00b7ge\u00b7r\u00fcst", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "NE", "APPRART", "NN", "$."], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}}, "stanza.36": {"line.1": {"text": "Er stieg die Stufen fest hinan,", "tokens": ["Er", "stieg", "die", "Stu\u00b7fen", "fest", "hi\u00b7nan", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das blanke Beil, er sah es nicht,", "tokens": ["Das", "blan\u00b7ke", "Beil", ",", "er", "sah", "es", "nicht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PPER", "VVFIN", "PPER", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sein Auge schweifte rings umher", "tokens": ["Sein", "Au\u00b7ge", "schweif\u00b7te", "rings", "um\u00b7her"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VVFIN", "ADV", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und traf des Douglas bleich Gesicht.", "tokens": ["Und", "traf", "des", "Doug\u00b7las", "bleich", "Ge\u00b7sicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "ADJD", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.37": {"line.1": {"text": "Noch einmal klang's ihm durch das Herz,", "tokens": ["Noch", "ein\u00b7mal", "klang's", "ihm", "durch", "das", "Herz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und bitter l\u00e4chelnd schaut' er drein:", "tokens": ["Und", "bit\u00b7ter", "l\u00e4\u00b7chelnd", "schaut'", "er", "drein", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "ADJD", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "\u00bbdie Douglas waren immer treu,", "tokens": ["\u00bb", "die", "Doug\u00b7las", "wa\u00b7ren", "im\u00b7mer", "treu", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "VAFIN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Auch William Douglas mu\u00df es sein.\u00ab", "tokens": ["Auch", "Wil\u00b7li\u00b7am", "Doug\u00b7las", "mu\u00df", "es", "sein", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "NE", "NE", "VMFIN", "PPER", "VAINF", "$.", "$("], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.38": {"line.1": {"text": "Dann lie\u00df er nieder sich aufs Knie", "tokens": ["Dann", "lie\u00df", "er", "nie\u00b7der", "sich", "aufs", "Knie"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PTKVZ", "PRF", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und gab das Zeichen mit der Hand;", "tokens": ["Und", "gab", "das", "Zei\u00b7chen", "mit", "der", "Hand", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ab flog sein Haupt: \u2013 das war das End'", "tokens": ["Ab", "flog", "sein", "Haupt", ":", "\u2013", "das", "war", "das", "End'"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word"], "pos": ["APPR", "VVFIN", "PPOSAT", "NN", "$.", "$(", "PDS", "VAFIN", "ART", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Des Percy von Northumberland.", "tokens": ["Des", "Per\u00b7cy", "von", "Nor\u00b7thum\u00b7ber\u00b7land", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NE", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.39": {"line.1": {"text": "\u00bbmein Dach ist der Himmel seit manchem Tag,", "tokens": ["\u00bb", "mein", "Dach", "ist", "der", "Him\u00b7mel", "seit", "man\u00b7chem", "Tag", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPOSAT", "NN", "VAFIN", "ART", "NN", "APPR", "PIAT", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Mein Lager zur Nacht des Waldes Streu:", "tokens": ["Mein", "La\u00b7ger", "zur", "Nacht", "des", "Wal\u00b7des", "Streu", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPRART", "NN", "ART", "NN", "NE", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Zu William Douglas will ich gehn,", "tokens": ["Zu", "Wil\u00b7li\u00b7am", "Doug\u00b7las", "will", "ich", "gehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "NE", "VMFIN", "PPER", "VVINF", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Sein Schlo\u00df ist fest, sein Herz ist treu.", "tokens": ["Sein", "Schlo\u00df", "ist", "fest", ",", "sein", "Herz", "ist", "treu", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADJD", "$,", "PPOSAT", "NN", "VAFIN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.40": {"line.1": {"text": "Als einst er floh, wie jetzt ich flieh',", "tokens": ["Als", "einst", "er", "floh", ",", "wie", "jetzt", "ich", "flieh'", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PPER", "VVFIN", "$,", "PWAV", "ADV", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da fand er Schutz am Herde mein:", "tokens": ["Da", "fand", "er", "Schutz", "am", "Her\u00b7de", "mein", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "NN", "APPRART", "NN", "PPOSAT", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die Douglas waren immer treu,", "tokens": ["Die", "Doug\u00b7las", "wa\u00b7ren", "im\u00b7mer", "treu", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Auch William Douglas mu\u00df es sein.\u00ab", "tokens": ["Auch", "Wil\u00b7li\u00b7am", "Doug\u00b7las", "mu\u00df", "es", "sein", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "NE", "NE", "VMFIN", "PPER", "VAINF", "$.", "$("], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.41": {"line.1": {"text": "Graf Percy spricht's. Sein m\u00fcdes Ro\u00df,", "tokens": ["Graf", "Per\u00b7cy", "spricht'", "s.", "Sein", "m\u00fc\u00b7des", "Ro\u00df", ","], "token_info": ["word", "word", "word", "abbreviation", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VVFIN", "VVIMP", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Er treibt es an mit Sporn und Schlag;", "tokens": ["Er", "treibt", "es", "an", "mit", "Sporn", "und", "Schlag", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Er reitet gen Lochleven-Schlo\u00df", "tokens": ["Er", "rei\u00b7tet", "gen", "Loch\u00b7le\u00b7ven\u00b7Schlo\u00df"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "NN"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.4": {"text": "Und h\u00e4lt davor am dritten Tag.", "tokens": ["Und", "h\u00e4lt", "da\u00b7vor", "am", "drit\u00b7ten", "Tag", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PAV", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.42": {"line.1": {"text": "Die Br\u00fccke rasselt niederw\u00e4rts,", "tokens": ["Die", "Br\u00fc\u00b7cke", "ras\u00b7selt", "nie\u00b7der\u00b7w\u00e4rts", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Graf Percy tritt zur Hall' hinein;", "tokens": ["Graf", "Per\u00b7cy", "tritt", "zur", "Hall'", "hin\u00b7ein", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VVFIN", "APPRART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Graf Douglas spricht: \u00bbWillkomm, willkomm!\u00ab", "tokens": ["Graf", "Doug\u00b7las", "spricht", ":", "\u00bb", "Will\u00b7komm", ",", "will\u00b7komm", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct", "word", "punct", "word", "punct", "punct"], "pos": ["NE", "NE", "VVFIN", "$.", "$(", "NE", "$,", "ADJD", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und reicht ihm Hand und reicht ihm Wein.", "tokens": ["Und", "reicht", "ihm", "Hand", "und", "reicht", "ihm", "Wein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "NN", "KON", "VVFIN", "PPER", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.43": {"line.1": {"text": "Es geht der Tag, die Monde gehn;", "tokens": ["Es", "geht", "der", "Tag", ",", "die", "Mon\u00b7de", "gehn", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Am Fenster r\u00fcttelt Herbsteswind,", "tokens": ["Am", "Fens\u00b7ter", "r\u00fct\u00b7telt", "Herbs\u00b7tes\u00b7wind", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Des Percy Herz wird bang und schwer,", "tokens": ["Des", "Per\u00b7cy", "Herz", "wird", "bang", "und", "schwer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VAFIN", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Er denkt an Weib und denkt an Kind.", "tokens": ["Er", "denkt", "an", "Weib", "und", "denkt", "an", "Kind", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "KON", "VVFIN", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.44": {"line.1": {"text": "Graf Douglas sitzt zu Seiten ihm", "tokens": ["Graf", "Doug\u00b7las", "sitzt", "zu", "Sei\u00b7ten", "ihm"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "NE", "VVFIN", "APPR", "NN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und ruft ihm zu: \u00bbWas tr\u00fcbt dich so?", "tokens": ["Und", "ruft", "ihm", "zu", ":", "\u00bb", "Was", "tr\u00fcbt", "dich", "so", "?"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PTKVZ", "$.", "$(", "PWS", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wir fahren morgen \u00fcber See,", "tokens": ["Wir", "fah\u00b7ren", "mor\u00b7gen", "\u00fc\u00b7ber", "See", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Lord Murray jagt bei Linlithgow.", "tokens": ["Lord", "Mur\u00b7ray", "jagt", "bei", "Lin\u00b7lith\u00b7gow", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "VVFIN", "APPR", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.45": {"line.1": {"text": "Und bist du krank, so heil' dein Herz", "tokens": ["Und", "bist", "du", "krank", ",", "so", "heil'", "dein", "Herz"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "PPER", "ADJD", "$,", "ADV", "ADJD", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Durch gr\u00fcnen Wald und raschen Ritt;", "tokens": ["Durch", "gr\u00fc\u00b7nen", "Wald", "und", "ra\u00b7schen", "Ritt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "KON", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Zudem, ich gab dem Lord mein Wort,", "tokens": ["Zu\u00b7dem", ",", "ich", "gab", "dem", "Lord", "mein", "Wort", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "$,", "PPER", "VVFIN", "ART", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Du w\u00e4rst dabei, du jagtest mit.\u00ab", "tokens": ["Du", "w\u00e4rst", "da\u00b7bei", ",", "du", "jag\u00b7test", "mit", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VAFIN", "PAV", "$,", "PPER", "VVFIN", "PTKVZ", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.46": {"line.1": {"text": "Der Douglas spricht's. Graf Percy drauf:", "tokens": ["Der", "Doug\u00b7las", "spricht'", "s.", "Graf", "Per\u00b7cy", "drauf", ":"], "token_info": ["word", "word", "word", "abbreviation", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "NE", "NE", "NE", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u00bbdu gabst dein Wort, \u2013 ich bin bereit!", "tokens": ["\u00bb", "du", "gabst", "dein", "Wort", ",", "\u2013", "ich", "bin", "be\u00b7reit", "!"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "PPOSAT", "NN", "$,", "$(", "PPER", "VAFIN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und ritt'st du bis zum heil'gen Grab,", "tokens": ["Und", "ritt'st", "du", "bis", "zum", "heil'\u00b7gen", "Grab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ich ritte mit an deiner Seit'.\u00ab", "tokens": ["Ich", "rit\u00b7te", "mit", "an", "dei\u00b7ner", "Seit'", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "APPR", "APPR", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.47": {"line.1": {"text": "Er spricht's und reicht ihm rasch die Hand;", "tokens": ["Er", "spricht's", "und", "reicht", "ihm", "rasch", "die", "Hand", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "PPER", "ADJD", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Rot wird des Douglas bleich Gesicht,", "tokens": ["Rot", "wird", "des", "Doug\u00b7las", "bleich", "Ge\u00b7sicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "ART", "NN", "ADJD", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Er senkt sein Aug' und geht hinaus.", "tokens": ["Er", "senkt", "sein", "Aug'", "und", "geht", "hin\u00b7aus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "KON", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Maria Douglas aber spricht:", "tokens": ["Ma\u00b7ria", "Doug\u00b7las", "a\u00b7ber", "spricht", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "ADV", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.48": {"line.1": {"text": "\u00bbhab acht! mein Bruder spinnt Verrat;", "tokens": ["\u00bb", "hab", "acht", "!", "mein", "Bru\u00b7der", "spinnt", "Ver\u00b7rat", ";"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "VAFIN", "CARD", "$.", "PPOSAT", "NN", "VVFIN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Unstet seit lang' sein Auge rollt;", "tokens": ["Un\u00b7stet", "seit", "lang'", "sein", "Au\u00b7ge", "rollt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "NE", "PPOSAT", "NN", "VVFIN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Das macht, er hat verkauft die Treu',", "tokens": ["Das", "macht", ",", "er", "hat", "ver\u00b7kauft", "die", "Treu'", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "$,", "PPER", "VAFIN", "VVPP", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Verkauft um englisch S\u00fcndengold.", "tokens": ["Ver\u00b7kauft", "um", "eng\u00b7lisch", "S\u00fcn\u00b7den\u00b7gold", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ADJD", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.49": {"line.1": {"text": "Er f\u00fchrt dich nicht nach Linlithgow,", "tokens": ["Er", "f\u00fchrt", "dich", "nicht", "nach", "Lin\u00b7lith\u00b7gow", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKNEG", "APPR", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Er f\u00fchrt dich, wo Schlo\u00df Berwick ragt;", "tokens": ["Er", "f\u00fchrt", "dich", ",", "wo", "Schlo\u00df", "Ber\u00b7wick", "ragt", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$,", "PWAV", "NN", "NE", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Nach ", "tokens": ["Nach"], "token_info": ["word"], "pos": ["APPR"], "meter": "+", "measure": "single.up"}, "line.4": {"text": "Du bist es ", "tokens": ["Du", "bist", "es"], "token_info": ["word", "word", "word"], "pos": ["PPER", "VAFIN", "PPER"], "meter": "-+-", "measure": "amphibrach.single"}}, "stanza.50": {"line.1": {"text": "Bleib hier und sprich: \u203adu seiest krank!\u2039", "tokens": ["Bleib", "hier", "und", "sprich", ":", "\u203a", "du", "sei\u00b7est", "krank", "!", "\u2039"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct", "punct"], "pos": ["NN", "ADV", "KON", "ADJD", "$.", "$(", "PPER", "VAFIN", "ADJD", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So helf mit Gott ich dir hindurch", "tokens": ["So", "helf", "mit", "Gott", "ich", "dir", "hin\u00b7durch"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "APPR", "NN", "PPER", "PPER", "PAV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und f\u00fchr' dich, auf verborgnem Pfad,", "tokens": ["Und", "f\u00fchr'", "dich", ",", "auf", "ver\u00b7borg\u00b7nem", "Pfad", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Durch Wald und Nacht nach Edinburg.", "tokens": ["Durch", "Wald", "und", "Nacht", "nach", "E\u00b7din\u00b7burg", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "APPR", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.51": {"line.1": {"text": "Und bring' dich zu Lord Hamilton,", "tokens": ["Und", "bring'", "dich", "zu", "Lord", "Ha\u00b7mil\u00b7ton", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "APPR", "NN", "NE", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Das ist ein echter Schotten-Lord,", "tokens": ["Das", "ist", "ein", "ech\u00b7ter", "Schot\u00b7ten\u00b7\u00b7L\u00b7ord", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Der lie\u00df wohl lieber Land und Leib,", "tokens": ["Der", "lie\u00df", "wohl", "lie\u00b7ber", "Land", "und", "Leib", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "ADV", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Als da\u00df er lie\u00df von seinem Wort.\u00ab", "tokens": ["Als", "da\u00df", "er", "lie\u00df", "von", "sei\u00b7nem", "Wort", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "KOUS", "PPER", "VVFIN", "APPR", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.52": {"line.1": {"text": "Graf Percy h\u00f6rt's, sein Aug' wird feucht,", "tokens": ["Graf", "Per\u00b7cy", "h\u00f6rt's", ",", "sein", "Aug'", "wird", "feucht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VVFIN", "$,", "PPOSAT", "NN", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Er spricht: \u00bbSchwer trifft mich Gottes Hand,", "tokens": ["Er", "spricht", ":", "\u00bb", "Schwer", "trifft", "mich", "Got\u00b7tes", "Hand", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "$(", "ADJD", "VVFIN", "PPER", "NN", "NN", "$,"], "meter": "-+---+-+", "measure": "dactylic.init"}, "line.3": {"text": "So vielen Freunden bracht' ich Tod,", "tokens": ["So", "vie\u00b7len", "Freun\u00b7den", "bracht'", "ich", "Tod", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "VVFIN", "PPER", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Dem letzten bring' ich Schimpf und Schand'.", "tokens": ["Dem", "letz\u00b7ten", "bring'", "ich", "Schimpf", "und", "Schand'", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "PPER", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.53": {"line.1": {"text": "Ich hab' gedacht: es sei vorbei,", "tokens": ["Ich", "hab'", "ge\u00b7dacht", ":", "es", "sei", "vor\u00b7bei", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVPP", "$.", "PPER", "VAFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und hab' gedacht: das Ma\u00df sei voll;", "tokens": ["Und", "hab'", "ge\u00b7dacht", ":", "das", "Ma\u00df", "sei", "voll", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "VVPP", "$.", "ART", "NN", "VAFIN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Weh mir, da\u00df Schlimmres nun als Tod", "tokens": ["Weh", "mir", ",", "da\u00df", "Schlimm\u00b7res", "nun", "als", "Tod"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "PPER", "$,", "KOUS", "NE", "ADV", "KOUS", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Auf Freundes Haupt ich laden soll.", "tokens": ["Auf", "Freun\u00b7des", "Haupt", "ich", "la\u00b7den", "soll", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "NN", "PPER", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.54": {"line.1": {"text": "Die Treue bring' ich in Verdacht,", "tokens": ["Die", "Treu\u00b7e", "bring'", "ich", "in", "Ver\u00b7dacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sie sei nicht treu, sei falsches Spiel;", "tokens": ["Sie", "sei", "nicht", "treu", ",", "sei", "fal\u00b7sches", "Spiel", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKNEG", "ADJD", "$,", "VAFIN", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ich trage Fluch in jedes Haus \u2013", "tokens": ["Ich", "tra\u00b7ge", "Fluch", "in", "je\u00b7des", "Haus", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "APPR", "PIAT", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Es ist zuviel, es ist zuviel.", "tokens": ["Es", "ist", "zu\u00b7viel", ",", "es", "ist", "zu\u00b7viel", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIS", "$,", "PPER", "VAFIN", "PIS", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.55": {"line.1": {"text": "Und sprichst du auch: Hab acht, hab acht!", "tokens": ["Und", "sprichst", "du", "auch", ":", "Hab", "acht", ",", "hab", "acht", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "$.", "NN", "CARD", "$,", "VAFIN", "CARD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ich sprech' doch nur: Halt ein, halt ein!", "tokens": ["Ich", "sprech'", "doch", "nur", ":", "Halt", "ein", ",", "halt", "ein", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "$.", "VVIMP", "PTKVZ", "$,", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die Douglas waren immer treu,", "tokens": ["Die", "Doug\u00b7las", "wa\u00b7ren", "im\u00b7mer", "treu", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Auch William Douglas mu\u00df es sein.\u00ab", "tokens": ["Auch", "Wil\u00b7li\u00b7am", "Doug\u00b7las", "mu\u00df", "es", "sein", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "NE", "NE", "VMFIN", "PPER", "VAINF", "$.", "$("], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.56": {"line.1": {"text": "Graf Percy spricht's. Die Lady drauf:", "tokens": ["Graf", "Per\u00b7cy", "spricht'", "s.", "Die", "La\u00b7dy", "drauf", ":"], "token_info": ["word", "word", "word", "abbreviation", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VVFIN", "VVIMP", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u00bbund sch\u00e4tzest du mein Wort gering,", "tokens": ["\u00bb", "und", "sch\u00e4t\u00b7zest", "du", "mein", "Wort", "ge\u00b7ring", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KON", "VVFIN", "PPER", "PPOSAT", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Komm mit mir an den Leven-See,", "tokens": ["Komm", "mit", "mir", "an", "den", "Le\u00b7ven\u00b7See", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und schau hinein durch diesen Ring.", "tokens": ["Und", "schau", "hin\u00b7ein", "durch", "die\u00b7sen", "Ring", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "ADV", "APPR", "PDAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.57": {"line.1": {"text": "Den Ring mir meine Mutter gab,", "tokens": ["Den", "Ring", "mir", "mei\u00b7ne", "Mut\u00b7ter", "gab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPER", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die konnte Wind und Wald verstehn,", "tokens": ["Die", "konn\u00b7te", "Wind", "und", "Wald", "ver\u00b7stehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "NN", "KON", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und blickst du auf des Sees Grund,", "tokens": ["Und", "blickst", "du", "auf", "des", "Sees", "Grund", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-++", "measure": "unknown.measure.tetra"}, "line.4": {"text": "So wirst du deine Zukunft sehn.", "tokens": ["So", "wirst", "du", "dei\u00b7ne", "Zu\u00b7kunft", "sehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.58": {"line.1": {"text": "Komm mit, komm mit! und willst du nicht,", "tokens": ["Komm", "mit", ",", "komm", "mit", "!", "und", "willst", "du", "nicht", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "$,", "VVFIN", "PTKVZ", "$.", "KON", "VMFIN", "PPER", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und glaubst du nicht, Gefahr sei nah,", "tokens": ["Und", "glaubst", "du", "nicht", ",", "Ge\u00b7fahr", "sei", "nah", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PTKNEG", "$,", "NN", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So gib mir deinen Diener mit,", "tokens": ["So", "gib", "mir", "dei\u00b7nen", "Die\u00b7ner", "mit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVIMP", "PPER", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der mag dir sagen, was er sah.\u00ab", "tokens": ["Der", "mag", "dir", "sa\u00b7gen", ",", "was", "er", "sah", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["PDS", "VMFIN", "PPER", "VVINF", "$,", "PWS", "PPER", "VVFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.59": {"line.1": {"text": "James Swinnard mit der Lady ging,", "tokens": ["Ja\u00b7mes", "Swin\u00b7nard", "mit", "der", "La\u00b7dy", "ging", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Sie kamen an den Leven-See;", "tokens": ["Sie", "ka\u00b7men", "an", "den", "Le\u00b7ven\u00b7See", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "James Swinnard spricht: \u00bbDas sind von York", "tokens": ["Ja\u00b7mes", "Swin\u00b7nard", "spricht", ":", "\u00bb", "Das", "sind", "von", "Y\u00b7ork"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word"], "pos": ["NE", "NE", "VVFIN", "$.", "$(", "PDS", "VAFIN", "APPR", "NE"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "Die T\u00fcrme, die ich drunten seh'!", "tokens": ["Die", "T\u00fcr\u00b7me", ",", "die", "ich", "drun\u00b7ten", "seh'", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.60": {"line.1": {"text": "Doch, Lady, sprich, auf offnem Platz", "tokens": ["Doch", ",", "La\u00b7dy", ",", "sprich", ",", "auf", "off\u00b7nem", "Platz"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["KON", "$,", "NE", "$,", "ADJD", "$,", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Was soll von Brettern das Ger\u00fcst?\u00ab", "tokens": ["Was", "soll", "von", "Bret\u00b7tern", "das", "Ge\u00b7r\u00fcst", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWS", "VMFIN", "APPR", "NN", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "\u00bbdas ist der Altar, drauf dein Herr", "tokens": ["\u00bb", "das", "ist", "der", "Al\u00b7tar", ",", "drauf", "dein", "Herr"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["$(", "PDS", "VAFIN", "ART", "NN", "$,", "PAV", "PPOSAT", "NN"], "meter": "-+--++-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Zum letzten Mal den Heiland k\u00fc\u00dft.\u00ab", "tokens": ["Zum", "letz\u00b7ten", "Mal", "den", "Hei\u00b7land", "k\u00fc\u00dft", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPRART", "ADJA", "NN", "ART", "NN", "VVFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.61": {"line.1": {"text": "\u00bbund, Lady, sprich, wer steht dabei,", "tokens": ["\u00bb", "und", ",", "La\u00b7dy", ",", "sprich", ",", "wer", "steht", "da\u00b7bei", ","], "token_info": ["punct", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "KON", "$,", "NE", "$,", "ADJD", "$,", "PWS", "VVFIN", "PAV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Geh\u00fcllt in Mantel, schwarz und dicht?\u00ab", "tokens": ["Ge\u00b7h\u00fcllt", "in", "Man\u00b7tel", ",", "schwarz", "und", "dicht", "?", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "APPR", "NN", "$,", "ADJD", "KON", "ADJD", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "\u00bbdas ist von York der Lord-Wardein,", "tokens": ["\u00bb", "das", "ist", "von", "Y\u00b7ork", "der", "Lord\u00b7War\u00b7dein", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PDS", "VAFIN", "APPR", "NE", "ART", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Der deinem Herrn das St\u00e4bchen bricht.\u00ab", "tokens": ["Der", "dei\u00b7nem", "Herrn", "das", "St\u00e4b\u00b7chen", "bricht", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "PPOSAT", "NN", "ART", "NN", "VVFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.62": {"line.1": {"text": "\u00bbund, Lady, sprich, wer steht dabei,", "tokens": ["\u00bb", "und", ",", "La\u00b7dy", ",", "sprich", ",", "wer", "steht", "da\u00b7bei", ","], "token_info": ["punct", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "KON", "$,", "NE", "$,", "ADJD", "$,", "PWS", "VVFIN", "PAV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Geh\u00fcllt in Mantel, rot wie Blut?\u00ab", "tokens": ["Ge\u00b7h\u00fcllt", "in", "Man\u00b7tel", ",", "rot", "wie", "Blut", "?", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "APPR", "NN", "$,", "ADJD", "KOKOM", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "\u00bbdas ist von York der Meister Hans,", "tokens": ["\u00bb", "das", "ist", "von", "Y\u00b7ork", "der", "Meis\u00b7ter", "Hans", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PDS", "VAFIN", "APPR", "NE", "ART", "NN", "NE", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Der deinem Herrn das Letzte tut.\u00ab", "tokens": ["Der", "dei\u00b7nem", "Herrn", "das", "Letz\u00b7te", "tut", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "PPOSAT", "NN", "ART", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.63": {"line.1": {"text": "James Swinnard trat vor seinen Herrn,", "tokens": ["Ja\u00b7mes", "Swin\u00b7nard", "trat", "vor", "sei\u00b7nen", "Herrn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Er sah ihn an und weinte laut;", "tokens": ["Er", "sah", "ihn", "an", "und", "wein\u00b7te", "laut", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKVZ", "KON", "VVFIN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Er sprach: \u00bbBleib hier, mein teurer Lord,", "tokens": ["Er", "sprach", ":", "\u00bb", "Bleib", "hier", ",", "mein", "teu\u00b7rer", "Lord", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "$(", "NN", "ADV", "$,", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ich hab' nichts Gutes da geschaut.\u00ab", "tokens": ["Ich", "hab'", "nichts", "Gu\u00b7tes", "da", "ge\u00b7schaut", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VAFIN", "PIS", "NN", "ADV", "VVPP", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.64": {"line.1": {"text": "Er schwieg. Graf Percy aber schnell:", "tokens": ["Er", "schwieg", ".", "Graf", "Per\u00b7cy", "a\u00b7ber", "schnell", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "NE", "NE", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u00bbund kostet's Leben mir und Leib,", "tokens": ["\u00bb", "und", "kos\u00b7tet's", "Le\u00b7ben", "mir", "und", "Leib", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KON", "ADJA", "NN", "PPER", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ich bau' auf Mann und Manneswort", "tokens": ["Ich", "bau'", "auf", "Mann", "und", "Man\u00b7nes\u00b7wort"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und nicht auf Spuk und Zauberweib.", "tokens": ["Und", "nicht", "auf", "Spuk", "und", "Zau\u00b7ber\u00b7weib", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.65": {"line.1": {"text": "Und w\u00e4r's kein Spuk und w\u00fcrd' es wahr,", "tokens": ["Und", "w\u00e4r's", "kein", "Spuk", "und", "w\u00fcrd'", "es", "wahr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PIAT", "NN", "KON", "VAFIN", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ich spr\u00e4che doch: 's ist Trug und Schein,", "tokens": ["Ich", "spr\u00e4\u00b7che", "doch", ":", "'s", "ist", "Trug", "und", "Schein", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$.", "PPER", "VAFIN", "NN", "KON", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Die Douglas waren immer treu,", "tokens": ["Die", "Doug\u00b7las", "wa\u00b7ren", "im\u00b7mer", "treu", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Auch William Douglas mu\u00df es sein.\u00ab", "tokens": ["Auch", "Wil\u00b7li\u00b7am", "Doug\u00b7las", "mu\u00df", "es", "sein", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "NE", "NE", "VMFIN", "PPER", "VAINF", "$.", "$("], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.66": {"line.1": {"text": "Der Morgen kam, der Wind war gut,", "tokens": ["Der", "Mor\u00b7gen", "kam", ",", "der", "Wind", "war", "gut", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "ART", "NN", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Pfeife rief: an Bord, an Bord!", "tokens": ["Die", "Pfei\u00b7fe", "rief", ":", "an", "Bord", ",", "an", "Bord", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$.", "APPR", "NN", "$,", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Man stieg zu Schiff \u2013 James Swinnard auch,", "tokens": ["Man", "stieg", "zu", "Schiff", "\u2013", "Ja\u00b7mes", "Swin\u00b7nard", "auch", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "APPR", "NN", "$(", "NE", "NE", "ADV", "$,"], "meter": "-+-++-+-+", "measure": "unknown.measure.penta"}, "line.4": {"text": "Der lie\u00df kein Aug' von seinem Lord.", "tokens": ["Der", "lie\u00df", "kein", "Aug'", "von", "sei\u00b7nem", "Lord", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PIAT", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.67": {"line.1": {"text": "Und Douglas rief: \u00bbSetzt Segel bei,", "tokens": ["Und", "Doug\u00b7las", "rief", ":", "\u00bb", "Setzt", "Se\u00b7gel", "bei", ","], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["KON", "NE", "VVFIN", "$.", "$(", "VVFIN", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Kein Handbreit Linnen sei gespart!\u00ab", "tokens": ["Kein", "Hand\u00b7breit", "Lin\u00b7nen", "sei", "ge\u00b7spart", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PIAT", "NN", "NE", "VAFIN", "VVPP", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Hell lag die Sonn' auf Land und Meer,", "tokens": ["Hell", "lag", "die", "Sonn'", "auf", "Land", "und", "Meer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ART", "NN", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und rasch gen S\u00fcden ging die Fahrt.", "tokens": ["Und", "rasch", "gen", "S\u00fc\u00b7den", "ging", "die", "Fahrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "APPR", "NN", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.68": {"line.1": {"text": "Sie fuhren f\u00fcnfzig Meilen schon,", "tokens": ["Sie", "fuh\u00b7ren", "f\u00fcnf\u00b7zig", "Mei\u00b7len", "schon", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "CARD", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Percy aber ward's nicht froh,", "tokens": ["Der", "Per\u00b7cy", "a\u00b7ber", "ward's", "nicht", "froh", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "ADV", "VAFIN", "PTKNEG", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Er sprach: \u00bbJames Swinnard, frag' den Lord,", "tokens": ["Er", "sprach", ":", "\u00bb", "Ja\u00b7mes", "Swin\u00b7nard", ",", "frag'", "den", "Lord", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "$(", "NE", "NE", "$,", "VVIMP", "ART", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Wie weit es noch bis Linlithgow.\u00ab", "tokens": ["Wie", "weit", "es", "noch", "bis", "Lin\u00b7lith\u00b7gow", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWAV", "ADJD", "PPER", "ADV", "APPR", "NE", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.69": {"line.1": {"text": "James Swinnard vor Lord Douglas trat;", "tokens": ["Ja\u00b7mes", "Swin\u00b7nard", "vor", "Lord", "Doug\u00b7las", "trat", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "APPR", "NN", "NE", "VVFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Der lacht und spricht: \u00bbWir sind noch fern!", "tokens": ["Der", "lacht", "und", "spricht", ":", "\u00bb", "Wir", "sind", "noch", "fern", "!"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "KON", "VVFIN", "$.", "$(", "PPER", "VAFIN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ein Narr, wer sch\u00f6nen Worten traut,", "tokens": ["Ein", "Narr", ",", "wer", "sch\u00f6\u00b7nen", "Wor\u00b7ten", "traut", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PWS", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und nun empfiehl mich deinem Herrn.\u00ab", "tokens": ["Und", "nun", "emp\u00b7fiehl", "mich", "dei\u00b7nem", "Herrn", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.70": {"line.1": {"text": "Und wieder f\u00fcnfzig Meilen ging's,", "tokens": ["Und", "wie\u00b7der", "f\u00fcnf\u00b7zig", "Mei\u00b7len", "ging's", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "CARD", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Rings offne See, kein Land zu sehn,", "tokens": ["Rings", "off\u00b7ne", "See", ",", "kein", "Land", "zu", "sehn", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJA", "NN", "$,", "PIAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da trat Graf Percy selbst heran:", "tokens": ["Da", "trat", "Graf", "Per\u00b7cy", "selbst", "he\u00b7ran", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NE", "NE", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "\u00bbdouglas, sag' an, was soll geschehn!\u00ab", "tokens": ["\u00bb", "doug\u00b7las", ",", "sag'", "an", ",", "was", "soll", "ge\u00b7schehn", "!", "\u00ab"], "token_info": ["punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PDS", "$,", "VVFIN", "PTKVZ", "$,", "PWS", "VMFIN", "VVINF", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.71": {"line.1": {"text": "Der lacht und spricht: \u00bbSetz' dich zu Ro\u00df", "tokens": ["Der", "lacht", "und", "spricht", ":", "\u00bb", "Setz'", "dich", "zu", "Ro\u00df"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "KON", "VVFIN", "$.", "$(", "VVFIN", "PRF", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und spring' ins Meer und such' dein Gl\u00fcck,", "tokens": ["Und", "spring'", "ins", "Meer", "und", "such'", "dein", "Gl\u00fcck", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPRART", "NN", "KON", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und willst du noch nach Linlithgow,", "tokens": ["Und", "willst", "du", "noch", "nach", "Lin\u00b7lith\u00b7gow", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "ADV", "APPR", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So reit' den halben Weg zur\u00fcck.\u00ab", "tokens": ["So", "reit'", "den", "hal\u00b7ben", "Weg", "zu\u00b7r\u00fcck", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "PTKVZ", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.72": {"line.1": {"text": "Und wieder f\u00fcnfzig Meilen ging's \u2013", "tokens": ["Und", "wie\u00b7der", "f\u00fcnf\u00b7zig", "Mei\u00b7len", "ging's", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "CARD", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da blinkt's wie T\u00fcrme \u00fcber See,", "tokens": ["Da", "blinkt's", "wie", "T\u00fcr\u00b7me", "\u00fc\u00b7ber", "See", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "KOKOM", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Graf Percy spricht: \u00bbNun helf' mir Gott,", "tokens": ["Graf", "Per\u00b7cy", "spricht", ":", "\u00bb", "Nun", "hel\u00b7f'", "mir", "Gott", ","], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VVFIN", "$.", "$(", "ADV", "VVFIN", "PPER", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Das ist Stadt Berwick, was ich seh'!\u00ab", "tokens": ["Das", "ist", "Stadt", "Ber\u00b7wick", ",", "was", "ich", "seh'", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["PDS", "VAFIN", "NN", "NE", "$,", "PWS", "PPER", "VVFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.73": {"line.1": {"text": "Sie legten an bei Abendschein,", "tokens": ["Sie", "leg\u00b7ten", "an", "bei", "A\u00b7bend\u00b7schein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Fr\u00fchmorgens hat er fortgem\u00fc\u00dft.", "tokens": ["Fr\u00fch\u00b7mor\u00b7gens", "hat", "er", "fort\u00b7ge\u00b7m\u00fc\u00dft", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "VVFIN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Und als der dritte Morgen kam,", "tokens": ["Und", "als", "der", "drit\u00b7te", "Mor\u00b7gen", "kam", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Stand er in York am Blutger\u00fcst.", "tokens": ["Stand", "er", "in", "Y\u00b7ork", "am", "Blut\u00b7ge\u00b7r\u00fcst", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "NE", "APPRART", "NN", "$."], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}}, "stanza.74": {"line.1": {"text": "Er stieg die Stufen fest hinan,", "tokens": ["Er", "stieg", "die", "Stu\u00b7fen", "fest", "hi\u00b7nan", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das blanke Beil, er sah es nicht,", "tokens": ["Das", "blan\u00b7ke", "Beil", ",", "er", "sah", "es", "nicht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PPER", "VVFIN", "PPER", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sein Auge schweifte rings umher", "tokens": ["Sein", "Au\u00b7ge", "schweif\u00b7te", "rings", "um\u00b7her"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VVFIN", "ADV", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und traf des Douglas bleich Gesicht.", "tokens": ["Und", "traf", "des", "Doug\u00b7las", "bleich", "Ge\u00b7sicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "ADJD", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.75": {"line.1": {"text": "Noch einmal klang's ihm durch das Herz,", "tokens": ["Noch", "ein\u00b7mal", "klang's", "ihm", "durch", "das", "Herz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und bitter l\u00e4chelnd schaut' er drein:", "tokens": ["Und", "bit\u00b7ter", "l\u00e4\u00b7chelnd", "schaut'", "er", "drein", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "ADJD", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "\u00bbdie Douglas waren immer treu,", "tokens": ["\u00bb", "die", "Doug\u00b7las", "wa\u00b7ren", "im\u00b7mer", "treu", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "VAFIN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Auch William Douglas mu\u00df es sein.\u00ab", "tokens": ["Auch", "Wil\u00b7li\u00b7am", "Doug\u00b7las", "mu\u00df", "es", "sein", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "NE", "NE", "VMFIN", "PPER", "VAINF", "$.", "$("], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.76": {"line.1": {"text": "Dann lie\u00df er nieder sich aufs Knie", "tokens": ["Dann", "lie\u00df", "er", "nie\u00b7der", "sich", "aufs", "Knie"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PTKVZ", "PRF", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und gab das Zeichen mit der Hand;", "tokens": ["Und", "gab", "das", "Zei\u00b7chen", "mit", "der", "Hand", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ab flog sein Haupt: \u2013 das war das End'", "tokens": ["Ab", "flog", "sein", "Haupt", ":", "\u2013", "das", "war", "das", "End'"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word"], "pos": ["APPR", "VVFIN", "PPOSAT", "NN", "$.", "$(", "PDS", "VAFIN", "ART", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Des Percy von Northumberland.", "tokens": ["Des", "Per\u00b7cy", "von", "Nor\u00b7thum\u00b7ber\u00b7land", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NE", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}}}}}