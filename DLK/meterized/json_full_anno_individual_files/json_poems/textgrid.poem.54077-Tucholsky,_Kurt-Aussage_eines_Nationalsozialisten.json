{"textgrid.poem.54077": {"metadata": {"author": {"name": "Tucholsky, Kurt", "birth": "N.A.", "death": "N.A."}, "title": "Aussage eines Nationalsozialisten", "genre": "verse", "period": "N.A.", "pub_year": 1912, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "\u00bbich m\u00f6chte den Eid in der religi\u00f6sen", "tokens": ["\u00bb", "ich", "m\u00f6ch\u00b7te", "den", "Eid", "in", "der", "re\u00b7li\u00b7gi\u00b7\u00f6\u00b7sen"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "PPER", "VMFIN", "ART", "NN", "APPR", "ART", "ADJA"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.2": {"text": "Form ablegen. Ich schw\u00f6re \u2013 da\u00df ich", "tokens": ["Form", "ab\u00b7le\u00b7gen", ".", "Ich", "schw\u00f6\u00b7re", "\u2013", "da\u00df", "ich"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["NN", "VVINF", "$.", "PPER", "VVFIN", "$(", "KOUS", "PPER"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "die reine Wahrheit sagen \u2013 und nichts ver\u2013", "tokens": ["die", "rei\u00b7ne", "Wahr\u00b7heit", "sa\u00b7gen", "\u2013", "und", "nichts", "ver", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "$(", "KON", "PIS", "NE", "$("], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "schweigen \u2013 und nichts hinzusetzen werde.", "tokens": ["schwei\u00b7gen", "\u2013", "und", "nichts", "hin\u00b7zu\u00b7set\u00b7zen", "wer\u00b7de", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$(", "KON", "PIS", "VVINF", "VAFIN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.5": {"text": "So wahr mir Gott helfe!\u00ab", "tokens": ["So", "wahr", "mir", "Gott", "hel\u00b7fe", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "ADJD", "PPER", "NN", "VVFIN", "$.", "$("], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.6": {"text": "Wir standen da vor Klippermanns Lokal", "tokens": ["Wir", "stan\u00b7den", "da", "vor", "Klip\u00b7per\u00b7manns", "Lo\u00b7kal"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "NE", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "und dachten weiter gar nichts Schlimmes \u2013", "tokens": ["und", "dach\u00b7ten", "wei\u00b7ter", "gar", "nichts", "Schlim\u00b7mes", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ADV", "PIS", "ADJA", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "wir stehn so harmlos da . . . Mit einem Mal \u2013", "tokens": ["wir", "stehn", "so", "harm\u00b7los", "da", ".", ".", ".", "Mit", "ei\u00b7nem", "Mal", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADJD", "PTKVZ", "$.", "$.", "$.", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "ich sag noch zu Parteigenossen Kimmes \u2013", "tokens": ["ich", "sag", "noch", "zu", "Par\u00b7tei\u00b7ge\u00b7nos\u00b7sen", "Kim\u00b7mes", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "NE", "NE", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "ich sage: \u00bbKimmes!\u00ab sag ich \u2013 \u00bbwir gehn bald", "tokens": ["ich", "sa\u00b7ge", ":", "\u00bb", "Kim\u00b7mes", "!", "\u00ab", "sag", "ich", "\u2013", "\u00bb", "wir", "gehn", "bald"], "token_info": ["word", "word", "punct", "punct", "word", "punct", "punct", "word", "word", "punct", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$.", "$(", "NE", "$.", "$(", "VVIMP", "PPER", "$(", "$(", "PPER", "VVFIN", "ADV"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.11": {"text": "jetzt Bl\u00fcmchen pfl\u00fccken in den gr\u00fcnen Wald . . . \u00ab", "tokens": ["jetzt", "Bl\u00fcm\u00b7chen", "pfl\u00fc\u00b7cken", "in", "den", "gr\u00fc\u00b7nen", "Wald", ".", ".", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct", "punct"], "pos": ["ADV", "NN", "VVFIN", "APPR", "ART", "ADJA", "NN", "$.", "$.", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "Auf einmal kommen da die Kommunisten \u2013", "tokens": ["Auf", "ein\u00b7mal", "kom\u00b7men", "da", "die", "Kom\u00b7mu\u00b7nis\u00b7ten", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "VVFIN", "ADV", "ART", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "acht oder hundert St\u00fcck . . . ich wei\u00df genau!", "tokens": ["acht", "o\u00b7der", "hun\u00b7dert", "St\u00fcck", ".", ".", ".", "ich", "wei\u00df", "ge\u00b7nau", "!"], "token_info": ["word", "word", "word", "word", "punct", "punct", "punct", "word", "word", "word", "punct"], "pos": ["CARD", "KON", "CARD", "NN", "$.", "$.", "$.", "PPER", "VVFIN", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "und schlagen auf uns los und machen Kisten \u2013", "tokens": ["und", "schla\u00b7gen", "auf", "uns", "los", "und", "ma\u00b7chen", "Kis\u00b7ten", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PPER", "PTKVZ", "KON", "VVFIN", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.15": {"text": "an ihrer Spitze eine wilde Frau!", "tokens": ["an", "ih\u00b7rer", "Spit\u00b7ze", "ei\u00b7ne", "wil\u00b7de", "Frau", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.16": {"text": "Wir mu\u00dften alle rasch in Deckung gehn.", "tokens": ["Wir", "mu\u00df\u00b7ten", "al\u00b7le", "rasch", "in", "De\u00b7ckung", "gehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PIS", "ADJD", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.17": {"text": "Ob wir geschossen . . . ?", "tokens": ["Ob", "wir", "ge\u00b7schos\u00b7sen", ".", ".", ".", "?"], "token_info": ["word", "word", "word", "punct", "punct", "punct", "punct"], "pos": ["KOUS", "PPER", "VVPP", "$.", "$.", "$.", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.18": {"text": "Ich hab nichts gesehn.", "tokens": ["Ich", "hab", "nichts", "ge\u00b7sehn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIS", "VVPP", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}}, "stanza.2": {"line.1": {"text": "Der eine Kommunist trug in der Linken", "tokens": ["Der", "ei\u00b7ne", "Kom\u00b7mu\u00b7nist", "trug", "in", "der", "Lin\u00b7ken"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ART", "NN", "VVFIN", "APPR", "ART", "NN"], "meter": "-+-+-++--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "ein typisch russisches M. G.:", "tokens": ["ein", "ty\u00b7pisch", "rus\u00b7si\u00b7sches", "M.", "G.", ":"], "token_info": ["word", "word", "word", "abbreviation", "abbreviation", "punct"], "pos": ["ART", "ADJD", "ADJA", "NE", "NE", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "mit seiner rechten Hand, da t\u00e4t er winken \u2013", "tokens": ["mit", "sei\u00b7ner", "rech\u00b7ten", "Hand", ",", "da", "t\u00e4t", "er", "win\u00b7ken", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$,", "ADV", "VVFIN", "PPER", "VVFIN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "der andere Trupp stand vorn auf der Chaussee.", "tokens": ["der", "an\u00b7de\u00b7re", "Trupp", "stand", "vorn", "auf", "der", "Chaus\u00b7see", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.5": {"text": "Zwei Kommunisten sangen freche Lieder.", "tokens": ["Zwei", "Kom\u00b7mu\u00b7nis\u00b7ten", "san\u00b7gen", "fre\u00b7che", "Lie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "VVFIN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Wir waren harmlos, ruhig, doch emp\u00f6rt . . .", "tokens": ["Wir", "wa\u00b7ren", "harm\u00b7los", ",", "ru\u00b7hig", ",", "doch", "em\u00b7p\u00f6rt", ".", ".", "."], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "punct", "punct", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "$,", "ADJD", "$,", "ADV", "ADJD", "$.", "$.", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Ich kenn die Angeklagten alle wieder \u2013", "tokens": ["Ich", "kenn", "die", "An\u00b7ge\u00b7klag\u00b7ten", "al\u00b7le", "wie\u00b7der", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "PIS", "ADV", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Ob was . . . ? Geschossen . . . ?", "tokens": ["Ob", "was", ".", ".", ".", "?", "Ge\u00b7schos\u00b7sen", ".", ".", ".", "?"], "token_info": ["word", "word", "punct", "punct", "punct", "punct", "word", "punct", "punct", "punct", "punct"], "pos": ["KOUS", "PIS", "$.", "$.", "$.", "$.", "NN", "$.", "$.", "$.", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.9": {"text": "Ich hab nichts geh\u00f6rt.", "tokens": ["Ich", "hab", "nichts", "ge\u00b7h\u00f6rt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIS", "VVFIN", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}}, "stanza.3": {"line.1": {"text": "Wir gehn ja immer leis und sanft von hinnen.", "tokens": ["Wir", "gehn", "ja", "im\u00b7mer", "leis", "und", "sanft", "von", "hin\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "ADJD", "KON", "ADJD", "APPR", "ADV", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Wir trinken Milch, weil das die Muskeln st\u00e4rkt.", "tokens": ["Wir", "trin\u00b7ken", "Milch", ",", "weil", "das", "die", "Mus\u00b7keln", "st\u00e4rkt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "$,", "KOUS", "PDS", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Gestochen . . . ? wir . . . ? Ich kann mich nicht besinnen.", "tokens": ["Ge\u00b7sto\u00b7chen", ".", ".", ".", "?", "wir", ".", ".", ".", "?", "Ich", "kann", "mich", "nicht", "be\u00b7sin\u00b7nen", "."], "token_info": ["word", "punct", "punct", "punct", "punct", "word", "punct", "punct", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "$.", "$.", "$.", "PPER", "$.", "$.", "$.", "$.", "PPER", "VMFIN", "PPER", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Mit einem Dolch . . . ? Ich habe nichts bemerkt.", "tokens": ["Mit", "ei\u00b7nem", "Dolch", ".", ".", ".", "?", "Ich", "ha\u00b7be", "nichts", "be\u00b7merkt", "."], "token_info": ["word", "word", "word", "punct", "punct", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$.", "$.", "$.", "$.", "PPER", "VAFIN", "PIS", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Wir sind die friedlichste und stillste Blase.", "tokens": ["Wir", "sind", "die", "fried\u00b7lichs\u00b7te", "und", "stills\u00b7te", "Bla\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "KON", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Wir schw\u00f6ren vor den Schranken des Gerichts.", "tokens": ["Wir", "schw\u00f6\u00b7ren", "vor", "den", "Schran\u00b7ken", "des", "Ge\u00b7richts", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Man glaubt uns gem. Mein Name, der ist Hase:", "tokens": ["Man", "glaubt", "uns", "gem.", "Mein", "Na\u00b7me", ",", "der", "ist", "Ha\u00b7se", ":"], "token_info": ["word", "word", "word", "abbreviation", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "ADV", "PPOSAT", "NN", "$,", "PRELS", "VAFIN", "NE", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "ich wei\u00df von nichts \u2013 ich wei\u00df von nichts.", "tokens": ["ich", "wei\u00df", "von", "nichts", "\u2013", "ich", "wei\u00df", "von", "nichts", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PIS", "$(", "PPER", "VVFIN", "APPR", "PIS", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Der Kommunist wird feste arretiert.", "tokens": ["Der", "Kom\u00b7mu\u00b7nist", "wird", "fes\u00b7te", "ar\u00b7re\u00b7tiert", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Beweisen Sie uns mal das Gegenteil!", "tokens": ["Be\u00b7wei\u00b7sen", "Sie", "uns", "mal", "das", "Ge\u00b7gen\u00b7teil", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "So wahr mir Gott helfe.", "tokens": ["So", "wahr", "mir", "Gott", "hel\u00b7fe", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "NN", "VVFIN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.12": {"text": "Hitler Heil!", "tokens": ["Hit\u00b7ler", "Heil", "!"], "token_info": ["word", "word", "punct"], "pos": ["NN", "NN", "$."], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.4": {"line.1": {"text": "\u00bbich m\u00f6chte den Eid in der religi\u00f6sen", "tokens": ["\u00bb", "ich", "m\u00f6ch\u00b7te", "den", "Eid", "in", "der", "re\u00b7li\u00b7gi\u00b7\u00f6\u00b7sen"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "PPER", "VMFIN", "ART", "NN", "APPR", "ART", "ADJA"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.2": {"text": "Form ablegen. Ich schw\u00f6re \u2013 da\u00df ich", "tokens": ["Form", "ab\u00b7le\u00b7gen", ".", "Ich", "schw\u00f6\u00b7re", "\u2013", "da\u00df", "ich"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["NN", "VVINF", "$.", "PPER", "VVFIN", "$(", "KOUS", "PPER"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "die reine Wahrheit sagen \u2013 und nichts ver\u2013", "tokens": ["die", "rei\u00b7ne", "Wahr\u00b7heit", "sa\u00b7gen", "\u2013", "und", "nichts", "ver", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "$(", "KON", "PIS", "NE", "$("], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "schweigen \u2013 und nichts hinzusetzen werde.", "tokens": ["schwei\u00b7gen", "\u2013", "und", "nichts", "hin\u00b7zu\u00b7set\u00b7zen", "wer\u00b7de", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$(", "KON", "PIS", "VVINF", "VAFIN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.5": {"text": "So wahr mir Gott helfe!\u00ab", "tokens": ["So", "wahr", "mir", "Gott", "hel\u00b7fe", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "ADJD", "PPER", "NN", "VVFIN", "$.", "$("], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.6": {"text": "Wir standen da vor Klippermanns Lokal", "tokens": ["Wir", "stan\u00b7den", "da", "vor", "Klip\u00b7per\u00b7manns", "Lo\u00b7kal"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "NE", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "und dachten weiter gar nichts Schlimmes \u2013", "tokens": ["und", "dach\u00b7ten", "wei\u00b7ter", "gar", "nichts", "Schlim\u00b7mes", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ADV", "PIS", "ADJA", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "wir stehn so harmlos da . . . Mit einem Mal \u2013", "tokens": ["wir", "stehn", "so", "harm\u00b7los", "da", ".", ".", ".", "Mit", "ei\u00b7nem", "Mal", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADJD", "PTKVZ", "$.", "$.", "$.", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "ich sag noch zu Parteigenossen Kimmes \u2013", "tokens": ["ich", "sag", "noch", "zu", "Par\u00b7tei\u00b7ge\u00b7nos\u00b7sen", "Kim\u00b7mes", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "NE", "NE", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "ich sage: \u00bbKimmes!\u00ab sag ich \u2013 \u00bbwir gehn bald", "tokens": ["ich", "sa\u00b7ge", ":", "\u00bb", "Kim\u00b7mes", "!", "\u00ab", "sag", "ich", "\u2013", "\u00bb", "wir", "gehn", "bald"], "token_info": ["word", "word", "punct", "punct", "word", "punct", "punct", "word", "word", "punct", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$.", "$(", "NE", "$.", "$(", "VVIMP", "PPER", "$(", "$(", "PPER", "VVFIN", "ADV"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.11": {"text": "jetzt Bl\u00fcmchen pfl\u00fccken in den gr\u00fcnen Wald . . . \u00ab", "tokens": ["jetzt", "Bl\u00fcm\u00b7chen", "pfl\u00fc\u00b7cken", "in", "den", "gr\u00fc\u00b7nen", "Wald", ".", ".", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct", "punct"], "pos": ["ADV", "NN", "VVFIN", "APPR", "ART", "ADJA", "NN", "$.", "$.", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "Auf einmal kommen da die Kommunisten \u2013", "tokens": ["Auf", "ein\u00b7mal", "kom\u00b7men", "da", "die", "Kom\u00b7mu\u00b7nis\u00b7ten", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "VVFIN", "ADV", "ART", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "acht oder hundert St\u00fcck . . . ich wei\u00df genau!", "tokens": ["acht", "o\u00b7der", "hun\u00b7dert", "St\u00fcck", ".", ".", ".", "ich", "wei\u00df", "ge\u00b7nau", "!"], "token_info": ["word", "word", "word", "word", "punct", "punct", "punct", "word", "word", "word", "punct"], "pos": ["CARD", "KON", "CARD", "NN", "$.", "$.", "$.", "PPER", "VVFIN", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "und schlagen auf uns los und machen Kisten \u2013", "tokens": ["und", "schla\u00b7gen", "auf", "uns", "los", "und", "ma\u00b7chen", "Kis\u00b7ten", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PPER", "PTKVZ", "KON", "VVFIN", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.15": {"text": "an ihrer Spitze eine wilde Frau!", "tokens": ["an", "ih\u00b7rer", "Spit\u00b7ze", "ei\u00b7ne", "wil\u00b7de", "Frau", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.16": {"text": "Wir mu\u00dften alle rasch in Deckung gehn.", "tokens": ["Wir", "mu\u00df\u00b7ten", "al\u00b7le", "rasch", "in", "De\u00b7ckung", "gehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PIS", "ADJD", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.17": {"text": "Ob wir geschossen . . . ?", "tokens": ["Ob", "wir", "ge\u00b7schos\u00b7sen", ".", ".", ".", "?"], "token_info": ["word", "word", "word", "punct", "punct", "punct", "punct"], "pos": ["KOUS", "PPER", "VVPP", "$.", "$.", "$.", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.18": {"text": "Ich hab nichts gesehn.", "tokens": ["Ich", "hab", "nichts", "ge\u00b7sehn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIS", "VVPP", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}}, "stanza.5": {"line.1": {"text": "Der eine Kommunist trug in der Linken", "tokens": ["Der", "ei\u00b7ne", "Kom\u00b7mu\u00b7nist", "trug", "in", "der", "Lin\u00b7ken"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ART", "NN", "VVFIN", "APPR", "ART", "NN"], "meter": "-+-+-++--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "ein typisch russisches M. G.:", "tokens": ["ein", "ty\u00b7pisch", "rus\u00b7si\u00b7sches", "M.", "G.", ":"], "token_info": ["word", "word", "word", "abbreviation", "abbreviation", "punct"], "pos": ["ART", "ADJD", "ADJA", "NE", "NE", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "mit seiner rechten Hand, da t\u00e4t er winken \u2013", "tokens": ["mit", "sei\u00b7ner", "rech\u00b7ten", "Hand", ",", "da", "t\u00e4t", "er", "win\u00b7ken", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$,", "ADV", "VVFIN", "PPER", "VVFIN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "der andere Trupp stand vorn auf der Chaussee.", "tokens": ["der", "an\u00b7de\u00b7re", "Trupp", "stand", "vorn", "auf", "der", "Chaus\u00b7see", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.5": {"text": "Zwei Kommunisten sangen freche Lieder.", "tokens": ["Zwei", "Kom\u00b7mu\u00b7nis\u00b7ten", "san\u00b7gen", "fre\u00b7che", "Lie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "VVFIN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Wir waren harmlos, ruhig, doch emp\u00f6rt . . .", "tokens": ["Wir", "wa\u00b7ren", "harm\u00b7los", ",", "ru\u00b7hig", ",", "doch", "em\u00b7p\u00f6rt", ".", ".", "."], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "punct", "punct", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "$,", "ADJD", "$,", "ADV", "ADJD", "$.", "$.", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Ich kenn die Angeklagten alle wieder \u2013", "tokens": ["Ich", "kenn", "die", "An\u00b7ge\u00b7klag\u00b7ten", "al\u00b7le", "wie\u00b7der", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "PIS", "ADV", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Ob was . . . ? Geschossen . . . ?", "tokens": ["Ob", "was", ".", ".", ".", "?", "Ge\u00b7schos\u00b7sen", ".", ".", ".", "?"], "token_info": ["word", "word", "punct", "punct", "punct", "punct", "word", "punct", "punct", "punct", "punct"], "pos": ["KOUS", "PIS", "$.", "$.", "$.", "$.", "NN", "$.", "$.", "$.", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.9": {"text": "Ich hab nichts geh\u00f6rt.", "tokens": ["Ich", "hab", "nichts", "ge\u00b7h\u00f6rt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIS", "VVFIN", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}}, "stanza.6": {"line.1": {"text": "Wir gehn ja immer leis und sanft von hinnen.", "tokens": ["Wir", "gehn", "ja", "im\u00b7mer", "leis", "und", "sanft", "von", "hin\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "ADJD", "KON", "ADJD", "APPR", "ADV", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Wir trinken Milch, weil das die Muskeln st\u00e4rkt.", "tokens": ["Wir", "trin\u00b7ken", "Milch", ",", "weil", "das", "die", "Mus\u00b7keln", "st\u00e4rkt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "$,", "KOUS", "PDS", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Gestochen . . . ? wir . . . ? Ich kann mich nicht besinnen.", "tokens": ["Ge\u00b7sto\u00b7chen", ".", ".", ".", "?", "wir", ".", ".", ".", "?", "Ich", "kann", "mich", "nicht", "be\u00b7sin\u00b7nen", "."], "token_info": ["word", "punct", "punct", "punct", "punct", "word", "punct", "punct", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "$.", "$.", "$.", "PPER", "$.", "$.", "$.", "$.", "PPER", "VMFIN", "PPER", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Mit einem Dolch . . . ? Ich habe nichts bemerkt.", "tokens": ["Mit", "ei\u00b7nem", "Dolch", ".", ".", ".", "?", "Ich", "ha\u00b7be", "nichts", "be\u00b7merkt", "."], "token_info": ["word", "word", "word", "punct", "punct", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$.", "$.", "$.", "$.", "PPER", "VAFIN", "PIS", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Wir sind die friedlichste und stillste Blase.", "tokens": ["Wir", "sind", "die", "fried\u00b7lichs\u00b7te", "und", "stills\u00b7te", "Bla\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "KON", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Wir schw\u00f6ren vor den Schranken des Gerichts.", "tokens": ["Wir", "schw\u00f6\u00b7ren", "vor", "den", "Schran\u00b7ken", "des", "Ge\u00b7richts", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Man glaubt uns gem. Mein Name, der ist Hase:", "tokens": ["Man", "glaubt", "uns", "gem.", "Mein", "Na\u00b7me", ",", "der", "ist", "Ha\u00b7se", ":"], "token_info": ["word", "word", "word", "abbreviation", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "ADV", "PPOSAT", "NN", "$,", "PRELS", "VAFIN", "NE", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "ich wei\u00df von nichts \u2013 ich wei\u00df von nichts.", "tokens": ["ich", "wei\u00df", "von", "nichts", "\u2013", "ich", "wei\u00df", "von", "nichts", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PIS", "$(", "PPER", "VVFIN", "APPR", "PIS", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Der Kommunist wird feste arretiert.", "tokens": ["Der", "Kom\u00b7mu\u00b7nist", "wird", "fes\u00b7te", "ar\u00b7re\u00b7tiert", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Beweisen Sie uns mal das Gegenteil!", "tokens": ["Be\u00b7wei\u00b7sen", "Sie", "uns", "mal", "das", "Ge\u00b7gen\u00b7teil", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "So wahr mir Gott helfe.", "tokens": ["So", "wahr", "mir", "Gott", "hel\u00b7fe", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "NN", "VVFIN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.12": {"text": "Hitler Heil!", "tokens": ["Hit\u00b7ler", "Heil", "!"], "token_info": ["word", "word", "punct"], "pos": ["NN", "NN", "$."], "meter": "+-+", "measure": "trochaic.di"}}}}}