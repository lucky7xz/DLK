{"textgrid.poem.26394": {"metadata": {"author": {"name": "Dauthendey, Max", "birth": "N.A.", "death": "N.A."}, "title": "1L: \u00bbja,\u00ab kam's von einer Andern", "genre": "verse", "period": "N.A.", "pub_year": 1892, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "\u00bbja,\u00ab kam's von einer Andern", "tokens": ["\u00bb", "ja", ",", "\u00ab", "kam's", "von", "ei\u00b7ner", "An\u00b7dern"], "token_info": ["punct", "word", "punct", "punct", "word", "word", "word", "word"], "pos": ["$(", "PTKANT", "$,", "$(", "VVFIN", "APPR", "ART", "ADJA"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "\u00bbhab's Herrn Heinz nie verdacht,", "tokens": ["\u00bb", "hab's", "Herrn", "Heinz", "nie", "ver\u00b7dacht", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VAFIN", "NN", "NE", "ADV", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Sein Herz tat flei\u00dfig wandern,", "tokens": ["Sein", "Herz", "tat", "flei\u00b7\u00dfig", "wan\u00b7dern", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Es war dazu gemacht.", "tokens": ["Es", "war", "da\u00b7zu", "ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PAV", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Auch meine Frau tut gleichen", "tokens": ["Auch", "mei\u00b7ne", "Frau", "tut", "glei\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "PPOSAT", "NN", "VVFIN", "ADJA"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Der Frau Brigitte sehr.", "tokens": ["Der", "Frau", "Bri\u00b7git\u00b7te", "sehr", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NE", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Zwei M\u00e4nner, ganz als Leichen,", "tokens": ["Zwei", "M\u00e4n\u00b7ner", ",", "ganz", "als", "Lei\u00b7chen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "$,", "ADV", "KOUS", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Gab sie f\u00fcr Heinzen her.\u00ab", "tokens": ["Gab", "sie", "f\u00fcr", "Hein\u00b7zen", "her", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PPER", "APPR", "NN", "PTKVZ", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Die sieben andern Ammen", "tokens": ["Die", "sie\u00b7ben", "an\u00b7dern", "Am\u00b7men"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "CARD", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Taten ans Herz sich fassen.", "tokens": ["Ta\u00b7ten", "ans", "Herz", "sich", "fas\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPRART", "NN", "PRF", "VVINF", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.3": {"text": "Sie r\u00fcckten eng zusammen", "tokens": ["Sie", "r\u00fcck\u00b7ten", "eng", "zu\u00b7sam\u00b7men"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADJD", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und stellten fort die Tassen.", "tokens": ["Und", "stell\u00b7ten", "fort", "die", "Tas\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKVZ", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "\u00bbdie F\u00fcrstin\u00ab, sprach die Eine", "tokens": ["\u00bb", "die", "F\u00fcrs\u00b7tin", "\u00ab", ",", "sprach", "die", "Ei\u00b7ne"], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "word"], "pos": ["$(", "ART", "NN", "$(", "$,", "VVFIN", "ART", "ART"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Und wischte sich den Mund,", "tokens": ["Und", "wischte", "sich", "den", "Mund", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "ART", "NN", "$,"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.3": {"text": "\u00bbwarf Perlen vor die Schweine", "tokens": ["\u00bb", "warf", "Per\u00b7len", "vor", "die", "Schwei\u00b7ne"], "token_info": ["punct", "word", "word", "word", "word", "word"], "pos": ["$(", "VVFIN", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "In ihrer Hochzeitsstund.\u00ab", "tokens": ["In", "ih\u00b7rer", "Hoch\u00b7zeits\u00b7stund", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Es ward Bonaventura", "tokens": ["Es", "ward", "Bo\u00b7na\u00b7ven\u00b7tu\u00b7ra"], "token_info": ["word", "word", "word"], "pos": ["PPER", "VAFIN", "NE"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Bald untreu ihrem Mann.", "tokens": ["Bald", "un\u00b7treu", "ih\u00b7rem", "Mann", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Weil von ihm kaum 'ne Spur da,", "tokens": ["Weil", "von", "ihm", "kaum", "'ne", "Spur", "da", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "PPER", "ADV", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Von dem, was da sein kann.", "tokens": ["Von", "dem", ",", "was", "da", "sein", "kann", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "$,", "PRELS", "ADV", "VAINF", "VMFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Mit einem Wort, es lebte", "tokens": ["Mit", "ei\u00b7nem", "Wort", ",", "es", "leb\u00b7te"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "ART", "NN", "$,", "PPER", "VVFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Der F\u00fcrst nur von Morphin.", "tokens": ["Der", "F\u00fcrst", "nur", "von", "Mor\u00b7phin", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "APPR", "NE", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Der F\u00fcrstin widerstrebte", "tokens": ["Der", "F\u00fcrs\u00b7tin", "wi\u00b7der\u00b7streb\u00b7te"], "token_info": ["word", "word", "word"], "pos": ["ART", "NN", "VVFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Alles, was Medizin.", "tokens": ["Al\u00b7les", ",", "was", "Me\u00b7di\u00b7zin", "."], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["PIS", "$,", "PRELS", "NE", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}}, "stanza.7": {"line.1": {"text": "Sie f\u00fchlte sich verstanden", "tokens": ["Sie", "f\u00fchl\u00b7te", "sich", "ver\u00b7stan\u00b7den"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PRF", "VVPP"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Vom Attach\u00e9 de l'O ....,", "tokens": ["Vom", "At\u00b7ta\u00b7ch\u00e9", "de", "l'O", "....", ","], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "$(", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und da sie sich schon kannten,", "tokens": ["Und", "da", "sie", "sich", "schon", "kann\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PRF", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Traf man sich leicht mal wo.", "tokens": ["Traf", "man", "sich", "leicht", "mal", "wo", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PRF", "ADJD", "ADV", "PWAV", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}}, "stanza.8": {"line.1": {"text": "Sie kam im dichten Schleier", "tokens": ["Sie", "kam", "im", "dich\u00b7ten", "Schlei\u00b7er"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Zum ersten Rendez-vous.", "tokens": ["Zum", "ers\u00b7ten", "Ren\u00b7de\u00b7zvous", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Im Wald f\u00fchlt man sich freier,", "tokens": ["Im", "Wald", "f\u00fchlt", "man", "sich", "frei\u00b7er", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PIS", "PRF", "ADJD", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Nur B\u00e4ume sehen zu.", "tokens": ["Nur", "B\u00e4u\u00b7me", "se\u00b7hen", "zu", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Doch wie die F\u00fcrstin schw\u00e4rmend", "tokens": ["Doch", "wie", "die", "F\u00fcrs\u00b7tin", "schw\u00e4r\u00b7mend"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "ART", "NN", "ADJD"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Anschaut den Attach\u00e9,", "tokens": ["An\u00b7schaut", "den", "At\u00b7ta\u00b7ch\u00e9", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Schien er ihr nicht erw\u00e4rmend,", "tokens": ["Schien", "er", "ihr", "nicht", "er\u00b7w\u00e4r\u00b7mend", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Weil jemand in der N\u00e4h.", "tokens": ["Weil", "je\u00b7mand", "in", "der", "N\u00e4h", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "APPR", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "Ein Mann suchte f\u00fcr Tinte", "tokens": ["Ein", "Mann", "such\u00b7te", "f\u00fcr", "Tin\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "APPR", "NN"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.2": {"text": "Gall\u00e4pfel, und es blitzt", "tokens": ["Gal\u00b7l\u00e4p\u00b7fel", ",", "und", "es", "blitzt"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "KON", "PPER", "VVFIN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Sein Aug wie eine Flinte,", "tokens": ["Sein", "Aug", "wie", "ei\u00b7ne", "Flin\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KOKOM", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Sein Blick, der zielt und sitzt.", "tokens": ["Sein", "Blick", ",", "der", "zielt", "und", "sitzt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PRELS", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "Der Mann folgt ihren Schritten,", "tokens": ["Der", "Mann", "folgt", "ih\u00b7ren", "Schrit\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Zuerst war sie emp\u00f6rt.", "tokens": ["Zu\u00b7erst", "war", "sie", "em\u00b7p\u00f6rt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "VVFIN", "$."], "meter": "--+--+", "measure": "anapaest.di.plus"}, "line.3": {"text": "Er hat in Waldesmitten", "tokens": ["Er", "hat", "in", "Wal\u00b7des\u00b7mit\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "APPR", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Ihr Rendez-vous gest\u00f6rt.", "tokens": ["Ihr", "Ren\u00b7de\u00b7zvous", "ge\u00b7st\u00f6rt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "Und auch am n\u00e4chsten Tage", "tokens": ["Und", "auch", "am", "n\u00e4chs\u00b7ten", "Ta\u00b7ge"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "War \u00fcberall er da.", "tokens": ["War", "\u00fc\u00b7be\u00b7rall", "er", "da", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PPER", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Der Wald ward eine Plage", "tokens": ["Der", "Wald", "ward", "ei\u00b7ne", "Pla\u00b7ge"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Frau Bonaventura.", "tokens": ["Frau", "Bo\u00b7na\u00b7ven\u00b7tu\u00b7ra", "."], "token_info": ["word", "word", "punct"], "pos": ["NN", "NE", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.13": {"line.1": {"text": "Gewisse Augen sitzen", "tokens": ["Ge\u00b7wis\u00b7se", "Au\u00b7gen", "sit\u00b7zen"], "token_info": ["word", "word", "word"], "pos": ["NN", "NN", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Von manchem Mannsgesicht.", "tokens": ["Von", "man\u00b7chem", "Manns\u00b7ge\u00b7sicht", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Dann mu\u00df jed' Weib erhitzen,", "tokens": ["Dann", "mu\u00df", "jed'", "Weib", "er\u00b7hit\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PIAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Will sie es oder nicht.", "tokens": ["Will", "sie", "es", "o\u00b7der", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PPER", "KON", "PTKNEG", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.14": {"line.1": {"text": "Sie konnt ihn nicht vergessen.", "tokens": ["Sie", "konnt", "ihn", "nicht", "ver\u00b7ges\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Und er, der so geschaut,", "tokens": ["Und", "er", ",", "der", "so", "ge\u00b7schaut", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "$,", "PRELS", "ADV", "VVPP", "$,"], "meter": "--+--+", "measure": "anapaest.di.plus"}, "line.3": {"text": "Das ist Herr Heinz gewesen \u2013", "tokens": ["Das", "ist", "Herr", "Heinz", "ge\u00b7we\u00b7sen", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "NN", "NE", "VAPP", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Sein Herz nahm sie zur Braut.", "tokens": ["Sein", "Herz", "nahm", "sie", "zur", "Braut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "APPRART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.15": {"line.1": {"text": "Der Attach\u00e9, nicht n\u00e4her", "tokens": ["Der", "At\u00b7ta\u00b7ch\u00e9", ",", "nicht", "n\u00e4\u00b7her"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "$,", "PTKNEG", "ADJD"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "War der von Heinz entz\u00fcckt", "tokens": ["War", "der", "von", "Heinz", "ent\u00b7z\u00fcckt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "ART", "APPR", "NE", "VVPP"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.3": {"text": "Er glaubt, es w\u00e4r ein Sp\u00e4her", "tokens": ["Er", "glaubt", ",", "es", "w\u00e4r", "ein", "Sp\u00e4\u00b7her"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VAFIN", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Vom F\u00fcrsten ausgeschickt.", "tokens": ["Vom", "F\u00fcrs\u00b7ten", "aus\u00b7ge\u00b7schickt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.16": {"line.1": {"text": "Darum schlug er zur Schonung,", "tokens": ["Da\u00b7rum", "schlug", "er", "zur", "Scho\u00b7nung", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "APPRART", "NN", "$,"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.2": {"text": "F\u00fcr Auge und f\u00fcr Ohr,", "tokens": ["F\u00fcr", "Au\u00b7ge", "und", "f\u00fcr", "Ohr", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "APPR", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Auf morgen seine Wohnung", "tokens": ["Auf", "mor\u00b7gen", "sei\u00b7ne", "Woh\u00b7nung"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ADV", "PPOSAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Als Rendez-vousplatz vor.", "tokens": ["Als", "Ren\u00b7de\u00b7zvous\u00b7platz", "vor", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KOUS", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.17": {"line.1": {"text": "Die F\u00fcrstin in Gedanken", "tokens": ["Die", "F\u00fcrs\u00b7tin", "in", "Ge\u00b7dan\u00b7ken"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Sagt' gleichg\u00fcltig nur: Ja.", "tokens": ["Sagt'", "gleich\u00b7g\u00fcl\u00b7tig", "nur", ":", "Ja", "."], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["VVFIN", "ADJD", "ADV", "$.", "PTKANT", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Denn bei den Liebeskranken", "tokens": ["Denn", "bei", "den", "Lie\u00b7bes\u00b7kran\u00b7ken"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Ist wenig Stimme da.", "tokens": ["Ist", "we\u00b7nig", "Stim\u00b7me", "da", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.18": {"line.1": {"text": "F\u00fcrstin Bonaventura", "tokens": ["F\u00fcrs\u00b7tin", "Bo\u00b7na\u00b7ven\u00b7tu\u00b7ra"], "token_info": ["word", "word"], "pos": ["NE", "NE"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.2": {"text": "Hat sich nicht eingestellt.", "tokens": ["Hat", "sich", "nicht", "ein\u00b7ge\u00b7stellt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PRF", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Sie fand, 's w\u00e4r mehr Natur da,", "tokens": ["Sie", "fand", ",", "'s", "w\u00e4r", "mehr", "Na\u00b7tur", "da", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VAFIN", "PIAT", "NN", "PTKVZ", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Wenn sie den Waldweg w\u00e4hlt.", "tokens": ["Wenn", "sie", "den", "Wald\u00b7weg", "w\u00e4hlt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.19": {"line.1": {"text": "Und diesmal wich die F\u00fcrstin", "tokens": ["Und", "dies\u00b7mal", "wich", "die", "F\u00fcrs\u00b7tin"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Dem Augenblick nicht aus,", "tokens": ["Dem", "Au\u00b7gen\u00b7blick", "nicht", "aus", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKNEG", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Sie lehnte sich an Heinz hin,", "tokens": ["Sie", "lehn\u00b7te", "sich", "an", "Heinz", "hin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "NE", "PTKVZ", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Sprach: \u00bbHier bin ich zu Haus.\u00ab", "tokens": ["Sprach", ":", "\u00bb", "Hier", "bin", "ich", "zu", "Haus", ".", "\u00ab"], "token_info": ["word", "punct", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "$.", "$(", "ADV", "VAFIN", "PPER", "APPR", "NN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.20": {"line.1": {"text": "Denn bei ihm fand sie Sprache,", "tokens": ["Denn", "bei", "ihm", "fand", "sie", "Spra\u00b7che", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPER", "VVFIN", "PPER", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Er schw\u00f6rt bei jedem Ku\u00df.", "tokens": ["Er", "schw\u00f6rt", "bei", "je\u00b7dem", "Ku\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Nat\u00fcrlich war die Sache", "tokens": ["Na\u00b7t\u00fcr\u00b7lich", "war", "die", "Sa\u00b7che"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und nicht blo\u00df, weil man mu\u00df.", "tokens": ["Und", "nicht", "blo\u00df", ",", "weil", "man", "mu\u00df", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "ADV", "$,", "KOUS", "PIS", "VMFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.21": {"line.1": {"text": "Er tat nicht Galle suchen,", "tokens": ["Er", "tat", "nicht", "Gal\u00b7le", "su\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Er suchte ihren Mund.", "tokens": ["Er", "such\u00b7te", "ih\u00b7ren", "Mund", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und unter grauen Buchen,", "tokens": ["Und", "un\u00b7ter", "grau\u00b7en", "Bu\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Da trieben sie es bunt.", "tokens": ["Da", "trie\u00b7ben", "sie", "es", "bunt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.22": {"line.1": {"text": "Wie Zweige vom Epheue", "tokens": ["Wie", "Zwei\u00b7ge", "vom", "E\u00b7pheu\u00b7e"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "NN", "APPRART", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "War Leib an Leib gerankt.", "tokens": ["War", "Leib", "an", "Leib", "ge\u00b7rankt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Sie schwuren schwere Treue,", "tokens": ["Sie", "schwu\u00b7ren", "schwe\u00b7re", "Treu\u00b7e", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und niemals w\u00fcrd' gezankt.", "tokens": ["Und", "nie\u00b7mals", "w\u00fcrd'", "ge\u00b7zankt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.23": {"line.1": {"text": "Sie konnt' ihn los nicht lassen,", "tokens": ["Sie", "konnt'", "ihn", "los", "nicht", "las\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Noch wie der Mond aufging,", "tokens": ["Noch", "wie", "der", "Mond", "auf\u00b7ging", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "K\u00fc\u00dft sie ihn ohne Ma\u00dfen \u2013", "tokens": ["K\u00fc\u00dft", "sie", "ihn", "oh\u00b7ne", "Ma\u00b7\u00dfen", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "APPR", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Der Wald fast Feuer fing.", "tokens": ["Der", "Wald", "fast", "Feu\u00b7er", "fing", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.24": {"line.1": {"text": "Sie sprach: \u00bbIch bin entschlossen,", "tokens": ["Sie", "sprach", ":", "\u00bb", "Ich", "bin", "ent\u00b7schlos\u00b7sen", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "$(", "PPER", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Noch heute rei\u00df ich aus,", "tokens": ["Noch", "heu\u00b7te", "rei\u00df", "ich", "aus", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "In meiner Staatskarossen", "tokens": ["In", "mei\u00b7ner", "Staats\u00b7ka\u00b7ros\u00b7sen"], "token_info": ["word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Fliehn wir zur Stadt hinaus.\u00ab", "tokens": ["Fliehn", "wir", "zur", "Stadt", "hin\u00b7aus", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PPER", "APPRART", "NN", "PTKVZ", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.25": {"line.1": {"text": "Sie nahm all ihre Broschen", "tokens": ["Sie", "nahm", "all", "ih\u00b7re", "Bro\u00b7schen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PIAT", "PPOSAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Und's silberne Besteck.", "tokens": ["Un\u00b7d's", "sil\u00b7ber\u00b7ne", "Be\u00b7steck", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Der F\u00fcrst fror in Galoschen,", "tokens": ["Der", "F\u00fcrst", "fror", "in", "Ga\u00b7lo\u00b7schen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "NN", "$,"], "meter": "-+--+--", "measure": "iambic.di.relaxed"}, "line.4": {"text": "Starb Mittags noch am Schreck.", "tokens": ["Starb", "Mit\u00b7tags", "noch", "am", "Schreck", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADV", "APPRART", "NN", "$."], "meter": "--+--+", "measure": "anapaest.di.plus"}}, "stanza.26": {"line.1": {"text": "Herr Heinz und seine F\u00fcrstin,", "tokens": ["Herr", "Heinz", "und", "sei\u00b7ne", "F\u00fcrs\u00b7tin", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "KON", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Sie flohn durch Feld und Stra\u00df'.", "tokens": ["Sie", "flohn", "durch", "Feld", "und", "Stra\u00df'", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Die Pferde flogen glatthin,", "tokens": ["Die", "Pfer\u00b7de", "flo\u00b7gen", "glat\u00b7thin", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Weil nichts im Wege sa\u00df.", "tokens": ["Weil", "nichts", "im", "We\u00b7ge", "sa\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.27": {"line.1": {"text": "Doch an dem n\u00e4chsten Flecken", "tokens": ["Doch", "an", "dem", "n\u00e4chs\u00b7ten", "Fle\u00b7cken"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Traf sie ein langer Brief;", "tokens": ["Traf", "sie", "ein", "lan\u00b7ger", "Brief", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und dieser tat bezwecken,", "tokens": ["Und", "die\u00b7ser", "tat", "be\u00b7zwe\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PDAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Da\u00df nachts man nicht mehr schlief.", "tokens": ["Da\u00df", "nachts", "man", "nicht", "mehr", "schlief", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "PIS", "PTKNEG", "ADV", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.28": {"line.1": {"text": "Der Attach\u00e9 schrieb klagend:", "tokens": ["Der", "At\u00b7ta\u00b7ch\u00e9", "schrieb", "kla\u00b7gend", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Er wollt' sie nochmals sehn,", "tokens": ["Er", "wollt'", "sie", "noch\u00b7mals", "sehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "VVINF", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Der F\u00fcrstin Lebwohl sagend,", "tokens": ["Der", "F\u00fcrs\u00b7tin", "Leb\u00b7wohl", "sa\u00b7gend", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Nur so k\u00f6nnt' er bestehn.", "tokens": ["Nur", "so", "k\u00f6nnt'", "er", "be\u00b7stehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VMFIN", "PPER", "VVINF", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}}, "stanza.29": {"line.1": {"text": "Er sei im st\u00e4dt'schen Garten", "tokens": ["Er", "sei", "im", "st\u00e4dt'\u00b7schen", "Gar\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Mittags von eins bis zwei.", "tokens": ["Mit\u00b7tags", "von", "eins", "bis", "zwei", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PIS", "APPR", "CARD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und m\u00f6cht' nicht l\u00e4nger warten,", "tokens": ["Und", "m\u00f6cht'", "nicht", "l\u00e4n\u00b7ger", "war\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PTKNEG", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Auf's H\u00f6chst' bis Viertel drei!", "tokens": ["Auf's", "H\u00f6chst'", "bis", "Vier\u00b7tel", "drei", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPR", "NN", "CARD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.30": {"line.1": {"text": "Und sei sie nicht entschlossen", "tokens": ["Und", "sei", "sie", "nicht", "ent\u00b7schlos\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "PPER", "PTKNEG", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Und k\u00e4me nicht genau,", "tokens": ["Und", "k\u00e4\u00b7me", "nicht", "ge\u00b7nau", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKNEG", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "So h\u00e4tt' er sich erschossen \u2013", "tokens": ["So", "h\u00e4tt'", "er", "sich", "er\u00b7schos\u00b7sen", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PRF", "VVPP", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Er sch\u00f6sse nicht in's Blau.", "tokens": ["Er", "sch\u00f6s\u00b7se", "nicht", "in's", "Blau", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "APPRART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.31": {"line.1": {"text": "Die Frau wollt' er verfluchen,", "tokens": ["Die", "Frau", "wollt'", "er", "ver\u00b7flu\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Dies Weib, das ihn bet\u00f6rt;", "tokens": ["Dies", "Weib", ",", "das", "ihn", "be\u00b7t\u00f6rt", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "NN", "$,", "PRELS", "PPER", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Sein Geist w\u00fcrd' sie aufsuchen,", "tokens": ["Sein", "Geist", "w\u00fcrd'", "sie", "auf\u00b7su\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Auch wenn er n\u00e4chtlich st\u00f6rt.", "tokens": ["Auch", "wenn", "er", "n\u00e4cht\u00b7lich", "st\u00f6rt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PPER", "ADJD", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.32": {"line.1": {"text": "Die F\u00fcrstin las das Schreiben", "tokens": ["Die", "F\u00fcrs\u00b7tin", "las", "das", "Schrei\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Dem Heinzen, Satz um Satz.", "tokens": ["Dem", "Hein\u00b7zen", ",", "Satz", "um", "Satz", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "NN", "APPR", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Heinz zwang sie nicht zu bleiben,", "tokens": ["Heinz", "zwang", "sie", "nicht", "zu", "blei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "PTKNEG", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Sprach: \u00bbGeh hin, sch\u00f6nster Schatz!", "tokens": ["Sprach", ":", "\u00bb", "Geh", "hin", ",", "sch\u00f6ns\u00b7ter", "Schatz", "!"], "token_info": ["word", "punct", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$.", "$(", "NE", "PTKVZ", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.33": {"line.1": {"text": "Hast meine warmen K\u00fcsse", "tokens": ["Hast", "mei\u00b7ne", "war\u00b7men", "K\u00fcs\u00b7se"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Als einen Talisman,", "tokens": ["Als", "ei\u00b7nen", "Ta\u00b7lis\u00b7man", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "$,"], "meter": "-+-+--", "measure": "unknown.measure.di"}, "line.3": {"text": "So da\u00df Revolversch\u00fcsse", "tokens": ["So", "da\u00df", "Re\u00b7vol\u00b7ver\u00b7sch\u00fcs\u00b7se"], "token_info": ["word", "word", "word"], "pos": ["ADV", "KOUS", "NN"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.4": {"text": "Und Dolch nichts schaden kann.\u00ab", "tokens": ["Und", "Dolch", "nichts", "scha\u00b7den", "kann", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "NN", "PIS", "VVINF", "VMFIN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.34": {"line.1": {"text": "Die F\u00fcrstin ging zum Garten,", "tokens": ["Die", "F\u00fcrs\u00b7tin", "ging", "zum", "Gar\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Wie Heinzen ihr's empfahl.", "tokens": ["Wie", "Hein\u00b7zen", "ih\u00b7r's", "emp\u00b7fahl", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "PPER", "VVFIN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Sie tat bis zwei Uhr warten", "tokens": ["Sie", "tat", "bis", "zwei", "Uhr", "war\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "CARD", "NN", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und tat es ohne Qual.", "tokens": ["Und", "tat", "es", "oh\u00b7ne", "Qual", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.35": {"line.1": {"text": "An Heinz dacht' sie best\u00e4ndig,", "tokens": ["An", "Heinz", "dacht'", "sie", "be\u00b7st\u00e4n\u00b7dig", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VVFIN", "PPER", "ADJD", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Um zwei ging sie nach Haus.", "tokens": ["Um", "zwei", "ging", "sie", "nach", "Haus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "CARD", "VVFIN", "PPER", "APPR", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Froh, da\u00df sie ganz lebendig,", "tokens": ["Froh", ",", "da\u00df", "sie", "ganz", "le\u00b7ben\u00b7dig", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "KOUS", "PPER", "ADV", "ADJD", "$,"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.4": {"text": "Zog sie die Uhr heraus.", "tokens": ["Zog", "sie", "die", "Uhr", "he\u00b7raus", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.36": {"line.1": {"text": "Schob sacht den Zeiger weiter,", "tokens": ["Schob", "sacht", "den", "Zei\u00b7ger", "wei\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ART", "NN", "PTKVZ", "$,"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.2": {"text": "Den sie vorher verstellt.", "tokens": ["Den", "sie", "vor\u00b7her", "ver\u00b7stellt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "VVPP", "$."], "meter": "---+-+", "measure": "unknown.measure.di"}, "line.3": {"text": "Denn deshalb hat sie leider", "tokens": ["Denn", "des\u00b7halb", "hat", "sie", "lei\u00b7der"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PAV", "VAFIN", "PPER", "ADV"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Das Rendez-vous verfehlt.", "tokens": ["Das", "Ren\u00b7de\u00b7zvous", "ver\u00b7fehlt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.37": {"line.1": {"text": "Sie hat sich schlau gerettet", "tokens": ["Sie", "hat", "sich", "schlau", "ge\u00b7ret\u00b7tet"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PRF", "ADJD", "VVPP"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Aus dieser schweren Stund.", "tokens": ["Aus", "die\u00b7ser", "schwe\u00b7ren", "Stund", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und Heinz hat recht gewettet:", "tokens": ["Und", "Heinz", "hat", "recht", "ge\u00b7wet\u00b7tet", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "VAFIN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Sie kehrte heim gesund.", "tokens": ["Sie", "kehr\u00b7te", "heim", "ge\u00b7sund", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKVZ", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.38": {"line.1": {"text": "Doch abends, da sie eben", "tokens": ["Doch", "a\u00b7bends", ",", "da", "sie", "e\u00b7ben"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["KON", "ADV", "$,", "KOUS", "PPER", "ADV"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Im Bett ihr Haar aufsteckt,", "tokens": ["Im", "Bett", "ihr", "Haar", "auf\u00b7steckt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Sieht sie was Wei\u00dfes schweben.", "tokens": ["Sieht", "sie", "was", "Wei\u00b7\u00dfes", "schwe\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PIS", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Was Sch\u00fcttelfrost erweckt.", "tokens": ["Was", "Sch\u00fct\u00b7tel\u00b7frost", "er\u00b7weckt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PWS", "NN", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.39": {"line.1": {"text": "Sie mu\u00df ans Bettend starren,", "tokens": ["Sie", "mu\u00df", "ans", "Bet\u00b7tend", "star\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Als m\u00fc\u00dft' dort Jemand stehn.", "tokens": ["Als", "m\u00fc\u00dft'", "dort", "Je\u00b7mand", "stehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VMFIN", "ADV", "PIS", "VVINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Mit Angst in allen Haaren", "tokens": ["Mit", "Angst", "in", "al\u00b7len", "Haa\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "APPR", "PIAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Mu\u00df sie das Wei\u00dfe sehn.", "tokens": ["Mu\u00df", "sie", "das", "Wei\u00b7\u00dfe", "sehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.40": {"line.1": {"text": "Heinz sagt, es ist 'ne Falte", "tokens": ["Heinz", "sagt", ",", "es", "ist", "'ne", "Fal\u00b7te"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "$,", "PPER", "VAFIN", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Im Vorhang. 'S geht nicht fort.", "tokens": ["Im", "Vor\u00b7hang", ".", "'s", "geht", "nicht", "fort", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$.", "NE", "VVFIN", "PTKNEG", "PTKVZ", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Sie f\u00fchlt die Luft, die kalte, \u2013", "tokens": ["Sie", "f\u00fchlt", "die", "Luft", ",", "die", "kal\u00b7te", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "ART", "ADJA", "$,", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Der Attach\u00e9 sitzt dort.", "tokens": ["Der", "At\u00b7ta\u00b7ch\u00e9", "sitzt", "dort", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.41": {"line.1": {"text": "Sie floh in Schreckensn\u00f6ten", "tokens": ["Sie", "floh", "in", "Schre\u00b7ckens\u00b7n\u00f6\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Zu Heinz unter die Deck.", "tokens": ["Zu", "Heinz", "un\u00b7ter", "die", "Deck", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "APPR", "ART", "NN", "$."], "meter": "--+--+", "measure": "anapaest.di.plus"}, "line.3": {"text": "Da mu\u00df der Geist err\u00f6ten,", "tokens": ["Da", "mu\u00df", "der", "Geist", "er\u00b7r\u00f6\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und sp\u00e4ter blieb er weg.", "tokens": ["Und", "sp\u00e4\u00b7ter", "blieb", "er", "weg", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.42": {"line.1": {"text": "Doch eh er ging f\u00fcr immer,", "tokens": ["Doch", "eh", "er", "ging", "f\u00fcr", "im\u00b7mer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "VVFIN", "APPR", "ADV", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Sprach er: \u00bbBonaventur,", "tokens": ["Sprach", "er", ":", "\u00bb", "Bo\u00b7na\u00b7ven\u00b7tur", ","], "token_info": ["word", "word", "punct", "punct", "word", "punct"], "pos": ["NN", "PPER", "$.", "$(", "NN", "$,"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.3": {"text": "Du Weib, Du bist noch schlimmer", "tokens": ["Du", "Weib", ",", "Du", "bist", "noch", "schlim\u00b7mer"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "NN", "$,", "PPER", "VAFIN", "ADV", "ADJD"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Wie's Weib sonst von Natur.\u00ab", "tokens": ["Wie's", "Weib", "sonst", "von", "Na\u00b7tur", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADJA", "NN", "ADV", "APPR", "NN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.43": {"line.1": {"text": "Und fr\u00fch las sie im Blatte,", "tokens": ["Und", "fr\u00fch", "las", "sie", "im", "Blat\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "PPER", "APPRART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Man fand den Attach\u00e9", "tokens": ["Man", "fand", "den", "At\u00b7ta\u00b7ch\u00e9"], "token_info": ["word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Erschossen, wo sie hatte", "tokens": ["Er\u00b7schos\u00b7sen", ",", "wo", "sie", "hat\u00b7te"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["VVPP", "$,", "PWAV", "PPER", "VAFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Verfehlt ihn ganz expr\u00e9s.", "tokens": ["Ver\u00b7fehlt", "ihn", "ganz", "ex\u00b7pr\u00e9s", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "NE", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.44": {"line.1": {"text": "So tat Bonaventura", "tokens": ["So", "tat", "Bo\u00b7na\u00b7ven\u00b7tu\u00b7ra"], "token_info": ["word", "word", "word"], "pos": ["ADV", "VVFIN", "NE"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Aus Liebe zu Herrn Heinz.", "tokens": ["Aus", "Lie\u00b7be", "zu", "Herrn", "Heinz", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "NN", "NE", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "F\u00fcr ihn war sie jetzt nur da,", "tokens": ["F\u00fcr", "ihn", "war", "sie", "jetzt", "nur", "da", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VAFIN", "PPER", "ADV", "ADV", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und alles war ihr eins.", "tokens": ["Und", "al\u00b7les", "war", "ihr", "eins", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VAFIN", "PPER", "PIS", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.45": {"line.1": {"text": "Liegen so Zwei im Bette", "tokens": ["Lie\u00b7gen", "so", "Zwei", "im", "Bet\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "ADV", "CARD", "APPRART", "NN"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.2": {"text": "Und kommt auch noch ein Geist,", "tokens": ["Und", "kommt", "auch", "noch", "ein", "Geist", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Sind sie der Nachwelt fette", "tokens": ["Sind", "sie", "der", "Nach\u00b7welt", "fet\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "ART", "NN", "VVFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Beweis', was Liebe hei\u00dft.", "tokens": ["Be\u00b7weis'", ",", "was", "Lie\u00b7be", "hei\u00dft", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PWS", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.46": {"line.1": {"text": "Und heut weint meine F\u00fcrstin", "tokens": ["Und", "heut", "weint", "mei\u00b7ne", "F\u00fcrs\u00b7tin"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Noch mehr als Jede weint.", "tokens": ["Noch", "mehr", "als", "Je\u00b7de", "weint", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "KOUS", "PIS", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Es starb ihr Lebensgeist hin", "tokens": ["Es", "starb", "ihr", "Le\u00b7bens\u00b7geist", "hin"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "PTKVZ"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "Mit Heinzen, ihrem Freund.", "tokens": ["Mit", "Hein\u00b7zen", ",", "ih\u00b7rem", "Freund", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.47": {"line.1": {"text": "\u00bbauch ich\u00ab, schlo\u00df hier die Amme", "tokens": ["\u00bb", "auch", "ich", "\u00ab", ",", "schlo\u00df", "hier", "die", "Am\u00b7me"], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "word", "word"], "pos": ["$(", "ADV", "PPER", "$(", "$,", "VVFIN", "ADV", "ART", "NN"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.2": {"text": "\u00bbwill jetzt Kaffee einschenken.", "tokens": ["\u00bb", "will", "jetzt", "Kaf\u00b7fee", "ein\u00b7schen\u00b7ken", "."], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "VMFIN", "ADV", "NN", "VVIZU", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.3": {"text": "Wahr ist's, kein Mensch verdamme!", "tokens": ["Wahr", "ist's", ",", "kein", "Mensch", "ver\u00b7dam\u00b7me", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Das Leben gibt zu denken.\u00ab \u2013", "tokens": ["Das", "Le\u00b7ben", "gibt", "zu", "den\u00b7ken", ".", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKZU", "VVINF", "$.", "$(", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.48": {"line.1": {"text": "\u00bbja,\u00ab kam's von einer Andern", "tokens": ["\u00bb", "ja", ",", "\u00ab", "kam's", "von", "ei\u00b7ner", "An\u00b7dern"], "token_info": ["punct", "word", "punct", "punct", "word", "word", "word", "word"], "pos": ["$(", "PTKANT", "$,", "$(", "VVFIN", "APPR", "ART", "ADJA"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "\u00bbhab's Herrn Heinz nie verdacht,", "tokens": ["\u00bb", "hab's", "Herrn", "Heinz", "nie", "ver\u00b7dacht", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VAFIN", "NN", "NE", "ADV", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Sein Herz tat flei\u00dfig wandern,", "tokens": ["Sein", "Herz", "tat", "flei\u00b7\u00dfig", "wan\u00b7dern", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Es war dazu gemacht.", "tokens": ["Es", "war", "da\u00b7zu", "ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PAV", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.49": {"line.1": {"text": "Auch meine Frau tut gleichen", "tokens": ["Auch", "mei\u00b7ne", "Frau", "tut", "glei\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "PPOSAT", "NN", "VVFIN", "ADJA"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Der Frau Brigitte sehr.", "tokens": ["Der", "Frau", "Bri\u00b7git\u00b7te", "sehr", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NE", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Zwei M\u00e4nner, ganz als Leichen,", "tokens": ["Zwei", "M\u00e4n\u00b7ner", ",", "ganz", "als", "Lei\u00b7chen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "$,", "ADV", "KOUS", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Gab sie f\u00fcr Heinzen her.\u00ab", "tokens": ["Gab", "sie", "f\u00fcr", "Hein\u00b7zen", "her", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PPER", "APPR", "NN", "PTKVZ", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.50": {"line.1": {"text": "Die sieben andern Ammen", "tokens": ["Die", "sie\u00b7ben", "an\u00b7dern", "Am\u00b7men"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "CARD", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Taten ans Herz sich fassen.", "tokens": ["Ta\u00b7ten", "ans", "Herz", "sich", "fas\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPRART", "NN", "PRF", "VVINF", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.3": {"text": "Sie r\u00fcckten eng zusammen", "tokens": ["Sie", "r\u00fcck\u00b7ten", "eng", "zu\u00b7sam\u00b7men"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADJD", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und stellten fort die Tassen.", "tokens": ["Und", "stell\u00b7ten", "fort", "die", "Tas\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKVZ", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.51": {"line.1": {"text": "\u00bbdie F\u00fcrstin\u00ab, sprach die Eine", "tokens": ["\u00bb", "die", "F\u00fcrs\u00b7tin", "\u00ab", ",", "sprach", "die", "Ei\u00b7ne"], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "word"], "pos": ["$(", "ART", "NN", "$(", "$,", "VVFIN", "ART", "ART"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Und wischte sich den Mund,", "tokens": ["Und", "wischte", "sich", "den", "Mund", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "ART", "NN", "$,"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.3": {"text": "\u00bbwarf Perlen vor die Schweine", "tokens": ["\u00bb", "warf", "Per\u00b7len", "vor", "die", "Schwei\u00b7ne"], "token_info": ["punct", "word", "word", "word", "word", "word"], "pos": ["$(", "VVFIN", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "In ihrer Hochzeitsstund.\u00ab", "tokens": ["In", "ih\u00b7rer", "Hoch\u00b7zeits\u00b7stund", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.52": {"line.1": {"text": "Es ward Bonaventura", "tokens": ["Es", "ward", "Bo\u00b7na\u00b7ven\u00b7tu\u00b7ra"], "token_info": ["word", "word", "word"], "pos": ["PPER", "VAFIN", "NE"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Bald untreu ihrem Mann.", "tokens": ["Bald", "un\u00b7treu", "ih\u00b7rem", "Mann", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Weil von ihm kaum 'ne Spur da,", "tokens": ["Weil", "von", "ihm", "kaum", "'ne", "Spur", "da", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "PPER", "ADV", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Von dem, was da sein kann.", "tokens": ["Von", "dem", ",", "was", "da", "sein", "kann", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "$,", "PRELS", "ADV", "VAINF", "VMFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.53": {"line.1": {"text": "Mit einem Wort, es lebte", "tokens": ["Mit", "ei\u00b7nem", "Wort", ",", "es", "leb\u00b7te"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "ART", "NN", "$,", "PPER", "VVFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Der F\u00fcrst nur von Morphin.", "tokens": ["Der", "F\u00fcrst", "nur", "von", "Mor\u00b7phin", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "APPR", "NE", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Der F\u00fcrstin widerstrebte", "tokens": ["Der", "F\u00fcrs\u00b7tin", "wi\u00b7der\u00b7streb\u00b7te"], "token_info": ["word", "word", "word"], "pos": ["ART", "NN", "VVFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Alles, was Medizin.", "tokens": ["Al\u00b7les", ",", "was", "Me\u00b7di\u00b7zin", "."], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["PIS", "$,", "PRELS", "NE", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}}, "stanza.54": {"line.1": {"text": "Sie f\u00fchlte sich verstanden", "tokens": ["Sie", "f\u00fchl\u00b7te", "sich", "ver\u00b7stan\u00b7den"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PRF", "VVPP"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Vom Attach\u00e9 de l'O ....,", "tokens": ["Vom", "At\u00b7ta\u00b7ch\u00e9", "de", "l'O", "....", ","], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "$(", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und da sie sich schon kannten,", "tokens": ["Und", "da", "sie", "sich", "schon", "kann\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PRF", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Traf man sich leicht mal wo.", "tokens": ["Traf", "man", "sich", "leicht", "mal", "wo", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PRF", "ADJD", "ADV", "PWAV", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}}, "stanza.55": {"line.1": {"text": "Sie kam im dichten Schleier", "tokens": ["Sie", "kam", "im", "dich\u00b7ten", "Schlei\u00b7er"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Zum ersten Rendez-vous.", "tokens": ["Zum", "ers\u00b7ten", "Ren\u00b7de\u00b7zvous", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Im Wald f\u00fchlt man sich freier,", "tokens": ["Im", "Wald", "f\u00fchlt", "man", "sich", "frei\u00b7er", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PIS", "PRF", "ADJD", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Nur B\u00e4ume sehen zu.", "tokens": ["Nur", "B\u00e4u\u00b7me", "se\u00b7hen", "zu", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.56": {"line.1": {"text": "Doch wie die F\u00fcrstin schw\u00e4rmend", "tokens": ["Doch", "wie", "die", "F\u00fcrs\u00b7tin", "schw\u00e4r\u00b7mend"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "ART", "NN", "ADJD"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Anschaut den Attach\u00e9,", "tokens": ["An\u00b7schaut", "den", "At\u00b7ta\u00b7ch\u00e9", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Schien er ihr nicht erw\u00e4rmend,", "tokens": ["Schien", "er", "ihr", "nicht", "er\u00b7w\u00e4r\u00b7mend", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Weil jemand in der N\u00e4h.", "tokens": ["Weil", "je\u00b7mand", "in", "der", "N\u00e4h", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "APPR", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.57": {"line.1": {"text": "Ein Mann suchte f\u00fcr Tinte", "tokens": ["Ein", "Mann", "such\u00b7te", "f\u00fcr", "Tin\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "APPR", "NN"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.2": {"text": "Gall\u00e4pfel, und es blitzt", "tokens": ["Gal\u00b7l\u00e4p\u00b7fel", ",", "und", "es", "blitzt"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "KON", "PPER", "VVFIN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Sein Aug wie eine Flinte,", "tokens": ["Sein", "Aug", "wie", "ei\u00b7ne", "Flin\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KOKOM", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Sein Blick, der zielt und sitzt.", "tokens": ["Sein", "Blick", ",", "der", "zielt", "und", "sitzt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PRELS", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.58": {"line.1": {"text": "Der Mann folgt ihren Schritten,", "tokens": ["Der", "Mann", "folgt", "ih\u00b7ren", "Schrit\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Zuerst war sie emp\u00f6rt.", "tokens": ["Zu\u00b7erst", "war", "sie", "em\u00b7p\u00f6rt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "VVFIN", "$."], "meter": "--+--+", "measure": "anapaest.di.plus"}, "line.3": {"text": "Er hat in Waldesmitten", "tokens": ["Er", "hat", "in", "Wal\u00b7des\u00b7mit\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "APPR", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Ihr Rendez-vous gest\u00f6rt.", "tokens": ["Ihr", "Ren\u00b7de\u00b7zvous", "ge\u00b7st\u00f6rt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.59": {"line.1": {"text": "Und auch am n\u00e4chsten Tage", "tokens": ["Und", "auch", "am", "n\u00e4chs\u00b7ten", "Ta\u00b7ge"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "War \u00fcberall er da.", "tokens": ["War", "\u00fc\u00b7be\u00b7rall", "er", "da", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PPER", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Der Wald ward eine Plage", "tokens": ["Der", "Wald", "ward", "ei\u00b7ne", "Pla\u00b7ge"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Frau Bonaventura.", "tokens": ["Frau", "Bo\u00b7na\u00b7ven\u00b7tu\u00b7ra", "."], "token_info": ["word", "word", "punct"], "pos": ["NN", "NE", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.60": {"line.1": {"text": "Gewisse Augen sitzen", "tokens": ["Ge\u00b7wis\u00b7se", "Au\u00b7gen", "sit\u00b7zen"], "token_info": ["word", "word", "word"], "pos": ["NN", "NN", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Von manchem Mannsgesicht.", "tokens": ["Von", "man\u00b7chem", "Manns\u00b7ge\u00b7sicht", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Dann mu\u00df jed' Weib erhitzen,", "tokens": ["Dann", "mu\u00df", "jed'", "Weib", "er\u00b7hit\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PIAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Will sie es oder nicht.", "tokens": ["Will", "sie", "es", "o\u00b7der", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PPER", "KON", "PTKNEG", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.61": {"line.1": {"text": "Sie konnt ihn nicht vergessen.", "tokens": ["Sie", "konnt", "ihn", "nicht", "ver\u00b7ges\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Und er, der so geschaut,", "tokens": ["Und", "er", ",", "der", "so", "ge\u00b7schaut", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "$,", "PRELS", "ADV", "VVPP", "$,"], "meter": "--+--+", "measure": "anapaest.di.plus"}, "line.3": {"text": "Das ist Herr Heinz gewesen \u2013", "tokens": ["Das", "ist", "Herr", "Heinz", "ge\u00b7we\u00b7sen", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "NN", "NE", "VAPP", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Sein Herz nahm sie zur Braut.", "tokens": ["Sein", "Herz", "nahm", "sie", "zur", "Braut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "APPRART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.62": {"line.1": {"text": "Der Attach\u00e9, nicht n\u00e4her", "tokens": ["Der", "At\u00b7ta\u00b7ch\u00e9", ",", "nicht", "n\u00e4\u00b7her"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "$,", "PTKNEG", "ADJD"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "War der von Heinz entz\u00fcckt", "tokens": ["War", "der", "von", "Heinz", "ent\u00b7z\u00fcckt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "ART", "APPR", "NE", "VVPP"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.3": {"text": "Er glaubt, es w\u00e4r ein Sp\u00e4her", "tokens": ["Er", "glaubt", ",", "es", "w\u00e4r", "ein", "Sp\u00e4\u00b7her"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VAFIN", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Vom F\u00fcrsten ausgeschickt.", "tokens": ["Vom", "F\u00fcrs\u00b7ten", "aus\u00b7ge\u00b7schickt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.63": {"line.1": {"text": "Darum schlug er zur Schonung,", "tokens": ["Da\u00b7rum", "schlug", "er", "zur", "Scho\u00b7nung", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "APPRART", "NN", "$,"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.2": {"text": "F\u00fcr Auge und f\u00fcr Ohr,", "tokens": ["F\u00fcr", "Au\u00b7ge", "und", "f\u00fcr", "Ohr", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "APPR", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Auf morgen seine Wohnung", "tokens": ["Auf", "mor\u00b7gen", "sei\u00b7ne", "Woh\u00b7nung"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ADV", "PPOSAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Als Rendez-vousplatz vor.", "tokens": ["Als", "Ren\u00b7de\u00b7zvous\u00b7platz", "vor", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KOUS", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.64": {"line.1": {"text": "Die F\u00fcrstin in Gedanken", "tokens": ["Die", "F\u00fcrs\u00b7tin", "in", "Ge\u00b7dan\u00b7ken"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Sagt' gleichg\u00fcltig nur: Ja.", "tokens": ["Sagt'", "gleich\u00b7g\u00fcl\u00b7tig", "nur", ":", "Ja", "."], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["VVFIN", "ADJD", "ADV", "$.", "PTKANT", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Denn bei den Liebeskranken", "tokens": ["Denn", "bei", "den", "Lie\u00b7bes\u00b7kran\u00b7ken"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Ist wenig Stimme da.", "tokens": ["Ist", "we\u00b7nig", "Stim\u00b7me", "da", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.65": {"line.1": {"text": "F\u00fcrstin Bonaventura", "tokens": ["F\u00fcrs\u00b7tin", "Bo\u00b7na\u00b7ven\u00b7tu\u00b7ra"], "token_info": ["word", "word"], "pos": ["NE", "NE"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.2": {"text": "Hat sich nicht eingestellt.", "tokens": ["Hat", "sich", "nicht", "ein\u00b7ge\u00b7stellt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PRF", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Sie fand, 's w\u00e4r mehr Natur da,", "tokens": ["Sie", "fand", ",", "'s", "w\u00e4r", "mehr", "Na\u00b7tur", "da", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VAFIN", "PIAT", "NN", "PTKVZ", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Wenn sie den Waldweg w\u00e4hlt.", "tokens": ["Wenn", "sie", "den", "Wald\u00b7weg", "w\u00e4hlt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.66": {"line.1": {"text": "Und diesmal wich die F\u00fcrstin", "tokens": ["Und", "dies\u00b7mal", "wich", "die", "F\u00fcrs\u00b7tin"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Dem Augenblick nicht aus,", "tokens": ["Dem", "Au\u00b7gen\u00b7blick", "nicht", "aus", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKNEG", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Sie lehnte sich an Heinz hin,", "tokens": ["Sie", "lehn\u00b7te", "sich", "an", "Heinz", "hin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "NE", "PTKVZ", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Sprach: \u00bbHier bin ich zu Haus.\u00ab", "tokens": ["Sprach", ":", "\u00bb", "Hier", "bin", "ich", "zu", "Haus", ".", "\u00ab"], "token_info": ["word", "punct", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "$.", "$(", "ADV", "VAFIN", "PPER", "APPR", "NN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.67": {"line.1": {"text": "Denn bei ihm fand sie Sprache,", "tokens": ["Denn", "bei", "ihm", "fand", "sie", "Spra\u00b7che", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPER", "VVFIN", "PPER", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Er schw\u00f6rt bei jedem Ku\u00df.", "tokens": ["Er", "schw\u00f6rt", "bei", "je\u00b7dem", "Ku\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Nat\u00fcrlich war die Sache", "tokens": ["Na\u00b7t\u00fcr\u00b7lich", "war", "die", "Sa\u00b7che"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und nicht blo\u00df, weil man mu\u00df.", "tokens": ["Und", "nicht", "blo\u00df", ",", "weil", "man", "mu\u00df", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "ADV", "$,", "KOUS", "PIS", "VMFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.68": {"line.1": {"text": "Er tat nicht Galle suchen,", "tokens": ["Er", "tat", "nicht", "Gal\u00b7le", "su\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Er suchte ihren Mund.", "tokens": ["Er", "such\u00b7te", "ih\u00b7ren", "Mund", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und unter grauen Buchen,", "tokens": ["Und", "un\u00b7ter", "grau\u00b7en", "Bu\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Da trieben sie es bunt.", "tokens": ["Da", "trie\u00b7ben", "sie", "es", "bunt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.69": {"line.1": {"text": "Wie Zweige vom Epheue", "tokens": ["Wie", "Zwei\u00b7ge", "vom", "E\u00b7pheu\u00b7e"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "NN", "APPRART", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "War Leib an Leib gerankt.", "tokens": ["War", "Leib", "an", "Leib", "ge\u00b7rankt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Sie schwuren schwere Treue,", "tokens": ["Sie", "schwu\u00b7ren", "schwe\u00b7re", "Treu\u00b7e", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und niemals w\u00fcrd' gezankt.", "tokens": ["Und", "nie\u00b7mals", "w\u00fcrd'", "ge\u00b7zankt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.70": {"line.1": {"text": "Sie konnt' ihn los nicht lassen,", "tokens": ["Sie", "konnt'", "ihn", "los", "nicht", "las\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Noch wie der Mond aufging,", "tokens": ["Noch", "wie", "der", "Mond", "auf\u00b7ging", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "K\u00fc\u00dft sie ihn ohne Ma\u00dfen \u2013", "tokens": ["K\u00fc\u00dft", "sie", "ihn", "oh\u00b7ne", "Ma\u00b7\u00dfen", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "APPR", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Der Wald fast Feuer fing.", "tokens": ["Der", "Wald", "fast", "Feu\u00b7er", "fing", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.71": {"line.1": {"text": "Sie sprach: \u00bbIch bin entschlossen,", "tokens": ["Sie", "sprach", ":", "\u00bb", "Ich", "bin", "ent\u00b7schlos\u00b7sen", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "$(", "PPER", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Noch heute rei\u00df ich aus,", "tokens": ["Noch", "heu\u00b7te", "rei\u00df", "ich", "aus", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "In meiner Staatskarossen", "tokens": ["In", "mei\u00b7ner", "Staats\u00b7ka\u00b7ros\u00b7sen"], "token_info": ["word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Fliehn wir zur Stadt hinaus.\u00ab", "tokens": ["Fliehn", "wir", "zur", "Stadt", "hin\u00b7aus", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PPER", "APPRART", "NN", "PTKVZ", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.72": {"line.1": {"text": "Sie nahm all ihre Broschen", "tokens": ["Sie", "nahm", "all", "ih\u00b7re", "Bro\u00b7schen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PIAT", "PPOSAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Und's silberne Besteck.", "tokens": ["Un\u00b7d's", "sil\u00b7ber\u00b7ne", "Be\u00b7steck", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Der F\u00fcrst fror in Galoschen,", "tokens": ["Der", "F\u00fcrst", "fror", "in", "Ga\u00b7lo\u00b7schen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "NN", "$,"], "meter": "-+--+--", "measure": "iambic.di.relaxed"}, "line.4": {"text": "Starb Mittags noch am Schreck.", "tokens": ["Starb", "Mit\u00b7tags", "noch", "am", "Schreck", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADV", "APPRART", "NN", "$."], "meter": "--+--+", "measure": "anapaest.di.plus"}}, "stanza.73": {"line.1": {"text": "Herr Heinz und seine F\u00fcrstin,", "tokens": ["Herr", "Heinz", "und", "sei\u00b7ne", "F\u00fcrs\u00b7tin", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "KON", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Sie flohn durch Feld und Stra\u00df'.", "tokens": ["Sie", "flohn", "durch", "Feld", "und", "Stra\u00df'", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Die Pferde flogen glatthin,", "tokens": ["Die", "Pfer\u00b7de", "flo\u00b7gen", "glat\u00b7thin", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Weil nichts im Wege sa\u00df.", "tokens": ["Weil", "nichts", "im", "We\u00b7ge", "sa\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.74": {"line.1": {"text": "Doch an dem n\u00e4chsten Flecken", "tokens": ["Doch", "an", "dem", "n\u00e4chs\u00b7ten", "Fle\u00b7cken"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Traf sie ein langer Brief;", "tokens": ["Traf", "sie", "ein", "lan\u00b7ger", "Brief", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und dieser tat bezwecken,", "tokens": ["Und", "die\u00b7ser", "tat", "be\u00b7zwe\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PDAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Da\u00df nachts man nicht mehr schlief.", "tokens": ["Da\u00df", "nachts", "man", "nicht", "mehr", "schlief", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "PIS", "PTKNEG", "ADV", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.75": {"line.1": {"text": "Der Attach\u00e9 schrieb klagend:", "tokens": ["Der", "At\u00b7ta\u00b7ch\u00e9", "schrieb", "kla\u00b7gend", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Er wollt' sie nochmals sehn,", "tokens": ["Er", "wollt'", "sie", "noch\u00b7mals", "sehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "VVINF", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Der F\u00fcrstin Lebwohl sagend,", "tokens": ["Der", "F\u00fcrs\u00b7tin", "Leb\u00b7wohl", "sa\u00b7gend", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Nur so k\u00f6nnt' er bestehn.", "tokens": ["Nur", "so", "k\u00f6nnt'", "er", "be\u00b7stehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VMFIN", "PPER", "VVINF", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}}, "stanza.76": {"line.1": {"text": "Er sei im st\u00e4dt'schen Garten", "tokens": ["Er", "sei", "im", "st\u00e4dt'\u00b7schen", "Gar\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Mittags von eins bis zwei.", "tokens": ["Mit\u00b7tags", "von", "eins", "bis", "zwei", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PIS", "APPR", "CARD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und m\u00f6cht' nicht l\u00e4nger warten,", "tokens": ["Und", "m\u00f6cht'", "nicht", "l\u00e4n\u00b7ger", "war\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PTKNEG", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Auf's H\u00f6chst' bis Viertel drei!", "tokens": ["Auf's", "H\u00f6chst'", "bis", "Vier\u00b7tel", "drei", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPR", "NN", "CARD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.77": {"line.1": {"text": "Und sei sie nicht entschlossen", "tokens": ["Und", "sei", "sie", "nicht", "ent\u00b7schlos\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "PPER", "PTKNEG", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Und k\u00e4me nicht genau,", "tokens": ["Und", "k\u00e4\u00b7me", "nicht", "ge\u00b7nau", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKNEG", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "So h\u00e4tt' er sich erschossen \u2013", "tokens": ["So", "h\u00e4tt'", "er", "sich", "er\u00b7schos\u00b7sen", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PRF", "VVPP", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Er sch\u00f6sse nicht in's Blau.", "tokens": ["Er", "sch\u00f6s\u00b7se", "nicht", "in's", "Blau", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "APPRART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.78": {"line.1": {"text": "Die Frau wollt' er verfluchen,", "tokens": ["Die", "Frau", "wollt'", "er", "ver\u00b7flu\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Dies Weib, das ihn bet\u00f6rt;", "tokens": ["Dies", "Weib", ",", "das", "ihn", "be\u00b7t\u00f6rt", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "NN", "$,", "PRELS", "PPER", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Sein Geist w\u00fcrd' sie aufsuchen,", "tokens": ["Sein", "Geist", "w\u00fcrd'", "sie", "auf\u00b7su\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Auch wenn er n\u00e4chtlich st\u00f6rt.", "tokens": ["Auch", "wenn", "er", "n\u00e4cht\u00b7lich", "st\u00f6rt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PPER", "ADJD", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.79": {"line.1": {"text": "Die F\u00fcrstin las das Schreiben", "tokens": ["Die", "F\u00fcrs\u00b7tin", "las", "das", "Schrei\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Dem Heinzen, Satz um Satz.", "tokens": ["Dem", "Hein\u00b7zen", ",", "Satz", "um", "Satz", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "NN", "APPR", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Heinz zwang sie nicht zu bleiben,", "tokens": ["Heinz", "zwang", "sie", "nicht", "zu", "blei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "PTKNEG", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Sprach: \u00bbGeh hin, sch\u00f6nster Schatz!", "tokens": ["Sprach", ":", "\u00bb", "Geh", "hin", ",", "sch\u00f6ns\u00b7ter", "Schatz", "!"], "token_info": ["word", "punct", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$.", "$(", "NE", "PTKVZ", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.80": {"line.1": {"text": "Hast meine warmen K\u00fcsse", "tokens": ["Hast", "mei\u00b7ne", "war\u00b7men", "K\u00fcs\u00b7se"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Als einen Talisman,", "tokens": ["Als", "ei\u00b7nen", "Ta\u00b7lis\u00b7man", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "$,"], "meter": "-+-+--", "measure": "unknown.measure.di"}, "line.3": {"text": "So da\u00df Revolversch\u00fcsse", "tokens": ["So", "da\u00df", "Re\u00b7vol\u00b7ver\u00b7sch\u00fcs\u00b7se"], "token_info": ["word", "word", "word"], "pos": ["ADV", "KOUS", "NN"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.4": {"text": "Und Dolch nichts schaden kann.\u00ab", "tokens": ["Und", "Dolch", "nichts", "scha\u00b7den", "kann", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "NN", "PIS", "VVINF", "VMFIN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.81": {"line.1": {"text": "Die F\u00fcrstin ging zum Garten,", "tokens": ["Die", "F\u00fcrs\u00b7tin", "ging", "zum", "Gar\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Wie Heinzen ihr's empfahl.", "tokens": ["Wie", "Hein\u00b7zen", "ih\u00b7r's", "emp\u00b7fahl", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "PPER", "VVFIN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Sie tat bis zwei Uhr warten", "tokens": ["Sie", "tat", "bis", "zwei", "Uhr", "war\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "CARD", "NN", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und tat es ohne Qual.", "tokens": ["Und", "tat", "es", "oh\u00b7ne", "Qual", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.82": {"line.1": {"text": "An Heinz dacht' sie best\u00e4ndig,", "tokens": ["An", "Heinz", "dacht'", "sie", "be\u00b7st\u00e4n\u00b7dig", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VVFIN", "PPER", "ADJD", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Um zwei ging sie nach Haus.", "tokens": ["Um", "zwei", "ging", "sie", "nach", "Haus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "CARD", "VVFIN", "PPER", "APPR", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Froh, da\u00df sie ganz lebendig,", "tokens": ["Froh", ",", "da\u00df", "sie", "ganz", "le\u00b7ben\u00b7dig", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "KOUS", "PPER", "ADV", "ADJD", "$,"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.4": {"text": "Zog sie die Uhr heraus.", "tokens": ["Zog", "sie", "die", "Uhr", "he\u00b7raus", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.83": {"line.1": {"text": "Schob sacht den Zeiger weiter,", "tokens": ["Schob", "sacht", "den", "Zei\u00b7ger", "wei\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ART", "NN", "PTKVZ", "$,"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.2": {"text": "Den sie vorher verstellt.", "tokens": ["Den", "sie", "vor\u00b7her", "ver\u00b7stellt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "VVPP", "$."], "meter": "---+-+", "measure": "unknown.measure.di"}, "line.3": {"text": "Denn deshalb hat sie leider", "tokens": ["Denn", "des\u00b7halb", "hat", "sie", "lei\u00b7der"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PAV", "VAFIN", "PPER", "ADV"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Das Rendez-vous verfehlt.", "tokens": ["Das", "Ren\u00b7de\u00b7zvous", "ver\u00b7fehlt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.84": {"line.1": {"text": "Sie hat sich schlau gerettet", "tokens": ["Sie", "hat", "sich", "schlau", "ge\u00b7ret\u00b7tet"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PRF", "ADJD", "VVPP"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Aus dieser schweren Stund.", "tokens": ["Aus", "die\u00b7ser", "schwe\u00b7ren", "Stund", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und Heinz hat recht gewettet:", "tokens": ["Und", "Heinz", "hat", "recht", "ge\u00b7wet\u00b7tet", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "VAFIN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Sie kehrte heim gesund.", "tokens": ["Sie", "kehr\u00b7te", "heim", "ge\u00b7sund", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKVZ", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.85": {"line.1": {"text": "Doch abends, da sie eben", "tokens": ["Doch", "a\u00b7bends", ",", "da", "sie", "e\u00b7ben"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["KON", "ADV", "$,", "KOUS", "PPER", "ADV"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Im Bett ihr Haar aufsteckt,", "tokens": ["Im", "Bett", "ihr", "Haar", "auf\u00b7steckt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Sieht sie was Wei\u00dfes schweben.", "tokens": ["Sieht", "sie", "was", "Wei\u00b7\u00dfes", "schwe\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PIS", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Was Sch\u00fcttelfrost erweckt.", "tokens": ["Was", "Sch\u00fct\u00b7tel\u00b7frost", "er\u00b7weckt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PWS", "NN", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.86": {"line.1": {"text": "Sie mu\u00df ans Bettend starren,", "tokens": ["Sie", "mu\u00df", "ans", "Bet\u00b7tend", "star\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Als m\u00fc\u00dft' dort Jemand stehn.", "tokens": ["Als", "m\u00fc\u00dft'", "dort", "Je\u00b7mand", "stehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VMFIN", "ADV", "PIS", "VVINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Mit Angst in allen Haaren", "tokens": ["Mit", "Angst", "in", "al\u00b7len", "Haa\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "APPR", "PIAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Mu\u00df sie das Wei\u00dfe sehn.", "tokens": ["Mu\u00df", "sie", "das", "Wei\u00b7\u00dfe", "sehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.87": {"line.1": {"text": "Heinz sagt, es ist 'ne Falte", "tokens": ["Heinz", "sagt", ",", "es", "ist", "'ne", "Fal\u00b7te"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "$,", "PPER", "VAFIN", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Im Vorhang. 'S geht nicht fort.", "tokens": ["Im", "Vor\u00b7hang", ".", "'s", "geht", "nicht", "fort", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$.", "NE", "VVFIN", "PTKNEG", "PTKVZ", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Sie f\u00fchlt die Luft, die kalte, \u2013", "tokens": ["Sie", "f\u00fchlt", "die", "Luft", ",", "die", "kal\u00b7te", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "ART", "ADJA", "$,", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Der Attach\u00e9 sitzt dort.", "tokens": ["Der", "At\u00b7ta\u00b7ch\u00e9", "sitzt", "dort", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.88": {"line.1": {"text": "Sie floh in Schreckensn\u00f6ten", "tokens": ["Sie", "floh", "in", "Schre\u00b7ckens\u00b7n\u00f6\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Zu Heinz unter die Deck.", "tokens": ["Zu", "Heinz", "un\u00b7ter", "die", "Deck", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "APPR", "ART", "NN", "$."], "meter": "--+--+", "measure": "anapaest.di.plus"}, "line.3": {"text": "Da mu\u00df der Geist err\u00f6ten,", "tokens": ["Da", "mu\u00df", "der", "Geist", "er\u00b7r\u00f6\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und sp\u00e4ter blieb er weg.", "tokens": ["Und", "sp\u00e4\u00b7ter", "blieb", "er", "weg", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.89": {"line.1": {"text": "Doch eh er ging f\u00fcr immer,", "tokens": ["Doch", "eh", "er", "ging", "f\u00fcr", "im\u00b7mer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "VVFIN", "APPR", "ADV", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Sprach er: \u00bbBonaventur,", "tokens": ["Sprach", "er", ":", "\u00bb", "Bo\u00b7na\u00b7ven\u00b7tur", ","], "token_info": ["word", "word", "punct", "punct", "word", "punct"], "pos": ["NN", "PPER", "$.", "$(", "NN", "$,"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.3": {"text": "Du Weib, Du bist noch schlimmer", "tokens": ["Du", "Weib", ",", "Du", "bist", "noch", "schlim\u00b7mer"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "NN", "$,", "PPER", "VAFIN", "ADV", "ADJD"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Wie's Weib sonst von Natur.\u00ab", "tokens": ["Wie's", "Weib", "sonst", "von", "Na\u00b7tur", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADJA", "NN", "ADV", "APPR", "NN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.90": {"line.1": {"text": "Und fr\u00fch las sie im Blatte,", "tokens": ["Und", "fr\u00fch", "las", "sie", "im", "Blat\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "PPER", "APPRART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Man fand den Attach\u00e9", "tokens": ["Man", "fand", "den", "At\u00b7ta\u00b7ch\u00e9"], "token_info": ["word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Erschossen, wo sie hatte", "tokens": ["Er\u00b7schos\u00b7sen", ",", "wo", "sie", "hat\u00b7te"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["VVPP", "$,", "PWAV", "PPER", "VAFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Verfehlt ihn ganz expr\u00e9s.", "tokens": ["Ver\u00b7fehlt", "ihn", "ganz", "ex\u00b7pr\u00e9s", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "NE", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.91": {"line.1": {"text": "So tat Bonaventura", "tokens": ["So", "tat", "Bo\u00b7na\u00b7ven\u00b7tu\u00b7ra"], "token_info": ["word", "word", "word"], "pos": ["ADV", "VVFIN", "NE"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Aus Liebe zu Herrn Heinz.", "tokens": ["Aus", "Lie\u00b7be", "zu", "Herrn", "Heinz", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "NN", "NE", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "F\u00fcr ihn war sie jetzt nur da,", "tokens": ["F\u00fcr", "ihn", "war", "sie", "jetzt", "nur", "da", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VAFIN", "PPER", "ADV", "ADV", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und alles war ihr eins.", "tokens": ["Und", "al\u00b7les", "war", "ihr", "eins", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VAFIN", "PPER", "PIS", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.92": {"line.1": {"text": "Liegen so Zwei im Bette", "tokens": ["Lie\u00b7gen", "so", "Zwei", "im", "Bet\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "ADV", "CARD", "APPRART", "NN"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.2": {"text": "Und kommt auch noch ein Geist,", "tokens": ["Und", "kommt", "auch", "noch", "ein", "Geist", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Sind sie der Nachwelt fette", "tokens": ["Sind", "sie", "der", "Nach\u00b7welt", "fet\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "ART", "NN", "VVFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Beweis', was Liebe hei\u00dft.", "tokens": ["Be\u00b7weis'", ",", "was", "Lie\u00b7be", "hei\u00dft", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PWS", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.93": {"line.1": {"text": "Und heut weint meine F\u00fcrstin", "tokens": ["Und", "heut", "weint", "mei\u00b7ne", "F\u00fcrs\u00b7tin"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Noch mehr als Jede weint.", "tokens": ["Noch", "mehr", "als", "Je\u00b7de", "weint", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "KOUS", "PIS", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Es starb ihr Lebensgeist hin", "tokens": ["Es", "starb", "ihr", "Le\u00b7bens\u00b7geist", "hin"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "PTKVZ"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "Mit Heinzen, ihrem Freund.", "tokens": ["Mit", "Hein\u00b7zen", ",", "ih\u00b7rem", "Freund", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.94": {"line.1": {"text": "\u00bbauch ich\u00ab, schlo\u00df hier die Amme", "tokens": ["\u00bb", "auch", "ich", "\u00ab", ",", "schlo\u00df", "hier", "die", "Am\u00b7me"], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "word", "word"], "pos": ["$(", "ADV", "PPER", "$(", "$,", "VVFIN", "ADV", "ART", "NN"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.2": {"text": "\u00bbwill jetzt Kaffee einschenken.", "tokens": ["\u00bb", "will", "jetzt", "Kaf\u00b7fee", "ein\u00b7schen\u00b7ken", "."], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "VMFIN", "ADV", "NN", "VVIZU", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.3": {"text": "Wahr ist's, kein Mensch verdamme!", "tokens": ["Wahr", "ist's", ",", "kein", "Mensch", "ver\u00b7dam\u00b7me", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Das Leben gibt zu denken.\u00ab \u2013", "tokens": ["Das", "Le\u00b7ben", "gibt", "zu", "den\u00b7ken", ".", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKZU", "VVINF", "$.", "$(", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}}}}