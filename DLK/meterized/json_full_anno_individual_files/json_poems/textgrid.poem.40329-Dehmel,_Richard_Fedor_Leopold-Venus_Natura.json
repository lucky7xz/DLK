{"textgrid.poem.40329": {"metadata": {"author": {"name": "Dehmel, Richard Fedor Leopold", "birth": "N.A.", "death": "N.A."}, "title": "Venus Natura", "genre": "verse", "period": "N.A.", "pub_year": 1891, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Durch einen menschenleeren Garten irrend", "tokens": ["Durch", "ei\u00b7nen", "men\u00b7schen\u00b7lee\u00b7ren", "Gar\u00b7ten", "ir\u00b7rend"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "VVPP"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "geriet ich an ein Pfauenpaar; der Pfau", "tokens": ["ge\u00b7riet", "ich", "an", "ein", "Pfau\u00b7en\u00b7paar", ";", "der", "Pfau"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["VVFIN", "PPER", "APPR", "ART", "NN", "$.", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "stand mit gespreiztem Rad vor seiner Frau,", "tokens": ["stand", "mit", "ge\u00b7spreiz\u00b7tem", "Rad", "vor", "sei\u00b7ner", "Frau", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ADJA", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "die Fl\u00fcgel tief gestr\u00e4ubt, von Lichtern flirrend.", "tokens": ["die", "Fl\u00fc\u00b7gel", "tief", "ge\u00b7str\u00e4ubt", ",", "von", "Lich\u00b7tern", "flir\u00b7rend", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "VVPP", "$,", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "So stand er kreisend, sich die Henne kirrend,", "tokens": ["So", "stand", "er", "krei\u00b7send", ",", "sich", "die", "Hen\u00b7ne", "kir\u00b7rend", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "$,", "PRF", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "und bannte sie zu feierlicher Schau;", "tokens": ["und", "bann\u00b7te", "sie", "zu", "fei\u00b7er\u00b7li\u00b7cher", "Schau", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "starr federte das goldne Gr\u00fcn und Blau", "tokens": ["starr", "fe\u00b7der\u00b7te", "das", "gold\u00b7ne", "Gr\u00fcn", "und", "Blau"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADJD", "VVFIN", "ART", "ADJA", "NN", "KON", "NN"], "meter": "+----+-+-+", "measure": "dactylic.init"}, "line.4": {"text": "des steilen Schweifes, vor Erregung klirrend.", "tokens": ["des", "stei\u00b7len", "Schwei\u00b7fes", ",", "vor", "Er\u00b7re\u00b7gung", "klir\u00b7rend", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "APPR", "NN", "VVPP", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.3": {"line.1": {"text": "Jetzt \u00fcberf\u00e4llt er sie, und seine Zier", "tokens": ["Jetzt", "\u00fc\u00b7berf\u00b7\u00e4llt", "er", "sie", ",", "und", "sei\u00b7ne", "Zier"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "$,", "KON", "PPOSAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "peitscht wild die Luft, die hei\u00dfe; funkelnd spaltet", "tokens": ["peitscht", "wild", "die", "Luft", ",", "die", "hei\u00b7\u00dfe", ";", "fun\u00b7kelnd", "spal\u00b7tet"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["VVFIN", "ADJD", "ART", "NN", "$,", "PRELS", "VVFIN", "$.", "VVPP", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "der Radsaum seine Speichen, da\u00df sich mir", "tokens": ["der", "Rad\u00b7saum", "sei\u00b7ne", "Spei\u00b7chen", ",", "da\u00df", "sich", "mir"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "PPOSAT", "NN", "$,", "KOUS", "PRF", "PPER"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "der Gartenkreis zum Paradies gestaltet \u2013", "tokens": ["der", "Gar\u00b7ten\u00b7kreis", "zum", "Pa\u00b7ra\u00b7dies", "ge\u00b7stal\u00b7tet", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "O Mensch, wie herrlich ist das Tier,", "tokens": ["O", "Mensch", ",", "wie", "herr\u00b7lich", "ist", "das", "Tier", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "PWAV", "ADJD", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "wenn es sich ganz als Tier entfaltet! \u2013", "tokens": ["wenn", "es", "sich", "ganz", "als", "Tier", "ent\u00b7fal\u00b7tet", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PPER", "PRF", "ADV", "KOUS", "NN", "VVFIN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": ". . . . . . . . . . . . . . . . . . . . . . . . . . . . .", "tokens": [".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", "."], "token_info": ["punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct"], "pos": ["$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$."]}}, "stanza.6": {"line.1": {"text": "Denn der Mensch: der eignen Notdurft Sp\u00f6tter,", "tokens": ["Denn", "der", "Mensch", ":", "der", "eig\u00b7nen", "Not\u00b7durft", "Sp\u00f6t\u00b7ter", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$.", "ART", "ADJA", "NN", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "ja, so war seit je ein Halbgott er.", "tokens": ["ja", ",", "so", "war", "seit", "je", "ein", "Halb\u00b7gott", "er", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "ADV", "VAFIN", "APPR", "ADV", "ART", "NN", "PPER", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Schob er seinen Ursprung ", "tokens": ["Schob", "er", "sei\u00b7nen", "Ur\u00b7sprung"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "PPOSAT", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.7": {"line.1": {"text": "Wo ich hinsah, \u00e4fften sich Begierden,", "tokens": ["Wo", "ich", "hin\u00b7sah", ",", "\u00e4ff\u00b7ten", "sich", "Be\u00b7gier\u00b7den", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VVFIN", "$,", "VVFIN", "PRF", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "die sich ihrer nackten Herkunft sch\u00e4mten,", "tokens": ["die", "sich", "ih\u00b7rer", "nack\u00b7ten", "Her\u00b7kunft", "sch\u00e4m\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRELS", "PRF", "PPOSAT", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Br\u00fcnste, die mit schlangenh\u00e4utigen Zierden", "tokens": ["Br\u00fcns\u00b7te", ",", "die", "mit", "schlan\u00b7gen\u00b7h\u00e4u\u00b7ti\u00b7gen", "Zier\u00b7den"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$,", "PRELS", "APPR", "ADJA", "NN"], "meter": "+-+-+-+--+-", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "ihre t\u00fcckische Unvernunft verbr\u00e4mten.", "tokens": ["ih\u00b7re", "t\u00fc\u00b7cki\u00b7sche", "Un\u00b7ver\u00b7nunft", "ver\u00b7br\u00e4m\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVFIN", "$."], "meter": "---+-+-+-+-", "measure": "unknown.measure.tetra"}}, "stanza.8": {"line.1": {"text": "Eine ungeheure Tollsuchtwildnis", "tokens": ["Ei\u00b7ne", "un\u00b7ge\u00b7heu\u00b7re", "Toll\u00b7sucht\u00b7wild\u00b7nis"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "d\u00fcnkte mir der ganze Sch\u00f6pfungsplan,", "tokens": ["d\u00fcnk\u00b7te", "mir", "der", "gan\u00b7ze", "Sch\u00f6p\u00b7fungs\u00b7plan", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "mittendrin der Menschheit t\u00f6nern Bildnis", "tokens": ["mit\u00b7ten\u00b7drin", "der", "Menschheit", "t\u00f6\u00b7nern", "Bild\u00b7nis"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "ADJA", "NN"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "mit dem Stempel: reif zum Gr\u00f6\u00dfenwahn.", "tokens": ["mit", "dem", "Stem\u00b7pel", ":", "reif", "zum", "Gr\u00f6\u00b7\u00dfen\u00b7wahn", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$.", "ADJD", "APPRART", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.9": {"line.1": {"text": "O verm\u00f6chte jene Zeit der Schrecken", "tokens": ["O", "ver\u00b7m\u00f6ch\u00b7te", "je\u00b7ne", "Zeit", "der", "Schre\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "PDAT", "NN", "ART", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "meinen D\u00fcnkel immerfort zu d\u00e4mpfen!", "tokens": ["mei\u00b7nen", "D\u00fcn\u00b7kel", "im\u00b7mer\u00b7fort", "zu", "d\u00e4mp\u00b7fen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADV", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Wieviel Ekel mu\u00dft ich schmecken,", "tokens": ["Wie\u00b7viel", "E\u00b7kel", "mu\u00dft", "ich", "schme\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VMFIN", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "wie verbissen mit dir k\u00e4mpfen,", "tokens": ["wie", "ver\u00b7bis\u00b7sen", "mit", "dir", "k\u00e4mp\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVPP", "APPR", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Durch einen menschenleeren Garten irrend", "tokens": ["Durch", "ei\u00b7nen", "men\u00b7schen\u00b7lee\u00b7ren", "Gar\u00b7ten", "ir\u00b7rend"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "VVPP"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "geriet ich an ein Pfauenpaar; der Pfau", "tokens": ["ge\u00b7riet", "ich", "an", "ein", "Pfau\u00b7en\u00b7paar", ";", "der", "Pfau"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["VVFIN", "PPER", "APPR", "ART", "NN", "$.", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "stand mit gespreiztem Rad vor seiner Frau,", "tokens": ["stand", "mit", "ge\u00b7spreiz\u00b7tem", "Rad", "vor", "sei\u00b7ner", "Frau", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ADJA", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "die Fl\u00fcgel tief gestr\u00e4ubt, von Lichtern flirrend.", "tokens": ["die", "Fl\u00fc\u00b7gel", "tief", "ge\u00b7str\u00e4ubt", ",", "von", "Lich\u00b7tern", "flir\u00b7rend", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "VVPP", "$,", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.11": {"line.1": {"text": "So stand er kreisend, sich die Henne kirrend,", "tokens": ["So", "stand", "er", "krei\u00b7send", ",", "sich", "die", "Hen\u00b7ne", "kir\u00b7rend", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "$,", "PRF", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "und bannte sie zu feierlicher Schau;", "tokens": ["und", "bann\u00b7te", "sie", "zu", "fei\u00b7er\u00b7li\u00b7cher", "Schau", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "starr federte das goldne Gr\u00fcn und Blau", "tokens": ["starr", "fe\u00b7der\u00b7te", "das", "gold\u00b7ne", "Gr\u00fcn", "und", "Blau"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADJD", "VVFIN", "ART", "ADJA", "NN", "KON", "NN"], "meter": "+----+-+-+", "measure": "dactylic.init"}, "line.4": {"text": "des steilen Schweifes, vor Erregung klirrend.", "tokens": ["des", "stei\u00b7len", "Schwei\u00b7fes", ",", "vor", "Er\u00b7re\u00b7gung", "klir\u00b7rend", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "APPR", "NN", "VVPP", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.12": {"line.1": {"text": "Jetzt \u00fcberf\u00e4llt er sie, und seine Zier", "tokens": ["Jetzt", "\u00fc\u00b7berf\u00b7\u00e4llt", "er", "sie", ",", "und", "sei\u00b7ne", "Zier"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "$,", "KON", "PPOSAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "peitscht wild die Luft, die hei\u00dfe; funkelnd spaltet", "tokens": ["peitscht", "wild", "die", "Luft", ",", "die", "hei\u00b7\u00dfe", ";", "fun\u00b7kelnd", "spal\u00b7tet"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["VVFIN", "ADJD", "ART", "NN", "$,", "PRELS", "VVFIN", "$.", "VVPP", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "der Radsaum seine Speichen, da\u00df sich mir", "tokens": ["der", "Rad\u00b7saum", "sei\u00b7ne", "Spei\u00b7chen", ",", "da\u00df", "sich", "mir"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "PPOSAT", "NN", "$,", "KOUS", "PRF", "PPER"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "der Gartenkreis zum Paradies gestaltet \u2013", "tokens": ["der", "Gar\u00b7ten\u00b7kreis", "zum", "Pa\u00b7ra\u00b7dies", "ge\u00b7stal\u00b7tet", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.13": {"line.1": {"text": "O Mensch, wie herrlich ist das Tier,", "tokens": ["O", "Mensch", ",", "wie", "herr\u00b7lich", "ist", "das", "Tier", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "PWAV", "ADJD", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "wenn es sich ganz als Tier entfaltet! \u2013", "tokens": ["wenn", "es", "sich", "ganz", "als", "Tier", "ent\u00b7fal\u00b7tet", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PPER", "PRF", "ADV", "KOUS", "NN", "VVFIN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": ". . . . . . . . . . . . . . . . . . . . . . . . . . . . .", "tokens": [".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", "."], "token_info": ["punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct"], "pos": ["$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$."]}}, "stanza.15": {"line.1": {"text": "Denn der Mensch: der eignen Notdurft Sp\u00f6tter,", "tokens": ["Denn", "der", "Mensch", ":", "der", "eig\u00b7nen", "Not\u00b7durft", "Sp\u00f6t\u00b7ter", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$.", "ART", "ADJA", "NN", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "ja, so war seit je ein Halbgott er.", "tokens": ["ja", ",", "so", "war", "seit", "je", "ein", "Halb\u00b7gott", "er", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "ADV", "VAFIN", "APPR", "ADV", "ART", "NN", "PPER", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Schob er seinen Ursprung ", "tokens": ["Schob", "er", "sei\u00b7nen", "Ur\u00b7sprung"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "PPOSAT", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.16": {"line.1": {"text": "Wo ich hinsah, \u00e4fften sich Begierden,", "tokens": ["Wo", "ich", "hin\u00b7sah", ",", "\u00e4ff\u00b7ten", "sich", "Be\u00b7gier\u00b7den", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VVFIN", "$,", "VVFIN", "PRF", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "die sich ihrer nackten Herkunft sch\u00e4mten,", "tokens": ["die", "sich", "ih\u00b7rer", "nack\u00b7ten", "Her\u00b7kunft", "sch\u00e4m\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRELS", "PRF", "PPOSAT", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Br\u00fcnste, die mit schlangenh\u00e4utigen Zierden", "tokens": ["Br\u00fcns\u00b7te", ",", "die", "mit", "schlan\u00b7gen\u00b7h\u00e4u\u00b7ti\u00b7gen", "Zier\u00b7den"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$,", "PRELS", "APPR", "ADJA", "NN"], "meter": "+-+-+-+--+-", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "ihre t\u00fcckische Unvernunft verbr\u00e4mten.", "tokens": ["ih\u00b7re", "t\u00fc\u00b7cki\u00b7sche", "Un\u00b7ver\u00b7nunft", "ver\u00b7br\u00e4m\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVFIN", "$."], "meter": "---+-+-+-+-", "measure": "unknown.measure.tetra"}}, "stanza.17": {"line.1": {"text": "Eine ungeheure Tollsuchtwildnis", "tokens": ["Ei\u00b7ne", "un\u00b7ge\u00b7heu\u00b7re", "Toll\u00b7sucht\u00b7wild\u00b7nis"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "d\u00fcnkte mir der ganze Sch\u00f6pfungsplan,", "tokens": ["d\u00fcnk\u00b7te", "mir", "der", "gan\u00b7ze", "Sch\u00f6p\u00b7fungs\u00b7plan", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "mittendrin der Menschheit t\u00f6nern Bildnis", "tokens": ["mit\u00b7ten\u00b7drin", "der", "Menschheit", "t\u00f6\u00b7nern", "Bild\u00b7nis"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "ADJA", "NN"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "mit dem Stempel: reif zum Gr\u00f6\u00dfenwahn.", "tokens": ["mit", "dem", "Stem\u00b7pel", ":", "reif", "zum", "Gr\u00f6\u00b7\u00dfen\u00b7wahn", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$.", "ADJD", "APPRART", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.18": {"line.1": {"text": "O verm\u00f6chte jene Zeit der Schrecken", "tokens": ["O", "ver\u00b7m\u00f6ch\u00b7te", "je\u00b7ne", "Zeit", "der", "Schre\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "PDAT", "NN", "ART", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "meinen D\u00fcnkel immerfort zu d\u00e4mpfen!", "tokens": ["mei\u00b7nen", "D\u00fcn\u00b7kel", "im\u00b7mer\u00b7fort", "zu", "d\u00e4mp\u00b7fen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADV", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Wieviel Ekel mu\u00dft ich schmecken,", "tokens": ["Wie\u00b7viel", "E\u00b7kel", "mu\u00dft", "ich", "schme\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VMFIN", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "wie verbissen mit dir k\u00e4mpfen,", "tokens": ["wie", "ver\u00b7bis\u00b7sen", "mit", "dir", "k\u00e4mp\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVPP", "APPR", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}}}}