{"textgrid.poem.35231": {"metadata": {"author": {"name": "Harsd\u00f6rffer, Georg Philipp", "birth": "N.A.", "death": "N.A."}, "title": "1L: Nun kommt, ihr Frommen, la\u00dft uns eilen,", "genre": "verse", "period": "N.A.", "pub_year": 1632, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Nun kommt, ihr Frommen, la\u00dft uns eilen,", "tokens": ["Nun", "kommt", ",", "ihr", "From\u00b7men", ",", "la\u00dft", "uns", "ei\u00b7len", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "PPOSAT", "NN", "$,", "VVIMP", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Zu schauen dieser Zeiten Gut,", "tokens": ["Zu", "schau\u00b7en", "die\u00b7ser", "Zei\u00b7ten", "Gut", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "PDAT", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Den Reichthum, der nicht lang' kann weilen,", "tokens": ["Den", "Reicht\u00b7hum", ",", "der", "nicht", "lang'", "kann", "wei\u00b7len", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PTKNEG", "ADV", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und schnell verrauschet, wie die Fluth.", "tokens": ["Und", "schnell", "ver\u00b7rau\u00b7schet", ",", "wie", "die", "Fluth", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "$,", "PWAV", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "In dieser Welt nichts lang' besteht,", "tokens": ["In", "die\u00b7ser", "Welt", "nichts", "lang'", "be\u00b7steht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "PIS", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wo ihr Bestand wie Tand vergeht.", "tokens": ["Wo", "ihr", "Be\u00b7stand", "wie", "Tand", "ver\u00b7geht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "NN", "KOKOM", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Der diese Feld' und W\u00e4lder bauet,", "tokens": ["Der", "die\u00b7se", "Feld'", "und", "W\u00e4l\u00b7der", "bau\u00b7et", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PDAT", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ist h\u00f6chstes Lobs und R\u00fchmens werth,", "tokens": ["Ist", "h\u00f6chs\u00b7tes", "Lobs", "und", "R\u00fch\u00b7mens", "werth", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJA", "NN", "KON", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der sie befruchtet und bethauet,", "tokens": ["Der", "sie", "be\u00b7fruch\u00b7tet", "und", "be\u00b7thau\u00b7et", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVPP", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Besch\u00fctzt, erh\u00e4lt und reichlich n\u00e4hrt.", "tokens": ["Be\u00b7sch\u00fctzt", ",", "er\u00b7h\u00e4lt", "und", "reich\u00b7lich", "n\u00e4hrt", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "VVFIN", "KON", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Er kr\u00f6nt das Jahr mit seinem Gut", "tokens": ["Er", "kr\u00f6nt", "das", "Jahr", "mit", "sei\u00b7nem", "Gut"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und giebt uns Menschen freien Muth.", "tokens": ["Und", "giebt", "uns", "Men\u00b7schen", "frei\u00b7en", "Muth", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Es gr\u00fcnt der Wald mit frechen Sprossen,", "tokens": ["Es", "gr\u00fcnt", "der", "Wald", "mit", "fre\u00b7chen", "Spros\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die Bienlein finden ihre Kost,", "tokens": ["Die", "Bien\u00b7lein", "fin\u00b7den", "ih\u00b7re", "Kost", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die Reben sind hoch aufgeschossen", "tokens": ["Die", "Re\u00b7ben", "sind", "hoch", "auf\u00b7ge\u00b7schos\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ADJD", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und machen hoffen guten Most;", "tokens": ["Und", "ma\u00b7chen", "hof\u00b7fen", "gu\u00b7ten", "Most", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVINF", "VVFIN", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Man h\u00f6rt der Lerchen hellen Klang", "tokens": ["Man", "h\u00f6rt", "der", "Ler\u00b7chen", "hel\u00b7len", "Klang"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und mancher Nachtigall Gesang.", "tokens": ["Und", "man\u00b7cher", "Nach\u00b7ti\u00b7gall", "Ge\u00b7sang", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Ein jedes Thier kann sich erf\u00fcllen,", "tokens": ["Ein", "je\u00b7des", "Thier", "kann", "sich", "er\u00b7f\u00fcl\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VMFIN", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Allein der Mensch wird nimmer satt:", "tokens": ["Al\u00b7lein", "der", "Mensch", "wird", "nim\u00b7mer", "satt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VAFIN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Er plaget sich mit Sorgengrillen,", "tokens": ["Er", "pla\u00b7get", "sich", "mit", "Sor\u00b7gen\u00b7gril\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die er sich selbst geheget hat.", "tokens": ["Die", "er", "sich", "selbst", "ge\u00b7he\u00b7get", "hat", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PRF", "ADV", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Mehr Reisegeld w\u00fcnscht er sich mit,", "tokens": ["Mehr", "Rei\u00b7se\u00b7geld", "w\u00fcnscht", "er", "sich", "mit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "PPER", "PRF", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wenn er fast thut den letzten Schritt.", "tokens": ["Wenn", "er", "fast", "thut", "den", "letz\u00b7ten", "Schritt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "---+-+-+", "measure": "unknown.measure.tri"}}, "stanza.5": {"line.1": {"text": "Wir wollen unsre Werke stellen", "tokens": ["Wir", "wol\u00b7len", "uns\u00b7re", "Wer\u00b7ke", "stel\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PPOSAT", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Auf Gottes Willen, Ehr' und Preis;", "tokens": ["Auf", "Got\u00b7tes", "Wil\u00b7len", ",", "Ehr'", "und", "Preis", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sonst wird die Erd' uns zu der H\u00f6llen,", "tokens": ["Sonst", "wird", "die", "Erd'", "uns", "zu", "der", "H\u00f6l\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die uns kann sein ein Paradeis,", "tokens": ["Die", "uns", "kann", "sein", "ein", "Pa\u00b7ra\u00b7deis", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VMFIN", "PPOSAT", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wenn unser Leben englisch ist,", "tokens": ["Wenn", "un\u00b7ser", "Le\u00b7ben", "eng\u00b7lisch", "ist", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Keusch, ohne S\u00fcnd' und falsche List.", "tokens": ["Keusch", ",", "oh\u00b7ne", "S\u00fcnd'", "und", "fal\u00b7sche", "List", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "KOUI", "NN", "KON", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Nun kommt, ihr Frommen, la\u00dft uns eilen,", "tokens": ["Nun", "kommt", ",", "ihr", "From\u00b7men", ",", "la\u00dft", "uns", "ei\u00b7len", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "PPOSAT", "NN", "$,", "VVIMP", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Zu schauen dieser Zeiten Gut,", "tokens": ["Zu", "schau\u00b7en", "die\u00b7ser", "Zei\u00b7ten", "Gut", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "PDAT", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Den Reichthum, der nicht lang' kann weilen,", "tokens": ["Den", "Reicht\u00b7hum", ",", "der", "nicht", "lang'", "kann", "wei\u00b7len", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PTKNEG", "ADV", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und schnell verrauschet, wie die Fluth.", "tokens": ["Und", "schnell", "ver\u00b7rau\u00b7schet", ",", "wie", "die", "Fluth", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "$,", "PWAV", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "In dieser Welt nichts lang' besteht,", "tokens": ["In", "die\u00b7ser", "Welt", "nichts", "lang'", "be\u00b7steht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "PIS", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wo ihr Bestand wie Tand vergeht.", "tokens": ["Wo", "ihr", "Be\u00b7stand", "wie", "Tand", "ver\u00b7geht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "NN", "KOKOM", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Der diese Feld' und W\u00e4lder bauet,", "tokens": ["Der", "die\u00b7se", "Feld'", "und", "W\u00e4l\u00b7der", "bau\u00b7et", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PDAT", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ist h\u00f6chstes Lobs und R\u00fchmens werth,", "tokens": ["Ist", "h\u00f6chs\u00b7tes", "Lobs", "und", "R\u00fch\u00b7mens", "werth", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJA", "NN", "KON", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der sie befruchtet und bethauet,", "tokens": ["Der", "sie", "be\u00b7fruch\u00b7tet", "und", "be\u00b7thau\u00b7et", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVPP", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Besch\u00fctzt, erh\u00e4lt und reichlich n\u00e4hrt.", "tokens": ["Be\u00b7sch\u00fctzt", ",", "er\u00b7h\u00e4lt", "und", "reich\u00b7lich", "n\u00e4hrt", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "VVFIN", "KON", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Er kr\u00f6nt das Jahr mit seinem Gut", "tokens": ["Er", "kr\u00f6nt", "das", "Jahr", "mit", "sei\u00b7nem", "Gut"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und giebt uns Menschen freien Muth.", "tokens": ["Und", "giebt", "uns", "Men\u00b7schen", "frei\u00b7en", "Muth", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Es gr\u00fcnt der Wald mit frechen Sprossen,", "tokens": ["Es", "gr\u00fcnt", "der", "Wald", "mit", "fre\u00b7chen", "Spros\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die Bienlein finden ihre Kost,", "tokens": ["Die", "Bien\u00b7lein", "fin\u00b7den", "ih\u00b7re", "Kost", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die Reben sind hoch aufgeschossen", "tokens": ["Die", "Re\u00b7ben", "sind", "hoch", "auf\u00b7ge\u00b7schos\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ADJD", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und machen hoffen guten Most;", "tokens": ["Und", "ma\u00b7chen", "hof\u00b7fen", "gu\u00b7ten", "Most", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVINF", "VVFIN", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Man h\u00f6rt der Lerchen hellen Klang", "tokens": ["Man", "h\u00f6rt", "der", "Ler\u00b7chen", "hel\u00b7len", "Klang"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und mancher Nachtigall Gesang.", "tokens": ["Und", "man\u00b7cher", "Nach\u00b7ti\u00b7gall", "Ge\u00b7sang", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Ein jedes Thier kann sich erf\u00fcllen,", "tokens": ["Ein", "je\u00b7des", "Thier", "kann", "sich", "er\u00b7f\u00fcl\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VMFIN", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Allein der Mensch wird nimmer satt:", "tokens": ["Al\u00b7lein", "der", "Mensch", "wird", "nim\u00b7mer", "satt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VAFIN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Er plaget sich mit Sorgengrillen,", "tokens": ["Er", "pla\u00b7get", "sich", "mit", "Sor\u00b7gen\u00b7gril\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die er sich selbst geheget hat.", "tokens": ["Die", "er", "sich", "selbst", "ge\u00b7he\u00b7get", "hat", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PRF", "ADV", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Mehr Reisegeld w\u00fcnscht er sich mit,", "tokens": ["Mehr", "Rei\u00b7se\u00b7geld", "w\u00fcnscht", "er", "sich", "mit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "PPER", "PRF", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wenn er fast thut den letzten Schritt.", "tokens": ["Wenn", "er", "fast", "thut", "den", "letz\u00b7ten", "Schritt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "---+-+-+", "measure": "unknown.measure.tri"}}, "stanza.10": {"line.1": {"text": "Wir wollen unsre Werke stellen", "tokens": ["Wir", "wol\u00b7len", "uns\u00b7re", "Wer\u00b7ke", "stel\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PPOSAT", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Auf Gottes Willen, Ehr' und Preis;", "tokens": ["Auf", "Got\u00b7tes", "Wil\u00b7len", ",", "Ehr'", "und", "Preis", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sonst wird die Erd' uns zu der H\u00f6llen,", "tokens": ["Sonst", "wird", "die", "Erd'", "uns", "zu", "der", "H\u00f6l\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die uns kann sein ein Paradeis,", "tokens": ["Die", "uns", "kann", "sein", "ein", "Pa\u00b7ra\u00b7deis", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VMFIN", "PPOSAT", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wenn unser Leben englisch ist,", "tokens": ["Wenn", "un\u00b7ser", "Le\u00b7ben", "eng\u00b7lisch", "ist", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Keusch, ohne S\u00fcnd' und falsche List.", "tokens": ["Keusch", ",", "oh\u00b7ne", "S\u00fcnd'", "und", "fal\u00b7sche", "List", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "KOUI", "NN", "KON", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}