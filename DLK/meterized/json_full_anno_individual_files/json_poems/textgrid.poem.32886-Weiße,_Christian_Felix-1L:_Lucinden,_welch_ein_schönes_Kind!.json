{"textgrid.poem.32886": {"metadata": {"author": {"name": "Wei\u00dfe, Christian Felix", "birth": "N.A.", "death": "N.A."}, "title": "1L: Lucinden, welch ein sch\u00f6nes Kind!", "genre": "verse", "period": "N.A.", "pub_year": 1765, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Lucinden, welch ein sch\u00f6nes Kind!", "tokens": ["Lu\u00b7cin\u00b7den", ",", "welch", "ein", "sch\u00f6\u00b7nes", "Kind", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PWAT", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das jeder J\u00fcngling lieb gewinnt,", "tokens": ["Das", "je\u00b7der", "J\u00fcng\u00b7ling", "lieb", "ge\u00b7winnt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sucht ietzt ein z\u00e4rtlicher Amynt", "tokens": ["Sucht", "ietzt", "ein", "z\u00e4rt\u00b7li\u00b7cher", "A\u00b7mynt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Im Lieben oft zu unterweisen:", "tokens": ["Im", "Lie\u00b7ben", "oft", "zu", "un\u00b7ter\u00b7wei\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Noch f\u00e4rbet, wenn er davon spricht,", "tokens": ["Noch", "f\u00e4r\u00b7bet", ",", "wenn", "er", "da\u00b7von", "spricht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "KOUS", "PPER", "PAV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ein sanftes Roth ihr hold Gesicht:", "tokens": ["Ein", "sanf\u00b7tes", "Roth", "ihr", "hold", "Ge\u00b7sicht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PPOSAT", "ADJD", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Obs in acht Tagen noch geschicht?", "tokens": ["Obs", "in", "acht", "Ta\u00b7gen", "noch", "ge\u00b7schicht", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "CARD", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Das wird sich weisen.", "tokens": ["Das", "wird", "sich", "wei\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PRF", "VVINF", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.2": {"line.1": {"text": "Cotill, ein junger Candidat,", "tokens": ["Co\u00b7till", ",", "ein", "jun\u00b7ger", "Can\u00b7di\u00b7dat", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sucht, da er noch kein Aemtgen hat,", "tokens": ["Sucht", ",", "da", "er", "noch", "kein", "A\u00b7emt\u00b7gen", "hat", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "KOUS", "PPER", "ADV", "PIAT", "NN", "VAFIN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Gerecht zu seyn in Rath und That,", "tokens": ["Ge\u00b7recht", "zu", "seyn", "in", "Rath", "und", "That", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKZU", "VAINF", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Den Richtern herrlich anzupreisen.", "tokens": ["Den", "Rich\u00b7tern", "herr\u00b7lich", "an\u00b7zu\u00b7prei\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "VVIZU", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Durch den bestochenen Patron", "tokens": ["Durch", "den", "be\u00b7sto\u00b7che\u00b7nen", "Pat\u00b7ron"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.6": {"text": "Tr\u00e4gt sein Verdienst ein Amt davon:", "tokens": ["Tr\u00e4gt", "sein", "Ver\u00b7dienst", "ein", "Amt", "da\u00b7von", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "ART", "NN", "PAV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Spricht er nun den Geschenken Hohn?", "tokens": ["Spricht", "er", "nun", "den", "Ge\u00b7schen\u00b7ken", "Hohn", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ART", "NN", "NN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.8": {"text": "Das wird sich weisen.", "tokens": ["Das", "wird", "sich", "wei\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PRF", "VVINF", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.3": {"line.1": {"text": "Wie \u00e4rgert sich Belinde nicht,", "tokens": ["Wie", "\u00e4r\u00b7gert", "sich", "Be\u00b7lin\u00b7de", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PRF", "NN", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wenn eine Frau Gesetz und Pflicht", "tokens": ["Wenn", "ei\u00b7ne", "Frau", "Ge\u00b7setz", "und", "Pflicht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und die geschworne Treue bricht!", "tokens": ["Und", "die", "ge\u00b7schwor\u00b7ne", "Treu\u00b7e", "bricht", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Da soll der Himmel sich zerrei\u00dfen.", "tokens": ["Da", "soll", "der", "Him\u00b7mel", "sich", "zer\u00b7rei\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "NN", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Itzt reichet sie ihr Herz und Hand", "tokens": ["Itzt", "rei\u00b7chet", "sie", "ihr", "Herz", "und", "Hand"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PPOSAT", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Dem jungen flatternden Cleant,", "tokens": ["Dem", "jun\u00b7gen", "flat\u00b7tern\u00b7den", "Cleant", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.7": {"text": "Ist noch ihr Eifer vom Bestand?", "tokens": ["Ist", "noch", "ihr", "Ei\u00b7fer", "vom", "Be\u00b7stand", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PPOSAT", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Das wird sich weisen.", "tokens": ["Das", "wird", "sich", "wei\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PRF", "VVINF", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.4": {"line.1": {"text": "Selinde zieht den Bellamor", "tokens": ["Se\u00b7lin\u00b7de", "zieht", "den", "Be\u00b7lla\u00b7mor"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "VVFIN", "ART", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Dem seufzervollen Lisidor", "tokens": ["Dem", "seuf\u00b7zer\u00b7vol\u00b7len", "Li\u00b7si\u00b7dor"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "In seinen hei\u00dfen W\u00fcnschen vor:", "tokens": ["In", "sei\u00b7nen", "hei\u00b7\u00dfen", "W\u00fcn\u00b7schen", "vor", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Er droht mit Gift, Pistol und Eisen:", "tokens": ["Er", "droht", "mit", "Gift", ",", "Pis\u00b7tol", "und", "Ei\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "$,", "NE", "KON", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Man l\u00e4\u00dft ihn ungeschlossen gehn,", "tokens": ["Man", "l\u00e4\u00dft", "ihn", "un\u00b7ge\u00b7schlos\u00b7sen", "gehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "L\u00e4\u00dft alles ihm im Wege stehn,", "tokens": ["L\u00e4\u00dft", "al\u00b7les", "ihm", "im", "We\u00b7ge", "stehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PPER", "APPRART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Ists um sein Leben nun geschehn?", "tokens": ["Ists", "um", "sein", "Le\u00b7ben", "nun", "ge\u00b7schehn", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "PPOSAT", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Das wird sich weisen.", "tokens": ["Das", "wird", "sich", "wei\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PRF", "VVINF", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.5": {"line.1": {"text": "Jobst, der das Geld nach Scheffeln z\u00e4hlt,", "tokens": ["Jobst", ",", "der", "das", "Geld", "nach", "Schef\u00b7feln", "z\u00e4hlt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PRELS", "ART", "NN", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dem der Verstand, nichts weiter fehlt,", "tokens": ["Dem", "der", "Ver\u00b7stand", ",", "nichts", "wei\u00b7ter", "fehlt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "ART", "NN", "$,", "PIS", "ADV", "VVFIN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Geht, von dem edlen Stolz beseelt,", "tokens": ["Geht", ",", "von", "dem", "ed\u00b7len", "Stolz", "be\u00b7seelt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "APPR", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Galant und klug zu seyn, auf Reisen:", "tokens": ["Ga\u00b7lant", "und", "klug", "zu", "seyn", ",", "auf", "Rei\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "KON", "ADJD", "PTKZU", "VAINF", "$,", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "In Frankreich, Welschland, Engeland", "tokens": ["In", "Fran\u00b7kreich", ",", "Wel\u00b7schland", ",", "En\u00b7ge\u00b7land"], "token_info": ["word", "word", "punct", "word", "punct", "word"], "pos": ["APPR", "NE", "$,", "NN", "$,", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wird bald der reiche Jobst bekannt:", "tokens": ["Wird", "bald", "der", "rei\u00b7che", "Jobst", "be\u00b7kannt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "K\u00f6mmt er zur\u00fcck reich am Verstand?", "tokens": ["K\u00f6mmt", "er", "zu\u00b7r\u00fcck", "reich", "am", "Ver\u00b7stand", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADJD", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Das wird sich weisen.", "tokens": ["Das", "wird", "sich", "wei\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PRF", "VVINF", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.6": {"line.1": {"text": "Bey R\u00f6mern, niemals leer vom Wein,", "tokens": ["Bey", "R\u00f6\u00b7mern", ",", "nie\u00b7mals", "leer", "vom", "Wein", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "ADV", "ADJD", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "H\u00f6r ich dort meine Nachbarn schreyn,", "tokens": ["H\u00f6r", "ich", "dort", "mei\u00b7ne", "Nach\u00b7barn", "schreyn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "ADV", "PPOSAT", "NN", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wer von den kriegenden Parteyn", "tokens": ["Wer", "von", "den", "krie\u00b7gen\u00b7den", "Par\u00b7teyn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Noch sieget? Oestreich oder Preussen?", "tokens": ["Noch", "sie\u00b7get", "?", "O\u00b7e\u00b7streich", "o\u00b7der", "Preus\u00b7sen", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$.", "NE", "KON", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.5": {"text": "Sie rufen mir entr\u00fcstet zu:", "tokens": ["Sie", "ru\u00b7fen", "mir", "ent\u00b7r\u00fcs\u00b7tet", "zu", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "\u00bbkomm Bruder, komm, entscheide du!\u00ab", "tokens": ["\u00bb", "komm", "Bru\u00b7der", ",", "komm", ",", "ent\u00b7schei\u00b7de", "du", "!", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "word", "punct", "word", "word", "punct", "punct"], "pos": ["$(", "VVFIN", "NN", "$,", "VVFIN", "$,", "VVFIN", "PPER", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Ich sag: ihr Narren, trinkt in Ruh,", "tokens": ["Ich", "sag", ":", "ihr", "Nar\u00b7ren", ",", "trinkt", "in", "Ruh", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "PPOSAT", "NN", "$,", "VVFIN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Das wird sich weisen.", "tokens": ["Das", "wird", "sich", "wei\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PRF", "VVINF", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.7": {"line.1": {"text": "Lucinden, welch ein sch\u00f6nes Kind!", "tokens": ["Lu\u00b7cin\u00b7den", ",", "welch", "ein", "sch\u00f6\u00b7nes", "Kind", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PWAT", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das jeder J\u00fcngling lieb gewinnt,", "tokens": ["Das", "je\u00b7der", "J\u00fcng\u00b7ling", "lieb", "ge\u00b7winnt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sucht ietzt ein z\u00e4rtlicher Amynt", "tokens": ["Sucht", "ietzt", "ein", "z\u00e4rt\u00b7li\u00b7cher", "A\u00b7mynt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Im Lieben oft zu unterweisen:", "tokens": ["Im", "Lie\u00b7ben", "oft", "zu", "un\u00b7ter\u00b7wei\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Noch f\u00e4rbet, wenn er davon spricht,", "tokens": ["Noch", "f\u00e4r\u00b7bet", ",", "wenn", "er", "da\u00b7von", "spricht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "KOUS", "PPER", "PAV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ein sanftes Roth ihr hold Gesicht:", "tokens": ["Ein", "sanf\u00b7tes", "Roth", "ihr", "hold", "Ge\u00b7sicht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PPOSAT", "ADJD", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Obs in acht Tagen noch geschicht?", "tokens": ["Obs", "in", "acht", "Ta\u00b7gen", "noch", "ge\u00b7schicht", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "CARD", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Das wird sich weisen.", "tokens": ["Das", "wird", "sich", "wei\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PRF", "VVINF", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.8": {"line.1": {"text": "Cotill, ein junger Candidat,", "tokens": ["Co\u00b7till", ",", "ein", "jun\u00b7ger", "Can\u00b7di\u00b7dat", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sucht, da er noch kein Aemtgen hat,", "tokens": ["Sucht", ",", "da", "er", "noch", "kein", "A\u00b7emt\u00b7gen", "hat", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "KOUS", "PPER", "ADV", "PIAT", "NN", "VAFIN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Gerecht zu seyn in Rath und That,", "tokens": ["Ge\u00b7recht", "zu", "seyn", "in", "Rath", "und", "That", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKZU", "VAINF", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Den Richtern herrlich anzupreisen.", "tokens": ["Den", "Rich\u00b7tern", "herr\u00b7lich", "an\u00b7zu\u00b7prei\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "VVIZU", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Durch den bestochenen Patron", "tokens": ["Durch", "den", "be\u00b7sto\u00b7che\u00b7nen", "Pat\u00b7ron"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.6": {"text": "Tr\u00e4gt sein Verdienst ein Amt davon:", "tokens": ["Tr\u00e4gt", "sein", "Ver\u00b7dienst", "ein", "Amt", "da\u00b7von", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "ART", "NN", "PAV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Spricht er nun den Geschenken Hohn?", "tokens": ["Spricht", "er", "nun", "den", "Ge\u00b7schen\u00b7ken", "Hohn", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ART", "NN", "NN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.8": {"text": "Das wird sich weisen.", "tokens": ["Das", "wird", "sich", "wei\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PRF", "VVINF", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.9": {"line.1": {"text": "Wie \u00e4rgert sich Belinde nicht,", "tokens": ["Wie", "\u00e4r\u00b7gert", "sich", "Be\u00b7lin\u00b7de", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PRF", "NN", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wenn eine Frau Gesetz und Pflicht", "tokens": ["Wenn", "ei\u00b7ne", "Frau", "Ge\u00b7setz", "und", "Pflicht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und die geschworne Treue bricht!", "tokens": ["Und", "die", "ge\u00b7schwor\u00b7ne", "Treu\u00b7e", "bricht", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Da soll der Himmel sich zerrei\u00dfen.", "tokens": ["Da", "soll", "der", "Him\u00b7mel", "sich", "zer\u00b7rei\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "NN", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Itzt reichet sie ihr Herz und Hand", "tokens": ["Itzt", "rei\u00b7chet", "sie", "ihr", "Herz", "und", "Hand"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PPOSAT", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Dem jungen flatternden Cleant,", "tokens": ["Dem", "jun\u00b7gen", "flat\u00b7tern\u00b7den", "Cleant", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.7": {"text": "Ist noch ihr Eifer vom Bestand?", "tokens": ["Ist", "noch", "ihr", "Ei\u00b7fer", "vom", "Be\u00b7stand", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PPOSAT", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Das wird sich weisen.", "tokens": ["Das", "wird", "sich", "wei\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PRF", "VVINF", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.10": {"line.1": {"text": "Selinde zieht den Bellamor", "tokens": ["Se\u00b7lin\u00b7de", "zieht", "den", "Be\u00b7lla\u00b7mor"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "VVFIN", "ART", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Dem seufzervollen Lisidor", "tokens": ["Dem", "seuf\u00b7zer\u00b7vol\u00b7len", "Li\u00b7si\u00b7dor"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "In seinen hei\u00dfen W\u00fcnschen vor:", "tokens": ["In", "sei\u00b7nen", "hei\u00b7\u00dfen", "W\u00fcn\u00b7schen", "vor", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Er droht mit Gift, Pistol und Eisen:", "tokens": ["Er", "droht", "mit", "Gift", ",", "Pis\u00b7tol", "und", "Ei\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "$,", "NE", "KON", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Man l\u00e4\u00dft ihn ungeschlossen gehn,", "tokens": ["Man", "l\u00e4\u00dft", "ihn", "un\u00b7ge\u00b7schlos\u00b7sen", "gehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "L\u00e4\u00dft alles ihm im Wege stehn,", "tokens": ["L\u00e4\u00dft", "al\u00b7les", "ihm", "im", "We\u00b7ge", "stehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PPER", "APPRART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Ists um sein Leben nun geschehn?", "tokens": ["Ists", "um", "sein", "Le\u00b7ben", "nun", "ge\u00b7schehn", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "PPOSAT", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Das wird sich weisen.", "tokens": ["Das", "wird", "sich", "wei\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PRF", "VVINF", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.11": {"line.1": {"text": "Jobst, der das Geld nach Scheffeln z\u00e4hlt,", "tokens": ["Jobst", ",", "der", "das", "Geld", "nach", "Schef\u00b7feln", "z\u00e4hlt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PRELS", "ART", "NN", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dem der Verstand, nichts weiter fehlt,", "tokens": ["Dem", "der", "Ver\u00b7stand", ",", "nichts", "wei\u00b7ter", "fehlt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "ART", "NN", "$,", "PIS", "ADV", "VVFIN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Geht, von dem edlen Stolz beseelt,", "tokens": ["Geht", ",", "von", "dem", "ed\u00b7len", "Stolz", "be\u00b7seelt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "APPR", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Galant und klug zu seyn, auf Reisen:", "tokens": ["Ga\u00b7lant", "und", "klug", "zu", "seyn", ",", "auf", "Rei\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "KON", "ADJD", "PTKZU", "VAINF", "$,", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "In Frankreich, Welschland, Engeland", "tokens": ["In", "Fran\u00b7kreich", ",", "Wel\u00b7schland", ",", "En\u00b7ge\u00b7land"], "token_info": ["word", "word", "punct", "word", "punct", "word"], "pos": ["APPR", "NE", "$,", "NN", "$,", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wird bald der reiche Jobst bekannt:", "tokens": ["Wird", "bald", "der", "rei\u00b7che", "Jobst", "be\u00b7kannt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "K\u00f6mmt er zur\u00fcck reich am Verstand?", "tokens": ["K\u00f6mmt", "er", "zu\u00b7r\u00fcck", "reich", "am", "Ver\u00b7stand", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADJD", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Das wird sich weisen.", "tokens": ["Das", "wird", "sich", "wei\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PRF", "VVINF", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.12": {"line.1": {"text": "Bey R\u00f6mern, niemals leer vom Wein,", "tokens": ["Bey", "R\u00f6\u00b7mern", ",", "nie\u00b7mals", "leer", "vom", "Wein", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "ADV", "ADJD", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "H\u00f6r ich dort meine Nachbarn schreyn,", "tokens": ["H\u00f6r", "ich", "dort", "mei\u00b7ne", "Nach\u00b7barn", "schreyn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "ADV", "PPOSAT", "NN", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wer von den kriegenden Parteyn", "tokens": ["Wer", "von", "den", "krie\u00b7gen\u00b7den", "Par\u00b7teyn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Noch sieget? Oestreich oder Preussen?", "tokens": ["Noch", "sie\u00b7get", "?", "O\u00b7e\u00b7streich", "o\u00b7der", "Preus\u00b7sen", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$.", "NE", "KON", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.5": {"text": "Sie rufen mir entr\u00fcstet zu:", "tokens": ["Sie", "ru\u00b7fen", "mir", "ent\u00b7r\u00fcs\u00b7tet", "zu", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "\u00bbkomm Bruder, komm, entscheide du!\u00ab", "tokens": ["\u00bb", "komm", "Bru\u00b7der", ",", "komm", ",", "ent\u00b7schei\u00b7de", "du", "!", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "word", "punct", "word", "word", "punct", "punct"], "pos": ["$(", "VVFIN", "NN", "$,", "VVFIN", "$,", "VVFIN", "PPER", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Ich sag: ihr Narren, trinkt in Ruh,", "tokens": ["Ich", "sag", ":", "ihr", "Nar\u00b7ren", ",", "trinkt", "in", "Ruh", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "PPOSAT", "NN", "$,", "VVFIN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Das wird sich weisen.", "tokens": ["Das", "wird", "sich", "wei\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PRF", "VVINF", "$."], "meter": "-+-+-", "measure": "iambic.di"}}}}}