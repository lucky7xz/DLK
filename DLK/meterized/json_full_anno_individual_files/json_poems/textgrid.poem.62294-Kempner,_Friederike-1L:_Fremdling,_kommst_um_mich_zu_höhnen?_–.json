{"textgrid.poem.62294": {"metadata": {"author": {"name": "Kempner, Friederike", "birth": "N.A.", "death": "N.A."}, "title": "1L: Fremdling, kommst um mich zu h\u00f6hnen? \u2013", "genre": "verse", "period": "N.A.", "pub_year": 1868, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Fremdling, kommst um mich zu h\u00f6hnen? \u2013", "tokens": ["Fremd\u00b7ling", ",", "kommst", "um", "mich", "zu", "h\u00f6h\u00b7nen", "?", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "$,", "VVFIN", "APPR", "PPER", "PTKZU", "VVINF", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Nein! \u2013 ich weih' Dir ein'ge Tr\u00e4nen,", "tokens": ["Nein", "!", "\u2013", "ich", "weih'", "Dir", "ein'\u00b7ge", "Tr\u00e4\u00b7nen", ","], "token_info": ["word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$.", "$(", "PPER", "VVFIN", "PPER", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Deiner Gr\u00f6\u00dfe, schwer verkannt,", "tokens": ["Dei\u00b7ner", "Gr\u00f6\u00b7\u00dfe", ",", "schwer", "ver\u00b7kannt", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "ADJD", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Schwer verkannt im eig'nen Land!", "tokens": ["Schwer", "ver\u00b7kannt", "im", "eig'\u00b7nen", "Land", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVPP", "APPRART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Hattest Ru\u00dflands Macht gebrochen, \u2013", "tokens": ["Hat\u00b7test", "Ru\u00df\u00b7lands", "Macht", "ge\u00b7bro\u00b7chen", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["VAFIN", "NE", "NN", "VVPP", "$,", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Hattest Frieden Dir versprochen, \u2013", "tokens": ["Hat\u00b7test", "Frie\u00b7den", "Dir", "ver\u00b7spro\u00b7chen", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["VAFIN", "NN", "PPER", "VVINF", "$,", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Nicht mehr Ruhm, befleckt mit Blut,", "tokens": ["Nicht", "mehr", "Ruhm", ",", "be\u00b7fleckt", "mit", "Blut", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "PIAT", "NN", "$,", "VVFIN", "APPR", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Trachtetest nach h\u00f6hrem Gut. \u2013", "tokens": ["Trach\u00b7te\u00b7test", "nach", "h\u00f6h\u00b7rem", "Gut", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "APPR", "ADJA", "NN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Napoleonische Ideen", "tokens": ["Na\u00b7po\u00b7le\u00b7o\u00b7ni\u00b7sche", "I\u00b7deen"], "token_info": ["word", "word"], "pos": ["ADJA", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Sollten endlich jetzt geschehen", "tokens": ["Soll\u00b7ten", "end\u00b7lich", "jetzt", "ge\u00b7sche\u00b7hen"], "token_info": ["word", "word", "word", "word"], "pos": ["VMFIN", "ADV", "ADV", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Schafftest Raum und Luft und Licht \u2013", "tokens": ["Schaff\u00b7test", "Raum", "und", "Luft", "und", "Licht", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "KON", "NN", "KON", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Aber Frankreich dankte nicht. \u2013", "tokens": ["A\u00b7ber", "Fran\u00b7kreich", "dank\u00b7te", "nicht", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "NE", "VVFIN", "PTKNEG", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Bautest f\u00fcr die Arbeit S\u00e4le", "tokens": ["Bau\u00b7test", "f\u00fcr", "die", "Ar\u00b7beit", "S\u00e4\u00b7le"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "ART", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und \u2013 da\u00df ich es hier erz\u00e4hle,", "tokens": ["Und", "\u2013", "da\u00df", "ich", "es", "hier", "er\u00b7z\u00e4h\u00b7le", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$(", "KOUS", "PPER", "PPER", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "W\u00fcrdigtest mit hellem Blick", "tokens": ["W\u00fcr\u00b7dig\u00b7test", "mit", "hel\u00b7lem", "Blick"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "APPR", "ADJA", "NN"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.4": {"text": "Unsrer Sitten Mi\u00dfgeschick: \u2013", "tokens": ["Uns\u00b7rer", "Sit\u00b7ten", "Mi\u00df\u00b7ge\u00b7schick", ":", "\u2013"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["PPOSAT", "NN", "NN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Anerkanntest die Gefahren", "tokens": ["An\u00b7er\u00b7kann\u00b7test", "die", "Ge\u00b7fah\u00b7ren"], "token_info": ["word", "word", "word"], "pos": ["VVFIN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Allerschrecklichsten, furchtbaren,", "tokens": ["Al\u00b7ler\u00b7schreck\u00b7lichs\u00b7ten", ",", "furcht\u00b7ba\u00b7ren", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["ADJA", "$,", "ADJA", "$,"], "meter": "--+--+--", "measure": "anapaest.di.plus"}, "line.3": {"text": "Grausam Los, das jedem droht \u2013", "tokens": ["Grau\u00b7sam", "Los", ",", "das", "je\u00b7dem", "droht", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "PRELS", "PIS", "VVFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Jenen, ach, lebend'gen Tod! \u2013", "tokens": ["Je\u00b7nen", ",", "ach", ",", "le\u00b7ben\u00b7d'\u00b7gen", "Tod", "!", "\u2013"], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "punct"], "pos": ["PDS", "$,", "ITJ", "$,", "ADJA", "NN", "$.", "$("], "meter": "+----+-+", "measure": "dactylic.init"}}, "stanza.6": {"line.1": {"text": "Frankreich gl\u00fccklich, wollte tr\u00e4umen", "tokens": ["Fran\u00b7kreich", "gl\u00fcck\u00b7lich", ",", "woll\u00b7te", "tr\u00e4u\u00b7men"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["NE", "ADJD", "$,", "VMFIN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Von des Rheines Bl\u00fctenb\u00e4umen,", "tokens": ["Von", "des", "Rhei\u00b7nes", "Bl\u00fc\u00b7ten\u00b7b\u00e4u\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wollte Kampf und Krieg \u2013 nicht Ruh'", "tokens": ["Woll\u00b7te", "Kampf", "und", "Krieg", "\u2013", "nicht", "Ruh'"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["VMFIN", "NN", "KON", "NN", "$(", "PTKNEG", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und das Opfer, das warst Du! \u2013", "tokens": ["Und", "das", "Op\u00b7fer", ",", "das", "warst", "Du", "!", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ART", "NN", "$,", "PDS", "VAFIN", "PPER", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Napoleonische Ideen", "tokens": ["Na\u00b7po\u00b7le\u00b7o\u00b7ni\u00b7sche", "I\u00b7deen"], "token_info": ["word", "word"], "pos": ["ADJA", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Werden aber doch gestehen,", "tokens": ["Wer\u00b7den", "a\u00b7ber", "doch", "ge\u00b7ste\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und den Dank, der Dir geziemt,", "tokens": ["Und", "den", "Dank", ",", "der", "Dir", "ge\u00b7ziemt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "PRELS", "PPER", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Ganz die Weltgeschichte r\u00fchmt. \u2013", "tokens": ["Ganz", "die", "Welt\u00b7ge\u00b7schich\u00b7te", "r\u00fchmt", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "ART", "NN", "VVFIN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Fremdling, kommst um mich zu h\u00f6hnen? \u2013", "tokens": ["Fremd\u00b7ling", ",", "kommst", "um", "mich", "zu", "h\u00f6h\u00b7nen", "?", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "$,", "VVFIN", "APPR", "PPER", "PTKZU", "VVINF", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Nein! \u2013 ich weih' Dir ein'ge Tr\u00e4nen,", "tokens": ["Nein", "!", "\u2013", "ich", "weih'", "Dir", "ein'\u00b7ge", "Tr\u00e4\u00b7nen", ","], "token_info": ["word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$.", "$(", "PPER", "VVFIN", "PPER", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Deiner Gr\u00f6\u00dfe, schwer verkannt,", "tokens": ["Dei\u00b7ner", "Gr\u00f6\u00b7\u00dfe", ",", "schwer", "ver\u00b7kannt", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "ADJD", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Schwer verkannt im eig'nen Land!", "tokens": ["Schwer", "ver\u00b7kannt", "im", "eig'\u00b7nen", "Land", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVPP", "APPRART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Hattest Ru\u00dflands Macht gebrochen, \u2013", "tokens": ["Hat\u00b7test", "Ru\u00df\u00b7lands", "Macht", "ge\u00b7bro\u00b7chen", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["VAFIN", "NE", "NN", "VVPP", "$,", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Hattest Frieden Dir versprochen, \u2013", "tokens": ["Hat\u00b7test", "Frie\u00b7den", "Dir", "ver\u00b7spro\u00b7chen", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["VAFIN", "NN", "PPER", "VVINF", "$,", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Nicht mehr Ruhm, befleckt mit Blut,", "tokens": ["Nicht", "mehr", "Ruhm", ",", "be\u00b7fleckt", "mit", "Blut", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "PIAT", "NN", "$,", "VVFIN", "APPR", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Trachtetest nach h\u00f6hrem Gut. \u2013", "tokens": ["Trach\u00b7te\u00b7test", "nach", "h\u00f6h\u00b7rem", "Gut", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "APPR", "ADJA", "NN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Napoleonische Ideen", "tokens": ["Na\u00b7po\u00b7le\u00b7o\u00b7ni\u00b7sche", "I\u00b7deen"], "token_info": ["word", "word"], "pos": ["ADJA", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Sollten endlich jetzt geschehen", "tokens": ["Soll\u00b7ten", "end\u00b7lich", "jetzt", "ge\u00b7sche\u00b7hen"], "token_info": ["word", "word", "word", "word"], "pos": ["VMFIN", "ADV", "ADV", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Schafftest Raum und Luft und Licht \u2013", "tokens": ["Schaff\u00b7test", "Raum", "und", "Luft", "und", "Licht", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "KON", "NN", "KON", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Aber Frankreich dankte nicht. \u2013", "tokens": ["A\u00b7ber", "Fran\u00b7kreich", "dank\u00b7te", "nicht", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "NE", "VVFIN", "PTKNEG", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Bautest f\u00fcr die Arbeit S\u00e4le", "tokens": ["Bau\u00b7test", "f\u00fcr", "die", "Ar\u00b7beit", "S\u00e4\u00b7le"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "ART", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und \u2013 da\u00df ich es hier erz\u00e4hle,", "tokens": ["Und", "\u2013", "da\u00df", "ich", "es", "hier", "er\u00b7z\u00e4h\u00b7le", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$(", "KOUS", "PPER", "PPER", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "W\u00fcrdigtest mit hellem Blick", "tokens": ["W\u00fcr\u00b7dig\u00b7test", "mit", "hel\u00b7lem", "Blick"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "APPR", "ADJA", "NN"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.4": {"text": "Unsrer Sitten Mi\u00dfgeschick: \u2013", "tokens": ["Uns\u00b7rer", "Sit\u00b7ten", "Mi\u00df\u00b7ge\u00b7schick", ":", "\u2013"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["PPOSAT", "NN", "NN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Anerkanntest die Gefahren", "tokens": ["An\u00b7er\u00b7kann\u00b7test", "die", "Ge\u00b7fah\u00b7ren"], "token_info": ["word", "word", "word"], "pos": ["VVFIN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Allerschrecklichsten, furchtbaren,", "tokens": ["Al\u00b7ler\u00b7schreck\u00b7lichs\u00b7ten", ",", "furcht\u00b7ba\u00b7ren", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["ADJA", "$,", "ADJA", "$,"], "meter": "--+--+--", "measure": "anapaest.di.plus"}, "line.3": {"text": "Grausam Los, das jedem droht \u2013", "tokens": ["Grau\u00b7sam", "Los", ",", "das", "je\u00b7dem", "droht", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "PRELS", "PIS", "VVFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Jenen, ach, lebend'gen Tod! \u2013", "tokens": ["Je\u00b7nen", ",", "ach", ",", "le\u00b7ben\u00b7d'\u00b7gen", "Tod", "!", "\u2013"], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "punct"], "pos": ["PDS", "$,", "ITJ", "$,", "ADJA", "NN", "$.", "$("], "meter": "+----+-+", "measure": "dactylic.init"}}, "stanza.13": {"line.1": {"text": "Frankreich gl\u00fccklich, wollte tr\u00e4umen", "tokens": ["Fran\u00b7kreich", "gl\u00fcck\u00b7lich", ",", "woll\u00b7te", "tr\u00e4u\u00b7men"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["NE", "ADJD", "$,", "VMFIN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Von des Rheines Bl\u00fctenb\u00e4umen,", "tokens": ["Von", "des", "Rhei\u00b7nes", "Bl\u00fc\u00b7ten\u00b7b\u00e4u\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wollte Kampf und Krieg \u2013 nicht Ruh'", "tokens": ["Woll\u00b7te", "Kampf", "und", "Krieg", "\u2013", "nicht", "Ruh'"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["VMFIN", "NN", "KON", "NN", "$(", "PTKNEG", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und das Opfer, das warst Du! \u2013", "tokens": ["Und", "das", "Op\u00b7fer", ",", "das", "warst", "Du", "!", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ART", "NN", "$,", "PDS", "VAFIN", "PPER", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "Napoleonische Ideen", "tokens": ["Na\u00b7po\u00b7le\u00b7o\u00b7ni\u00b7sche", "I\u00b7deen"], "token_info": ["word", "word"], "pos": ["ADJA", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Werden aber doch gestehen,", "tokens": ["Wer\u00b7den", "a\u00b7ber", "doch", "ge\u00b7ste\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und den Dank, der Dir geziemt,", "tokens": ["Und", "den", "Dank", ",", "der", "Dir", "ge\u00b7ziemt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "PRELS", "PPER", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Ganz die Weltgeschichte r\u00fchmt. \u2013", "tokens": ["Ganz", "die", "Welt\u00b7ge\u00b7schich\u00b7te", "r\u00fchmt", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "ART", "NN", "VVFIN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}