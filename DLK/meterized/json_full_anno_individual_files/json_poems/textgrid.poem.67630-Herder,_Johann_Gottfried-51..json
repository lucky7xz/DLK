{"textgrid.poem.67630": {"metadata": {"author": {"name": "Herder, Johann Gottfried", "birth": "N.A.", "death": "N.A."}, "title": "51.", "genre": "verse", "period": "N.A.", "pub_year": 1773, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "\u00bbund ich bin doch", "tokens": ["\u00bb", "und", "ich", "bin", "doch"], "token_info": ["punct", "word", "word", "word", "word"], "pos": ["$(", "KON", "PPER", "VAFIN", "ADV"], "meter": "-+-+", "measure": "iambic.di"}, "line.2": {"text": "Vornehmer noch", "tokens": ["Vor\u00b7neh\u00b7mer", "noch"], "token_info": ["word", "word"], "pos": ["ADV", "ADV"], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "Als Du, Frau L\u00f6wenk\u00f6nigin!\u00ab", "tokens": ["Als", "Du", ",", "Frau", "L\u00f6\u00b7wen\u00b7k\u00f6\u00b7ni\u00b7gin", "!", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["KOUS", "PPER", "$,", "NN", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und trippelt vor sie hin.", "tokens": ["Und", "trip\u00b7pelt", "vor", "sie", "hin", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PPER", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "\u00bbklein, als ich bin,", "tokens": ["\u00bb", "klein", ",", "als", "ich", "bin", ","], "token_info": ["punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "$,", "KOUS", "PPER", "VAFIN", "$,"], "meter": "+--+", "measure": "iambic.di.chol"}, "line.6": {"text": "Vermehre", "tokens": ["Ver\u00b7meh\u00b7re"], "token_info": ["word"], "pos": ["NN"], "meter": "-+-", "measure": "amphibrach.single"}, "line.7": {"text": "Zu meines Manns und meiner Kleinen Ehre", "tokens": ["Zu", "mei\u00b7nes", "Manns", "und", "mei\u00b7ner", "Klei\u00b7nen", "Eh\u00b7re"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "KON", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Ich mein Geschlecht doch immerzu", "tokens": ["Ich", "mein", "Ge\u00b7schlecht", "doch", "im\u00b7mer\u00b7zu"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "PPOSAT", "NN", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Jahrj\u00e4hrlich mehr als Du.\u00ab", "tokens": ["Jahr\u00b7j\u00e4hr\u00b7lich", "mehr", "als", "Du", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ADJD", "PIAT", "KOKOM", "PPER", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.10": {"text": "\u00bbfrau Hase,\u00ab sprach die K\u00f6nigin,", "tokens": ["\u00bb", "frau", "Ha\u00b7se", ",", "\u00ab", "sprach", "die", "K\u00f6\u00b7ni\u00b7gin", ","], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "NN", "$,", "$(", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "\u00bbgeb\u00e4r' Sie Hasen immerhin", "tokens": ["\u00bb", "ge\u00b7b\u00e4r'", "Sie", "Ha\u00b7sen", "im\u00b7mer\u00b7hin"], "token_info": ["punct", "word", "word", "word", "word"], "pos": ["$(", "VVFIN", "PPER", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Und oft und viel und mancherlei", "tokens": ["Und", "oft", "und", "viel", "und", "man\u00b7cher\u00b7lei"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "KON", "ADV", "KON", "PIS"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Zu aller Hasen Ehre;", "tokens": ["Zu", "al\u00b7ler", "Ha\u00b7sen", "Eh\u00b7re", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.14": {"text": "Was einmal ich geb\u00e4re,", "tokens": ["Was", "ein\u00b7mal", "ich", "ge\u00b7b\u00e4\u00b7re", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.15": {"text": "Ist Leu.\u00ab", "tokens": ["Ist", "Leu", ".", "\u00ab"], "token_info": ["word", "word", "punct", "punct"], "pos": ["VAFIN", "NE", "$.", "$("], "meter": "-+", "measure": "iambic.single"}}, "stanza.2": {"line.1": {"text": "\u00bbund ich bin doch", "tokens": ["\u00bb", "und", "ich", "bin", "doch"], "token_info": ["punct", "word", "word", "word", "word"], "pos": ["$(", "KON", "PPER", "VAFIN", "ADV"], "meter": "-+-+", "measure": "iambic.di"}, "line.2": {"text": "Vornehmer noch", "tokens": ["Vor\u00b7neh\u00b7mer", "noch"], "token_info": ["word", "word"], "pos": ["ADV", "ADV"], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "Als Du, Frau L\u00f6wenk\u00f6nigin!\u00ab", "tokens": ["Als", "Du", ",", "Frau", "L\u00f6\u00b7wen\u00b7k\u00f6\u00b7ni\u00b7gin", "!", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["KOUS", "PPER", "$,", "NN", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und trippelt vor sie hin.", "tokens": ["Und", "trip\u00b7pelt", "vor", "sie", "hin", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PPER", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "\u00bbklein, als ich bin,", "tokens": ["\u00bb", "klein", ",", "als", "ich", "bin", ","], "token_info": ["punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "$,", "KOUS", "PPER", "VAFIN", "$,"], "meter": "+--+", "measure": "iambic.di.chol"}, "line.6": {"text": "Vermehre", "tokens": ["Ver\u00b7meh\u00b7re"], "token_info": ["word"], "pos": ["NN"], "meter": "-+-", "measure": "amphibrach.single"}, "line.7": {"text": "Zu meines Manns und meiner Kleinen Ehre", "tokens": ["Zu", "mei\u00b7nes", "Manns", "und", "mei\u00b7ner", "Klei\u00b7nen", "Eh\u00b7re"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "KON", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Ich mein Geschlecht doch immerzu", "tokens": ["Ich", "mein", "Ge\u00b7schlecht", "doch", "im\u00b7mer\u00b7zu"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "PPOSAT", "NN", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Jahrj\u00e4hrlich mehr als Du.\u00ab", "tokens": ["Jahr\u00b7j\u00e4hr\u00b7lich", "mehr", "als", "Du", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ADJD", "PIAT", "KOKOM", "PPER", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.10": {"text": "\u00bbfrau Hase,\u00ab sprach die K\u00f6nigin,", "tokens": ["\u00bb", "frau", "Ha\u00b7se", ",", "\u00ab", "sprach", "die", "K\u00f6\u00b7ni\u00b7gin", ","], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "NN", "$,", "$(", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "\u00bbgeb\u00e4r' Sie Hasen immerhin", "tokens": ["\u00bb", "ge\u00b7b\u00e4r'", "Sie", "Ha\u00b7sen", "im\u00b7mer\u00b7hin"], "token_info": ["punct", "word", "word", "word", "word"], "pos": ["$(", "VVFIN", "PPER", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Und oft und viel und mancherlei", "tokens": ["Und", "oft", "und", "viel", "und", "man\u00b7cher\u00b7lei"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "KON", "ADV", "KON", "PIS"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Zu aller Hasen Ehre;", "tokens": ["Zu", "al\u00b7ler", "Ha\u00b7sen", "Eh\u00b7re", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.14": {"text": "Was einmal ich geb\u00e4re,", "tokens": ["Was", "ein\u00b7mal", "ich", "ge\u00b7b\u00e4\u00b7re", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.15": {"text": "Ist Leu.\u00ab", "tokens": ["Ist", "Leu", ".", "\u00ab"], "token_info": ["word", "word", "punct", "punct"], "pos": ["VAFIN", "NE", "$.", "$("], "meter": "-+", "measure": "iambic.single"}}}}}