{"dta.poem.9852": {"metadata": {"author": {"name": "Hofmannswaldau, Christian Hofmann von", "birth": "N.A.", "death": "N.A."}, "title": "Die m\u00e4nner auch nicht.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1697", "urn": "urn:nbn:de:kobv:b4-200905199377", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Ein mann sey wie er immer sey/", "tokens": ["Ein", "mann", "sey", "wie", "er", "im\u00b7mer", "sey", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "KOKOM", "PPER", "ADV", "VAFIN", "$("], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.2": {"text": "So wird ihm doch was fehlen;", "tokens": ["So", "wird", "ihm", "doch", "was", "feh\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "PIS", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Der s\u00e4uffer legt das geld nicht bey/", "tokens": ["Der", "s\u00e4uf\u00b7fer", "legt", "das", "geld", "nicht", "bey", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "PTKNEG", "APPR", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Er jagt es durch die kehlen;", "tokens": ["Er", "jagt", "es", "durch", "die", "keh\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "ART", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Der jung ist liederlicher art/", "tokens": ["Der", "jung", "ist", "lie\u00b7der\u00b7li\u00b7cher", "art", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "VAFIN", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und nascht gern auf der seiten;", "tokens": ["Und", "nascht", "gern", "auf", "der", "sei\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Der alte ist ein n\u00f6\u00dfelbart/", "tokens": ["Der", "al\u00b7te", "ist", "ein", "n\u00f6\u00b7\u00dfel\u00b7bart", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VAFIN", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Und kan wol nicht zu zeiten.", "tokens": ["Und", "kan", "wol", "nicht", "zu", "zei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ADV", "PTKNEG", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.9": {"text": "Der geitz des reichen leidet noth", "tokens": ["Der", "geitz", "des", "rei\u00b7chen", "lei\u00b7det", "noth"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "ADJA", "VVFIN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Bey seinem vollen kasten;", "tokens": ["Bey", "sei\u00b7nem", "vol\u00b7len", "kas\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.11": {"text": "Der arme l\u00e4st bey schwartzem brodt", "tokens": ["Der", "ar\u00b7me", "l\u00e4st", "bey", "schwart\u00b7zem", "brodt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Das arme weibchen fasten.", "tokens": ["Das", "ar\u00b7me", "weib\u00b7chen", "fas\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.13": {"text": "Der krieger ist kein courtisan", "tokens": ["Der", "krie\u00b7ger", "ist", "kein", "cour\u00b7ti\u00b7san"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "VAFIN", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Und macht es nicht fein sachte;", "tokens": ["Und", "macht", "es", "nicht", "fein", "sach\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PTKNEG", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.15": {"text": "Dem keuschen kommts nicht allzeit an;", "tokens": ["Dem", "keu\u00b7schen", "kommts", "nicht", "all\u00b7zeit", "an", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "PTKNEG", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Dem wilden alle nachte.", "tokens": ["Dem", "wil\u00b7den", "al\u00b7le", "nach\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "PIS", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.17": {"text": "Der hochgelahrte ist erpicht", "tokens": ["Der", "hoch\u00b7ge\u00b7lahr\u00b7te", "ist", "er\u00b7picht"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "VAFIN", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.18": {"text": "Allein auf seine b\u00fccher;", "tokens": ["Al\u00b7lein", "auf", "sei\u00b7ne", "b\u00fc\u00b7cher", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPOSAT", "ADJA", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.19": {"text": "Der ignorant taugt folgends nicht", "tokens": ["Der", "ig\u00b7no\u00b7rant", "taugt", "fol\u00b7gends", "nicht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJD", "VVFIN", "PIS", "PTKNEG"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.20": {"text": "Und ist noch wunderlicher.", "tokens": ["Und", "ist", "noch", "wun\u00b7der\u00b7li\u00b7cher", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "ADJD", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.21": {"text": "Mit kurtzem: es bleibt wohl dabey", "tokens": ["Mit", "kurt\u00b7zem", ":", "es", "bleibt", "wohl", "da\u00b7bey"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "$.", "PPER", "VVFIN", "ADV", "PAV"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.22": {"text": "Und ist nicht zu verhehlen;", "tokens": ["Und", "ist", "nicht", "zu", "ver\u00b7heh\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PTKNEG", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.23": {"text": "Ein mann sey wie er immer sey/", "tokens": ["Ein", "mann", "sey", "wie", "er", "im\u00b7mer", "sey", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "KOKOM", "PPER", "ADV", "VAFIN", "$("], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.24": {"text": "So wird ihm doch was fehlen.", "tokens": ["So", "wird", "ihm", "doch", "was", "feh\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "PIS", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Ich mu\u00df Eudoxe dir/ und Creon/ doch entdecken/", "tokens": ["Ich", "mu\u00df", "Eu\u00b7do\u00b7xe", "dir", "/", "und", "Creon", "/", "doch", "ent\u00b7de\u00b7cken", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "NE", "PPER", "$(", "KON", "NE", "$(", "ADV", "VVINF", "$("], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.2": {"text": "Wie ich euch gestern sah verbotner speise schmecken:", "tokens": ["Wie", "ich", "euch", "ge\u00b7stern", "sah", "ver\u00b7bot\u00b7ner", "spei\u00b7se", "schme\u00b7cken", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PPER", "ADV", "VVFIN", "ADJA", "NN", "VVINF", "$."], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Denn da ihr beyderseits gantz sicher dacht zu seyn/", "tokens": ["Denn", "da", "ihr", "bey\u00b7der\u00b7seits", "gantz", "si\u00b7cher", "dacht", "zu", "seyn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "ADV", "ADJD", "VVFIN", "PTKZU", "VAINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So guckt ich unverhofft zum schl\u00fcssel-loch hinein.", "tokens": ["So", "guckt", "ich", "un\u00b7ver\u00b7hofft", "zum", "schl\u00fcs\u00b7sel\u00b7loch", "hin\u00b7ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "APPRART", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Doch weil ich schweigen kan/ so soll kein mensch nicht wissen/", "tokens": ["Doch", "weil", "ich", "schwei\u00b7gen", "kan", "/", "so", "soll", "kein", "mensch", "nicht", "wis\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "VVINF", "VMFIN", "$(", "ADV", "VMFIN", "PIAT", "NN", "PTKNEG", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Da\u00df ihr euch \u00f6ffters so pflegt ingeheim zu k\u00fcssen.", "tokens": ["Da\u00df", "ihr", "euch", "\u00f6ff\u00b7ters", "so", "pflegt", "in\u00b7ge\u00b7heim", "zu", "k\u00fcs\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "ADV", "ADV", "VVFIN", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.7": {"text": "Nur dieses rath ich euch/ und bitte/ folgt mir doch;", "tokens": ["Nur", "die\u00b7ses", "rath", "ich", "euch", "/", "und", "bit\u00b7te", "/", "folgt", "mir", "doch", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PDAT", "NN", "PPER", "PPER", "$(", "KON", "PTKANT", "$(", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Wolt ihrs noch weiter thun/ verstopfft das schl\u00fcssel-loch.", "tokens": ["Wolt", "ihrs", "noch", "wei\u00b7ter", "thun", "/", "ver\u00b7stopfft", "das", "schl\u00fcs\u00b7sel\u00b7loch", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "ADV", "VVINF", "$(", "VVFIN", "ART", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}