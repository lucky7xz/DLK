{"textgrid.poem.43469": {"metadata": {"author": {"name": "Hoffmann von Fallersleben, August Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "1L: Es kam ein deutscher Edelmann", "genre": "verse", "period": "N.A.", "pub_year": 1836, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Es kam ein deutscher Edelmann", "tokens": ["Es", "kam", "ein", "deut\u00b7scher", "E\u00b7del\u00b7mann"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Einst vor das Himmelsthor;", "tokens": ["Einst", "vor", "das", "Him\u00b7mel\u00b7sthor", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Mach auf, mach auf! so pocht' er dran,", "tokens": ["Mach", "auf", ",", "mach", "auf", "!", "so", "pocht'", "er", "dran", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "$,", "VVFIN", "PTKVZ", "$.", "ADV", "VVFIN", "PPER", "PAV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und l\u00e4rmte sehr davor.", "tokens": ["Und", "l\u00e4rm\u00b7te", "sehr", "da\u00b7vor", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "PAV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "So la lala lala lala!", "tokens": ["So", "la", "la\u00b7la", "la\u00b7la", "la\u00b7la", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "FM", "FM", "FM", "FM", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Mach auf, mach auf! so pocht' er dran,", "tokens": ["Mach", "auf", ",", "mach", "auf", "!", "so", "pocht'", "er", "dran", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "$,", "VVFIN", "PTKVZ", "$.", "ADV", "VVFIN", "PPER", "PAV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und l\u00e4rmte sehr davor.", "tokens": ["Und", "l\u00e4rm\u00b7te", "sehr", "da\u00b7vor", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "PAV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "St. Petrus kommt gemach heran,", "tokens": ["St.", "Pet\u00b7rus", "kommt", "ge\u00b7mach", "he\u00b7ran", ","], "token_info": ["abbreviation", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VVFIN", "ADV", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Er hat den L\u00e4rm geh\u00f6rt:", "tokens": ["Er", "hat", "den", "L\u00e4rm", "ge\u00b7h\u00f6rt", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "\u00bbwas ist das f\u00fcr ein grober Mann,", "tokens": ["\u00bb", "was", "ist", "das", "f\u00fcr", "ein", "gro\u00b7ber", "Mann", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "VAFIN", "PDS", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der mich so sp\u00e4t noch st\u00f6rt?", "tokens": ["Der", "mich", "so", "sp\u00e4t", "noch", "st\u00f6rt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "ADJD", "ADV", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "So la lala lala lala!", "tokens": ["So", "la", "la\u00b7la", "la\u00b7la", "la\u00b7la", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "FM", "FM", "FM", "FM", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Was ist das f\u00fcr ein grober Mann,", "tokens": ["Was", "ist", "das", "f\u00fcr", "ein", "gro\u00b7ber", "Mann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PDS", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Der mich so sp\u00e4t noch st\u00f6rt?\u00ab", "tokens": ["Der", "mich", "so", "sp\u00e4t", "noch", "st\u00f6rt", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "PPER", "ADV", "ADJD", "ADV", "VVFIN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Ich bin ein deutscher Edelmann,", "tokens": ["Ich", "bin", "ein", "deut\u00b7scher", "E\u00b7del\u00b7mann", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Kurz ein Herr ", "tokens": ["Kurz", "ein", "Herr"], "token_info": ["word", "word", "word"], "pos": ["ADJD", "ART", "NN"], "meter": "+-+", "measure": "trochaic.di"}, "line.3": {"text": "Und h\u00f6rst du mir denn das nicht an?", "tokens": ["Und", "h\u00f6rst", "du", "mir", "denn", "das", "nicht", "an", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PPER", "ADV", "PDS", "PTKNEG", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Hab' mehr Respect vor mir!", "tokens": ["Hab'", "mehr", "Res\u00b7pect", "vor", "mir", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PIAT", "NN", "APPR", "PPER", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "So la lala lala lala!", "tokens": ["So", "la", "la\u00b7la", "la\u00b7la", "la\u00b7la", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "FM", "FM", "FM", "FM", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und h\u00f6rst du mir denn das nicht an?", "tokens": ["Und", "h\u00f6rst", "du", "mir", "denn", "das", "nicht", "an", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PPER", "ADV", "PDS", "PTKNEG", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Hab' mehr Respect vor mir!", "tokens": ["Hab'", "mehr", "Res\u00b7pect", "vor", "mir", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PIAT", "NN", "APPR", "PPER", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "\u00bbo la\u00df dein L\u00e4rmen und dein Schrei'n!", "tokens": ["\u00bb", "o", "la\u00df", "dein", "L\u00e4r\u00b7men", "und", "dein", "Schrei'n", "!"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "FM", "VVIMP", "PPOSAT", "NN", "KON", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Such anderswo Quartier!", "tokens": ["Such", "an\u00b7ders\u00b7wo", "Quar\u00b7tier", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "ADV", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Bei deines Gleichen willst du sein,", "tokens": ["Bei", "dei\u00b7nes", "Glei\u00b7chen", "willst", "du", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VMFIN", "PPER", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die findest du nicht hier.", "tokens": ["Die", "fin\u00b7dest", "du", "nicht", "hier", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "PTKNEG", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "So la lala lala lala!", "tokens": ["So", "la", "la\u00b7la", "la\u00b7la", "la\u00b7la", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "FM", "FM", "FM", "FM", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Bei deines Gleichen willst du sein,", "tokens": ["Bei", "dei\u00b7nes", "Glei\u00b7chen", "willst", "du", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VMFIN", "PPER", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Die findest du nicht hier.\u00ab", "tokens": ["Die", "fin\u00b7dest", "du", "nicht", "hier", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PDS", "VVFIN", "PPER", "PTKNEG", "ADV", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Es kam ein deutscher Edelmann", "tokens": ["Es", "kam", "ein", "deut\u00b7scher", "E\u00b7del\u00b7mann"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Einst vor das Himmelsthor;", "tokens": ["Einst", "vor", "das", "Him\u00b7mel\u00b7sthor", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Mach auf, mach auf! so pocht' er dran,", "tokens": ["Mach", "auf", ",", "mach", "auf", "!", "so", "pocht'", "er", "dran", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "$,", "VVFIN", "PTKVZ", "$.", "ADV", "VVFIN", "PPER", "PAV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und l\u00e4rmte sehr davor.", "tokens": ["Und", "l\u00e4rm\u00b7te", "sehr", "da\u00b7vor", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "PAV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "So la lala lala lala!", "tokens": ["So", "la", "la\u00b7la", "la\u00b7la", "la\u00b7la", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "FM", "FM", "FM", "FM", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Mach auf, mach auf! so pocht' er dran,", "tokens": ["Mach", "auf", ",", "mach", "auf", "!", "so", "pocht'", "er", "dran", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "$,", "VVFIN", "PTKVZ", "$.", "ADV", "VVFIN", "PPER", "PAV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und l\u00e4rmte sehr davor.", "tokens": ["Und", "l\u00e4rm\u00b7te", "sehr", "da\u00b7vor", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "PAV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "St. Petrus kommt gemach heran,", "tokens": ["St.", "Pet\u00b7rus", "kommt", "ge\u00b7mach", "he\u00b7ran", ","], "token_info": ["abbreviation", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VVFIN", "ADV", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Er hat den L\u00e4rm geh\u00f6rt:", "tokens": ["Er", "hat", "den", "L\u00e4rm", "ge\u00b7h\u00f6rt", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "\u00bbwas ist das f\u00fcr ein grober Mann,", "tokens": ["\u00bb", "was", "ist", "das", "f\u00fcr", "ein", "gro\u00b7ber", "Mann", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "VAFIN", "PDS", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der mich so sp\u00e4t noch st\u00f6rt?", "tokens": ["Der", "mich", "so", "sp\u00e4t", "noch", "st\u00f6rt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "ADJD", "ADV", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "So la lala lala lala!", "tokens": ["So", "la", "la\u00b7la", "la\u00b7la", "la\u00b7la", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "FM", "FM", "FM", "FM", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Was ist das f\u00fcr ein grober Mann,", "tokens": ["Was", "ist", "das", "f\u00fcr", "ein", "gro\u00b7ber", "Mann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PDS", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Der mich so sp\u00e4t noch st\u00f6rt?\u00ab", "tokens": ["Der", "mich", "so", "sp\u00e4t", "noch", "st\u00f6rt", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "PPER", "ADV", "ADJD", "ADV", "VVFIN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Ich bin ein deutscher Edelmann,", "tokens": ["Ich", "bin", "ein", "deut\u00b7scher", "E\u00b7del\u00b7mann", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Kurz ein Herr ", "tokens": ["Kurz", "ein", "Herr"], "token_info": ["word", "word", "word"], "pos": ["ADJD", "ART", "NN"], "meter": "+-+", "measure": "trochaic.di"}, "line.3": {"text": "Und h\u00f6rst du mir denn das nicht an?", "tokens": ["Und", "h\u00f6rst", "du", "mir", "denn", "das", "nicht", "an", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PPER", "ADV", "PDS", "PTKNEG", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Hab' mehr Respect vor mir!", "tokens": ["Hab'", "mehr", "Res\u00b7pect", "vor", "mir", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PIAT", "NN", "APPR", "PPER", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "So la lala lala lala!", "tokens": ["So", "la", "la\u00b7la", "la\u00b7la", "la\u00b7la", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "FM", "FM", "FM", "FM", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und h\u00f6rst du mir denn das nicht an?", "tokens": ["Und", "h\u00f6rst", "du", "mir", "denn", "das", "nicht", "an", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PPER", "ADV", "PDS", "PTKNEG", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Hab' mehr Respect vor mir!", "tokens": ["Hab'", "mehr", "Res\u00b7pect", "vor", "mir", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PIAT", "NN", "APPR", "PPER", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "\u00bbo la\u00df dein L\u00e4rmen und dein Schrei'n!", "tokens": ["\u00bb", "o", "la\u00df", "dein", "L\u00e4r\u00b7men", "und", "dein", "Schrei'n", "!"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "FM", "VVIMP", "PPOSAT", "NN", "KON", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Such anderswo Quartier!", "tokens": ["Such", "an\u00b7ders\u00b7wo", "Quar\u00b7tier", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "ADV", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Bei deines Gleichen willst du sein,", "tokens": ["Bei", "dei\u00b7nes", "Glei\u00b7chen", "willst", "du", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VMFIN", "PPER", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die findest du nicht hier.", "tokens": ["Die", "fin\u00b7dest", "du", "nicht", "hier", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "PTKNEG", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "So la lala lala lala!", "tokens": ["So", "la", "la\u00b7la", "la\u00b7la", "la\u00b7la", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "FM", "FM", "FM", "FM", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Bei deines Gleichen willst du sein,", "tokens": ["Bei", "dei\u00b7nes", "Glei\u00b7chen", "willst", "du", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VMFIN", "PPER", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Die findest du nicht hier.\u00ab", "tokens": ["Die", "fin\u00b7dest", "du", "nicht", "hier", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PDS", "VVFIN", "PPER", "PTKNEG", "ADV", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}}}}