{"textgrid.poem.42768": {"metadata": {"author": {"name": "Ringelnatz, Joachim", "birth": "N.A.", "death": "N.A."}, "title": "Der Athlet", "genre": "verse", "period": "N.A.", "pub_year": 1908, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Mein Name ist Murxis, der Kraftmensch genannt.", "tokens": ["Mein", "Na\u00b7me", "ist", "Mur\u00b7xis", ",", "der", "Kraft\u00b7mensch", "ge\u00b7nannt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "NE", "$,", "ART", "NN", "VVPP", "$."], "meter": "-+--+--++-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Meine Nahrung ist Goulasch vom Elefant", "tokens": ["Mei\u00b7ne", "Nah\u00b7rung", "ist", "Gou\u00b7lasch", "vom", "E\u00b7le\u00b7fant"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VAFIN", "NN", "APPRART", "NN"], "meter": "+-+--+--+-+", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "In einer Sauce des St\u00e4rkemehles.", "tokens": ["In", "ei\u00b7ner", "Sau\u00b7ce", "des", "St\u00e4r\u00b7ke\u00b7meh\u00b7les", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Meine Heimat ist das Zentrum S\u00fcdwales,", "tokens": ["Mei\u00b7ne", "Hei\u00b7mat", "ist", "das", "Zent\u00b7rum", "S\u00fcd\u00b7wa\u00b7les", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ART", "NE", "NE", "$,"], "meter": "+-+-+-+-+--", "measure": "unknown.measure.penta"}, "line.5": {"text": "Upsala!", "tokens": ["Up\u00b7sa\u00b7la", "!"], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.2": {"line.1": {"text": "Ich wurde durch einen Kaiserschnitt", "tokens": ["Ich", "wur\u00b7de", "durch", "ei\u00b7nen", "Kai\u00b7ser\u00b7schnitt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "APPR", "ART", "NN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Geboren, mit Hilfe von Dynamit.", "tokens": ["Ge\u00b7bo\u00b7ren", ",", "mit", "Hil\u00b7fe", "von", "Dy\u00b7na\u00b7mit", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "APPR", "NN", "APPR", "NE", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Da\u00df ich noch lebte, war reines Gl\u00fcck.", "tokens": ["Da\u00df", "ich", "noch", "leb\u00b7te", ",", "war", "rei\u00b7nes", "Gl\u00fcck", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VVFIN", "$,", "VAFIN", "ADJA", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Von meiner Mutter blieb wenig zur\u00fcck.", "tokens": ["Von", "mei\u00b7ner", "Mut\u00b7ter", "blieb", "we\u00b7nig", "zu\u00b7r\u00fcck", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "PIS", "PTKVZ", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "20 kg mit dem kleinen Finger.", "tokens": ["kg", "mit", "dem", "klei\u00b7nen", "Fin\u00b7ger", "."], "token_info": ["measurement", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.3": {"line.1": {"text": "Man baute um mich eine Art von Dock.", "tokens": ["Man", "bau\u00b7te", "um", "mich", "ei\u00b7ne", "Art", "von", "Dock", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "APPR", "PRF", "ART", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Mit Strebest\u00fctzen im 16. Stock", "tokens": ["Mit", "Stre\u00b7be\u00b7st\u00fct\u00b7zen", "im", "16.", "Stock"], "token_info": ["word", "word", "word", "ordinal", "word"], "pos": ["APPR", "NN", "APPRART", "ADJA", "NN"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Eines Wolkenkratzers von Rockefeiler.", "tokens": ["Ei\u00b7nes", "Wol\u00b7ken\u00b7krat\u00b7zers", "von", "Ro\u00b7ck\u00b7e\u00b7fei\u00b7ler", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NE", "$."], "meter": "+-+-+--+--+-", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Das Stockwerk brach, man fand mich im Keller", "tokens": ["Das", "Stock\u00b7werk", "brach", ",", "man", "fand", "mich", "im", "Kel\u00b7ler"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "$,", "PIS", "VVFIN", "PRF", "APPRART", "NN"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Mit verschr\u00e4nkten Armen.", "tokens": ["Mit", "ver\u00b7schr\u00e4nk\u00b7ten", "Ar\u00b7men", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.4": {"line.1": {"text": "Ich war in allen St\u00e4dten der Welt", "tokens": ["Ich", "war", "in", "al\u00b7len", "St\u00e4d\u00b7ten", "der", "Welt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "APPR", "PIAT", "NN", "ART", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Als Muster von Herkules ausgestellt.", "tokens": ["Als", "Mus\u00b7ter", "von", "Her\u00b7ku\u00b7les", "aus\u00b7ge\u00b7stellt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "APPR", "NE", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Wer das bezweifelt \u2013 5 Groschen \u2013, der fordre", "tokens": ["Wer", "das", "be\u00b7zwei\u00b7felt", "\u2013", "5", "Gro\u00b7schen", "\u2013", ",", "der", "ford\u00b7re"], "token_info": ["word", "word", "word", "punct", "number", "word", "punct", "punct", "word", "word"], "pos": ["PWS", "PDS", "VVFIN", "$(", "CARD", "NN", "$(", "$,", "PRELS", "VVFIN"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "An der Kasse die Wachskabinettsordre.", "tokens": ["An", "der", "Kas\u00b7se", "die", "Wachs\u00b7ka\u00b7bi\u00b7nett\u00b7sord\u00b7re", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.5": {"text": "Ich nenne mich selbst den Venus von Milo.", "tokens": ["Ich", "nen\u00b7ne", "mich", "selbst", "den", "Ve\u00b7nus", "von", "Mi\u00b7lo", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ART", "NN", "APPR", "NE", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.6": {"text": "Bruttogewicht: 200 Kilo.", "tokens": ["Brut\u00b7to\u00b7ge\u00b7wicht", ":", "200", "Ki\u00b7lo", "."], "token_info": ["word", "punct", "number", "word", "punct"], "pos": ["NN", "$.", "CARD", "NE", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}}, "stanza.5": {"line.1": {"text": "Es haben mich K\u00f6niginnen betastet.", "tokens": ["Es", "ha\u00b7ben", "mich", "K\u00f6\u00b7ni\u00b7gin\u00b7nen", "be\u00b7tas\u00b7tet", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "NN", "VVPP", "$."], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Ich habe einmal drei Wochen gefastet", "tokens": ["Ich", "ha\u00b7be", "ein\u00b7mal", "drei", "Wo\u00b7chen", "ge\u00b7fas\u00b7tet"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "CARD", "NN", "VVPP"], "meter": "-+-+-+---+-", "measure": "unknown.measure.tetra"}, "line.3": {"text": "Und unternehme auch heute noch Schritte", "tokens": ["Und", "un\u00b7ter\u00b7neh\u00b7me", "auch", "heu\u00b7te", "noch", "Schrit\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "ADV", "ADV", "NN"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Zu meiner Entlastung. Und deshalb bitte", "tokens": ["Zu", "mei\u00b7ner", "Ent\u00b7las\u00b7tung", ".", "Und", "des\u00b7halb", "bit\u00b7te"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "$.", "KON", "PAV", "VVFIN"], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Ich die Herrschaften um ein kleines Douceur.", "tokens": ["Ich", "die", "Herr\u00b7schaf\u00b7ten", "um", "ein", "klei\u00b7nes", "Dou\u00b7ce\u00b7ur", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Mein Name ist Murxis, der Kraftmensch genannt.", "tokens": ["Mein", "Na\u00b7me", "ist", "Mur\u00b7xis", ",", "der", "Kraft\u00b7mensch", "ge\u00b7nannt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "NE", "$,", "ART", "NN", "VVPP", "$."], "meter": "-+--+--++-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Meine Nahrung ist Goulasch vom Elefant", "tokens": ["Mei\u00b7ne", "Nah\u00b7rung", "ist", "Gou\u00b7lasch", "vom", "E\u00b7le\u00b7fant"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VAFIN", "NN", "APPRART", "NN"], "meter": "+-+--+--+-+", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "In einer Sauce des St\u00e4rkemehles.", "tokens": ["In", "ei\u00b7ner", "Sau\u00b7ce", "des", "St\u00e4r\u00b7ke\u00b7meh\u00b7les", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Meine Heimat ist das Zentrum S\u00fcdwales,", "tokens": ["Mei\u00b7ne", "Hei\u00b7mat", "ist", "das", "Zent\u00b7rum", "S\u00fcd\u00b7wa\u00b7les", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ART", "NE", "NE", "$,"], "meter": "+-+-+-+-+--", "measure": "unknown.measure.penta"}, "line.5": {"text": "Upsala!", "tokens": ["Up\u00b7sa\u00b7la", "!"], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.7": {"line.1": {"text": "Ich wurde durch einen Kaiserschnitt", "tokens": ["Ich", "wur\u00b7de", "durch", "ei\u00b7nen", "Kai\u00b7ser\u00b7schnitt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "APPR", "ART", "NN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Geboren, mit Hilfe von Dynamit.", "tokens": ["Ge\u00b7bo\u00b7ren", ",", "mit", "Hil\u00b7fe", "von", "Dy\u00b7na\u00b7mit", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "APPR", "NN", "APPR", "NE", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Da\u00df ich noch lebte, war reines Gl\u00fcck.", "tokens": ["Da\u00df", "ich", "noch", "leb\u00b7te", ",", "war", "rei\u00b7nes", "Gl\u00fcck", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VVFIN", "$,", "VAFIN", "ADJA", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Von meiner Mutter blieb wenig zur\u00fcck.", "tokens": ["Von", "mei\u00b7ner", "Mut\u00b7ter", "blieb", "we\u00b7nig", "zu\u00b7r\u00fcck", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "PIS", "PTKVZ", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "20 kg mit dem kleinen Finger.", "tokens": ["kg", "mit", "dem", "klei\u00b7nen", "Fin\u00b7ger", "."], "token_info": ["measurement", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.8": {"line.1": {"text": "Man baute um mich eine Art von Dock.", "tokens": ["Man", "bau\u00b7te", "um", "mich", "ei\u00b7ne", "Art", "von", "Dock", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "APPR", "PRF", "ART", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Mit Strebest\u00fctzen im 16. Stock", "tokens": ["Mit", "Stre\u00b7be\u00b7st\u00fct\u00b7zen", "im", "16.", "Stock"], "token_info": ["word", "word", "word", "ordinal", "word"], "pos": ["APPR", "NN", "APPRART", "ADJA", "NN"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Eines Wolkenkratzers von Rockefeiler.", "tokens": ["Ei\u00b7nes", "Wol\u00b7ken\u00b7krat\u00b7zers", "von", "Ro\u00b7ck\u00b7e\u00b7fei\u00b7ler", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NE", "$."], "meter": "+-+-+--+--+-", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Das Stockwerk brach, man fand mich im Keller", "tokens": ["Das", "Stock\u00b7werk", "brach", ",", "man", "fand", "mich", "im", "Kel\u00b7ler"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "$,", "PIS", "VVFIN", "PRF", "APPRART", "NN"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Mit verschr\u00e4nkten Armen.", "tokens": ["Mit", "ver\u00b7schr\u00e4nk\u00b7ten", "Ar\u00b7men", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.9": {"line.1": {"text": "Ich war in allen St\u00e4dten der Welt", "tokens": ["Ich", "war", "in", "al\u00b7len", "St\u00e4d\u00b7ten", "der", "Welt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "APPR", "PIAT", "NN", "ART", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Als Muster von Herkules ausgestellt.", "tokens": ["Als", "Mus\u00b7ter", "von", "Her\u00b7ku\u00b7les", "aus\u00b7ge\u00b7stellt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "APPR", "NE", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Wer das bezweifelt \u2013 5 Groschen \u2013, der fordre", "tokens": ["Wer", "das", "be\u00b7zwei\u00b7felt", "\u2013", "5", "Gro\u00b7schen", "\u2013", ",", "der", "ford\u00b7re"], "token_info": ["word", "word", "word", "punct", "number", "word", "punct", "punct", "word", "word"], "pos": ["PWS", "PDS", "VVFIN", "$(", "CARD", "NN", "$(", "$,", "PRELS", "VVFIN"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "An der Kasse die Wachskabinettsordre.", "tokens": ["An", "der", "Kas\u00b7se", "die", "Wachs\u00b7ka\u00b7bi\u00b7nett\u00b7sord\u00b7re", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.5": {"text": "Ich nenne mich selbst den Venus von Milo.", "tokens": ["Ich", "nen\u00b7ne", "mich", "selbst", "den", "Ve\u00b7nus", "von", "Mi\u00b7lo", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ART", "NN", "APPR", "NE", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.6": {"text": "Bruttogewicht: 200 Kilo.", "tokens": ["Brut\u00b7to\u00b7ge\u00b7wicht", ":", "200", "Ki\u00b7lo", "."], "token_info": ["word", "punct", "number", "word", "punct"], "pos": ["NN", "$.", "CARD", "NE", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}}, "stanza.10": {"line.1": {"text": "Es haben mich K\u00f6niginnen betastet.", "tokens": ["Es", "ha\u00b7ben", "mich", "K\u00f6\u00b7ni\u00b7gin\u00b7nen", "be\u00b7tas\u00b7tet", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "NN", "VVPP", "$."], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Ich habe einmal drei Wochen gefastet", "tokens": ["Ich", "ha\u00b7be", "ein\u00b7mal", "drei", "Wo\u00b7chen", "ge\u00b7fas\u00b7tet"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "CARD", "NN", "VVPP"], "meter": "-+-+-+---+-", "measure": "unknown.measure.tetra"}, "line.3": {"text": "Und unternehme auch heute noch Schritte", "tokens": ["Und", "un\u00b7ter\u00b7neh\u00b7me", "auch", "heu\u00b7te", "noch", "Schrit\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "ADV", "ADV", "NN"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Zu meiner Entlastung. Und deshalb bitte", "tokens": ["Zu", "mei\u00b7ner", "Ent\u00b7las\u00b7tung", ".", "Und", "des\u00b7halb", "bit\u00b7te"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "$.", "KON", "PAV", "VVFIN"], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Ich die Herrschaften um ein kleines Douceur.", "tokens": ["Ich", "die", "Herr\u00b7schaf\u00b7ten", "um", "ein", "klei\u00b7nes", "Dou\u00b7ce\u00b7ur", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}