{"textgrid.poem.60711": {"metadata": {"author": {"name": "La Fontaine, Jean de", "birth": "N.A.", "death": "N.A."}, "title": "1L: Aus Eulenschnabel fiel einst eine Maus.", "genre": "verse", "period": "N.A.", "pub_year": 1658, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Aus Eulenschnabel fiel einst eine Maus.", "tokens": ["Aus", "Eu\u00b7len\u00b7schna\u00b7bel", "fiel", "einst", "ei\u00b7ne", "Maus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Ich h\u00e4tte sie nicht aufgehoben.", "tokens": ["Ich", "h\u00e4t\u00b7te", "sie", "nicht", "auf\u00b7ge\u00b7ho\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Doch ein Brahmine tat's und nahm sie mit nach Haus.", "tokens": ["Doch", "ein", "Brah\u00b7mi\u00b7ne", "tat's", "und", "nahm", "sie", "mit", "nach", "Haus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "NE", "KON", "VVFIN", "PPER", "APPR", "APPR", "NN", "$."], "meter": "-+---+-+-+-+", "measure": "dactylic.init"}, "line.4": {"text": "Ich glaub's; denn jedes Volk gebietet andre Proben", "tokens": ["Ich", "glaub's", ";", "denn", "je\u00b7des", "Volk", "ge\u00b7bie\u00b7tet", "and\u00b7re", "Pro\u00b7ben"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "NE", "$.", "KON", "PIAT", "NN", "VVFIN", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Von N\u00e4chstenliebe. W\u00fcrden wir", "tokens": ["Von", "N\u00e4chs\u00b7ten\u00b7lie\u00b7be", ".", "W\u00fcr\u00b7den", "wir"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["APPR", "NN", "$.", "VAFIN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Uns viel bem\u00fchn um ein geschundnes Tier?", "tokens": ["Uns", "viel", "be\u00b7m\u00fchn", "um", "ein", "ge\u00b7schund\u00b7nes", "Tier", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADJD", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Nein, dreimal nein! Doch der Brahminen Volk behandelt", "tokens": ["Nein", ",", "drei\u00b7mal", "nein", "!", "Doch", "der", "Brah\u00b7mi\u00b7nen", "Volk", "be\u00b7han\u00b7delt"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "$,", "ADV", "PTKANT", "$.", "KON", "ART", "ADJA", "NN", "VVPP"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Das Tier als Bruder; denn sie glauben fest,", "tokens": ["Das", "Tier", "als", "Bru\u00b7der", ";", "denn", "sie", "glau\u00b7ben", "fest", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KOUS", "NN", "$.", "KON", "PPER", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Da\u00df unsre Seele, wenn sie ihren Herrn verl\u00e4\u00dft,", "tokens": ["Da\u00df", "uns\u00b7re", "See\u00b7le", ",", "wenn", "sie", "ih\u00b7ren", "Herrn", "ver\u00b7l\u00e4\u00dft", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "$,", "KOUS", "PPER", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "In eine K\u00e4semade wandelt", "tokens": ["In", "ei\u00b7ne", "K\u00e4\u00b7se\u00b7ma\u00b7de", "wan\u00b7delt"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Oder in andre Lebewesen,", "tokens": ["O\u00b7der", "in", "and\u00b7re", "Le\u00b7be\u00b7we\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Wof\u00fcr sie just das Schicksal auserlesen.", "tokens": ["Wo\u00b7f\u00fcr", "sie", "just", "das", "Schick\u00b7sal", "au\u00b7ser\u00b7le\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Das ist ein alter Glaubenssatz bei ihnen,", "tokens": ["Das", "ist", "ein", "al\u00b7ter", "Glau\u00b7bens\u00b7satz", "bei", "ih\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "ADJA", "NN", "APPR", "PPER", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Pythagoras schon kundete ihn aus.", "tokens": ["Py\u00b7tha\u00b7go\u00b7ras", "schon", "kun\u00b7de\u00b7te", "ihn", "aus", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.8": {"text": "Und so erkl\u00e4rt sich auch die Bitte des Brahminen", "tokens": ["Und", "so", "er\u00b7kl\u00e4rt", "sich", "auch", "die", "Bit\u00b7te", "des", "Brah\u00b7mi\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "PRF", "ADV", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "An einen Zaubrer, seiner Maus", "tokens": ["An", "ei\u00b7nen", "Zaub\u00b7rer", ",", "sei\u00b7ner", "Maus"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "ART", "NN", "$,", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Den Leib zur\u00fcckzugeben,", "tokens": ["Den", "Leib", "zu\u00b7r\u00fcck\u00b7zu\u00b7ge\u00b7ben", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVIZU", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.11": {"text": "Den sie besa\u00df im Leben.", "tokens": ["Den", "sie", "be\u00b7sa\u00df", "im", "Le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVFIN", "APPRART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.12": {"text": "Der Zaubrer tat's. Was kam heraus?", "tokens": ["Der", "Zaub\u00b7rer", "tat'", "s.", "Was", "kam", "he\u00b7raus", "?"], "token_info": ["word", "word", "word", "abbreviation", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "NE", "PWS", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Ein M\u00e4dchen, f\u00fcnfzehn Jahre eben,", "tokens": ["Ein", "M\u00e4d\u00b7chen", ",", "f\u00fcnf\u00b7zehn", "Jah\u00b7re", "e\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "CARD", "NN", "ADV", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "So sch\u00f6n, da\u00df hier um einen Ku\u00df", "tokens": ["So", "sch\u00f6n", ",", "da\u00df", "hier", "um", "ei\u00b7nen", "Ku\u00df"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "$,", "KOUS", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Der k\u00fchne Sohn des Priamus", "tokens": ["Der", "k\u00fch\u00b7ne", "Sohn", "des", "Pri\u00b7a\u00b7mus"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Weit mehr gewagt noch h\u00e4tte als um Helena.", "tokens": ["Weit", "mehr", "ge\u00b7wagt", "noch", "h\u00e4t\u00b7te", "als", "um", "He\u00b7le\u00b7na", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADV", "VVPP", "ADV", "VAFIN", "KOKOM", "APPR", "NE", "$."], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.17": {"text": "Als der Brahmine \u00fcberrascht die Sch\u00f6nheit sah,", "tokens": ["Als", "der", "Brah\u00b7mi\u00b7ne", "\u00fc\u00b7berr\u00b7ascht", "die", "Sch\u00f6n\u00b7heit", "sah", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "VVFIN", "ART", "NN", "VVFIN", "$,"], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.18": {"text": "Da sprach er: \u00bbDu brauchst nur zu w\u00e4hlen,", "tokens": ["Da", "sprach", "er", ":", "\u00bb", "Du", "brauchst", "nur", "zu", "w\u00e4h\u00b7len", ","], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$.", "$(", "PPER", "VVFIN", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.19": {"text": "Du kannst gewi\u00df auf jeden z\u00e4hlen,", "tokens": ["Du", "kannst", "ge\u00b7wi\u00df", "auf", "je\u00b7den", "z\u00e4h\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "APPR", "PIS", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.20": {"text": "Der dir zum Gatten mag gefallen.\u00ab", "tokens": ["Der", "dir", "zum", "Gat\u00b7ten", "mag", "ge\u00b7fal\u00b7len", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "PPER", "APPRART", "NN", "VMFIN", "VVPP", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.21": {"text": "\u00bbso gebe ich mein Wort dem m\u00e4chtigsten von allen.\u00ab", "tokens": ["\u00bb", "so", "ge\u00b7be", "ich", "mein", "Wort", "dem", "m\u00e4ch\u00b7tigs\u00b7ten", "von", "al\u00b7len", ".", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADV", "VVFIN", "PPER", "PPOSAT", "NN", "ART", "ADJA", "APPR", "PIAT", "$.", "$("], "meter": "-+-+-+-+---+-", "measure": "unknown.measure.penta"}, "line.22": {"text": "\u00bbdir Sonnengott dein Lohn!\u00ab", "tokens": ["\u00bb", "dir", "Son\u00b7nen\u00b7gott", "dein", "Lohn", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPER", "NN", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.23": {"text": "Rief der Brahmine laut;", "tokens": ["Rief", "der", "Brah\u00b7mi\u00b7ne", "laut", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ADJD", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.24": {"text": "\u00bbsei du mein Schwiegersohn", "tokens": ["\u00bb", "sei", "du", "mein", "Schwie\u00b7ger\u00b7sohn"], "token_info": ["punct", "word", "word", "word", "word"], "pos": ["$(", "VAFIN", "PPER", "PPOSAT", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.25": {"text": "Und nimm die sch\u00f6nste Braut!\u00ab", "tokens": ["Und", "nimm", "die", "sch\u00f6ns\u00b7te", "Braut", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VVIMP", "ART", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.26": {"text": "\u00bbnein\u00ab, rief der Gott darauf,", "tokens": ["\u00bb", "nein", "\u00ab", ",", "rief", "der", "Gott", "da\u00b7rauf", ","], "token_info": ["punct", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PTKANT", "$(", "$,", "VVFIN", "ART", "NN", "PAV", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.27": {"text": "\u00bbnoch m\u00e4chtiger als ich", "tokens": ["\u00bb", "noch", "m\u00e4ch\u00b7ti\u00b7ger", "als", "ich"], "token_info": ["punct", "word", "word", "word", "word"], "pos": ["$(", "ADV", "ADJA", "KOUS", "PPER"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.28": {"text": "Ist dieser Wolkenhauf,", "tokens": ["Ist", "die\u00b7ser", "Wol\u00b7ken\u00b7hauf", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "PDAT", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.29": {"text": "Denn er verdunkelt mich.", "tokens": ["Denn", "er", "ver\u00b7dun\u00b7kelt", "mich", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPER", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.30": {"text": "Er sei von dir erkoren!\u00ab", "tokens": ["Er", "sei", "von", "dir", "er\u00b7ko\u00b7ren", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VAFIN", "APPR", "PPER", "VVINF", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.31": {"text": "\u00bbf\u00fcr dich, Gew\u00f6lk, geboren", "tokens": ["\u00bb", "f\u00fcr", "dich", ",", "Ge\u00b7w\u00f6lk", ",", "ge\u00b7bo\u00b7ren"], "token_info": ["punct", "word", "word", "punct", "word", "punct", "word"], "pos": ["$(", "APPR", "PPER", "$,", "NN", "$,", "VVPP"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.32": {"text": "Ist also dies mein Kind\u00ab,", "tokens": ["Ist", "al\u00b7so", "dies", "mein", "Kind", "\u00ab", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VAFIN", "ADV", "PDS", "PPOSAT", "NN", "$(", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.33": {"text": "Rief der Brahmine wieder.", "tokens": ["Rief", "der", "Brah\u00b7mi\u00b7ne", "wie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ADV", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.34": {"text": "Von droben t\u00f6nt es nieder:", "tokens": ["Von", "dro\u00b7ben", "t\u00f6nt", "es", "nie\u00b7der", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.35": {"text": "\u00bbnein, st\u00e4rker ist der Wind,", "tokens": ["\u00bb", "nein", ",", "st\u00e4r\u00b7ker", "ist", "der", "Wind", ","], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PTKANT", "$,", "ADJD", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.36": {"text": "Er jagt mich nach Gefallen;", "tokens": ["Er", "jagt", "mich", "nach", "Ge\u00b7fal\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.37": {"text": "Dem Boreas vor allen", "tokens": ["Dem", "Bo\u00b7re\u00b7as", "vor", "al\u00b7len"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NE", "APPR", "PIAT"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.38": {"text": "Geh\u00f6rt die Sch\u00f6ne an.\u00ab", "tokens": ["Ge\u00b7h\u00f6rt", "die", "Sch\u00f6\u00b7ne", "an", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "ART", "NN", "PTKVZ", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.39": {"text": "Verdrie\u00dflich sprach der Mann:", "tokens": ["Ver\u00b7drie\u00df\u00b7lich", "sprach", "der", "Mann", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.40": {"text": "\u00bbauf, kommen wir zum Schlu\u00df,", "tokens": ["\u00bb", "auf", ",", "kom\u00b7men", "wir", "zum", "Schlu\u00df", ","], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PTKVZ", "$,", "VVFIN", "PPER", "APPRART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.41": {"text": "Und da es dich, o Wind,", "tokens": ["Und", "da", "es", "dich", ",", "o", "Wind", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PRF", "$,", "FM", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.42": {"text": "Doch einmal geben mu\u00df,", "tokens": ["Doch", "ein\u00b7mal", "ge\u00b7ben", "mu\u00df", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.43": {"text": "So komm und nimm das Kind!\u00ab", "tokens": ["So", "komm", "und", "nimm", "das", "Kind", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VVFIN", "KON", "VVIMP", "ART", "NN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.44": {"text": "Der kam in schnellem Lauf.", "tokens": ["Der", "kam", "in", "schnel\u00b7lem", "Lauf", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.45": {"text": "Da hielt ein Berg ihn auf.", "tokens": ["Da", "hielt", "ein", "Berg", "ihn", "auf", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.46": {"text": "Der fing den Ball und warf", "tokens": ["Der", "fing", "den", "Ball", "und", "warf"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "ART", "NN", "KON", "VVFIN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.47": {"text": "Ihn weiter: \u00bbNein, ich darf", "tokens": ["Ihn", "wei\u00b7ter", ":", "\u00bb", "Nein", ",", "ich", "darf"], "token_info": ["word", "word", "punct", "punct", "word", "punct", "word", "word"], "pos": ["PPER", "PTKVZ", "$.", "$(", "PTKANT", "$,", "PPER", "VMFIN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.48": {"text": "Die Ratte nicht verletzen,", "tokens": ["Die", "Rat\u00b7te", "nicht", "ver\u00b7let\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.49": {"text": "Die mich durchbohren kann;", "tokens": ["Die", "mich", "durch\u00b7boh\u00b7ren", "kann", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVINF", "VMFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.50": {"text": "Sie w\u00fcrde mich zerfetzen,", "tokens": ["Sie", "w\u00fcr\u00b7de", "mich", "zer\u00b7fet\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.51": {"text": "Tr\u00e4t ich als Freier an.\u00ab", "tokens": ["Tr\u00e4t", "ich", "als", "Frei\u00b7er", "an", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "PPER", "KOUS", "NN", "PTKVZ", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.52": {"text": "Es spitzt beim Worte Ratte", "tokens": ["Es", "spitzt", "beim", "Wor\u00b7te", "Rat\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.53": {"text": "Die Sch\u00f6ne ihre Ohren:", "tokens": ["Die", "Sch\u00f6\u00b7ne", "ih\u00b7re", "Oh\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.54": {"text": "\u00bbja, dieses ist mein Gatte!\u00ab", "tokens": ["\u00bb", "ja", ",", "die\u00b7ses", "ist", "mein", "Gat\u00b7te", "!", "\u00ab"], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PTKANT", "$,", "PDS", "VAFIN", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.55": {"text": "Die Ratt, die Ratt erkoren!", "tokens": ["Die", "Ratt", ",", "die", "Ratt", "er\u00b7ko\u00b7ren", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.56": {"text": "Das war ein Sprung, wie ihn die Liebe liebt.", "tokens": ["Das", "war", "ein", "Sprung", ",", "wie", "ihn", "die", "Lie\u00b7be", "liebt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "$,", "PWAV", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.57": {"text": "Beweise? Nun, ihr wi\u00dft, da\u00df es recht viele gibt.", "tokens": ["Be\u00b7wei\u00b7se", "?", "Nun", ",", "ihr", "wi\u00dft", ",", "da\u00df", "es", "recht", "vie\u00b7le", "gibt", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "ADV", "$,", "PPER", "VVFIN", "$,", "KOUS", "PPER", "ADV", "PIS", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.58": {"text": "Man kommt von jenem Ort,", "tokens": ["Man", "kommt", "von", "je\u00b7nem", "Ort", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.59": {"text": "Dem man entstammt, nicht fort.", "tokens": ["Dem", "man", "ent\u00b7stammt", ",", "nicht", "fort", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "PIS", "VVFIN", "$,", "PTKNEG", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.60": {"text": "Die Fabel hat den Fall bewiesen.", "tokens": ["Die", "Fa\u00b7bel", "hat", "den", "Fall", "be\u00b7wie\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.61": {"text": "Doch pr\u00fcft man n\u00e4her, findet man dabei", "tokens": ["Doch", "pr\u00fcft", "man", "n\u00e4\u00b7her", ",", "fin\u00b7det", "man", "da\u00b7bei"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "VVFIN", "PIS", "ADJD", "$,", "VVFIN", "PIS", "PAV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.62": {"text": "Ein gutes Teil Sophisterei.", "tokens": ["Ein", "gu\u00b7tes", "Teil", "So\u00b7phis\u00b7te\u00b7rei", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.63": {"text": "Zum Gatten sich den Sonnenball erkiesen?", "tokens": ["Zum", "Gat\u00b7ten", "sich", "den", "Son\u00b7nen\u00b7ball", "er\u00b7kie\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PRF", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.64": {"text": "So t\u00f6richt w\u00e4re eine Sch\u00f6ne nicht.", "tokens": ["So", "t\u00f6\u00b7richt", "w\u00e4\u00b7re", "ei\u00b7ne", "Sch\u00f6\u00b7ne", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VAFIN", "ART", "NN", "PTKNEG", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.65": {"text": "Und darum schw\u00e4cher nennen einen Riesen", "tokens": ["Und", "da\u00b7rum", "schw\u00e4\u00b7cher", "nen\u00b7nen", "ei\u00b7nen", "Rie\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PAV", "ADJD", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.66": {"text": "Als einen Floh, nur weil der Floh ihn sticht?", "tokens": ["Als", "ei\u00b7nen", "Floh", ",", "nur", "weil", "der", "Floh", "ihn", "sticht", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "$,", "ADV", "KOUS", "ART", "NN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.67": {"text": "Und mu\u00dfte nicht die Ratt der Katze unterliegen,", "tokens": ["Und", "mu\u00df\u00b7te", "nicht", "die", "Ratt", "der", "Kat\u00b7ze", "un\u00b7ter\u00b7lie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PTKNEG", "ART", "NN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Die Katz dem Hund, der Hund dem Wolfe und so weiter?", "tokens": ["Die", "Katz", "dem", "Hund", ",", "der", "Hund", "dem", "Wol\u00b7fe", "und", "so", "wei\u00b7ter", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$,", "ART", "NN", "ART", "NN", "KON", "ADV", "ADV", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Und w\u00e4re Pilpai nicht auf dieser langen Leiter", "tokens": ["Und", "w\u00e4\u00b7re", "Pil\u00b7pai", "nicht", "auf", "die\u00b7ser", "lan\u00b7gen", "Lei\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "NN", "PTKNEG", "APPR", "PDAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Doch wieder bis zum Sonnenball emporgestiegen,", "tokens": ["Doch", "wie\u00b7der", "bis", "zum", "Son\u00b7nen\u00b7ball", "em\u00b7por\u00b7ge\u00b7stie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Um schlie\u00dflich ihm zu schenken jenes Liebesgl\u00fcck?", "tokens": ["Um", "schlie\u00df\u00b7lich", "ihm", "zu", "schen\u00b7ken", "je\u00b7nes", "Lie\u00b7bes\u00b7gl\u00fcck", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "ADJD", "PPER", "PTKZU", "VVINF", "PDAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und nun zu der Metempsychose noch zur\u00fcck!", "tokens": ["Und", "nun", "zu", "der", "Me\u00b7tem\u00b7psy\u00b7cho\u00b7se", "noch", "zu\u00b7r\u00fcck", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "ART", "NN", "ADV", "PTKVZ", "$."], "meter": "-+--+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Sie zu beweisen, ist das Wunder des Brahminen", "tokens": ["Sie", "zu", "be\u00b7wei\u00b7sen", ",", "ist", "das", "Wun\u00b7der", "des", "Brah\u00b7mi\u00b7nen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "PTKZU", "VVINF", "$,", "VAFIN", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Sehr ungeeignet, ja es wird in ihm sogar", "tokens": ["Sehr", "un\u00b7ge\u00b7eig\u00b7net", ",", "ja", "es", "wird", "in", "ihm", "so\u00b7gar"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "$,", "ADV", "PPER", "VAFIN", "APPR", "PPER", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Ihre Unhaltbarkeit uns offenbar.", "tokens": ["Ih\u00b7re", "Un\u00b7halt\u00b7bar\u00b7keit", "uns", "of\u00b7fen\u00b7bar", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PPER", "ADJD", "$."], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.8": {"text": "Nach dem System, dem jene Leute dienen,", "tokens": ["Nach", "dem", "Sys\u00b7tem", ",", "dem", "je\u00b7ne", "Leu\u00b7te", "die\u00b7nen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "PRELS", "PDAT", "NN", "VVINF", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.9": {"text": "Mu\u00df Mann, Maus, Wurm, kurz jeder seine Seele", "tokens": ["Mu\u00df", "Mann", ",", "Maus", ",", "Wurm", ",", "kurz", "je\u00b7der", "sei\u00b7ne", "See\u00b7le"], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["VMFIN", "NN", "$,", "NN", "$,", "NN", "$,", "ADJD", "PIAT", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Aus einem Schatz entnehmen, der gemeinsam Gut;", "tokens": ["Aus", "ei\u00b7nem", "Schatz", "ent\u00b7neh\u00b7men", ",", "der", "ge\u00b7mein\u00b7sam", "Gut", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVINF", "$,", "PRELS", "ADJD", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Und so \u2013 sofern ich mich im Folgern nicht verfehle \u2013", "tokens": ["Und", "so", "\u2013", "so\u00b7fern", "ich", "mich", "im", "Fol\u00b7gern", "nicht", "ver\u00b7feh\u00b7le", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$(", "KON", "PPER", "PRF", "APPRART", "NN", "PTKNEG", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Sind alle gleicher Art; Verschiedenheit beruht", "tokens": ["Sind", "al\u00b7le", "glei\u00b7cher", "Art", ";", "Ver\u00b7schie\u00b7den\u00b7heit", "be\u00b7ruht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["VAFIN", "PIAT", "ADJA", "NN", "$.", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "In ihrer Konstitution allein:", "tokens": ["In", "ih\u00b7rer", "Kons\u00b7ti\u00b7tu\u00b7ti\u00b7on", "al\u00b7lein", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "Wie diese handelt, das bestimmt,", "tokens": ["Wie", "die\u00b7se", "han\u00b7delt", ",", "das", "be\u00b7stimmt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "PDS", "VVFIN", "$,", "PDS", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Ob einer sinkt, ob H\u00f6hen er erklimmt.", "tokens": ["Ob", "ei\u00b7ner", "sinkt", ",", "ob", "H\u00f6\u00b7hen", "er", "er\u00b7klimmt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "VVFIN", "$,", "KOUS", "NN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.16": {"text": "Hier darf der Einwand wohl berechtigt sein:", "tokens": ["Hier", "darf", "der", "Ein\u00b7wand", "wohl", "be\u00b7rech\u00b7tigt", "sein", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "NN", "ADV", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.17": {"text": "Warum vermochte jenes sch\u00f6nheitsvolle Wesen", "tokens": ["Wa\u00b7rum", "ver\u00b7moch\u00b7te", "je\u00b7nes", "sch\u00f6n\u00b7heits\u00b7vol\u00b7le", "We\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "VVFIN", "PDAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Von seiner Wirtin nicht so weit sich zu befrein,", "tokens": ["Von", "sei\u00b7ner", "Wir\u00b7tin", "nicht", "so", "weit", "sich", "zu", "be\u00b7fr\u00b7ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PTKNEG", "ADV", "ADJD", "PRF", "PTKA", "ADJD", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Um sich der Sonne zu verm\u00e4hlen?", "tokens": ["Um", "sich", "der", "Son\u00b7ne", "zu", "ver\u00b7m\u00e4h\u00b7len", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PRF", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.20": {"text": "Wie kam's, da\u00df sie ein Rattenvieh sich auserlesen?", "tokens": ["Wie", "kam's", ",", "da\u00df", "sie", "ein", "Rat\u00b7ten\u00b7vieh", "sich", "au\u00b7ser\u00b7le\u00b7sen", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NE", "$,", "KOUS", "PPER", "ART", "NN", "PRF", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Erw\u00e4gt man alles St\u00fcck f\u00fcr St\u00fcck,", "tokens": ["Er\u00b7w\u00e4gt", "man", "al\u00b7les", "St\u00fcck", "f\u00fcr", "St\u00fcck", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PIAT", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.22": {"text": "So sind der M\u00e4use Seelen und der Sch\u00f6nen Seelen", "tokens": ["So", "sind", "der", "M\u00e4u\u00b7se", "See\u00b7len", "und", "der", "Sch\u00f6\u00b7nen", "See\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ART", "NN", "NN", "KON", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Doch voneinander gar verschieden,", "tokens": ["Doch", "von\u00b7ein\u00b7an\u00b7der", "gar", "ver\u00b7schie\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.24": {"text": "Und eine jede mu\u00df in ihre Bahn zur\u00fcck.", "tokens": ["Und", "ei\u00b7ne", "je\u00b7de", "mu\u00df", "in", "ih\u00b7re", "Bahn", "zu\u00b7r\u00fcck", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "PIAT", "VMFIN", "APPR", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Das ist ein himmlisches Gesetz hienieden.", "tokens": ["Das", "ist", "ein", "himm\u00b7li\u00b7sches", "Ge\u00b7setz", "hien\u00b7ie\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.26": {"text": "Besprecht den Teufel, treibt Magie auch noch so viel,", "tokens": ["Be\u00b7sprecht", "den", "Teu\u00b7fel", ",", "treibt", "Ma\u00b7gie", "auch", "noch", "so", "viel", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "$,", "VVFIN", "NN", "ADV", "ADV", "ADV", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Ihr bringt kein Wesen ab vom vorbestimmten Ziel.", "tokens": ["Ihr", "bringt", "kein", "We\u00b7sen", "ab", "vom", "vor\u00b7be\u00b7stimm\u00b7ten", "Ziel", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIAT", "NN", "PTKVZ", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Aus Eulenschnabel fiel einst eine Maus.", "tokens": ["Aus", "Eu\u00b7len\u00b7schna\u00b7bel", "fiel", "einst", "ei\u00b7ne", "Maus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Ich h\u00e4tte sie nicht aufgehoben.", "tokens": ["Ich", "h\u00e4t\u00b7te", "sie", "nicht", "auf\u00b7ge\u00b7ho\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Doch ein Brahmine tat's und nahm sie mit nach Haus.", "tokens": ["Doch", "ein", "Brah\u00b7mi\u00b7ne", "tat's", "und", "nahm", "sie", "mit", "nach", "Haus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "NE", "KON", "VVFIN", "PPER", "APPR", "APPR", "NN", "$."], "meter": "-+---+-+-+-+", "measure": "dactylic.init"}, "line.4": {"text": "Ich glaub's; denn jedes Volk gebietet andre Proben", "tokens": ["Ich", "glaub's", ";", "denn", "je\u00b7des", "Volk", "ge\u00b7bie\u00b7tet", "and\u00b7re", "Pro\u00b7ben"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "NE", "$.", "KON", "PIAT", "NN", "VVFIN", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Von N\u00e4chstenliebe. W\u00fcrden wir", "tokens": ["Von", "N\u00e4chs\u00b7ten\u00b7lie\u00b7be", ".", "W\u00fcr\u00b7den", "wir"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["APPR", "NN", "$.", "VAFIN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Uns viel bem\u00fchn um ein geschundnes Tier?", "tokens": ["Uns", "viel", "be\u00b7m\u00fchn", "um", "ein", "ge\u00b7schund\u00b7nes", "Tier", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADJD", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.7": {"line.1": {"text": "Nein, dreimal nein! Doch der Brahminen Volk behandelt", "tokens": ["Nein", ",", "drei\u00b7mal", "nein", "!", "Doch", "der", "Brah\u00b7mi\u00b7nen", "Volk", "be\u00b7han\u00b7delt"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "$,", "ADV", "PTKANT", "$.", "KON", "ART", "ADJA", "NN", "VVPP"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "Das Tier als Bruder; denn sie glauben fest,", "tokens": ["Das", "Tier", "als", "Bru\u00b7der", ";", "denn", "sie", "glau\u00b7ben", "fest", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KOUS", "NN", "$.", "KON", "PPER", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Da\u00df unsre Seele, wenn sie ihren Herrn verl\u00e4\u00dft,", "tokens": ["Da\u00df", "uns\u00b7re", "See\u00b7le", ",", "wenn", "sie", "ih\u00b7ren", "Herrn", "ver\u00b7l\u00e4\u00dft", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "$,", "KOUS", "PPER", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "In eine K\u00e4semade wandelt", "tokens": ["In", "ei\u00b7ne", "K\u00e4\u00b7se\u00b7ma\u00b7de", "wan\u00b7delt"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Oder in andre Lebewesen,", "tokens": ["O\u00b7der", "in", "and\u00b7re", "Le\u00b7be\u00b7we\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Wof\u00fcr sie just das Schicksal auserlesen.", "tokens": ["Wo\u00b7f\u00fcr", "sie", "just", "das", "Schick\u00b7sal", "au\u00b7ser\u00b7le\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Das ist ein alter Glaubenssatz bei ihnen,", "tokens": ["Das", "ist", "ein", "al\u00b7ter", "Glau\u00b7bens\u00b7satz", "bei", "ih\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "ADJA", "NN", "APPR", "PPER", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Pythagoras schon kundete ihn aus.", "tokens": ["Py\u00b7tha\u00b7go\u00b7ras", "schon", "kun\u00b7de\u00b7te", "ihn", "aus", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.8": {"text": "Und so erkl\u00e4rt sich auch die Bitte des Brahminen", "tokens": ["Und", "so", "er\u00b7kl\u00e4rt", "sich", "auch", "die", "Bit\u00b7te", "des", "Brah\u00b7mi\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "PRF", "ADV", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "An einen Zaubrer, seiner Maus", "tokens": ["An", "ei\u00b7nen", "Zaub\u00b7rer", ",", "sei\u00b7ner", "Maus"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "ART", "NN", "$,", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Den Leib zur\u00fcckzugeben,", "tokens": ["Den", "Leib", "zu\u00b7r\u00fcck\u00b7zu\u00b7ge\u00b7ben", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVIZU", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.11": {"text": "Den sie besa\u00df im Leben.", "tokens": ["Den", "sie", "be\u00b7sa\u00df", "im", "Le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVFIN", "APPRART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.12": {"text": "Der Zaubrer tat's. Was kam heraus?", "tokens": ["Der", "Zaub\u00b7rer", "tat'", "s.", "Was", "kam", "he\u00b7raus", "?"], "token_info": ["word", "word", "word", "abbreviation", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "NE", "PWS", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Ein M\u00e4dchen, f\u00fcnfzehn Jahre eben,", "tokens": ["Ein", "M\u00e4d\u00b7chen", ",", "f\u00fcnf\u00b7zehn", "Jah\u00b7re", "e\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "CARD", "NN", "ADV", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "So sch\u00f6n, da\u00df hier um einen Ku\u00df", "tokens": ["So", "sch\u00f6n", ",", "da\u00df", "hier", "um", "ei\u00b7nen", "Ku\u00df"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "$,", "KOUS", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Der k\u00fchne Sohn des Priamus", "tokens": ["Der", "k\u00fch\u00b7ne", "Sohn", "des", "Pri\u00b7a\u00b7mus"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Weit mehr gewagt noch h\u00e4tte als um Helena.", "tokens": ["Weit", "mehr", "ge\u00b7wagt", "noch", "h\u00e4t\u00b7te", "als", "um", "He\u00b7le\u00b7na", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADV", "VVPP", "ADV", "VAFIN", "KOKOM", "APPR", "NE", "$."], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.17": {"text": "Als der Brahmine \u00fcberrascht die Sch\u00f6nheit sah,", "tokens": ["Als", "der", "Brah\u00b7mi\u00b7ne", "\u00fc\u00b7berr\u00b7ascht", "die", "Sch\u00f6n\u00b7heit", "sah", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "VVFIN", "ART", "NN", "VVFIN", "$,"], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.18": {"text": "Da sprach er: \u00bbDu brauchst nur zu w\u00e4hlen,", "tokens": ["Da", "sprach", "er", ":", "\u00bb", "Du", "brauchst", "nur", "zu", "w\u00e4h\u00b7len", ","], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$.", "$(", "PPER", "VVFIN", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.19": {"text": "Du kannst gewi\u00df auf jeden z\u00e4hlen,", "tokens": ["Du", "kannst", "ge\u00b7wi\u00df", "auf", "je\u00b7den", "z\u00e4h\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "APPR", "PIS", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.20": {"text": "Der dir zum Gatten mag gefallen.\u00ab", "tokens": ["Der", "dir", "zum", "Gat\u00b7ten", "mag", "ge\u00b7fal\u00b7len", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "PPER", "APPRART", "NN", "VMFIN", "VVPP", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.21": {"text": "\u00bbso gebe ich mein Wort dem m\u00e4chtigsten von allen.\u00ab", "tokens": ["\u00bb", "so", "ge\u00b7be", "ich", "mein", "Wort", "dem", "m\u00e4ch\u00b7tigs\u00b7ten", "von", "al\u00b7len", ".", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADV", "VVFIN", "PPER", "PPOSAT", "NN", "ART", "ADJA", "APPR", "PIAT", "$.", "$("], "meter": "-+-+-+-+---+-", "measure": "unknown.measure.penta"}, "line.22": {"text": "\u00bbdir Sonnengott dein Lohn!\u00ab", "tokens": ["\u00bb", "dir", "Son\u00b7nen\u00b7gott", "dein", "Lohn", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPER", "NN", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.23": {"text": "Rief der Brahmine laut;", "tokens": ["Rief", "der", "Brah\u00b7mi\u00b7ne", "laut", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ADJD", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.24": {"text": "\u00bbsei du mein Schwiegersohn", "tokens": ["\u00bb", "sei", "du", "mein", "Schwie\u00b7ger\u00b7sohn"], "token_info": ["punct", "word", "word", "word", "word"], "pos": ["$(", "VAFIN", "PPER", "PPOSAT", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.25": {"text": "Und nimm die sch\u00f6nste Braut!\u00ab", "tokens": ["Und", "nimm", "die", "sch\u00f6ns\u00b7te", "Braut", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VVIMP", "ART", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.26": {"text": "\u00bbnein\u00ab, rief der Gott darauf,", "tokens": ["\u00bb", "nein", "\u00ab", ",", "rief", "der", "Gott", "da\u00b7rauf", ","], "token_info": ["punct", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PTKANT", "$(", "$,", "VVFIN", "ART", "NN", "PAV", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.27": {"text": "\u00bbnoch m\u00e4chtiger als ich", "tokens": ["\u00bb", "noch", "m\u00e4ch\u00b7ti\u00b7ger", "als", "ich"], "token_info": ["punct", "word", "word", "word", "word"], "pos": ["$(", "ADV", "ADJA", "KOUS", "PPER"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.28": {"text": "Ist dieser Wolkenhauf,", "tokens": ["Ist", "die\u00b7ser", "Wol\u00b7ken\u00b7hauf", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "PDAT", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.29": {"text": "Denn er verdunkelt mich.", "tokens": ["Denn", "er", "ver\u00b7dun\u00b7kelt", "mich", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPER", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.30": {"text": "Er sei von dir erkoren!\u00ab", "tokens": ["Er", "sei", "von", "dir", "er\u00b7ko\u00b7ren", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VAFIN", "APPR", "PPER", "VVINF", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.31": {"text": "\u00bbf\u00fcr dich, Gew\u00f6lk, geboren", "tokens": ["\u00bb", "f\u00fcr", "dich", ",", "Ge\u00b7w\u00f6lk", ",", "ge\u00b7bo\u00b7ren"], "token_info": ["punct", "word", "word", "punct", "word", "punct", "word"], "pos": ["$(", "APPR", "PPER", "$,", "NN", "$,", "VVPP"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.32": {"text": "Ist also dies mein Kind\u00ab,", "tokens": ["Ist", "al\u00b7so", "dies", "mein", "Kind", "\u00ab", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VAFIN", "ADV", "PDS", "PPOSAT", "NN", "$(", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.33": {"text": "Rief der Brahmine wieder.", "tokens": ["Rief", "der", "Brah\u00b7mi\u00b7ne", "wie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ADV", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.34": {"text": "Von droben t\u00f6nt es nieder:", "tokens": ["Von", "dro\u00b7ben", "t\u00f6nt", "es", "nie\u00b7der", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.35": {"text": "\u00bbnein, st\u00e4rker ist der Wind,", "tokens": ["\u00bb", "nein", ",", "st\u00e4r\u00b7ker", "ist", "der", "Wind", ","], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PTKANT", "$,", "ADJD", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.36": {"text": "Er jagt mich nach Gefallen;", "tokens": ["Er", "jagt", "mich", "nach", "Ge\u00b7fal\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.37": {"text": "Dem Boreas vor allen", "tokens": ["Dem", "Bo\u00b7re\u00b7as", "vor", "al\u00b7len"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NE", "APPR", "PIAT"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.38": {"text": "Geh\u00f6rt die Sch\u00f6ne an.\u00ab", "tokens": ["Ge\u00b7h\u00f6rt", "die", "Sch\u00f6\u00b7ne", "an", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "ART", "NN", "PTKVZ", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.39": {"text": "Verdrie\u00dflich sprach der Mann:", "tokens": ["Ver\u00b7drie\u00df\u00b7lich", "sprach", "der", "Mann", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.40": {"text": "\u00bbauf, kommen wir zum Schlu\u00df,", "tokens": ["\u00bb", "auf", ",", "kom\u00b7men", "wir", "zum", "Schlu\u00df", ","], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PTKVZ", "$,", "VVFIN", "PPER", "APPRART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.41": {"text": "Und da es dich, o Wind,", "tokens": ["Und", "da", "es", "dich", ",", "o", "Wind", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PRF", "$,", "FM", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.42": {"text": "Doch einmal geben mu\u00df,", "tokens": ["Doch", "ein\u00b7mal", "ge\u00b7ben", "mu\u00df", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.43": {"text": "So komm und nimm das Kind!\u00ab", "tokens": ["So", "komm", "und", "nimm", "das", "Kind", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VVFIN", "KON", "VVIMP", "ART", "NN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.44": {"text": "Der kam in schnellem Lauf.", "tokens": ["Der", "kam", "in", "schnel\u00b7lem", "Lauf", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.45": {"text": "Da hielt ein Berg ihn auf.", "tokens": ["Da", "hielt", "ein", "Berg", "ihn", "auf", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.46": {"text": "Der fing den Ball und warf", "tokens": ["Der", "fing", "den", "Ball", "und", "warf"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "ART", "NN", "KON", "VVFIN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.47": {"text": "Ihn weiter: \u00bbNein, ich darf", "tokens": ["Ihn", "wei\u00b7ter", ":", "\u00bb", "Nein", ",", "ich", "darf"], "token_info": ["word", "word", "punct", "punct", "word", "punct", "word", "word"], "pos": ["PPER", "PTKVZ", "$.", "$(", "PTKANT", "$,", "PPER", "VMFIN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.48": {"text": "Die Ratte nicht verletzen,", "tokens": ["Die", "Rat\u00b7te", "nicht", "ver\u00b7let\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.49": {"text": "Die mich durchbohren kann;", "tokens": ["Die", "mich", "durch\u00b7boh\u00b7ren", "kann", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVINF", "VMFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.50": {"text": "Sie w\u00fcrde mich zerfetzen,", "tokens": ["Sie", "w\u00fcr\u00b7de", "mich", "zer\u00b7fet\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.51": {"text": "Tr\u00e4t ich als Freier an.\u00ab", "tokens": ["Tr\u00e4t", "ich", "als", "Frei\u00b7er", "an", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "PPER", "KOUS", "NN", "PTKVZ", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.52": {"text": "Es spitzt beim Worte Ratte", "tokens": ["Es", "spitzt", "beim", "Wor\u00b7te", "Rat\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.53": {"text": "Die Sch\u00f6ne ihre Ohren:", "tokens": ["Die", "Sch\u00f6\u00b7ne", "ih\u00b7re", "Oh\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.54": {"text": "\u00bbja, dieses ist mein Gatte!\u00ab", "tokens": ["\u00bb", "ja", ",", "die\u00b7ses", "ist", "mein", "Gat\u00b7te", "!", "\u00ab"], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PTKANT", "$,", "PDS", "VAFIN", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.55": {"text": "Die Ratt, die Ratt erkoren!", "tokens": ["Die", "Ratt", ",", "die", "Ratt", "er\u00b7ko\u00b7ren", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.56": {"text": "Das war ein Sprung, wie ihn die Liebe liebt.", "tokens": ["Das", "war", "ein", "Sprung", ",", "wie", "ihn", "die", "Lie\u00b7be", "liebt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "$,", "PWAV", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.57": {"text": "Beweise? Nun, ihr wi\u00dft, da\u00df es recht viele gibt.", "tokens": ["Be\u00b7wei\u00b7se", "?", "Nun", ",", "ihr", "wi\u00dft", ",", "da\u00df", "es", "recht", "vie\u00b7le", "gibt", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "ADV", "$,", "PPER", "VVFIN", "$,", "KOUS", "PPER", "ADV", "PIS", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.58": {"text": "Man kommt von jenem Ort,", "tokens": ["Man", "kommt", "von", "je\u00b7nem", "Ort", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.59": {"text": "Dem man entstammt, nicht fort.", "tokens": ["Dem", "man", "ent\u00b7stammt", ",", "nicht", "fort", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "PIS", "VVFIN", "$,", "PTKNEG", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.60": {"text": "Die Fabel hat den Fall bewiesen.", "tokens": ["Die", "Fa\u00b7bel", "hat", "den", "Fall", "be\u00b7wie\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.61": {"text": "Doch pr\u00fcft man n\u00e4her, findet man dabei", "tokens": ["Doch", "pr\u00fcft", "man", "n\u00e4\u00b7her", ",", "fin\u00b7det", "man", "da\u00b7bei"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "VVFIN", "PIS", "ADJD", "$,", "VVFIN", "PIS", "PAV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.62": {"text": "Ein gutes Teil Sophisterei.", "tokens": ["Ein", "gu\u00b7tes", "Teil", "So\u00b7phis\u00b7te\u00b7rei", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.63": {"text": "Zum Gatten sich den Sonnenball erkiesen?", "tokens": ["Zum", "Gat\u00b7ten", "sich", "den", "Son\u00b7nen\u00b7ball", "er\u00b7kie\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PRF", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.64": {"text": "So t\u00f6richt w\u00e4re eine Sch\u00f6ne nicht.", "tokens": ["So", "t\u00f6\u00b7richt", "w\u00e4\u00b7re", "ei\u00b7ne", "Sch\u00f6\u00b7ne", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VAFIN", "ART", "NN", "PTKNEG", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.65": {"text": "Und darum schw\u00e4cher nennen einen Riesen", "tokens": ["Und", "da\u00b7rum", "schw\u00e4\u00b7cher", "nen\u00b7nen", "ei\u00b7nen", "Rie\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PAV", "ADJD", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.66": {"text": "Als einen Floh, nur weil der Floh ihn sticht?", "tokens": ["Als", "ei\u00b7nen", "Floh", ",", "nur", "weil", "der", "Floh", "ihn", "sticht", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "$,", "ADV", "KOUS", "ART", "NN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.67": {"text": "Und mu\u00dfte nicht die Ratt der Katze unterliegen,", "tokens": ["Und", "mu\u00df\u00b7te", "nicht", "die", "Ratt", "der", "Kat\u00b7ze", "un\u00b7ter\u00b7lie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PTKNEG", "ART", "NN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Die Katz dem Hund, der Hund dem Wolfe und so weiter?", "tokens": ["Die", "Katz", "dem", "Hund", ",", "der", "Hund", "dem", "Wol\u00b7fe", "und", "so", "wei\u00b7ter", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$,", "ART", "NN", "ART", "NN", "KON", "ADV", "ADV", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.10": {"line.1": {"text": "Und w\u00e4re Pilpai nicht auf dieser langen Leiter", "tokens": ["Und", "w\u00e4\u00b7re", "Pil\u00b7pai", "nicht", "auf", "die\u00b7ser", "lan\u00b7gen", "Lei\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "NN", "PTKNEG", "APPR", "PDAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Doch wieder bis zum Sonnenball emporgestiegen,", "tokens": ["Doch", "wie\u00b7der", "bis", "zum", "Son\u00b7nen\u00b7ball", "em\u00b7por\u00b7ge\u00b7stie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Um schlie\u00dflich ihm zu schenken jenes Liebesgl\u00fcck?", "tokens": ["Um", "schlie\u00df\u00b7lich", "ihm", "zu", "schen\u00b7ken", "je\u00b7nes", "Lie\u00b7bes\u00b7gl\u00fcck", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "ADJD", "PPER", "PTKZU", "VVINF", "PDAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und nun zu der Metempsychose noch zur\u00fcck!", "tokens": ["Und", "nun", "zu", "der", "Me\u00b7tem\u00b7psy\u00b7cho\u00b7se", "noch", "zu\u00b7r\u00fcck", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "ART", "NN", "ADV", "PTKVZ", "$."], "meter": "-+--+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Sie zu beweisen, ist das Wunder des Brahminen", "tokens": ["Sie", "zu", "be\u00b7wei\u00b7sen", ",", "ist", "das", "Wun\u00b7der", "des", "Brah\u00b7mi\u00b7nen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "PTKZU", "VVINF", "$,", "VAFIN", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Sehr ungeeignet, ja es wird in ihm sogar", "tokens": ["Sehr", "un\u00b7ge\u00b7eig\u00b7net", ",", "ja", "es", "wird", "in", "ihm", "so\u00b7gar"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "$,", "ADV", "PPER", "VAFIN", "APPR", "PPER", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Ihre Unhaltbarkeit uns offenbar.", "tokens": ["Ih\u00b7re", "Un\u00b7halt\u00b7bar\u00b7keit", "uns", "of\u00b7fen\u00b7bar", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PPER", "ADJD", "$."], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.8": {"text": "Nach dem System, dem jene Leute dienen,", "tokens": ["Nach", "dem", "Sys\u00b7tem", ",", "dem", "je\u00b7ne", "Leu\u00b7te", "die\u00b7nen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "PRELS", "PDAT", "NN", "VVINF", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.9": {"text": "Mu\u00df Mann, Maus, Wurm, kurz jeder seine Seele", "tokens": ["Mu\u00df", "Mann", ",", "Maus", ",", "Wurm", ",", "kurz", "je\u00b7der", "sei\u00b7ne", "See\u00b7le"], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["VMFIN", "NN", "$,", "NN", "$,", "NN", "$,", "ADJD", "PIAT", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Aus einem Schatz entnehmen, der gemeinsam Gut;", "tokens": ["Aus", "ei\u00b7nem", "Schatz", "ent\u00b7neh\u00b7men", ",", "der", "ge\u00b7mein\u00b7sam", "Gut", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVINF", "$,", "PRELS", "ADJD", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Und so \u2013 sofern ich mich im Folgern nicht verfehle \u2013", "tokens": ["Und", "so", "\u2013", "so\u00b7fern", "ich", "mich", "im", "Fol\u00b7gern", "nicht", "ver\u00b7feh\u00b7le", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$(", "KON", "PPER", "PRF", "APPRART", "NN", "PTKNEG", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Sind alle gleicher Art; Verschiedenheit beruht", "tokens": ["Sind", "al\u00b7le", "glei\u00b7cher", "Art", ";", "Ver\u00b7schie\u00b7den\u00b7heit", "be\u00b7ruht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["VAFIN", "PIAT", "ADJA", "NN", "$.", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "In ihrer Konstitution allein:", "tokens": ["In", "ih\u00b7rer", "Kons\u00b7ti\u00b7tu\u00b7ti\u00b7on", "al\u00b7lein", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "Wie diese handelt, das bestimmt,", "tokens": ["Wie", "die\u00b7se", "han\u00b7delt", ",", "das", "be\u00b7stimmt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "PDS", "VVFIN", "$,", "PDS", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Ob einer sinkt, ob H\u00f6hen er erklimmt.", "tokens": ["Ob", "ei\u00b7ner", "sinkt", ",", "ob", "H\u00f6\u00b7hen", "er", "er\u00b7klimmt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "VVFIN", "$,", "KOUS", "NN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.16": {"text": "Hier darf der Einwand wohl berechtigt sein:", "tokens": ["Hier", "darf", "der", "Ein\u00b7wand", "wohl", "be\u00b7rech\u00b7tigt", "sein", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "NN", "ADV", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.17": {"text": "Warum vermochte jenes sch\u00f6nheitsvolle Wesen", "tokens": ["Wa\u00b7rum", "ver\u00b7moch\u00b7te", "je\u00b7nes", "sch\u00f6n\u00b7heits\u00b7vol\u00b7le", "We\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "VVFIN", "PDAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Von seiner Wirtin nicht so weit sich zu befrein,", "tokens": ["Von", "sei\u00b7ner", "Wir\u00b7tin", "nicht", "so", "weit", "sich", "zu", "be\u00b7fr\u00b7ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PTKNEG", "ADV", "ADJD", "PRF", "PTKA", "ADJD", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Um sich der Sonne zu verm\u00e4hlen?", "tokens": ["Um", "sich", "der", "Son\u00b7ne", "zu", "ver\u00b7m\u00e4h\u00b7len", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PRF", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.20": {"text": "Wie kam's, da\u00df sie ein Rattenvieh sich auserlesen?", "tokens": ["Wie", "kam's", ",", "da\u00df", "sie", "ein", "Rat\u00b7ten\u00b7vieh", "sich", "au\u00b7ser\u00b7le\u00b7sen", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NE", "$,", "KOUS", "PPER", "ART", "NN", "PRF", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Erw\u00e4gt man alles St\u00fcck f\u00fcr St\u00fcck,", "tokens": ["Er\u00b7w\u00e4gt", "man", "al\u00b7les", "St\u00fcck", "f\u00fcr", "St\u00fcck", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PIAT", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.22": {"text": "So sind der M\u00e4use Seelen und der Sch\u00f6nen Seelen", "tokens": ["So", "sind", "der", "M\u00e4u\u00b7se", "See\u00b7len", "und", "der", "Sch\u00f6\u00b7nen", "See\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ART", "NN", "NN", "KON", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Doch voneinander gar verschieden,", "tokens": ["Doch", "von\u00b7ein\u00b7an\u00b7der", "gar", "ver\u00b7schie\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.24": {"text": "Und eine jede mu\u00df in ihre Bahn zur\u00fcck.", "tokens": ["Und", "ei\u00b7ne", "je\u00b7de", "mu\u00df", "in", "ih\u00b7re", "Bahn", "zu\u00b7r\u00fcck", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "PIAT", "VMFIN", "APPR", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Das ist ein himmlisches Gesetz hienieden.", "tokens": ["Das", "ist", "ein", "himm\u00b7li\u00b7sches", "Ge\u00b7setz", "hien\u00b7ie\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.26": {"text": "Besprecht den Teufel, treibt Magie auch noch so viel,", "tokens": ["Be\u00b7sprecht", "den", "Teu\u00b7fel", ",", "treibt", "Ma\u00b7gie", "auch", "noch", "so", "viel", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "$,", "VVFIN", "NN", "ADV", "ADV", "ADV", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Ihr bringt kein Wesen ab vom vorbestimmten Ziel.", "tokens": ["Ihr", "bringt", "kein", "We\u00b7sen", "ab", "vom", "vor\u00b7be\u00b7stimm\u00b7ten", "Ziel", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIAT", "NN", "PTKVZ", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}