{"textgrid.poem.32622": {"metadata": {"author": {"name": "Pet\u00f6fi, S\u00e1ndor", "birth": "N.A.", "death": "N.A."}, "title": "Ii.", "genre": "verse", "period": "N.A.", "pub_year": 1836, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Beim ersten Hahnenruf erwacht", "tokens": ["Beim", "ers\u00b7ten", "Hah\u00b7nen\u00b7ruf", "er\u00b7wacht"], "token_info": ["word", "word", "word", "word"], "pos": ["APPRART", "ADJA", "NN", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das Morgenrot aus dunkler Nacht;", "tokens": ["Das", "Mor\u00b7gen\u00b7rot", "aus", "dunk\u00b7ler", "Nacht", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Bei M\u00e4dchen gilt das auch, und wie!", "tokens": ["Bei", "M\u00e4d\u00b7chen", "gilt", "das", "auch", ",", "und", "wie", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PDS", "ADV", "$,", "KON", "PWAV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Beim ersten Wort err\u00f6ten sie.", "tokens": ["Beim", "ers\u00b7ten", "Wort", "er\u00b7r\u00f6\u00b7ten", "sie", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Drum schweig' ich gern. Ihr denkt dabei,", "tokens": ["Drum", "schweig'", "ich", "gern", ".", "Ihr", "denkt", "da\u00b7bei", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "ADV", "$.", "PPER", "VVFIN", "PAV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df ich dem Hahne \u00e4hnlich sei?", "tokens": ["Da\u00df", "ich", "dem", "Hah\u00b7ne", "\u00e4hn\u00b7lich", "sei", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Stets hat sich gern der falsche Hahn", "tokens": ["Stets", "hat", "sich", "gern", "der", "fal\u00b7sche", "Hahn"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PRF", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "In fremden Nestern umgetan.", "tokens": ["In", "frem\u00b7den", "Nes\u00b7tern", "um\u00b7ge\u00b7tan", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Der Hahn, der nascht von Fall zu Fall,", "tokens": ["Der", "Hahn", ",", "der", "nascht", "von", "Fall", "zu", "Fall", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "APPR", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Doch ", "tokens": ["Doch"], "token_info": ["word"], "pos": ["KON"], "meter": "+", "measure": "single.up"}, "line.3": {"text": "F\u00fcr ", "tokens": ["F\u00fcr"], "token_info": ["word"], "pos": ["NN"], "meter": "+", "measure": "single.up"}}, "stanza.4": {"line.1": {"text": "Beim ersten Hahnenruf erwacht", "tokens": ["Beim", "ers\u00b7ten", "Hah\u00b7nen\u00b7ruf", "er\u00b7wacht"], "token_info": ["word", "word", "word", "word"], "pos": ["APPRART", "ADJA", "NN", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das Morgenrot aus dunkler Nacht;", "tokens": ["Das", "Mor\u00b7gen\u00b7rot", "aus", "dunk\u00b7ler", "Nacht", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Bei M\u00e4dchen gilt das auch, und wie!", "tokens": ["Bei", "M\u00e4d\u00b7chen", "gilt", "das", "auch", ",", "und", "wie", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PDS", "ADV", "$,", "KON", "PWAV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Beim ersten Wort err\u00f6ten sie.", "tokens": ["Beim", "ers\u00b7ten", "Wort", "er\u00b7r\u00f6\u00b7ten", "sie", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Drum schweig' ich gern. Ihr denkt dabei,", "tokens": ["Drum", "schweig'", "ich", "gern", ".", "Ihr", "denkt", "da\u00b7bei", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "ADV", "$.", "PPER", "VVFIN", "PAV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df ich dem Hahne \u00e4hnlich sei?", "tokens": ["Da\u00df", "ich", "dem", "Hah\u00b7ne", "\u00e4hn\u00b7lich", "sei", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Stets hat sich gern der falsche Hahn", "tokens": ["Stets", "hat", "sich", "gern", "der", "fal\u00b7sche", "Hahn"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PRF", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "In fremden Nestern umgetan.", "tokens": ["In", "frem\u00b7den", "Nes\u00b7tern", "um\u00b7ge\u00b7tan", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Der Hahn, der nascht von Fall zu Fall,", "tokens": ["Der", "Hahn", ",", "der", "nascht", "von", "Fall", "zu", "Fall", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "APPR", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Doch ", "tokens": ["Doch"], "token_info": ["word"], "pos": ["KON"], "meter": "+", "measure": "single.up"}, "line.3": {"text": "F\u00fcr ", "tokens": ["F\u00fcr"], "token_info": ["word"], "pos": ["NN"], "meter": "+", "measure": "single.up"}}}}}