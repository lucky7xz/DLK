{"textgrid.poem.64173": {"metadata": {"author": {"name": "Dahn, Felix", "birth": "N.A.", "death": "N.A."}, "title": "K\u00f6nig Alfred", "genre": "verse", "period": "N.A.", "pub_year": 1873, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "\u00bbin harter Not liegt Engelland!", "tokens": ["\u00bb", "in", "har\u00b7ter", "Not", "liegt", "En\u00b7gel\u00b7land", "!"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "ADJA", "NN", "VVFIN", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Es sind mit tausend K\u00e4hnen", "tokens": ["Es", "sind", "mit", "tau\u00b7send", "K\u00e4h\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "APPR", "CARD", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Die gottverha\u00dften D\u00e4nen", "tokens": ["Die", "gott\u00b7ver\u00b7ha\u00df\u00b7ten", "D\u00e4\u00b7nen"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Gelandet an des Humber Strand:", "tokens": ["Ge\u00b7lan\u00b7det", "an", "des", "Hum\u00b7ber", "Strand", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "APPR", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Durch Yorkshire w\u00fctet Mord und Brand,", "tokens": ["Durch", "Y\u00b7orks\u00b7hi\u00b7re", "w\u00fc\u00b7tet", "Mord", "und", "Brand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VVFIN", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Und wo ist K\u00f6nig Alfreds Hand,", "tokens": ["Und", "wo", "ist", "K\u00f6\u00b7nig", "Al\u00b7freds", "Hand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "VAFIN", "NN", "NE", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Zu trocknen unsre Tr\u00e4nen?", "tokens": ["Zu", "trock\u00b7nen", "uns\u00b7re", "Tr\u00e4\u00b7nen", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Er fiel, er fiel der teure Held", "tokens": ["Er", "fiel", ",", "er", "fiel", "der", "teu\u00b7re", "Held"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Von einem scharfen Speere!", "tokens": ["Von", "ei\u00b7nem", "schar\u00b7fen", "Spee\u00b7re", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "So bringt's die blut'ge M\u00e4re!", "tokens": ["So", "bringt's", "die", "blut'\u00b7ge", "M\u00e4\u00b7re", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Kein Retter steht uns mehr im Feld:", "tokens": ["Kein", "Ret\u00b7ter", "steht", "uns", "mehr", "im", "Feld", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "PPER", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "So r\u00e4umt denn diese Inselwelt,", "tokens": ["So", "r\u00e4umt", "denn", "die\u00b7se", "In\u00b7sel\u00b7welt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "PDAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Die Hengst und Horsas Asche h\u00e4lt,", "tokens": ["Die", "Hengst", "und", "Hor\u00b7sas", "A\u00b7sche", "h\u00e4lt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NE", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und suchet neue Meere!\u00ab", "tokens": ["Und", "su\u00b7chet", "neu\u00b7e", "Mee\u00b7re", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "So schallt's im Gaugericht zu Kent", "tokens": ["So", "schallt's", "im", "Gau\u00b7ge\u00b7richt", "zu", "Kent"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "APPRART", "NN", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Bei Grafen und bei Thanen,", "tokens": ["Bei", "Gra\u00b7fen", "und", "bei", "Tha\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "APPR", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Zu rascher Flucht zu mahnen.", "tokens": ["Zu", "ra\u00b7scher", "Flucht", "zu", "mah\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Da ist kein Mund, der Hilfe nennt:", "tokens": ["Da", "ist", "kein", "Mund", ",", "der", "Hil\u00b7fe", "nennt", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIAT", "NN", "$,", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Schon ist der Sch\u00f6ffen Kreis getrennt,", "tokens": ["Schon", "ist", "der", "Sch\u00f6f\u00b7fen", "Kreis", "ge\u00b7trennt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Schon senken sich \u2013 des Dinges End' \u2013", "tokens": ["Schon", "sen\u00b7ken", "sich", "\u2013", "des", "Din\u00b7ges", "End'", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "$(", "ART", "NN", "NN", "$("], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.7": {"text": "Vom Lindenbaum die Fahnen.", "tokens": ["Vom", "Lin\u00b7den\u00b7baum", "die", "Fah\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Da trat hervor ein Harfner alt:", "tokens": ["Da", "trat", "her\u00b7vor", "ein", "Harf\u00b7ner", "alt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PTKVZ", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Er stand am Stamm der Linde,", "tokens": ["Er", "stand", "am", "Stamm", "der", "Lin\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "ART", "NE", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Es flog sein Haar im Winde:", "tokens": ["Es", "flog", "sein", "Haar", "im", "Win\u00b7de", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Vom Kriegermantel braun umwallt", "tokens": ["Vom", "Krie\u00b7ger\u00b7man\u00b7tel", "braun", "um\u00b7wallt"], "token_info": ["word", "word", "word", "word"], "pos": ["APPRART", "NN", "ADJD", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Stolz reckte sich die Erzgestalt,", "tokens": ["Stolz", "reck\u00b7te", "sich", "die", "Erz\u00b7ge\u00b7stalt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PRF", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "In seinem Schild' ein breiter Spalt,", "tokens": ["In", "sei\u00b7nem", "Schild'", "ein", "brei\u00b7ter", "Spalt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Sein Haupt verbarg die Binde.", "tokens": ["Sein", "Haupt", "ver\u00b7barg", "die", "Bin\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "\u00bbgemach, ihr lieben Herr'n zumal,", "tokens": ["\u00bb", "ge\u00b7mach", ",", "ihr", "lie\u00b7ben", "Herr'n", "zu\u00b7mal", ","], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "$,", "PPOSAT", "ADJA", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ich will euch nicht bet\u00f6ren,", "tokens": ["Ich", "will", "euch", "nicht", "be\u00b7t\u00f6\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Nicht euren Ratschlu\u00df st\u00f6ren:", "tokens": ["Nicht", "eu\u00b7ren", "Rat\u00b7schlu\u00df", "st\u00f6\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Doch komm' ich frisch von blut'ger Wal: \u2013", "tokens": ["Doch", "komm'", "ich", "frisch", "von", "blut'\u00b7ger", "Wal", ":", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADJD", "APPR", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Sprecht, wollt ihr nicht zum letztenmal", "tokens": ["Sprecht", ",", "wollt", "ihr", "nicht", "zum", "letz\u00b7ten\u00b7mal"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "$,", "VMFIN", "PPER", "PTKNEG", "APPRART", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Von eurem Herrn, der dort befahl,", "tokens": ["Von", "eu\u00b7rem", "Herrn", ",", "der", "dort", "be\u00b7fahl", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "PRELS", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Von K\u00f6nig Alfred h\u00f6ren?\u00ab", "tokens": ["Von", "K\u00f6\u00b7nig", "Al\u00b7fred", "h\u00f6\u00b7ren", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "NE", "NE", "VVINF", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "\u00bbvon K\u00f6nig Alfred!\u00ab \u2013 ruft die Schar \u2013", "tokens": ["\u00bb", "von", "K\u00f6\u00b7nig", "Al\u00b7fred", "!", "\u00ab", "\u2013", "ruft", "die", "Schar", "\u2013"], "token_info": ["punct", "word", "word", "word", "punct", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "NE", "NE", "$.", "$(", "$(", "VVFIN", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und alles bleibt, zu lauschen", "tokens": ["Und", "al\u00b7les", "bleibt", ",", "zu", "lau\u00b7schen"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["KON", "PIS", "VVFIN", "$,", "PTKZU", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und feuchten Blick zu tauschen, \u2013", "tokens": ["Und", "feuch\u00b7ten", "Blick", "zu", "tau\u00b7schen", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ADJA", "NN", "PTKZU", "VVINF", "$,", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "\u00bbwei\u00dft du von seinem Ende gar?", "tokens": ["\u00bb", "wei\u00dft", "du", "von", "sei\u00b7nem", "En\u00b7de", "gar", "?"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "O, sing' von ihm, wie gro\u00df er war!\u00ab", "tokens": ["O", ",", "sing'", "von", "ihm", ",", "wie", "gro\u00df", "er", "war", "!", "\u00ab"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "$,", "VVFIN", "APPR", "PPER", "$,", "PWAV", "ADJD", "PPER", "VAFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Da blitzt des Harfners Auge klar,", "tokens": ["Da", "blitzt", "des", "Harf\u00b7ners", "Au\u00b7ge", "klar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und seine Saiten rauschen:", "tokens": ["Und", "sei\u00b7ne", "Sai\u00b7ten", "rau\u00b7schen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "\u00bbo Wodenswood, du arges Feld,", "tokens": ["\u00bb", "o", "Wo\u00b7dens\u00b7wood", ",", "du", "ar\u00b7ges", "Feld", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "FM", "FM", "$,", "PPER", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Fluch sei mit deinen Eichen!", "tokens": ["Fluch", "sei", "mit", "dei\u00b7nen", "Ei\u00b7chen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Da ward von D\u00e4nenstreichen", "tokens": ["Da", "ward", "von", "D\u00e4\u00b7nen\u00b7strei\u00b7chen"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "APPR", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Manch' alter Sachsenschild zerspellt!", "tokens": ["Man\u00b7ch'", "al\u00b7ter", "Sach\u00b7sen\u00b7schild", "zer\u00b7spellt", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "VVPP", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.5": {"text": "Und, k\u00fchn zum Fu\u00dfkampf erst gestellt,", "tokens": ["Und", ",", "k\u00fchn", "zum", "Fu\u00df\u00b7kampf", "erst", "ge\u00b7stellt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "ADJD", "APPRART", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Nach seinem Hengst rief mancher Held,", "tokens": ["Nach", "sei\u00b7nem", "Hengst", "rief", "man\u00b7cher", "Held", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "In Flucht hindann zu weichen.", "tokens": ["In", "Flucht", "hin\u00b7dann", "zu", "wei\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Das d\u00fcnkte K\u00f6nig Alfred schlecht:", "tokens": ["Das", "d\u00fcnk\u00b7te", "K\u00f6\u00b7nig", "Al\u00b7fred", "schlecht", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NE", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Er jagte hin und wieder", "tokens": ["Er", "jag\u00b7te", "hin", "und", "wie\u00b7der"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PTKVZ", "KON", "ADV"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Durch alle Reiterglieder,", "tokens": ["Durch", "al\u00b7le", "Rei\u00b7ter\u00b7glie\u00b7der", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und rief: \u203aEin Sachse, treu und echt,", "tokens": ["Und", "rief", ":", "\u203a", "Ein", "Sach\u00b7se", ",", "treu", "und", "echt", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "$(", "ART", "NN", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Harrt aus im Tod, ob Than, ob Knecht!\u2039 \u2013", "tokens": ["Harrt", "aus", "im", "Tod", ",", "ob", "Than", ",", "ob", "Knecht", "!", "\u2039", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "punct", "punct"], "pos": ["VVFIN", "APPR", "APPRART", "NN", "$,", "KOUS", "NE", "$,", "KOUS", "NN", "$.", "$(", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und sprang herab zum Fu\u00dfgefecht", "tokens": ["Und", "sprang", "her\u00b7ab", "zum", "Fu\u00df\u00b7ge\u00b7fecht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und stach sein Streitro\u00df nieder.", "tokens": ["Und", "stach", "sein", "Strei\u00b7tro\u00df", "nie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Und nahm von York das Sturmpanier,", "tokens": ["Und", "nahm", "von", "Y\u00b7ork", "das", "Sturm\u00b7pa\u00b7nier", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "NE", "ART", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Der Bauern Kampfgenosse,", "tokens": ["Der", "Bau\u00b7ern", "Kampf\u00b7ge\u00b7nos\u00b7se", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und trug's in die Geschosse.", "tokens": ["Und", "trug's", "in", "die", "Ge\u00b7schos\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Da schlug ein Beil ihm ins Visier,", "tokens": ["Da", "schlug", "ein", "Beil", "ihm", "ins", "Vi\u00b7sier", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "PPER", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Schlug ihm vom Helm die Kronenzier, \u2013", "tokens": ["Schlug", "ihm", "vom", "Helm", "die", "Kro\u00b7nen\u00b7zier", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PPER", "APPRART", "NN", "ART", "NN", "$,", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Schlug ihm ins Haupt, zum Tode schier,", "tokens": ["Schlug", "ihm", "ins", "Haupt", ",", "zum", "To\u00b7de", "schier", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPRART", "NN", "$,", "APPRART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und \u00fcber ihm die Rosse! \u2013", "tokens": ["Und", "\u00fc\u00b7ber", "ihm", "die", "Ros\u00b7se", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "APPR", "PPER", "ART", "NN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "Lang lag er so, die Nacht war kalt \u2013", "tokens": ["Lang", "lag", "er", "so", ",", "die", "Nacht", "war", "kalt", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "ADV", "$,", "ART", "NN", "VAFIN", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da weckten ihn mit Kratzen", "tokens": ["Da", "weck\u00b7ten", "ihn", "mit", "Krat\u00b7zen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Des Leichenwolfes Tatzen \u2013", "tokens": ["Des", "Lei\u00b7chen\u00b7wol\u00b7fes", "Tat\u00b7zen", "\u2013"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Er schlug \u2013 das Untier wich alsbald \u2013:", "tokens": ["Er", "schlug", "\u2013", "das", "Un\u00b7tier", "wich", "als\u00b7bald", "\u2013", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "$(", "ART", "NN", "VVFIN", "ADV", "$(", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Da dacht' er, wie des Feinds Gewalt", "tokens": ["Da", "dacht'", "er", ",", "wie", "des", "Feinds", "Ge\u00b7walt"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "$,", "PWAV", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Nun wird sein Land vieltausendfalt", "tokens": ["Nun", "wird", "sein", "Land", "viel\u00b7tau\u00b7send\u00b7falt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPOSAT", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Verw\u00fcsten, heeren, schatzen.", "tokens": ["Ver\u00b7w\u00fcs\u00b7ten", ",", "hee\u00b7ren", ",", "schat\u00b7zen", "."], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "VVINF", "$,", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "Das brannte mehr als Wundenschmerz!", "tokens": ["Das", "brann\u00b7te", "mehr", "als", "Wun\u00b7den\u00b7schmerz", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PIS", "KOKOM", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Er h\u00e4tt' sich gern gewendet,", "tokens": ["Er", "h\u00e4tt'", "sich", "gern", "ge\u00b7wen\u00b7det", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PRF", "ADV", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Verzweifelt und geendet:", "tokens": ["Ver\u00b7zwei\u00b7felt", "und", "ge\u00b7en\u00b7det", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["VVPP", "KON", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Doch lauter sprach sein K\u00f6nigsherz:", "tokens": ["Doch", "lau\u00b7ter", "sprach", "sein", "K\u00f6\u00b7nigs\u00b7herz", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "\u203adu bist des Landes Schild von Erz,", "tokens": ["\u203a", "du", "bist", "des", "Lan\u00b7des", "Schild", "von", "Erz", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "ART", "NN", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und sinkt dein Hoffen niederw\u00e4rts,", "tokens": ["Und", "sinkt", "dein", "Hof\u00b7fen", "nie\u00b7der\u00b7w\u00e4rts", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Ist Engelland gesch\u00e4ndet.\u2039", "tokens": ["Ist", "En\u00b7gel\u00b7land", "ge\u00b7sch\u00e4n\u00b7det", ".", "\u2039"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["VAFIN", "NE", "VVPP", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "Schwer stand er auf, schwer war sein Schritt:", "tokens": ["Schwer", "stand", "er", "auf", ",", "schwer", "war", "sein", "Schritt", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "PPER", "PTKVZ", "$,", "ADJD", "VAFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da, unter tausend Toten,", "tokens": ["Da", ",", "un\u00b7ter", "tau\u00b7send", "To\u00b7ten", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "APPR", "CARD", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Sein Kronhelm lag zerschroten:", "tokens": ["Sein", "Kron\u00b7helm", "lag", "zer\u00b7schro\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Er lie\u00df ihn, wie's sein Herz zerschnitt,", "tokens": ["Er", "lie\u00df", "ihn", ",", "wie's", "sein", "Herz", "zer\u00b7schnitt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$,", "KOUS", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Es ist das Volk die Krone nit: \u2013", "tokens": ["Es", "ist", "das", "Volk", "die", "Kro\u00b7ne", "nit", ":", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "ART", "NN", "PTKNEG", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Doch seinen Schild, den nahm er mit,", "tokens": ["Doch", "sei\u00b7nen", "Schild", ",", "den", "nahm", "er", "mit", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "$,", "ART", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Die Ehre hat's geboten.\u00ab", "tokens": ["Die", "Eh\u00b7re", "hat's", "ge\u00b7bo\u00b7ten", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "VAFIN", "VVPP", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.13": {"line.1": {"text": "\u00bbso lebt er noch? \u2013 ich bitte dich\u00ab \u2013", "tokens": ["\u00bb", "so", "lebt", "er", "noch", "?", "\u2013", "ich", "bit\u00b7te", "dich", "\u00ab", "\u2013"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADV", "VVFIN", "PPER", "ADV", "$.", "$(", "PPER", "VVFIN", "PPER", "$(", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u2013 So scholl's aus jedem Munde \u2013", "tokens": ["\u2013", "So", "scholl's", "aus", "je\u00b7dem", "Mun\u00b7de", "\u2013"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VVFIN", "APPR", "PIAT", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "\u00bbwoher ward dir die Kunde?", "tokens": ["\u00bb", "wo\u00b7her", "ward", "dir", "die", "Kun\u00b7de", "?"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWAV", "VAFIN", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Ist das sein Schild? Wer bist du? Sprich!\u00ab \u2013", "tokens": ["Ist", "das", "sein", "Schild", "?", "Wer", "bist", "du", "?", "Sprich", "!", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct", "punct", "punct"], "pos": ["VAFIN", "PDS", "PPOSAT", "NN", "$.", "PWS", "VAFIN", "PPER", "$.", "VVIMP", "$.", "$(", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Da warf der Harfner hinter sich", "tokens": ["Da", "warf", "der", "Harf\u00b7ner", "hin\u00b7ter", "sich"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPR", "PRF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Die H\u00fcllen und voll-k\u00f6niglich", "tokens": ["Die", "H\u00fcl\u00b7len", "und", "voll\u00b7k\u00f6\u00b7nig\u00b7lich"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "KON", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Durchflog sein Blick die Runde.", "tokens": ["Durch\u00b7flog", "sein", "Blick", "die", "Run\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.14": {"line.1": {"text": "\u00bbja, das ist eures K\u00f6nigs Schild,", "tokens": ["\u00bb", "ja", ",", "das", "ist", "eu\u00b7res", "K\u00f6\u00b7nigs", "Schild", ","], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PTKANT", "$,", "PDS", "VAFIN", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und ich\u00ab \u2013 da hob von allen", "tokens": ["Und", "ich", "\u00ab", "\u2013", "da", "hob", "von", "al\u00b7len"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word"], "pos": ["KON", "PPER", "$(", "$(", "ADV", "VVFIN", "APPR", "PIAT"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Ein Rufen sich und Schallen \u2013:", "tokens": ["Ein", "Ru\u00b7fen", "sich", "und", "Schal\u00b7len", "\u2013", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "PRF", "KON", "NN", "$(", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "\u00bbund du, du teures Heldenbild,", "tokens": ["\u00bb", "und", "du", ",", "du", "teu\u00b7res", "Hel\u00b7den\u00b7bild", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "KON", "PPER", "$,", "PPER", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Bist K\u00f6nig Alfred stark und mild,", "tokens": ["Bist", "K\u00f6\u00b7nig", "Al\u00b7fred", "stark", "und", "mild", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "NE", "ADJD", "KON", "ADJD", "$,"], "meter": "-+---+-+", "measure": "dactylic.init"}, "line.6": {"text": "Auf! f\u00fchr' uns an ins Schlachtgefild: \u2013", "tokens": ["Auf", "!", "f\u00fchr'", "uns", "an", "ins", "Schlacht\u00b7ge\u00b7fild", ":", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "$.", "VVFIN", "PPER", "APPR", "APPRART", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Die D\u00e4nen sollen fallen!\u00ab", "tokens": ["Die", "D\u00e4\u00b7nen", "sol\u00b7len", "fal\u00b7len", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "VMFIN", "VVINF", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.15": {"line.1": {"text": "Da sprach der F\u00fcrst: \u00bbDie Treu' ist echt,", "tokens": ["Da", "sprach", "der", "F\u00fcrst", ":", "\u00bb", "Die", "Treu'", "ist", "echt", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$.", "$(", "ART", "NN", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die nimmer will verzagen.", "tokens": ["Die", "nim\u00b7mer", "will", "ver\u00b7za\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Des will ich Dank euch sagen:", "tokens": ["Des", "will", "ich", "Dank", "euch", "sa\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "VMFIN", "PPER", "APPR", "PPER", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Du Volk von Kent: das sei dein Recht,", "tokens": ["Du", "Volk", "von", "Kent", ":", "das", "sei", "dein", "Recht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "APPR", "NE", "$.", "PDS", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Da\u00df von Geschlechte zu Geschlecht", "tokens": ["Da\u00df", "von", "Ge\u00b7schlech\u00b7te", "zu", "Ge\u00b7schlecht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "APPR", "NN", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Du sollst in jeglichem Gefecht", "tokens": ["Du", "sollst", "in", "jeg\u00b7li\u00b7chem", "Ge\u00b7fecht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Das Banner Englands tragen.\u00ab", "tokens": ["Das", "Ban\u00b7ner", "En\u00b7glands", "tra\u00b7gen", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.16": {"line.1": {"text": "\u00bbin harter Not liegt Engelland!", "tokens": ["\u00bb", "in", "har\u00b7ter", "Not", "liegt", "En\u00b7gel\u00b7land", "!"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "ADJA", "NN", "VVFIN", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Es sind mit tausend K\u00e4hnen", "tokens": ["Es", "sind", "mit", "tau\u00b7send", "K\u00e4h\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "APPR", "CARD", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Die gottverha\u00dften D\u00e4nen", "tokens": ["Die", "gott\u00b7ver\u00b7ha\u00df\u00b7ten", "D\u00e4\u00b7nen"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Gelandet an des Humber Strand:", "tokens": ["Ge\u00b7lan\u00b7det", "an", "des", "Hum\u00b7ber", "Strand", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "APPR", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Durch Yorkshire w\u00fctet Mord und Brand,", "tokens": ["Durch", "Y\u00b7orks\u00b7hi\u00b7re", "w\u00fc\u00b7tet", "Mord", "und", "Brand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VVFIN", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Und wo ist K\u00f6nig Alfreds Hand,", "tokens": ["Und", "wo", "ist", "K\u00f6\u00b7nig", "Al\u00b7freds", "Hand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "VAFIN", "NN", "NE", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Zu trocknen unsre Tr\u00e4nen?", "tokens": ["Zu", "trock\u00b7nen", "uns\u00b7re", "Tr\u00e4\u00b7nen", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.17": {"line.1": {"text": "Er fiel, er fiel der teure Held", "tokens": ["Er", "fiel", ",", "er", "fiel", "der", "teu\u00b7re", "Held"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Von einem scharfen Speere!", "tokens": ["Von", "ei\u00b7nem", "schar\u00b7fen", "Spee\u00b7re", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "So bringt's die blut'ge M\u00e4re!", "tokens": ["So", "bringt's", "die", "blut'\u00b7ge", "M\u00e4\u00b7re", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Kein Retter steht uns mehr im Feld:", "tokens": ["Kein", "Ret\u00b7ter", "steht", "uns", "mehr", "im", "Feld", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "PPER", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "So r\u00e4umt denn diese Inselwelt,", "tokens": ["So", "r\u00e4umt", "denn", "die\u00b7se", "In\u00b7sel\u00b7welt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "PDAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Die Hengst und Horsas Asche h\u00e4lt,", "tokens": ["Die", "Hengst", "und", "Hor\u00b7sas", "A\u00b7sche", "h\u00e4lt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NE", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und suchet neue Meere!\u00ab", "tokens": ["Und", "su\u00b7chet", "neu\u00b7e", "Mee\u00b7re", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.18": {"line.1": {"text": "So schallt's im Gaugericht zu Kent", "tokens": ["So", "schallt's", "im", "Gau\u00b7ge\u00b7richt", "zu", "Kent"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "APPRART", "NN", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Bei Grafen und bei Thanen,", "tokens": ["Bei", "Gra\u00b7fen", "und", "bei", "Tha\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "APPR", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Zu rascher Flucht zu mahnen.", "tokens": ["Zu", "ra\u00b7scher", "Flucht", "zu", "mah\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Da ist kein Mund, der Hilfe nennt:", "tokens": ["Da", "ist", "kein", "Mund", ",", "der", "Hil\u00b7fe", "nennt", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIAT", "NN", "$,", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Schon ist der Sch\u00f6ffen Kreis getrennt,", "tokens": ["Schon", "ist", "der", "Sch\u00f6f\u00b7fen", "Kreis", "ge\u00b7trennt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Schon senken sich \u2013 des Dinges End' \u2013", "tokens": ["Schon", "sen\u00b7ken", "sich", "\u2013", "des", "Din\u00b7ges", "End'", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "$(", "ART", "NN", "NN", "$("], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.7": {"text": "Vom Lindenbaum die Fahnen.", "tokens": ["Vom", "Lin\u00b7den\u00b7baum", "die", "Fah\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.19": {"line.1": {"text": "Da trat hervor ein Harfner alt:", "tokens": ["Da", "trat", "her\u00b7vor", "ein", "Harf\u00b7ner", "alt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PTKVZ", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Er stand am Stamm der Linde,", "tokens": ["Er", "stand", "am", "Stamm", "der", "Lin\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "ART", "NE", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Es flog sein Haar im Winde:", "tokens": ["Es", "flog", "sein", "Haar", "im", "Win\u00b7de", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Vom Kriegermantel braun umwallt", "tokens": ["Vom", "Krie\u00b7ger\u00b7man\u00b7tel", "braun", "um\u00b7wallt"], "token_info": ["word", "word", "word", "word"], "pos": ["APPRART", "NN", "ADJD", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Stolz reckte sich die Erzgestalt,", "tokens": ["Stolz", "reck\u00b7te", "sich", "die", "Erz\u00b7ge\u00b7stalt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PRF", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "In seinem Schild' ein breiter Spalt,", "tokens": ["In", "sei\u00b7nem", "Schild'", "ein", "brei\u00b7ter", "Spalt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Sein Haupt verbarg die Binde.", "tokens": ["Sein", "Haupt", "ver\u00b7barg", "die", "Bin\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.20": {"line.1": {"text": "\u00bbgemach, ihr lieben Herr'n zumal,", "tokens": ["\u00bb", "ge\u00b7mach", ",", "ihr", "lie\u00b7ben", "Herr'n", "zu\u00b7mal", ","], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "$,", "PPOSAT", "ADJA", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ich will euch nicht bet\u00f6ren,", "tokens": ["Ich", "will", "euch", "nicht", "be\u00b7t\u00f6\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Nicht euren Ratschlu\u00df st\u00f6ren:", "tokens": ["Nicht", "eu\u00b7ren", "Rat\u00b7schlu\u00df", "st\u00f6\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Doch komm' ich frisch von blut'ger Wal: \u2013", "tokens": ["Doch", "komm'", "ich", "frisch", "von", "blut'\u00b7ger", "Wal", ":", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADJD", "APPR", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Sprecht, wollt ihr nicht zum letztenmal", "tokens": ["Sprecht", ",", "wollt", "ihr", "nicht", "zum", "letz\u00b7ten\u00b7mal"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "$,", "VMFIN", "PPER", "PTKNEG", "APPRART", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Von eurem Herrn, der dort befahl,", "tokens": ["Von", "eu\u00b7rem", "Herrn", ",", "der", "dort", "be\u00b7fahl", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "PRELS", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Von K\u00f6nig Alfred h\u00f6ren?\u00ab", "tokens": ["Von", "K\u00f6\u00b7nig", "Al\u00b7fred", "h\u00f6\u00b7ren", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "NE", "NE", "VVINF", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.21": {"line.1": {"text": "\u00bbvon K\u00f6nig Alfred!\u00ab \u2013 ruft die Schar \u2013", "tokens": ["\u00bb", "von", "K\u00f6\u00b7nig", "Al\u00b7fred", "!", "\u00ab", "\u2013", "ruft", "die", "Schar", "\u2013"], "token_info": ["punct", "word", "word", "word", "punct", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "NE", "NE", "$.", "$(", "$(", "VVFIN", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und alles bleibt, zu lauschen", "tokens": ["Und", "al\u00b7les", "bleibt", ",", "zu", "lau\u00b7schen"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["KON", "PIS", "VVFIN", "$,", "PTKZU", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und feuchten Blick zu tauschen, \u2013", "tokens": ["Und", "feuch\u00b7ten", "Blick", "zu", "tau\u00b7schen", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ADJA", "NN", "PTKZU", "VVINF", "$,", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "\u00bbwei\u00dft du von seinem Ende gar?", "tokens": ["\u00bb", "wei\u00dft", "du", "von", "sei\u00b7nem", "En\u00b7de", "gar", "?"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "O, sing' von ihm, wie gro\u00df er war!\u00ab", "tokens": ["O", ",", "sing'", "von", "ihm", ",", "wie", "gro\u00df", "er", "war", "!", "\u00ab"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "$,", "VVFIN", "APPR", "PPER", "$,", "PWAV", "ADJD", "PPER", "VAFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Da blitzt des Harfners Auge klar,", "tokens": ["Da", "blitzt", "des", "Harf\u00b7ners", "Au\u00b7ge", "klar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und seine Saiten rauschen:", "tokens": ["Und", "sei\u00b7ne", "Sai\u00b7ten", "rau\u00b7schen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.22": {"line.1": {"text": "\u00bbo Wodenswood, du arges Feld,", "tokens": ["\u00bb", "o", "Wo\u00b7dens\u00b7wood", ",", "du", "ar\u00b7ges", "Feld", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "FM", "FM", "$,", "PPER", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Fluch sei mit deinen Eichen!", "tokens": ["Fluch", "sei", "mit", "dei\u00b7nen", "Ei\u00b7chen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Da ward von D\u00e4nenstreichen", "tokens": ["Da", "ward", "von", "D\u00e4\u00b7nen\u00b7strei\u00b7chen"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "APPR", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Manch' alter Sachsenschild zerspellt!", "tokens": ["Man\u00b7ch'", "al\u00b7ter", "Sach\u00b7sen\u00b7schild", "zer\u00b7spellt", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "VVPP", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.5": {"text": "Und, k\u00fchn zum Fu\u00dfkampf erst gestellt,", "tokens": ["Und", ",", "k\u00fchn", "zum", "Fu\u00df\u00b7kampf", "erst", "ge\u00b7stellt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "ADJD", "APPRART", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Nach seinem Hengst rief mancher Held,", "tokens": ["Nach", "sei\u00b7nem", "Hengst", "rief", "man\u00b7cher", "Held", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "In Flucht hindann zu weichen.", "tokens": ["In", "Flucht", "hin\u00b7dann", "zu", "wei\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.23": {"line.1": {"text": "Das d\u00fcnkte K\u00f6nig Alfred schlecht:", "tokens": ["Das", "d\u00fcnk\u00b7te", "K\u00f6\u00b7nig", "Al\u00b7fred", "schlecht", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NE", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Er jagte hin und wieder", "tokens": ["Er", "jag\u00b7te", "hin", "und", "wie\u00b7der"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PTKVZ", "KON", "ADV"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Durch alle Reiterglieder,", "tokens": ["Durch", "al\u00b7le", "Rei\u00b7ter\u00b7glie\u00b7der", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und rief: \u203aEin Sachse, treu und echt,", "tokens": ["Und", "rief", ":", "\u203a", "Ein", "Sach\u00b7se", ",", "treu", "und", "echt", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "$(", "ART", "NN", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Harrt aus im Tod, ob Than, ob Knecht!\u2039 \u2013", "tokens": ["Harrt", "aus", "im", "Tod", ",", "ob", "Than", ",", "ob", "Knecht", "!", "\u2039", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "punct", "punct"], "pos": ["VVFIN", "APPR", "APPRART", "NN", "$,", "KOUS", "NE", "$,", "KOUS", "NN", "$.", "$(", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und sprang herab zum Fu\u00dfgefecht", "tokens": ["Und", "sprang", "her\u00b7ab", "zum", "Fu\u00df\u00b7ge\u00b7fecht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und stach sein Streitro\u00df nieder.", "tokens": ["Und", "stach", "sein", "Strei\u00b7tro\u00df", "nie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.24": {"line.1": {"text": "Und nahm von York das Sturmpanier,", "tokens": ["Und", "nahm", "von", "Y\u00b7ork", "das", "Sturm\u00b7pa\u00b7nier", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "NE", "ART", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Der Bauern Kampfgenosse,", "tokens": ["Der", "Bau\u00b7ern", "Kampf\u00b7ge\u00b7nos\u00b7se", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und trug's in die Geschosse.", "tokens": ["Und", "trug's", "in", "die", "Ge\u00b7schos\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Da schlug ein Beil ihm ins Visier,", "tokens": ["Da", "schlug", "ein", "Beil", "ihm", "ins", "Vi\u00b7sier", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "PPER", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Schlug ihm vom Helm die Kronenzier, \u2013", "tokens": ["Schlug", "ihm", "vom", "Helm", "die", "Kro\u00b7nen\u00b7zier", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PPER", "APPRART", "NN", "ART", "NN", "$,", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Schlug ihm ins Haupt, zum Tode schier,", "tokens": ["Schlug", "ihm", "ins", "Haupt", ",", "zum", "To\u00b7de", "schier", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPRART", "NN", "$,", "APPRART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und \u00fcber ihm die Rosse! \u2013", "tokens": ["Und", "\u00fc\u00b7ber", "ihm", "die", "Ros\u00b7se", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "APPR", "PPER", "ART", "NN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.25": {"line.1": {"text": "Lang lag er so, die Nacht war kalt \u2013", "tokens": ["Lang", "lag", "er", "so", ",", "die", "Nacht", "war", "kalt", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "ADV", "$,", "ART", "NN", "VAFIN", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da weckten ihn mit Kratzen", "tokens": ["Da", "weck\u00b7ten", "ihn", "mit", "Krat\u00b7zen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Des Leichenwolfes Tatzen \u2013", "tokens": ["Des", "Lei\u00b7chen\u00b7wol\u00b7fes", "Tat\u00b7zen", "\u2013"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Er schlug \u2013 das Untier wich alsbald \u2013:", "tokens": ["Er", "schlug", "\u2013", "das", "Un\u00b7tier", "wich", "als\u00b7bald", "\u2013", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "$(", "ART", "NN", "VVFIN", "ADV", "$(", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Da dacht' er, wie des Feinds Gewalt", "tokens": ["Da", "dacht'", "er", ",", "wie", "des", "Feinds", "Ge\u00b7walt"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "$,", "PWAV", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Nun wird sein Land vieltausendfalt", "tokens": ["Nun", "wird", "sein", "Land", "viel\u00b7tau\u00b7send\u00b7falt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPOSAT", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Verw\u00fcsten, heeren, schatzen.", "tokens": ["Ver\u00b7w\u00fcs\u00b7ten", ",", "hee\u00b7ren", ",", "schat\u00b7zen", "."], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "VVINF", "$,", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.26": {"line.1": {"text": "Das brannte mehr als Wundenschmerz!", "tokens": ["Das", "brann\u00b7te", "mehr", "als", "Wun\u00b7den\u00b7schmerz", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PIS", "KOKOM", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Er h\u00e4tt' sich gern gewendet,", "tokens": ["Er", "h\u00e4tt'", "sich", "gern", "ge\u00b7wen\u00b7det", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PRF", "ADV", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Verzweifelt und geendet:", "tokens": ["Ver\u00b7zwei\u00b7felt", "und", "ge\u00b7en\u00b7det", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["VVPP", "KON", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Doch lauter sprach sein K\u00f6nigsherz:", "tokens": ["Doch", "lau\u00b7ter", "sprach", "sein", "K\u00f6\u00b7nigs\u00b7herz", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "\u203adu bist des Landes Schild von Erz,", "tokens": ["\u203a", "du", "bist", "des", "Lan\u00b7des", "Schild", "von", "Erz", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "ART", "NN", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und sinkt dein Hoffen niederw\u00e4rts,", "tokens": ["Und", "sinkt", "dein", "Hof\u00b7fen", "nie\u00b7der\u00b7w\u00e4rts", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Ist Engelland gesch\u00e4ndet.\u2039", "tokens": ["Ist", "En\u00b7gel\u00b7land", "ge\u00b7sch\u00e4n\u00b7det", ".", "\u2039"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["VAFIN", "NE", "VVPP", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.27": {"line.1": {"text": "Schwer stand er auf, schwer war sein Schritt:", "tokens": ["Schwer", "stand", "er", "auf", ",", "schwer", "war", "sein", "Schritt", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "PPER", "PTKVZ", "$,", "ADJD", "VAFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da, unter tausend Toten,", "tokens": ["Da", ",", "un\u00b7ter", "tau\u00b7send", "To\u00b7ten", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "APPR", "CARD", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Sein Kronhelm lag zerschroten:", "tokens": ["Sein", "Kron\u00b7helm", "lag", "zer\u00b7schro\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Er lie\u00df ihn, wie's sein Herz zerschnitt,", "tokens": ["Er", "lie\u00df", "ihn", ",", "wie's", "sein", "Herz", "zer\u00b7schnitt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$,", "KOUS", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Es ist das Volk die Krone nit: \u2013", "tokens": ["Es", "ist", "das", "Volk", "die", "Kro\u00b7ne", "nit", ":", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "ART", "NN", "PTKNEG", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Doch seinen Schild, den nahm er mit,", "tokens": ["Doch", "sei\u00b7nen", "Schild", ",", "den", "nahm", "er", "mit", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "$,", "ART", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Die Ehre hat's geboten.\u00ab", "tokens": ["Die", "Eh\u00b7re", "hat's", "ge\u00b7bo\u00b7ten", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "VAFIN", "VVPP", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.28": {"line.1": {"text": "\u00bbso lebt er noch? \u2013 ich bitte dich\u00ab \u2013", "tokens": ["\u00bb", "so", "lebt", "er", "noch", "?", "\u2013", "ich", "bit\u00b7te", "dich", "\u00ab", "\u2013"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADV", "VVFIN", "PPER", "ADV", "$.", "$(", "PPER", "VVFIN", "PPER", "$(", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u2013 So scholl's aus jedem Munde \u2013", "tokens": ["\u2013", "So", "scholl's", "aus", "je\u00b7dem", "Mun\u00b7de", "\u2013"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VVFIN", "APPR", "PIAT", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "\u00bbwoher ward dir die Kunde?", "tokens": ["\u00bb", "wo\u00b7her", "ward", "dir", "die", "Kun\u00b7de", "?"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWAV", "VAFIN", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Ist das sein Schild? Wer bist du? Sprich!\u00ab \u2013", "tokens": ["Ist", "das", "sein", "Schild", "?", "Wer", "bist", "du", "?", "Sprich", "!", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct", "punct", "punct"], "pos": ["VAFIN", "PDS", "PPOSAT", "NN", "$.", "PWS", "VAFIN", "PPER", "$.", "VVIMP", "$.", "$(", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Da warf der Harfner hinter sich", "tokens": ["Da", "warf", "der", "Harf\u00b7ner", "hin\u00b7ter", "sich"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPR", "PRF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Die H\u00fcllen und voll-k\u00f6niglich", "tokens": ["Die", "H\u00fcl\u00b7len", "und", "voll\u00b7k\u00f6\u00b7nig\u00b7lich"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "KON", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Durchflog sein Blick die Runde.", "tokens": ["Durch\u00b7flog", "sein", "Blick", "die", "Run\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.29": {"line.1": {"text": "\u00bbja, das ist eures K\u00f6nigs Schild,", "tokens": ["\u00bb", "ja", ",", "das", "ist", "eu\u00b7res", "K\u00f6\u00b7nigs", "Schild", ","], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PTKANT", "$,", "PDS", "VAFIN", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und ich\u00ab \u2013 da hob von allen", "tokens": ["Und", "ich", "\u00ab", "\u2013", "da", "hob", "von", "al\u00b7len"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word"], "pos": ["KON", "PPER", "$(", "$(", "ADV", "VVFIN", "APPR", "PIAT"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Ein Rufen sich und Schallen \u2013:", "tokens": ["Ein", "Ru\u00b7fen", "sich", "und", "Schal\u00b7len", "\u2013", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "PRF", "KON", "NN", "$(", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "\u00bbund du, du teures Heldenbild,", "tokens": ["\u00bb", "und", "du", ",", "du", "teu\u00b7res", "Hel\u00b7den\u00b7bild", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "KON", "PPER", "$,", "PPER", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Bist K\u00f6nig Alfred stark und mild,", "tokens": ["Bist", "K\u00f6\u00b7nig", "Al\u00b7fred", "stark", "und", "mild", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "NE", "ADJD", "KON", "ADJD", "$,"], "meter": "-+---+-+", "measure": "dactylic.init"}, "line.6": {"text": "Auf! f\u00fchr' uns an ins Schlachtgefild: \u2013", "tokens": ["Auf", "!", "f\u00fchr'", "uns", "an", "ins", "Schlacht\u00b7ge\u00b7fild", ":", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "$.", "VVFIN", "PPER", "APPR", "APPRART", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Die D\u00e4nen sollen fallen!\u00ab", "tokens": ["Die", "D\u00e4\u00b7nen", "sol\u00b7len", "fal\u00b7len", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "VMFIN", "VVINF", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.30": {"line.1": {"text": "Da sprach der F\u00fcrst: \u00bbDie Treu' ist echt,", "tokens": ["Da", "sprach", "der", "F\u00fcrst", ":", "\u00bb", "Die", "Treu'", "ist", "echt", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$.", "$(", "ART", "NN", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die nimmer will verzagen.", "tokens": ["Die", "nim\u00b7mer", "will", "ver\u00b7za\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Des will ich Dank euch sagen:", "tokens": ["Des", "will", "ich", "Dank", "euch", "sa\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "VMFIN", "PPER", "APPR", "PPER", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Du Volk von Kent: das sei dein Recht,", "tokens": ["Du", "Volk", "von", "Kent", ":", "das", "sei", "dein", "Recht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "APPR", "NE", "$.", "PDS", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Da\u00df von Geschlechte zu Geschlecht", "tokens": ["Da\u00df", "von", "Ge\u00b7schlech\u00b7te", "zu", "Ge\u00b7schlecht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "APPR", "NN", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Du sollst in jeglichem Gefecht", "tokens": ["Du", "sollst", "in", "jeg\u00b7li\u00b7chem", "Ge\u00b7fecht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Das Banner Englands tragen.\u00ab", "tokens": ["Das", "Ban\u00b7ner", "En\u00b7glands", "tra\u00b7gen", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}}}}