{"dta.poem.10971": {"metadata": {"author": {"name": "Brockes, Barthold Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "Beweisgrund  \n gegen die Alchimisten.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1740", "urn": "urn:nbn:de:kobv:b4-200905198572", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Da\u00df in den Blumen Honig stecket,", "tokens": ["Da\u00df", "in", "den", "Blu\u00b7men", "Ho\u00b7nig", "ste\u00b7cket", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "ART", "NN", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Hat uns die Bien allein entdecket.", "tokens": ["Hat", "uns", "die", "Bi\u00b7en", "al\u00b7lein", "ent\u00b7de\u00b7cket", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Man kann auch Honig, ohne sie,", "tokens": ["Man", "kann", "auch", "Ho\u00b7nig", ",", "oh\u00b7ne", "sie", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "ADV", "NN", "$,", "KOUI", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Auch mit der allergr\u00f6\u00dften M\u00fch,", "tokens": ["Auch", "mit", "der", "al\u00b7ler\u00b7gr\u00f6\u00df\u00b7ten", "M\u00fch", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Unm\u00f6glich aus den Blumen bringen.", "tokens": ["Un\u00b7m\u00f6g\u00b7lich", "aus", "den", "Blu\u00b7men", "brin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Da\u00df Milch aus Kr\u00e4utern zu erzwingen,", "tokens": ["Da\u00df", "Milch", "aus", "Kr\u00e4u\u00b7tern", "zu", "er\u00b7zwin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "APPR", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "W\u00e4r unserm menschlichen Verstand", "tokens": ["W\u00e4r", "un\u00b7serm", "menschli\u00b7chen", "Ver\u00b7stand"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "PPOSAT", "ADJA", "NN"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.8": {"text": "Und blieb uns stetig unbekannt;", "tokens": ["Und", "blieb", "uns", "ste\u00b7tig", "un\u00b7be\u00b7kannt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADJD", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Es zeigen solches unsre K\u00fch.", "tokens": ["Es", "zei\u00b7gen", "sol\u00b7ches", "uns\u00b7re", "K\u00fch", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIAT", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Auch w\u00e4r unm\u00f6glich, ohne Vieh,", "tokens": ["Auch", "w\u00e4r", "un\u00b7m\u00f6g\u00b7lich", ",", "oh\u00b7ne", "Vieh", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADJD", "$,", "KOUI", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Auf andre Weise, durch Filtriren,", "tokens": ["Auf", "and\u00b7re", "Wei\u00b7se", ",", "durch", "Filt\u00b7ri\u00b7ren", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Durch Mengen und durch Distilliren,", "tokens": ["Durch", "Men\u00b7gen", "und", "durch", "Dis\u00b7til\u00b7li\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Mit noch so viel gemischten Sachen,", "tokens": ["Mit", "noch", "so", "viel", "ge\u00b7mischten", "Sa\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "ADV", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.14": {"text": "Aus Gras und Kr\u00e4utern, Milch zu machen.", "tokens": ["Aus", "Gras", "und", "Kr\u00e4u\u00b7tern", ",", "Milch", "zu", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$,", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "Natur hat zu derselben Wesen", "tokens": ["Na\u00b7tur", "hat", "zu", "der\u00b7sel\u00b7ben", "We\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "VAFIN", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "Nur eine Weise sich erlesen.", "tokens": ["Nur", "ei\u00b7ne", "Wei\u00b7se", "sich", "er\u00b7le\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.17": {"text": "Wenn nun in der Metallen Reich", "tokens": ["Wenn", "nun", "in", "der", "Me\u00b7tal\u00b7len", "Reich"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.18": {"text": "Auf eine gleiche Weise, gleich", "tokens": ["Auf", "ei\u00b7ne", "glei\u00b7che", "Wei\u00b7se", ",", "gleich"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "$,", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "Die Anordnungen m\u00f6glich w\u00e4ren,", "tokens": ["Die", "An\u00b7ord\u00b7nun\u00b7gen", "m\u00f6g\u00b7lich", "w\u00e4\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.20": {"text": "In Gold ein gr\u00f6bers zu verkehren;", "tokens": ["In", "Gold", "ein", "gr\u00f6\u00b7bers", "zu", "ver\u00b7keh\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ART", "ADJA", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.21": {"text": "Mu\u00df denn nicht jeder zugestehn,", "tokens": ["Mu\u00df", "denn", "nicht", "je\u00b7der", "zu\u00b7ge\u00b7stehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "PTKNEG", "PIS", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.22": {"text": "Dem Sch\u00f6pfer der Natur zum Preise,", "tokens": ["Dem", "Sch\u00f6p\u00b7fer", "der", "Na\u00b7tur", "zum", "Prei\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.23": {"text": "Es k\u00f6nn, auf eine andre Weise,", "tokens": ["Es", "k\u00f6nn", ",", "auf", "ei\u00b7ne", "and\u00b7re", "Wei\u00b7se", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "$,", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.24": {"text": "Als die Natur dazu ersehn,", "tokens": ["Als", "die", "Na\u00b7tur", "da\u00b7zu", "er\u00b7sehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "PAV", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.25": {"text": "Mit keiner M\u00f6glichkeit geschehn?", "tokens": ["Mit", "kei\u00b7ner", "M\u00f6g\u00b7lich\u00b7keit", "ge\u00b7schehn", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}