{"textgrid.poem.46043": {"metadata": {"author": {"name": "Brentano, Clemens", "birth": "N.A.", "death": "N.A."}, "title": "Am vierundzwanzigsten Sonntage nach Pfingsten", "genre": "verse", "period": "N.A.", "pub_year": 1826, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wenn nach Daniel sich hebet", "tokens": ["Wenn", "nach", "Da\u00b7ni\u00b7el", "sich", "he\u00b7bet"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "APPR", "NE", "PRF", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Fluch und Greul an heil'gem Ort,", "tokens": ["Fluch", "und", "Greul", "an", "heil'\u00b7gem", "Ort", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wer dann in Jud\u00e4a lebet", "tokens": ["Wer", "dann", "in", "Ju\u00b7d\u00e4a", "le\u00b7bet"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "ADV", "APPR", "NE", "VVFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Fliehe auf die Berge fort!", "tokens": ["Flie\u00b7he", "auf", "die", "Ber\u00b7ge", "fort", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Keiner steig' vom Dache nieder", "tokens": ["Kei\u00b7ner", "steig'", "vom", "Da\u00b7che", "nie\u00b7der"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "APPRART", "NN", "PTKVZ"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Etwas holen in dem Haus;", "tokens": ["Et\u00b7was", "ho\u00b7len", "in", "dem", "Haus", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVINF", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Keiner kehr' vom Felde wieder,", "tokens": ["Kei\u00b7ner", "kehr'", "vom", "Fel\u00b7de", "wie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "APPRART", "NN", "ADV", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Um sein Kleid etwa, nach Haus.", "tokens": ["Um", "sein", "Kleid", "et\u00b7wa", ",", "nach", "Haus", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUI", "PPOSAT", "NN", "ADV", "$,", "APPR", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Weh der Schwangern, und der Kinder", "tokens": ["Weh", "der", "Schwan\u00b7gern", ",", "und", "der", "Kin\u00b7der"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "ART", "NN", "$,", "KON", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "S\u00e4ugenden, dann schweres Weh!", "tokens": ["S\u00e4u\u00b7gen\u00b7den", ",", "dann", "schwe\u00b7res", "Weh", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADV", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Fleht, da\u00df nicht die Flucht im Winter", "tokens": ["Fleht", ",", "da\u00df", "nicht", "die", "Flucht", "im", "Win\u00b7ter"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "$,", "KOUS", "PTKNEG", "ART", "NN", "APPRART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und am Sabbat nicht gescheh'.", "tokens": ["Und", "am", "Sab\u00b7bat", "nicht", "ge\u00b7scheh'", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "NN", "PTKNEG", "VVPP", "$."], "meter": "--+-+-+", "measure": "anapaest.init"}}, "stanza.4": {"line.1": {"text": "Solche Not war nie ersehen", "tokens": ["Sol\u00b7che", "Not", "war", "nie", "er\u00b7se\u00b7hen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "VAFIN", "ADV", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Von dem Anfang bis zur Zeit,", "tokens": ["Von", "dem", "An\u00b7fang", "bis", "zur", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "APPRART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wird nicht wieder auch ergehen", "tokens": ["Wird", "nicht", "wie\u00b7der", "auch", "er\u00b7ge\u00b7hen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "PTKNEG", "ADV", "ADV", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Bis zum Ende aller Zeit.", "tokens": ["Bis", "zum", "En\u00b7de", "al\u00b7ler", "Zeit", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "APPRART", "NN", "PIAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Niemand w\u00fcrde selig werden,", "tokens": ["Nie\u00b7mand", "w\u00fcr\u00b7de", "se\u00b7lig", "wer\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "ADJD", "VAINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "W\u00fcrde nicht verk\u00fcrzt die Pein,", "tokens": ["W\u00fcr\u00b7de", "nicht", "ver\u00b7k\u00fcrzt", "die", "Pein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PTKNEG", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Um die Auserw\u00e4hlten werden", "tokens": ["Um", "die", "Au\u00b7ser\u00b7w\u00e4hl\u00b7ten", "wer\u00b7den"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUI", "ART", "NN", "VAINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Doch verk\u00fcrzt die Tage sein.", "tokens": ["Doch", "ver\u00b7k\u00fcrzt", "die", "Ta\u00b7ge", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Glaubt dann nicht, sollt' einer reden:", "tokens": ["Glaubt", "dann", "nicht", ",", "sollt'", "ei\u00b7ner", "re\u00b7den", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PTKNEG", "$,", "VMFIN", "PIS", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "\u00bbhier ist Christus, dort ist er!\u00ab", "tokens": ["\u00bb", "hier", "ist", "Chris\u00b7tus", ",", "dort", "ist", "er", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADV", "VAFIN", "NE", "$,", "ADV", "VAFIN", "PPER", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Falsche Christus, Trugpropheten", "tokens": ["Fal\u00b7sche", "Chris\u00b7tus", ",", "Trug\u00b7pro\u00b7phe\u00b7ten"], "token_info": ["word", "word", "punct", "word"], "pos": ["NN", "NE", "$,", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ziehn mit Wundern dann umher.", "tokens": ["Ziehn", "mit", "Wun\u00b7dern", "dann", "um\u00b7her", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "NN", "ADV", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Hei\u00dft es: \u00bbIn der W\u00fcste gehet", "tokens": ["Hei\u00dft", "es", ":", "\u00bb", "In", "der", "W\u00fcs\u00b7te", "ge\u00b7het"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "$.", "$(", "APPR", "ART", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Christus dort!\u00ab Geht nicht hinaus.", "tokens": ["Chris\u00b7tus", "dort", "!", "\u00ab", "Geht", "nicht", "hin\u00b7aus", "."], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "$.", "$(", "VVFIN", "PTKNEG", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Hei\u00dft's: \u00bbIm innern Haus ihn sehet!\u00ab", "tokens": ["Hei\u00dft's", ":", "\u00bb", "Im", "in\u00b7nern", "Haus", "ihn", "se\u00b7het", "!", "\u00ab"], "token_info": ["word", "punct", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "$.", "$(", "APPRART", "ADJA", "NN", "PPER", "VVFIN", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Gehet nicht nach ihm ins Haus.", "tokens": ["Ge\u00b7het", "nicht", "nach", "ihm", "ins", "Haus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "APPR", "PPER", "APPRART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Denn wie Blitz vom Aufgang helle", "tokens": ["Denn", "wie", "Blitz", "vom", "Auf\u00b7gang", "hel\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "NN", "APPRART", "NN", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Leuchtend f\u00e4hrt von Gottes Thron", "tokens": ["Leuch\u00b7tend", "f\u00e4hrt", "von", "Got\u00b7tes", "Thron"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "APPR", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "In des Niederganges Schwelle,", "tokens": ["In", "des", "Nie\u00b7der\u00b7gan\u00b7ges", "Schwel\u00b7le", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "So k\u00f6mmt einst der Menschensohn.", "tokens": ["So", "k\u00f6mmt", "einst", "der", "Men\u00b7schen\u00b7sohn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.9": {"line.1": {"text": "Wo der Leib sein wird, da wieder", "tokens": ["Wo", "der", "Leib", "sein", "wird", ",", "da", "wie\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PWAV", "ART", "NN", "VAINF", "VAFIN", "$,", "KOUS", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sammelt sich der Adler Schar:", "tokens": ["Sam\u00b7melt", "sich", "der", "Ad\u00b7ler", "Schar", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ART", "NN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Zu dem Haupte kommt ihr Glieder,", "tokens": ["Zu", "dem", "Haup\u00b7te", "kommt", "ihr", "Glie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Stellt mit ihm die Kirche dar.", "tokens": ["Stellt", "mit", "ihm", "die", "Kir\u00b7che", "dar", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PPER", "ART", "NN", "PTKVZ", "$."], "meter": "--+-+-+", "measure": "anapaest.init"}}, "stanza.10": {"line.1": {"text": "Nach der Notzeit bald erdunkeln", "tokens": ["Nach", "der", "Not\u00b7zeit", "bald", "er\u00b7dun\u00b7keln"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ADV", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sonnenschein und Mondenlicht,", "tokens": ["Son\u00b7nen\u00b7schein", "und", "Mon\u00b7den\u00b7licht", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Sterne fallen, die jetzt funkeln;", "tokens": ["Ster\u00b7ne", "fal\u00b7len", ",", "die", "jetzt", "fun\u00b7keln", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VVINF", "$,", "PRELS", "ADV", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Himmelskraft ersch\u00fcttert bricht.", "tokens": ["Him\u00b7mels\u00b7kraft", "er\u00b7sch\u00fct\u00b7tert", "bricht", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "VVPP", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Nur des Menschensohnes Zeichen", "tokens": ["Nur", "des", "Men\u00b7schen\u00b7soh\u00b7nes", "Zei\u00b7chen"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wird am Himmel leuchtend stehn,", "tokens": ["Wird", "am", "Him\u00b7mel", "leuch\u00b7tend", "stehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPRART", "NN", "VVPP", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und der Erdgeschlechter Schweigen", "tokens": ["Und", "der", "Erd\u00b7ge\u00b7schlech\u00b7ter", "Schwei\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Laut in Wehklang \u00fcbergehn;", "tokens": ["Laut", "in", "Weh\u00b7klang", "\u00fc\u00b7ber\u00b7gehn", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "APPR", "NN", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Denn sie sehen, gro\u00df und m\u00e4chtig", "tokens": ["Denn", "sie", "se\u00b7hen", ",", "gro\u00df", "und", "m\u00e4ch\u00b7tig"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "PPER", "VVINF", "$,", "ADJD", "KON", "ADJD"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Kommet nun der Menschensohn", "tokens": ["Kom\u00b7met", "nun", "der", "Men\u00b7schen\u00b7sohn"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ganz in Herrlichkeit und pr\u00e4chtig", "tokens": ["Ganz", "in", "Herr\u00b7lich\u00b7keit", "und", "pr\u00e4ch\u00b7tig"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "NN", "KON", "ADJD"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Auf der Himmelswolken Thron.", "tokens": ["Auf", "der", "Him\u00b7mels\u00b7wol\u00b7ken", "Thron", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Seine Engel wird er senden,", "tokens": ["Sei\u00b7ne", "En\u00b7gel", "wird", "er", "sen\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sammelnd mit Posaunenschall", "tokens": ["Sam\u00b7melnd", "mit", "Po\u00b7sau\u00b7nen\u00b7schall"], "token_info": ["word", "word", "word"], "pos": ["ADJD", "APPR", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Von Weltenden zu Weltenden", "tokens": ["Von", "Wel\u00b7ten\u00b7den", "zu", "Wel\u00b7ten\u00b7den"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NN", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Seine Auserw\u00e4hlten all.", "tokens": ["Sei\u00b7ne", "Au\u00b7ser\u00b7w\u00e4hl\u00b7ten", "all", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PIAT", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "Zweig und Blatt vom Baum der Feigen", "tokens": ["Zweig", "und", "Blatt", "vom", "Baum", "der", "Fei\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "KON", "NN", "APPRART", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Lehrt euch, wann der Sommer nah;", "tokens": ["Lehrt", "euch", ",", "wann", "der", "Som\u00b7mer", "nah", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "PWAV", "ART", "NN", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Seht ihr nun einst diese Zeichen,", "tokens": ["Seht", "ihr", "nun", "einst", "die\u00b7se", "Zei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "PDAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ist des Herren Tag auch da.", "tokens": ["Ist", "des", "Her\u00b7ren", "Tag", "auch", "da", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "NN", "ADV", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.15": {"line.1": {"text": "Dies Geschlecht wird nicht vergehen,", "tokens": ["Dies", "Ge\u00b7schlecht", "wird", "nicht", "ver\u00b7ge\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "NN", "VAFIN", "PTKNEG", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wahrlich! bis dies wird geschehn;", "tokens": ["Wahr\u00b7lich", "!", "bis", "dies", "wird", "ge\u00b7schehn", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$.", "APPR", "PDS", "VAFIN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Erd' und Himmel wird vergehen,", "tokens": ["Erd'", "und", "Him\u00b7mel", "wird", "ver\u00b7ge\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VAFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Doch mein Wort wird ewig stehn.", "tokens": ["Doch", "mein", "Wort", "wird", "e\u00b7wig", "stehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VAFIN", "ADJD", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.16": {"line.1": {"text": "Der Erl\u00f6ser nennt die Zeichen,", "tokens": ["Der", "Er\u00b7l\u00f6\u00b7ser", "nennt", "die", "Zei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Die voran dem Richter gehn,", "tokens": ["Die", "vo\u00b7ran", "dem", "Rich\u00b7ter", "gehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df erl\u00f6set, ohn' Erbleichen,", "tokens": ["Da\u00df", "er\u00b7l\u00f6\u00b7set", ",", "ohn'", "Er\u00b7blei\u00b7chen", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "VVPP", "$,", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wir den Richter kommen sehn.", "tokens": ["Wir", "den", "Rich\u00b7ter", "kom\u00b7men", "sehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "VVINF", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.17": {"line.1": {"text": "Wenn nach Daniel sich hebet", "tokens": ["Wenn", "nach", "Da\u00b7ni\u00b7el", "sich", "he\u00b7bet"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "APPR", "NE", "PRF", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Fluch und Greul an heil'gem Ort,", "tokens": ["Fluch", "und", "Greul", "an", "heil'\u00b7gem", "Ort", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wer dann in Jud\u00e4a lebet", "tokens": ["Wer", "dann", "in", "Ju\u00b7d\u00e4a", "le\u00b7bet"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "ADV", "APPR", "NE", "VVFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Fliehe auf die Berge fort!", "tokens": ["Flie\u00b7he", "auf", "die", "Ber\u00b7ge", "fort", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.18": {"line.1": {"text": "Keiner steig' vom Dache nieder", "tokens": ["Kei\u00b7ner", "steig'", "vom", "Da\u00b7che", "nie\u00b7der"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "APPRART", "NN", "PTKVZ"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Etwas holen in dem Haus;", "tokens": ["Et\u00b7was", "ho\u00b7len", "in", "dem", "Haus", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVINF", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Keiner kehr' vom Felde wieder,", "tokens": ["Kei\u00b7ner", "kehr'", "vom", "Fel\u00b7de", "wie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "APPRART", "NN", "ADV", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Um sein Kleid etwa, nach Haus.", "tokens": ["Um", "sein", "Kleid", "et\u00b7wa", ",", "nach", "Haus", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUI", "PPOSAT", "NN", "ADV", "$,", "APPR", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.19": {"line.1": {"text": "Weh der Schwangern, und der Kinder", "tokens": ["Weh", "der", "Schwan\u00b7gern", ",", "und", "der", "Kin\u00b7der"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "ART", "NN", "$,", "KON", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "S\u00e4ugenden, dann schweres Weh!", "tokens": ["S\u00e4u\u00b7gen\u00b7den", ",", "dann", "schwe\u00b7res", "Weh", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADV", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Fleht, da\u00df nicht die Flucht im Winter", "tokens": ["Fleht", ",", "da\u00df", "nicht", "die", "Flucht", "im", "Win\u00b7ter"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "$,", "KOUS", "PTKNEG", "ART", "NN", "APPRART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und am Sabbat nicht gescheh'.", "tokens": ["Und", "am", "Sab\u00b7bat", "nicht", "ge\u00b7scheh'", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "NN", "PTKNEG", "VVPP", "$."], "meter": "--+-+-+", "measure": "anapaest.init"}}, "stanza.20": {"line.1": {"text": "Solche Not war nie ersehen", "tokens": ["Sol\u00b7che", "Not", "war", "nie", "er\u00b7se\u00b7hen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "VAFIN", "ADV", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Von dem Anfang bis zur Zeit,", "tokens": ["Von", "dem", "An\u00b7fang", "bis", "zur", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "APPRART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wird nicht wieder auch ergehen", "tokens": ["Wird", "nicht", "wie\u00b7der", "auch", "er\u00b7ge\u00b7hen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "PTKNEG", "ADV", "ADV", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Bis zum Ende aller Zeit.", "tokens": ["Bis", "zum", "En\u00b7de", "al\u00b7ler", "Zeit", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "APPRART", "NN", "PIAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.21": {"line.1": {"text": "Niemand w\u00fcrde selig werden,", "tokens": ["Nie\u00b7mand", "w\u00fcr\u00b7de", "se\u00b7lig", "wer\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "ADJD", "VAINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "W\u00fcrde nicht verk\u00fcrzt die Pein,", "tokens": ["W\u00fcr\u00b7de", "nicht", "ver\u00b7k\u00fcrzt", "die", "Pein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PTKNEG", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Um die Auserw\u00e4hlten werden", "tokens": ["Um", "die", "Au\u00b7ser\u00b7w\u00e4hl\u00b7ten", "wer\u00b7den"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUI", "ART", "NN", "VAINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Doch verk\u00fcrzt die Tage sein.", "tokens": ["Doch", "ver\u00b7k\u00fcrzt", "die", "Ta\u00b7ge", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.22": {"line.1": {"text": "Glaubt dann nicht, sollt' einer reden:", "tokens": ["Glaubt", "dann", "nicht", ",", "sollt'", "ei\u00b7ner", "re\u00b7den", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PTKNEG", "$,", "VMFIN", "PIS", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "\u00bbhier ist Christus, dort ist er!\u00ab", "tokens": ["\u00bb", "hier", "ist", "Chris\u00b7tus", ",", "dort", "ist", "er", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADV", "VAFIN", "NE", "$,", "ADV", "VAFIN", "PPER", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Falsche Christus, Trugpropheten", "tokens": ["Fal\u00b7sche", "Chris\u00b7tus", ",", "Trug\u00b7pro\u00b7phe\u00b7ten"], "token_info": ["word", "word", "punct", "word"], "pos": ["NN", "NE", "$,", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ziehn mit Wundern dann umher.", "tokens": ["Ziehn", "mit", "Wun\u00b7dern", "dann", "um\u00b7her", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "NN", "ADV", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.23": {"line.1": {"text": "Hei\u00dft es: \u00bbIn der W\u00fcste gehet", "tokens": ["Hei\u00dft", "es", ":", "\u00bb", "In", "der", "W\u00fcs\u00b7te", "ge\u00b7het"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "$.", "$(", "APPR", "ART", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Christus dort!\u00ab Geht nicht hinaus.", "tokens": ["Chris\u00b7tus", "dort", "!", "\u00ab", "Geht", "nicht", "hin\u00b7aus", "."], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "$.", "$(", "VVFIN", "PTKNEG", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Hei\u00dft's: \u00bbIm innern Haus ihn sehet!\u00ab", "tokens": ["Hei\u00dft's", ":", "\u00bb", "Im", "in\u00b7nern", "Haus", "ihn", "se\u00b7het", "!", "\u00ab"], "token_info": ["word", "punct", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "$.", "$(", "APPRART", "ADJA", "NN", "PPER", "VVFIN", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Gehet nicht nach ihm ins Haus.", "tokens": ["Ge\u00b7het", "nicht", "nach", "ihm", "ins", "Haus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "APPR", "PPER", "APPRART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.24": {"line.1": {"text": "Denn wie Blitz vom Aufgang helle", "tokens": ["Denn", "wie", "Blitz", "vom", "Auf\u00b7gang", "hel\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "NN", "APPRART", "NN", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Leuchtend f\u00e4hrt von Gottes Thron", "tokens": ["Leuch\u00b7tend", "f\u00e4hrt", "von", "Got\u00b7tes", "Thron"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "APPR", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "In des Niederganges Schwelle,", "tokens": ["In", "des", "Nie\u00b7der\u00b7gan\u00b7ges", "Schwel\u00b7le", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "So k\u00f6mmt einst der Menschensohn.", "tokens": ["So", "k\u00f6mmt", "einst", "der", "Men\u00b7schen\u00b7sohn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.25": {"line.1": {"text": "Wo der Leib sein wird, da wieder", "tokens": ["Wo", "der", "Leib", "sein", "wird", ",", "da", "wie\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PWAV", "ART", "NN", "VAINF", "VAFIN", "$,", "KOUS", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sammelt sich der Adler Schar:", "tokens": ["Sam\u00b7melt", "sich", "der", "Ad\u00b7ler", "Schar", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ART", "NN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Zu dem Haupte kommt ihr Glieder,", "tokens": ["Zu", "dem", "Haup\u00b7te", "kommt", "ihr", "Glie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Stellt mit ihm die Kirche dar.", "tokens": ["Stellt", "mit", "ihm", "die", "Kir\u00b7che", "dar", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PPER", "ART", "NN", "PTKVZ", "$."], "meter": "--+-+-+", "measure": "anapaest.init"}}, "stanza.26": {"line.1": {"text": "Nach der Notzeit bald erdunkeln", "tokens": ["Nach", "der", "Not\u00b7zeit", "bald", "er\u00b7dun\u00b7keln"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ADV", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sonnenschein und Mondenlicht,", "tokens": ["Son\u00b7nen\u00b7schein", "und", "Mon\u00b7den\u00b7licht", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Sterne fallen, die jetzt funkeln;", "tokens": ["Ster\u00b7ne", "fal\u00b7len", ",", "die", "jetzt", "fun\u00b7keln", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VVINF", "$,", "PRELS", "ADV", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Himmelskraft ersch\u00fcttert bricht.", "tokens": ["Him\u00b7mels\u00b7kraft", "er\u00b7sch\u00fct\u00b7tert", "bricht", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "VVPP", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.27": {"line.1": {"text": "Nur des Menschensohnes Zeichen", "tokens": ["Nur", "des", "Men\u00b7schen\u00b7soh\u00b7nes", "Zei\u00b7chen"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wird am Himmel leuchtend stehn,", "tokens": ["Wird", "am", "Him\u00b7mel", "leuch\u00b7tend", "stehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPRART", "NN", "VVPP", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und der Erdgeschlechter Schweigen", "tokens": ["Und", "der", "Erd\u00b7ge\u00b7schlech\u00b7ter", "Schwei\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Laut in Wehklang \u00fcbergehn;", "tokens": ["Laut", "in", "Weh\u00b7klang", "\u00fc\u00b7ber\u00b7gehn", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "APPR", "NN", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.28": {"line.1": {"text": "Denn sie sehen, gro\u00df und m\u00e4chtig", "tokens": ["Denn", "sie", "se\u00b7hen", ",", "gro\u00df", "und", "m\u00e4ch\u00b7tig"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "PPER", "VVINF", "$,", "ADJD", "KON", "ADJD"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Kommet nun der Menschensohn", "tokens": ["Kom\u00b7met", "nun", "der", "Men\u00b7schen\u00b7sohn"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ganz in Herrlichkeit und pr\u00e4chtig", "tokens": ["Ganz", "in", "Herr\u00b7lich\u00b7keit", "und", "pr\u00e4ch\u00b7tig"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "NN", "KON", "ADJD"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Auf der Himmelswolken Thron.", "tokens": ["Auf", "der", "Him\u00b7mels\u00b7wol\u00b7ken", "Thron", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.29": {"line.1": {"text": "Seine Engel wird er senden,", "tokens": ["Sei\u00b7ne", "En\u00b7gel", "wird", "er", "sen\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sammelnd mit Posaunenschall", "tokens": ["Sam\u00b7melnd", "mit", "Po\u00b7sau\u00b7nen\u00b7schall"], "token_info": ["word", "word", "word"], "pos": ["ADJD", "APPR", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Von Weltenden zu Weltenden", "tokens": ["Von", "Wel\u00b7ten\u00b7den", "zu", "Wel\u00b7ten\u00b7den"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NN", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Seine Auserw\u00e4hlten all.", "tokens": ["Sei\u00b7ne", "Au\u00b7ser\u00b7w\u00e4hl\u00b7ten", "all", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PIAT", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.30": {"line.1": {"text": "Zweig und Blatt vom Baum der Feigen", "tokens": ["Zweig", "und", "Blatt", "vom", "Baum", "der", "Fei\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "KON", "NN", "APPRART", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Lehrt euch, wann der Sommer nah;", "tokens": ["Lehrt", "euch", ",", "wann", "der", "Som\u00b7mer", "nah", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "PWAV", "ART", "NN", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Seht ihr nun einst diese Zeichen,", "tokens": ["Seht", "ihr", "nun", "einst", "die\u00b7se", "Zei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "PDAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ist des Herren Tag auch da.", "tokens": ["Ist", "des", "Her\u00b7ren", "Tag", "auch", "da", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "NN", "ADV", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.31": {"line.1": {"text": "Dies Geschlecht wird nicht vergehen,", "tokens": ["Dies", "Ge\u00b7schlecht", "wird", "nicht", "ver\u00b7ge\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "NN", "VAFIN", "PTKNEG", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wahrlich! bis dies wird geschehn;", "tokens": ["Wahr\u00b7lich", "!", "bis", "dies", "wird", "ge\u00b7schehn", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$.", "APPR", "PDS", "VAFIN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Erd' und Himmel wird vergehen,", "tokens": ["Erd'", "und", "Him\u00b7mel", "wird", "ver\u00b7ge\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VAFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Doch mein Wort wird ewig stehn.", "tokens": ["Doch", "mein", "Wort", "wird", "e\u00b7wig", "stehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VAFIN", "ADJD", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.32": {"line.1": {"text": "Der Erl\u00f6ser nennt die Zeichen,", "tokens": ["Der", "Er\u00b7l\u00f6\u00b7ser", "nennt", "die", "Zei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Die voran dem Richter gehn,", "tokens": ["Die", "vo\u00b7ran", "dem", "Rich\u00b7ter", "gehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df erl\u00f6set, ohn' Erbleichen,", "tokens": ["Da\u00df", "er\u00b7l\u00f6\u00b7set", ",", "ohn'", "Er\u00b7blei\u00b7chen", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "VVPP", "$,", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wir den Richter kommen sehn.", "tokens": ["Wir", "den", "Rich\u00b7ter", "kom\u00b7men", "sehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "VVINF", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}