{"dta.poem.2864": {"metadata": {"author": {"name": "R\u00fcckert, Friedrich", "birth": "N.A.", "death": "N.A."}, "title": "65.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1838", "urn": "urn:nbn:de:kobv:b4-200905195108", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Villeicht, doch nur villeicht vollkommener vollendet", "tokens": ["Vil\u00b7leicht", ",", "doch", "nur", "vil\u00b7leicht", "voll\u00b7kom\u00b7me\u00b7ner", "voll\u00b7en\u00b7det"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "ADV", "ADV", "ADV", "ADJD", "VVPP"], "meter": "-+-+-+-+---+-", "measure": "unknown.measure.penta"}, "line.2": {"text": "W\u00e4r' eines, h\u00e4ttest du darauf mehr Zeit verwendet.", "tokens": ["W\u00e4r'", "ei\u00b7nes", ",", "h\u00e4t\u00b7test", "du", "da\u00b7rauf", "mehr", "Zeit", "ver\u00b7wen\u00b7det", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "$,", "VAFIN", "PPER", "PAV", "PIAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Doch k\u00fcmmre dich nur nicht! was etwa diesem fehlt,", "tokens": ["Doch", "k\u00fcmm\u00b7re", "dich", "nur", "nicht", "!", "was", "et\u00b7wa", "die\u00b7sem", "fehlt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "PTKNEG", "$.", "PWS", "ADV", "PDAT", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ersetzt ein andres, das dein Flei\u00df inzwischen w\u00e4hlt.", "tokens": ["Er\u00b7setzt", "ein", "and\u00b7res", ",", "das", "dein", "Flei\u00df", "in\u00b7zwi\u00b7schen", "w\u00e4hlt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "PIS", "$,", "PRELS", "PPOSAT", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Der Dinge sind soviel zu thun in dieser Welt,", "tokens": ["Der", "Din\u00b7ge", "sind", "so\u00b7viel", "zu", "thun", "in", "die\u00b7ser", "Welt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PIS", "PTKZU", "VVINF", "APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Da\u00df gar zuviel vers\u00e4umt, wer lang beim einen h\u00e4lt.", "tokens": ["Da\u00df", "gar", "zu\u00b7viel", "ver\u00b7s\u00e4umt", ",", "wer", "lang", "beim", "ei\u00b7nen", "h\u00e4lt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PIS", "VVPP", "$,", "PWS", "ADJD", "APPRART", "PIS", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Rath' ich dir Sudelei drum und Eilfertigkeit?", "tokens": ["Ra\u00b7th'", "ich", "dir", "Su\u00b7de\u00b7lei", "drum", "und", "Eil\u00b7fer\u00b7tig\u00b7keit", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PPER", "NN", "PAV", "KON", "NN", "$."], "meter": "-+--+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Nein, aber Eilfahrt! denn mit Eilfahrt f\u00e4hrt die Zeit.", "tokens": ["Nein", ",", "a\u00b7ber", "Eil\u00b7fahrt", "!", "denn", "mit", "Eil\u00b7fahrt", "f\u00e4hrt", "die", "Zeit", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "KON", "NN", "$.", "ADV", "APPR", "NN", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Eilfertiger als je die Eilfuhr mit den G\u00e4sten,", "tokens": ["Eil\u00b7fer\u00b7ti\u00b7ger", "als", "je", "die", "Eil\u00b7fuhr", "mit", "den", "G\u00e4s\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KOKOM", "ADV", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "F\u00e4hrt meine Wolkenpost stets zwischen Ost und Westen.", "tokens": ["F\u00e4hrt", "mei\u00b7ne", "Wol\u00b7ken\u00b7post", "stets", "zwi\u00b7schen", "Ost", "und", "Wes\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "ADV", "APPR", "NN", "KON", "NN", "$."], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}}}}}