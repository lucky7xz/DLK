{"textgrid.poem.47083": {"metadata": {"author": {"name": "R\u00fcckert, Friedrich", "birth": "N.A.", "death": "N.A."}, "title": "4.", "genre": "verse", "period": "N.A.", "pub_year": 1827, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Bringt her die Fackeln und das Grabger\u00e4te,", "tokens": ["Bringt", "her", "die", "Fa\u00b7ckeln", "und", "das", "Grab\u00b7ge\u00b7r\u00e4\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "KON", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die T\u00fccher bringt, und schm\u00fccket reich die Bahre!", "tokens": ["Die", "T\u00fc\u00b7cher", "bringt", ",", "und", "schm\u00fc\u00b7cket", "reich", "die", "Bah\u00b7re", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "KON", "VVFIN", "ADJD", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Wie ", "tokens": ["Wie"], "token_info": ["word"], "pos": ["PWAV"], "meter": "+", "measure": "single.up"}, "line.4": {"text": "Sonst schm\u00fcckte, schm\u00fcckt ", "tokens": ["Sonst", "schm\u00fcck\u00b7te", ",", "schm\u00fcckt"], "token_info": ["word", "word", "punct", "word"], "pos": ["ADV", "VVFIN", "$,", "VVFIN"], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.2": {"line.1": {"text": "Den Brautkranz, den der d\u00fcstre Schnitter m\u00e4hte,", "tokens": ["Den", "Braut\u00b7kranz", ",", "den", "der", "d\u00fcst\u00b7re", "Schnit\u00b7ter", "m\u00e4h\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ersetz' ein Totenkranz im \u00fcpp'gen Haare:", "tokens": ["Er\u00b7setz'", "ein", "To\u00b7ten\u00b7kranz", "im", "\u00fcpp'\u00b7gen", "Haa\u00b7re", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Wie wir gef\u00fchrt sie h\u00e4tten zum Altare,", "tokens": ["Wie", "wir", "ge\u00b7f\u00fchrt", "sie", "h\u00e4t\u00b7ten", "zum", "Al\u00b7ta\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VVPP", "PPER", "VAFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "So f\u00fchren wir sie heut zur letzten St\u00e4tte.", "tokens": ["So", "f\u00fch\u00b7ren", "wir", "sie", "heut", "zur", "letz\u00b7ten", "St\u00e4t\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "ADV", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Nicht das Gepr\u00e4ng', das nicht'ge, sei gescholten!", "tokens": ["Nicht", "das", "Ge\u00b7pr\u00e4ng'", ",", "das", "nicht'\u00b7ge", ",", "sei", "ge\u00b7schol\u00b7ten", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PTKNEG", "ART", "NN", "$,", "PRELS", "PIS", "$,", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die Tote schm\u00fccken wir, um kundzugeben,", "tokens": ["Die", "To\u00b7te", "schm\u00fc\u00b7cken", "wir", ",", "um", "kund\u00b7zu\u00b7ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "$,", "KOUI", "VVIZU", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Wie wir sie, wenn sie lebte, schm\u00fccken wollten.", "tokens": ["Wie", "wir", "sie", ",", "wenn", "sie", "leb\u00b7te", ",", "schm\u00fc\u00b7cken", "woll\u00b7ten", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PPER", "$,", "KOUS", "PPER", "VVFIN", "$,", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Was ", "tokens": ["Was"], "token_info": ["word"], "pos": ["PWS"], "meter": "-", "measure": "single.down"}, "line.2": {"text": "Sei von der Liebe ", "tokens": ["Sei", "von", "der", "Lie\u00b7be"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "APPR", "ART", "NN"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Und neidenswert soll ", "tokens": ["Und", "nei\u00b7dens\u00b7wert", "soll"], "token_info": ["word", "word", "word"], "pos": ["KON", "VVFIN", "VMFIN"], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.5": {"line.1": {"text": "Bringt her die Fackeln und das Grabger\u00e4te,", "tokens": ["Bringt", "her", "die", "Fa\u00b7ckeln", "und", "das", "Grab\u00b7ge\u00b7r\u00e4\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "KON", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die T\u00fccher bringt, und schm\u00fccket reich die Bahre!", "tokens": ["Die", "T\u00fc\u00b7cher", "bringt", ",", "und", "schm\u00fc\u00b7cket", "reich", "die", "Bah\u00b7re", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "KON", "VVFIN", "ADJD", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Wie ", "tokens": ["Wie"], "token_info": ["word"], "pos": ["PWAV"], "meter": "+", "measure": "single.up"}, "line.4": {"text": "Sonst schm\u00fcckte, schm\u00fcckt ", "tokens": ["Sonst", "schm\u00fcck\u00b7te", ",", "schm\u00fcckt"], "token_info": ["word", "word", "punct", "word"], "pos": ["ADV", "VVFIN", "$,", "VVFIN"], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.6": {"line.1": {"text": "Den Brautkranz, den der d\u00fcstre Schnitter m\u00e4hte,", "tokens": ["Den", "Braut\u00b7kranz", ",", "den", "der", "d\u00fcst\u00b7re", "Schnit\u00b7ter", "m\u00e4h\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ersetz' ein Totenkranz im \u00fcpp'gen Haare:", "tokens": ["Er\u00b7setz'", "ein", "To\u00b7ten\u00b7kranz", "im", "\u00fcpp'\u00b7gen", "Haa\u00b7re", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Wie wir gef\u00fchrt sie h\u00e4tten zum Altare,", "tokens": ["Wie", "wir", "ge\u00b7f\u00fchrt", "sie", "h\u00e4t\u00b7ten", "zum", "Al\u00b7ta\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VVPP", "PPER", "VAFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "So f\u00fchren wir sie heut zur letzten St\u00e4tte.", "tokens": ["So", "f\u00fch\u00b7ren", "wir", "sie", "heut", "zur", "letz\u00b7ten", "St\u00e4t\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "ADV", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.7": {"line.1": {"text": "Nicht das Gepr\u00e4ng', das nicht'ge, sei gescholten!", "tokens": ["Nicht", "das", "Ge\u00b7pr\u00e4ng'", ",", "das", "nicht'\u00b7ge", ",", "sei", "ge\u00b7schol\u00b7ten", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PTKNEG", "ART", "NN", "$,", "PRELS", "PIS", "$,", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die Tote schm\u00fccken wir, um kundzugeben,", "tokens": ["Die", "To\u00b7te", "schm\u00fc\u00b7cken", "wir", ",", "um", "kund\u00b7zu\u00b7ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "$,", "KOUI", "VVIZU", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Wie wir sie, wenn sie lebte, schm\u00fccken wollten.", "tokens": ["Wie", "wir", "sie", ",", "wenn", "sie", "leb\u00b7te", ",", "schm\u00fc\u00b7cken", "woll\u00b7ten", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PPER", "$,", "KOUS", "PPER", "VVFIN", "$,", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.8": {"line.1": {"text": "Was ", "tokens": ["Was"], "token_info": ["word"], "pos": ["PWS"], "meter": "-", "measure": "single.down"}, "line.2": {"text": "Sei von der Liebe ", "tokens": ["Sei", "von", "der", "Lie\u00b7be"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "APPR", "ART", "NN"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Und neidenswert soll ", "tokens": ["Und", "nei\u00b7dens\u00b7wert", "soll"], "token_info": ["word", "word", "word"], "pos": ["KON", "VVFIN", "VMFIN"], "meter": "-+-+-", "measure": "iambic.di"}}}}}