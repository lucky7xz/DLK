{"dta.poem.9556": {"metadata": {"author": {"name": "Hofmannswaldau, Christian Hofmann von", "birth": "N.A.", "death": "N.A."}, "title": "Sie tadelt/ da\u00df di\u00df bildni\u00df ihr nicht gleich sehe.  \n C. E.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1697", "urn": "urn:nbn:de:kobv:b4-200905199377", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Wje? soll das bildni\u00df nicht Liboren \u00e4hnlich seyn/", "tokens": ["Wie", "?", "soll", "das", "bild\u00b7ni\u00df", "nicht", "Li\u00b7bo\u00b7ren", "\u00e4hn\u00b7lich", "seyn", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "VMFIN", "ART", "NN", "PTKNEG", "NN", "ADJD", "VAINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Das ich zu mahlen mich erst neulich unterfangen?", "tokens": ["Das", "ich", "zu", "mah\u00b7len", "mich", "erst", "neu\u00b7lich", "un\u00b7ter\u00b7fan\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "PTKZU", "VVINF", "PPER", "ADV", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Trifft augen/ stirn und mund/ und die bemilchte wangen", "tokens": ["Trifft", "au\u00b7gen", "/", "stirn", "und", "mund", "/", "und", "die", "be\u00b7milch\u00b7te", "wan\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "NN", "$(", "VVINF", "KON", "NN", "$(", "KON", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Nicht mehr als allzuwohl mit ihrer anmuth ein?", "tokens": ["Nicht", "mehr", "als", "all\u00b7zu\u00b7wohl", "mit", "ih\u00b7rer", "an\u00b7muth", "ein", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "PIAT", "KOKOM", "ADV", "APPR", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Der tadel ist gantz falsch. Doch nein! verwegner/ nein!", "tokens": ["Der", "ta\u00b7del", "ist", "gantz", "falsch", ".", "Doch", "nein", "!", "ver\u00b7weg\u00b7ner", "/", "nein", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "ADJD", "$.", "KON", "PTKANT", "$.", "ADJD", "$(", "PTKANT", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Du mahlst nicht hei\u00df genug der hellen augen schein/", "tokens": ["Du", "mahlst", "nicht", "hei\u00df", "ge\u00b7nug", "der", "hel\u00b7len", "au\u00b7gen", "schein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "ADJD", "ADV", "ART", "ADJA", "NN", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Die wangen k\u00f6nten noch ein be\u00dfres lob erlangen/", "tokens": ["Die", "wan\u00b7gen", "k\u00f6n\u00b7ten", "noch", "ein", "be\u00df\u00b7res", "lob", "er\u00b7lan\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "ADV", "ART", "ADJA", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Der rothe nelcken-mund in sch\u00f6nrem purpur prangen/", "tokens": ["Der", "ro\u00b7the", "nel\u00b7cken\u00b7mund", "in", "sch\u00f6n\u00b7rem", "pur\u00b7pur", "pran\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "ADJA", "ADJD", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Die stirn/ da scham und zucht die keusche wohnung h\u00e4lt/", "tokens": ["Die", "stirn", "/", "da", "scham", "und", "zucht", "die", "keu\u00b7sche", "woh\u00b7nung", "h\u00e4lt", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "ADV", "ADJD", "KON", "VVFIN", "ART", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Die ist nicht wei\u00df genug und pr\u00e4chtig vorgestellt/", "tokens": ["Die", "ist", "nicht", "wei\u00df", "ge\u00b7nug", "und", "pr\u00e4ch\u00b7tig", "vor\u00b7ge\u00b7stellt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PTKNEG", "VVFIN", "ADV", "KON", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Den glantz/ vor welchem selbst die Venus mu\u00df erblassen/", "tokens": ["Den", "glantz", "/", "vor", "wel\u00b7chem", "selbst", "die", "Ve\u00b7nus", "mu\u00df", "er\u00b7blas\u00b7sen", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "APPR", "PRELS", "ADV", "ART", "NN", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Den wei\u00df die feder nicht recht schimmrend abzufassen.", "tokens": ["Den", "wei\u00df", "die", "fe\u00b7der", "nicht", "recht", "schimm\u00b7rend", "ab\u00b7zu\u00b7fas\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ART", "NN", "PTKNEG", "ADV", "ADJD", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Ich habe dann gefehlt: und will di\u00df fehlen nennen/", "tokens": ["Ich", "ha\u00b7be", "dann", "ge\u00b7fehlt", ":", "und", "will", "di\u00df", "feh\u00b7len", "nen\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "VVPP", "$.", "KON", "VMFIN", "PDS", "VVINF", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Da\u00df ich nicht sch\u00f6n genug sie hab entwerffen k\u00f6nnen.", "tokens": ["Da\u00df", "ich", "nicht", "sch\u00f6n", "ge\u00b7nug", "sie", "hab", "ent\u00b7werf\u00b7fen", "k\u00f6n\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "ADJD", "ADV", "PPER", "VAFIN", "VVINF", "VMINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}