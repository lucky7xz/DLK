{"textgrid.poem.33819": {"metadata": {"author": {"name": "Lingg, Hermann von", "birth": "N.A.", "death": "N.A."}, "title": "N\u00e4chtlicher Ritt", "genre": "verse", "period": "N.A.", "pub_year": 1862, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ich ritt vom Berg herab nach Hause", "tokens": ["Ich", "ritt", "vom", "Berg", "her\u00b7ab", "nach", "Hau\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "ADV", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sp\u00e4t Nachts, es blitzte dann und wann,", "tokens": ["Sp\u00e4t", "Nachts", ",", "es", "blitz\u00b7te", "dann", "und", "wann", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADV", "$,", "PPER", "VVFIN", "ADV", "KON", "PWAV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ein Sturm mit wachsendem Gesause", "tokens": ["Ein", "Sturm", "mit", "wach\u00b7sen\u00b7dem", "Ge\u00b7sau\u00b7se"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ging durch den hohen dunklen Tann.", "tokens": ["Ging", "durch", "den", "ho\u00b7hen", "dunk\u00b7len", "Tann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "ADJA", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Ich sah nur bei der Blitze Glimmen", "tokens": ["Ich", "sah", "nur", "bei", "der", "Blit\u00b7ze", "Glim\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Den Weg vor meines Pferdes Huf,", "tokens": ["Den", "Weg", "vor", "mei\u00b7nes", "Pfer\u00b7des", "Huf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da h\u00f6rt' ich in dem Donner Stimmen,", "tokens": ["Da", "h\u00f6rt'", "ich", "in", "dem", "Don\u00b7ner", "Stim\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wie wohlbekannter Stimme Ruf.", "tokens": ["Wie", "wohl\u00b7be\u00b7kann\u00b7ter", "Stim\u00b7me", "Ruf", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Bald ward auf meiner Fragen jede", "tokens": ["Bald", "ward", "auf", "mei\u00b7ner", "Fra\u00b7gen", "je\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "APPR", "PPOSAT", "NN", "PIAT"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ein Wort im Donner offenbar,", "tokens": ["Ein", "Wort", "im", "Don\u00b7ner", "of\u00b7fen\u00b7bar", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und ich in k\u00fchner Gegenrede,", "tokens": ["Und", "ich", "in", "k\u00fch\u00b7ner", "Ge\u00b7gen\u00b7re\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ich legte ganz mein Innres dar.", "tokens": ["Ich", "leg\u00b7te", "ganz", "mein", "Inn\u00b7res", "dar", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Wie vielen Streit ich schon gestritten,", "tokens": ["Wie", "vie\u00b7len", "Streit", "ich", "schon", "ge\u00b7strit\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIAT", "NN", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wie viel ich Eitles oft begehrt,", "tokens": ["Wie", "viel", "ich", "Eit\u00b7les", "oft", "be\u00b7gehrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "PPER", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wie viele Not ich schon gelitten,", "tokens": ["Wie", "vie\u00b7le", "Not", "ich", "schon", "ge\u00b7lit\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIAT", "NN", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "An wie viel Gram ich schon gezehrt.", "tokens": ["An", "wie", "viel", "Gram", "ich", "schon", "ge\u00b7zehrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "KOKOM", "PIAT", "NN", "PPER", "ADV", "VVPP", "$."], "meter": "---+-+-+", "measure": "unknown.measure.tri"}}, "stanza.5": {"line.1": {"text": "Auf wie viel Stunden, klagereiche,", "tokens": ["Auf", "wie", "viel", "Stun\u00b7den", ",", "kla\u00b7ge\u00b7rei\u00b7che", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "KOKOM", "PIAT", "NN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ich schauen mu\u00df, und ach, zur\u00fcck", "tokens": ["Ich", "schau\u00b7en", "mu\u00df", ",", "und", "ach", ",", "zu\u00b7r\u00fcck"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word"], "pos": ["PPER", "VVINF", "VMFIN", "$,", "KON", "XY", "$,", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Auf wie viel wilde Torenstreiche", "tokens": ["Auf", "wie", "viel", "wil\u00b7de", "To\u00b7rens\u00b7trei\u00b7che"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "KOKOM", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und auf wie viel verfehltes Gl\u00fcck!", "tokens": ["Und", "auf", "wie", "viel", "ver\u00b7fehl\u00b7tes", "Gl\u00fcck", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKVZ", "KOKOM", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Da rollte mild in mein Erschauern", "tokens": ["Da", "roll\u00b7te", "mild", "in", "mein", "Er\u00b7schau\u00b7ern"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ADJD", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und milder nur des Donners Laut,", "tokens": ["Und", "mil\u00b7der", "nur", "des", "Don\u00b7ners", "Laut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "ADV", "ART", "NN", "APPR", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wie eine Mahnung, auszudauern,", "tokens": ["Wie", "ei\u00b7ne", "Mah\u00b7nung", ",", "aus\u00b7zu\u00b7dau\u00b7ern", ","], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["PWAV", "ART", "NN", "$,", "VVIZU", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und stolzer hab' ich ihm vertraut.", "tokens": ["Und", "stol\u00b7zer", "hab'", "ich", "ihm", "ver\u00b7traut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VAFIN", "PPER", "PPER", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Ich sprach, von keiner Furcht beklommen,", "tokens": ["Ich", "sprach", ",", "von", "kei\u00b7ner", "Furcht", "be\u00b7klom\u00b7men", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "APPR", "PIAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Was ich zu tun auf Erde hier", "tokens": ["Was", "ich", "zu", "tun", "auf", "Er\u00b7de", "hier"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWS", "PPER", "PTKZU", "VVINF", "APPR", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mit aller Kraft mir vorgenommen,", "tokens": ["Mit", "al\u00b7ler", "Kraft", "mir", "vor\u00b7ge\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und m\u00e4chtig klang es \u00fcber mir.", "tokens": ["Und", "m\u00e4ch\u00b7tig", "klang", "es", "\u00fc\u00b7ber", "mir", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "PPER", "APPR", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Mein R\u00f6\u00dflein b\u00e4umte sich und schnaubte,", "tokens": ["Mein", "R\u00f6\u00df\u00b7lein", "b\u00e4um\u00b7te", "sich", "und", "schnaub\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PRF", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ich dachte: war die Stimme die,", "tokens": ["Ich", "dach\u00b7te", ":", "war", "die", "Stim\u00b7me", "die", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "VAFIN", "ART", "NN", "ART", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die auch ein Mann zu h\u00f6ren glaubte", "tokens": ["Die", "auch", "ein", "Mann", "zu", "h\u00f6\u00b7ren", "glaub\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "ART", "NN", "PTKZU", "VVINF", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Im Donner auf dem Sinai?", "tokens": ["Im", "Don\u00b7ner", "auf", "dem", "Si\u00b7nai", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+---", "measure": "unknown.measure.di"}}, "stanza.9": {"line.1": {"text": "Ich ritt vom Berg herab nach Hause", "tokens": ["Ich", "ritt", "vom", "Berg", "her\u00b7ab", "nach", "Hau\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "ADV", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sp\u00e4t Nachts, es blitzte dann und wann,", "tokens": ["Sp\u00e4t", "Nachts", ",", "es", "blitz\u00b7te", "dann", "und", "wann", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADV", "$,", "PPER", "VVFIN", "ADV", "KON", "PWAV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ein Sturm mit wachsendem Gesause", "tokens": ["Ein", "Sturm", "mit", "wach\u00b7sen\u00b7dem", "Ge\u00b7sau\u00b7se"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ging durch den hohen dunklen Tann.", "tokens": ["Ging", "durch", "den", "ho\u00b7hen", "dunk\u00b7len", "Tann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "ADJA", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Ich sah nur bei der Blitze Glimmen", "tokens": ["Ich", "sah", "nur", "bei", "der", "Blit\u00b7ze", "Glim\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Den Weg vor meines Pferdes Huf,", "tokens": ["Den", "Weg", "vor", "mei\u00b7nes", "Pfer\u00b7des", "Huf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da h\u00f6rt' ich in dem Donner Stimmen,", "tokens": ["Da", "h\u00f6rt'", "ich", "in", "dem", "Don\u00b7ner", "Stim\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wie wohlbekannter Stimme Ruf.", "tokens": ["Wie", "wohl\u00b7be\u00b7kann\u00b7ter", "Stim\u00b7me", "Ruf", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Bald ward auf meiner Fragen jede", "tokens": ["Bald", "ward", "auf", "mei\u00b7ner", "Fra\u00b7gen", "je\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "APPR", "PPOSAT", "NN", "PIAT"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ein Wort im Donner offenbar,", "tokens": ["Ein", "Wort", "im", "Don\u00b7ner", "of\u00b7fen\u00b7bar", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und ich in k\u00fchner Gegenrede,", "tokens": ["Und", "ich", "in", "k\u00fch\u00b7ner", "Ge\u00b7gen\u00b7re\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ich legte ganz mein Innres dar.", "tokens": ["Ich", "leg\u00b7te", "ganz", "mein", "Inn\u00b7res", "dar", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Wie vielen Streit ich schon gestritten,", "tokens": ["Wie", "vie\u00b7len", "Streit", "ich", "schon", "ge\u00b7strit\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIAT", "NN", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wie viel ich Eitles oft begehrt,", "tokens": ["Wie", "viel", "ich", "Eit\u00b7les", "oft", "be\u00b7gehrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "PPER", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wie viele Not ich schon gelitten,", "tokens": ["Wie", "vie\u00b7le", "Not", "ich", "schon", "ge\u00b7lit\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIAT", "NN", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "An wie viel Gram ich schon gezehrt.", "tokens": ["An", "wie", "viel", "Gram", "ich", "schon", "ge\u00b7zehrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "KOKOM", "PIAT", "NN", "PPER", "ADV", "VVPP", "$."], "meter": "---+-+-+", "measure": "unknown.measure.tri"}}, "stanza.13": {"line.1": {"text": "Auf wie viel Stunden, klagereiche,", "tokens": ["Auf", "wie", "viel", "Stun\u00b7den", ",", "kla\u00b7ge\u00b7rei\u00b7che", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "KOKOM", "PIAT", "NN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ich schauen mu\u00df, und ach, zur\u00fcck", "tokens": ["Ich", "schau\u00b7en", "mu\u00df", ",", "und", "ach", ",", "zu\u00b7r\u00fcck"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word"], "pos": ["PPER", "VVINF", "VMFIN", "$,", "KON", "XY", "$,", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Auf wie viel wilde Torenstreiche", "tokens": ["Auf", "wie", "viel", "wil\u00b7de", "To\u00b7rens\u00b7trei\u00b7che"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "KOKOM", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und auf wie viel verfehltes Gl\u00fcck!", "tokens": ["Und", "auf", "wie", "viel", "ver\u00b7fehl\u00b7tes", "Gl\u00fcck", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKVZ", "KOKOM", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Da rollte mild in mein Erschauern", "tokens": ["Da", "roll\u00b7te", "mild", "in", "mein", "Er\u00b7schau\u00b7ern"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ADJD", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und milder nur des Donners Laut,", "tokens": ["Und", "mil\u00b7der", "nur", "des", "Don\u00b7ners", "Laut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "ADV", "ART", "NN", "APPR", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wie eine Mahnung, auszudauern,", "tokens": ["Wie", "ei\u00b7ne", "Mah\u00b7nung", ",", "aus\u00b7zu\u00b7dau\u00b7ern", ","], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["PWAV", "ART", "NN", "$,", "VVIZU", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und stolzer hab' ich ihm vertraut.", "tokens": ["Und", "stol\u00b7zer", "hab'", "ich", "ihm", "ver\u00b7traut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VAFIN", "PPER", "PPER", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "Ich sprach, von keiner Furcht beklommen,", "tokens": ["Ich", "sprach", ",", "von", "kei\u00b7ner", "Furcht", "be\u00b7klom\u00b7men", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "APPR", "PIAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Was ich zu tun auf Erde hier", "tokens": ["Was", "ich", "zu", "tun", "auf", "Er\u00b7de", "hier"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWS", "PPER", "PTKZU", "VVINF", "APPR", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mit aller Kraft mir vorgenommen,", "tokens": ["Mit", "al\u00b7ler", "Kraft", "mir", "vor\u00b7ge\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und m\u00e4chtig klang es \u00fcber mir.", "tokens": ["Und", "m\u00e4ch\u00b7tig", "klang", "es", "\u00fc\u00b7ber", "mir", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "PPER", "APPR", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "Mein R\u00f6\u00dflein b\u00e4umte sich und schnaubte,", "tokens": ["Mein", "R\u00f6\u00df\u00b7lein", "b\u00e4um\u00b7te", "sich", "und", "schnaub\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PRF", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ich dachte: war die Stimme die,", "tokens": ["Ich", "dach\u00b7te", ":", "war", "die", "Stim\u00b7me", "die", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "VAFIN", "ART", "NN", "ART", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die auch ein Mann zu h\u00f6ren glaubte", "tokens": ["Die", "auch", "ein", "Mann", "zu", "h\u00f6\u00b7ren", "glaub\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "ART", "NN", "PTKZU", "VVINF", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Im Donner auf dem Sinai?", "tokens": ["Im", "Don\u00b7ner", "auf", "dem", "Si\u00b7nai", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+---", "measure": "unknown.measure.di"}}}}}