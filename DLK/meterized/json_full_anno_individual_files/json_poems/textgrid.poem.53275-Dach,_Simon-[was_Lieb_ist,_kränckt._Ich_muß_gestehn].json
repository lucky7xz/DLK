{"textgrid.poem.53275": {"metadata": {"author": {"name": "Dach, Simon", "birth": "N.A.", "death": "N.A."}, "title": "[was Lieb ist, kr\u00e4nckt. Ich mu\u00df gestehn]", "genre": "verse", "period": "N.A.", "pub_year": 1632, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Was Lieb ist, kr\u00e4nckt. Ich mu\u00df gestehn,", "tokens": ["Was", "Lieb", "ist", ",", "kr\u00e4nckt", ".", "Ich", "mu\u00df", "ge\u00b7stehn", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "VAFIN", "$,", "VVFIN", "$.", "PPER", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Freunde Todes-F\u00e4lle gehn", "tokens": ["Der", "Freun\u00b7de", "To\u00b7des\u00b7F\u00e4l\u00b7le", "gehn"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "NN", "VVINF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Vns allen tieff zu Hertzen:", "tokens": ["Vns", "al\u00b7len", "tieff", "zu", "Hert\u00b7zen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PIAT", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Das Seelen-band, die feste Schnur,", "tokens": ["Das", "See\u00b7len\u00b7band", ",", "die", "fes\u00b7te", "Schnur", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "So Gott gekn\u00fcpfft vnd die Natur,", "tokens": ["So", "Gott", "ge\u00b7kn\u00fcpfft", "vnd", "die", "Na\u00b7tur", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "VVPP", "KON", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Zerreisset nicht ohn Schmertzen.", "tokens": ["Zer\u00b7reis\u00b7set", "nicht", "ohn", "Schmert\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "APPR", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Wer aber bey sich vberlegt", "tokens": ["Wer", "a\u00b7ber", "bey", "sich", "vber\u00b7legt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "ADV", "APPR", "PRF", "VVFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Was Jammer dieses Leben hegt,", "tokens": ["Was", "Jam\u00b7mer", "die\u00b7ses", "Le\u00b7ben", "hegt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "PDAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wird nicht so \u00e4ngstig weinen,", "tokens": ["Wird", "nicht", "so", "\u00e4ngs\u00b7tig", "wei\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PTKNEG", "ADV", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Wird w\u00fcndschen, da\u00df auch er der Noht", "tokens": ["Wird", "w\u00fcnd\u00b7schen", ",", "da\u00df", "auch", "er", "der", "Noht"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "VVINF", "$,", "KOUS", "ADV", "PPER", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Befreyt durch einen s\u00fcssen Todt", "tokens": ["Be\u00b7freyt", "durch", "ei\u00b7nen", "s\u00fcs\u00b7sen", "Todt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Nur schlieffe bey den Seinen.", "tokens": ["Nur", "schlief\u00b7fe", "bey", "den", "Sei\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "ART", "PPOSS", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Was leiden wir nicht f\u00fcr Gefahr,", "tokens": ["Was", "lei\u00b7den", "wir", "nicht", "f\u00fcr", "Ge\u00b7fahr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "PTKNEG", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Eh' als man auff die Todten-Bahr", "tokens": ["Eh'", "als", "man", "auff", "die", "Tod\u00b7ten\u00b7Bahr"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "KOUS", "PIS", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mit vnserm Leichnam eilet?", "tokens": ["Mit", "vn\u00b7serm", "Leich\u00b7nam", "ei\u00b7let", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Wenn drengt vns nicht das leichte Gl\u00fcck,", "tokens": ["Wenn", "drengt", "vns", "nicht", "das", "leich\u00b7te", "Gl\u00fcck", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VVFIN", "PPER", "PTKNEG", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Das jedem sein genantes St\u00fcck", "tokens": ["Das", "je\u00b7dem", "sein", "ge\u00b7nan\u00b7tes", "St\u00fcck"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "PIAT", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Des Vngemachs ertheilet?", "tokens": ["Des", "Vn\u00b7ge\u00b7machs", "er\u00b7thei\u00b7let", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Ich sag' hie nichts von Fleisch vnd Blut,", "tokens": ["Ich", "sag'", "hie", "nichts", "von", "Fleisch", "vnd", "Blut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PIS", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df doch vns grossen schaden thut,", "tokens": ["Da\u00df", "doch", "vns", "gros\u00b7sen", "scha\u00b7den", "thut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PPER", "ADJA", "ADJA", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wir wallen in der W\u00fcsten,", "tokens": ["Wir", "wal\u00b7len", "in", "der", "W\u00fcs\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Wo Sathanas sich hat versteckt,", "tokens": ["Wo", "Sa\u00b7tha\u00b7nas", "sich", "hat", "ver\u00b7steckt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NE", "PRF", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Vnd vns mit seiner Macht erschreckt,", "tokens": ["Vnd", "vns", "mit", "sei\u00b7ner", "Macht", "er\u00b7schreckt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wo Mord vnd Grawen nisten.", "tokens": ["Wo", "Mord", "vnd", "Gra\u00b7wen", "nis\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Wie manchen hat er doch gef\u00e4llt", "tokens": ["Wie", "man\u00b7chen", "hat", "er", "doch", "ge\u00b7f\u00e4llt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PIS", "VAFIN", "PPER", "ADV", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Durch seine Netze, die er stellt?", "tokens": ["Durch", "sei\u00b7ne", "Net\u00b7ze", ",", "die", "er", "stellt", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "PRELS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Er liegt in seiner H\u00f6len,", "tokens": ["Er", "liegt", "in", "sei\u00b7ner", "H\u00f6\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Hat Finsternus vmb sich gethan,", "tokens": ["Hat", "Fins\u00b7ter\u00b7nus", "vmb", "sich", "ge\u00b7than", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NE", "APPR", "PRF", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Verwachet listig alle Bahn", "tokens": ["Ver\u00b7wa\u00b7chet", "lis\u00b7tig", "al\u00b7le", "Bahn"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "ADJD", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Vnd steht nach vnsrer Seelen.", "tokens": ["Vnd", "steht", "nach", "vns\u00b7rer", "See\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Dem jagt er nach durch Trunckenheit,", "tokens": ["Dem", "jagt", "er", "nach", "durch", "Trun\u00b7cken\u00b7heit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "APPR", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Durch Vnzucht dem, vnd dem durch Neid,", "tokens": ["Durch", "Vn\u00b7zucht", "dem", ",", "vnd", "dem", "durch", "Neid", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ART", "$,", "KON", "ART", "APPR", "NN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "Den mu\u00df der Zorn besiegen:", "tokens": ["Den", "mu\u00df", "der", "Zorn", "be\u00b7sie\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VMFIN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Durch Hochmuht k\u00f6mpt er diesem bey", "tokens": ["Durch", "Hoch\u00b7muht", "k\u00f6mpt", "er", "die\u00b7sem", "bey"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "VVFIN", "PPER", "PDAT", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Vnd diesem wo durch Heucheley,", "tokens": ["Vnd", "die\u00b7sem", "wo", "durch", "Heu\u00b7che\u00b7ley", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDAT", "PWAV", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Durch Geitz mu\u00df der erliegen.", "tokens": ["Durch", "Geitz", "mu\u00df", "der", "er\u00b7lie\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VMFIN", "ART", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Nachdem wir also sind ber\u00fcckt,", "tokens": ["Nach\u00b7dem", "wir", "al\u00b7so", "sind", "be\u00b7r\u00fcckt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wie sonst ein Vogel sich verstrickt,", "tokens": ["Wie", "sonst", "ein", "Vo\u00b7gel", "sich", "ver\u00b7strickt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "ART", "NN", "PRF", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Gehn irr' in seinen Banden,", "tokens": ["Gehn", "irr'", "in", "sei\u00b7nen", "Ban\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Erkennen vnser Elend nicht,", "tokens": ["Er\u00b7ken\u00b7nen", "vn\u00b7ser", "E\u00b7lend", "nicht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Sind frembde von des Glaubens Liecht,", "tokens": ["Sind", "fremb\u00b7de", "von", "des", "Glau\u00b7bens", "Liecht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJA", "APPR", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "So ist der Todt verhanden.", "tokens": ["So", "ist", "der", "Todt", "ver\u00b7han\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Wie eine Spinne sich verbirgt", "tokens": ["Wie", "ei\u00b7ne", "Spin\u00b7ne", "sich", "ver\u00b7birgt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "ART", "NN", "PRF", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Vnd vnvorsehens alles w\u00fcrgt", "tokens": ["Vnd", "vn\u00b7vor\u00b7se\u00b7hens", "al\u00b7les", "w\u00fcrgt"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ADV", "PIS", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Was jhr Gewehb' erhaschet,", "tokens": ["Was", "jhr", "Ge\u00b7wehb'", "er\u00b7ha\u00b7schet", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "So heist der Todt es auch geschehn;", "tokens": ["So", "heist", "der", "Todt", "es", "auch", "ge\u00b7schehn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Eh als man sein sich kan versehn,", "tokens": ["Eh", "als", "man", "sein", "sich", "kan", "ver\u00b7sehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KOUS", "PIS", "PPOSAT", "PRF", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Hat er vns vberraschet.", "tokens": ["Hat", "er", "vns", "vber\u00b7ra\u00b7schet", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PPER", "VVFIN", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}}, "stanza.9": {"line.1": {"text": "Ach wer getrawt jhm alle Pein,", "tokens": ["Ach", "wer", "ge\u00b7trawt", "jhm", "al\u00b7le", "Pein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "PWS", "VVFIN", "PPER", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mit der wir stets zu Felde seyn,", "tokens": ["Mit", "der", "wir", "stets", "zu", "Fel\u00b7de", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "ADV", "APPR", "NN", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Nur k\u00fcrtzlich anzuf\u00fchren?", "tokens": ["Nur", "k\u00fcrtz\u00b7lich", "an\u00b7zu\u00b7f\u00fch\u00b7ren", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVIZU", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Wir bawen hie ein Jammer-Hau\u00df,", "tokens": ["Wir", "ba\u00b7wen", "hie", "ein", "Jam\u00b7mer\u00b7Hau\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Vnd m\u00fcssen s\u00e4mptlich au\u00df vnd au\u00df", "tokens": ["Vnd", "m\u00fcs\u00b7sen", "s\u00e4mpt\u00b7lich", "au\u00df", "vnd", "au\u00df"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VMFIN", "ADJD", "PTKVZ", "KON", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Mit M\u00fch vnd Noht es zieren.", "tokens": ["Mit", "M\u00fch", "vnd", "Noht", "es", "zie\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "Der giebt dazu der Sorgen Last,", "tokens": ["Der", "giebt", "da\u00b7zu", "der", "Sor\u00b7gen", "Last", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PAV", "ART", "NN", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Vnd der hat Furcht, der Hohn gefasst,", "tokens": ["Vnd", "der", "hat", "Furcht", ",", "der", "Hohn", "ge\u00b7fasst", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VAFIN", "NN", "$,", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der mu\u00df verfolgung tragen,", "tokens": ["Der", "mu\u00df", "ver\u00b7fol\u00b7gung", "tra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "NN", "VVINF", "$,"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.4": {"text": "Der k\u00f6mpt mit Armuht, der mit Qual,", "tokens": ["Der", "k\u00f6mpt", "mit", "Ar\u00b7muht", ",", "der", "mit", "Qual", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPR", "NN", "$,", "PRELS", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Der bringt der Kranckheit grosse Zahl,", "tokens": ["Der", "bringt", "der", "Kran\u00b7ck\u00b7heit", "gros\u00b7se", "Zahl", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Ein andrer andre Plagen.", "tokens": ["Ein", "an\u00b7drer", "and\u00b7re", "Pla\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "Wer aber sich davon gemacht", "tokens": ["Wer", "a\u00b7ber", "sich", "da\u00b7von", "ge\u00b7macht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "ADV", "PRF", "PAV", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Vnd seelig seinen Lauff vollbracht,", "tokens": ["Vnd", "see\u00b7lig", "sei\u00b7nen", "Lauff", "voll\u00b7bracht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Geht einmal recht zu Bette,", "tokens": ["Geht", "ein\u00b7mal", "recht", "zu", "Bet\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADJD", "APPR", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Deckt sich mit frischer Erde zu,", "tokens": ["Deckt", "sich", "mit", "fri\u00b7scher", "Er\u00b7de", "zu", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "APPR", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Vnd rastet da in stoltzer Rhue", "tokens": ["Vnd", "ras\u00b7tet", "da", "in", "stolt\u00b7zer", "Rhue"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Mit andern vmb die Wette.", "tokens": ["Mit", "an\u00b7dern", "vmb", "die", "Wet\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "Er dencket an die Welt nicht mehr,", "tokens": ["Er", "den\u00b7cket", "an", "die", "Welt", "nicht", "mehr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "PTKNEG", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "G\u00f6nnt weder Augen noch Geh\u00f6r", "tokens": ["G\u00f6nnt", "we\u00b7der", "Au\u00b7gen", "noch", "Ge\u00b7h\u00f6r"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "KON", "NN", "ADV", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Des Lebens eiteln Dingen:", "tokens": ["Des", "Le\u00b7bens", "ei\u00b7teln", "Din\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Schl\u00e4fft vngeweckt, vnd solte gleich", "tokens": ["Schl\u00e4fft", "vn\u00b7ge\u00b7weckt", ",", "vnd", "sol\u00b7te", "gleich"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["NN", "ADJD", "$,", "KON", "VMFIN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Durch Mord vnd Brandt der Erden Reich", "tokens": ["Durch", "Mord", "vnd", "Brandt", "der", "Er\u00b7den", "Reich"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "In St\u00fccke gantz zerspringen.", "tokens": ["In", "St\u00fc\u00b7cke", "gantz", "zer\u00b7sprin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.13": {"line.1": {"text": "Ein Tausendt Jahr vnd noch so viel", "tokens": ["Ein", "Tau\u00b7sendt", "Jahr", "vnd", "noch", "so", "viel"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "CARD", "NN", "KON", "ADV", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ist jhm kaum einer Stunden Ziel,", "tokens": ["Ist", "jhm", "kaum", "ei\u00b7ner", "Stun\u00b7den", "Ziel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Bi\u00df nun die Welt wird fallen,", "tokens": ["Bi\u00df", "nun", "die", "Welt", "wird", "fal\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "ART", "NN", "VAFIN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Gott ank\u00f6mpt mit dem Tagelohn,", "tokens": ["Gott", "an\u00b7k\u00f6mpt", "mit", "dem", "Ta\u00b7ge\u00b7lohn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Vnd der Posaunen heller Thon", "tokens": ["Vnd", "der", "Po\u00b7sau\u00b7nen", "hel\u00b7ler", "Thon"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Auch Gr\u00e4ber-durch wird schallen.", "tokens": ["Auch", "Gr\u00e4\u00b7ber\u00b7durch", "wird", "schal\u00b7len", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "VAFIN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.14": {"line.1": {"text": "Sein Geist lebt da, wo Abraham", "tokens": ["Sein", "Geist", "lebt", "da", ",", "wo", "Ab\u00b7ra\u00b7ham"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["PPOSAT", "NN", "VVFIN", "ADV", "$,", "PWAV", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ist stets zu finden vmb das Lamm,", "tokens": ["Ist", "stets", "zu", "fin\u00b7den", "vmb", "das", "Lamm", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PTKZU", "VVINF", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "H\u00f6rt zu den Musicanten:", "tokens": ["H\u00f6rt", "zu", "den", "Mu\u00b7si\u00b7can\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "$."], "meter": "---+-+-", "measure": "unknown.measure.di"}, "line.4": {"text": "Lacht aller Lust in dieser Welt,", "tokens": ["Lacht", "al\u00b7ler", "Lust", "in", "die\u00b7ser", "Welt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PIAT", "NN", "APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Forscht vmb das sch\u00f6ne Himmelsfeld", "tokens": ["Forscht", "vmb", "das", "sch\u00f6\u00b7ne", "Him\u00b7mels\u00b7feld"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Nach seinen Anverwandten.", "tokens": ["Nach", "sei\u00b7nen", "An\u00b7ver\u00b7wand\u00b7ten", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.15": {"line.1": {"text": "Wer nichts nach diesem allen fragt,", "tokens": ["Wer", "nichts", "nach", "die\u00b7sem", "al\u00b7len", "fragt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PIS", "APPR", "PDAT", "PIAT", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Seinen vngetr\u00f6stet klagt,", "tokens": ["Die", "Sei\u00b7nen", "vn\u00b7ge\u00b7tr\u00f6s\u00b7tet", "klagt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSS", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ist in der Welt ersoffen:", "tokens": ["Ist", "in", "der", "Welt", "er\u00b7sof\u00b7fen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Ist Glaubens-lo\u00df, bekennet frey,", "tokens": ["Ist", "Glau\u00b7bens\u00b7lo\u00df", ",", "be\u00b7ken\u00b7net", "frey", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "NN", "$,", "VVFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Nach diesem schn\u00f6den Leben sey", "tokens": ["Nach", "die\u00b7sem", "schn\u00f6\u00b7den", "Le\u00b7ben", "sey"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PDAT", "ADJA", "NN", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Kein Himmel mehr zu hoffen.", "tokens": ["Kein", "Him\u00b7mel", "mehr", "zu", "hof\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.16": {"line.1": {"text": "Gott, der du auffgenommen bist,", "tokens": ["Gott", ",", "der", "du", "auff\u00b7ge\u00b7nom\u00b7men", "bist", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PRELS", "PPER", "VVPP", "VAFIN", "$,"], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.2": {"text": "Wo vnser rechtes Erbtheil ist,", "tokens": ["Wo", "vn\u00b7ser", "rech\u00b7tes", "E\u00b7rbtheil", "ist", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "ADJA", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "La\u00df keiner M\u00fch vns sparen", "tokens": ["La\u00df", "kei\u00b7ner", "M\u00fch", "vns", "spa\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVIMP", "PIAT", "NN", "PPER", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Recht zu erwegen diese Zeit,", "tokens": ["Recht", "zu", "er\u00b7we\u00b7gen", "die\u00b7se", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKZU", "VVFIN", "PDAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Vnd durch so vieles Hertzeleid", "tokens": ["Vnd", "durch", "so", "vie\u00b7les", "Hert\u00b7ze\u00b7leid"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ADV", "PIS", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Nur bald dir nachzufahren.", "tokens": ["Nur", "bald", "dir", "nach\u00b7zu\u00b7fah\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "VVIZU", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.17": {"line.1": {"text": "Was Lieb ist, kr\u00e4nckt. Ich mu\u00df gestehn,", "tokens": ["Was", "Lieb", "ist", ",", "kr\u00e4nckt", ".", "Ich", "mu\u00df", "ge\u00b7stehn", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "VAFIN", "$,", "VVFIN", "$.", "PPER", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Freunde Todes-F\u00e4lle gehn", "tokens": ["Der", "Freun\u00b7de", "To\u00b7des\u00b7F\u00e4l\u00b7le", "gehn"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "NN", "VVINF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Vns allen tieff zu Hertzen:", "tokens": ["Vns", "al\u00b7len", "tieff", "zu", "Hert\u00b7zen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PIAT", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Das Seelen-band, die feste Schnur,", "tokens": ["Das", "See\u00b7len\u00b7band", ",", "die", "fes\u00b7te", "Schnur", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "So Gott gekn\u00fcpfft vnd die Natur,", "tokens": ["So", "Gott", "ge\u00b7kn\u00fcpfft", "vnd", "die", "Na\u00b7tur", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "VVPP", "KON", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Zerreisset nicht ohn Schmertzen.", "tokens": ["Zer\u00b7reis\u00b7set", "nicht", "ohn", "Schmert\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "APPR", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.18": {"line.1": {"text": "Wer aber bey sich vberlegt", "tokens": ["Wer", "a\u00b7ber", "bey", "sich", "vber\u00b7legt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "ADV", "APPR", "PRF", "VVFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Was Jammer dieses Leben hegt,", "tokens": ["Was", "Jam\u00b7mer", "die\u00b7ses", "Le\u00b7ben", "hegt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "PDAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wird nicht so \u00e4ngstig weinen,", "tokens": ["Wird", "nicht", "so", "\u00e4ngs\u00b7tig", "wei\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PTKNEG", "ADV", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Wird w\u00fcndschen, da\u00df auch er der Noht", "tokens": ["Wird", "w\u00fcnd\u00b7schen", ",", "da\u00df", "auch", "er", "der", "Noht"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "VVINF", "$,", "KOUS", "ADV", "PPER", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Befreyt durch einen s\u00fcssen Todt", "tokens": ["Be\u00b7freyt", "durch", "ei\u00b7nen", "s\u00fcs\u00b7sen", "Todt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Nur schlieffe bey den Seinen.", "tokens": ["Nur", "schlief\u00b7fe", "bey", "den", "Sei\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "ART", "PPOSS", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.19": {"line.1": {"text": "Was leiden wir nicht f\u00fcr Gefahr,", "tokens": ["Was", "lei\u00b7den", "wir", "nicht", "f\u00fcr", "Ge\u00b7fahr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "PTKNEG", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Eh' als man auff die Todten-Bahr", "tokens": ["Eh'", "als", "man", "auff", "die", "Tod\u00b7ten\u00b7Bahr"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "KOUS", "PIS", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mit vnserm Leichnam eilet?", "tokens": ["Mit", "vn\u00b7serm", "Leich\u00b7nam", "ei\u00b7let", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Wenn drengt vns nicht das leichte Gl\u00fcck,", "tokens": ["Wenn", "drengt", "vns", "nicht", "das", "leich\u00b7te", "Gl\u00fcck", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VVFIN", "PPER", "PTKNEG", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Das jedem sein genantes St\u00fcck", "tokens": ["Das", "je\u00b7dem", "sein", "ge\u00b7nan\u00b7tes", "St\u00fcck"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "PIAT", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Des Vngemachs ertheilet?", "tokens": ["Des", "Vn\u00b7ge\u00b7machs", "er\u00b7thei\u00b7let", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.20": {"line.1": {"text": "Ich sag' hie nichts von Fleisch vnd Blut,", "tokens": ["Ich", "sag'", "hie", "nichts", "von", "Fleisch", "vnd", "Blut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PIS", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df doch vns grossen schaden thut,", "tokens": ["Da\u00df", "doch", "vns", "gros\u00b7sen", "scha\u00b7den", "thut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PPER", "ADJA", "ADJA", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wir wallen in der W\u00fcsten,", "tokens": ["Wir", "wal\u00b7len", "in", "der", "W\u00fcs\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Wo Sathanas sich hat versteckt,", "tokens": ["Wo", "Sa\u00b7tha\u00b7nas", "sich", "hat", "ver\u00b7steckt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NE", "PRF", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Vnd vns mit seiner Macht erschreckt,", "tokens": ["Vnd", "vns", "mit", "sei\u00b7ner", "Macht", "er\u00b7schreckt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wo Mord vnd Grawen nisten.", "tokens": ["Wo", "Mord", "vnd", "Gra\u00b7wen", "nis\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.21": {"line.1": {"text": "Wie manchen hat er doch gef\u00e4llt", "tokens": ["Wie", "man\u00b7chen", "hat", "er", "doch", "ge\u00b7f\u00e4llt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PIS", "VAFIN", "PPER", "ADV", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Durch seine Netze, die er stellt?", "tokens": ["Durch", "sei\u00b7ne", "Net\u00b7ze", ",", "die", "er", "stellt", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "PRELS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Er liegt in seiner H\u00f6len,", "tokens": ["Er", "liegt", "in", "sei\u00b7ner", "H\u00f6\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Hat Finsternus vmb sich gethan,", "tokens": ["Hat", "Fins\u00b7ter\u00b7nus", "vmb", "sich", "ge\u00b7than", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NE", "APPR", "PRF", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Verwachet listig alle Bahn", "tokens": ["Ver\u00b7wa\u00b7chet", "lis\u00b7tig", "al\u00b7le", "Bahn"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "ADJD", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Vnd steht nach vnsrer Seelen.", "tokens": ["Vnd", "steht", "nach", "vns\u00b7rer", "See\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.22": {"line.1": {"text": "Dem jagt er nach durch Trunckenheit,", "tokens": ["Dem", "jagt", "er", "nach", "durch", "Trun\u00b7cken\u00b7heit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "APPR", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Durch Vnzucht dem, vnd dem durch Neid,", "tokens": ["Durch", "Vn\u00b7zucht", "dem", ",", "vnd", "dem", "durch", "Neid", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ART", "$,", "KON", "ART", "APPR", "NN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "Den mu\u00df der Zorn besiegen:", "tokens": ["Den", "mu\u00df", "der", "Zorn", "be\u00b7sie\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VMFIN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Durch Hochmuht k\u00f6mpt er diesem bey", "tokens": ["Durch", "Hoch\u00b7muht", "k\u00f6mpt", "er", "die\u00b7sem", "bey"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "VVFIN", "PPER", "PDAT", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Vnd diesem wo durch Heucheley,", "tokens": ["Vnd", "die\u00b7sem", "wo", "durch", "Heu\u00b7che\u00b7ley", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDAT", "PWAV", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Durch Geitz mu\u00df der erliegen.", "tokens": ["Durch", "Geitz", "mu\u00df", "der", "er\u00b7lie\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VMFIN", "ART", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.23": {"line.1": {"text": "Nachdem wir also sind ber\u00fcckt,", "tokens": ["Nach\u00b7dem", "wir", "al\u00b7so", "sind", "be\u00b7r\u00fcckt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wie sonst ein Vogel sich verstrickt,", "tokens": ["Wie", "sonst", "ein", "Vo\u00b7gel", "sich", "ver\u00b7strickt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "ART", "NN", "PRF", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Gehn irr' in seinen Banden,", "tokens": ["Gehn", "irr'", "in", "sei\u00b7nen", "Ban\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Erkennen vnser Elend nicht,", "tokens": ["Er\u00b7ken\u00b7nen", "vn\u00b7ser", "E\u00b7lend", "nicht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Sind frembde von des Glaubens Liecht,", "tokens": ["Sind", "fremb\u00b7de", "von", "des", "Glau\u00b7bens", "Liecht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJA", "APPR", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "So ist der Todt verhanden.", "tokens": ["So", "ist", "der", "Todt", "ver\u00b7han\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.24": {"line.1": {"text": "Wie eine Spinne sich verbirgt", "tokens": ["Wie", "ei\u00b7ne", "Spin\u00b7ne", "sich", "ver\u00b7birgt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "ART", "NN", "PRF", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Vnd vnvorsehens alles w\u00fcrgt", "tokens": ["Vnd", "vn\u00b7vor\u00b7se\u00b7hens", "al\u00b7les", "w\u00fcrgt"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ADV", "PIS", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Was jhr Gewehb' erhaschet,", "tokens": ["Was", "jhr", "Ge\u00b7wehb'", "er\u00b7ha\u00b7schet", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "So heist der Todt es auch geschehn;", "tokens": ["So", "heist", "der", "Todt", "es", "auch", "ge\u00b7schehn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Eh als man sein sich kan versehn,", "tokens": ["Eh", "als", "man", "sein", "sich", "kan", "ver\u00b7sehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KOUS", "PIS", "PPOSAT", "PRF", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Hat er vns vberraschet.", "tokens": ["Hat", "er", "vns", "vber\u00b7ra\u00b7schet", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PPER", "VVFIN", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}}, "stanza.25": {"line.1": {"text": "Ach wer getrawt jhm alle Pein,", "tokens": ["Ach", "wer", "ge\u00b7trawt", "jhm", "al\u00b7le", "Pein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "PWS", "VVFIN", "PPER", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mit der wir stets zu Felde seyn,", "tokens": ["Mit", "der", "wir", "stets", "zu", "Fel\u00b7de", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "ADV", "APPR", "NN", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Nur k\u00fcrtzlich anzuf\u00fchren?", "tokens": ["Nur", "k\u00fcrtz\u00b7lich", "an\u00b7zu\u00b7f\u00fch\u00b7ren", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVIZU", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Wir bawen hie ein Jammer-Hau\u00df,", "tokens": ["Wir", "ba\u00b7wen", "hie", "ein", "Jam\u00b7mer\u00b7Hau\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Vnd m\u00fcssen s\u00e4mptlich au\u00df vnd au\u00df", "tokens": ["Vnd", "m\u00fcs\u00b7sen", "s\u00e4mpt\u00b7lich", "au\u00df", "vnd", "au\u00df"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VMFIN", "ADJD", "PTKVZ", "KON", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Mit M\u00fch vnd Noht es zieren.", "tokens": ["Mit", "M\u00fch", "vnd", "Noht", "es", "zie\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.26": {"line.1": {"text": "Der giebt dazu der Sorgen Last,", "tokens": ["Der", "giebt", "da\u00b7zu", "der", "Sor\u00b7gen", "Last", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PAV", "ART", "NN", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Vnd der hat Furcht, der Hohn gefasst,", "tokens": ["Vnd", "der", "hat", "Furcht", ",", "der", "Hohn", "ge\u00b7fasst", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VAFIN", "NN", "$,", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der mu\u00df verfolgung tragen,", "tokens": ["Der", "mu\u00df", "ver\u00b7fol\u00b7gung", "tra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "NN", "VVINF", "$,"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.4": {"text": "Der k\u00f6mpt mit Armuht, der mit Qual,", "tokens": ["Der", "k\u00f6mpt", "mit", "Ar\u00b7muht", ",", "der", "mit", "Qual", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPR", "NN", "$,", "PRELS", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Der bringt der Kranckheit grosse Zahl,", "tokens": ["Der", "bringt", "der", "Kran\u00b7ck\u00b7heit", "gros\u00b7se", "Zahl", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Ein andrer andre Plagen.", "tokens": ["Ein", "an\u00b7drer", "and\u00b7re", "Pla\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.27": {"line.1": {"text": "Wer aber sich davon gemacht", "tokens": ["Wer", "a\u00b7ber", "sich", "da\u00b7von", "ge\u00b7macht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "ADV", "PRF", "PAV", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Vnd seelig seinen Lauff vollbracht,", "tokens": ["Vnd", "see\u00b7lig", "sei\u00b7nen", "Lauff", "voll\u00b7bracht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Geht einmal recht zu Bette,", "tokens": ["Geht", "ein\u00b7mal", "recht", "zu", "Bet\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADJD", "APPR", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Deckt sich mit frischer Erde zu,", "tokens": ["Deckt", "sich", "mit", "fri\u00b7scher", "Er\u00b7de", "zu", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "APPR", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Vnd rastet da in stoltzer Rhue", "tokens": ["Vnd", "ras\u00b7tet", "da", "in", "stolt\u00b7zer", "Rhue"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Mit andern vmb die Wette.", "tokens": ["Mit", "an\u00b7dern", "vmb", "die", "Wet\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.28": {"line.1": {"text": "Er dencket an die Welt nicht mehr,", "tokens": ["Er", "den\u00b7cket", "an", "die", "Welt", "nicht", "mehr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "PTKNEG", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "G\u00f6nnt weder Augen noch Geh\u00f6r", "tokens": ["G\u00f6nnt", "we\u00b7der", "Au\u00b7gen", "noch", "Ge\u00b7h\u00f6r"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "KON", "NN", "ADV", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Des Lebens eiteln Dingen:", "tokens": ["Des", "Le\u00b7bens", "ei\u00b7teln", "Din\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Schl\u00e4fft vngeweckt, vnd solte gleich", "tokens": ["Schl\u00e4fft", "vn\u00b7ge\u00b7weckt", ",", "vnd", "sol\u00b7te", "gleich"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["NN", "ADJD", "$,", "KON", "VMFIN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Durch Mord vnd Brandt der Erden Reich", "tokens": ["Durch", "Mord", "vnd", "Brandt", "der", "Er\u00b7den", "Reich"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "In St\u00fccke gantz zerspringen.", "tokens": ["In", "St\u00fc\u00b7cke", "gantz", "zer\u00b7sprin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.29": {"line.1": {"text": "Ein Tausendt Jahr vnd noch so viel", "tokens": ["Ein", "Tau\u00b7sendt", "Jahr", "vnd", "noch", "so", "viel"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "CARD", "NN", "KON", "ADV", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ist jhm kaum einer Stunden Ziel,", "tokens": ["Ist", "jhm", "kaum", "ei\u00b7ner", "Stun\u00b7den", "Ziel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Bi\u00df nun die Welt wird fallen,", "tokens": ["Bi\u00df", "nun", "die", "Welt", "wird", "fal\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "ART", "NN", "VAFIN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Gott ank\u00f6mpt mit dem Tagelohn,", "tokens": ["Gott", "an\u00b7k\u00f6mpt", "mit", "dem", "Ta\u00b7ge\u00b7lohn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Vnd der Posaunen heller Thon", "tokens": ["Vnd", "der", "Po\u00b7sau\u00b7nen", "hel\u00b7ler", "Thon"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Auch Gr\u00e4ber-durch wird schallen.", "tokens": ["Auch", "Gr\u00e4\u00b7ber\u00b7durch", "wird", "schal\u00b7len", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "VAFIN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.30": {"line.1": {"text": "Sein Geist lebt da, wo Abraham", "tokens": ["Sein", "Geist", "lebt", "da", ",", "wo", "Ab\u00b7ra\u00b7ham"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["PPOSAT", "NN", "VVFIN", "ADV", "$,", "PWAV", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ist stets zu finden vmb das Lamm,", "tokens": ["Ist", "stets", "zu", "fin\u00b7den", "vmb", "das", "Lamm", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PTKZU", "VVINF", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "H\u00f6rt zu den Musicanten:", "tokens": ["H\u00f6rt", "zu", "den", "Mu\u00b7si\u00b7can\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "$."], "meter": "---+-+-", "measure": "unknown.measure.di"}, "line.4": {"text": "Lacht aller Lust in dieser Welt,", "tokens": ["Lacht", "al\u00b7ler", "Lust", "in", "die\u00b7ser", "Welt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PIAT", "NN", "APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Forscht vmb das sch\u00f6ne Himmelsfeld", "tokens": ["Forscht", "vmb", "das", "sch\u00f6\u00b7ne", "Him\u00b7mels\u00b7feld"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Nach seinen Anverwandten.", "tokens": ["Nach", "sei\u00b7nen", "An\u00b7ver\u00b7wand\u00b7ten", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.31": {"line.1": {"text": "Wer nichts nach diesem allen fragt,", "tokens": ["Wer", "nichts", "nach", "die\u00b7sem", "al\u00b7len", "fragt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PIS", "APPR", "PDAT", "PIAT", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Seinen vngetr\u00f6stet klagt,", "tokens": ["Die", "Sei\u00b7nen", "vn\u00b7ge\u00b7tr\u00f6s\u00b7tet", "klagt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSS", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ist in der Welt ersoffen:", "tokens": ["Ist", "in", "der", "Welt", "er\u00b7sof\u00b7fen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Ist Glaubens-lo\u00df, bekennet frey,", "tokens": ["Ist", "Glau\u00b7bens\u00b7lo\u00df", ",", "be\u00b7ken\u00b7net", "frey", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "NN", "$,", "VVFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Nach diesem schn\u00f6den Leben sey", "tokens": ["Nach", "die\u00b7sem", "schn\u00f6\u00b7den", "Le\u00b7ben", "sey"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PDAT", "ADJA", "NN", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Kein Himmel mehr zu hoffen.", "tokens": ["Kein", "Him\u00b7mel", "mehr", "zu", "hof\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.32": {"line.1": {"text": "Gott, der du auffgenommen bist,", "tokens": ["Gott", ",", "der", "du", "auff\u00b7ge\u00b7nom\u00b7men", "bist", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PRELS", "PPER", "VVPP", "VAFIN", "$,"], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.2": {"text": "Wo vnser rechtes Erbtheil ist,", "tokens": ["Wo", "vn\u00b7ser", "rech\u00b7tes", "E\u00b7rbtheil", "ist", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "ADJA", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "La\u00df keiner M\u00fch vns sparen", "tokens": ["La\u00df", "kei\u00b7ner", "M\u00fch", "vns", "spa\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVIMP", "PIAT", "NN", "PPER", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Recht zu erwegen diese Zeit,", "tokens": ["Recht", "zu", "er\u00b7we\u00b7gen", "die\u00b7se", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKZU", "VVFIN", "PDAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Vnd durch so vieles Hertzeleid", "tokens": ["Vnd", "durch", "so", "vie\u00b7les", "Hert\u00b7ze\u00b7leid"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ADV", "PIS", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Nur bald dir nachzufahren.", "tokens": ["Nur", "bald", "dir", "nach\u00b7zu\u00b7fah\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "VVIZU", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}}}}