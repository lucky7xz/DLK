{"dta.poem.21771": {"metadata": {"author": {"name": "Stieler, Kaspar von", "birth": "N.A.", "death": "N.A."}, "title": "1.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1660", "urn": "urn:nbn:de:kobv:b4-20586-2", "language": ["de:0.99"], "booktitle": "Filidor der Dorfferer [i. e. Stieler, Kaspar von]: Die Geharnschte Venus. Hamburg, 1660."}, "poem": {"stanza.1": {"line.1": {"text": "Da\u00df ich auff deinen Ladungs-Brieff/", "tokens": ["Da\u00df", "ich", "auff", "dei\u00b7nen", "La\u00b7dungs\u00b7Brieff", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "mein Damon/ nicht bin zu dir kom\u0303en/", "tokens": ["mein", "Da\u00b7mon", "/", "nicht", "bin", "zu", "dir", "kom\u0303en", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$(", "PTKNEG", "VAFIN", "APPR", "PPER", "VVINF", "$("], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "das schmerzet dich/ wie ich vernommen:", "tokens": ["das", "schmer\u00b7zet", "dich", "/", "wie", "ich", "ver\u00b7nom\u00b7men", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "$(", "PWAV", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "als wen\u0303 bey unsrer Freundschaft Gr\u00fcnden", "tokens": ["als", "we\u00f1", "bey", "uns\u00b7rer", "Freund\u00b7schaft", "Gr\u00fcn\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "APPR", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "und Falschheit womit unter lieff\u2019.", "tokens": ["und", "Falschheit", "wo\u00b7mit", "un\u00b7ter", "lief\u00b7f'", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "PWAV", "APPR", "NE", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.2": {"line.1": {"text": "Ach! Damon/ la\u00df den Argwohn sein.", "tokens": ["Ach", "!", "Da\u00b7mon", "/", "la\u00df", "den", "Arg\u00b7wohn", "sein", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$.", "NE", "$(", "VVIMP", "ART", "NN", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Kein Wechsel hat dich je verdrungen.", "tokens": ["Kein", "Wech\u00b7sel", "hat", "dich", "je", "ver\u00b7drun\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "die Rosilis h\u00e4lt mich gezwungen", "tokens": ["die", "Ro\u00b7si\u00b7lis", "h\u00e4lt", "mich", "ge\u00b7zwun\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NE", "VVFIN", "PPER", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Sie h\u00e4lt mein Wollen und Verlangen", "tokens": ["Sie", "h\u00e4lt", "mein", "Wol\u00b7len", "und", "Ver\u00b7lan\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "KON", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "ja meine Seele selbst gefangen.", "tokens": ["ja", "mei\u00b7ne", "See\u00b7le", "selbst", "ge\u00b7fan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Ich bin nu selber nicht mehr mein.", "tokens": ["Ich", "bin", "nu", "sel\u00b7ber", "nicht", "mehr", "mein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "PTKNEG", "ADV", "PPOSAT", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Ich wei\u00df/ da\u00df dein belobtes Feld", "tokens": ["Ich", "wei\u00df", "/", "da\u00df", "dein", "be\u00b7lob\u00b7tes", "Feld"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$(", "KOUS", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Makarjen auch ist f\u00fcr zu ziehen/", "tokens": ["Ma\u00b7kar\u00b7jen", "auch", "ist", "f\u00fcr", "zu", "zie\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "VAFIN", "APPR", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "ich kenne deiner Wiesen bl\u00fchen/", "tokens": ["ich", "ken\u00b7ne", "dei\u00b7ner", "Wie\u00b7sen", "bl\u00fc\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "die J\u00e4ger-lust/ die Fischereyen/", "tokens": ["die", "J\u00e4\u00b7ger\u00b7lust", "/", "die", "Fi\u00b7sche\u00b7re\u00b7yen", "/"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "ART", "NN", "$("], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.5": {"text": "den Vogel-fang und was f\u00fcr freuen", "tokens": ["den", "Vo\u00b7gel\u00b7fang", "und", "was", "f\u00fcr", "freu\u00b7en"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "KON", "PWS", "APPR", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "mehr dein Robitten in sich h\u00e4lt.", "tokens": ["mehr", "dein", "Ro\u00b7bit\u00b7ten", "in", "sich", "h\u00e4lt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "APPR", "PRF", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Mir klingt der sanffte Drescher-schlag", "tokens": ["Mir", "klingt", "der", "sanff\u00b7te", "Dre\u00b7scher\u00b7schlag"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "in Ohren noch/ wenn in dem fr\u00fchen", "tokens": ["in", "Oh\u00b7ren", "noch", "/", "wenn", "in", "dem", "fr\u00fc\u00b7hen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "NN", "ADV", "$(", "KOUS", "APPR", "ART", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "die Morgen-treume reiner ziehen/", "tokens": ["die", "Mor\u00b7gen\u00b7treu\u00b7me", "rei\u00b7ner", "zie\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "ich h\u00f6re noch der Schaaffe blehen/", "tokens": ["ich", "h\u00f6\u00b7re", "noch", "der", "Schaaf\u00b7fe", "ble\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "die Dader-Gan\u00df/ der Hanen krehen/", "tokens": ["die", "Da\u00b7der\u00b7Gan\u00df", "/", "der", "Ha\u00b7nen", "kre\u00b7hen", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "wenn sich enttz\u00fcndt der junge Tag.", "tokens": ["wenn", "sich", "entt\u00b7z\u00fcndt", "der", "jun\u00b7ge", "Tag", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Mich schmertzt die Hoffart/ Geitz und Neid/", "tokens": ["Mich", "schmertzt", "die", "Hof\u00b7fart", "/", "Geitz", "und", "Neid", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$(", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Betrug und List sampt andern S\u00fcnden", "tokens": ["Be\u00b7trug", "und", "List", "sampt", "an\u00b7dern", "S\u00fcn\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "KON", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "die sich in St\u00e4dten h\u00e4uffig finden.", "tokens": ["die", "sich", "in", "St\u00e4d\u00b7ten", "h\u00e4uf\u00b7fig", "fin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRELS", "PRF", "APPR", "NN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Hier herschet Unrecht/ Trozz un\u0303 Schande.", "tokens": ["Hier", "her\u00b7schet", "Un\u00b7recht", "/", "Trozz", "u\u00f1", "Schan\u00b7de", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NN", "$(", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "die Unschuld wohnet auff dem Lande/", "tokens": ["die", "Un\u00b7schuld", "woh\u00b7net", "auff", "dem", "Lan\u00b7de", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "wie umb Saturnus g\u00f6ldne Zeit.", "tokens": ["wie", "umb", "Sa\u00b7tur\u00b7nus", "g\u00f6ld\u00b7ne", "Zeit", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPR", "NE", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Wie gerne w\u00e4r\u2019 ich einmahl mein!", "tokens": ["Wie", "ger\u00b7ne", "w\u00e4r'", "ich", "ein\u00b7mahl", "mein", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "VAFIN", "PPER", "ADV", "PPOSAT", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "wie gerne m\u00f6cht\u2019 ich dich erblikken", "tokens": ["wie", "ger\u00b7ne", "m\u00f6cht'", "ich", "dich", "er\u00b7blik\u00b7ken"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADV", "VMFIN", "PPER", "PRF", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "wie gerne mich bey dir erqwikken!", "tokens": ["wie", "ger\u00b7ne", "mich", "bey", "dir", "er\u00b7qwik\u00b7ken", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "PPER", "APPR", "PPER", "VVINF", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "dein Brot gemengt au\u00df schwartzer Kleyen", "tokens": ["dein", "Brot", "ge\u00b7mengt", "au\u00df", "schwart\u00b7zer", "Kle\u00b7yen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VVPP", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "dein Wasser-trunk als Nektar sein:", "tokens": ["dein", "Was\u00b7ser\u00b7trunk", "als", "Nek\u00b7tar", "sein", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KOUS", "NN", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Wer aber kan die Thr\u00e4hnen sehn/", "tokens": ["Wer", "a\u00b7ber", "kan", "die", "Thr\u00b7\u00e4h\u00b7nen", "sehn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "VMFIN", "ART", "NN", "VVINF", "$("], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "wenn die Rosille/ mein Verlangen/", "tokens": ["wenn", "die", "Ro\u00b7sil\u00b7le", "/", "mein", "Ver\u00b7lan\u00b7gen", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "$(", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "mir trieffend na\u00df macht Stirn un\u0303 Wangen", "tokens": ["mir", "trief\u00b7fend", "na\u00df", "macht", "Stirn", "u\u00f1", "Wan\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "ADJD", "ADJD", "VVFIN", "NN", "KON", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "wen\u0303 sie verschweert mit Hand und Munde", "tokens": ["we\u00f1", "sie", "ver\u00b7schweert", "mit", "Hand", "und", "Mun\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "VVFIN", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "mir gut zu seyn/ wenn eine Stunde", "tokens": ["mir", "gut", "zu", "seyn", "/", "wenn", "ei\u00b7ne", "Stun\u00b7de"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "ADJD", "PTKZU", "VAINF", "$(", "KOUS", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "ich w\u00fcrd\u2019 ab-ihrer Seite-gehn?", "tokens": ["ich", "w\u00fcrd'", "ab\u00b7ih\u00b7rer", "Sei\u00b7te\u00b7gehn", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJA", "NN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.8": {"line.1": {"text": "Bald bittet sie/ bald dreuet sie/", "tokens": ["Bald", "bit\u00b7tet", "sie", "/", "bald", "dreu\u00b7et", "sie", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$(", "ADV", "VVFIN", "PPER", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "bald hebt sie wieder an zu klagen/", "tokens": ["bald", "hebt", "sie", "wie\u00b7der", "an", "zu", "kla\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "PTKVZ", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "bald will sie sich mit Feusten schlagen/", "tokens": ["bald", "will", "sie", "sich", "mit", "Feus\u00b7ten", "schla\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PRF", "APPR", "NN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "bald bl\u00f6\u00dft sie sterbend ihr Gesichte", "tokens": ["bald", "bl\u00f6\u00dft", "sie", "ster\u00b7bend", "ihr", "Ge\u00b7sich\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "und flucht dem strengen Stern-Gerichte", "tokens": ["und", "flucht", "dem", "stren\u00b7gen", "Stern\u00b7Ge\u00b7rich\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Wer kan ertragen so viel M\u00fch?", "tokens": ["Wer", "kan", "er\u00b7tra\u00b7gen", "so", "viel", "M\u00fch", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "VVINF", "ADV", "PIAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Ich bin kein Stein/ ich lasse mich", "tokens": ["Ich", "bin", "kein", "Stein", "/", "ich", "las\u00b7se", "mich"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PIAT", "NN", "$(", "PPER", "VVFIN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "auff ihre Klag\u2019 alsdenn erweichen/", "tokens": ["auff", "ih\u00b7re", "Klag'", "als\u00b7denn", "er\u00b7wei\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "ich habe/ Freund/ dich nicht gesprochen", "tokens": ["ich", "ha\u00b7be", "/", "Freund", "/", "dich", "nicht", "ge\u00b7spro\u00b7chen"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VAFIN", "$(", "NN", "$(", "PPER", "PTKNEG", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "da meinstu denn/ es sey gebrochen/", "tokens": ["da", "meins\u00b7tu", "denn", "/", "es", "sey", "ge\u00b7bro\u00b7chen", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "$(", "PPER", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "was uns verbindet/ mich und dich.", "tokens": ["was", "uns", "ver\u00b7bin\u00b7det", "/", "mich", "und", "dich", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVFIN", "$(", "PPER", "KON", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Ich wei\u00df nicht/ was f\u00fcr Haltn\u00fc\u00df doch", "tokens": ["Ich", "wei\u00df", "nicht", "/", "was", "f\u00fcr", "Halt\u00b7n\u00fc\u00df", "doch"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PTKNEG", "$(", "PWS", "APPR", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "der schmeichlend\u2019 Amor in sich heget.", "tokens": ["der", "schmeich\u00b7lend'", "A\u00b7mor", "in", "sich", "he\u00b7get", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NE", "APPR", "PRF", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Der Freyheit Pa\u00df wird nur verleget", "tokens": ["Der", "Frey\u00b7heit", "Pa\u00df", "wird", "nur", "ver\u00b7le\u00b7get"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "NN", "VAFIN", "ADV", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "ich kan au\u00df seinen Zauber-Ketten", "tokens": ["ich", "kan", "au\u00df", "sei\u00b7nen", "Zau\u00b7ber\u00b7Ket\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "mich durch kein einig Mittel retten/", "tokens": ["mich", "durch", "kein", "ei\u00b7nig", "Mit\u00b7tel", "ret\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "PIAT", "ADJD", "NN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Komm/ Bruder/ sieh es einst mit an/", "tokens": ["Komm", "/", "Bru\u00b7der", "/", "sieh", "es", "einst", "mit", "an", "/"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$(", "NN", "$(", "VVIMP", "PPER", "ADV", "APPR", "APPR", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "du wirst es selbst mit mir gestehen/", "tokens": ["du", "wirst", "es", "selbst", "mit", "mir", "ge\u00b7ste\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "APPR", "PPER", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "es sey vergeblich nicht geschehen/", "tokens": ["es", "sey", "ver\u00b7geb\u00b7lich", "nicht", "ge\u00b7sche\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "PTKNEG", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "da\u00df ich zu dir nicht bin gekommen/", "tokens": ["da\u00df", "ich", "zu", "dir", "nicht", "bin", "ge\u00b7kom\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PPER", "PTKNEG", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "da\u00df mir die Freyheit sey genommen/", "tokens": ["da\u00df", "mir", "die", "Frey\u00b7heit", "sey", "ge\u00b7nom\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "und da\u00df Rosill\u2019 es hat getahn.", "tokens": ["und", "da\u00df", "Ro\u00b7sill'", "es", "hat", "ge\u00b7tahn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "NE", "PPER", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}