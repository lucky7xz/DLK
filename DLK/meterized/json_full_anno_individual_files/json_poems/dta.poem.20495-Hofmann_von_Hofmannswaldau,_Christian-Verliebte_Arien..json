{"dta.poem.20495": {"metadata": {"author": {"name": "Hofmann von Hofmannswaldau, Christian", "birth": "N.A.", "death": "N.A."}, "title": "Verliebte Arien.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1695", "urn": "urn:nbn:de:kobv:b4-200905197751", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Falsche Doris deine thr\u00e4nen/", "tokens": ["Fal\u00b7sche", "Do\u00b7ris", "dei\u00b7ne", "thr\u00e4\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NE", "PPOSAT", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Dein verstelltes angesicht/", "tokens": ["Dein", "ver\u00b7stell\u00b7tes", "an\u00b7ge\u00b7sicht", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Deiner seuffzer \u00e4ngstigs sehnen", "tokens": ["Dei\u00b7ner", "seuff\u00b7zer", "\u00e4ngs\u00b7tigs", "seh\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Hemmet meinen vorsatz nicht/", "tokens": ["Hem\u00b7met", "mei\u00b7nen", "vor\u00b7satz", "nicht", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "PTKNEG", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Ich will deinen strick zerreissen/", "tokens": ["Ich", "will", "dei\u00b7nen", "strick", "zer\u00b7reis\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPOSAT", "NN", "VVPP", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Und nicht mehr der deine heissen.", "tokens": ["Und", "nicht", "mehr", "der", "dei\u00b7ne", "heis\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "ADV", "ART", "PPOSAT", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Reiche/ falsche lust-Syrene/", "tokens": ["Rei\u00b7che", "/", "fal\u00b7sche", "lust\u00b7Sy\u00b7re\u00b7ne", "/"], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NE", "$(", "ADJA", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Einem andern deinen mund/", "tokens": ["Ei\u00b7nem", "an\u00b7dern", "dei\u00b7nen", "mund", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "PPOSAT", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Dein bezaubernd mund-geth\u00f6ne", "tokens": ["Dein", "be\u00b7zau\u00b7bernd", "mun\u00b7dget\u00b7h\u00f6\u00b7ne"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "ADJD", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "F\u00fchrt auff ungeb\u00e4hnten grund/", "tokens": ["F\u00fchrt", "auff", "un\u00b7ge\u00b7b\u00e4hn\u00b7ten", "grund", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ADJA", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Mein schiff soll auff deinen h\u00f6hen/", "tokens": ["Mein", "schiff", "soll", "auff", "dei\u00b7nen", "h\u00f6\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "VVFIN", "VMFIN", "APPR", "PPOSAT", "ADJA", "$("], "meter": "+---+-+-", "measure": "dactylic.init"}, "line.6": {"text": "Nun nicht mehr zu scheitern gehen.", "tokens": ["Nun", "nicht", "mehr", "zu", "schei\u00b7tern", "ge\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKNEG", "ADV", "PTKZU", "VVINF", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Weg du brandmahl meines lebens/", "tokens": ["Weg", "du", "brand\u00b7mahl", "mei\u00b7nes", "le\u00b7bens", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "VVFIN", "PPOSAT", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Falsche Doris weg mit dir/", "tokens": ["Fal\u00b7sche", "Do\u00b7ris", "weg", "mit", "dir", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NE", "ADV", "APPR", "PPER", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Weine nicht/ es ist vergebens/", "tokens": ["Wei\u00b7ne", "nicht", "/", "es", "ist", "ver\u00b7ge\u00b7bens", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "PTKNEG", "$(", "PPER", "VAFIN", "ADV", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Bringe ja kein klagen f\u00fcr/", "tokens": ["Brin\u00b7ge", "ja", "kein", "kla\u00b7gen", "f\u00fcr", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PIAT", "ADJA", "APPR", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Ich bin (war ich gleich gefangen)", "tokens": ["Ich", "bin", "(", "war", "ich", "gleich", "ge\u00b7fan\u00b7gen", ")"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$(", "VAFIN", "PPER", "ADV", "VVPP", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Dennoch deiner macht entgangen.", "tokens": ["Den\u00b7noch", "dei\u00b7ner", "macht", "ent\u00b7gan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "VVFIN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Solt ich dich wohl k\u00f6nnen lieben/", "tokens": ["Solt", "ich", "dich", "wohl", "k\u00f6n\u00b7nen", "lie\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PRF", "ADV", "VMFIN", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Derer gr\u00fcne jungfer-krantz", "tokens": ["De\u00b7rer", "gr\u00fc\u00b7ne", "jung\u00b7fer\u00b7krantz"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "L\u00e4ngst/ ich wei\u00df nicht wo/ geblieben?", "tokens": ["L\u00e4ngst", "/", "ich", "wei\u00df", "nicht", "wo", "/", "ge\u00b7blie\u00b7ben", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["NN", "$(", "PPER", "VVFIN", "PTKNEG", "PWAV", "$(", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Welcher mit entlehntem glantz/", "tokens": ["Wel\u00b7cher", "mit", "ent\u00b7lehn\u00b7tem", "glantz", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAT", "APPR", "ADJA", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Als ein irr-licht meiner seelen/", "tokens": ["Als", "ein", "irr\u00b7licht", "mei\u00b7ner", "see\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "PPOSAT", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "F\u00fchrt zu lauter laster-h\u00f6len.", "tokens": ["F\u00fchrt", "zu", "lau\u00b7ter", "las\u00b7ter\u00b7h\u00f6len", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKA", "ADJD", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Weg ihr meine knechtschaffts-pf\u00e4nder/", "tokens": ["Weg", "ihr", "mei\u00b7ne", "knecht\u00b7schaffts\u00b7pf\u00e4n\u00b7der", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PPOSAT", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Die ich nechst von ihr empfing/", "tokens": ["Die", "ich", "nechst", "von", "ihr", "emp\u00b7fing", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "APPR", "PPER", "VVFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Brieffe/ kr\u00e4ntze/ haar und b\u00e4nder/", "tokens": ["Brief\u00b7fe", "/", "kr\u00e4nt\u00b7ze", "/", "haar", "und", "b\u00e4n\u00b7der", "/"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$(", "VVFIN", "$(", "NN", "KON", "ADJD", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Weg verfluchter zauber-ring/", "tokens": ["Weg", "ver\u00b7fluch\u00b7ter", "zau\u00b7ber\u00b7ring", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ADJA", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Ihr habt allem sclaven-leben", "tokens": ["Ihr", "habt", "al\u00b7lem", "scla\u00b7ven\u00b7le\u00b7ben"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PIS", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Nunmehr gute nacht gegeben.", "tokens": ["Nun\u00b7mehr", "gu\u00b7te", "nacht", "ge\u00b7ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Brennet wohl/ ihr liebes-schreiben/", "tokens": ["Bren\u00b7net", "wohl", "/", "ihr", "lie\u00b7bes\u00b7schrei\u00b7ben", "/"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "ADV", "$(", "PPOSAT", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Brennt zum zeichen meiner treu/", "tokens": ["Brennt", "zum", "zei\u00b7chen", "mei\u00b7ner", "treu", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPRART", "NN", "PPOSAT", "ADJD", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ich bin (Doris mag es gl\u00e4uben)", "tokens": ["Ich", "bin", "(", "Do\u00b7ris", "mag", "es", "gl\u00e4u\u00b7ben", ")"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$(", "NE", "VMFIN", "PPER", "VVINF", "$("], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Nunmehr alles kummers frey/", "tokens": ["Nun\u00b7mehr", "al\u00b7les", "kum\u00b7mers", "frey", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "ADV", "ADJD", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Brennet brieffe/ band und haare/", "tokens": ["Bren\u00b7net", "brief\u00b7fe", "/", "band", "und", "haa\u00b7re", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "$(", "VVFIN", "KON", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Brenn verfluchte buhler-waare.", "tokens": ["Brenn", "ver\u00b7fluch\u00b7te", "buh\u00b7ler\u00b7waa\u00b7re", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Eure asche soll besagen/", "tokens": ["Eu\u00b7re", "asc\u00b7he", "soll", "be\u00b7sa\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "VMFIN", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Da\u00df die glut der besten treu/", "tokens": ["Da\u00df", "die", "glut", "der", "bes\u00b7ten", "treu", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ART", "ADJA", "ADJD", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Die ich bi\u00df hieher getragen/", "tokens": ["Die", "ich", "bi\u00df", "hie\u00b7her", "ge\u00b7tra\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "PAV", "VVPP", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Asch in meinem hertzen sey/", "tokens": ["Asch", "in", "mei\u00b7nem", "hert\u00b7zen", "sey", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "PPOSAT", "NN", "VAFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Wo kein f\u00fcncklein ist zufinden/", "tokens": ["Wo", "kein", "f\u00fcnc\u00b7klein", "ist", "zu\u00b7fin\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIAT", "NN", "VAFIN", "ADJD", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Das mich wieder m\u00f6cht entz\u00fcnden.", "tokens": ["Das", "mich", "wie\u00b7der", "m\u00f6cht", "ent\u00b7z\u00fcn\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "ADV", "VMFIN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Itzund trag ich unverholen/", "tokens": ["It\u00b7zund", "trag", "ich", "un\u00b7ver\u00b7ho\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "ADJD", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Doris/ ich gesteh es dir/", "tokens": ["Do\u00b7ris", "/", "ich", "ge\u00b7steh", "es", "dir", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$(", "PPER", "VVFIN", "PPER", "PPER", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Nichts denn lauter todte kohlen/", "tokens": ["Nichts", "denn", "lau\u00b7ter", "tod\u00b7te", "koh\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "ADV", "PIAT", "NN", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und verleschte br\u00e4nd\u2019 in mir/", "tokens": ["Und", "ver\u00b7leschte", "br\u00e4nd'", "in", "mir", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "APPR", "PPER", "$("], "meter": "--+--+", "measure": "anapaest.di.plus"}, "line.5": {"text": "Weil die falschheit/ die mich schrecket/", "tokens": ["Weil", "die", "falschheit", "/", "die", "mich", "schre\u00b7cket", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "$(", "PRELS", "PPER", "VVFIN", "$("], "meter": "-++--+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Gleich die erste flamm erstecket.", "tokens": ["Gleich", "die", "ers\u00b7te", "flamm", "er\u00b7ste\u00b7cket", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Falsche Doris/ vor mein himmel/", "tokens": ["Fal\u00b7sche", "Do\u00b7ris", "/", "vor", "mein", "him\u00b7mel", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "NE", "$(", "APPR", "PPOSAT", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Itzund nichts denn h\u00f6ll und nacht/", "tokens": ["It\u00b7zund", "nichts", "denn", "h\u00f6ll", "und", "nacht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "ADV", "ADJD", "KON", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ich bin \u00fcber dem get\u00fcmmel", "tokens": ["Ich", "bin", "\u00fc\u00b7ber", "dem", "ge\u00b7t\u00fcm\u00b7mel"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "APPR", "ART", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Deiner untreu auffgewacht;", "tokens": ["Dei\u00b7ner", "un\u00b7treu", "auff\u00b7ge\u00b7wacht", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJD", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Drum gedencke nicht mit l\u00fcgen", "tokens": ["Drum", "ge\u00b7den\u00b7cke", "nicht", "mit", "l\u00fc\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "PTKNEG", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Mich auffs neu im schlaff zu wiegen.", "tokens": ["Mich", "auffs", "neu", "im", "schlaff", "zu", "wie\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPRART", "ADJD", "APPRART", "ADJD", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "S\u00fcnden-schwester/ zauber- dirne/", "tokens": ["S\u00fcn\u00b7den\u00b7schwes\u00b7ter", "/", "zau\u00b7ber", "dir\u00b7ne", "/"], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NN", "$(", "TRUNC", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Falsche Doris/ nun adjeu/", "tokens": ["Fal\u00b7sche", "Do\u00b7ris", "/", "nun", "ad\u00b7jeu", "/"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADJA", "NE", "$(", "ADV", "NE", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Mich bringt deine glatte stirne", "tokens": ["Mich", "bringt", "dei\u00b7ne", "glat\u00b7te", "stir\u00b7ne"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPOSAT", "ADJA", "ADJA"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Nun nicht mehr in angst und weh.", "tokens": ["Nun", "nicht", "mehr", "in", "angst", "und", "weh", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKNEG", "ADV", "APPR", "NN", "KON", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Welcher dir hinfort begegnet/", "tokens": ["Wel\u00b7cher", "dir", "hin\u00b7fort", "be\u00b7geg\u00b7net", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAT", "PPER", "ADV", "VVFIN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Sey verflucht/ ich bin gesegnet.", "tokens": ["Sey", "ver\u00b7flucht", "/", "ich", "bin", "ge\u00b7seg\u00b7net", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "VVPP", "$(", "PPER", "VAFIN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}}}}