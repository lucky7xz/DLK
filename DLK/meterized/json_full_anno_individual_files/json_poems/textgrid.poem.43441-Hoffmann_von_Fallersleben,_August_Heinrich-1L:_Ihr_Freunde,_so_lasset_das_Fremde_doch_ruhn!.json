{"textgrid.poem.43441": {"metadata": {"author": {"name": "Hoffmann von Fallersleben, August Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "1L: Ihr Freunde, so lasset das Fremde doch ruhn!", "genre": "verse", "period": "N.A.", "pub_year": 1836, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ihr Freunde, so lasset das Fremde doch ruhn!", "tokens": ["Ihr", "Freun\u00b7de", ",", "so", "las\u00b7set", "das", "Frem\u00b7de", "doch", "ruhn", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "ADV", "VVFIN", "ART", "NN", "ADV", "VVINF", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "Wir haben genug noch zu Hause zu thun.", "tokens": ["Wir", "ha\u00b7ben", "ge\u00b7nug", "noch", "zu", "Hau\u00b7se", "zu", "thun", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "APPR", "NN", "PTKZU", "VVINF", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}}, "stanza.2": {"line.1": {"text": "Das Fremde bewundern kann Jedermann;", "tokens": ["Das", "Frem\u00b7de", "be\u00b7wun\u00b7dern", "kann", "Je\u00b7der\u00b7mann", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "VMFIN", "PIS", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Macht Eigenes, was man bewundern kann!", "tokens": ["Macht", "Ei\u00b7ge\u00b7nes", ",", "was", "man", "be\u00b7wun\u00b7dern", "kann", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJA", "$,", "PRELS", "PIS", "VVINF", "VMFIN", "$."], "meter": "-+---+-+-+", "measure": "dactylic.init"}}, "stanza.3": {"line.1": {"text": "\u00dcberall mir das Gut' und das Sch\u00f6ne gef\u00e4llt,", "tokens": ["\u00dc\u00b7be\u00b7rall", "mir", "das", "Gut'", "und", "das", "Sch\u00f6\u00b7ne", "ge\u00b7f\u00e4llt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "ART", "NN", "KON", "ART", "NN", "VVPP", "$,"], "meter": "--+--+--+--+", "measure": "anapaest.tetra.plus"}, "line.2": {"text": "Doch bin ich kein Affe der ganzen Welt.", "tokens": ["Doch", "bin", "ich", "kein", "Af\u00b7fe", "der", "gan\u00b7zen", "Welt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "PIAT", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}}, "stanza.4": {"line.1": {"text": "Ich wei\u00df was ich habe, ich wei\u00df was ich bin,", "tokens": ["Ich", "wei\u00df", "was", "ich", "ha\u00b7be", ",", "ich", "wei\u00df", "was", "ich", "bin", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PWS", "PPER", "VAFIN", "$,", "PPER", "VVFIN", "PWS", "PPER", "VAFIN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "Ich bin ein Deutscher mit Leib und Sinn.", "tokens": ["Ich", "bin", "ein", "Deut\u00b7scher", "mit", "Leib", "und", "Sinn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.5": {"line.1": {"text": "Das Fremde zu hassen, das f\u00e4llt mir nicht ein \u2013", "tokens": ["Das", "Frem\u00b7de", "zu", "has\u00b7sen", ",", "das", "f\u00e4llt", "mir", "nicht", "ein", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKZU", "VVINF", "$,", "PDS", "VVFIN", "PPER", "PTKNEG", "ART", "$("], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "Doch kann ich und will ich ein Deutscher nur sein.", "tokens": ["Doch", "kann", "ich", "und", "will", "ich", "ein", "Deut\u00b7scher", "nur", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "KON", "VMFIN", "PPER", "ART", "NN", "ADV", "VAINF", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}}, "stanza.6": {"line.1": {"text": "Und bleib's bis zum letzten Athemzug \u2013", "tokens": ["Und", "bleib's", "bis", "zum", "letz\u00b7ten", "A\u00b7them\u00b7zug", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "APPRART", "ADJA", "NN", "$("], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Nun liebt oder ha\u00dft mich, nun wi\u00dft ihr genug.", "tokens": ["Nun", "liebt", "o\u00b7der", "ha\u00dft", "mich", ",", "nun", "wi\u00dft", "ihr", "ge\u00b7nug", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "KON", "VVFIN", "PPER", "$,", "ADV", "VVFIN", "PPER", "ADV", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}}, "stanza.7": {"line.1": {"text": "Ihr Freunde, so lasset das Fremde doch ruhn!", "tokens": ["Ihr", "Freun\u00b7de", ",", "so", "las\u00b7set", "das", "Frem\u00b7de", "doch", "ruhn", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "ADV", "VVFIN", "ART", "NN", "ADV", "VVINF", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "Wir haben genug noch zu Hause zu thun.", "tokens": ["Wir", "ha\u00b7ben", "ge\u00b7nug", "noch", "zu", "Hau\u00b7se", "zu", "thun", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "APPR", "NN", "PTKZU", "VVINF", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}}, "stanza.8": {"line.1": {"text": "Das Fremde bewundern kann Jedermann;", "tokens": ["Das", "Frem\u00b7de", "be\u00b7wun\u00b7dern", "kann", "Je\u00b7der\u00b7mann", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "VMFIN", "PIS", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Macht Eigenes, was man bewundern kann!", "tokens": ["Macht", "Ei\u00b7ge\u00b7nes", ",", "was", "man", "be\u00b7wun\u00b7dern", "kann", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJA", "$,", "PRELS", "PIS", "VVINF", "VMFIN", "$."], "meter": "-+---+-+-+", "measure": "dactylic.init"}}, "stanza.9": {"line.1": {"text": "\u00dcberall mir das Gut' und das Sch\u00f6ne gef\u00e4llt,", "tokens": ["\u00dc\u00b7be\u00b7rall", "mir", "das", "Gut'", "und", "das", "Sch\u00f6\u00b7ne", "ge\u00b7f\u00e4llt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "ART", "NN", "KON", "ART", "NN", "VVPP", "$,"], "meter": "--+--+--+--+", "measure": "anapaest.tetra.plus"}, "line.2": {"text": "Doch bin ich kein Affe der ganzen Welt.", "tokens": ["Doch", "bin", "ich", "kein", "Af\u00b7fe", "der", "gan\u00b7zen", "Welt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "PIAT", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}}, "stanza.10": {"line.1": {"text": "Ich wei\u00df was ich habe, ich wei\u00df was ich bin,", "tokens": ["Ich", "wei\u00df", "was", "ich", "ha\u00b7be", ",", "ich", "wei\u00df", "was", "ich", "bin", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PWS", "PPER", "VAFIN", "$,", "PPER", "VVFIN", "PWS", "PPER", "VAFIN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "Ich bin ein Deutscher mit Leib und Sinn.", "tokens": ["Ich", "bin", "ein", "Deut\u00b7scher", "mit", "Leib", "und", "Sinn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.11": {"line.1": {"text": "Das Fremde zu hassen, das f\u00e4llt mir nicht ein \u2013", "tokens": ["Das", "Frem\u00b7de", "zu", "has\u00b7sen", ",", "das", "f\u00e4llt", "mir", "nicht", "ein", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKZU", "VVINF", "$,", "PDS", "VVFIN", "PPER", "PTKNEG", "ART", "$("], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "Doch kann ich und will ich ein Deutscher nur sein.", "tokens": ["Doch", "kann", "ich", "und", "will", "ich", "ein", "Deut\u00b7scher", "nur", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "KON", "VMFIN", "PPER", "ART", "NN", "ADV", "VAINF", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}}, "stanza.12": {"line.1": {"text": "Und bleib's bis zum letzten Athemzug \u2013", "tokens": ["Und", "bleib's", "bis", "zum", "letz\u00b7ten", "A\u00b7them\u00b7zug", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "APPRART", "ADJA", "NN", "$("], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Nun liebt oder ha\u00dft mich, nun wi\u00dft ihr genug.", "tokens": ["Nun", "liebt", "o\u00b7der", "ha\u00dft", "mich", ",", "nun", "wi\u00dft", "ihr", "ge\u00b7nug", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "KON", "VVFIN", "PPER", "$,", "ADV", "VVFIN", "PPER", "ADV", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}}}}}