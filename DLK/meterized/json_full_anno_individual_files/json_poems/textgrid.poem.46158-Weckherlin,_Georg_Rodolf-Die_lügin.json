{"textgrid.poem.46158": {"metadata": {"author": {"name": "Weckherlin, Georg Rodolf", "birth": "N.A.", "death": "N.A."}, "title": "Die l\u00fcgin", "genre": "verse", "period": "N.A.", "pub_year": 1618, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Geh durch die welt, o meine seel,", "tokens": ["Geh", "durch", "die", "welt", ",", "o", "mei\u00b7ne", "seel", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ART", "NN", "$,", "FM", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "der welt undankbarkeit zu sehen,", "tokens": ["der", "welt", "un\u00b7dank\u00b7bar\u00b7keit", "zu", "se\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "sag jedem ohn scheu seinen fehl,", "tokens": ["sag", "je\u00b7dem", "ohn", "scheu", "sei\u00b7nen", "fehl", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "APPR", "ADJD", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "die warheit selbs soll dir beistehen:", "tokens": ["die", "war\u00b7heit", "selbs", "soll", "dir", "bei\u00b7ste\u00b7hen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "kan ja die welt nichts dan betriegen,", "tokens": ["kan", "ja", "die", "welt", "nichts", "dan", "be\u00b7trie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "ART", "NN", "PIS", "ADV", "VVFIN", "$,"], "meter": "---+-+-+-", "measure": "unknown.measure.tri"}, "line.6": {"text": "so hei\u00df sie offentlich rund liegen.", "tokens": ["so", "hei\u00df", "sie", "of\u00b7fent\u00b7lich", "rund", "lie\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "ADJD", "ADJD", "VVFIN", "$."], "meter": "-+-++-++-", "measure": "unknown.measure.penta"}}, "stanza.2": {"line.1": {"text": "Dem hof sag, da\u00df sein pracht und ehr", "tokens": ["Dem", "hof", "sag", ",", "da\u00df", "sein", "pracht", "und", "ehr"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "$,", "KOUS", "PPOSAT", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "wie faul holz unbest\u00e4ndig scheinen;", "tokens": ["wie", "faul", "holz", "un\u00b7be\u00b7st\u00e4n\u00b7dig", "schei\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "ADJD", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "der kirchen sag, was ihre lehr", "tokens": ["der", "kir\u00b7chen", "sag", ",", "was", "ih\u00b7re", "lehr"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "$,", "PRELS", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "gut hei\u00dfet, ihre werk verneinen;", "tokens": ["gut", "hei\u00b7\u00dfet", ",", "ih\u00b7re", "werk", "ver\u00b7nei\u00b7nen", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "$,", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "und sagen sie, du bist betrogen,", "tokens": ["und", "sa\u00b7gen", "sie", ",", "du", "bist", "be\u00b7tro\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "$,", "PPER", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "so sag ohn scham: es ist erlogen.", "tokens": ["so", "sag", "ohn", "scham", ":", "es", "ist", "er\u00b7lo\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "NE", "$.", "PPER", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Den f\u00fcrsten sag, ihr stand und hab", "tokens": ["Den", "f\u00fcrs\u00b7ten", "sag", ",", "ihr", "stand", "und", "hab"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "VVFIN", "$,", "PPER", "VVFIN", "KON", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "k\u00f6nd nicht ohn andrer hilf lang wehren,", "tokens": ["k\u00f6nd", "nicht", "ohn", "an\u00b7drer", "hilf", "lang", "weh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PTKNEG", "APPR", "ADJA", "NN", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "und da\u00df man pfleg mehr ihre gab,", "tokens": ["und", "da\u00df", "man", "pfleg", "mehr", "ih\u00b7re", "gab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PIS", "VVFIN", "ADV", "PPOSAT", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "dan sie zu loben und zu ehren;", "tokens": ["dan", "sie", "zu", "lo\u00b7ben", "und", "zu", "eh\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "PTKZU", "VVINF", "KON", "PTKZU", "VVINF", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.5": {"text": "und sprechen sie: du bist betrogen,", "tokens": ["und", "spre\u00b7chen", "sie", ":", "du", "bist", "be\u00b7tro\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "$.", "PPER", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "so sag ohn forcht: es ist erlogen.", "tokens": ["so", "sag", "ohn", "forcht", ":", "es", "ist", "er\u00b7lo\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "NN", "$.", "PPER", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Den herren sag, die sich beseits", "tokens": ["Den", "her\u00b7ren", "sag", ",", "die", "sich", "be\u00b7seits"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "$,", "PRELS", "PRF", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "in ihren hohen \u00e4mptern sprei\u00dfen,", "tokens": ["in", "ih\u00b7ren", "ho\u00b7hen", "\u00e4mp\u00b7tern", "sprei\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "ADJA", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "da\u00df sie des ehrgeiz und neids", "tokens": ["da\u00df", "sie", "des", "ehr\u00b7geiz", "und", "neids"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "NN", "KON", "NE"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "mehr dan der billichkeit befleissen;", "tokens": ["mehr", "dan", "der", "bil\u00b7lich\u00b7keit", "be\u00b7fleis\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "und sagen sie: du bist betrogen,", "tokens": ["und", "sa\u00b7gen", "sie", ":", "du", "bist", "be\u00b7tro\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "$.", "PPER", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "antwort du rund: es ist erlogen.", "tokens": ["ant\u00b7wort", "du", "rund", ":", "es", "ist", "er\u00b7lo\u00b7gen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "$.", "PPER", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Sag denen, welche f\u00fcr der welt", "tokens": ["Sag", "de\u00b7nen", ",", "wel\u00b7che", "f\u00fcr", "der", "welt"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "PDS", "$,", "PRELS", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "mit zeug und kleidern statlich prangen", "tokens": ["mit", "zeug", "und", "klei\u00b7dern", "stat\u00b7lich", "pran\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "VVFIN", "ADJD", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "sie wolten gern dardurch mehr geld", "tokens": ["sie", "wol\u00b7ten", "gern", "dar\u00b7durch", "mehr", "geld"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ADV", "PAV", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "und gr\u00f6\u00dfern dienst und ruhm erlangen;", "tokens": ["und", "gr\u00f6\u00b7\u00dfern", "dienst", "und", "ruhm", "er\u00b7lan\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "antworten sie, man sei betrogen,", "tokens": ["ant\u00b7wor\u00b7ten", "sie", ",", "man", "sei", "be\u00b7tro\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "PIS", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "so antwort du: es ist erlogen.", "tokens": ["so", "ant\u00b7wort", "du", ":", "es", "ist", "er\u00b7lo\u00b7gen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$.", "PPER", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Sag, buhlerei sei b\u00f6ser lust,", "tokens": ["Sag", ",", "buh\u00b7le\u00b7rei", "sei", "b\u00f6\u00b7ser", "lust", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADJD", "VAFIN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "sag, ehr m\u00f6g bald verkehret werden,", "tokens": ["sag", ",", "ehr", "m\u00f6g", "bald", "ver\u00b7keh\u00b7ret", "wer\u00b7den", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "NN", "VMFIN", "ADV", "VVPP", "VAINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "sag, sch\u00f6nheit k\u00fcrzlich werd ein wust,", "tokens": ["sag", ",", "sch\u00f6n\u00b7heit", "k\u00fcrz\u00b7lich", "werd", "ein", "wust", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "ADV", "ADJD", "VAFIN", "ART", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "sag, alter neig sich zu der erden;", "tokens": ["sag", ",", "al\u00b7ter", "neig", "sich", "zu", "der", "er\u00b7den", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "ADJA", "VVFIN", "PRF", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "antworten sie, man sei betrogen,", "tokens": ["ant\u00b7wor\u00b7ten", "sie", ",", "man", "sei", "be\u00b7tro\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "PIS", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "so sag du frech: es ist erlogen.", "tokens": ["so", "sag", "du", "frech", ":", "es", "ist", "er\u00b7lo\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "$.", "PPER", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Dem rechten sag, es sei voll zank,", "tokens": ["Dem", "rech\u00b7ten", "sag", ",", "es", "sei", "voll", "zank", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "$,", "PPER", "VAFIN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "sag, klugheit pfleg sich zu beth\u00f6ren,", "tokens": ["sag", ",", "klug\u00b7heit", "pfleg", "sich", "zu", "be\u00b7th\u00f6\u00b7ren", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "ADJD", "VVFIN", "PRF", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "der arznei sag, sie sei selbs krank,", "tokens": ["der", "arz\u00b7nei", "sag", ",", "sie", "sei", "selbs", "krank", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "PPER", "VAFIN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "sag, keinen grund die schulen lehren;", "tokens": ["sag", ",", "kei\u00b7nen", "grund", "die", "schu\u00b7len", "leh\u00b7ren", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PIAT", "NN", "ART", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "und sagen sie, man sei betrogen,", "tokens": ["und", "sa\u00b7gen", "sie", ",", "man", "sei", "be\u00b7tro\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "$,", "PIS", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "so antwort du, es sei erlogen.", "tokens": ["so", "ant\u00b7wort", "du", ",", "es", "sei", "er\u00b7lo\u00b7gen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "PPER", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Der gunst sag, sie sei voll betrug,", "tokens": ["Der", "gunst", "sag", ",", "sie", "sei", "voll", "be\u00b7trug", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "PPER", "VAFIN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "dem gl\u00fcck sag, es sei ganz verblindet,", "tokens": ["dem", "gl\u00fcck", "sag", ",", "es", "sei", "ganz", "ver\u00b7blin\u00b7det", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "PPER", "VAFIN", "ADV", "VVPP", "$,"], "meter": "-+---+-+-", "measure": "dactylic.init"}, "line.3": {"text": "der reichtum sag, sie hab nie gnug,", "tokens": ["der", "reich\u00b7tum", "sag", ",", "sie", "hab", "nie", "gnug", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "FM", "FM", "$,", "PPER", "VAFIN", "ADV", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "sag, da\u00df die kunst nicht wol gegr\u00fcndet;", "tokens": ["sag", ",", "da\u00df", "die", "kunst", "nicht", "wol", "ge\u00b7gr\u00fcn\u00b7det", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "KOUS", "ART", "NN", "PTKNEG", "ADV", "VVPP", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.5": {"text": "antworten sie, man sei betrogen,", "tokens": ["ant\u00b7wor\u00b7ten", "sie", ",", "man", "sei", "be\u00b7tro\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "PIS", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "so sag du rund: es ist erlogen.", "tokens": ["so", "sag", "du", "rund", ":", "es", "ist", "er\u00b7lo\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "$.", "PPER", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Der dapferkeit halt dise sprach,", "tokens": ["Der", "dap\u00b7fer\u00b7keit", "halt", "di\u00b7se", "sprach", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PDS", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "da\u00df sie trag selten ein mitleiden,", "tokens": ["da\u00df", "sie", "trag", "sel\u00b7ten", "ein", "mit\u00b7lei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "ADJD", "ART", "ADJA", "$,"], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "sag der natur, da\u00df sie werd schwach", "tokens": ["sag", "der", "na\u00b7tur", ",", "da\u00df", "sie", "werd", "schwach"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "NN", "$,", "KOUS", "PPER", "VAFIN", "ADJD"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "und k\u00f6nd den abgang nicht vermeiden;", "tokens": ["und", "k\u00f6nd", "den", "ab\u00b7gang", "nicht", "ver\u00b7mei\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ART", "NN", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "antworten sie, man sei betrogen,", "tokens": ["ant\u00b7wor\u00b7ten", "sie", ",", "man", "sei", "be\u00b7tro\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "PIS", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "so sag du bald: es ist erlogen.", "tokens": ["so", "sag", "du", "bald", ":", "es", "ist", "er\u00b7lo\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "$.", "PPER", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Der freindschaft zeig an, wie sie mag", "tokens": ["Der", "freind\u00b7schaft", "zeig", "an", ",", "wie", "sie", "mag"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "$,", "PWAV", "PPER", "VMFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "f\u00fcr ihre freind so wenig sorgen,", "tokens": ["f\u00fcr", "ih\u00b7re", "freind", "so", "we\u00b7nig", "sor\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADV", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "und der gerechtigkeit selbs sag,", "tokens": ["und", "der", "ge\u00b7rech\u00b7tig\u00b7keit", "selbs", "sag", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "sie lig gefangen und verborgen;", "tokens": ["sie", "lig", "ge\u00b7fan\u00b7gen", "und", "ver\u00b7bor\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "VVPP", "KON", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "antworten sie, man sei betrogen,", "tokens": ["ant\u00b7wor\u00b7ten", "sie", ",", "man", "sei", "be\u00b7tro\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "PIS", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "so sag du gleich: es ist erlogen.", "tokens": ["so", "sag", "du", "gleich", ":", "es", "ist", "er\u00b7lo\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "$.", "PPER", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Den st\u00e4tten sag, wie treu, glaub, ehr", "tokens": ["Den", "st\u00e4t\u00b7ten", "sag", ",", "wie", "treu", ",", "glaub", ",", "ehr"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct", "word"], "pos": ["ART", "ADJA", "VVFIN", "$,", "PWAV", "ADJD", "$,", "VVFIN", "$,", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "und redlichkeit aus ihnen fliehen,", "tokens": ["und", "red\u00b7lich\u00b7keit", "aus", "ih\u00b7nen", "flie\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "APPR", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "den d\u00f6rfern sag, wie sie so sehr", "tokens": ["den", "d\u00f6r\u00b7fern", "sag", ",", "wie", "sie", "so", "sehr"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "$,", "PWAV", "PPER", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "an grobheit und an irrtum bl\u00fchen;", "tokens": ["an", "grob\u00b7heit", "und", "an", "irr\u00b7tum", "bl\u00fc\u00b7hen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "APPR", "NE", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "und sagen sie: du bist betrogen,", "tokens": ["und", "sa\u00b7gen", "sie", ":", "du", "bist", "be\u00b7tro\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "$.", "PPER", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "so sag du rund: es ist erlogen.", "tokens": ["so", "sag", "du", "rund", ":", "es", "ist", "er\u00b7lo\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "$.", "PPER", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Letztlich die tugend selbs bericht", "tokens": ["Letzt\u00b7lich", "die", "tu\u00b7gend", "selbs", "be\u00b7richt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "ADV", "VVFIN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "(wa du sie anders soltest finden),", "tokens": ["(", "wa", "du", "sie", "an\u00b7ders", "sol\u00b7test", "fin\u00b7den", ")", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PWAV", "PPER", "PPER", "ADV", "VMFIN", "VVINF", "$(", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "da\u00df man mehr ihrer achtet nicht", "tokens": ["da\u00df", "man", "mehr", "ih\u00b7rer", "ach\u00b7tet", "nicht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "ADV", "PPOSAT", "VVFIN", "PTKNEG"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "und sie allein bleib gar dahinden;", "tokens": ["und", "sie", "al\u00b7lein", "bleib", "gar", "da\u00b7hin\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ADV", "VVFIN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "antwortet sie, man sei betrogen,", "tokens": ["ant\u00b7wor\u00b7tet", "sie", ",", "man", "sei", "be\u00b7tro\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "PIS", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "so sag du frei: es ist erlogen.", "tokens": ["so", "sag", "du", "frei", ":", "es", "ist", "er\u00b7lo\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "$.", "PPER", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Wolan, wan du nu mit warheit", "tokens": ["Wo\u00b7lan", ",", "wan", "du", "nu", "mit", "war\u00b7heit"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "$,", "PWAV", "PPER", "ADV", "APPR", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "die welt ganz zornig soltest machen,", "tokens": ["die", "welt", "ganz", "zor\u00b7nig", "sol\u00b7test", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ADJD", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "so kanst du noch auch mit frechheit", "tokens": ["so", "kanst", "du", "noch", "auch", "mit", "frech\u00b7heit"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "ADV", "APPR", "NN"], "meter": "-+-++-+-", "measure": "unknown.measure.tetra"}, "line.4": {"text": "ohn forcht die ganze welt auslachen,", "tokens": ["ohn", "forcht", "die", "gan\u00b7ze", "welt", "aus\u00b7la\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "VVFIN", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "dan wer will, seel, mag dich verklagen,", "tokens": ["dan", "wer", "will", ",", "seel", ",", "mag", "dich", "ver\u00b7kla\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PWS", "VMFIN", "$,", "ADJD", "$,", "VMFIN", "PRF", "VVINF", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.6": {"text": "auch um den kopf die geigen schlagen.", "tokens": ["auch", "um", "den", "kopf", "die", "gei\u00b7gen", "schla\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "ART", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Geh durch die welt, o meine seel,", "tokens": ["Geh", "durch", "die", "welt", ",", "o", "mei\u00b7ne", "seel", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ART", "NN", "$,", "FM", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "der welt undankbarkeit zu sehen,", "tokens": ["der", "welt", "un\u00b7dank\u00b7bar\u00b7keit", "zu", "se\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "sag jedem ohn scheu seinen fehl,", "tokens": ["sag", "je\u00b7dem", "ohn", "scheu", "sei\u00b7nen", "fehl", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "APPR", "ADJD", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "die warheit selbs soll dir beistehen:", "tokens": ["die", "war\u00b7heit", "selbs", "soll", "dir", "bei\u00b7ste\u00b7hen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "kan ja die welt nichts dan betriegen,", "tokens": ["kan", "ja", "die", "welt", "nichts", "dan", "be\u00b7trie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "ART", "NN", "PIS", "ADV", "VVFIN", "$,"], "meter": "---+-+-+-", "measure": "unknown.measure.tri"}, "line.6": {"text": "so hei\u00df sie offentlich rund liegen.", "tokens": ["so", "hei\u00df", "sie", "of\u00b7fent\u00b7lich", "rund", "lie\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "ADJD", "ADJD", "VVFIN", "$."], "meter": "-+-++-++-", "measure": "unknown.measure.penta"}}, "stanza.15": {"line.1": {"text": "Dem hof sag, da\u00df sein pracht und ehr", "tokens": ["Dem", "hof", "sag", ",", "da\u00df", "sein", "pracht", "und", "ehr"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "$,", "KOUS", "PPOSAT", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "wie faul holz unbest\u00e4ndig scheinen;", "tokens": ["wie", "faul", "holz", "un\u00b7be\u00b7st\u00e4n\u00b7dig", "schei\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "ADJD", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "der kirchen sag, was ihre lehr", "tokens": ["der", "kir\u00b7chen", "sag", ",", "was", "ih\u00b7re", "lehr"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "$,", "PRELS", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "gut hei\u00dfet, ihre werk verneinen;", "tokens": ["gut", "hei\u00b7\u00dfet", ",", "ih\u00b7re", "werk", "ver\u00b7nei\u00b7nen", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "$,", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "und sagen sie, du bist betrogen,", "tokens": ["und", "sa\u00b7gen", "sie", ",", "du", "bist", "be\u00b7tro\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "$,", "PPER", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "so sag ohn scham: es ist erlogen.", "tokens": ["so", "sag", "ohn", "scham", ":", "es", "ist", "er\u00b7lo\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "NE", "$.", "PPER", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "Den f\u00fcrsten sag, ihr stand und hab", "tokens": ["Den", "f\u00fcrs\u00b7ten", "sag", ",", "ihr", "stand", "und", "hab"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "VVFIN", "$,", "PPER", "VVFIN", "KON", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "k\u00f6nd nicht ohn andrer hilf lang wehren,", "tokens": ["k\u00f6nd", "nicht", "ohn", "an\u00b7drer", "hilf", "lang", "weh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PTKNEG", "APPR", "ADJA", "NN", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "und da\u00df man pfleg mehr ihre gab,", "tokens": ["und", "da\u00df", "man", "pfleg", "mehr", "ih\u00b7re", "gab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PIS", "VVFIN", "ADV", "PPOSAT", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "dan sie zu loben und zu ehren;", "tokens": ["dan", "sie", "zu", "lo\u00b7ben", "und", "zu", "eh\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "PTKZU", "VVINF", "KON", "PTKZU", "VVINF", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.5": {"text": "und sprechen sie: du bist betrogen,", "tokens": ["und", "spre\u00b7chen", "sie", ":", "du", "bist", "be\u00b7tro\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "$.", "PPER", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "so sag ohn forcht: es ist erlogen.", "tokens": ["so", "sag", "ohn", "forcht", ":", "es", "ist", "er\u00b7lo\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "NN", "$.", "PPER", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.17": {"line.1": {"text": "Den herren sag, die sich beseits", "tokens": ["Den", "her\u00b7ren", "sag", ",", "die", "sich", "be\u00b7seits"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "$,", "PRELS", "PRF", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "in ihren hohen \u00e4mptern sprei\u00dfen,", "tokens": ["in", "ih\u00b7ren", "ho\u00b7hen", "\u00e4mp\u00b7tern", "sprei\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "ADJA", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "da\u00df sie des ehrgeiz und neids", "tokens": ["da\u00df", "sie", "des", "ehr\u00b7geiz", "und", "neids"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "NN", "KON", "NE"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "mehr dan der billichkeit befleissen;", "tokens": ["mehr", "dan", "der", "bil\u00b7lich\u00b7keit", "be\u00b7fleis\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "und sagen sie: du bist betrogen,", "tokens": ["und", "sa\u00b7gen", "sie", ":", "du", "bist", "be\u00b7tro\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "$.", "PPER", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "antwort du rund: es ist erlogen.", "tokens": ["ant\u00b7wort", "du", "rund", ":", "es", "ist", "er\u00b7lo\u00b7gen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "$.", "PPER", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.18": {"line.1": {"text": "Sag denen, welche f\u00fcr der welt", "tokens": ["Sag", "de\u00b7nen", ",", "wel\u00b7che", "f\u00fcr", "der", "welt"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "PDS", "$,", "PRELS", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "mit zeug und kleidern statlich prangen", "tokens": ["mit", "zeug", "und", "klei\u00b7dern", "stat\u00b7lich", "pran\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "VVFIN", "ADJD", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "sie wolten gern dardurch mehr geld", "tokens": ["sie", "wol\u00b7ten", "gern", "dar\u00b7durch", "mehr", "geld"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ADV", "PAV", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "und gr\u00f6\u00dfern dienst und ruhm erlangen;", "tokens": ["und", "gr\u00f6\u00b7\u00dfern", "dienst", "und", "ruhm", "er\u00b7lan\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "antworten sie, man sei betrogen,", "tokens": ["ant\u00b7wor\u00b7ten", "sie", ",", "man", "sei", "be\u00b7tro\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "PIS", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "so antwort du: es ist erlogen.", "tokens": ["so", "ant\u00b7wort", "du", ":", "es", "ist", "er\u00b7lo\u00b7gen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$.", "PPER", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.19": {"line.1": {"text": "Sag, buhlerei sei b\u00f6ser lust,", "tokens": ["Sag", ",", "buh\u00b7le\u00b7rei", "sei", "b\u00f6\u00b7ser", "lust", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADJD", "VAFIN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "sag, ehr m\u00f6g bald verkehret werden,", "tokens": ["sag", ",", "ehr", "m\u00f6g", "bald", "ver\u00b7keh\u00b7ret", "wer\u00b7den", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "NN", "VMFIN", "ADV", "VVPP", "VAINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "sag, sch\u00f6nheit k\u00fcrzlich werd ein wust,", "tokens": ["sag", ",", "sch\u00f6n\u00b7heit", "k\u00fcrz\u00b7lich", "werd", "ein", "wust", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "ADV", "ADJD", "VAFIN", "ART", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "sag, alter neig sich zu der erden;", "tokens": ["sag", ",", "al\u00b7ter", "neig", "sich", "zu", "der", "er\u00b7den", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "ADJA", "VVFIN", "PRF", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "antworten sie, man sei betrogen,", "tokens": ["ant\u00b7wor\u00b7ten", "sie", ",", "man", "sei", "be\u00b7tro\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "PIS", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "so sag du frech: es ist erlogen.", "tokens": ["so", "sag", "du", "frech", ":", "es", "ist", "er\u00b7lo\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "$.", "PPER", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.20": {"line.1": {"text": "Dem rechten sag, es sei voll zank,", "tokens": ["Dem", "rech\u00b7ten", "sag", ",", "es", "sei", "voll", "zank", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "$,", "PPER", "VAFIN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "sag, klugheit pfleg sich zu beth\u00f6ren,", "tokens": ["sag", ",", "klug\u00b7heit", "pfleg", "sich", "zu", "be\u00b7th\u00f6\u00b7ren", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "ADJD", "VVFIN", "PRF", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "der arznei sag, sie sei selbs krank,", "tokens": ["der", "arz\u00b7nei", "sag", ",", "sie", "sei", "selbs", "krank", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "PPER", "VAFIN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "sag, keinen grund die schulen lehren;", "tokens": ["sag", ",", "kei\u00b7nen", "grund", "die", "schu\u00b7len", "leh\u00b7ren", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PIAT", "NN", "ART", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "und sagen sie, man sei betrogen,", "tokens": ["und", "sa\u00b7gen", "sie", ",", "man", "sei", "be\u00b7tro\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "$,", "PIS", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "so antwort du, es sei erlogen.", "tokens": ["so", "ant\u00b7wort", "du", ",", "es", "sei", "er\u00b7lo\u00b7gen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "PPER", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.21": {"line.1": {"text": "Der gunst sag, sie sei voll betrug,", "tokens": ["Der", "gunst", "sag", ",", "sie", "sei", "voll", "be\u00b7trug", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "PPER", "VAFIN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "dem gl\u00fcck sag, es sei ganz verblindet,", "tokens": ["dem", "gl\u00fcck", "sag", ",", "es", "sei", "ganz", "ver\u00b7blin\u00b7det", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "PPER", "VAFIN", "ADV", "VVPP", "$,"], "meter": "-+---+-+-", "measure": "dactylic.init"}, "line.3": {"text": "der reichtum sag, sie hab nie gnug,", "tokens": ["der", "reich\u00b7tum", "sag", ",", "sie", "hab", "nie", "gnug", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "FM", "FM", "$,", "PPER", "VAFIN", "ADV", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "sag, da\u00df die kunst nicht wol gegr\u00fcndet;", "tokens": ["sag", ",", "da\u00df", "die", "kunst", "nicht", "wol", "ge\u00b7gr\u00fcn\u00b7det", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "KOUS", "ART", "NN", "PTKNEG", "ADV", "VVPP", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.5": {"text": "antworten sie, man sei betrogen,", "tokens": ["ant\u00b7wor\u00b7ten", "sie", ",", "man", "sei", "be\u00b7tro\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "PIS", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "so sag du rund: es ist erlogen.", "tokens": ["so", "sag", "du", "rund", ":", "es", "ist", "er\u00b7lo\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "$.", "PPER", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.22": {"line.1": {"text": "Der dapferkeit halt dise sprach,", "tokens": ["Der", "dap\u00b7fer\u00b7keit", "halt", "di\u00b7se", "sprach", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PDS", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "da\u00df sie trag selten ein mitleiden,", "tokens": ["da\u00df", "sie", "trag", "sel\u00b7ten", "ein", "mit\u00b7lei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "ADJD", "ART", "ADJA", "$,"], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "sag der natur, da\u00df sie werd schwach", "tokens": ["sag", "der", "na\u00b7tur", ",", "da\u00df", "sie", "werd", "schwach"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "NN", "$,", "KOUS", "PPER", "VAFIN", "ADJD"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "und k\u00f6nd den abgang nicht vermeiden;", "tokens": ["und", "k\u00f6nd", "den", "ab\u00b7gang", "nicht", "ver\u00b7mei\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ART", "NN", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "antworten sie, man sei betrogen,", "tokens": ["ant\u00b7wor\u00b7ten", "sie", ",", "man", "sei", "be\u00b7tro\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "PIS", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "so sag du bald: es ist erlogen.", "tokens": ["so", "sag", "du", "bald", ":", "es", "ist", "er\u00b7lo\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "$.", "PPER", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.23": {"line.1": {"text": "Der freindschaft zeig an, wie sie mag", "tokens": ["Der", "freind\u00b7schaft", "zeig", "an", ",", "wie", "sie", "mag"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "$,", "PWAV", "PPER", "VMFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "f\u00fcr ihre freind so wenig sorgen,", "tokens": ["f\u00fcr", "ih\u00b7re", "freind", "so", "we\u00b7nig", "sor\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADV", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "und der gerechtigkeit selbs sag,", "tokens": ["und", "der", "ge\u00b7rech\u00b7tig\u00b7keit", "selbs", "sag", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "sie lig gefangen und verborgen;", "tokens": ["sie", "lig", "ge\u00b7fan\u00b7gen", "und", "ver\u00b7bor\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "VVPP", "KON", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "antworten sie, man sei betrogen,", "tokens": ["ant\u00b7wor\u00b7ten", "sie", ",", "man", "sei", "be\u00b7tro\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "PIS", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "so sag du gleich: es ist erlogen.", "tokens": ["so", "sag", "du", "gleich", ":", "es", "ist", "er\u00b7lo\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "$.", "PPER", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.24": {"line.1": {"text": "Den st\u00e4tten sag, wie treu, glaub, ehr", "tokens": ["Den", "st\u00e4t\u00b7ten", "sag", ",", "wie", "treu", ",", "glaub", ",", "ehr"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct", "word"], "pos": ["ART", "ADJA", "VVFIN", "$,", "PWAV", "ADJD", "$,", "VVFIN", "$,", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "und redlichkeit aus ihnen fliehen,", "tokens": ["und", "red\u00b7lich\u00b7keit", "aus", "ih\u00b7nen", "flie\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "APPR", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "den d\u00f6rfern sag, wie sie so sehr", "tokens": ["den", "d\u00f6r\u00b7fern", "sag", ",", "wie", "sie", "so", "sehr"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "$,", "PWAV", "PPER", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "an grobheit und an irrtum bl\u00fchen;", "tokens": ["an", "grob\u00b7heit", "und", "an", "irr\u00b7tum", "bl\u00fc\u00b7hen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "APPR", "NE", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "und sagen sie: du bist betrogen,", "tokens": ["und", "sa\u00b7gen", "sie", ":", "du", "bist", "be\u00b7tro\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "$.", "PPER", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "so sag du rund: es ist erlogen.", "tokens": ["so", "sag", "du", "rund", ":", "es", "ist", "er\u00b7lo\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "$.", "PPER", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.25": {"line.1": {"text": "Letztlich die tugend selbs bericht", "tokens": ["Letzt\u00b7lich", "die", "tu\u00b7gend", "selbs", "be\u00b7richt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "ADV", "VVFIN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "(wa du sie anders soltest finden),", "tokens": ["(", "wa", "du", "sie", "an\u00b7ders", "sol\u00b7test", "fin\u00b7den", ")", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PWAV", "PPER", "PPER", "ADV", "VMFIN", "VVINF", "$(", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "da\u00df man mehr ihrer achtet nicht", "tokens": ["da\u00df", "man", "mehr", "ih\u00b7rer", "ach\u00b7tet", "nicht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "ADV", "PPOSAT", "VVFIN", "PTKNEG"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "und sie allein bleib gar dahinden;", "tokens": ["und", "sie", "al\u00b7lein", "bleib", "gar", "da\u00b7hin\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ADV", "VVFIN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "antwortet sie, man sei betrogen,", "tokens": ["ant\u00b7wor\u00b7tet", "sie", ",", "man", "sei", "be\u00b7tro\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "PIS", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "so sag du frei: es ist erlogen.", "tokens": ["so", "sag", "du", "frei", ":", "es", "ist", "er\u00b7lo\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "$.", "PPER", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.26": {"line.1": {"text": "Wolan, wan du nu mit warheit", "tokens": ["Wo\u00b7lan", ",", "wan", "du", "nu", "mit", "war\u00b7heit"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "$,", "PWAV", "PPER", "ADV", "APPR", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "die welt ganz zornig soltest machen,", "tokens": ["die", "welt", "ganz", "zor\u00b7nig", "sol\u00b7test", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ADJD", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "so kanst du noch auch mit frechheit", "tokens": ["so", "kanst", "du", "noch", "auch", "mit", "frech\u00b7heit"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "ADV", "APPR", "NN"], "meter": "-+-++-+-", "measure": "unknown.measure.tetra"}, "line.4": {"text": "ohn forcht die ganze welt auslachen,", "tokens": ["ohn", "forcht", "die", "gan\u00b7ze", "welt", "aus\u00b7la\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "VVFIN", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "dan wer will, seel, mag dich verklagen,", "tokens": ["dan", "wer", "will", ",", "seel", ",", "mag", "dich", "ver\u00b7kla\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PWS", "VMFIN", "$,", "ADJD", "$,", "VMFIN", "PRF", "VVINF", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.6": {"text": "auch um den kopf die geigen schlagen.", "tokens": ["auch", "um", "den", "kopf", "die", "gei\u00b7gen", "schla\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "ART", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}