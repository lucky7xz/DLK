{"dta.poem.20383": {"metadata": {"author": {"name": "Hofmann von Hofmannswaldau, Christian", "birth": "N.A.", "death": "N.A."}, "title": "Auff das Albinische und Kamperische  \n hochzeit-fest.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1695", "urn": "urn:nbn:de:kobv:b4-200905197751", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Ist lieben seuche/ pest und gifft/", "tokens": ["Ist", "lie\u00b7ben", "seu\u00b7che", "/", "pest", "und", "gifft", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "VVINF", "VVFIN", "$(", "VVFIN", "KON", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das nattern t\u00f6dten kan/ und scorpion entgeistert?", "tokens": ["Das", "nat\u00b7tern", "t\u00f6d\u00b7ten", "kan", "/", "und", "scor\u00b7pi\u00b7on", "ent\u00b7geis\u00b7tert", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVINF", "VMFIN", "$(", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Das gelbe molchen \u00fcbertrifft?", "tokens": ["Das", "gel\u00b7be", "mol\u00b7chen", "\u00fc\u00b7bert\u00b7rifft", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ist lieben raserey/ die die vernunfft bemeistert?", "tokens": ["Ist", "lie\u00b7ben", "ra\u00b7se\u00b7rey", "/", "die", "die", "ver\u00b7nunfft", "be\u00b7meis\u00b7tert", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJA", "NN", "$(", "PRELS", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ein nagend krebs/ der marck und bein frist aus?", "tokens": ["Ein", "na\u00b7gend", "krebs", "/", "der", "marck", "und", "bein", "frist", "aus", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "VVFIN", "$(", "ART", "NN", "KON", "ADV", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Ein wurm/ der aus den stauden edler jugend", "tokens": ["Ein", "wurm", "/", "der", "aus", "den", "stau\u00b7den", "ed\u00b7ler", "ju\u00b7gend"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$(", "ART", "APPR", "ART", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Nicht nur den kern/ die wurtzel rei\u00dft der tugend?", "tokens": ["Nicht", "nur", "den", "kern", "/", "die", "wurt\u00b7zel", "rei\u00dft", "der", "tu\u00b7gend", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "ART", "NN", "$(", "ART", "NN", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Ein feuer/ das in asche/ staub und grau\u00df", "tokens": ["Ein", "feu\u00b7er", "/", "das", "in", "asc\u00b7he", "/", "staub", "und", "grau\u00df"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "$(", "ART", "APPR", "ADJA", "$(", "VVFIN", "KON", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Volckreiche st\u00e4dte leg\u2019t/ und l\u00e4nder st\u00fcrtzt in grund/", "tokens": ["Vol\u00b7ckrei\u00b7che", "st\u00e4d\u00b7te", "leg't", "/", "und", "l\u00e4n\u00b7der", "st\u00fcrtzt", "in", "grund", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "VVFIN", "$(", "KON", "ADV", "VVFIN", "APPR", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Da\u00df itzo wilde buchen stehen/", "tokens": ["Da\u00df", "it\u00b7zo", "wil\u00b7de", "bu\u00b7chen", "ste\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Und seegel-volle maste gehen/", "tokens": ["Und", "see\u00b7gel\u00b7vol\u00b7le", "mas\u00b7te", "ge\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Wo weiland Troja war/ und vormals Tyrus stund?", "tokens": ["Wo", "wei\u00b7land", "Tro\u00b7ja", "war", "/", "und", "vor\u00b7mals", "Ty\u00b7rus", "stund", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "NE", "VAFIN", "$(", "KON", "ADV", "NE", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "So ists! di\u00df w\u00fcrckt der liebe brand.", "tokens": ["So", "ists", "!", "di\u00df", "w\u00fcrckt", "der", "lie\u00b7be", "brand", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "$.", "PDS", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Durch sie flog Sodoma geschwefelt in die l\u00fcffte.", "tokens": ["Durch", "sie", "flog", "So\u00b7do\u00b7ma", "ge\u00b7schwe\u00b7felt", "in", "die", "l\u00fcff\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVFIN", "NN", "VVPP", "APPR", "ART", "ADJA", "$."], "meter": "+-+-+--+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.3": {"text": "Und Loth/ der dort entronnen/ fand", "tokens": ["Und", "Loth", "/", "der", "dort", "ent\u00b7ron\u00b7nen", "/", "fand"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["KON", "NN", "$(", "ART", "ADV", "VVINF", "$(", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Auff seiner tochter schoo\u00df mehr als Gomorrens kl\u00fcffte.", "tokens": ["Auff", "sei\u00b7ner", "toch\u00b7ter", "schoo\u00df", "mehr", "als", "Go\u00b7mor\u00b7rens", "kl\u00fcff\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "PIS", "KOKOM", "NE", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ja Samson mu\u00df/ den Rom doch und Athen", "tokens": ["Ja", "Sam\u00b7son", "mu\u00df", "/", "den", "Rom", "doch", "und", "A\u00b7then"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "NN", "VMFIN", "$(", "ART", "NE", "ADV", "KON", "NE"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Im Hercules zu einen Gotte machte/", "tokens": ["Im", "Her\u00b7cu\u00b7les", "zu", "ei\u00b7nen", "Got\u00b7te", "mach\u00b7te", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPR", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Als Amphale ihn in ihr netze brachte/", "tokens": ["Als", "Am\u00b7pha\u00b7le", "ihn", "in", "ihr", "net\u00b7ze", "brach\u00b7te", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "PPER", "APPR", "PPOSAT", "ADJA", "VVFIN", "$("], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.8": {"text": "Durch Deliden ver\u00e4chtlich untergehn.", "tokens": ["Durch", "De\u00b7li\u00b7den", "ver\u00b7\u00e4cht\u00b7lich", "un\u00b7ter\u00b7gehn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Als GOttes hertzens mann kaum Batseben ersieh\u2019t/", "tokens": ["Als", "Got\u00b7tes", "hert\u00b7zens", "mann", "kaum", "Bat\u00b7se\u00b7ben", "er\u00b7sieh't", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "ADV", "NN", "ADV", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Und er auch aus der flut entglimmet/", "tokens": ["Und", "er", "auch", "aus", "der", "flut", "ent\u00b7glim\u00b7met", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ADV", "APPR", "ART", "NN", "VVFIN", "$("], "meter": "-----+-+-", "measure": "unknown.measure.di"}, "line.11": {"text": "Wird Davids harffe so verstimmet/", "tokens": ["Wird", "Da\u00b7vids", "harf\u00b7fe", "so", "ver\u00b7stim\u00b7met", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NE", "VVFIN", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Da\u00df sie f\u00fcr psalmen spielt ein geiles buhler-lied.", "tokens": ["Da\u00df", "sie", "f\u00fcr", "psal\u00b7men", "spielt", "ein", "gei\u00b7les", "buh\u00b7ler\u00b7lied", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NN", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Wer macht ihm nun nicht selbst den schlu\u00df?", "tokens": ["Wer", "macht", "ihm", "nun", "nicht", "selbst", "den", "schlu\u00df", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "PTKNEG", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df wer den keuschen geist GOtt rein und keusch will ehren/", "tokens": ["Da\u00df", "wer", "den", "keu\u00b7schen", "geist", "Gott", "rein", "und", "keusch", "will", "eh\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PWS", "ART", "ADJA", "NN", "NN", "ADJD", "KON", "ADJD", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der liebe g\u00f6tzen abthun mu\u00df/", "tokens": ["Der", "lie\u00b7be", "g\u00f6t\u00b7zen", "ab\u00b7thun", "mu\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und in der andachts-glut di\u00df g\u00f6ldne kalb zerst\u00f6ren.", "tokens": ["Und", "in", "der", "an\u00b7dachts\u00b7glut", "di\u00df", "g\u00f6ld\u00b7ne", "kalb", "zer\u00b7st\u00f6\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "PDS", "ADJA", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Der Weyrauch/ der in Venus tempel brennt/", "tokens": ["Der", "Wey\u00b7rauch", "/", "der", "in", "Ve\u00b7nus", "tem\u00b7pel", "brennt", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "ART", "APPR", "NE", "NE", "VVFIN", "$("], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Reucht GOtt nicht wohl/ die engel/ die uns dienen/", "tokens": ["Reucht", "Gott", "nicht", "wohl", "/", "die", "en\u00b7gel", "/", "die", "uns", "die\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NN", "PTKNEG", "ADV", "$(", "ART", "NN", "$(", "PRELS", "PPER", "VVINF", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Entfernen sich/ wie f\u00fcr dem rauche bienen.", "tokens": ["Ent\u00b7fer\u00b7nen", "sich", "/", "wie", "f\u00fcr", "dem", "rau\u00b7che", "bie\u00b7nen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "$(", "KOKOM", "APPR", "ART", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Die opffer/ die auch Paphas heilig nennt/", "tokens": ["Die", "opf\u00b7fer", "/", "die", "auch", "Pa\u00b7phas", "hei\u00b7lig", "nennt", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "PRELS", "ADV", "NN", "ADJD", "VVFIN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Sind zu Jerusalem ein stinckend Gottesdienst.", "tokens": ["Sind", "zu", "Je\u00b7ru\u00b7sa\u00b7lem", "ein", "stin\u00b7ckend", "Got\u00b7tes\u00b7dienst", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "NE", "ART", "ADJD", "NN", "$."], "meter": "+-+-+--+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.10": {"text": "Ja die mit brunst sich unterstehen", "tokens": ["Ja", "die", "mit", "brunst", "sich", "un\u00b7ter\u00b7ste\u00b7hen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "ART", "APPR", "VVFIN", "PRF", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "In GOttes heiligthum zu gehen/", "tokens": ["In", "Got\u00b7tes", "hei\u00b7lig\u00b7thum", "zu", "ge\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "NN", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Bekommen fluch zu lohn/ und straffe zu gewinst.", "tokens": ["Be\u00b7kom\u00b7men", "fluch", "zu", "lohn", "/", "und", "straf\u00b7fe", "zu", "ge\u00b7winst", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "PTKZU", "VVINF", "$(", "KON", "VVFIN", "PTKA", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}