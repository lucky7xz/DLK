{"dta.poem.18529": {"metadata": {"author": {"name": "Hofmannswaldau, Christian Hofmann von", "birth": "N.A.", "death": "N.A."}, "title": "Auf den ersten Geburts-tag  \n eines jungen T\u00f6chterleins.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1703", "urn": "urn:nbn:de:kobv:b4-200905199360", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Verzeihe/ theures paar/ da\u00df ich mich untersteh/", "tokens": ["Ver\u00b7zei\u00b7he", "/", "theu\u00b7res", "paar", "/", "da\u00df", "ich", "mich", "un\u00b7ter\u00b7steh", "/"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$(", "FM", "FM", "$(", "KOUS", "PPER", "PRF", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und deiner zarten frucht/ der noch die sprache fehlet/", "tokens": ["Und", "dei\u00b7ner", "zar\u00b7ten", "frucht", "/", "der", "noch", "die", "spra\u00b7che", "feh\u00b7let", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "$(", "ART", "ADV", "ART", "ADJA", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Doch schon mit einer schrifft gleich heut entgegen geh/", "tokens": ["Doch", "schon", "mit", "ei\u00b7ner", "schrifft", "gleich", "heut", "ent\u00b7ge\u00b7gen", "geh", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "PIS", "VVFIN", "ADV", "ADV", "PTKVZ", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Da dieser holde zweig den ersten jahrs-tag zehlet.", "tokens": ["Da", "die\u00b7ser", "hol\u00b7de", "zweig", "den", "ers\u00b7ten", "jahr\u00b7stag", "zeh\u00b7let", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDAT", "ADJA", "NN", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ein kind/ dem so ein haupt zum vater ist erkiest/", "tokens": ["Ein", "kind", "/", "dem", "so", "ein", "haupt", "zum", "va\u00b7ter", "ist", "er\u00b7kiest", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "ART", "ADV", "ART", "NN", "APPRART", "NN", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Das wie Johannes lebt/ das wie Johannes lehret/", "tokens": ["Das", "wie", "Jo\u00b7han\u00b7nes", "lebt", "/", "das", "wie", "Jo\u00b7han\u00b7nes", "leh\u00b7ret", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "KOKOM", "NE", "VVFIN", "$(", "PDS", "KOKOM", "NE", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und dessen Mutter-hertz gleich einer Rahel ist/", "tokens": ["Und", "des\u00b7sen", "Mut\u00b7ter\u00b7hertz", "gleich", "ei\u00b7ner", "Ra\u00b7hel", "ist", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRELAT", "NN", "ADV", "ART", "NN", "VAFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Verdient/ da\u00df man es schon in wieg und windeln ehret.", "tokens": ["Ver\u00b7di\u00b7ent", "/", "da\u00df", "man", "es", "schon", "in", "wieg", "und", "win\u00b7deln", "eh\u00b7ret", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$(", "KOUS", "PIS", "PPER", "ADV", "APPR", "NN", "KON", "VVINF", "VVFIN", "$."], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.9": {"text": "Lie\u00df Rom doch solche pflicht bey seinen kindern zu/", "tokens": ["Lie\u00df", "Rom", "doch", "sol\u00b7che", "pflicht", "bey", "sei\u00b7nen", "kin\u00b7dern", "zu", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "ADV", "PIAT", "NN", "APPR", "PPOSAT", "NN", "PTKZU", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Wenn unter derer haupt ein wunsch ward eingeleget/", "tokens": ["Wenn", "un\u00b7ter", "de\u00b7rer", "haupt", "ein", "wunsch", "ward", "ein\u00b7ge\u00b7le\u00b7get", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "PDS", "NN", "ART", "ADJD", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Zu lehren/ da\u00df ein kind darauff am besten ruh/", "tokens": ["Zu", "leh\u00b7ren", "/", "da\u00df", "ein", "kind", "dar\u00b7auff", "am", "bes\u00b7ten", "ruh", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "$(", "KOUS", "ART", "NN", "PAV", "APPRART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Und da\u00df man nicht zu fr\u00fch ihm heil zu w\u00fcnschen pfleget.", "tokens": ["Und", "da\u00df", "man", "nicht", "zu", "fr\u00fch", "ihm", "heil", "zu", "w\u00fcn\u00b7schen", "pfle\u00b7get", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PIS", "PTKNEG", "PTKA", "ADJD", "PPER", "ADJD", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Ja ward mir \u00fcberdi\u00df zu wohlbewuster zeit", "tokens": ["Ja", "ward", "mir", "\u00fc\u00b7ber\u00b7di\u00df", "zu", "wohl\u00b7be\u00b7wus\u00b7ter", "zeit"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "VAFIN", "PPER", "ADV", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Ein holder krantz verehrt durch dieser Tochter h\u00e4nde/", "tokens": ["Ein", "hol\u00b7der", "krantz", "ver\u00b7ehrt", "durch", "die\u00b7ser", "Toch\u00b7ter", "h\u00e4n\u00b7de", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVPP", "APPR", "PDAT", "NN", "ADJA", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "So nehm ich/ wie mich deucht/ mit recht gelegenheit/", "tokens": ["So", "nehm", "ich", "/", "wie", "mich", "deucht", "/", "mit", "recht", "ge\u00b7le\u00b7gen\u00b7heit", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$(", "PWAV", "PPER", "VVFIN", "$(", "APPR", "ADJD", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Da\u00df ich ihr einen krantz von dichter-blumen sende.", "tokens": ["Da\u00df", "ich", "ihr", "ei\u00b7nen", "krantz", "von", "dich\u00b7ter\u00b7blu\u00b7men", "sen\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "ART", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Ich winde zwar nicht viel von lob und r\u00fchmen ein;", "tokens": ["Ich", "win\u00b7de", "zwar", "nicht", "viel", "von", "lob", "und", "r\u00fch\u00b7men", "ein", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PTKNEG", "ADV", "APPR", "NN", "KON", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Doch seh ich nur im geist ihr k\u00fcnfftiges erziehen/", "tokens": ["Doch", "seh", "ich", "nur", "im", "geist", "ihr", "k\u00fcnff\u00b7ti\u00b7ges", "er\u00b7zie\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "APPRART", "NN", "PPOSAT", "ADJA", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "So k\u00f6nnen allbereit zwey T\u00f6chter zeugen seyn/", "tokens": ["So", "k\u00f6n\u00b7nen", "all\u00b7be\u00b7reit", "zwey", "T\u00f6ch\u00b7ter", "zeu\u00b7gen", "seyn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ADV", "CARD", "NN", "VVFIN", "VAINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Da\u00df auf dem Dornenfeld die sch\u00f6nsten rosen bl\u00fchen.", "tokens": ["Da\u00df", "auf", "dem", "Dor\u00b7nen\u00b7feld", "die", "sch\u00f6ns\u00b7ten", "ro\u00b7sen", "bl\u00fc\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "ART", "NN", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Wir loben noch die kunst und wunder-volle that/", "tokens": ["Wir", "lo\u00b7ben", "noch", "die", "kunst", "und", "wun\u00b7der\u00b7vol\u00b7le", "that", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN", "KON", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Die des Homeri werck in eine nu\u00df verstecket;", "tokens": ["Die", "des", "Ho\u00b7me\u00b7ri", "werck", "in", "ei\u00b7ne", "nu\u00df", "ver\u00b7ste\u00b7cket", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NE", "NN", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "+-+--+-+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.23": {"text": "Man r\u00fchmt Alumni flei\u00df/ der so geschrieben hat/", "tokens": ["Man", "r\u00fchmt", "A\u00b7lum\u00b7ni", "flei\u00df", "/", "der", "so", "ge\u00b7schrie\u00b7ben", "hat", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "NE", "VVFIN", "$(", "ART", "ADV", "VVPP", "VAFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Da\u00df hundert w\u00f6rter offt ein pfennig hat bedecket:", "tokens": ["Da\u00df", "hun\u00b7dert", "w\u00f6r\u00b7ter", "offt", "ein", "pfen\u00b7nig", "hat", "be\u00b7de\u00b7cket", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "CARD", "NN", "ADV", "ART", "NN", "VAFIN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Euch aber geht solch lob vielmehr/ hochwerthen/ an/", "tokens": ["Euch", "a\u00b7ber", "geht", "solch", "lob", "viel\u00b7mehr", "/", "hoch\u00b7wert\u00b7hen", "/", "an", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "PIAT", "NN", "ADV", "$(", "ADJA", "$(", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Die ihr den glaubens-grund/ der Christen bestes wissen/", "tokens": ["Die", "ihr", "den", "glau\u00b7bens\u00b7grund", "/", "der", "Chris\u00b7ten", "bes\u00b7tes", "wis\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ART", "NN", "$(", "ART", "NN", "ADJA", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Den ein erwachsner offt nicht leicht begreiffen kan/", "tokens": ["Den", "ein", "er\u00b7wachs\u00b7ner", "offt", "nicht", "leicht", "be\u00b7greif\u00b7fen", "kan", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "ADJA", "ADV", "PTKNEG", "ADJD", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Auf kinder-hertzen habt so wei\u00dflich abgerissen.", "tokens": ["Auf", "kin\u00b7der\u00b7hert\u00b7zen", "habt", "so", "wei\u00df\u00b7lich", "ab\u00b7ge\u00b7ris\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VAFIN", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Und gleiche hoffnung giebt auch diese j\u00fcngste frucht/", "tokens": ["Und", "glei\u00b7che", "hoff\u00b7nung", "giebt", "auch", "die\u00b7se", "j\u00fcngs\u00b7te", "frucht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "VVFIN", "ADV", "PDAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "Der selbst die anmuth hat ihr ebenbild geschencket.", "tokens": ["Der", "selbst", "die", "an\u00b7muth", "hat", "ihr", "e\u00b7ben\u00b7bild", "ge\u00b7schen\u00b7cket", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ART", "NN", "VAFIN", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Jhr habet schon ihr wohl und bestes heil gesucht/", "tokens": ["Ihr", "ha\u00b7bet", "schon", "ihr", "wohl", "und", "bes\u00b7tes", "heil", "ge\u00b7sucht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "PPER", "ADV", "KON", "ADJA", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Weil ihr durch beten l\u00e4ngst den ersten grund gesencket.", "tokens": ["Weil", "ihr", "durch", "be\u00b7ten", "l\u00e4ngst", "den", "ers\u00b7ten", "grund", "ge\u00b7sen\u00b7cket", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "VVFIN", "ADV", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "Zwar Sparta badete die kinder gar im wein/", "tokens": ["Zwar", "Spar\u00b7ta", "ba\u00b7de\u00b7te", "die", "kin\u00b7der", "gar", "im", "wein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NE", "VVFIN", "ART", "NN", "ADV", "APPRART", "NN", "$("], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.34": {"text": "Doch eures kindes bad hat dieses \u00fcberwogen/", "tokens": ["Doch", "eu\u00b7res", "kin\u00b7des", "bad", "hat", "die\u00b7ses", "\u00fc\u00b7ber\u00b7wo\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "NE", "VAFIN", "PDS", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "Denn Heyden kleidte man in g\u00f6tzen-kleider ein/", "tokens": ["Denn", "Hey\u00b7den", "kleid\u00b7te", "man", "in", "g\u00f6t\u00b7zen\u00b7klei\u00b7der", "ein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "PIS", "APPR", "ADJA", "ART", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "Da eure tochter hier hat Christum angezogen.", "tokens": ["Da", "eu\u00b7re", "toch\u00b7ter", "hier", "hat", "Chris\u00b7tum", "an\u00b7ge\u00b7zo\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "ADV", "VAFIN", "NE", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "Wohlan so bl\u00fche denn du hofnung-volles kind", "tokens": ["Wo\u00b7hlan", "so", "bl\u00fc\u00b7he", "denn", "du", "hof\u00b7nung\u00b7vol\u00b7les", "kind"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "ADJA", "KON", "PPER", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.38": {"text": "Zu deines GOttes ruhm/ zu deiner eltern freude.", "tokens": ["Zu", "dei\u00b7nes", "Got\u00b7tes", "ruhm", "/", "zu", "dei\u00b7ner", "el\u00b7tern", "freu\u00b7de", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NN", "$(", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.39": {"text": "Sey gegen tugenden einst so wie sie gesinnt.", "tokens": ["Sey", "ge\u00b7gen", "tu\u00b7gen\u00b7den", "einst", "so", "wie", "sie", "ge\u00b7sinnt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "NN", "ADV", "ADV", "KOKOM", "PPER", "VVPP", "$."], "meter": "+--+--+--+-+", "measure": "dactylic.tri.plus"}, "line.40": {"text": "Bleib mit den Schwestern stets ihr schertz und augen-weyde.", "tokens": ["Bleib", "mit", "den", "Schwes\u00b7tern", "stets", "ihr", "schertz", "und", "au\u00b7gen\u00b7wey\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "VVFIN", "PPER", "ADJD", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.41": {"text": "Dir aber w\u00fcnsche ich zu letzt/ hochtheures Paar/", "tokens": ["Dir", "a\u00b7ber", "w\u00fcn\u00b7sche", "ich", "zu", "letzt", "/", "hoch\u00b7theu\u00b7res", "Paar", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "PPER", "APPR", "ADV", "$(", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.42": {"text": "Da\u00df du dein wohlergehn sehr lange m\u00f6gst geniessen/", "tokens": ["Da\u00df", "du", "dein", "woh\u00b7ler\u00b7gehn", "sehr", "lan\u00b7ge", "m\u00f6gst", "ge\u00b7nies\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "VVFIN", "ADV", "ADV", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.43": {"text": "Und/ stellet k\u00fcnfftig sich noch gr\u00f6sser seegen dar/", "tokens": ["Und", "/", "stel\u00b7let", "k\u00fcnff\u00b7tig", "sich", "noch", "gr\u00f6s\u00b7ser", "see\u00b7gen", "dar", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$(", "VVFIN", "ADJD", "PRF", "ADV", "ADJD", "VVFIN", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.44": {"text": "Da\u00df aus drey Gratien neun Musen werden m\u00fcssen.", "tokens": ["Da\u00df", "aus", "drey", "Gra\u00b7ti\u00b7en", "neun", "Mu\u00b7sen", "wer\u00b7den", "m\u00fcs\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "CARD", "NN", "CARD", "NN", "VAINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}