{"dta.poem.19630": {"metadata": {"author": {"name": "Meyer, Conrad Ferdinand", "birth": "N.A.", "death": "N.A."}, "title": "Das Reiterlein.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1882", "urn": "urn:nbn:de:kobv:b4-200905193933", "language": ["de:0.99"], "booktitle": "Meyer, Conrad Ferdinand: Gedichte. Leipzig, 1882."}, "poem": {"stanza.1": {"line.1": {"text": "Das B\u00e4chlein nimmt nach der Loire den Gang,", "tokens": ["Das", "B\u00e4ch\u00b7lein", "nimmt", "nach", "der", "Loi\u00b7re", "den", "Gang", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "An beiden Seiten", "tokens": ["An", "bei\u00b7den", "Sei\u00b7ten"], "token_info": ["word", "word", "word"], "pos": ["APPR", "PIAT", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.3": {"text": "Auf und ab, die Ufer entlang", "tokens": ["Auf", "und", "ab", ",", "die", "U\u00b7fer", "ent\u00b7lang"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "KON", "PTKVZ", "$,", "ART", "NN", "APPO"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Sp\u00e4hn sie und reiten.", "tokens": ["Sp\u00e4hn", "sie", "und", "rei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "KON", "VVFIN", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.5": {"text": "Sie sind sich so nahe! Sie sind sich so fern!", "tokens": ["Sie", "sind", "sich", "so", "na\u00b7he", "!", "Sie", "sind", "sich", "so", "fern", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PRF", "ADV", "ADJD", "$.", "PPER", "VAFIN", "PRF", "ADV", "ADJD", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.6": {"text": "\u201ebon jour! meine Herrn!\u201c", "tokens": ["\u201e", "bon", "jour", "!", "mei\u00b7ne", "Herrn", "!", "\u201c"], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["$(", "ADV", "NE", "$.", "PPOSAT", "NN", "$.", "$("], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.7": {"text": "Gr\u00fc\u00dft keck eine Stimme.", "tokens": ["Gr\u00fc\u00dft", "keck", "ei\u00b7ne", "Stim\u00b7me", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.2": {"line.1": {"text": "Ein feurig, unb\u00e4ndig Reiterlein", "tokens": ["Ein", "feu\u00b7rig", ",", "un\u00b7b\u00e4n\u00b7dig", "Rei\u00b7ter\u00b7lein"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ART", "ADJD", "$,", "ADJD", "NN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Springt ab behende,", "tokens": ["Springt", "ab", "be\u00b7hen\u00b7de", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ADJA", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.3": {"text": "Setzt rechts ein Bein und links ein Bein", "tokens": ["Setzt", "rechts", "ein", "Bein", "und", "links", "ein", "Bein"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "ART", "NN", "KON", "ADV", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "In beide Gel\u00e4nde:", "tokens": ["In", "bei\u00b7de", "Ge\u00b7l\u00e4n\u00b7de", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.5": {"text": "\u201egro\u00df ist der Sonne Glut \u2014", "tokens": ["\u201e", "gro\u00df", "ist", "der", "Son\u00b7ne", "Glut"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "VAFIN", "ART", "NN", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Herrn, meint Ihr's gut,", "tokens": ["Herrn", ",", "meint", "Ih\u00b7r's", "gut", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "PIS", "ADJD", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.7": {"text": "Schafft eins zu trinken!\u201c", "tokens": ["Schafft", "eins", "zu", "trin\u00b7ken", "!", "\u201c"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PIS", "PTKZU", "VVINF", "$.", "$("], "meter": "---+-", "measure": "unknown.measure.single"}}, "stanza.3": {"line.1": {"text": "Rechts kommt ein Pokal und links ein Pokal", "tokens": ["Rechts", "kommt", "ein", "Po\u00b7kal", "und", "links", "ein", "Po\u00b7kal"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "KON", "ADV", "ART", "NN"], "meter": "----+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Von verschiedener Helle,", "tokens": ["Von", "ver\u00b7schie\u00b7de\u00b7ner", "Hel\u00b7le", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.3": {"text": "Der: sch\u00e4umender Champagnerstrahl", "tokens": ["Der", ":", "sch\u00e4u\u00b7men\u00b7der", "Cham\u00b7pag\u00b7ner\u00b7strahl"], "token_info": ["word", "punct", "word", "word"], "pos": ["ART", "$.", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der andere: Purpurwelle \u2014", "tokens": ["Der", "an\u00b7de\u00b7re", ":", "Pur\u00b7pur\u00b7wel\u00b7le"], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["ART", "ADJA", "$.", "NN", "$("], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "\u201ekatholik? Calvinist?", "tokens": ["\u201e", "ka\u00b7tho\u00b7lik", "?", "Cal\u00b7vi\u00b7nist", "?"], "token_info": ["punct", "word", "punct", "word", "punct"], "pos": ["$(", "VVIMP", "$.", "NN", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.6": {"text": "Hier ein Christ! Dort ein Christ!\u201c", "tokens": ["Hier", "ein", "Christ", "!", "Dort", "ein", "Christ", "!", "\u201c"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "ART", "NN", "$.", "ADV", "ART", "NN", "$.", "$("], "meter": "---+-+", "measure": "unknown.measure.di"}, "line.7": {"text": "Er schl\u00fcrft aus beiden Bechern.", "tokens": ["Er", "schl\u00fcrft", "aus", "bei\u00b7den", "Be\u00b7chern", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "\u201emit streitender Theologie", "tokens": ["\u201e", "mit", "strei\u00b7ten\u00b7der", "Theo\u00b7lo\u00b7gie"], "token_info": ["punct", "word", "word", "word"], "pos": ["$(", "APPR", "ADJA", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Mach' ich mir nichts zu schaffen,", "tokens": ["Mach'", "ich", "mir", "nichts", "zu", "schaf\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "PIS", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Den Guisen \u00fcberla\u00df ich sie,", "tokens": ["Den", "Gui\u00b7sen", "\u00fc\u00b7berl\u00b7a\u00df", "ich", "sie", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Den Weibern und den Pfaffen!", "tokens": ["Den", "Wei\u00b7bern", "und", "den", "Pfaf\u00b7fen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Pred'gerrock? Me\u00dfgewand?", "tokens": ["Pre\u00b7d'\u00b7ger\u00b7rock", "?", "Me\u00df\u00b7ge\u00b7wand", "?"], "token_info": ["word", "punct", "word", "punct"], "pos": ["NE", "$.", "NN", "$."], "meter": "+---+-+", "measure": "dactylic.init"}, "line.6": {"text": "Stich und Schu\u00df! Mord und Brand!", "tokens": ["Stich", "und", "Schu\u00df", "!", "Mord", "und", "Brand", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "KON", "NN", "$.", "NN", "KON", "NN", "$."], "meter": "+-++-+", "measure": "unknown.measure.tetra"}, "line.7": {"text": "Ins Meer geschwemmte Leichen!", "tokens": ["Ins", "Meer", "ge\u00b7schwemm\u00b7te", "Lei\u00b7chen", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Bekennt mir, Herren, frei und frank:", "tokens": ["Be\u00b7kennt", "mir", ",", "Her\u00b7ren", ",", "frei", "und", "frank", ":"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "NN", "$,", "ADJD", "KON", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wie thut Ihr, wann Ihr d\u00fcrstet?", "tokens": ["Wie", "thut", "Ihr", ",", "wann", "Ihr", "d\u00fcrs\u00b7tet", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "$,", "PWAV", "PPER", "VMFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Ihr setzt Euch rittlings auf die Bank", "tokens": ["Ihr", "setzt", "Euch", "ritt\u00b7lings", "auf", "die", "Bank"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und ruft nach Wein und b\u00fcrstet!", "tokens": ["Und", "ruft", "nach", "Wein", "und", "b\u00fcrs\u00b7tet", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "NN", "KON", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Zug und Schluck! Schluck und Zug!", "tokens": ["Zug", "und", "Schluck", "!", "Schluck", "und", "Zug", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "$.", "NN", "KON", "NN", "$."], "meter": "+-++-+", "measure": "unknown.measure.tetra"}, "line.6": {"text": "Noch ein Trunk! Nie genug!", "tokens": ["Noch", "ein", "Trunk", "!", "Nie", "ge\u00b7nug", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "$.", "ADV", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Die Einen wie die Andern.", "tokens": ["Die", "Ei\u00b7nen", "wie", "die", "An\u00b7dern", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KOKOM", "ART", "ADJA", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Genie\u00dft Ihr wonn'ge Minnelust", "tokens": ["Ge\u00b7nie\u00dft", "Ihr", "wonn'\u00b7ge", "Min\u00b7ne\u00b7lust"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Nach Dogmen oder Schulen?", "tokens": ["Nach", "Dog\u00b7men", "o\u00b7der", "Schu\u00b7len", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Kost alle nicht Ihr Brust an Brust", "tokens": ["Kost", "al\u00b7le", "nicht", "Ihr", "Brust", "an", "Brust"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "PIS", "PTKNEG", "PPOSAT", "NN", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mit Euren trauten Buhlen?", "tokens": ["Mit", "Eu\u00b7ren", "trau\u00b7ten", "Buh\u00b7len", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Th\u00f6rt Ihr nicht? Tr\u00fcgt Ihr nicht?", "tokens": ["Th\u00f6rt", "Ihr", "nicht", "?", "Tr\u00fcgt", "Ihr", "nicht", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKNEG", "$.", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Schw\u00f6rt Ihr nicht? L\u00fcgt Ihr nicht?", "tokens": ["Schw\u00f6rt", "Ihr", "nicht", "?", "L\u00fcgt", "Ihr", "nicht", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKNEG", "$.", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Die Einen wie die Andern.", "tokens": ["Die", "Ei\u00b7nen", "wie", "die", "An\u00b7dern", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KOKOM", "ART", "ADJA", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Drum lassen wir auf sich bestehn", "tokens": ["Drum", "las\u00b7sen", "wir", "auf", "sich", "be\u00b7stehn"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "PPER", "APPR", "PRF", "VVINF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Lehren die uns trennten,", "tokens": ["Die", "Leh\u00b7ren", "die", "uns", "trenn\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Da wir erbaulich einig gehn", "tokens": ["Da", "wir", "er\u00b7bau\u00b7lich", "ei\u00b7nig", "gehn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADJD", "ADJD", "VVINF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "In allen Elementen:", "tokens": ["In", "al\u00b7len", "E\u00b7le\u00b7men\u00b7ten", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "$."], "meter": "-+--+--", "measure": "iambic.di.relaxed"}, "line.5": {"text": "Erntefest! Winzertanz!", "tokens": ["Ern\u00b7te\u00b7fest", "!", "Win\u00b7zer\u00b7tanz", "!"], "token_info": ["word", "punct", "word", "punct"], "pos": ["NE", "$.", "NN", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.6": {"text": "Aehrenkranz! Traubenkranz!", "tokens": ["A\u00b7eh\u00b7ren\u00b7kranz", "!", "Trau\u00b7ben\u00b7kranz", "!"], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$.", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.7": {"text": "Feldruhm und edle Waffen!", "tokens": ["Feld\u00b7ruhm", "und", "ed\u00b7le", "Waf\u00b7fen", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Spricht's und es f\u00e4hrt ein elektrischer Schlag", "tokens": ["Spricht's", "und", "es", "f\u00e4hrt", "ein", "e\u00b7lekt\u00b7ri\u00b7scher", "Schlag"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "KON", "PPER", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Rundum und setzt Alles in Flammen:", "tokens": ["Run\u00b7dum", "und", "setzt", "Al\u00b7les", "in", "Flam\u00b7men", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "VVFIN", "PIS", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Frankreich hoch! Freudetag!", "tokens": ["Fran\u00b7kreich", "hoch", "!", "Freu\u00b7de\u00b7tag", "!"], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["NE", "ADJD", "$.", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Heut w\u00e4chst es zusammen!", "tokens": ["Heut", "w\u00e4chst", "es", "zu\u00b7sam\u00b7men", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.5": {"text": "Sie springen ins Wasser, sie waten im Flu\u00df,", "tokens": ["Sie", "sprin\u00b7gen", "ins", "Was\u00b7ser", ",", "sie", "wa\u00b7ten", "im", "Flu\u00df", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "$,", "PPER", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.6": {"text": "Sie spitzen die b\u00e4rtigen Lippen zum Ku\u00df,", "tokens": ["Sie", "spit\u00b7zen", "die", "b\u00e4r\u00b7ti\u00b7gen", "Lip\u00b7pen", "zum", "Ku\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "APPRART", "NN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.7": {"text": "Sie fallen sich all in die Arme.", "tokens": ["Sie", "fal\u00b7len", "sich", "all", "in", "die", "Ar\u00b7me", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "PIAT", "APPR", "ART", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.9": {"line.1": {"text": "Der Kleine dr\u00fcckt und k\u00fc\u00dft und herzt", "tokens": ["Der", "Klei\u00b7ne", "dr\u00fcckt", "und", "k\u00fc\u00dft", "und", "herzt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "VVFIN", "KON", "VVFIN", "KON", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sie alle wie alte Bekannte.", "tokens": ["Sie", "al\u00b7le", "wie", "al\u00b7te", "Be\u00b7kann\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PIS", "KOKOM", "ADJA", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "\u201ewie aber, Herren, steht es,\u201c scherzt", "tokens": ["\u201e", "wie", "a\u00b7ber", ",", "Her\u00b7ren", ",", "steht", "es", ",", "\u201c", "scherzt"], "token_info": ["punct", "word", "word", "punct", "word", "punct", "word", "word", "punct", "punct", "word"], "pos": ["$(", "PWAV", "ADV", "$,", "NN", "$,", "VVFIN", "PPER", "$,", "$(", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Er, \u201emit dem Proviante?", "tokens": ["Er", ",", "\u201e", "mit", "dem", "Pro\u00b7vi\u00b7an\u00b7te", "?"], "token_info": ["word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "$(", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Alles her! Fleisch oder Fisch!", "tokens": ["Al\u00b7les", "her", "!", "Fleisch", "o\u00b7der", "Fisch", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIS", "PTKVZ", "$.", "NN", "KON", "NN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.6": {"text": "Ihr seid geladen heut zu Tisch", "tokens": ["Ihr", "seid", "ge\u00b7la\u00b7den", "heut", "zu", "Tisch"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "VVPP", "ADV", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Bei Heinrich von Navarra.\u201c", "tokens": ["Bei", "Hein\u00b7rich", "von", "Na\u00b7var\u00b7ra", ".", "\u201c"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "NE", "APPR", "NE", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}}}}