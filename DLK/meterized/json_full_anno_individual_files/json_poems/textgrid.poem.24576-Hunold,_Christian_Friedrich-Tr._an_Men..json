{"textgrid.poem.24576": {"metadata": {"author": {"name": "Hunold, Christian Friedrich", "birth": "N.A.", "death": "N.A."}, "title": "Tr. an Men.", "genre": "verse", "period": "N.A.", "pub_year": 1701, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ich liebe blo\u00df ein Hertz/ das tugendhafft und rein/", "tokens": ["Ich", "lie\u00b7be", "blo\u00df", "ein", "Hertz", "/", "das", "tu\u00b7gend\u00b7hafft", "und", "rein", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN", "$(", "ART", "NN", "KON", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "So kan die Liebe wohl erlaubt und edel seyn.", "tokens": ["So", "kan", "die", "Lie\u00b7be", "wohl", "er\u00b7laubt", "und", "e\u00b7del", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "NN", "ADV", "VVPP", "KON", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Di\u00df was man Wollust nennt/kan uns zuletzt betr\u00fcben/", "tokens": ["Di\u00df", "was", "man", "Wol\u00b7lust", "nennt", "/", "kan", "uns", "zu\u00b7letzt", "be\u00b7tr\u00fc\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PRELS", "PIS", "NN", "VVFIN", "$(", "VMFIN", "PPER", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Hein dieses nun bey dir/mein wehrter H -- lieben:", "tokens": ["Hein", "die\u00b7ses", "nun", "bey", "dir", "/", "mein", "wehr\u00b7ter", "H", "lie\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PDAT", "ADV", "APPR", "PPER", "$(", "PPOSAT", "NN", "XY", "$(", "VVINF", "$."], "meter": "-+--+--+-+--+", "measure": "amphibrach.tri.plus"}, "line.5": {"text": "So pflicht ich also fort der sch\u00f6nen Meinung bey.", "tokens": ["So", "pflicht", "ich", "al\u00b7so", "fort", "der", "sch\u00f6\u00b7nen", "Mei\u00b7nung", "bey", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "PTKVZ", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Da\u00df meine Liebe nichts als eine Freundschafft sey", "tokens": ["Da\u00df", "mei\u00b7ne", "Lie\u00b7be", "nichts", "als", "ei\u00b7ne", "Freund\u00b7schafft", "sey"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPOSAT", "NN", "PIS", "KOKOM", "ART", "NN", "VAFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Bekenn ich dir hierdurch. Nicht Amors Lumpen Sachen/", "tokens": ["Be\u00b7kenn", "ich", "dir", "hier\u00b7durch", ".", "Nicht", "A\u00b7mors", "Lum\u00b7pen", "Sa\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "PAV", "$.", "PTKNEG", "NE", "NN", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Blo\u00df Tugend und Verstand kan mich entz\u00fcndet machen.", "tokens": ["Blo\u00df", "Tu\u00b7gend", "und", "Ver\u00b7stand", "kan", "mich", "ent\u00b7z\u00fcn\u00b7det", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "KON", "NN", "VMFIN", "PPER", "VVFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Und also/wehrter Freund/seh ich es wei\u00dflich an/", "tokens": ["Und", "al\u00b7so", "/", "wehr\u00b7ter", "Freund", "/", "seh", "ich", "es", "wei\u00df\u00b7lich", "an", "/"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$(", "ADJA", "NN", "$(", "VVFIN", "PPER", "PPER", "ADJD", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Da\u00df das/was ich geliebt/mich wieder lieben kan.", "tokens": ["Da\u00df", "das", "/", "was", "ich", "ge\u00b7liebt", "/", "mich", "wie\u00b7der", "lie\u00b7ben", "kan", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "$(", "PWS", "PPER", "VVPP", "$(", "PPER", "ADV", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Komm auf ein --- her/wilst du was weiter wissen?", "tokens": ["Komm", "auf", "ein", "her", "/", "wilst", "du", "was", "wei\u00b7ter", "wis\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "$(", "PTKVZ", "$(", "VMFIN", "PPER", "PIS", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Bey einen Gla\u00dfgen Wein wird dich von Hertzen k\u00f6ssen.", "tokens": ["Bey", "ei\u00b7nen", "Gla\u00df\u00b7gen", "Wein", "wird", "dich", "von", "Hert\u00b7zen", "k\u00f6s\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "VAFIN", "PRF", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Ich liebe blo\u00df ein Hertz/ das tugendhafft und rein/", "tokens": ["Ich", "lie\u00b7be", "blo\u00df", "ein", "Hertz", "/", "das", "tu\u00b7gend\u00b7hafft", "und", "rein", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN", "$(", "ART", "NN", "KON", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "So kan die Liebe wohl erlaubt und edel seyn.", "tokens": ["So", "kan", "die", "Lie\u00b7be", "wohl", "er\u00b7laubt", "und", "e\u00b7del", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "NN", "ADV", "VVPP", "KON", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Di\u00df was man Wollust nennt/kan uns zuletzt betr\u00fcben/", "tokens": ["Di\u00df", "was", "man", "Wol\u00b7lust", "nennt", "/", "kan", "uns", "zu\u00b7letzt", "be\u00b7tr\u00fc\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PRELS", "PIS", "NN", "VVFIN", "$(", "VMFIN", "PPER", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Hein dieses nun bey dir/mein wehrter H -- lieben:", "tokens": ["Hein", "die\u00b7ses", "nun", "bey", "dir", "/", "mein", "wehr\u00b7ter", "H", "lie\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PDAT", "ADV", "APPR", "PPER", "$(", "PPOSAT", "NN", "XY", "$(", "VVINF", "$."], "meter": "-+--+--+-+--+", "measure": "amphibrach.tri.plus"}, "line.5": {"text": "So pflicht ich also fort der sch\u00f6nen Meinung bey.", "tokens": ["So", "pflicht", "ich", "al\u00b7so", "fort", "der", "sch\u00f6\u00b7nen", "Mei\u00b7nung", "bey", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "PTKVZ", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Da\u00df meine Liebe nichts als eine Freundschafft sey", "tokens": ["Da\u00df", "mei\u00b7ne", "Lie\u00b7be", "nichts", "als", "ei\u00b7ne", "Freund\u00b7schafft", "sey"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPOSAT", "NN", "PIS", "KOKOM", "ART", "NN", "VAFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Bekenn ich dir hierdurch. Nicht Amors Lumpen Sachen/", "tokens": ["Be\u00b7kenn", "ich", "dir", "hier\u00b7durch", ".", "Nicht", "A\u00b7mors", "Lum\u00b7pen", "Sa\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "PAV", "$.", "PTKNEG", "NE", "NN", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Blo\u00df Tugend und Verstand kan mich entz\u00fcndet machen.", "tokens": ["Blo\u00df", "Tu\u00b7gend", "und", "Ver\u00b7stand", "kan", "mich", "ent\u00b7z\u00fcn\u00b7det", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "KON", "NN", "VMFIN", "PPER", "VVFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Und also/wehrter Freund/seh ich es wei\u00dflich an/", "tokens": ["Und", "al\u00b7so", "/", "wehr\u00b7ter", "Freund", "/", "seh", "ich", "es", "wei\u00df\u00b7lich", "an", "/"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$(", "ADJA", "NN", "$(", "VVFIN", "PPER", "PPER", "ADJD", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Da\u00df das/was ich geliebt/mich wieder lieben kan.", "tokens": ["Da\u00df", "das", "/", "was", "ich", "ge\u00b7liebt", "/", "mich", "wie\u00b7der", "lie\u00b7ben", "kan", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "$(", "PWS", "PPER", "VVPP", "$(", "PPER", "ADV", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Komm auf ein --- her/wilst du was weiter wissen?", "tokens": ["Komm", "auf", "ein", "her", "/", "wilst", "du", "was", "wei\u00b7ter", "wis\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "$(", "PTKVZ", "$(", "VMFIN", "PPER", "PIS", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Bey einen Gla\u00dfgen Wein wird dich von Hertzen k\u00f6ssen.", "tokens": ["Bey", "ei\u00b7nen", "Gla\u00df\u00b7gen", "Wein", "wird", "dich", "von", "Hert\u00b7zen", "k\u00f6s\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "VAFIN", "PRF", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}