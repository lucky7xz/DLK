{"textgrid.poem.57498": {"metadata": {"author": {"name": "Gottsched, Johann Christoph", "birth": "N.A.", "death": "N.A."}, "title": "Als ein geschickter Rechtsgelehrter zu Halle 1730 den Doctorhut erhielt", "genre": "verse", "period": "N.A.", "pub_year": 1733, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wie freudig h\u00f6r ich doch, vertrautgeliebter Freund!", "tokens": ["Wie", "freu\u00b7dig", "h\u00f6r", "ich", "doch", ",", "ver\u00b7traut\u00b7ge\u00b7lieb\u00b7ter", "Freund", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VVFIN", "PPER", "ADV", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Da\u00df dein gelehrtes Haupt im Doctorhut erscheint;", "tokens": ["Da\u00df", "dein", "ge\u00b7lehr\u00b7tes", "Haupt", "im", "Doc\u00b7tor\u00b7hut", "er\u00b7scheint", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "ADJA", "NN", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und da\u00df dir ", "tokens": ["Und", "da\u00df", "dir"], "token_info": ["word", "word", "word"], "pos": ["KON", "KOUS", "PPER"], "meter": "+-+", "measure": "trochaic.di"}, "line.4": {"text": "Den Putz der Lehrer schenkt, und um das Haupt will flechten.", "tokens": ["Den", "Putz", "der", "Leh\u00b7rer", "schenkt", ",", "und", "um", "das", "Haupt", "will", "flech\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VVFIN", "$,", "KON", "APPR", "ART", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ich sag es noch einmal, Freund! ich erfreue mich!", "tokens": ["Ich", "sag", "es", "noch", "ein\u00b7mal", ",", "Freund", "!", "ich", "er\u00b7freu\u00b7e", "mich", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ADV", "$,", "NN", "$.", "PPER", "VVFIN", "PPER", "$."], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Denn wer dein Wesen kennt, der r\u00fchmt und lobet dich,", "tokens": ["Denn", "wer", "dein", "We\u00b7sen", "kennt", ",", "der", "r\u00fchmt", "und", "lo\u00b7bet", "dich", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPOSAT", "NN", "VVFIN", "$,", "PRELS", "VVFIN", "KON", "VVFIN", "PPER", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Da\u00df du dir endlich auch den Schmuck belieben lassen,", "tokens": ["Da\u00df", "du", "dir", "end\u00b7lich", "auch", "den", "Schmuck", "be\u00b7lie\u00b7ben", "las\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "ADV", "ADV", "ART", "NN", "VVINF", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Der deine, Scheitel itzt so w\u00fcrdig kann umfassen.", "tokens": ["Der", "dei\u00b7ne", ",", "Schei\u00b7tel", "itzt", "so", "w\u00fcr\u00b7dig", "kann", "um\u00b7fas\u00b7sen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "$,", "NN", "ADV", "ADV", "ADJD", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Nun kehr ich wieder um, und gebe gar nicht mehr", "tokens": ["Nun", "kehr", "ich", "wie\u00b7der", "um", ",", "und", "ge\u00b7be", "gar", "nicht", "mehr"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "PTKVZ", "$,", "KON", "VVFIN", "ADV", "PTKNEG", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Der alten Tadelsucht der frechen Welt Geh\u00f6r,", "tokens": ["Der", "al\u00b7ten", "Ta\u00b7del\u00b7sucht", "der", "fre\u00b7chen", "Welt", "Ge\u00b7h\u00f6r", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Die alle Titel schilt; als ob ihr hoher Orden", "tokens": ["Die", "al\u00b7le", "Ti\u00b7tel", "schilt", ";", "als", "ob", "ihr", "ho\u00b7her", "Or\u00b7den"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "PIAT", "NN", "VVFIN", "$.", "KOKOM", "KOUS", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Zu zahlreich, zu gemein, und ganz ver\u00e4chtlich worden.", "tokens": ["Zu", "zahl\u00b7reich", ",", "zu", "ge\u00b7mein", ",", "und", "ganz", "ver\u00b7\u00e4cht\u00b7lich", "wor\u00b7den", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKA", "ADJD", "$,", "PTKA", "ADJD", "$,", "KON", "ADV", "ADJD", "VAPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Ich leugne solches nicht, ich hab es mitgemacht;", "tokens": ["Ich", "leug\u00b7ne", "sol\u00b7ches", "nicht", ",", "ich", "hab", "es", "mit\u00b7ge\u00b7macht", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "PTKNEG", "$,", "PPER", "VAFIN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Weil ich den seichten Grund des Urtheils nie bedacht,", "tokens": ["Weil", "ich", "den", "seich\u00b7ten", "Grund", "des", "Ur\u00b7theils", "nie", "be\u00b7dacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "ART", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Nie reiflich \u00fcberlegt. Itzt will ich mich bem\u00fchen,", "tokens": ["Nie", "reif\u00b7lich", "\u00fc\u00b7ber\u00b7legt", ".", "Itzt", "will", "ich", "mich", "be\u00b7m\u00fc\u00b7hen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVPP", "$.", "ADV", "VMFIN", "PPER", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Und ihm den ganzen Schein der Richtigkeit entziehen.", "tokens": ["Und", "ihm", "den", "gan\u00b7zen", "Schein", "der", "Rich\u00b7tig\u00b7keit", "ent\u00b7zie\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ART", "ADJA", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Ja, spricht man, dazumal verstund man noch das", "tokens": ["Ja", ",", "spricht", "man", ",", "da\u00b7zu\u00b7mal", "ver\u00b7stund", "man", "noch", "das"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "$,", "VVFIN", "PIS", "$,", "ADV", "VVFIN", "PIS", "ADV", "ART"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.2": {"text": "Als noch ", "tokens": ["Als", "noch"], "token_info": ["word", "word"], "pos": ["KOUS", "ADV"], "meter": "+-", "measure": "trochaic.single"}, "line.3": {"text": "Nach vierzig Jahren kaum zu sagen sich erk\u00fchnten,", "tokens": ["Nach", "vier\u00b7zig", "Jah\u00b7ren", "kaum", "zu", "sa\u00b7gen", "sich", "er\u00b7k\u00fchn\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "CARD", "NN", "ADV", "PTKZU", "VVINF", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Da\u00df sie der Themis recht, wie sichs geh\u00f6rte, dienten.", "tokens": ["Da\u00df", "sie", "der", "The\u00b7mis", "recht", ",", "wie", "sichs", "ge\u00b7h\u00f6r\u00b7te", ",", "dien\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "ADJD", "$,", "PWAV", "PIS", "VVFIN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Nun aber d\u00fcnkt sich ja ein junger ", "tokens": ["Nun", "a\u00b7ber", "d\u00fcnkt", "sich", "ja", "ein", "jun\u00b7ger"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "VVFIN", "PRF", "ADV", "ART", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Der kaum recht schreiben kann, so klug, als ", "tokens": ["Der", "kaum", "recht", "schrei\u00b7ben", "kann", ",", "so", "klug", ",", "als"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word"], "pos": ["ART", "ADV", "ADJD", "VVINF", "VMFIN", "$,", "ADV", "ADJD", "$,", "KOUS"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Und st\u00fcrbe fast vor Scham, dafern ihn die Clienten", "tokens": ["Und", "st\u00fcr\u00b7be", "fast", "vor", "Scham", ",", "da\u00b7fern", "ihn", "die", "Clien\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "APPR", "NN", "$,", "KOUS", "PPER", "ART", "NN"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.8": {"text": "Schlecht weg, Herr ", "tokens": ["Schlecht", "weg", ",", "Herr"], "token_info": ["word", "word", "punct", "word"], "pos": ["NN", "PTKVZ", "$,", "NN"], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.3": {"line.1": {"text": "Zum Theil hat man schon recht. Was Rang und Ansehn giebt,", "tokens": ["Zum", "Theil", "hat", "man", "schon", "recht", ".", "Was", "Rang", "und", "An\u00b7sehn", "giebt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VAFIN", "PIS", "ADV", "ADJD", "$.", "PWS", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ist unsrer stolzen Zeit weit mehr, als je, beliebt.", "tokens": ["Ist", "uns\u00b7rer", "stol\u00b7zen", "Zeit", "weit", "mehr", ",", "als", "je", ",", "be\u00b7liebt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "ADJA", "NN", "ADJD", "ADV", "$,", "KOUS", "ADV", "$,", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Man borgt und bettelt Geld, daf\u00fcr zu ", "tokens": ["Man", "borgt", "und", "bet\u00b7telt", "Geld", ",", "da\u00b7f\u00fcr", "zu"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PIS", "VVFIN", "KON", "VVFIN", "NN", "$,", "PAV", "PTKZU"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Und hungert herzlich gern, den Staat nur auszuf\u00fchren.", "tokens": ["Und", "hun\u00b7gert", "herz\u00b7lich", "gern", ",", "den", "Staat", "nur", "aus\u00b7zu\u00b7f\u00fch\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "ADV", "$,", "ART", "NN", "ADV", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Kein Wunder! da\u00df darnach, wer schwere Beutel hebt,", "tokens": ["Kein", "Wun\u00b7der", "!", "da\u00df", "dar\u00b7nach", ",", "wer", "schwe\u00b7re", "Beu\u00b7tel", "hebt", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "$.", "KOUS", "PAV", "$,", "PWS", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Der armen Kunst zu Trotz, bey reicher Thorheit, strebt;", "tokens": ["Der", "ar\u00b7men", "Kunst", "zu", "Trotz", ",", "bey", "rei\u00b7cher", "Thor\u00b7heit", ",", "strebt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "NN", "$,", "APPR", "ADJD", "NN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und, weil die Jungfern auch nach Rang und Titeln w\u00e4hlen,", "tokens": ["Und", ",", "weil", "die", "Jung\u00b7fern", "auch", "nach", "Rang", "und", "Ti\u00b7teln", "w\u00e4h\u00b7len", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "ART", "NN", "ADV", "APPR", "NN", "KON", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Sehr viele Hut und Ring, die Braut zu \u00e4ffen, stehlen.", "tokens": ["Sehr", "vie\u00b7le", "Hut", "und", "Ring", ",", "die", "Braut", "zu", "\u00e4f\u00b7fen", ",", "steh\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "KON", "NN", "$,", "ART", "NN", "PTKZU", "VVINF", "$,", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Daher entsteht denn auch ein gro\u00dfer Uebelstand,", "tokens": ["Da\u00b7her", "ent\u00b7steht", "denn", "auch", "ein", "gro\u00b7\u00dfer", "Ue\u00b7bel\u00b7stand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "ADV", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Der ", "tokens": ["Der"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}, "line.11": {"text": "Und k\u00f6nnte mit der Zeit zu einer Last der Erden,", "tokens": ["Und", "k\u00f6nn\u00b7te", "mit", "der", "Zeit", "zu", "ei\u00b7ner", "Last", "der", "Er\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "APPR", "ART", "NN", "APPR", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Wie sonst das fromme Stift der Tempelherren, werden.", "tokens": ["Wie", "sonst", "das", "from\u00b7me", "Stift", "der", "Tem\u00b7pel\u00b7her\u00b7ren", ",", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PWAV", "ADV", "ART", "ADJA", "NN", "ART", "NN", "$,", "VAINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Die Jugend st\u00fcrmt ja schon der ", "tokens": ["Die", "Ju\u00b7gend", "st\u00fcrmt", "ja", "schon", "der"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ADV", "ADV", "ART"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.14": {"text": "Ihr Schwert besch\u00fctzt sie nicht vor dringender Gewalt.", "tokens": ["Ihr", "Schwert", "be\u00b7sch\u00fctzt", "sie", "nicht", "vor", "drin\u00b7gen\u00b7der", "Ge\u00b7walt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "PTKNEG", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Die Kr\u00e4nze werden ihr leicht aus der Hand gewunden:", "tokens": ["Die", "Kr\u00e4n\u00b7ze", "wer\u00b7den", "ihr", "leicht", "aus", "der", "Hand", "ge\u00b7wun\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "ADJD", "APPR", "ART", "NN", "VAPP", "$."], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.16": {"text": "Was Wunder? sind ihr doch die Augen zugebunden.", "tokens": ["Was", "Wun\u00b7der", "?", "sind", "ihr", "doch", "die", "Au\u00b7gen", "zu\u00b7ge\u00b7bun\u00b7den", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "$.", "VAFIN", "PPER", "ADV", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Doch hebt ja den Gebrauch der Misbrauch niemals auf:", "tokens": ["Doch", "hebt", "ja", "den", "Ge\u00b7brauch", "der", "Mis\u00b7brauch", "nie\u00b7mals", "auf", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ART", "NN", "ART", "NN", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wer schilt die Kaufmannschaft im Handel, Kauf, Verkauf;", "tokens": ["Wer", "schilt", "die", "Kauf\u00b7mann\u00b7schaft", "im", "Han\u00b7del", ",", "Kauf", ",", "Ver\u00b7kauf", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PWS", "VVFIN", "ART", "NN", "APPRART", "NN", "$,", "NN", "$,", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ob gleich sich hier und da Betr\u00fcger eingeschlichen,", "tokens": ["Ob", "gleich", "sich", "hier", "und", "da", "Be\u00b7tr\u00fc\u00b7ger", "ein\u00b7ge\u00b7schli\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PRF", "ADV", "KON", "KOUS", "NN", "VVIZU", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Aus deren ganzem Thun die Billigkeit entwichen?", "tokens": ["Aus", "de\u00b7ren", "gan\u00b7zem", "Thun", "die", "Bil\u00b7lig\u00b7keit", "ent\u00b7wi\u00b7chen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELAT", "ADJA", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Es schm\u00fcckt der Lehrerhut noch manche kluge Stirn,", "tokens": ["Es", "schm\u00fcckt", "der", "Leh\u00b7rer\u00b7hut", "noch", "man\u00b7che", "klu\u00b7ge", "Stirn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADV", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und giebt er, wenn es fehlt, gleich selber kein Gehirn:", "tokens": ["Und", "giebt", "er", ",", "wenn", "es", "fehlt", ",", "gleich", "sel\u00b7ber", "kein", "Ge\u00b7hirn", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "$,", "KOUS", "PPER", "VVFIN", "$,", "ADV", "ADV", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "So trifft mans doch noch oft, wie guten Wein bey Kr\u00e4nzen,", "tokens": ["So", "trifft", "mans", "doch", "noch", "oft", ",", "wie", "gu\u00b7ten", "Wein", "bey", "Kr\u00e4n\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "ADV", "ADV", "ADV", "$,", "PWAV", "ADJA", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Wo man die Scheitel sieht mit diesem Schmucke gl\u00e4nzen.", "tokens": ["Wo", "man", "die", "Schei\u00b7tel", "sieht", "mit", "die\u00b7sem", "Schmu\u00b7cke", "gl\u00e4n\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "ART", "NN", "VVFIN", "APPR", "PDAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Genug! dein Beyspiel selbst, mein Freund! best\u00e4rket mich,", "tokens": ["Ge\u00b7nug", "!", "dein", "Bey\u00b7spiel", "selbst", ",", "mein", "Freund", "!", "be\u00b7st\u00e4r\u00b7ket", "mich", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "$.", "PPOSAT", "NN", "ADV", "$,", "PPOSAT", "NN", "$.", "VVFIN", "PPER", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Du raubst der ", "tokens": ["Du", "raubst", "der"], "token_info": ["word", "word", "word"], "pos": ["PPER", "VVFIN", "ART"], "meter": "-+-", "measure": "amphibrach.single"}, "line.3": {"text": "Dein Witz, dein Aemsigseyn und dein gelehrtes Wachen", "tokens": ["Dein", "Witz", ",", "dein", "A\u00b7em\u00b7si\u00b7gseyn", "und", "dein", "ge\u00b7lehr\u00b7tes", "Wa\u00b7chen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "$,", "PPOSAT", "NN", "KON", "PPOSAT", "ADJA", "NN"], "meter": "-+-+--+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Kann dir der G\u00f6ttinn Huld und Herz zu eigen machen.", "tokens": ["Kann", "dir", "der", "G\u00f6t\u00b7tinn", "Huld", "und", "Herz", "zu", "ei\u00b7gen", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ART", "NN", "NN", "KON", "NN", "PTKA", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Da hast du nun den Lohn, da hast du nun die Frucht,", "tokens": ["Da", "hast", "du", "nun", "den", "Lohn", ",", "da", "hast", "du", "nun", "die", "Frucht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ART", "NN", "$,", "ADV", "VAFIN", "PPER", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Darnach du l\u00e4ngst gestrebt, die du so sehr gesucht.", "tokens": ["Dar\u00b7nach", "du", "l\u00e4ngst", "ge\u00b7strebt", ",", "die", "du", "so", "sehr", "ge\u00b7sucht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PPER", "ADV", "VVPP", "$,", "PRELS", "PPER", "ADV", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "So pflegt in der Natur nach Schwei\u00df und Samenstreuen,", "tokens": ["So", "pflegt", "in", "der", "Na\u00b7tur", "nach", "Schwei\u00df", "und", "Sa\u00b7men\u00b7streu\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "ART", "NN", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Den Schnitter bald darauf die Aernte zu erfreuen.", "tokens": ["Den", "Schnit\u00b7ter", "bald", "da\u00b7rauf", "die", "A\u00b7ern\u00b7te", "zu", "er\u00b7freu\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "PAV", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}}, "stanza.6": {"line.1": {"text": "Gl\u00fcck zu, belohnter Freund! die Wohlfahrt folge dir,", "tokens": ["Gl\u00fcck", "zu", ",", "be\u00b7lohn\u00b7ter", "Freund", "!", "die", "Wohl\u00b7fahrt", "fol\u00b7ge", "dir", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKVZ", "$,", "ADJA", "NN", "$.", "ART", "NN", "VVFIN", "PPER", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Dein werthes Vaterland, dein Frankfurt winket mir;", "tokens": ["Dein", "wert\u00b7hes", "Va\u00b7ter\u00b7land", ",", "dein", "Frank\u00b7furt", "win\u00b7ket", "mir", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,", "PPOSAT", "NN", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und will, ich soll dich nur zu fernerm Flei\u00df entz\u00fcnden,", "tokens": ["Und", "will", ",", "ich", "soll", "dich", "nur", "zu", "fer\u00b7nerm", "Flei\u00df", "ent\u00b7z\u00fcn\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "$,", "PPER", "VMFIN", "PPER", "ADV", "APPR", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Den Lohn daf\u00fcr sollst du in seinen Mauren finden.", "tokens": ["Den", "Lohn", "da\u00b7f\u00fcr", "sollst", "du", "in", "sei\u00b7nen", "Mau\u00b7ren", "fin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PAV", "VMFIN", "PPER", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Du thust es von dir selbst; drum schweig ich mit Bedacht,", "tokens": ["Du", "thust", "es", "von", "dir", "selbst", ";", "drum", "schweig", "ich", "mit", "Be\u00b7dacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "PPER", "ADV", "$.", "PAV", "VVFIN", "PPER", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und da auch ", "tokens": ["Und", "da", "auch"], "token_info": ["word", "word", "word"], "pos": ["KON", "ADV", "ADV"], "meter": "+-+", "measure": "trochaic.di"}, "line.7": {"text": "So w\u00fcnsch ich, wenn du selbst es wirst f\u00fcr rathsam sch\u00e4tzen,", "tokens": ["So", "w\u00fcnsch", "ich", ",", "wenn", "du", "selbst", "es", "wirst", "f\u00fcr", "rath\u00b7sam", "sch\u00e4t\u00b7zen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "KOUS", "PPER", "ADV", "PPER", "VAFIN", "APPR", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Da\u00df dich die sch\u00f6nste Braut aus Frankfurt mag ergetzen.", "tokens": ["Da\u00df", "dich", "die", "sch\u00f6ns\u00b7te", "Braut", "aus", "Frank\u00b7furt", "mag", "er\u00b7get\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "APPR", "NE", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Wie freudig h\u00f6r ich doch, vertrautgeliebter Freund!", "tokens": ["Wie", "freu\u00b7dig", "h\u00f6r", "ich", "doch", ",", "ver\u00b7traut\u00b7ge\u00b7lieb\u00b7ter", "Freund", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VVFIN", "PPER", "ADV", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Da\u00df dein gelehrtes Haupt im Doctorhut erscheint;", "tokens": ["Da\u00df", "dein", "ge\u00b7lehr\u00b7tes", "Haupt", "im", "Doc\u00b7tor\u00b7hut", "er\u00b7scheint", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "ADJA", "NN", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und da\u00df dir ", "tokens": ["Und", "da\u00df", "dir"], "token_info": ["word", "word", "word"], "pos": ["KON", "KOUS", "PPER"], "meter": "+-+", "measure": "trochaic.di"}, "line.4": {"text": "Den Putz der Lehrer schenkt, und um das Haupt will flechten.", "tokens": ["Den", "Putz", "der", "Leh\u00b7rer", "schenkt", ",", "und", "um", "das", "Haupt", "will", "flech\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VVFIN", "$,", "KON", "APPR", "ART", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ich sag es noch einmal, Freund! ich erfreue mich!", "tokens": ["Ich", "sag", "es", "noch", "ein\u00b7mal", ",", "Freund", "!", "ich", "er\u00b7freu\u00b7e", "mich", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ADV", "$,", "NN", "$.", "PPER", "VVFIN", "PPER", "$."], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Denn wer dein Wesen kennt, der r\u00fchmt und lobet dich,", "tokens": ["Denn", "wer", "dein", "We\u00b7sen", "kennt", ",", "der", "r\u00fchmt", "und", "lo\u00b7bet", "dich", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPOSAT", "NN", "VVFIN", "$,", "PRELS", "VVFIN", "KON", "VVFIN", "PPER", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Da\u00df du dir endlich auch den Schmuck belieben lassen,", "tokens": ["Da\u00df", "du", "dir", "end\u00b7lich", "auch", "den", "Schmuck", "be\u00b7lie\u00b7ben", "las\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "ADV", "ADV", "ART", "NN", "VVINF", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Der deine, Scheitel itzt so w\u00fcrdig kann umfassen.", "tokens": ["Der", "dei\u00b7ne", ",", "Schei\u00b7tel", "itzt", "so", "w\u00fcr\u00b7dig", "kann", "um\u00b7fas\u00b7sen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "$,", "NN", "ADV", "ADV", "ADJD", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Nun kehr ich wieder um, und gebe gar nicht mehr", "tokens": ["Nun", "kehr", "ich", "wie\u00b7der", "um", ",", "und", "ge\u00b7be", "gar", "nicht", "mehr"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "PTKVZ", "$,", "KON", "VVFIN", "ADV", "PTKNEG", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Der alten Tadelsucht der frechen Welt Geh\u00f6r,", "tokens": ["Der", "al\u00b7ten", "Ta\u00b7del\u00b7sucht", "der", "fre\u00b7chen", "Welt", "Ge\u00b7h\u00f6r", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Die alle Titel schilt; als ob ihr hoher Orden", "tokens": ["Die", "al\u00b7le", "Ti\u00b7tel", "schilt", ";", "als", "ob", "ihr", "ho\u00b7her", "Or\u00b7den"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "PIAT", "NN", "VVFIN", "$.", "KOKOM", "KOUS", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Zu zahlreich, zu gemein, und ganz ver\u00e4chtlich worden.", "tokens": ["Zu", "zahl\u00b7reich", ",", "zu", "ge\u00b7mein", ",", "und", "ganz", "ver\u00b7\u00e4cht\u00b7lich", "wor\u00b7den", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKA", "ADJD", "$,", "PTKA", "ADJD", "$,", "KON", "ADV", "ADJD", "VAPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Ich leugne solches nicht, ich hab es mitgemacht;", "tokens": ["Ich", "leug\u00b7ne", "sol\u00b7ches", "nicht", ",", "ich", "hab", "es", "mit\u00b7ge\u00b7macht", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "PTKNEG", "$,", "PPER", "VAFIN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Weil ich den seichten Grund des Urtheils nie bedacht,", "tokens": ["Weil", "ich", "den", "seich\u00b7ten", "Grund", "des", "Ur\u00b7theils", "nie", "be\u00b7dacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "ART", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Nie reiflich \u00fcberlegt. Itzt will ich mich bem\u00fchen,", "tokens": ["Nie", "reif\u00b7lich", "\u00fc\u00b7ber\u00b7legt", ".", "Itzt", "will", "ich", "mich", "be\u00b7m\u00fc\u00b7hen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVPP", "$.", "ADV", "VMFIN", "PPER", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Und ihm den ganzen Schein der Richtigkeit entziehen.", "tokens": ["Und", "ihm", "den", "gan\u00b7zen", "Schein", "der", "Rich\u00b7tig\u00b7keit", "ent\u00b7zie\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ART", "ADJA", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "Ja, spricht man, dazumal verstund man noch das", "tokens": ["Ja", ",", "spricht", "man", ",", "da\u00b7zu\u00b7mal", "ver\u00b7stund", "man", "noch", "das"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "$,", "VVFIN", "PIS", "$,", "ADV", "VVFIN", "PIS", "ADV", "ART"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.2": {"text": "Als noch ", "tokens": ["Als", "noch"], "token_info": ["word", "word"], "pos": ["KOUS", "ADV"], "meter": "+-", "measure": "trochaic.single"}, "line.3": {"text": "Nach vierzig Jahren kaum zu sagen sich erk\u00fchnten,", "tokens": ["Nach", "vier\u00b7zig", "Jah\u00b7ren", "kaum", "zu", "sa\u00b7gen", "sich", "er\u00b7k\u00fchn\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "CARD", "NN", "ADV", "PTKZU", "VVINF", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Da\u00df sie der Themis recht, wie sichs geh\u00f6rte, dienten.", "tokens": ["Da\u00df", "sie", "der", "The\u00b7mis", "recht", ",", "wie", "sichs", "ge\u00b7h\u00f6r\u00b7te", ",", "dien\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "ADJD", "$,", "PWAV", "PIS", "VVFIN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Nun aber d\u00fcnkt sich ja ein junger ", "tokens": ["Nun", "a\u00b7ber", "d\u00fcnkt", "sich", "ja", "ein", "jun\u00b7ger"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "VVFIN", "PRF", "ADV", "ART", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Der kaum recht schreiben kann, so klug, als ", "tokens": ["Der", "kaum", "recht", "schrei\u00b7ben", "kann", ",", "so", "klug", ",", "als"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word"], "pos": ["ART", "ADV", "ADJD", "VVINF", "VMFIN", "$,", "ADV", "ADJD", "$,", "KOUS"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Und st\u00fcrbe fast vor Scham, dafern ihn die Clienten", "tokens": ["Und", "st\u00fcr\u00b7be", "fast", "vor", "Scham", ",", "da\u00b7fern", "ihn", "die", "Clien\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "APPR", "NN", "$,", "KOUS", "PPER", "ART", "NN"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.8": {"text": "Schlecht weg, Herr ", "tokens": ["Schlecht", "weg", ",", "Herr"], "token_info": ["word", "word", "punct", "word"], "pos": ["NN", "PTKVZ", "$,", "NN"], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.9": {"line.1": {"text": "Zum Theil hat man schon recht. Was Rang und Ansehn giebt,", "tokens": ["Zum", "Theil", "hat", "man", "schon", "recht", ".", "Was", "Rang", "und", "An\u00b7sehn", "giebt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VAFIN", "PIS", "ADV", "ADJD", "$.", "PWS", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ist unsrer stolzen Zeit weit mehr, als je, beliebt.", "tokens": ["Ist", "uns\u00b7rer", "stol\u00b7zen", "Zeit", "weit", "mehr", ",", "als", "je", ",", "be\u00b7liebt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "ADJA", "NN", "ADJD", "ADV", "$,", "KOUS", "ADV", "$,", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Man borgt und bettelt Geld, daf\u00fcr zu ", "tokens": ["Man", "borgt", "und", "bet\u00b7telt", "Geld", ",", "da\u00b7f\u00fcr", "zu"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PIS", "VVFIN", "KON", "VVFIN", "NN", "$,", "PAV", "PTKZU"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Und hungert herzlich gern, den Staat nur auszuf\u00fchren.", "tokens": ["Und", "hun\u00b7gert", "herz\u00b7lich", "gern", ",", "den", "Staat", "nur", "aus\u00b7zu\u00b7f\u00fch\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "ADV", "$,", "ART", "NN", "ADV", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Kein Wunder! da\u00df darnach, wer schwere Beutel hebt,", "tokens": ["Kein", "Wun\u00b7der", "!", "da\u00df", "dar\u00b7nach", ",", "wer", "schwe\u00b7re", "Beu\u00b7tel", "hebt", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "$.", "KOUS", "PAV", "$,", "PWS", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Der armen Kunst zu Trotz, bey reicher Thorheit, strebt;", "tokens": ["Der", "ar\u00b7men", "Kunst", "zu", "Trotz", ",", "bey", "rei\u00b7cher", "Thor\u00b7heit", ",", "strebt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "NN", "$,", "APPR", "ADJD", "NN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und, weil die Jungfern auch nach Rang und Titeln w\u00e4hlen,", "tokens": ["Und", ",", "weil", "die", "Jung\u00b7fern", "auch", "nach", "Rang", "und", "Ti\u00b7teln", "w\u00e4h\u00b7len", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "ART", "NN", "ADV", "APPR", "NN", "KON", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Sehr viele Hut und Ring, die Braut zu \u00e4ffen, stehlen.", "tokens": ["Sehr", "vie\u00b7le", "Hut", "und", "Ring", ",", "die", "Braut", "zu", "\u00e4f\u00b7fen", ",", "steh\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "KON", "NN", "$,", "ART", "NN", "PTKZU", "VVINF", "$,", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Daher entsteht denn auch ein gro\u00dfer Uebelstand,", "tokens": ["Da\u00b7her", "ent\u00b7steht", "denn", "auch", "ein", "gro\u00b7\u00dfer", "Ue\u00b7bel\u00b7stand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "ADV", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Der ", "tokens": ["Der"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}, "line.11": {"text": "Und k\u00f6nnte mit der Zeit zu einer Last der Erden,", "tokens": ["Und", "k\u00f6nn\u00b7te", "mit", "der", "Zeit", "zu", "ei\u00b7ner", "Last", "der", "Er\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "APPR", "ART", "NN", "APPR", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Wie sonst das fromme Stift der Tempelherren, werden.", "tokens": ["Wie", "sonst", "das", "from\u00b7me", "Stift", "der", "Tem\u00b7pel\u00b7her\u00b7ren", ",", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PWAV", "ADV", "ART", "ADJA", "NN", "ART", "NN", "$,", "VAINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Die Jugend st\u00fcrmt ja schon der ", "tokens": ["Die", "Ju\u00b7gend", "st\u00fcrmt", "ja", "schon", "der"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ADV", "ADV", "ART"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.14": {"text": "Ihr Schwert besch\u00fctzt sie nicht vor dringender Gewalt.", "tokens": ["Ihr", "Schwert", "be\u00b7sch\u00fctzt", "sie", "nicht", "vor", "drin\u00b7gen\u00b7der", "Ge\u00b7walt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "PTKNEG", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Die Kr\u00e4nze werden ihr leicht aus der Hand gewunden:", "tokens": ["Die", "Kr\u00e4n\u00b7ze", "wer\u00b7den", "ihr", "leicht", "aus", "der", "Hand", "ge\u00b7wun\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "ADJD", "APPR", "ART", "NN", "VAPP", "$."], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.16": {"text": "Was Wunder? sind ihr doch die Augen zugebunden.", "tokens": ["Was", "Wun\u00b7der", "?", "sind", "ihr", "doch", "die", "Au\u00b7gen", "zu\u00b7ge\u00b7bun\u00b7den", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "$.", "VAFIN", "PPER", "ADV", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.10": {"line.1": {"text": "Doch hebt ja den Gebrauch der Misbrauch niemals auf:", "tokens": ["Doch", "hebt", "ja", "den", "Ge\u00b7brauch", "der", "Mis\u00b7brauch", "nie\u00b7mals", "auf", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ART", "NN", "ART", "NN", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wer schilt die Kaufmannschaft im Handel, Kauf, Verkauf;", "tokens": ["Wer", "schilt", "die", "Kauf\u00b7mann\u00b7schaft", "im", "Han\u00b7del", ",", "Kauf", ",", "Ver\u00b7kauf", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PWS", "VVFIN", "ART", "NN", "APPRART", "NN", "$,", "NN", "$,", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ob gleich sich hier und da Betr\u00fcger eingeschlichen,", "tokens": ["Ob", "gleich", "sich", "hier", "und", "da", "Be\u00b7tr\u00fc\u00b7ger", "ein\u00b7ge\u00b7schli\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PRF", "ADV", "KON", "KOUS", "NN", "VVIZU", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Aus deren ganzem Thun die Billigkeit entwichen?", "tokens": ["Aus", "de\u00b7ren", "gan\u00b7zem", "Thun", "die", "Bil\u00b7lig\u00b7keit", "ent\u00b7wi\u00b7chen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELAT", "ADJA", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Es schm\u00fcckt der Lehrerhut noch manche kluge Stirn,", "tokens": ["Es", "schm\u00fcckt", "der", "Leh\u00b7rer\u00b7hut", "noch", "man\u00b7che", "klu\u00b7ge", "Stirn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADV", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und giebt er, wenn es fehlt, gleich selber kein Gehirn:", "tokens": ["Und", "giebt", "er", ",", "wenn", "es", "fehlt", ",", "gleich", "sel\u00b7ber", "kein", "Ge\u00b7hirn", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "$,", "KOUS", "PPER", "VVFIN", "$,", "ADV", "ADV", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "So trifft mans doch noch oft, wie guten Wein bey Kr\u00e4nzen,", "tokens": ["So", "trifft", "mans", "doch", "noch", "oft", ",", "wie", "gu\u00b7ten", "Wein", "bey", "Kr\u00e4n\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "ADV", "ADV", "ADV", "$,", "PWAV", "ADJA", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Wo man die Scheitel sieht mit diesem Schmucke gl\u00e4nzen.", "tokens": ["Wo", "man", "die", "Schei\u00b7tel", "sieht", "mit", "die\u00b7sem", "Schmu\u00b7cke", "gl\u00e4n\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "ART", "NN", "VVFIN", "APPR", "PDAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.11": {"line.1": {"text": "Genug! dein Beyspiel selbst, mein Freund! best\u00e4rket mich,", "tokens": ["Ge\u00b7nug", "!", "dein", "Bey\u00b7spiel", "selbst", ",", "mein", "Freund", "!", "be\u00b7st\u00e4r\u00b7ket", "mich", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "$.", "PPOSAT", "NN", "ADV", "$,", "PPOSAT", "NN", "$.", "VVFIN", "PPER", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Du raubst der ", "tokens": ["Du", "raubst", "der"], "token_info": ["word", "word", "word"], "pos": ["PPER", "VVFIN", "ART"], "meter": "-+-", "measure": "amphibrach.single"}, "line.3": {"text": "Dein Witz, dein Aemsigseyn und dein gelehrtes Wachen", "tokens": ["Dein", "Witz", ",", "dein", "A\u00b7em\u00b7si\u00b7gseyn", "und", "dein", "ge\u00b7lehr\u00b7tes", "Wa\u00b7chen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "$,", "PPOSAT", "NN", "KON", "PPOSAT", "ADJA", "NN"], "meter": "-+-+--+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Kann dir der G\u00f6ttinn Huld und Herz zu eigen machen.", "tokens": ["Kann", "dir", "der", "G\u00f6t\u00b7tinn", "Huld", "und", "Herz", "zu", "ei\u00b7gen", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ART", "NN", "NN", "KON", "NN", "PTKA", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Da hast du nun den Lohn, da hast du nun die Frucht,", "tokens": ["Da", "hast", "du", "nun", "den", "Lohn", ",", "da", "hast", "du", "nun", "die", "Frucht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ART", "NN", "$,", "ADV", "VAFIN", "PPER", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Darnach du l\u00e4ngst gestrebt, die du so sehr gesucht.", "tokens": ["Dar\u00b7nach", "du", "l\u00e4ngst", "ge\u00b7strebt", ",", "die", "du", "so", "sehr", "ge\u00b7sucht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PPER", "ADV", "VVPP", "$,", "PRELS", "PPER", "ADV", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "So pflegt in der Natur nach Schwei\u00df und Samenstreuen,", "tokens": ["So", "pflegt", "in", "der", "Na\u00b7tur", "nach", "Schwei\u00df", "und", "Sa\u00b7men\u00b7streu\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "ART", "NN", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Den Schnitter bald darauf die Aernte zu erfreuen.", "tokens": ["Den", "Schnit\u00b7ter", "bald", "da\u00b7rauf", "die", "A\u00b7ern\u00b7te", "zu", "er\u00b7freu\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "PAV", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}}, "stanza.12": {"line.1": {"text": "Gl\u00fcck zu, belohnter Freund! die Wohlfahrt folge dir,", "tokens": ["Gl\u00fcck", "zu", ",", "be\u00b7lohn\u00b7ter", "Freund", "!", "die", "Wohl\u00b7fahrt", "fol\u00b7ge", "dir", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKVZ", "$,", "ADJA", "NN", "$.", "ART", "NN", "VVFIN", "PPER", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Dein werthes Vaterland, dein Frankfurt winket mir;", "tokens": ["Dein", "wert\u00b7hes", "Va\u00b7ter\u00b7land", ",", "dein", "Frank\u00b7furt", "win\u00b7ket", "mir", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,", "PPOSAT", "NN", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und will, ich soll dich nur zu fernerm Flei\u00df entz\u00fcnden,", "tokens": ["Und", "will", ",", "ich", "soll", "dich", "nur", "zu", "fer\u00b7nerm", "Flei\u00df", "ent\u00b7z\u00fcn\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "$,", "PPER", "VMFIN", "PPER", "ADV", "APPR", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Den Lohn daf\u00fcr sollst du in seinen Mauren finden.", "tokens": ["Den", "Lohn", "da\u00b7f\u00fcr", "sollst", "du", "in", "sei\u00b7nen", "Mau\u00b7ren", "fin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PAV", "VMFIN", "PPER", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Du thust es von dir selbst; drum schweig ich mit Bedacht,", "tokens": ["Du", "thust", "es", "von", "dir", "selbst", ";", "drum", "schweig", "ich", "mit", "Be\u00b7dacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "PPER", "ADV", "$.", "PAV", "VVFIN", "PPER", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und da auch ", "tokens": ["Und", "da", "auch"], "token_info": ["word", "word", "word"], "pos": ["KON", "ADV", "ADV"], "meter": "+-+", "measure": "trochaic.di"}, "line.7": {"text": "So w\u00fcnsch ich, wenn du selbst es wirst f\u00fcr rathsam sch\u00e4tzen,", "tokens": ["So", "w\u00fcnsch", "ich", ",", "wenn", "du", "selbst", "es", "wirst", "f\u00fcr", "rath\u00b7sam", "sch\u00e4t\u00b7zen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "KOUS", "PPER", "ADV", "PPER", "VAFIN", "APPR", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Da\u00df dich die sch\u00f6nste Braut aus Frankfurt mag ergetzen.", "tokens": ["Da\u00df", "dich", "die", "sch\u00f6ns\u00b7te", "Braut", "aus", "Frank\u00b7furt", "mag", "er\u00b7get\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "APPR", "NE", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}