{"dta.poem.11099": {"metadata": {"author": {"name": "Hofmannswaldau, Christian Hofmann von", "birth": "N.A.", "death": "N.A."}, "title": "Die vers\u00e4umte liebes-erkl\u00e4rung.  \n  Talander.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1709", "urn": "urn:nbn:de:kobv:b4-20283-5", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Bekr\u00e4ucktes hertz! was hilfft es dir,", "tokens": ["Be\u00b7kr\u00e4uck\u00b7tes", "hertz", "!", "was", "hilfft", "es", "dir", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$.", "PWS", "VVFIN", "PPER", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df du dein leid verschwiegen?", "tokens": ["Da\u00df", "du", "dein", "leid", "ver\u00b7schwie\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "ADJD", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Du wirst doch endlich noch daf\u00fcr", "tokens": ["Du", "wirst", "doch", "end\u00b7lich", "noch", "da\u00b7f\u00fcr"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "ADV", "PAV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "In staub und asche liegen.", "tokens": ["In", "staub", "und", "asc\u00b7he", "lie\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJD", "KON", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Denn wer da brennt, und schweigt die pein,", "tokens": ["Denn", "wer", "da", "brennt", ",", "und", "schweigt", "die", "pein", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ADV", "VVFIN", "$,", "KON", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Der mu\u00df zuletzt verbrennet seyn.", "tokens": ["Der", "mu\u00df", "zu\u00b7letzt", "ver\u00b7bren\u00b7net", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "ADV", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "O sch\u00f6ne zeit! als mich ihr blick", "tokens": ["O", "sch\u00f6\u00b7ne", "zeit", "!", "als", "mich", "ihr", "blick"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "ADJA", "NN", "$.", "KOUS", "PPER", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Zum ersten angez\u00fcndet!", "tokens": ["Zum", "ers\u00b7ten", "an\u00b7ge\u00b7z\u00fcn\u00b7det", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Was hielt ich da die gluth zur\u00fcck,", "tokens": ["Was", "hielt", "ich", "da", "die", "gluth", "zu\u00b7r\u00fcck", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die nun nicht rettung findet?", "tokens": ["Die", "nun", "nicht", "ret\u00b7tung", "fin\u00b7det", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "PTKNEG", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Jtzt zeig ich durch die sp\u00e4te reu:", "tokens": ["Jtzt", "zeig", "ich", "durch", "die", "sp\u00e4\u00b7te", "reu", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "ADJA", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Da\u00df reden nun zu langsam sey.", "tokens": ["Da\u00df", "re\u00b7den", "nun", "zu", "lang\u00b7sam", "sey", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VVINF", "ADV", "PTKA", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Wie offt gab es gelegenheit,", "tokens": ["Wie", "offt", "gab", "es", "ge\u00b7le\u00b7gen\u00b7heit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "VVFIN", "PPER", "NN", "$,"], "meter": "--+--++-", "measure": "anapaest.di.plus"}, "line.2": {"text": "Mein leiden dir zu klagen?", "tokens": ["Mein", "lei\u00b7den", "dir", "zu", "kla\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Wie offt befahl es mir die zeit,", "tokens": ["Wie", "offt", "be\u00b7fahl", "es", "mir", "die", "zeit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "VVFIN", "PPER", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Durch seufftzen vorzutragen?", "tokens": ["Durch", "seufft\u00b7zen", "vor\u00b7zu\u00b7tra\u00b7gen", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVIZU", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Jtzt h\u00e4lt das gantz erz\u00f6rnte gl\u00fcck", "tokens": ["Jtzt", "h\u00e4lt", "das", "gantz", "er\u00b7z\u00f6rn\u00b7te", "gl\u00fcck"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Dir seufftzer blick und wort zur\u00fcck.", "tokens": ["Dir", "seufft\u00b7zer", "blick", "und", "wort", "zu\u00b7r\u00fcck", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "KON", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Doch soll mein geist stets fertig stehn,", "tokens": ["Doch", "soll", "mein", "geist", "stets", "fer\u00b7tig", "stehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPOSAT", "NN", "ADV", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dich ewig zu verehren.", "tokens": ["Dich", "e\u00b7wig", "zu", "ver\u00b7eh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und m\u00fc\u00dft ich ja in gluth zergehn;", "tokens": ["Und", "m\u00fc\u00dft", "ich", "ja", "in", "gluth", "zer\u00b7gehn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "ADV", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Will ich als Ph\u00f6nix lehren:", "tokens": ["Will", "ich", "als", "Ph\u00f6\u00b7nix", "leh\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "KOUS", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Da\u00df, wer von einer sonne glimmt,", "tokens": ["Da\u00df", ",", "wer", "von", "ei\u00b7ner", "son\u00b7ne", "glimmt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$,", "PWS", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ein neues leben an sich nimmt.", "tokens": ["Ein", "neu\u00b7es", "le\u00b7ben", "an", "sich", "nimmt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "APPR", "PRF", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}