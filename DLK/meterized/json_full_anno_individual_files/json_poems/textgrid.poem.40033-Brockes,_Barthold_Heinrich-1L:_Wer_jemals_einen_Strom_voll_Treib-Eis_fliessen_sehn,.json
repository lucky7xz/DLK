{"textgrid.poem.40033": {"metadata": {"author": {"name": "Brockes, Barthold Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "1L: Wer jemals einen Strom voll Treib-Eis fliessen sehn,", "genre": "verse", "period": "N.A.", "pub_year": 1713, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wer jemals einen Strom voll Treib-Eis fliessen sehn,", "tokens": ["Wer", "je\u00b7mals", "ei\u00b7nen", "Strom", "voll", "Treib\u00b7Eis", "flies\u00b7sen", "sehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "ART", "NN", "ADJD", "NN", "VVINF", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Mit welch gewaltig streng und dennoch stillem Drange,", "tokens": ["Mit", "welch", "ge\u00b7wal\u00b7tig", "streng", "und", "den\u00b7noch", "stil\u00b7lem", "Dran\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PWAT", "ADJD", "VVFIN", "KON", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "In einem ungehemmt- und Wirbel-reichen Gange,", "tokens": ["In", "ei\u00b7nem", "un\u00b7ge\u00b7hemm\u00b7t", "und", "Wir\u00b7bel\u00b7rei\u00b7chen", "Gan\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "TRUNC", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Die Fluth die Schollen f\u00fchrt, der mu\u00df gestehn,", "tokens": ["Die", "Fluth", "die", "Schol\u00b7len", "f\u00fchrt", ",", "der", "mu\u00df", "ge\u00b7stehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VVFIN", "$,", "ART", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Da\u00df es den Augen Lust, dem Hertzen Schrecken,", "tokens": ["Da\u00df", "es", "den", "Au\u00b7gen", "Lust", ",", "dem", "Hert\u00b7zen", "Schre\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "NN", "$,", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Zugleich verm\u00f6gend zu erwecken,", "tokens": ["Zu\u00b7gleich", "ver\u00b7m\u00f6\u00b7gend", "zu", "er\u00b7we\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVPP", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Indem es in der That", "tokens": ["In\u00b7dem", "es", "in", "der", "That"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "Was Majest\u00e4tisches, was gr\u00e4\u00dflich-sch\u00f6nes hat.", "tokens": ["Was", "Ma\u00b7jes\u00b7t\u00e4\u00b7ti\u00b7sches", ",", "was", "gr\u00e4\u00df\u00b7lich\u00b7sch\u00f6\u00b7nes", "hat", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "PIS", "$,", "PWS", "ADJA", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Den Augen schwindelt recht, wenn sie ein flaches Feld,", "tokens": ["Den", "Au\u00b7gen", "schwin\u00b7delt", "recht", ",", "wenn", "sie", "ein", "fla\u00b7ches", "Feld", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJD", "$,", "KOUS", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "(wie es von weitem scheint) geborsten, sich bewegen,", "tokens": ["(", "wie", "es", "von", "wei\u00b7tem", "scheint", ")", "ge\u00b7bors\u00b7ten", ",", "sich", "be\u00b7we\u00b7gen", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["$(", "PWAV", "PPER", "APPR", "PIS", "VVFIN", "$(", "VVPP", "$,", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die Erde nicht mehr ruhn, den Boden selbst sich regen,", "tokens": ["Die", "Er\u00b7de", "nicht", "mehr", "ruhn", ",", "den", "Bo\u00b7den", "selbst", "sich", "re\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKNEG", "ADV", "VVINF", "$,", "ART", "NN", "ADV", "PRF", "ADJA", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und Felsen schwimmen sehn. Es reisst die Wasser-Welt,", "tokens": ["Und", "Fel\u00b7sen", "schwim\u00b7men", "sehn", ".", "Es", "reisst", "die", "Was\u00b7ser\u00b7Welt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVINF", "VVINF", "$.", "PPER", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "In schroffen, ungeformt- und ungeheuren St\u00fccken.", "tokens": ["In", "schrof\u00b7fen", ",", "un\u00b7ge\u00b7form\u00b7t", "und", "un\u00b7ge\u00b7heu\u00b7ren", "St\u00fc\u00b7cken", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "VVINF", "$,", "TRUNC", "KON", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "Selbst Berge mit sich fort. Ein w\u00fcstes, kaltes Grau", "tokens": ["Selbst", "Ber\u00b7ge", "mit", "sich", "fort", ".", "Ein", "w\u00fcs\u00b7tes", ",", "kal\u00b7tes", "Grau"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["ADV", "NN", "APPR", "PRF", "PTKVZ", "$.", "ART", "ADJA", "$,", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Deckt Wasser, Land und Strand. Ber\u00f6det, wild und rauh", "tokens": ["Deckt", "Was\u00b7ser", ",", "Land", "und", "Strand", ".", "Be\u00b7r\u00f6\u00b7det", ",", "wild", "und", "rauh"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "NN", "$,", "NN", "KON", "NN", "$.", "VVPP", "$,", "ADJD", "KON", "ADJD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Ist alles, was man sieht. Der Sonne Strahlen schm\u00fccken", "tokens": ["Ist", "al\u00b7les", ",", "was", "man", "sieht", ".", "Der", "Son\u00b7ne", "Strah\u00b7len", "schm\u00fc\u00b7cken"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VAFIN", "PIS", "$,", "PRELS", "PIS", "VVFIN", "$.", "ART", "NN", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Doch \u00f6fters manchen Ort,", "tokens": ["Doch", "\u00f6f\u00b7ters", "man\u00b7chen", "Ort", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PIAT", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.10": {"text": "Da denn bald hier, bald dort,", "tokens": ["Da", "denn", "bald", "hier", ",", "bald", "dort", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "ADV", "$,", "ADV", "ADV", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.11": {"text": "Zumahl an den versteinten Wellen,", "tokens": ["Zu\u00b7mahl", "an", "den", "ver\u00b7stein\u00b7ten", "Wel\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.12": {"text": "Manch schneller Blitz, manch heller Glantz erscheint,", "tokens": ["Manch", "schnel\u00b7ler", "Blitz", ",", "manch", "hel\u00b7ler", "Glantz", "er\u00b7scheint", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "$,", "PIAT", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "So da\u00df man fast nicht anders meynt,", "tokens": ["So", "da\u00df", "man", "fast", "nicht", "an\u00b7ders", "meynt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PIS", "ADV", "PTKNEG", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Als wenn an unterschied'nen Stellen,", "tokens": ["Als", "wenn", "an", "un\u00b7ter\u00b7schie\u00b7d'\u00b7nen", "Stel\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.15": {"text": "Selbst in der kalten Fluth,", "tokens": ["Selbst", "in", "der", "kal\u00b7ten", "Fluth", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.16": {"text": "Man eine bunte Gluht,", "tokens": ["Man", "ei\u00b7ne", "bun\u00b7te", "Gluht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.17": {"text": "Gef\u00e4rbter Flammen funckeln, s\u00e4he.", "tokens": ["Ge\u00b7f\u00e4rb\u00b7ter", "Flam\u00b7men", "fun\u00b7ckeln", ",", "s\u00e4\u00b7he", "."], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["NN", "NN", "VVINF", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Die\u00df alles sah ich j\u00fcngst, und, wie ich in der N\u00e4he", "tokens": ["Die\u00df", "al\u00b7les", "sah", "ich", "j\u00fcngst", ",", "und", ",", "wie", "ich", "in", "der", "N\u00e4\u00b7he"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PDS", "PIS", "VVFIN", "PPER", "ADV", "$,", "KON", "$,", "PWAV", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Im strengen Flu\u00df das Eis schnell vor mir \u00fcberschiessen,", "tokens": ["Im", "stren\u00b7gen", "Flu\u00df", "das", "Eis", "schnell", "vor", "mir", "\u00fc\u00b7bersc\u00b7hies\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "ART", "NN", "ADJD", "APPR", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und eilend, dennoch sanft, best\u00e4ndig vor sich fliessen", "tokens": ["Und", "ei\u00b7lend", ",", "den\u00b7noch", "sanft", ",", "be\u00b7st\u00e4n\u00b7dig", "vor", "sich", "flies\u00b7sen"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVPP", "$,", "ADV", "ADJD", "$,", "ADJD", "APPR", "PRF", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und sich verlieren sah; kam mir", "tokens": ["Und", "sich", "ver\u00b7lie\u00b7ren", "sah", ";", "kam", "mir"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "PRF", "VVINF", "VVFIN", "$.", "VVFIN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "\u00bbdes Stroms nie stiller Zug und sanfte Strengigkeit,", "tokens": ["\u00bb", "des", "Stroms", "nie", "stil\u00b7ler", "Zug", "und", "sanf\u00b7te", "Stren\u00b7gig\u00b7keit", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "ADV", "ADJA", "NN", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Recht, wie der streng' und stille Lauf der Zeit,", "tokens": ["Recht", ",", "wie", "der", "streng'", "und", "stil\u00b7le", "Lauf", "der", "Zeit", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PWAV", "ART", "NN", "KON", "ADJA", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Die Schollen, wie wir Menschen, f\u00fcr.\u00ab", "tokens": ["Die", "Schol\u00b7len", ",", "wie", "wir", "Men\u00b7schen", ",", "f\u00fcr", ".", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct", "punct"], "pos": ["ART", "NN", "$,", "PWAV", "PPER", "NN", "$,", "APPR", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Wir werden durch die Fluth der Zeit dahin gef\u00fchret,", "tokens": ["Wir", "wer\u00b7den", "durch", "die", "Fluth", "der", "Zeit", "da\u00b7hin", "ge\u00b7f\u00fch\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "ART", "NN", "ART", "NN", "PAV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Und weil, das um uns ist, best\u00e4ndig mit uns geht;", "tokens": ["Und", "weil", ",", "das", "um", "uns", "ist", ",", "be\u00b7st\u00e4n\u00b7dig", "mit", "uns", "geht", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "$,", "PRELS", "APPR", "PPER", "VAFIN", "$,", "ADJD", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Wird die gewaltige Bewegung nicht gesp\u00fchret,", "tokens": ["Wird", "die", "ge\u00b7wal\u00b7ti\u00b7ge", "Be\u00b7we\u00b7gung", "nicht", "ge\u00b7sp\u00fch\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "ADJA", "NN", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Ob gleich nicht einer stille steht.", "tokens": ["Ob", "gleich", "nicht", "ei\u00b7ner", "stil\u00b7le", "steht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PTKNEG", "ART", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "\u00bbgebrechlich ist das Eis; Wir auch. die Schollen werden", "tokens": ["\u00bb", "ge\u00b7brech\u00b7lich", "ist", "das", "Eis", ";", "Wir", "auch", ".", "die", "Schol\u00b7len", "wer\u00b7den"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["$(", "ADJD", "VAFIN", "ART", "NN", "$.", "PPER", "ADV", "$.", "ART", "NN", "VAINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Zu ihrem erstem Stoff, zu Wasser; wir zu Erden.", "tokens": ["Zu", "ih\u00b7rem", "ers\u00b7tem", "Stoff", ",", "zu", "Was\u00b7ser", ";", "wir", "zu", "Er\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$,", "APPR", "NN", "$.", "PPER", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die wenigsten sind gro\u00df, die meisten klein;", "tokens": ["Die", "we\u00b7nigs\u00b7ten", "sind", "gro\u00df", ",", "die", "meis\u00b7ten", "klein", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VAFIN", "ADJD", "$,", "PRELS", "PIS", "ADJD", "$."], "meter": "--+--+-+-+", "measure": "anapaest.di.plus"}, "line.4": {"text": "So geht es auch mit uns. Es werden von den Grossen", "tokens": ["So", "geht", "es", "auch", "mit", "uns", ".", "Es", "wer\u00b7den", "von", "den", "Gros\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPR", "PPER", "$.", "PPER", "VAFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die Kleinen mitgef\u00fchrt und fortgestossen;", "tokens": ["Die", "Klei\u00b7nen", "mit\u00b7ge\u00b7f\u00fchrt", "und", "fort\u00b7ges\u00b7tos\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "KON", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Ist die\u00df der Grossen Brauch", "tokens": ["Ist", "die\u00df", "der", "Gros\u00b7sen", "Brauch"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "PDS", "ART", "NN", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Nicht bey den Menschen auch?\u00ab", "tokens": ["Nicht", "bey", "den", "Men\u00b7schen", "auch", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PTKNEG", "APPR", "ART", "NN", "ADV", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "Wenn manche St\u00fcckchen Eis, vom Sonnen-Strahl geschm\u00fcckt,", "tokens": ["Wenn", "man\u00b7che", "St\u00fcck\u00b7chen", "Eis", ",", "vom", "Son\u00b7nen\u00b7Strahl", "ge\u00b7schm\u00fcckt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "NN", "NN", "$,", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Vor andern funckelten; so kommen mir", "tokens": ["Vor", "an\u00b7dern", "fun\u00b7ckel\u00b7ten", ";", "so", "kom\u00b7men", "mir"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "PIS", "VVFIN", "$.", "ADV", "VVFIN", "PPER"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Dieselbigen in ihrer Zier", "tokens": ["Die\u00b7sel\u00b7bi\u00b7gen", "in", "ih\u00b7rer", "Zier"], "token_info": ["word", "word", "word", "word"], "pos": ["PDS", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Als sloche Menschen f\u00fcr,", "tokens": ["Als", "slo\u00b7che", "Men\u00b7schen", "f\u00fcr", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "NN", "APPR", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.12": {"text": "Die in der Welt vor anderen begl\u00fcckt.", "tokens": ["Die", "in", "der", "Welt", "vor", "an\u00b7de\u00b7ren", "be\u00b7gl\u00fcckt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "APPR", "PIS", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "Es w\u00e4hret dieser, so wie jener Herrlichkeit,", "tokens": ["Es", "w\u00e4h\u00b7ret", "die\u00b7ser", ",", "so", "wie", "je\u00b7ner", "Herr\u00b7lich\u00b7keit", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PDS", "$,", "ADV", "KOKOM", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Nur eine kurtze Zeit,", "tokens": ["Nur", "ei\u00b7ne", "kurt\u00b7ze", "Zeit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.15": {"text": "So bald sie sich ein wenig drehen,", "tokens": ["So", "bald", "sie", "sich", "ein", "we\u00b7nig", "dre\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "PRF", "ART", "PIS", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "Sieht man den hellen Glantz den Augenblick vergehen.", "tokens": ["Sieht", "man", "den", "hel\u00b7len", "Glantz", "den", "Au\u00b7gen\u00b7blick", "ver\u00b7ge\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ART", "ADJA", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "\u00bbverschiedene setzen sich zuammen, und formiren,", "tokens": ["\u00bb", "ver\u00b7schie\u00b7de\u00b7ne", "set\u00b7zen", "sich", "zu\u00b7am\u00b7men", ",", "und", "for\u00b7mi\u00b7ren", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "ADJA", "VVFIN", "PRF", "VVINF", "$,", "KON", "VVFIN", "$,"], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Dem Ansehn nach, ein festes Land;", "tokens": ["Dem", "An\u00b7sehn", "nach", ",", "ein", "fes\u00b7tes", "Land", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "$,", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Doch wird das scheinbar-sichre Band", "tokens": ["Doch", "wird", "das", "schein\u00b7ba\u00b7rsich\u00b7re", "Band"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Festigkeit gar bald verlieren.\u00ab", "tokens": ["Die", "Fes\u00b7tig\u00b7keit", "gar", "bald", "ver\u00b7lie\u00b7ren", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "ADV", "ADV", "VVINF", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Mit diesen k\u00f6mmt ein Regiment, ein Reich,", "tokens": ["Mit", "die\u00b7sen", "k\u00f6mmt", "ein", "Re\u00b7gi\u00b7ment", ",", "ein", "Reich", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PDAT", "VVFIN", "ART", "NN", "$,", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Das aus so mancherley Gem\u00fcthern auch bestehet,", "tokens": ["Das", "aus", "so", "man\u00b7cher\u00b7ley", "Ge\u00b7m\u00fc\u00b7thern", "auch", "be\u00b7ste\u00b7het", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "APPR", "ADV", "PIAT", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Das auch, wie starck es scheint, doch \u00f6fters bald vergehet,", "tokens": ["Das", "auch", ",", "wie", "starck", "es", "scheint", ",", "doch", "\u00f6f\u00b7ters", "bald", "ver\u00b7ge\u00b7het", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "$,", "PWAV", "ADJD", "PPER", "VVFIN", "$,", "ADV", "ADV", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "In billigen Vergleich.", "tokens": ["In", "bil\u00b7li\u00b7gen", "Ver\u00b7gleich", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "\u00bbich sah mit Lust viel kleine ruhig fliessen,", "tokens": ["\u00bb", "ich", "sah", "mit", "Lust", "viel", "klei\u00b7ne", "ru\u00b7hig", "flies\u00b7sen", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "APPR", "NN", "PIAT", "ADJA", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "So lange sie sich nicht mit andern stiessen.", "tokens": ["So", "lan\u00b7ge", "sie", "sich", "nicht", "mit", "an\u00b7dern", "sties\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "PRF", "PTKNEG", "APPR", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Wann aber das geschah;", "tokens": ["Wann", "a\u00b7ber", "das", "ge\u00b7schah", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "PDS", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Erhob sich alsobald ein Wirbel in der Fluth,", "tokens": ["Er\u00b7hob", "sich", "al\u00b7so\u00b7bald", "ein", "Wir\u00b7bel", "in", "der", "Fluth", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ADV", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ein f\u00fcrchterlichs Gekrach,", "tokens": ["Ein", "f\u00fcrch\u00b7ter\u00b7lichs", "Ge\u00b7krach", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Da\u00df ein St\u00fcck hier, das andre dorten, brach,", "tokens": ["Da\u00df", "ein", "St\u00fcck", "hier", ",", "das", "and\u00b7re", "dor\u00b7ten", ",", "brach", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ADV", "$,", "PRELS", "PIS", "ADV", "$,", "VVFIN", "$,"], "meter": "--+--+-+-+", "measure": "anapaest.di.plus"}, "line.7": {"text": "Und beyde wurde von der Wuth", "tokens": ["Und", "bey\u00b7de", "wur\u00b7de", "von", "der", "Wuth"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PIS", "VAFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Erz\u00fcrnter Wellen umgeschwungen,", "tokens": ["Er\u00b7z\u00fcrn\u00b7ter", "Wel\u00b7len", "um\u00b7ge\u00b7schwun\u00b7gen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Zuweilen auch wohl gar verschlungen.", "tokens": ["Zu\u00b7wei\u00b7len", "auch", "wohl", "gar", "ver\u00b7schlun\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Hieraus nahm ich mir diese Lehre,", "tokens": ["Hier\u00b7aus", "nahm", "ich", "mir", "die\u00b7se", "Leh\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "PPER", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Und dacht': Ach da\u00df doch das auch uns ein Beyspiel w\u00e4re,", "tokens": ["Und", "dacht'", ":", "Ach", "da\u00df", "doch", "das", "auch", "uns", "ein", "Bey\u00b7spiel", "w\u00e4\u00b7re", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "ITJ", "KOUS", "ADV", "PDS", "ADV", "PPER", "ART", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Wie nichts so sehr, als Zanck und Streit,", "tokens": ["Wie", "nichts", "so", "sehr", ",", "als", "Zanck", "und", "Streit", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "ADV", "ADV", "$,", "KOUS", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Die ruhige Zufriedenheit", "tokens": ["Die", "ru\u00b7hi\u00b7ge", "Zu\u00b7frie\u00b7den\u00b7heit"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.14": {"text": "Auf dieser Welt vermind're!\u00ab", "tokens": ["Auf", "die\u00b7ser", "Welt", "ver\u00b7min\u00b7d'\u00b7re", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "PDAT", "NN", "VVFIN", "$.", "$("], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}, "line.15": {"text": "Und alle Lust des Lebens hind're!", "tokens": ["Und", "al\u00b7le", "Lust", "des", "Le\u00b7bens", "hin\u00b7d'\u00b7re", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.16": {"text": "Dagegen, wenn man mit der Zeit", "tokens": ["Da\u00b7ge\u00b7gen", ",", "wenn", "man", "mit", "der", "Zeit"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["PAV", "$,", "KOUS", "PIS", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "Und ihrem Strom gelassen fliesset,", "tokens": ["Und", "ih\u00b7rem", "Strom", "ge\u00b7las\u00b7sen", "flies\u00b7set", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVPP", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.18": {"text": "Man vielerley Vergn\u00fcglichkeit,", "tokens": ["Man", "vie\u00b7ler\u00b7ley", "Ver\u00b7gn\u00fcg\u00b7lich\u00b7keit", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PIS", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "Zu Gottes Ruhm, Der sie uns schenckt, geniesset.", "tokens": ["Zu", "Got\u00b7tes", "Ruhm", ",", "Der", "sie", "uns", "schenckt", ",", "ge\u00b7nies\u00b7set", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "NN", "NN", "$,", "ART", "PPER", "PPER", "VVFIN", "$,", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.7": {"line.1": {"text": "\u00bbnoch ward ich einiger aufs neu gewahr,", "tokens": ["\u00bb", "noch", "ward", "ich", "ei\u00b7ni\u00b7ger", "aufs", "neu", "ge\u00b7wahr", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VAFIN", "PPER", "PIAT", "APPRART", "ADJD", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Die (von der Sonnen Glantz bestrahlet) heiter, klar,", "tokens": ["Die", "(", "von", "der", "Son\u00b7nen", "Glantz", "be\u00b7strah\u00b7let", ")", "hei\u00b7ter", ",", "klar", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ART", "$(", "APPR", "ART", "NN", "NN", "VVFIN", "$(", "ADJD", "$,", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und lieblich funckelten, in blauen, bald in gr\u00fcnen,", "tokens": ["Und", "lieb\u00b7lich", "fun\u00b7ckel\u00b7ten", ",", "in", "blau\u00b7en", ",", "bald", "in", "gr\u00fc\u00b7nen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "$,", "APPR", "ADJA", "$,", "ADV", "APPR", "ADJA", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und bald in r\u00f6thlichen, bald gelben, Flammen schienen.", "tokens": ["Und", "bald", "in", "r\u00f6th\u00b7li\u00b7chen", ",", "bald", "gel\u00b7ben", ",", "Flam\u00b7men", "schie\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "ADJA", "$,", "ADV", "VVPP", "$,", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ein jedes St\u00fcckchen Eis, ein jeder kleiner H\u00fcgel", "tokens": ["Ein", "je\u00b7des", "St\u00fcck\u00b7chen", "Eis", ",", "ein", "je\u00b7der", "klei\u00b7ner", "H\u00fc\u00b7gel"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "PIAT", "NN", "NN", "$,", "ART", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Schien recht ein klarer Sonnen-Spiegel,", "tokens": ["Schien", "recht", "ein", "kla\u00b7rer", "Son\u00b7nen\u00b7Spie\u00b7gel", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Der und bald hier, bald dort der Strahlen heitre Pracht,", "tokens": ["Der", "und", "bald", "hier", ",", "bald", "dort", "der", "Strah\u00b7len", "heit\u00b7re", "Pracht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "KON", "ADV", "ADV", "$,", "ADV", "ADV", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "So sonst nicht sichtbar, sichtbar macht.", "tokens": ["So", "sonst", "nicht", "sicht\u00b7bar", ",", "sicht\u00b7bar", "macht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ADV", "PTKNEG", "ADJD", "$,", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Es pr\u00e4gte deren reiner Schein", "tokens": ["Es", "pr\u00e4g\u00b7te", "de\u00b7ren", "rei\u00b7ner", "Schein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PDS", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Recht tief sich den Gedancken ein,", "tokens": ["Recht", "tief", "sich", "den", "Ge\u00b7dan\u00b7cken", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "PRF", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und w\u00fcnsch' ich, da\u00df in meiner kurtzen Fahrt,", "tokens": ["Und", "w\u00fcn\u00b7sch'", "ich", ",", "da\u00df", "in", "mei\u00b7ner", "kurt\u00b7zen", "Fahrt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "$,", "KOUS", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.4": {"text": "Von aller Sonnen ", "tokens": ["Von", "al\u00b7ler", "Son\u00b7nen"], "token_info": ["word", "word", "word"], "pos": ["APPR", "PIAT", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.5": {"text": "Ich auf dergleichen Art,", "tokens": ["Ich", "auf", "derg\u00b7lei\u00b7chen", "Art", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "PIS", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Als wie ein Licht, dem N\u00e4chsten m\u00f6ge dienen!\u00ab", "tokens": ["Als", "wie", "ein", "Licht", ",", "dem", "N\u00e4chs\u00b7ten", "m\u00f6\u00b7ge", "die\u00b7nen", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "KOKOM", "ART", "NN", "$,", "ART", "NN", "VMFIN", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.9": {"line.1": {"text": "Gib, ", "tokens": ["Gib", ","], "token_info": ["word", "punct"], "pos": ["VVIMP", "$,"], "meter": "+", "measure": "single.up"}, "line.2": {"text": "Im Tugend-Glantze sanft vor\u00fcber fliessen m\u00f6ge,", "tokens": ["Im", "Tu\u00b7gen\u00b7dGlant\u00b7ze", "sanft", "vor\u00b7\u00fc\u00b7ber", "flies\u00b7sen", "m\u00f6\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADJD", "ADV", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und auf der nimmer stillen Reise", "tokens": ["Und", "auf", "der", "nim\u00b7mer", "stil\u00b7len", "Rei\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Zum seel'gen Meer der Ewigkeit,", "tokens": ["Zum", "seel'\u00b7gen", "Meer", "der", "E\u00b7wig\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Von aller Laster Ru\u00df befreyt,", "tokens": ["Von", "al\u00b7ler", "Las\u00b7ter", "Ru\u00df", "be\u00b7freyt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "In reinem Wiederschein des Sch\u00f6pfers Allmacht weise!", "tokens": ["In", "rei\u00b7nem", "Wie\u00b7der\u00b7schein", "des", "Sch\u00f6p\u00b7fers", "All\u00b7macht", "wei\u00b7se", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ART", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.10": {"line.1": {"text": "Wer jemals einen Strom voll Treib-Eis fliessen sehn,", "tokens": ["Wer", "je\u00b7mals", "ei\u00b7nen", "Strom", "voll", "Treib\u00b7Eis", "flies\u00b7sen", "sehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "ART", "NN", "ADJD", "NN", "VVINF", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Mit welch gewaltig streng und dennoch stillem Drange,", "tokens": ["Mit", "welch", "ge\u00b7wal\u00b7tig", "streng", "und", "den\u00b7noch", "stil\u00b7lem", "Dran\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PWAT", "ADJD", "VVFIN", "KON", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "In einem ungehemmt- und Wirbel-reichen Gange,", "tokens": ["In", "ei\u00b7nem", "un\u00b7ge\u00b7hemm\u00b7t", "und", "Wir\u00b7bel\u00b7rei\u00b7chen", "Gan\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "TRUNC", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Die Fluth die Schollen f\u00fchrt, der mu\u00df gestehn,", "tokens": ["Die", "Fluth", "die", "Schol\u00b7len", "f\u00fchrt", ",", "der", "mu\u00df", "ge\u00b7stehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VVFIN", "$,", "ART", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Da\u00df es den Augen Lust, dem Hertzen Schrecken,", "tokens": ["Da\u00df", "es", "den", "Au\u00b7gen", "Lust", ",", "dem", "Hert\u00b7zen", "Schre\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "NN", "$,", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Zugleich verm\u00f6gend zu erwecken,", "tokens": ["Zu\u00b7gleich", "ver\u00b7m\u00f6\u00b7gend", "zu", "er\u00b7we\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVPP", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Indem es in der That", "tokens": ["In\u00b7dem", "es", "in", "der", "That"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "Was Majest\u00e4tisches, was gr\u00e4\u00dflich-sch\u00f6nes hat.", "tokens": ["Was", "Ma\u00b7jes\u00b7t\u00e4\u00b7ti\u00b7sches", ",", "was", "gr\u00e4\u00df\u00b7lich\u00b7sch\u00f6\u00b7nes", "hat", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "PIS", "$,", "PWS", "ADJA", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.11": {"line.1": {"text": "Den Augen schwindelt recht, wenn sie ein flaches Feld,", "tokens": ["Den", "Au\u00b7gen", "schwin\u00b7delt", "recht", ",", "wenn", "sie", "ein", "fla\u00b7ches", "Feld", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJD", "$,", "KOUS", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "(wie es von weitem scheint) geborsten, sich bewegen,", "tokens": ["(", "wie", "es", "von", "wei\u00b7tem", "scheint", ")", "ge\u00b7bors\u00b7ten", ",", "sich", "be\u00b7we\u00b7gen", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["$(", "PWAV", "PPER", "APPR", "PIS", "VVFIN", "$(", "VVPP", "$,", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die Erde nicht mehr ruhn, den Boden selbst sich regen,", "tokens": ["Die", "Er\u00b7de", "nicht", "mehr", "ruhn", ",", "den", "Bo\u00b7den", "selbst", "sich", "re\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKNEG", "ADV", "VVINF", "$,", "ART", "NN", "ADV", "PRF", "ADJA", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und Felsen schwimmen sehn. Es reisst die Wasser-Welt,", "tokens": ["Und", "Fel\u00b7sen", "schwim\u00b7men", "sehn", ".", "Es", "reisst", "die", "Was\u00b7ser\u00b7Welt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVINF", "VVINF", "$.", "PPER", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "In schroffen, ungeformt- und ungeheuren St\u00fccken.", "tokens": ["In", "schrof\u00b7fen", ",", "un\u00b7ge\u00b7form\u00b7t", "und", "un\u00b7ge\u00b7heu\u00b7ren", "St\u00fc\u00b7cken", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "VVINF", "$,", "TRUNC", "KON", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "Selbst Berge mit sich fort. Ein w\u00fcstes, kaltes Grau", "tokens": ["Selbst", "Ber\u00b7ge", "mit", "sich", "fort", ".", "Ein", "w\u00fcs\u00b7tes", ",", "kal\u00b7tes", "Grau"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["ADV", "NN", "APPR", "PRF", "PTKVZ", "$.", "ART", "ADJA", "$,", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Deckt Wasser, Land und Strand. Ber\u00f6det, wild und rauh", "tokens": ["Deckt", "Was\u00b7ser", ",", "Land", "und", "Strand", ".", "Be\u00b7r\u00f6\u00b7det", ",", "wild", "und", "rauh"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "NN", "$,", "NN", "KON", "NN", "$.", "VVPP", "$,", "ADJD", "KON", "ADJD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Ist alles, was man sieht. Der Sonne Strahlen schm\u00fccken", "tokens": ["Ist", "al\u00b7les", ",", "was", "man", "sieht", ".", "Der", "Son\u00b7ne", "Strah\u00b7len", "schm\u00fc\u00b7cken"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VAFIN", "PIS", "$,", "PRELS", "PIS", "VVFIN", "$.", "ART", "NN", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Doch \u00f6fters manchen Ort,", "tokens": ["Doch", "\u00f6f\u00b7ters", "man\u00b7chen", "Ort", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PIAT", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.10": {"text": "Da denn bald hier, bald dort,", "tokens": ["Da", "denn", "bald", "hier", ",", "bald", "dort", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "ADV", "$,", "ADV", "ADV", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.11": {"text": "Zumahl an den versteinten Wellen,", "tokens": ["Zu\u00b7mahl", "an", "den", "ver\u00b7stein\u00b7ten", "Wel\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.12": {"text": "Manch schneller Blitz, manch heller Glantz erscheint,", "tokens": ["Manch", "schnel\u00b7ler", "Blitz", ",", "manch", "hel\u00b7ler", "Glantz", "er\u00b7scheint", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "$,", "PIAT", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "So da\u00df man fast nicht anders meynt,", "tokens": ["So", "da\u00df", "man", "fast", "nicht", "an\u00b7ders", "meynt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PIS", "ADV", "PTKNEG", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Als wenn an unterschied'nen Stellen,", "tokens": ["Als", "wenn", "an", "un\u00b7ter\u00b7schie\u00b7d'\u00b7nen", "Stel\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.15": {"text": "Selbst in der kalten Fluth,", "tokens": ["Selbst", "in", "der", "kal\u00b7ten", "Fluth", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.16": {"text": "Man eine bunte Gluht,", "tokens": ["Man", "ei\u00b7ne", "bun\u00b7te", "Gluht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.17": {"text": "Gef\u00e4rbter Flammen funckeln, s\u00e4he.", "tokens": ["Ge\u00b7f\u00e4rb\u00b7ter", "Flam\u00b7men", "fun\u00b7ckeln", ",", "s\u00e4\u00b7he", "."], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["NN", "NN", "VVINF", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Die\u00df alles sah ich j\u00fcngst, und, wie ich in der N\u00e4he", "tokens": ["Die\u00df", "al\u00b7les", "sah", "ich", "j\u00fcngst", ",", "und", ",", "wie", "ich", "in", "der", "N\u00e4\u00b7he"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PDS", "PIS", "VVFIN", "PPER", "ADV", "$,", "KON", "$,", "PWAV", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Im strengen Flu\u00df das Eis schnell vor mir \u00fcberschiessen,", "tokens": ["Im", "stren\u00b7gen", "Flu\u00df", "das", "Eis", "schnell", "vor", "mir", "\u00fc\u00b7bersc\u00b7hies\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "ART", "NN", "ADJD", "APPR", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und eilend, dennoch sanft, best\u00e4ndig vor sich fliessen", "tokens": ["Und", "ei\u00b7lend", ",", "den\u00b7noch", "sanft", ",", "be\u00b7st\u00e4n\u00b7dig", "vor", "sich", "flies\u00b7sen"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVPP", "$,", "ADV", "ADJD", "$,", "ADJD", "APPR", "PRF", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und sich verlieren sah; kam mir", "tokens": ["Und", "sich", "ver\u00b7lie\u00b7ren", "sah", ";", "kam", "mir"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "PRF", "VVINF", "VVFIN", "$.", "VVFIN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "\u00bbdes Stroms nie stiller Zug und sanfte Strengigkeit,", "tokens": ["\u00bb", "des", "Stroms", "nie", "stil\u00b7ler", "Zug", "und", "sanf\u00b7te", "Stren\u00b7gig\u00b7keit", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "ADV", "ADJA", "NN", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Recht, wie der streng' und stille Lauf der Zeit,", "tokens": ["Recht", ",", "wie", "der", "streng'", "und", "stil\u00b7le", "Lauf", "der", "Zeit", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PWAV", "ART", "NN", "KON", "ADJA", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Die Schollen, wie wir Menschen, f\u00fcr.\u00ab", "tokens": ["Die", "Schol\u00b7len", ",", "wie", "wir", "Men\u00b7schen", ",", "f\u00fcr", ".", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct", "punct"], "pos": ["ART", "NN", "$,", "PWAV", "PPER", "NN", "$,", "APPR", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Wir werden durch die Fluth der Zeit dahin gef\u00fchret,", "tokens": ["Wir", "wer\u00b7den", "durch", "die", "Fluth", "der", "Zeit", "da\u00b7hin", "ge\u00b7f\u00fch\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "ART", "NN", "ART", "NN", "PAV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Und weil, das um uns ist, best\u00e4ndig mit uns geht;", "tokens": ["Und", "weil", ",", "das", "um", "uns", "ist", ",", "be\u00b7st\u00e4n\u00b7dig", "mit", "uns", "geht", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "$,", "PRELS", "APPR", "PPER", "VAFIN", "$,", "ADJD", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Wird die gewaltige Bewegung nicht gesp\u00fchret,", "tokens": ["Wird", "die", "ge\u00b7wal\u00b7ti\u00b7ge", "Be\u00b7we\u00b7gung", "nicht", "ge\u00b7sp\u00fch\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "ADJA", "NN", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Ob gleich nicht einer stille steht.", "tokens": ["Ob", "gleich", "nicht", "ei\u00b7ner", "stil\u00b7le", "steht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PTKNEG", "ART", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "\u00bbgebrechlich ist das Eis; Wir auch. die Schollen werden", "tokens": ["\u00bb", "ge\u00b7brech\u00b7lich", "ist", "das", "Eis", ";", "Wir", "auch", ".", "die", "Schol\u00b7len", "wer\u00b7den"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["$(", "ADJD", "VAFIN", "ART", "NN", "$.", "PPER", "ADV", "$.", "ART", "NN", "VAINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Zu ihrem erstem Stoff, zu Wasser; wir zu Erden.", "tokens": ["Zu", "ih\u00b7rem", "ers\u00b7tem", "Stoff", ",", "zu", "Was\u00b7ser", ";", "wir", "zu", "Er\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$,", "APPR", "NN", "$.", "PPER", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die wenigsten sind gro\u00df, die meisten klein;", "tokens": ["Die", "we\u00b7nigs\u00b7ten", "sind", "gro\u00df", ",", "die", "meis\u00b7ten", "klein", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VAFIN", "ADJD", "$,", "PRELS", "PIS", "ADJD", "$."], "meter": "--+--+-+-+", "measure": "anapaest.di.plus"}, "line.4": {"text": "So geht es auch mit uns. Es werden von den Grossen", "tokens": ["So", "geht", "es", "auch", "mit", "uns", ".", "Es", "wer\u00b7den", "von", "den", "Gros\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPR", "PPER", "$.", "PPER", "VAFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die Kleinen mitgef\u00fchrt und fortgestossen;", "tokens": ["Die", "Klei\u00b7nen", "mit\u00b7ge\u00b7f\u00fchrt", "und", "fort\u00b7ges\u00b7tos\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "KON", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Ist die\u00df der Grossen Brauch", "tokens": ["Ist", "die\u00df", "der", "Gros\u00b7sen", "Brauch"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "PDS", "ART", "NN", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Nicht bey den Menschen auch?\u00ab", "tokens": ["Nicht", "bey", "den", "Men\u00b7schen", "auch", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PTKNEG", "APPR", "ART", "NN", "ADV", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "Wenn manche St\u00fcckchen Eis, vom Sonnen-Strahl geschm\u00fcckt,", "tokens": ["Wenn", "man\u00b7che", "St\u00fcck\u00b7chen", "Eis", ",", "vom", "Son\u00b7nen\u00b7Strahl", "ge\u00b7schm\u00fcckt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "NN", "NN", "$,", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Vor andern funckelten; so kommen mir", "tokens": ["Vor", "an\u00b7dern", "fun\u00b7ckel\u00b7ten", ";", "so", "kom\u00b7men", "mir"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "PIS", "VVFIN", "$.", "ADV", "VVFIN", "PPER"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Dieselbigen in ihrer Zier", "tokens": ["Die\u00b7sel\u00b7bi\u00b7gen", "in", "ih\u00b7rer", "Zier"], "token_info": ["word", "word", "word", "word"], "pos": ["PDS", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Als sloche Menschen f\u00fcr,", "tokens": ["Als", "slo\u00b7che", "Men\u00b7schen", "f\u00fcr", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "NN", "APPR", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.12": {"text": "Die in der Welt vor anderen begl\u00fcckt.", "tokens": ["Die", "in", "der", "Welt", "vor", "an\u00b7de\u00b7ren", "be\u00b7gl\u00fcckt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "APPR", "PIS", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "Es w\u00e4hret dieser, so wie jener Herrlichkeit,", "tokens": ["Es", "w\u00e4h\u00b7ret", "die\u00b7ser", ",", "so", "wie", "je\u00b7ner", "Herr\u00b7lich\u00b7keit", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PDS", "$,", "ADV", "KOKOM", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Nur eine kurtze Zeit,", "tokens": ["Nur", "ei\u00b7ne", "kurt\u00b7ze", "Zeit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.15": {"text": "So bald sie sich ein wenig drehen,", "tokens": ["So", "bald", "sie", "sich", "ein", "we\u00b7nig", "dre\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "PRF", "ART", "PIS", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "Sieht man den hellen Glantz den Augenblick vergehen.", "tokens": ["Sieht", "man", "den", "hel\u00b7len", "Glantz", "den", "Au\u00b7gen\u00b7blick", "ver\u00b7ge\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ART", "ADJA", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.14": {"line.1": {"text": "\u00bbverschiedene setzen sich zuammen, und formiren,", "tokens": ["\u00bb", "ver\u00b7schie\u00b7de\u00b7ne", "set\u00b7zen", "sich", "zu\u00b7am\u00b7men", ",", "und", "for\u00b7mi\u00b7ren", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "ADJA", "VVFIN", "PRF", "VVINF", "$,", "KON", "VVFIN", "$,"], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Dem Ansehn nach, ein festes Land;", "tokens": ["Dem", "An\u00b7sehn", "nach", ",", "ein", "fes\u00b7tes", "Land", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "$,", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Doch wird das scheinbar-sichre Band", "tokens": ["Doch", "wird", "das", "schein\u00b7ba\u00b7rsich\u00b7re", "Band"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Festigkeit gar bald verlieren.\u00ab", "tokens": ["Die", "Fes\u00b7tig\u00b7keit", "gar", "bald", "ver\u00b7lie\u00b7ren", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "ADV", "ADV", "VVINF", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Mit diesen k\u00f6mmt ein Regiment, ein Reich,", "tokens": ["Mit", "die\u00b7sen", "k\u00f6mmt", "ein", "Re\u00b7gi\u00b7ment", ",", "ein", "Reich", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PDAT", "VVFIN", "ART", "NN", "$,", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Das aus so mancherley Gem\u00fcthern auch bestehet,", "tokens": ["Das", "aus", "so", "man\u00b7cher\u00b7ley", "Ge\u00b7m\u00fc\u00b7thern", "auch", "be\u00b7ste\u00b7het", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "APPR", "ADV", "PIAT", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Das auch, wie starck es scheint, doch \u00f6fters bald vergehet,", "tokens": ["Das", "auch", ",", "wie", "starck", "es", "scheint", ",", "doch", "\u00f6f\u00b7ters", "bald", "ver\u00b7ge\u00b7het", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "$,", "PWAV", "ADJD", "PPER", "VVFIN", "$,", "ADV", "ADV", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "In billigen Vergleich.", "tokens": ["In", "bil\u00b7li\u00b7gen", "Ver\u00b7gleich", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.15": {"line.1": {"text": "\u00bbich sah mit Lust viel kleine ruhig fliessen,", "tokens": ["\u00bb", "ich", "sah", "mit", "Lust", "viel", "klei\u00b7ne", "ru\u00b7hig", "flies\u00b7sen", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "APPR", "NN", "PIAT", "ADJA", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "So lange sie sich nicht mit andern stiessen.", "tokens": ["So", "lan\u00b7ge", "sie", "sich", "nicht", "mit", "an\u00b7dern", "sties\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "PRF", "PTKNEG", "APPR", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Wann aber das geschah;", "tokens": ["Wann", "a\u00b7ber", "das", "ge\u00b7schah", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "PDS", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Erhob sich alsobald ein Wirbel in der Fluth,", "tokens": ["Er\u00b7hob", "sich", "al\u00b7so\u00b7bald", "ein", "Wir\u00b7bel", "in", "der", "Fluth", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ADV", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ein f\u00fcrchterlichs Gekrach,", "tokens": ["Ein", "f\u00fcrch\u00b7ter\u00b7lichs", "Ge\u00b7krach", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Da\u00df ein St\u00fcck hier, das andre dorten, brach,", "tokens": ["Da\u00df", "ein", "St\u00fcck", "hier", ",", "das", "and\u00b7re", "dor\u00b7ten", ",", "brach", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ADV", "$,", "PRELS", "PIS", "ADV", "$,", "VVFIN", "$,"], "meter": "--+--+-+-+", "measure": "anapaest.di.plus"}, "line.7": {"text": "Und beyde wurde von der Wuth", "tokens": ["Und", "bey\u00b7de", "wur\u00b7de", "von", "der", "Wuth"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PIS", "VAFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Erz\u00fcrnter Wellen umgeschwungen,", "tokens": ["Er\u00b7z\u00fcrn\u00b7ter", "Wel\u00b7len", "um\u00b7ge\u00b7schwun\u00b7gen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Zuweilen auch wohl gar verschlungen.", "tokens": ["Zu\u00b7wei\u00b7len", "auch", "wohl", "gar", "ver\u00b7schlun\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Hieraus nahm ich mir diese Lehre,", "tokens": ["Hier\u00b7aus", "nahm", "ich", "mir", "die\u00b7se", "Leh\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "PPER", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Und dacht': Ach da\u00df doch das auch uns ein Beyspiel w\u00e4re,", "tokens": ["Und", "dacht'", ":", "Ach", "da\u00df", "doch", "das", "auch", "uns", "ein", "Bey\u00b7spiel", "w\u00e4\u00b7re", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "ITJ", "KOUS", "ADV", "PDS", "ADV", "PPER", "ART", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Wie nichts so sehr, als Zanck und Streit,", "tokens": ["Wie", "nichts", "so", "sehr", ",", "als", "Zanck", "und", "Streit", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "ADV", "ADV", "$,", "KOUS", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Die ruhige Zufriedenheit", "tokens": ["Die", "ru\u00b7hi\u00b7ge", "Zu\u00b7frie\u00b7den\u00b7heit"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.14": {"text": "Auf dieser Welt vermind're!\u00ab", "tokens": ["Auf", "die\u00b7ser", "Welt", "ver\u00b7min\u00b7d'\u00b7re", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "PDAT", "NN", "VVFIN", "$.", "$("], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}, "line.15": {"text": "Und alle Lust des Lebens hind're!", "tokens": ["Und", "al\u00b7le", "Lust", "des", "Le\u00b7bens", "hin\u00b7d'\u00b7re", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.16": {"text": "Dagegen, wenn man mit der Zeit", "tokens": ["Da\u00b7ge\u00b7gen", ",", "wenn", "man", "mit", "der", "Zeit"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["PAV", "$,", "KOUS", "PIS", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "Und ihrem Strom gelassen fliesset,", "tokens": ["Und", "ih\u00b7rem", "Strom", "ge\u00b7las\u00b7sen", "flies\u00b7set", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVPP", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.18": {"text": "Man vielerley Vergn\u00fcglichkeit,", "tokens": ["Man", "vie\u00b7ler\u00b7ley", "Ver\u00b7gn\u00fcg\u00b7lich\u00b7keit", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PIS", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "Zu Gottes Ruhm, Der sie uns schenckt, geniesset.", "tokens": ["Zu", "Got\u00b7tes", "Ruhm", ",", "Der", "sie", "uns", "schenckt", ",", "ge\u00b7nies\u00b7set", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "NN", "NN", "$,", "ART", "PPER", "PPER", "VVFIN", "$,", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.16": {"line.1": {"text": "\u00bbnoch ward ich einiger aufs neu gewahr,", "tokens": ["\u00bb", "noch", "ward", "ich", "ei\u00b7ni\u00b7ger", "aufs", "neu", "ge\u00b7wahr", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VAFIN", "PPER", "PIAT", "APPRART", "ADJD", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Die (von der Sonnen Glantz bestrahlet) heiter, klar,", "tokens": ["Die", "(", "von", "der", "Son\u00b7nen", "Glantz", "be\u00b7strah\u00b7let", ")", "hei\u00b7ter", ",", "klar", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ART", "$(", "APPR", "ART", "NN", "NN", "VVFIN", "$(", "ADJD", "$,", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und lieblich funckelten, in blauen, bald in gr\u00fcnen,", "tokens": ["Und", "lieb\u00b7lich", "fun\u00b7ckel\u00b7ten", ",", "in", "blau\u00b7en", ",", "bald", "in", "gr\u00fc\u00b7nen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "$,", "APPR", "ADJA", "$,", "ADV", "APPR", "ADJA", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und bald in r\u00f6thlichen, bald gelben, Flammen schienen.", "tokens": ["Und", "bald", "in", "r\u00f6th\u00b7li\u00b7chen", ",", "bald", "gel\u00b7ben", ",", "Flam\u00b7men", "schie\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "ADJA", "$,", "ADV", "VVPP", "$,", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ein jedes St\u00fcckchen Eis, ein jeder kleiner H\u00fcgel", "tokens": ["Ein", "je\u00b7des", "St\u00fcck\u00b7chen", "Eis", ",", "ein", "je\u00b7der", "klei\u00b7ner", "H\u00fc\u00b7gel"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "PIAT", "NN", "NN", "$,", "ART", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Schien recht ein klarer Sonnen-Spiegel,", "tokens": ["Schien", "recht", "ein", "kla\u00b7rer", "Son\u00b7nen\u00b7Spie\u00b7gel", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Der und bald hier, bald dort der Strahlen heitre Pracht,", "tokens": ["Der", "und", "bald", "hier", ",", "bald", "dort", "der", "Strah\u00b7len", "heit\u00b7re", "Pracht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "KON", "ADV", "ADV", "$,", "ADV", "ADV", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "So sonst nicht sichtbar, sichtbar macht.", "tokens": ["So", "sonst", "nicht", "sicht\u00b7bar", ",", "sicht\u00b7bar", "macht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ADV", "PTKNEG", "ADJD", "$,", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.17": {"line.1": {"text": "Es pr\u00e4gte deren reiner Schein", "tokens": ["Es", "pr\u00e4g\u00b7te", "de\u00b7ren", "rei\u00b7ner", "Schein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PDS", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Recht tief sich den Gedancken ein,", "tokens": ["Recht", "tief", "sich", "den", "Ge\u00b7dan\u00b7cken", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "PRF", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und w\u00fcnsch' ich, da\u00df in meiner kurtzen Fahrt,", "tokens": ["Und", "w\u00fcn\u00b7sch'", "ich", ",", "da\u00df", "in", "mei\u00b7ner", "kurt\u00b7zen", "Fahrt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "$,", "KOUS", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.4": {"text": "Von aller Sonnen ", "tokens": ["Von", "al\u00b7ler", "Son\u00b7nen"], "token_info": ["word", "word", "word"], "pos": ["APPR", "PIAT", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.5": {"text": "Ich auf dergleichen Art,", "tokens": ["Ich", "auf", "derg\u00b7lei\u00b7chen", "Art", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "PIS", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Als wie ein Licht, dem N\u00e4chsten m\u00f6ge dienen!\u00ab", "tokens": ["Als", "wie", "ein", "Licht", ",", "dem", "N\u00e4chs\u00b7ten", "m\u00f6\u00b7ge", "die\u00b7nen", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "KOKOM", "ART", "NN", "$,", "ART", "NN", "VMFIN", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.18": {"line.1": {"text": "Gib, ", "tokens": ["Gib", ","], "token_info": ["word", "punct"], "pos": ["VVIMP", "$,"], "meter": "+", "measure": "single.up"}, "line.2": {"text": "Im Tugend-Glantze sanft vor\u00fcber fliessen m\u00f6ge,", "tokens": ["Im", "Tu\u00b7gen\u00b7dGlant\u00b7ze", "sanft", "vor\u00b7\u00fc\u00b7ber", "flies\u00b7sen", "m\u00f6\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADJD", "ADV", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und auf der nimmer stillen Reise", "tokens": ["Und", "auf", "der", "nim\u00b7mer", "stil\u00b7len", "Rei\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Zum seel'gen Meer der Ewigkeit,", "tokens": ["Zum", "seel'\u00b7gen", "Meer", "der", "E\u00b7wig\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Von aller Laster Ru\u00df befreyt,", "tokens": ["Von", "al\u00b7ler", "Las\u00b7ter", "Ru\u00df", "be\u00b7freyt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "In reinem Wiederschein des Sch\u00f6pfers Allmacht weise!", "tokens": ["In", "rei\u00b7nem", "Wie\u00b7der\u00b7schein", "des", "Sch\u00f6p\u00b7fers", "All\u00b7macht", "wei\u00b7se", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ART", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}