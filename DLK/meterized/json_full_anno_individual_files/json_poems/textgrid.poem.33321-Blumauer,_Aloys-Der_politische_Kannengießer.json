{"textgrid.poem.33321": {"metadata": {"author": {"name": "Blumauer, Aloys", "birth": "N.A.", "death": "N.A."}, "title": "Der politische Kannengie\u00dfer", "genre": "verse", "period": "N.A.", "pub_year": 1776, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Star wei\u00df alle Neuigkeiten,", "tokens": ["Star", "wei\u00df", "al\u00b7le", "Neu\u00b7ig\u00b7kei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PIAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wei\u00df, was man zu allen Zeiten", "tokens": ["Wei\u00df", ",", "was", "man", "zu", "al\u00b7len", "Zei\u00b7ten"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NE", "$,", "PRELS", "PIS", "APPR", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und in allen L\u00e4ndern spricht;", "tokens": ["Und", "in", "al\u00b7len", "L\u00e4n\u00b7dern", "spricht", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PIAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Doch was inner seinen Pf\u00e4hlen", "tokens": ["Doch", "was", "in\u00b7ner", "sei\u00b7nen", "Pf\u00e4h\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PWS", "ADJD", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Laut sich Knecht und Magd erz\u00e4hlen,", "tokens": ["Laut", "sich", "Knecht", "und", "Magd", "er\u00b7z\u00e4h\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRF", "NE", "KON", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Dies allein nur wei\u00df er nicht.", "tokens": ["Dies", "al\u00b7lein", "nur", "wei\u00df", "er", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "ADV", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Der Minister Konferenzen,", "tokens": ["Der", "Mi\u00b7nis\u00b7ter", "Kon\u00b7fe\u00b7ren\u00b7zen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Jedes Hof's Korrespondenzen", "tokens": ["Je\u00b7des", "Hof's", "Kor\u00b7res\u00b7pon\u00b7den\u00b7zen"], "token_info": ["word", "word", "word"], "pos": ["PIAT", "NN", "NN"], "meter": "+--+-+--", "measure": "iambic.tri.invert"}, "line.3": {"text": "Sieht er wie bei hellem Licht;", "tokens": ["Sieht", "er", "wie", "bei", "hel\u00b7lem", "Licht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "KOKOM", "APPR", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Aber was sein Weibchen treibet,", "tokens": ["A\u00b7ber", "was", "sein", "Weib\u00b7chen", "trei\u00b7bet", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Und an wen es Briefe schreibet,", "tokens": ["Und", "an", "wen", "es", "Brie\u00b7fe", "schrei\u00b7bet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PWS", "PPER", "NN", "VVFIN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Dies allein nur wei\u00df er nicht.", "tokens": ["Dies", "al\u00b7lein", "nur", "wei\u00df", "er", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "ADV", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Star wei\u00df, was in Kabineten", "tokens": ["Star", "wei\u00df", ",", "was", "in", "Ka\u00b7bi\u00b7ne\u00b7ten"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["NN", "VVFIN", "$,", "PRELS", "APPR", "NN"], "meter": "+-++-+--", "measure": "unknown.measure.tetra"}, "line.2": {"text": "Man bei nahen Kriegesn\u00f6then", "tokens": ["Man", "bei", "na\u00b7hen", "Krie\u00b7ges\u00b7n\u00f6\u00b7then"], "token_info": ["word", "word", "word", "word"], "pos": ["PIS", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Sich nur in die Ohren spricht;", "tokens": ["Sich", "nur", "in", "die", "Oh\u00b7ren", "spricht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADV", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Aber seines Kutschers Sprache", "tokens": ["A\u00b7ber", "sei\u00b7nes", "Kut\u00b7schers", "Spra\u00b7che"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "In dem nahen Schlafgemache", "tokens": ["In", "dem", "na\u00b7hen", "Schlaf\u00b7ge\u00b7ma\u00b7che"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Seiner Gattin h\u00f6rt er nicht.", "tokens": ["Sei\u00b7ner", "Gat\u00b7tin", "h\u00f6rt", "er", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Von der Grossen Anverwandten,", "tokens": ["Von", "der", "Gros\u00b7sen", "An\u00b7ver\u00b7wand\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ihren Schw\u00e4gern, Basen, Tanten", "tokens": ["Ih\u00b7ren", "Schw\u00e4\u00b7gern", ",", "Ba\u00b7sen", ",", "Tan\u00b7ten"], "token_info": ["word", "word", "punct", "word", "punct", "word"], "pos": ["PPOSAT", "NN", "$,", "NE", "$,", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Gibt er Jedermann Bericht;", "tokens": ["Gibt", "er", "Je\u00b7der\u00b7mann", "Be\u00b7richt", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PIAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Doch die vielen Schw\u00e4gerschaften", "tokens": ["Doch", "die", "vie\u00b7len", "Schw\u00e4\u00b7ger\u00b7schaf\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Die drei Weiber ihm verschafften,", "tokens": ["Die", "drei", "Wei\u00b7ber", "ihm", "ver\u00b7schaff\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "CARD", "NN", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Kennt er noch bis dato nicht.", "tokens": ["Kennt", "er", "noch", "bis", "da\u00b7to", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "ADV", "PTKNEG", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Ueber jedes Staat's Bilanzen,", "tokens": ["Ue\u00b7ber", "je\u00b7des", "Staat's", "Bi\u00b7lan\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Dessen Schulden und Finanzen", "tokens": ["Des\u00b7sen", "Schul\u00b7den", "und", "Fi\u00b7nan\u00b7zen"], "token_info": ["word", "word", "word", "word"], "pos": ["PDAT", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "H\u00e4lt Stax Rechnung und Gericht;", "tokens": ["H\u00e4lt", "Stax", "Rech\u00b7nung", "und", "Ge\u00b7richt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "NN", "KON", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Aber die Laus Deo Flecken,", "tokens": ["A\u00b7ber", "die", "Laus", "Deo", "Fle\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ART", "NN", "$,"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.5": {"text": "Die an seinen Fenstern stecken,", "tokens": ["Die", "an", "sei\u00b7nen", "Fens\u00b7tern", "ste\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "PPOSAT", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Ueberz\u00e4hlt und liest er nicht.", "tokens": ["Ue\u00b7ber\u00b7z\u00e4hlt", "und", "liest", "er", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "KON", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Jedes Hofes Staatsintriguen,", "tokens": ["Je\u00b7des", "Ho\u00b7fes", "Staats\u00b7int\u00b7ri\u00b7gu\u00b7en", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PIAT", "NN", "NN", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Allianzen oder Liguen", "tokens": ["Al\u00b7li\u00b7an\u00b7zen", "o\u00b7der", "Li\u00b7gu\u00b7en"], "token_info": ["word", "word", "word"], "pos": ["NN", "KON", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "H\u00e4lt er auszusp\u00e4h'n f\u00fcr Pflicht;", "tokens": ["H\u00e4lt", "er", "aus\u00b7zu\u00b7sp\u00e4h'n", "f\u00fcr", "Pflicht", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "VVFIN", "APPR", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Aber die Koketterien", "tokens": ["A\u00b7ber", "die", "Ko\u00b7ket\u00b7te\u00b7ri\u00b7en"], "token_info": ["word", "word", "word"], "pos": ["KON", "ART", "NN"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.5": {"text": "Und geheimen Galant'rien", "tokens": ["Und", "ge\u00b7hei\u00b7men", "Ga\u00b7lant'\u00b7ri\u00b7en"], "token_info": ["word", "word", "word"], "pos": ["KON", "ADJA", "NN"], "meter": "--+--+--", "measure": "anapaest.di.plus"}, "line.6": {"text": "Seiner Tochter kennt er nicht.", "tokens": ["Sei\u00b7ner", "Toch\u00b7ter", "kennt", "er", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Von der F\u00fcrsten Testamenten,", "tokens": ["Von", "der", "F\u00fcrs\u00b7ten", "Tes\u00b7ta\u00b7men\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Erbvertr\u00e4gen, Dokumenten,", "tokens": ["Erb\u00b7ver\u00b7tr\u00e4\u00b7gen", ",", "Do\u00b7ku\u00b7men\u00b7ten", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Gibt Stax jedem Unterricht;", "tokens": ["Gibt", "Stax", "je\u00b7dem", "Un\u00b7ter\u00b7richt", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "PIAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Aber was bei seinem Sterben", "tokens": ["A\u00b7ber", "was", "bei", "sei\u00b7nem", "Ster\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PWS", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Seine Kinder werden erben,", "tokens": ["Sei\u00b7ne", "Kin\u00b7der", "wer\u00b7den", "er\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Darum k\u00fcmmert er sich nicht.", "tokens": ["Da\u00b7rum", "k\u00fcm\u00b7mert", "er", "sich", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "PRF", "PTKNEG", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Star wei\u00df alle Neuigkeiten,", "tokens": ["Star", "wei\u00df", "al\u00b7le", "Neu\u00b7ig\u00b7kei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PIAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wei\u00df, was man zu allen Zeiten", "tokens": ["Wei\u00df", ",", "was", "man", "zu", "al\u00b7len", "Zei\u00b7ten"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NE", "$,", "PRELS", "PIS", "APPR", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und in allen L\u00e4ndern spricht;", "tokens": ["Und", "in", "al\u00b7len", "L\u00e4n\u00b7dern", "spricht", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PIAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Doch was inner seinen Pf\u00e4hlen", "tokens": ["Doch", "was", "in\u00b7ner", "sei\u00b7nen", "Pf\u00e4h\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PWS", "ADJD", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Laut sich Knecht und Magd erz\u00e4hlen,", "tokens": ["Laut", "sich", "Knecht", "und", "Magd", "er\u00b7z\u00e4h\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRF", "NE", "KON", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Dies allein nur wei\u00df er nicht.", "tokens": ["Dies", "al\u00b7lein", "nur", "wei\u00df", "er", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "ADV", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Der Minister Konferenzen,", "tokens": ["Der", "Mi\u00b7nis\u00b7ter", "Kon\u00b7fe\u00b7ren\u00b7zen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Jedes Hof's Korrespondenzen", "tokens": ["Je\u00b7des", "Hof's", "Kor\u00b7res\u00b7pon\u00b7den\u00b7zen"], "token_info": ["word", "word", "word"], "pos": ["PIAT", "NN", "NN"], "meter": "+--+-+--", "measure": "iambic.tri.invert"}, "line.3": {"text": "Sieht er wie bei hellem Licht;", "tokens": ["Sieht", "er", "wie", "bei", "hel\u00b7lem", "Licht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "KOKOM", "APPR", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Aber was sein Weibchen treibet,", "tokens": ["A\u00b7ber", "was", "sein", "Weib\u00b7chen", "trei\u00b7bet", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Und an wen es Briefe schreibet,", "tokens": ["Und", "an", "wen", "es", "Brie\u00b7fe", "schrei\u00b7bet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PWS", "PPER", "NN", "VVFIN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Dies allein nur wei\u00df er nicht.", "tokens": ["Dies", "al\u00b7lein", "nur", "wei\u00df", "er", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "ADV", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Star wei\u00df, was in Kabineten", "tokens": ["Star", "wei\u00df", ",", "was", "in", "Ka\u00b7bi\u00b7ne\u00b7ten"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["NN", "VVFIN", "$,", "PRELS", "APPR", "NN"], "meter": "+-++-+--", "measure": "unknown.measure.tetra"}, "line.2": {"text": "Man bei nahen Kriegesn\u00f6then", "tokens": ["Man", "bei", "na\u00b7hen", "Krie\u00b7ges\u00b7n\u00f6\u00b7then"], "token_info": ["word", "word", "word", "word"], "pos": ["PIS", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Sich nur in die Ohren spricht;", "tokens": ["Sich", "nur", "in", "die", "Oh\u00b7ren", "spricht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADV", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Aber seines Kutschers Sprache", "tokens": ["A\u00b7ber", "sei\u00b7nes", "Kut\u00b7schers", "Spra\u00b7che"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "In dem nahen Schlafgemache", "tokens": ["In", "dem", "na\u00b7hen", "Schlaf\u00b7ge\u00b7ma\u00b7che"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Seiner Gattin h\u00f6rt er nicht.", "tokens": ["Sei\u00b7ner", "Gat\u00b7tin", "h\u00f6rt", "er", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Von der Grossen Anverwandten,", "tokens": ["Von", "der", "Gros\u00b7sen", "An\u00b7ver\u00b7wand\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ihren Schw\u00e4gern, Basen, Tanten", "tokens": ["Ih\u00b7ren", "Schw\u00e4\u00b7gern", ",", "Ba\u00b7sen", ",", "Tan\u00b7ten"], "token_info": ["word", "word", "punct", "word", "punct", "word"], "pos": ["PPOSAT", "NN", "$,", "NE", "$,", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Gibt er Jedermann Bericht;", "tokens": ["Gibt", "er", "Je\u00b7der\u00b7mann", "Be\u00b7richt", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PIAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Doch die vielen Schw\u00e4gerschaften", "tokens": ["Doch", "die", "vie\u00b7len", "Schw\u00e4\u00b7ger\u00b7schaf\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Die drei Weiber ihm verschafften,", "tokens": ["Die", "drei", "Wei\u00b7ber", "ihm", "ver\u00b7schaff\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "CARD", "NN", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Kennt er noch bis dato nicht.", "tokens": ["Kennt", "er", "noch", "bis", "da\u00b7to", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "ADV", "PTKNEG", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Ueber jedes Staat's Bilanzen,", "tokens": ["Ue\u00b7ber", "je\u00b7des", "Staat's", "Bi\u00b7lan\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Dessen Schulden und Finanzen", "tokens": ["Des\u00b7sen", "Schul\u00b7den", "und", "Fi\u00b7nan\u00b7zen"], "token_info": ["word", "word", "word", "word"], "pos": ["PDAT", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "H\u00e4lt Stax Rechnung und Gericht;", "tokens": ["H\u00e4lt", "Stax", "Rech\u00b7nung", "und", "Ge\u00b7richt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "NN", "KON", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Aber die Laus Deo Flecken,", "tokens": ["A\u00b7ber", "die", "Laus", "Deo", "Fle\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ART", "NN", "$,"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.5": {"text": "Die an seinen Fenstern stecken,", "tokens": ["Die", "an", "sei\u00b7nen", "Fens\u00b7tern", "ste\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "PPOSAT", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Ueberz\u00e4hlt und liest er nicht.", "tokens": ["Ue\u00b7ber\u00b7z\u00e4hlt", "und", "liest", "er", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "KON", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Jedes Hofes Staatsintriguen,", "tokens": ["Je\u00b7des", "Ho\u00b7fes", "Staats\u00b7int\u00b7ri\u00b7gu\u00b7en", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PIAT", "NN", "NN", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Allianzen oder Liguen", "tokens": ["Al\u00b7li\u00b7an\u00b7zen", "o\u00b7der", "Li\u00b7gu\u00b7en"], "token_info": ["word", "word", "word"], "pos": ["NN", "KON", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "H\u00e4lt er auszusp\u00e4h'n f\u00fcr Pflicht;", "tokens": ["H\u00e4lt", "er", "aus\u00b7zu\u00b7sp\u00e4h'n", "f\u00fcr", "Pflicht", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "VVFIN", "APPR", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Aber die Koketterien", "tokens": ["A\u00b7ber", "die", "Ko\u00b7ket\u00b7te\u00b7ri\u00b7en"], "token_info": ["word", "word", "word"], "pos": ["KON", "ART", "NN"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.5": {"text": "Und geheimen Galant'rien", "tokens": ["Und", "ge\u00b7hei\u00b7men", "Ga\u00b7lant'\u00b7ri\u00b7en"], "token_info": ["word", "word", "word"], "pos": ["KON", "ADJA", "NN"], "meter": "--+--+--", "measure": "anapaest.di.plus"}, "line.6": {"text": "Seiner Tochter kennt er nicht.", "tokens": ["Sei\u00b7ner", "Toch\u00b7ter", "kennt", "er", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "Von der F\u00fcrsten Testamenten,", "tokens": ["Von", "der", "F\u00fcrs\u00b7ten", "Tes\u00b7ta\u00b7men\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Erbvertr\u00e4gen, Dokumenten,", "tokens": ["Erb\u00b7ver\u00b7tr\u00e4\u00b7gen", ",", "Do\u00b7ku\u00b7men\u00b7ten", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Gibt Stax jedem Unterricht;", "tokens": ["Gibt", "Stax", "je\u00b7dem", "Un\u00b7ter\u00b7richt", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "PIAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Aber was bei seinem Sterben", "tokens": ["A\u00b7ber", "was", "bei", "sei\u00b7nem", "Ster\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PWS", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Seine Kinder werden erben,", "tokens": ["Sei\u00b7ne", "Kin\u00b7der", "wer\u00b7den", "er\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Darum k\u00fcmmert er sich nicht.", "tokens": ["Da\u00b7rum", "k\u00fcm\u00b7mert", "er", "sich", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "PRF", "PTKNEG", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}