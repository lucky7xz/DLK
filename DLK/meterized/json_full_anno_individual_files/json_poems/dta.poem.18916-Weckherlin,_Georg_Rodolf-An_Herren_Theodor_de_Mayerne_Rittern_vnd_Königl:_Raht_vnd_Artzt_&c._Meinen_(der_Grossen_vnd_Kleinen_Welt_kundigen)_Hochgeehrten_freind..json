{"dta.poem.18916": {"metadata": {"author": {"name": "Weckherlin, Georg Rodolf", "birth": "N.A.", "death": "N.A."}, "title": "An Herren Theodor   de Mayerne  \n  Rittern vnd K\u00f6nigl: Raht vnd Artzt/   &c.  \n Meinen (der Grossen vnd Kleinen Welt kundigen)  \n Hochgeehrten freind.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1641", "urn": "urn:nbn:de:kobv:b4-200905198111", "language": ["de:0.99"], "booktitle": "Weckherlin, Georg Rodolf: Gaistliche und Weltliche Gedichte. Amsterdam, 1641."}, "poem": {"stanza.1": {"line.1": {"text": "Der leib des gr\u00f6sten Reichs des menschen leib sich", "tokens": ["Der", "leib", "des", "gr\u00f6s\u00b7ten", "Reichs", "des", "men\u00b7schen", "leib", "sich"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "ADJA", "NN", "ART", "ADJA", "NN", "PRF"], "meter": "-+-+-+---+-", "measure": "unknown.measure.tetra"}, "line.2": {"text": "gleichet/", "tokens": ["glei\u00b7chet", "/"], "token_info": ["word", "punct"], "pos": ["VVFIN", "$("], "meter": "+-", "measure": "trochaic.single"}, "line.3": {"text": "In beeden sihet man/ wie mit m\u00fcssigkeit schand/", "tokens": ["In", "bee\u00b7den", "si\u00b7het", "man", "/", "wie", "mit", "m\u00fcs\u00b7sig\u00b7keit", "schand", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "VVFIN", "PIS", "$(", "KOKOM", "APPR", "NN", "VVFIN", "$("], "meter": "-+--+-+-+--+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Durch schand vneinigkeit/ Durch zertrennung", "tokens": ["Durch", "schand", "vnei\u00b7nig\u00b7keit", "/", "Durch", "zer\u00b7tren\u00b7nung"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "VVFIN", "NN", "$(", "APPR", "NN"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.5": {"text": "auffstand/", "tokens": ["auffs\u00b7tand", "/"], "token_info": ["word", "punct"], "pos": ["VVFIN", "$("], "meter": "+-", "measure": "trochaic.single"}, "line.6": {"text": "Durch entp\u00f6rung schwachheit/ durch schwachheit", "tokens": ["Durch", "ent\u00b7p\u00f6\u00b7rung", "schwach\u00b7heit", "/", "durch", "schwach\u00b7heit"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "NN", "VVFIN", "$(", "APPR", "NN"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.7": {"text": "der Tod schleichet.", "tokens": ["der", "Tod", "schlei\u00b7chet", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$."], "meter": "-++-", "measure": "unknown.measure.di"}}, "stanza.2": {"line.1": {"text": "Doch wa\u0303 durch Gottes gnad dz b\u00f6\u00df de\u0304 guten weichet", "tokens": ["Doch", "w\u00e3", "durch", "Got\u00b7tes", "gnad", "dz", "b\u00f6\u00df", "d\u0113", "gu\u00b7ten", "wei\u00b7chet"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "NN", "NN", "KOUS", "ADJD", "ART", "ADJA", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Auff gute\u0304 raht vn\u0303 hilff des haupts vn\u0303 auch d\u2019 ha\u0303d/", "tokens": ["Auff", "gut\u0113", "raht", "v\u00f1", "hilff", "des", "haupts", "v\u00f1", "auch", "d'", "h\u00e3d", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$("], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.3": {"text": "Al\u00dfdan gesundheit/ frid vnd frewd zugleich dz la\u0303d/", "tokens": ["Al\u00df\u00b7dan", "ge\u00b7sund\u00b7heit", "/", "frid", "vnd", "frewd", "zu\u00b7gleich", "dz", "l\u00e3d", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVPP", "$(", "NE", "KON", "NN", "ADV", "KOUS", "NE", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wie auch des mensche\u0304 leib lieblich wider bereichet.", "tokens": ["Wie", "auch", "des", "men\u00b7sch\u0113", "leib", "lieb\u00b7lich", "wi\u00b7der", "be\u00b7rei\u00b7chet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "ART", "NN", "NN", "ADJD", "PTKVZ", "VVFIN", "$."], "meter": "+-+--++-+--+-", "measure": "trochaic.hexa.relaxed"}}, "stanza.3": {"line.1": {"text": "Ach nem das Teutsche Reich/ das jtzt in seinem blut", "tokens": ["Ach", "nem", "das", "Teut\u00b7sche", "Reich", "/", "das", "jtzt", "in", "sei\u00b7nem", "blut"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ITJ", "ADV", "ART", "ADJA", "NN", "$(", "PDS", "ADV", "APPR", "PPOSAT", "NN"], "meter": "---+-+-+-+-+", "measure": "unknown.measure.penta"}, "line.2": {"text": "Gantz zaghafft/ trostlo\u00df/ schwach mit des tods", "tokens": ["Gantz", "zag\u00b7hafft", "/", "trost\u00b7lo\u00df", "/", "schwach", "mit", "des", "tods"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "$(", "VVFIN", "$(", "VVFIN", "APPR", "ART", "NN"], "meter": "+--+-+--+", "measure": "iambic.tetra.invert"}, "line.3": {"text": "band vmbfangen/", "tokens": ["band", "vmb\u00b7fan\u00b7gen", "/"], "token_info": ["word", "word", "punct"], "pos": ["ADV", "VVPP", "$("], "meter": "+-+-", "measure": "trochaic.di"}, "line.4": {"text": "Mayerne deinen Raht allein getrew/ wei\u00df/ gut;", "tokens": ["May\u00b7er\u00b7ne", "dei\u00b7nen", "Raht", "al\u00b7lein", "ge\u00b7trew", "/", "wei\u00df", "/", "gut", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NE", "PPOSAT", "NN", "ADV", "ADJD", "$(", "VVFIN", "$(", "ADJD", "$."], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}}, "stanza.4": {"line.1": {"text": "So solt es nicht allein trost/ hilff vn\u0303 hail empfangen/", "tokens": ["So", "solt", "es", "nicht", "al\u00b7lein", "trost", "/", "hilff", "v\u00f1", "hail", "emp\u00b7fan\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PTKNEG", "ADV", "VVFIN", "$(", "NN", "APPR", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Sondern sein hertz/ hand/ hirn/ von zagheit/", "tokens": ["Son\u00b7dern", "sein", "hertz", "/", "hand", "/", "hirn", "/", "von", "zag\u00b7heit", "/"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "$(", "NN", "$(", "XY", "$(", "APPR", "NN", "$("], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.3": {"text": "schwachheit/ wuht/", "tokens": ["schwach\u00b7heit", "/", "wuht", "/"], "token_info": ["word", "punct", "word", "punct"], "pos": ["ADJD", "$(", "VVFIN", "$("], "meter": "+-+", "measure": "trochaic.di"}, "line.4": {"text": "Gefreyhet/ solten noch Vnsterblichkeit erlangen.", "tokens": ["Ge\u00b7frey\u00b7het", "/", "sol\u00b7ten", "noch", "Vns\u00b7terb\u00b7lich\u00b7keit", "er\u00b7lan\u00b7gen", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "VMFIN", "ADV", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}