{"dta.poem.12256": {"metadata": {"author": {"name": "Brentano, Clemens", "birth": "N.A.", "death": "N.A."}, "title": "Der Ritter und die Magd .", "genre": "Lyrik", "period": "N.A.", "pub_year": "1806", "urn": "urn:nbn:de:kobv:b4-20090519157", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Es spielt ein Ritter mit seiner Magd,               ", "tokens": ["Es", "spielt", "ein", "Rit\u00b7ter", "mit", "sei\u00b7ner", "Magd", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Bis an den hellen Morgen.", "tokens": ["Bis", "an", "den", "hel\u00b7len", "Mor\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Bis da\u00df das M\u00e4dchen schwanger war,", "tokens": ["Bis", "da\u00df", "das", "M\u00e4d\u00b7chen", "schwan\u00b7ger", "war", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "KOUS", "ART", "NN", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da fing es an zu weinen;", "tokens": ["Da", "fing", "es", "an", "zu", "wei\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PTKVZ", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "\u201ewein' nicht, wein' nicht, braun's M\u00e4delein,", "tokens": ["\u201e", "wein'", "nicht", ",", "wein'", "nicht", ",", "braun's", "M\u00e4\u00b7de\u00b7lein", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PTKNEG", "$,", "VVFIN", "PTKNEG", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u201edein Ehr will ich dir zahlen,", "tokens": ["\u201e", "dein", "Ehr", "will", "ich", "dir", "zah\u00b7len", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPOSAT", "NN", "VMFIN", "PPER", "PPER", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "\u201eich will dir geben den Reitknecht mein,", "tokens": ["\u201e", "ich", "will", "dir", "ge\u00b7ben", "den", "Reit\u00b7knecht", "mein", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VMFIN", "PPER", "VVFIN", "ART", "NN", "PPOSAT", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "\u201edazu f\u00fcnfhundert Thaler.\u201c", "tokens": ["\u201e", "da\u00b7zu", "f\u00fcnf\u00b7hun\u00b7dert", "Tha\u00b7ler", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PAV", "CARD", "NN", "$.", "$("], "meter": "+-+--+-", "measure": "pherekrateus"}}, "stanza.5": {"line.1": {"text": "\u201eden Reitknecht und den mag ich nicht,", "tokens": ["\u201e", "den", "Reit\u00b7knecht", "und", "den", "mag", "ich", "nicht", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "KON", "ART", "VMFIN", "PPER", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u201ewill lieber den Herrn selber;", "tokens": ["\u201e", "will", "lie\u00b7ber", "den", "Herrn", "sel\u00b7ber", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VMFIN", "ADV", "ART", "NN", "ADV", "$."], "meter": "-+--++-", "measure": "iambic.tri.relaxed"}}, "stanza.6": {"line.1": {"text": "\u201ewann ich den Herrn nicht selber krieg,", "tokens": ["\u201e", "wann", "ich", "den", "Herrn", "nicht", "sel\u00b7ber", "krieg", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWAV", "PPER", "ART", "NN", "PTKNEG", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u201eso geh ich zu meiner Mutter,", "tokens": ["\u201e", "so", "geh", "ich", "zu", "mei\u00b7ner", "Mut\u00b7ter", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "\u201ein Freuden bin ich von ihr gangen,", "tokens": ["\u201e", "in", "Freu\u00b7den", "bin", "ich", "von", "ihr", "gan\u00b7gen", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "NN", "VAFIN", "PPER", "APPR", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "\u201ein Trauer wieder zu ihr.\u201c", "tokens": ["\u201e", "in", "Trau\u00b7er", "wie\u00b7der", "zu", "ihr", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "APPR", "NN", "ADV", "APPR", "PPOSAT", "$.", "$("], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.8": {"line.1": {"text": "Und da sie vor die Stadt Augsburg kam,", "tokens": ["Und", "da", "sie", "vor", "die", "Stadt", "Augs\u00b7burg", "kam", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "APPR", "ART", "NN", "NE", "VVFIN", "$,"], "meter": "-+----+-+", "measure": "dactylic.init"}, "line.2": {"text": "Wohl in die enge Gasse,", "tokens": ["Wohl", "in", "die", "en\u00b7ge", "Gas\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Da sah sie ihre Mutter stehn,", "tokens": ["Da", "sah", "sie", "ih\u00b7re", "Mut\u00b7ter", "stehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "An einem k\u00fchlen Wasser.", "tokens": ["An", "ei\u00b7nem", "k\u00fch\u00b7len", "Was\u00b7ser", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "\u201ebist du willkommen liebs T\u00f6chterlein,", "tokens": ["\u201e", "bist", "du", "will\u00b7kom\u00b7men", "liebs", "T\u00f6ch\u00b7ter\u00b7lein", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VAFIN", "PPER", "ADJD", "ADJA", "NN", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.2": {"text": "\u201ewie ist es dir ergangen,", "tokens": ["\u201e", "wie", "ist", "es", "dir", "er\u00b7gan\u00b7gen", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWAV", "VAFIN", "PPER", "PPER", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "\u201eda\u00df dir dein Rock von vorne so klein,", "tokens": ["\u201e", "da\u00df", "dir", "dein", "Rock", "von", "vor\u00b7ne", "so", "klein", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "PPER", "PPOSAT", "NN", "APPR", "ADV", "ADV", "ADJD", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "\u201eund hinten viel zu lange?\u201c", "tokens": ["\u201e", "und", "hin\u00b7ten", "viel", "zu", "lan\u00b7ge", "?", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "KON", "ADV", "ADV", "PTKA", "ADV", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "\u201eund wie es mir ergangen ist,", "tokens": ["\u201e", "und", "wie", "es", "mir", "er\u00b7gan\u00b7gen", "ist", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KON", "PWAV", "PPER", "PPER", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u201edas darf ich Euch wohl sagen:", "tokens": ["\u201e", "das", "darf", "ich", "Euch", "wohl", "sa\u00b7gen", ":"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PDS", "VMFIN", "PPER", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.13": {"line.1": {"text": "\u201eich hab mit einem Edelherrn gespielt,", "tokens": ["\u201e", "ich", "hab", "mit", "ei\u00b7nem", "E\u00b7del\u00b7herrn", "ge\u00b7spielt", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "\u201eein Kindlein mu\u00df ich tragen.\u201c", "tokens": ["\u201e", "ein", "Kin\u00b7dlein", "mu\u00df", "ich", "tra\u00b7gen", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ART", "NN", "VMFIN", "PPER", "VVINF", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.14": {"line.1": {"text": "\u201ehast du mit einem Edelherrn gespielt,", "tokens": ["\u201e", "hast", "du", "mit", "ei\u00b7nem", "E\u00b7del\u00b7herrn", "ge\u00b7spielt", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VAFIN", "PPER", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "\u201edas sollst du niemand sagen.", "tokens": ["\u201e", "das", "sollst", "du", "nie\u00b7mand", "sa\u00b7gen", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PDS", "VMFIN", "PPER", "PIS", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.15": {"line.1": {"text": "\u201ewenn du dein Kindlein zur Welt gebierst,", "tokens": ["\u201e", "wenn", "du", "dein", "Kin\u00b7dlein", "zur", "Welt", "ge\u00b7bierst", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "PPER", "PPOSAT", "NN", "APPRART", "NN", "VVPP", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.2": {"text": "\u201eins Wasser wollen wirs tragen.\u201c", "tokens": ["\u201e", "ins", "Was\u00b7ser", "wol\u00b7len", "wirs", "tra\u00b7gen", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "APPRART", "NN", "VMFIN", "PIS", "VVINF", "$.", "$("], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.16": {"line.1": {"text": "\u201each nein, ach nein, liebe Mutter mein,", "tokens": ["\u201e", "ach", "nein", ",", "ach", "nein", ",", "lie\u00b7be", "Mut\u00b7ter", "mein", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "PTKANT", "$,", "XY", "PTKANT", "$,", "ADJA", "NN", "PPOSAT", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "\u201edas wollen wir lassen bleiben.", "tokens": ["\u201e", "das", "wol\u00b7len", "wir", "las\u00b7sen", "blei\u00b7ben", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PDS", "VMFIN", "PPER", "VVINF", "VVINF", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.17": {"line.1": {"text": "\u201ewann ich das Kind zur Welt geb\u00e4hr,", "tokens": ["\u201e", "wann", "ich", "das", "Kind", "zur", "Welt", "ge\u00b7b\u00e4hr", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWAV", "PPER", "ART", "NN", "APPRART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u201edem Vater will ich zuschreiben.", "tokens": ["\u201e", "dem", "Va\u00b7ter", "will", "ich", "zu\u00b7schrei\u00b7ben", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.18": {"line.1": {"text": "\u201each Mutter, liebe Mutter mein,", "tokens": ["\u201e", "ach", "Mut\u00b7ter", ",", "lie\u00b7be", "Mut\u00b7ter", "mein", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "XY", "NN", "$,", "ADJA", "NN", "PPOSAT", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u201emachet mir das Bettlein nicht zu klein,", "tokens": ["\u201e", "ma\u00b7chet", "mir", "das", "Bet\u00b7tlein", "nicht", "zu", "klein", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PPER", "ART", "NN", "PTKNEG", "PTKA", "ADJD", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.19": {"line.1": {"text": "\u201edarin will ich leiden Schmerz und Pein,", "tokens": ["\u201e", "da\u00b7rin", "will", "ich", "lei\u00b7den", "Schmerz", "und", "Pein", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PAV", "VMFIN", "PPER", "ADJA", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "\u201edazu den bittern Tod.\u201c", "tokens": ["\u201e", "da\u00b7zu", "den", "bit\u00b7tern", "Tod", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PAV", "ART", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.20": {"line.1": {"text": "Und da es war um Mitternacht,", "tokens": ["Und", "da", "es", "war", "um", "Mit\u00b7ter\u00b7nacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "VAFIN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dem Edelherrn tr\u00e4umt es schwer:", "tokens": ["Dem", "E\u00b7del\u00b7herrn", "tr\u00e4umt", "es", "schwer", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADJD", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.21": {"line.1": {"text": "Als wenn sein herzallerliebster Schatz", "tokens": ["Als", "wenn", "sein", "her\u00b7zal\u00b7ler\u00b7liebs\u00b7ter", "Schatz"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "KOUS", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Im Kindbett gestorben w\u00e4r.", "tokens": ["Im", "Kind\u00b7bett", "ge\u00b7stor\u00b7ben", "w\u00e4r", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVPP", "VAFIN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.22": {"line.1": {"text": "\u201esteh auf, steh auf, lieb Reitknecht mein,", "tokens": ["\u201e", "steh", "auf", ",", "steh", "auf", ",", "lieb", "Reit\u00b7knecht", "mein", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PTKVZ", "$,", "VVFIN", "PTKVZ", "$,", "ADJD", "NN", "PPOSAT", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u201esattle mir und dir zwey Pferd,", "tokens": ["\u201e", "satt\u00b7le", "mir", "und", "dir", "zwey", "Pferd", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PPER", "KON", "PPER", "CARD", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.23": {"line.1": {"text": "\u201ewir wollen reiten bey Tag und Nacht,", "tokens": ["\u201e", "wir", "wol\u00b7len", "rei\u00b7ten", "bey", "Tag", "und", "Nacht", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VMFIN", "VVFIN", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "\u201ebis wir den Traum erfahren.\u201c", "tokens": ["\u201e", "bis", "wir", "den", "Traum", "er\u00b7fah\u00b7ren", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "KOUS", "PPER", "ART", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.24": {"line.1": {"text": "Und als sie \u00fcber die Heid 'naus kamen,", "tokens": ["Und", "als", "sie", "\u00fc\u00b7ber", "die", "Heid", "'naus", "ka\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "APPR", "ART", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "H\u00f6rten sie ein Gl\u00f6cklein l\u00e4uten.", "tokens": ["H\u00f6r\u00b7ten", "sie", "ein", "Gl\u00f6c\u00b7klein", "l\u00e4u\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "+---+-+-", "measure": "dactylic.init"}}, "stanza.25": {"line.1": {"text": "\u201each gro\u00dfer Gott vom Himmel herab,", "tokens": ["\u201e", "ach", "gro\u00b7\u00dfer", "Gott", "vom", "Him\u00b7mel", "her\u00b7ab", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "ADJA", "NN", "APPRART", "NN", "ADV", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "\u201ewas mag doch die\u00df bedeuten.\u201c", "tokens": ["\u201e", "was", "mag", "doch", "die\u00df", "be\u00b7deu\u00b7ten", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PWS", "VMFIN", "ADV", "PDS", "VVINF", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.26": {"line.1": {"text": "Als sie vor die Stadt Augsburg kamen,", "tokens": ["Als", "sie", "vor", "die", "Stadt", "Augs\u00b7burg", "ka\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ART", "NN", "NE", "VVFIN", "$,"], "meter": "-+---+-+-", "measure": "dactylic.init"}, "line.2": {"text": "Wohl vor die hohe Thore,", "tokens": ["Wohl", "vor", "die", "ho\u00b7he", "Tho\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.27": {"line.1": {"text": "Hier sahen sie vier Tr\u00e4ger schwarz,", "tokens": ["Hier", "sa\u00b7hen", "sie", "vier", "Tr\u00e4\u00b7ger", "schwarz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "CARD", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mit einer Todenbahre.", "tokens": ["Mit", "ei\u00b7ner", "To\u00b7den\u00b7bah\u00b7re", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.28": {"line.1": {"text": "\u201estellt ab, stellt ab, ih Tr\u00e4ger mein,", "tokens": ["\u201e", "stellt", "ab", ",", "stellt", "ab", ",", "ih", "Tr\u00e4\u00b7ger", "mein", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PTKVZ", "$,", "VVFIN", "PTKVZ", "$,", "PPER", "NN", "PPOSAT", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u201ela\u00dft mir den Todten schauen,", "tokens": ["\u201e", "la\u00dft", "mir", "den", "Tod\u00b7ten", "schau\u00b7en", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVIMP", "PPER", "ART", "NN", "VVINF", "$,"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}}, "stanza.29": {"line.1": {"text": "\u201ees m\u00f6cht meine Herzallerliebste sein", "tokens": ["\u201e", "es", "m\u00f6cht", "mei\u00b7ne", "Her\u00b7zal\u00b7ler\u00b7liebs\u00b7te", "sein"], "token_info": ["punct", "word", "word", "word", "word", "word"], "pos": ["$(", "PPER", "VMFIN", "PPOSAT", "NN", "PPOSAT"], "meter": "-++--+-+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "\u201emit ihren schwarzbraunen Augen.", "tokens": ["\u201e", "mit", "ih\u00b7ren", "schwarz\u00b7brau\u00b7nen", "Au\u00b7gen", "."], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-++-+-", "measure": "unknown.measure.tetra"}}, "stanza.30": {"line.1": {"text": "\u201edu bist f\u00fcrwahr mein Schatz gewe\u00dft,", "tokens": ["\u201e", "du", "bist", "f\u00fcr\u00b7wahr", "mein", "Schatz", "ge\u00b7we\u00dft", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "ADV", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u201eund hast es nicht geglaubet.", "tokens": ["\u201e", "und", "hast", "es", "nicht", "ge\u00b7glau\u00b7bet", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KON", "VAFIN", "PPER", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.31": {"line.1": {"text": "\u201eh\u00e4tt dir der liebe Gott das Leben geschenkt,", "tokens": ["\u201e", "h\u00e4tt", "dir", "der", "lie\u00b7be", "Gott", "das", "Le\u00b7ben", "ge\u00b7schenkt", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VAFIN", "PPER", "ART", "ADJA", "NN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.2": {"text": "\u201ef\u00fcrwahr ich h\u00e4tt dich behalten.", "tokens": ["\u201e", "f\u00fcr\u00b7wahr", "ich", "h\u00e4tt", "dich", "be\u00b7hal\u00b7ten", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PPER", "VAFIN", "PPER", "VVINF", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.32": {"line.1": {"text": "\u201ehast du gelitten den bittern Tod,", "tokens": ["\u201e", "hast", "du", "ge\u00b7lit\u00b7ten", "den", "bit\u00b7tern", "Tod", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VAFIN", "PPER", "VVPP", "ART", "ADJA", "NN", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.2": {"text": "\u201ejezt leid ich gro\u00dfe Schmerzen.\u201c", "tokens": ["\u201e", "jezt", "leid", "ich", "gro\u00b7\u00dfe", "Schmer\u00b7zen", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADV", "ADJD", "PPER", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.33": {"line.1": {"text": "Er zog das blanke Schwerdt heraus", "tokens": ["Er", "zog", "das", "blan\u00b7ke", "Schwerdt", "he\u00b7raus"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und stach es sich ins Herze.", "tokens": ["Und", "stach", "es", "sich", "ins", "Her\u00b7ze", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PRF", "APPRART", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.34": {"line.1": {"text": "\u201eo nein! o nein! o Edelherr!", "tokens": ["\u201e", "o", "nein", "!", "o", "nein", "!", "o", "E\u00b7del\u00b7herr", "!"], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "FM", "PTKANT", "$.", "FM", "PTKANT", "$.", "FM", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u201enein das sollt ihr lassen bleiben,", "tokens": ["\u201e", "nein", "das", "sollt", "ihr", "las\u00b7sen", "blei\u00b7ben", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PTKANT", "PDS", "VMFIN", "PPER", "VVINF", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.35": {"line.1": {"text": "\u201ees hat schon manches liebe Paar,", "tokens": ["\u201e", "es", "hat", "schon", "man\u00b7ches", "lie\u00b7be", "Paar", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "ADV", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u201evon einander m\u00fcssen scheiden.\u201c", "tokens": ["\u201e", "von", "ein\u00b7an\u00b7der", "m\u00fcs\u00b7sen", "schei\u00b7den", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "APPR", "PRF", "VMFIN", "VVINF", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.36": {"line.1": {"text": "\u201emacht uns, macht uns ein tiefes Grab,", "tokens": ["\u201e", "macht", "uns", ",", "macht", "uns", "ein", "tie\u00b7fes", "Grab", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PPER", "$,", "VVFIN", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.2": {"text": "\u201ewohl zwischen zwey hohe Felsen.", "tokens": ["\u201e", "wohl", "zwi\u00b7schen", "zwey", "ho\u00b7he", "Fel\u00b7sen", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "APPR", "CARD", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.37": {"line.1": {"text": "\u201eda will ich bey meinem herzliebsten Schatz,", "tokens": ["\u201e", "da", "will", "ich", "bey", "mei\u00b7nem", "herz\u00b7liebs\u00b7ten", "Schatz", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VMFIN", "PPER", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "\u201ein seinem Arm erstehen.\u201c", "tokens": ["\u201e", "in", "sei\u00b7nem", "Arm", "er\u00b7ste\u00b7hen", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "APPR", "PPOSAT", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.38": {"line.1": {"text": "Sie begruben sie auf den Kirchhof hin,", "tokens": ["Sie", "be\u00b7gru\u00b7ben", "sie", "auf", "den", "Kirch\u00b7hof", "hin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "ART", "NN", "PTKVZ", "$,"], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Ihn aber unter den Galgen.", "tokens": ["Ihn", "a\u00b7ber", "un\u00b7ter", "den", "Gal\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.39": {"line.1": {"text": "Es stunde an kein Vierteljahr,", "tokens": ["Es", "stun\u00b7de", "an", "kein", "Vier\u00b7tel\u00b7jahr", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Eine Lilie w\u00e4chst auf seinem Grabe.", "tokens": ["Ei\u00b7ne", "Li\u00b7lie", "w\u00e4chst", "auf", "sei\u00b7nem", "Gra\u00b7be", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.40": {"line.1": {"text": "Es stund geschrieben auf den Bl\u00e4ttern da,", "tokens": ["Es", "stund", "ge\u00b7schrie\u00b7ben", "auf", "den", "Bl\u00e4t\u00b7tern", "da", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "VVPP", "APPR", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Beyd w\u00e4ren beysammen im Himmel.", "tokens": ["Beyd", "w\u00e4\u00b7ren", "bey\u00b7sam\u00b7men", "im", "Him\u00b7mel", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "VVPP", "APPRART", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}}}}