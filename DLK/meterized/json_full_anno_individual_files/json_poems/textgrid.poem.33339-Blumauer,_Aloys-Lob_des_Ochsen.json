{"textgrid.poem.33339": {"metadata": {"author": {"name": "Blumauer, Aloys", "birth": "N.A.", "death": "N.A."}, "title": "Lob des Ochsen", "genre": "verse", "period": "N.A.", "pub_year": 1776, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Du edles Thier, von dessen Fleisch wir essen,", "tokens": ["Du", "ed\u00b7les", "Thier", ",", "von", "des\u00b7sen", "Fleisch", "wir", "es\u00b7sen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "$,", "APPR", "PRELAT", "NN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Auf dessen Haut wir geh'n,", "tokens": ["Auf", "des\u00b7sen", "Haut", "wir", "geh'n", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELAT", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Du, den die Dichter, ach, so ganz vergessen!", "tokens": ["Du", ",", "den", "die", "Dich\u00b7ter", ",", "ach", ",", "so", "ganz", "ver\u00b7ges\u00b7sen", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PRELS", "ART", "NN", "$,", "ITJ", "$,", "ADV", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Dich soll mein Lied erh\u00f6h'n.", "tokens": ["Dich", "soll", "mein", "Lied", "er\u00b7h\u00f6h'", "n."], "token_info": ["word", "word", "word", "word", "word", "abbreviation"], "pos": ["PPER", "VMFIN", "PPOSAT", "NN", "VVFIN", "NE"], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Man kann Orest und Pylades nicht trennen,", "tokens": ["Man", "kann", "O\u00b7rest", "und", "Py\u00b7la\u00b7des", "nicht", "tren\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "NE", "KON", "NE", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Wenn man von Einem spricht,", "tokens": ["Wenn", "man", "von", "Ei\u00b7nem", "spricht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "APPR", "PIS", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Den Esel pflegt man hundertmal zu nennen,", "tokens": ["Den", "E\u00b7sel", "pflegt", "man", "hun\u00b7dert\u00b7mal", "zu", "nen\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PIS", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+---", "measure": "unknown.measure.tetra"}, "line.4": {"text": "Und dein gedenkt man nicht.", "tokens": ["Und", "dein", "ge\u00b7denkt", "man", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "VVFIN", "PIS", "PTKNEG", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Das tr\u00e4ge Thier bek\u00f6mmt die fettsten Pfr\u00fcnden,", "tokens": ["Das", "tr\u00e4\u00b7ge", "Thier", "be\u00b7k\u00f6mmt", "die", "fetts\u00b7ten", "Pfr\u00fcn\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Dich spannt man an den Pflug;", "tokens": ["Dich", "spannt", "man", "an", "den", "Pflug", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "APPR", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Du bist, um unter uns dein Gl\u00fcck zu finden,", "tokens": ["Du", "bist", ",", "um", "un\u00b7ter", "uns", "dein", "Gl\u00fcck", "zu", "fin\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "KOUI", "APPR", "PPER", "PPOSAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Nicht unbrauchbar genug.", "tokens": ["Nicht", "un\u00b7brauch\u00b7bar", "ge\u00b7nug", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PTKNEG", "ADJD", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Arbeitsamkeit ist immer zu bedauern,", "tokens": ["Ar\u00b7beit\u00b7sam\u00b7keit", "ist", "im\u00b7mer", "zu", "be\u00b7dau\u00b7ern", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ADV", "PTKZU", "VVINF", "$,"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.2": {"text": "Damit bringts keiner hoch,", "tokens": ["Da\u00b7mit", "bringts", "kei\u00b7ner", "hoch", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PIS", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "W\u00e4rst du nicht stark, man spannte mit den Bauern", "tokens": ["W\u00e4rst", "du", "nicht", "stark", ",", "man", "spann\u00b7te", "mit", "den", "Bau\u00b7ern"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "PTKNEG", "ADJD", "$,", "PIS", "VVFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Dich niemals an ein Joch.", "tokens": ["Dich", "nie\u00b7mals", "an", "ein", "Joch", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Du bist sowohl gesotten als gebraten", "tokens": ["Du", "bist", "so\u00b7wohl", "ge\u00b7sot\u00b7ten", "als", "ge\u00b7bra\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "VVPP", "KOKOM", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Bei Jedermann beliebt,", "tokens": ["Bei", "Je\u00b7der\u00b7mann", "be\u00b7liebt", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PIS", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Du bist das Magazin: das ganzen Staaten", "tokens": ["Du", "bist", "das", "Ma\u00b7ga\u00b7zin", ":", "das", "gan\u00b7zen", "Staa\u00b7ten"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "NN", "$.", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Zur H\u00e4lfte Nahrung gibt.", "tokens": ["Zur", "H\u00e4lf\u00b7te", "Nah\u00b7rung", "gibt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Was f\u00fcr ein Thier hat sich im Nahrungsstande,", "tokens": ["Was", "f\u00fcr", "ein", "Thier", "hat", "sich", "im", "Nah\u00b7rungs\u00b7stan\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "ART", "NN", "VAFIN", "PRF", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Wie du, signalisirt?", "tokens": ["Wie", "du", ",", "sig\u00b7na\u00b7li\u00b7sirt", "?"], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["PWAV", "PPER", "$,", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und dennoch hat man dich in keinem Lande", "tokens": ["Und", "den\u00b7noch", "hat", "man", "dich", "in", "kei\u00b7nem", "Lan\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VAFIN", "PIS", "PRF", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Daf\u00fcr nobilitirt.", "tokens": ["Da\u00b7f\u00fcr", "no\u00b7bi\u00b7li\u00b7tirt", "."], "token_info": ["word", "word", "punct"], "pos": ["PAV", "VVPP", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}}, "stanza.7": {"line.1": {"text": "Du gibst mit deinem Fett bei schlechtem Futter", "tokens": ["Du", "gibst", "mit", "dei\u00b7nem", "Fett", "bei", "schlech\u00b7tem", "Fut\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Der halben Erde Licht;", "tokens": ["Der", "hal\u00b7ben", "Er\u00b7de", "Licht", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ein Domherrnbauch, gef\u00fcllt mit eitel Butter,", "tokens": ["Ein", "Dom\u00b7herrn\u00b7bauch", ",", "ge\u00b7f\u00fcllt", "mit", "ei\u00b7tel", "But\u00b7ter", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "VVPP", "APPR", "ADJD", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Stinkt nur und leuchtet nicht.", "tokens": ["Stinkt", "nur", "und", "leuch\u00b7tet", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "KON", "VVFIN", "PTKNEG", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Der Esel ward ber\u00fchmt, weil er vor Zeiten", "tokens": ["Der", "E\u00b7sel", "ward", "be\u00b7r\u00fchmt", ",", "weil", "er", "vor", "Zei\u00b7ten"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ADJD", "$,", "KOUS", "PPER", "APPR", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Sein Ohr dem Midas lieh:", "tokens": ["Sein", "Ohr", "dem", "Mi\u00b7das", "lieh", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Du leihst dein Horn so vielen gro\u00dfen Leuten,", "tokens": ["Du", "leihst", "dein", "Horn", "so", "vie\u00b7len", "gro\u00b7\u00dfen", "Leu\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "ADV", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und davon spricht man nie.", "tokens": ["Und", "da\u00b7von", "spricht", "man", "nie", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PAV", "VVFIN", "PIS", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "So viel durch dich auch grosse M\u00e4nner prangen,", "tokens": ["So", "viel", "durch", "dich", "auch", "gros\u00b7se", "M\u00e4n\u00b7ner", "pran\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "PPER", "ADV", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "So sch\u00f6n dein Horn sie ziert,", "tokens": ["So", "sch\u00f6n", "dein", "Horn", "sie", "ziert", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPOSAT", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "So werden doch daraus zum L\u00e4usefangen", "tokens": ["So", "wer\u00b7den", "doch", "da\u00b7raus", "zum", "L\u00e4u\u00b7se\u00b7fan\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ADV", "PAV", "APPRART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Nur K\u00e4mme fabricirt.", "tokens": ["Nur", "K\u00e4m\u00b7me", "fab\u00b7ri\u00b7cirt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "NN", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "Doch besser denkt von deiner H\u00f6rner St\u00e4rke", "tokens": ["Doch", "bes\u00b7ser", "denkt", "von", "dei\u00b7ner", "H\u00f6r\u00b7ner", "St\u00e4r\u00b7ke"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "VVFIN", "APPR", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Der Dialektiker;", "tokens": ["Der", "Di\u00b7a\u00b7lek\u00b7ti\u00b7ker", ";"], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$."], "meter": "-+-+--", "measure": "unknown.measure.di"}, "line.3": {"text": "Die h\u00f6chste Kraft zum Ueberzeugungswerke", "tokens": ["Die", "h\u00f6chs\u00b7te", "Kraft", "zum", "Ue\u00b7ber\u00b7zeu\u00b7gungs\u00b7wer\u00b7ke"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "APPRART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Nimmt er von ihnen her.", "tokens": ["Nimmt", "er", "von", "ih\u00b7nen", "her", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "PPER", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "Dein Doppelhorn hat eine \u00fcbergrosse", "tokens": ["Dein", "Dop\u00b7pel\u00b7horn", "hat", "ei\u00b7ne", "\u00fc\u00b7berg\u00b7ros\u00b7se"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VAFIN", "ART", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Gewalt in seiner Hand,", "tokens": ["Ge\u00b7walt", "in", "sei\u00b7ner", "Hand", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Es st\u00f6\u00dft dem Gegenpart bei jedem Stosse", "tokens": ["Es", "st\u00f6\u00dft", "dem", "Ge\u00b7gen\u00b7part", "bei", "je\u00b7dem", "Stos\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Ein Loch in den Verstand.", "tokens": ["Ein", "Loch", "in", "den", "Ver\u00b7stand", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "Ja, Freund, so lang die Welt Juristen, Pfaffen", "tokens": ["Ja", ",", "Freund", ",", "so", "lang", "die", "Welt", "Ju\u00b7ris\u00b7ten", ",", "Pfaf\u00b7fen"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["PTKANT", "$,", "NN", "$,", "ADV", "ADJD", "ART", "NN", "NN", "$,", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und Theologen hat,", "tokens": ["Und", "Theo\u00b7lo\u00b7gen", "hat", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "NN", "VAFIN", "$,"], "meter": "-++-+", "measure": "unknown.measure.tri"}, "line.3": {"text": "Besch\u00fctzest du allein mit diesen Waffen", "tokens": ["Be\u00b7sch\u00fct\u00b7zest", "du", "al\u00b7lein", "mit", "die\u00b7sen", "Waf\u00b7fen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Religion und Staat.", "tokens": ["Re\u00b7li\u00b7gi\u00b7on", "und", "Staat", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}}, "stanza.13": {"line.1": {"text": "D'rum haben auch die guten G\u00f6tter immer", "tokens": ["D'\u00b7rum", "ha\u00b7ben", "auch", "die", "gu\u00b7ten", "G\u00f6t\u00b7ter", "im\u00b7mer"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PAV", "VAFIN", "ADV", "ART", "ADJA", "NN", "ADV"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.2": {"text": "Dein Doppelhorn gesch\u00e4tzt,", "tokens": ["Dein", "Dop\u00b7pel\u00b7horn", "ge\u00b7sch\u00e4tzt", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und es verkl\u00e4rt mit hellem Silberschimmer", "tokens": ["Und", "es", "ver\u00b7kl\u00e4rt", "mit", "hel\u00b7lem", "Sil\u00b7ber\u00b7schim\u00b7mer"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "In unsern Mond versetzt.", "tokens": ["In", "un\u00b7sern", "Mond", "ver\u00b7setzt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.14": {"line.1": {"text": "Du edles Thier, von dessen Fleisch wir essen,", "tokens": ["Du", "ed\u00b7les", "Thier", ",", "von", "des\u00b7sen", "Fleisch", "wir", "es\u00b7sen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "$,", "APPR", "PRELAT", "NN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Auf dessen Haut wir geh'n,", "tokens": ["Auf", "des\u00b7sen", "Haut", "wir", "geh'n", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELAT", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Du, den die Dichter, ach, so ganz vergessen!", "tokens": ["Du", ",", "den", "die", "Dich\u00b7ter", ",", "ach", ",", "so", "ganz", "ver\u00b7ges\u00b7sen", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PRELS", "ART", "NN", "$,", "ITJ", "$,", "ADV", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Dich soll mein Lied erh\u00f6h'n.", "tokens": ["Dich", "soll", "mein", "Lied", "er\u00b7h\u00f6h'", "n."], "token_info": ["word", "word", "word", "word", "word", "abbreviation"], "pos": ["PPER", "VMFIN", "PPOSAT", "NN", "VVFIN", "NE"], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.15": {"line.1": {"text": "Man kann Orest und Pylades nicht trennen,", "tokens": ["Man", "kann", "O\u00b7rest", "und", "Py\u00b7la\u00b7des", "nicht", "tren\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "NE", "KON", "NE", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Wenn man von Einem spricht,", "tokens": ["Wenn", "man", "von", "Ei\u00b7nem", "spricht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "APPR", "PIS", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Den Esel pflegt man hundertmal zu nennen,", "tokens": ["Den", "E\u00b7sel", "pflegt", "man", "hun\u00b7dert\u00b7mal", "zu", "nen\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PIS", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+---", "measure": "unknown.measure.tetra"}, "line.4": {"text": "Und dein gedenkt man nicht.", "tokens": ["Und", "dein", "ge\u00b7denkt", "man", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "VVFIN", "PIS", "PTKNEG", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.16": {"line.1": {"text": "Das tr\u00e4ge Thier bek\u00f6mmt die fettsten Pfr\u00fcnden,", "tokens": ["Das", "tr\u00e4\u00b7ge", "Thier", "be\u00b7k\u00f6mmt", "die", "fetts\u00b7ten", "Pfr\u00fcn\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Dich spannt man an den Pflug;", "tokens": ["Dich", "spannt", "man", "an", "den", "Pflug", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "APPR", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Du bist, um unter uns dein Gl\u00fcck zu finden,", "tokens": ["Du", "bist", ",", "um", "un\u00b7ter", "uns", "dein", "Gl\u00fcck", "zu", "fin\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "KOUI", "APPR", "PPER", "PPOSAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Nicht unbrauchbar genug.", "tokens": ["Nicht", "un\u00b7brauch\u00b7bar", "ge\u00b7nug", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PTKNEG", "ADJD", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.17": {"line.1": {"text": "Arbeitsamkeit ist immer zu bedauern,", "tokens": ["Ar\u00b7beit\u00b7sam\u00b7keit", "ist", "im\u00b7mer", "zu", "be\u00b7dau\u00b7ern", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ADV", "PTKZU", "VVINF", "$,"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.2": {"text": "Damit bringts keiner hoch,", "tokens": ["Da\u00b7mit", "bringts", "kei\u00b7ner", "hoch", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PIS", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "W\u00e4rst du nicht stark, man spannte mit den Bauern", "tokens": ["W\u00e4rst", "du", "nicht", "stark", ",", "man", "spann\u00b7te", "mit", "den", "Bau\u00b7ern"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "PTKNEG", "ADJD", "$,", "PIS", "VVFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Dich niemals an ein Joch.", "tokens": ["Dich", "nie\u00b7mals", "an", "ein", "Joch", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.18": {"line.1": {"text": "Du bist sowohl gesotten als gebraten", "tokens": ["Du", "bist", "so\u00b7wohl", "ge\u00b7sot\u00b7ten", "als", "ge\u00b7bra\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "VVPP", "KOKOM", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Bei Jedermann beliebt,", "tokens": ["Bei", "Je\u00b7der\u00b7mann", "be\u00b7liebt", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PIS", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Du bist das Magazin: das ganzen Staaten", "tokens": ["Du", "bist", "das", "Ma\u00b7ga\u00b7zin", ":", "das", "gan\u00b7zen", "Staa\u00b7ten"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "NN", "$.", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Zur H\u00e4lfte Nahrung gibt.", "tokens": ["Zur", "H\u00e4lf\u00b7te", "Nah\u00b7rung", "gibt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.19": {"line.1": {"text": "Was f\u00fcr ein Thier hat sich im Nahrungsstande,", "tokens": ["Was", "f\u00fcr", "ein", "Thier", "hat", "sich", "im", "Nah\u00b7rungs\u00b7stan\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "ART", "NN", "VAFIN", "PRF", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Wie du, signalisirt?", "tokens": ["Wie", "du", ",", "sig\u00b7na\u00b7li\u00b7sirt", "?"], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["PWAV", "PPER", "$,", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und dennoch hat man dich in keinem Lande", "tokens": ["Und", "den\u00b7noch", "hat", "man", "dich", "in", "kei\u00b7nem", "Lan\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VAFIN", "PIS", "PRF", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Daf\u00fcr nobilitirt.", "tokens": ["Da\u00b7f\u00fcr", "no\u00b7bi\u00b7li\u00b7tirt", "."], "token_info": ["word", "word", "punct"], "pos": ["PAV", "VVPP", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}}, "stanza.20": {"line.1": {"text": "Du gibst mit deinem Fett bei schlechtem Futter", "tokens": ["Du", "gibst", "mit", "dei\u00b7nem", "Fett", "bei", "schlech\u00b7tem", "Fut\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Der halben Erde Licht;", "tokens": ["Der", "hal\u00b7ben", "Er\u00b7de", "Licht", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ein Domherrnbauch, gef\u00fcllt mit eitel Butter,", "tokens": ["Ein", "Dom\u00b7herrn\u00b7bauch", ",", "ge\u00b7f\u00fcllt", "mit", "ei\u00b7tel", "But\u00b7ter", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "VVPP", "APPR", "ADJD", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Stinkt nur und leuchtet nicht.", "tokens": ["Stinkt", "nur", "und", "leuch\u00b7tet", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "KON", "VVFIN", "PTKNEG", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.21": {"line.1": {"text": "Der Esel ward ber\u00fchmt, weil er vor Zeiten", "tokens": ["Der", "E\u00b7sel", "ward", "be\u00b7r\u00fchmt", ",", "weil", "er", "vor", "Zei\u00b7ten"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ADJD", "$,", "KOUS", "PPER", "APPR", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Sein Ohr dem Midas lieh:", "tokens": ["Sein", "Ohr", "dem", "Mi\u00b7das", "lieh", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Du leihst dein Horn so vielen gro\u00dfen Leuten,", "tokens": ["Du", "leihst", "dein", "Horn", "so", "vie\u00b7len", "gro\u00b7\u00dfen", "Leu\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "ADV", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und davon spricht man nie.", "tokens": ["Und", "da\u00b7von", "spricht", "man", "nie", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PAV", "VVFIN", "PIS", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.22": {"line.1": {"text": "So viel durch dich auch grosse M\u00e4nner prangen,", "tokens": ["So", "viel", "durch", "dich", "auch", "gros\u00b7se", "M\u00e4n\u00b7ner", "pran\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "PPER", "ADV", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "So sch\u00f6n dein Horn sie ziert,", "tokens": ["So", "sch\u00f6n", "dein", "Horn", "sie", "ziert", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPOSAT", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "So werden doch daraus zum L\u00e4usefangen", "tokens": ["So", "wer\u00b7den", "doch", "da\u00b7raus", "zum", "L\u00e4u\u00b7se\u00b7fan\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ADV", "PAV", "APPRART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Nur K\u00e4mme fabricirt.", "tokens": ["Nur", "K\u00e4m\u00b7me", "fab\u00b7ri\u00b7cirt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "NN", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.23": {"line.1": {"text": "Doch besser denkt von deiner H\u00f6rner St\u00e4rke", "tokens": ["Doch", "bes\u00b7ser", "denkt", "von", "dei\u00b7ner", "H\u00f6r\u00b7ner", "St\u00e4r\u00b7ke"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "VVFIN", "APPR", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Der Dialektiker;", "tokens": ["Der", "Di\u00b7a\u00b7lek\u00b7ti\u00b7ker", ";"], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$."], "meter": "-+-+--", "measure": "unknown.measure.di"}, "line.3": {"text": "Die h\u00f6chste Kraft zum Ueberzeugungswerke", "tokens": ["Die", "h\u00f6chs\u00b7te", "Kraft", "zum", "Ue\u00b7ber\u00b7zeu\u00b7gungs\u00b7wer\u00b7ke"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "APPRART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Nimmt er von ihnen her.", "tokens": ["Nimmt", "er", "von", "ih\u00b7nen", "her", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "PPER", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.24": {"line.1": {"text": "Dein Doppelhorn hat eine \u00fcbergrosse", "tokens": ["Dein", "Dop\u00b7pel\u00b7horn", "hat", "ei\u00b7ne", "\u00fc\u00b7berg\u00b7ros\u00b7se"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VAFIN", "ART", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Gewalt in seiner Hand,", "tokens": ["Ge\u00b7walt", "in", "sei\u00b7ner", "Hand", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Es st\u00f6\u00dft dem Gegenpart bei jedem Stosse", "tokens": ["Es", "st\u00f6\u00dft", "dem", "Ge\u00b7gen\u00b7part", "bei", "je\u00b7dem", "Stos\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Ein Loch in den Verstand.", "tokens": ["Ein", "Loch", "in", "den", "Ver\u00b7stand", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.25": {"line.1": {"text": "Ja, Freund, so lang die Welt Juristen, Pfaffen", "tokens": ["Ja", ",", "Freund", ",", "so", "lang", "die", "Welt", "Ju\u00b7ris\u00b7ten", ",", "Pfaf\u00b7fen"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["PTKANT", "$,", "NN", "$,", "ADV", "ADJD", "ART", "NN", "NN", "$,", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und Theologen hat,", "tokens": ["Und", "Theo\u00b7lo\u00b7gen", "hat", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "NN", "VAFIN", "$,"], "meter": "-++-+", "measure": "unknown.measure.tri"}, "line.3": {"text": "Besch\u00fctzest du allein mit diesen Waffen", "tokens": ["Be\u00b7sch\u00fct\u00b7zest", "du", "al\u00b7lein", "mit", "die\u00b7sen", "Waf\u00b7fen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Religion und Staat.", "tokens": ["Re\u00b7li\u00b7gi\u00b7on", "und", "Staat", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}}, "stanza.26": {"line.1": {"text": "D'rum haben auch die guten G\u00f6tter immer", "tokens": ["D'\u00b7rum", "ha\u00b7ben", "auch", "die", "gu\u00b7ten", "G\u00f6t\u00b7ter", "im\u00b7mer"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PAV", "VAFIN", "ADV", "ART", "ADJA", "NN", "ADV"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.2": {"text": "Dein Doppelhorn gesch\u00e4tzt,", "tokens": ["Dein", "Dop\u00b7pel\u00b7horn", "ge\u00b7sch\u00e4tzt", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und es verkl\u00e4rt mit hellem Silberschimmer", "tokens": ["Und", "es", "ver\u00b7kl\u00e4rt", "mit", "hel\u00b7lem", "Sil\u00b7ber\u00b7schim\u00b7mer"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "In unsern Mond versetzt.", "tokens": ["In", "un\u00b7sern", "Mond", "ver\u00b7setzt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}}}}