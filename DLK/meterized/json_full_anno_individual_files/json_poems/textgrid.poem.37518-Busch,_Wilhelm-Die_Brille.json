{"textgrid.poem.37518": {"metadata": {"author": {"name": "Busch, Wilhelm", "birth": "N.A.", "death": "N.A."}, "title": "Die Brille", "genre": "verse", "period": "N.A.", "pub_year": 1870, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Des Mittags, als es zw\u00f6lfe war,", "tokens": ["Des", "Mit\u00b7tags", ",", "als", "es", "zw\u00f6l\u00b7fe", "war", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "KOUS", "PPER", "CARD", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Setzt sich zu Tisch der Herr Aktuar.", "tokens": ["Setzt", "sich", "zu", "Tisch", "der", "Herr", "Ak\u00b7tu\u00b7ar", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "APPR", "NN", "ART", "NN", "NN", "$."], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}}, "stanza.2": {"line.1": {"text": "Er schaut bedenklich, ernst und stille,", "tokens": ["Er", "schaut", "be\u00b7denk\u00b7lich", ",", "ernst", "und", "stil\u00b7le", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "$,", "ADJD", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die Suppe an durch seine Brille.", "tokens": ["Die", "Sup\u00b7pe", "an", "durch", "sei\u00b7ne", "Bril\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Und durch die Brille, scharf und klar,", "tokens": ["Und", "durch", "die", "Bril\u00b7le", ",", "scharf", "und", "klar", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Entdeckt er gleich ein langes Haar.", "tokens": ["Ent\u00b7deckt", "er", "gleich", "ein", "lan\u00b7ges", "Haar", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "\u00bbnun!\u00ab \u2013 sprach die Frau \u2013 \u00bbdas kann wohl mal passieren!", "tokens": ["\u00bb", "nun", "!", "\u00ab", "\u2013", "sprach", "die", "Frau", "\u2013", "\u00bb", "das", "kann", "wohl", "mal", "pas\u00b7sie\u00b7ren", "!"], "token_info": ["punct", "word", "punct", "punct", "punct", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "$.", "$(", "$(", "VVFIN", "ART", "NN", "$(", "$(", "PDS", "VMFIN", "ADV", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Hast du mich lieb, so wird's dich nicht genieren!\u00ab", "tokens": ["Hast", "du", "mich", "lieb", ",", "so", "wird's", "dich", "nicht", "ge\u00b7nie\u00b7ren", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VAFIN", "PPER", "PRF", "ADJD", "$,", "ADV", "VAFIN", "PPER", "PTKNEG", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "Er aber kehrt sich schleunigst um", "tokens": ["Er", "a\u00b7ber", "kehrt", "sich", "schleu\u00b7nigst", "um"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "VVFIN", "PRF", "VVFIN", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und holt die Flasche, die voll Rum.", "tokens": ["Und", "holt", "die", "Fla\u00b7sche", ",", "die", "voll", "Rum", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "$,", "PRELS", "ADJD", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Er trinkt und ist so sehr verstockt,", "tokens": ["Er", "trinkt", "und", "ist", "so", "sehr", "ver\u00b7stockt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VAFIN", "ADV", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df selbst die Wurst ihn nicht verlockt.", "tokens": ["Da\u00df", "selbst", "die", "Wurst", "ihn", "nicht", "ver\u00b7lockt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "PPER", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "\u00bbach!\u00ab denkt die Frau, \u00bbwie wird das enden!\u00ab", "tokens": ["\u00bb", "ach", "!", "\u00ab", "denkt", "die", "Frau", ",", "\u00bb", "wie", "wird", "das", "en\u00b7den", "!", "\u00ab"], "token_info": ["punct", "word", "punct", "punct", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ITJ", "$.", "$(", "VVFIN", "ART", "NN", "$,", "$(", "PWAV", "VAFIN", "PDS", "VVINF", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und sucht die Flasche zu entwenden.", "tokens": ["Und", "sucht", "die", "Fla\u00b7sche", "zu", "ent\u00b7wen\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Doch hierin kennt er keinen Spa\u00df:", "tokens": ["Doch", "hie\u00b7rin", "kennt", "er", "kei\u00b7nen", "Spa\u00df", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "PIAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u00bbgleich stell' sie her! Sonst gibt es was!\u00ab", "tokens": ["\u00bb", "gleich", "stell'", "sie", "her", "!", "Sonst", "gibt", "es", "was", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADV", "VVFIN", "PPER", "PTKVZ", "$.", "ADV", "VVFIN", "PPER", "PIS", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Und schon ergreift er mit der Hand", "tokens": ["Und", "schon", "er\u00b7greift", "er", "mit", "der", "Hand"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Den Stock, der in der Ecke stand.", "tokens": ["Den", "Stock", ",", "der", "in", "der", "E\u00b7cke", "stand", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Die Frau versucht zu fliehn; indes", "tokens": ["Die", "Frau", "ver\u00b7sucht", "zu", "fliehn", ";", "in\u00b7des"], "token_info": ["word", "word", "word", "word", "word", "punct", "word"], "pos": ["ART", "NN", "VVPP", "PTKZU", "VVINF", "$.", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Hakenstock verhindert es.", "tokens": ["Der", "Ha\u00b7ken\u00b7stock", "ver\u00b7hin\u00b7dert", "es", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Ein Schlag, gar wohlgezielt und t\u00fcchtig,", "tokens": ["Ein", "Schlag", ",", "gar", "wohl\u00b7ge\u00b7zielt", "und", "t\u00fcch\u00b7tig", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADV", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Trifft und zerbricht die Flasche richtig.", "tokens": ["Trifft", "und", "zer\u00b7bricht", "die", "Fla\u00b7sche", "rich\u00b7tig", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "VVFIN", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Nun nimmt die Frau die Sache krumm", "tokens": ["Nun", "nimmt", "die", "Frau", "die", "Sa\u00b7che", "krumm"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "ART", "NN", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und kehrt sich zur Attacke um.", "tokens": ["Und", "kehrt", "sich", "zur", "At\u00b7ta\u00b7cke", "um", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "APPRART", "NN", "PTKVZ", "$."], "meter": "-+---+-+", "measure": "dactylic.init"}}, "stanza.13": {"line.1": {"text": "Sie hat die Brill' und freut sich sehr,", "tokens": ["Sie", "hat", "die", "Brill'", "und", "freut", "sich", "sehr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "KON", "VVFIN", "PRF", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Mann steht da und sieht nichts mehr.", "tokens": ["Der", "Mann", "steht", "da", "und", "sieht", "nichts", "mehr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "KON", "VVFIN", "PIS", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Er tappt herum als blinder Mann,", "tokens": ["Er", "tappt", "he\u00b7rum", "als", "blin\u00b7der", "Mann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKVZ", "KOKOM", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ob er den Feind nicht finden kann.", "tokens": ["Ob", "er", "den", "Feind", "nicht", "fin\u00b7den", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "PTKNEG", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "Und tappt in seiner blinden Wut \u2013", "tokens": ["Und", "tappt", "in", "sei\u00b7ner", "blin\u00b7den", "Wut", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PPOSAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Autsch! \u2013 an des Ofens hei\u00dfe Glut.", "tokens": ["Autsch", "!", "\u2013", "an", "des", "O\u00b7fens", "hei\u00b7\u00dfe", "Glut", "."], "token_info": ["word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "$(", "APPR", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "Er dreht sich um und allbereits", "tokens": ["Er", "dreht", "sich", "um", "und", "all\u00b7be\u00b7reits"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "KON", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Brennt ihn der Ofen anderseits.", "tokens": ["Brennt", "ihn", "der", "O\u00b7fen", "an\u00b7der\u00b7seits", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.17": {"line.1": {"text": "Nun aber wird die Wut erst gro\u00df \u2013", "tokens": ["Nun", "a\u00b7ber", "wird", "die", "Wut", "erst", "gro\u00df", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VAFIN", "ART", "NN", "ADV", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Was es auch sei \u2013 er haut drauf los.", "tokens": ["Was", "es", "auch", "sei", "\u2013", "er", "haut", "drauf", "los", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "VAFIN", "$(", "PPER", "VVFIN", "PAV", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.18": {"line.1": {"text": "Die Suppensch\u00fcssel, Wurst und Glas", "tokens": ["Die", "Sup\u00b7pen\u00b7sch\u00fcs\u00b7sel", ",", "Wurst", "und", "Glas"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wird ruiniert, der Hund wird na\u00df.", "tokens": ["Wird", "ru\u00b7i\u00b7niert", ",", "der", "Hund", "wird", "na\u00df", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "VVPP", "$,", "ART", "NN", "VAFIN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.19": {"line.1": {"text": "Und Frau und Hund entfliehn; doch er", "tokens": ["Und", "Frau", "und", "Hund", "ent\u00b7fliehn", ";", "doch", "er"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "NN", "KON", "NN", "VVINF", "$.", "KON", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "F\u00e4llt mit dem Stuhl schnell hinterher.", "tokens": ["F\u00e4llt", "mit", "dem", "Stuhl", "schnell", "hin\u00b7ter\u00b7her", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "ADJD", "PTKVZ", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.20": {"line.1": {"text": "Voll Eifer will er nach, und ach!", "tokens": ["Voll", "Ei\u00b7fer", "will", "er", "nach", ",", "und", "ach", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADJD", "NN", "VMFIN", "PPER", "PTKVZ", "$,", "KON", "XY", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Rennt an die T\u00fcr mit gro\u00dfem Krach.", "tokens": ["Rennt", "an", "die", "T\u00fcr", "mit", "gro\u00b7\u00dfem", "Krach", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.21": {"line.1": {"text": "Nun ist's zu Ende mit dem Rasen;", "tokens": ["Nun", "ist's", "zu", "En\u00b7de", "mit", "dem", "Ra\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "APPR", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Das rote Blut rinnt aus der Nasen.", "tokens": ["Das", "ro\u00b7te", "Blut", "rinnt", "aus", "der", "Na\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.22": {"line.1": {"text": "Und demutsvoll und flehentlich", "tokens": ["Und", "de\u00b7muts\u00b7voll", "und", "fle\u00b7hent\u00b7lich"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ADJD", "KON", "ADJD"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Bem\u00fcht er um die Brille sich.", "tokens": ["Be\u00b7m\u00fcht", "er", "um", "die", "Bril\u00b7le", "sich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ART", "NN", "PRF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.23": {"line.1": {"text": "Er nimmt mit Freud' und Dankgef\u00fchl", "tokens": ["Er", "nimmt", "mit", "Freud'", "und", "Dank\u00b7ge\u00b7f\u00fchl"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Brille von dem Besenstiel.", "tokens": ["Die", "Bril\u00b7le", "von", "dem", "Be\u00b7sen\u00b7stiel", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.24": {"line.1": {"text": "So triumphiert das brave Weib. \u2013", "tokens": ["So", "tri\u00b7um\u00b7phiert", "das", "bra\u00b7ve", "Weib", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Wurst hat Tapp, der Hund, im Leib.", "tokens": ["Die", "Wurst", "hat", "Tapp", ",", "der", "Hund", ",", "im", "Leib", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "NE", "$,", "ART", "NN", "$,", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.25": {"line.1": {"text": "Des Mittags, als es zw\u00f6lfe war,", "tokens": ["Des", "Mit\u00b7tags", ",", "als", "es", "zw\u00f6l\u00b7fe", "war", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "KOUS", "PPER", "CARD", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Setzt sich zu Tisch der Herr Aktuar.", "tokens": ["Setzt", "sich", "zu", "Tisch", "der", "Herr", "Ak\u00b7tu\u00b7ar", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "APPR", "NN", "ART", "NN", "NN", "$."], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}}, "stanza.26": {"line.1": {"text": "Er schaut bedenklich, ernst und stille,", "tokens": ["Er", "schaut", "be\u00b7denk\u00b7lich", ",", "ernst", "und", "stil\u00b7le", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "$,", "ADJD", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die Suppe an durch seine Brille.", "tokens": ["Die", "Sup\u00b7pe", "an", "durch", "sei\u00b7ne", "Bril\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.27": {"line.1": {"text": "Und durch die Brille, scharf und klar,", "tokens": ["Und", "durch", "die", "Bril\u00b7le", ",", "scharf", "und", "klar", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Entdeckt er gleich ein langes Haar.", "tokens": ["Ent\u00b7deckt", "er", "gleich", "ein", "lan\u00b7ges", "Haar", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.28": {"line.1": {"text": "\u00bbnun!\u00ab \u2013 sprach die Frau \u2013 \u00bbdas kann wohl mal passieren!", "tokens": ["\u00bb", "nun", "!", "\u00ab", "\u2013", "sprach", "die", "Frau", "\u2013", "\u00bb", "das", "kann", "wohl", "mal", "pas\u00b7sie\u00b7ren", "!"], "token_info": ["punct", "word", "punct", "punct", "punct", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "$.", "$(", "$(", "VVFIN", "ART", "NN", "$(", "$(", "PDS", "VMFIN", "ADV", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Hast du mich lieb, so wird's dich nicht genieren!\u00ab", "tokens": ["Hast", "du", "mich", "lieb", ",", "so", "wird's", "dich", "nicht", "ge\u00b7nie\u00b7ren", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VAFIN", "PPER", "PRF", "ADJD", "$,", "ADV", "VAFIN", "PPER", "PTKNEG", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.29": {"line.1": {"text": "Er aber kehrt sich schleunigst um", "tokens": ["Er", "a\u00b7ber", "kehrt", "sich", "schleu\u00b7nigst", "um"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "VVFIN", "PRF", "VVFIN", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und holt die Flasche, die voll Rum.", "tokens": ["Und", "holt", "die", "Fla\u00b7sche", ",", "die", "voll", "Rum", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "$,", "PRELS", "ADJD", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.30": {"line.1": {"text": "Er trinkt und ist so sehr verstockt,", "tokens": ["Er", "trinkt", "und", "ist", "so", "sehr", "ver\u00b7stockt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VAFIN", "ADV", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df selbst die Wurst ihn nicht verlockt.", "tokens": ["Da\u00df", "selbst", "die", "Wurst", "ihn", "nicht", "ver\u00b7lockt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "PPER", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.31": {"line.1": {"text": "\u00bbach!\u00ab denkt die Frau, \u00bbwie wird das enden!\u00ab", "tokens": ["\u00bb", "ach", "!", "\u00ab", "denkt", "die", "Frau", ",", "\u00bb", "wie", "wird", "das", "en\u00b7den", "!", "\u00ab"], "token_info": ["punct", "word", "punct", "punct", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ITJ", "$.", "$(", "VVFIN", "ART", "NN", "$,", "$(", "PWAV", "VAFIN", "PDS", "VVINF", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und sucht die Flasche zu entwenden.", "tokens": ["Und", "sucht", "die", "Fla\u00b7sche", "zu", "ent\u00b7wen\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.32": {"line.1": {"text": "Doch hierin kennt er keinen Spa\u00df:", "tokens": ["Doch", "hie\u00b7rin", "kennt", "er", "kei\u00b7nen", "Spa\u00df", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "PIAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u00bbgleich stell' sie her! Sonst gibt es was!\u00ab", "tokens": ["\u00bb", "gleich", "stell'", "sie", "her", "!", "Sonst", "gibt", "es", "was", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADV", "VVFIN", "PPER", "PTKVZ", "$.", "ADV", "VVFIN", "PPER", "PIS", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.33": {"line.1": {"text": "Und schon ergreift er mit der Hand", "tokens": ["Und", "schon", "er\u00b7greift", "er", "mit", "der", "Hand"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Den Stock, der in der Ecke stand.", "tokens": ["Den", "Stock", ",", "der", "in", "der", "E\u00b7cke", "stand", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.34": {"line.1": {"text": "Die Frau versucht zu fliehn; indes", "tokens": ["Die", "Frau", "ver\u00b7sucht", "zu", "fliehn", ";", "in\u00b7des"], "token_info": ["word", "word", "word", "word", "word", "punct", "word"], "pos": ["ART", "NN", "VVPP", "PTKZU", "VVINF", "$.", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Hakenstock verhindert es.", "tokens": ["Der", "Ha\u00b7ken\u00b7stock", "ver\u00b7hin\u00b7dert", "es", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.35": {"line.1": {"text": "Ein Schlag, gar wohlgezielt und t\u00fcchtig,", "tokens": ["Ein", "Schlag", ",", "gar", "wohl\u00b7ge\u00b7zielt", "und", "t\u00fcch\u00b7tig", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADV", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Trifft und zerbricht die Flasche richtig.", "tokens": ["Trifft", "und", "zer\u00b7bricht", "die", "Fla\u00b7sche", "rich\u00b7tig", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "VVFIN", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.36": {"line.1": {"text": "Nun nimmt die Frau die Sache krumm", "tokens": ["Nun", "nimmt", "die", "Frau", "die", "Sa\u00b7che", "krumm"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "ART", "NN", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und kehrt sich zur Attacke um.", "tokens": ["Und", "kehrt", "sich", "zur", "At\u00b7ta\u00b7cke", "um", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "APPRART", "NN", "PTKVZ", "$."], "meter": "-+---+-+", "measure": "dactylic.init"}}, "stanza.37": {"line.1": {"text": "Sie hat die Brill' und freut sich sehr,", "tokens": ["Sie", "hat", "die", "Brill'", "und", "freut", "sich", "sehr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "KON", "VVFIN", "PRF", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Mann steht da und sieht nichts mehr.", "tokens": ["Der", "Mann", "steht", "da", "und", "sieht", "nichts", "mehr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "KON", "VVFIN", "PIS", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.38": {"line.1": {"text": "Er tappt herum als blinder Mann,", "tokens": ["Er", "tappt", "he\u00b7rum", "als", "blin\u00b7der", "Mann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKVZ", "KOKOM", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ob er den Feind nicht finden kann.", "tokens": ["Ob", "er", "den", "Feind", "nicht", "fin\u00b7den", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "PTKNEG", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.39": {"line.1": {"text": "Und tappt in seiner blinden Wut \u2013", "tokens": ["Und", "tappt", "in", "sei\u00b7ner", "blin\u00b7den", "Wut", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PPOSAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Autsch! \u2013 an des Ofens hei\u00dfe Glut.", "tokens": ["Autsch", "!", "\u2013", "an", "des", "O\u00b7fens", "hei\u00b7\u00dfe", "Glut", "."], "token_info": ["word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "$(", "APPR", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.40": {"line.1": {"text": "Er dreht sich um und allbereits", "tokens": ["Er", "dreht", "sich", "um", "und", "all\u00b7be\u00b7reits"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "KON", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Brennt ihn der Ofen anderseits.", "tokens": ["Brennt", "ihn", "der", "O\u00b7fen", "an\u00b7der\u00b7seits", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.41": {"line.1": {"text": "Nun aber wird die Wut erst gro\u00df \u2013", "tokens": ["Nun", "a\u00b7ber", "wird", "die", "Wut", "erst", "gro\u00df", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VAFIN", "ART", "NN", "ADV", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Was es auch sei \u2013 er haut drauf los.", "tokens": ["Was", "es", "auch", "sei", "\u2013", "er", "haut", "drauf", "los", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "VAFIN", "$(", "PPER", "VVFIN", "PAV", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.42": {"line.1": {"text": "Die Suppensch\u00fcssel, Wurst und Glas", "tokens": ["Die", "Sup\u00b7pen\u00b7sch\u00fcs\u00b7sel", ",", "Wurst", "und", "Glas"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wird ruiniert, der Hund wird na\u00df.", "tokens": ["Wird", "ru\u00b7i\u00b7niert", ",", "der", "Hund", "wird", "na\u00df", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "VVPP", "$,", "ART", "NN", "VAFIN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.43": {"line.1": {"text": "Und Frau und Hund entfliehn; doch er", "tokens": ["Und", "Frau", "und", "Hund", "ent\u00b7fliehn", ";", "doch", "er"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "NN", "KON", "NN", "VVINF", "$.", "KON", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "F\u00e4llt mit dem Stuhl schnell hinterher.", "tokens": ["F\u00e4llt", "mit", "dem", "Stuhl", "schnell", "hin\u00b7ter\u00b7her", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "ADJD", "PTKVZ", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.44": {"line.1": {"text": "Voll Eifer will er nach, und ach!", "tokens": ["Voll", "Ei\u00b7fer", "will", "er", "nach", ",", "und", "ach", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADJD", "NN", "VMFIN", "PPER", "PTKVZ", "$,", "KON", "XY", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Rennt an die T\u00fcr mit gro\u00dfem Krach.", "tokens": ["Rennt", "an", "die", "T\u00fcr", "mit", "gro\u00b7\u00dfem", "Krach", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.45": {"line.1": {"text": "Nun ist's zu Ende mit dem Rasen;", "tokens": ["Nun", "ist's", "zu", "En\u00b7de", "mit", "dem", "Ra\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "APPR", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Das rote Blut rinnt aus der Nasen.", "tokens": ["Das", "ro\u00b7te", "Blut", "rinnt", "aus", "der", "Na\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.46": {"line.1": {"text": "Und demutsvoll und flehentlich", "tokens": ["Und", "de\u00b7muts\u00b7voll", "und", "fle\u00b7hent\u00b7lich"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ADJD", "KON", "ADJD"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Bem\u00fcht er um die Brille sich.", "tokens": ["Be\u00b7m\u00fcht", "er", "um", "die", "Bril\u00b7le", "sich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ART", "NN", "PRF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.47": {"line.1": {"text": "Er nimmt mit Freud' und Dankgef\u00fchl", "tokens": ["Er", "nimmt", "mit", "Freud'", "und", "Dank\u00b7ge\u00b7f\u00fchl"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Brille von dem Besenstiel.", "tokens": ["Die", "Bril\u00b7le", "von", "dem", "Be\u00b7sen\u00b7stiel", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.48": {"line.1": {"text": "So triumphiert das brave Weib. \u2013", "tokens": ["So", "tri\u00b7um\u00b7phiert", "das", "bra\u00b7ve", "Weib", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Wurst hat Tapp, der Hund, im Leib.", "tokens": ["Die", "Wurst", "hat", "Tapp", ",", "der", "Hund", ",", "im", "Leib", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "NE", "$,", "ART", "NN", "$,", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}