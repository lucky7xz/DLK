{"dta.poem.2712": {"metadata": {"author": {"name": "M\u00fchlpfort, Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "Bey Beerdigung Hn. C. G. den  3.  \n Junii 1678.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1686", "urn": "urn:nbn:de:kobv:b4-20414-7", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Was ist das/ das wir leben heissen?", "tokens": ["Was", "ist", "das", "/", "das", "wir", "le\u00b7ben", "heis\u00b7sen", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ART", "$(", "PRELS", "PPER", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ein Circkel voll gedrungner Noth.", "tokens": ["Ein", "Cir\u00b7ckel", "voll", "ge\u00b7drung\u00b7ner", "Noth", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ein Traum und ein betr\u00fcglich gleissen/", "tokens": ["Ein", "Traum", "und", "ein", "be\u00b7tr\u00fcg\u00b7lich", "gleis\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "ADJD", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ein ungewisses Morgenroth.", "tokens": ["Ein", "un\u00b7ge\u00b7wis\u00b7ses", "Mor\u00b7gen\u00b7roth", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ein Rauch/ der wenn er k\u00f6mmt/ verschwindet/", "tokens": ["Ein", "Rauch", "/", "der", "wenn", "er", "k\u00f6mmt", "/", "ver\u00b7schwin\u00b7det", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "$(", "ART", "KOUS", "PPER", "VVFIN", "$(", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Ein Meer das stets von Jammer pranst/", "tokens": ["Ein", "Meer", "das", "stets", "von", "Jam\u00b7mer", "pranst", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "ADV", "APPR", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Ein Fallstrick/ der die Seele bindet/", "tokens": ["Ein", "Fall\u00b7strick", "/", "der", "die", "See\u00b7le", "bin\u00b7det", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "ART", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Ein Wind/ der uns zu st\u00fcrtzen saust.", "tokens": ["Ein", "Wind", "/", "der", "uns", "zu", "st\u00fcrt\u00b7zen", "saust", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "PRELS", "PPER", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Ist noch was fl\u00fcchtiger als Schatten?", "tokens": ["Ist", "noch", "was", "fl\u00fcch\u00b7ti\u00b7ger", "als", "Schat\u00b7ten", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PWS", "ADJA", "KOUS", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ach ja der kurtzen Tage Flucht.", "tokens": ["Ach", "ja", "der", "kurt\u00b7zen", "Ta\u00b7ge", "Flucht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "ADV", "ART", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der Thau den man auf gr\u00fcnen Matten", "tokens": ["Der", "Thau", "den", "man", "auf", "gr\u00fc\u00b7nen", "Mat\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "PIS", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Bey aufgewachter Sonne sucht/", "tokens": ["Bey", "auf\u00b7ge\u00b7wach\u00b7ter", "Son\u00b7ne", "sucht", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wird vielmals nicht so schnell vergehen/", "tokens": ["Wird", "viel\u00b7mals", "nicht", "so", "schnell", "ver\u00b7ge\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PTKNEG", "ADV", "ADJD", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Als die elende Sterbligkeit:", "tokens": ["Als", "die", "e\u00b7len\u00b7de", "Ster\u00b7blig\u00b7keit", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.7": {"text": "Da/ eh wir lernen/ reden/ gehen", "tokens": ["Da", "/", "eh", "wir", "ler\u00b7nen", "/", "re\u00b7den", "/", "ge\u00b7hen"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct", "word"], "pos": ["ADV", "$(", "KOUS", "PPER", "VVINF", "$(", "VVINF", "$(", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Man schon uns macht das Todten-Kleid.", "tokens": ["Man", "schon", "uns", "macht", "das", "Tod\u00b7ten\u00b7Kleid", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "ADV", "PPER", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Der Fortgang mit erwachsnen Jahren/", "tokens": ["Der", "Fort\u00b7gang", "mit", "er\u00b7wachs\u00b7nen", "Jah\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ist nur ein Weg zu gr\u00f6\u00dfrer Pein/", "tokens": ["Ist", "nur", "ein", "Weg", "zu", "gr\u00f6\u00df\u00b7rer", "Pein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Di\u00df was wir lesen und erfahren", "tokens": ["Di\u00df", "was", "wir", "le\u00b7sen", "und", "er\u00b7fah\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "PRELS", "PPER", "VVINF", "KON", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wird oft ein faul Geschw\u00e4tze seyn.", "tokens": ["Wird", "oft", "ein", "faul", "Ge\u00b7schw\u00e4t\u00b7ze", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "ADJA", "NN", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Weil unser Wissen unvollkommen/", "tokens": ["Weil", "un\u00b7ser", "Wis\u00b7sen", "un\u00b7voll\u00b7kom\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "ADJD", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Und der Verstand voll Unverstand;", "tokens": ["Und", "der", "Ver\u00b7stand", "voll", "Un\u00b7ver\u00b7stand", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ADJD", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "So ist/ was wir je f\u00fcr genommen", "tokens": ["So", "ist", "/", "was", "wir", "je", "f\u00fcr", "ge\u00b7nom\u00b7men"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "$(", "PWS", "PPER", "ADV", "APPR", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Auf nichts gebaut als Tr\u00fcbe-Sand.", "tokens": ["Auf", "nichts", "ge\u00b7baut", "als", "Tr\u00fc\u00b7be\u00b7\u00b7Sand", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "VVPP", "KOKOM", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Wir m\u00f6gen in die Frembde reisen/", "tokens": ["Wir", "m\u00f6\u00b7gen", "in", "die", "Fremb\u00b7de", "rei\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPR", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Der Kummer zieht uns immer nach.", "tokens": ["Der", "Kum\u00b7mer", "zieht", "uns", "im\u00b7mer", "nach", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Bey Freuden/ Wollust/ Schertz und Speisen", "tokens": ["Bey", "Freu\u00b7den", "/", "Wol\u00b7lust", "/", "Schertz", "und", "Spei\u00b7sen"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["APPR", "NN", "$(", "NN", "$(", "NN", "KON", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Dr\u00fcckt uns manch heimlich Ungemach.", "tokens": ["Dr\u00fcckt", "uns", "manch", "heim\u00b7lich", "Un\u00b7ge\u00b7mach", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PIAT", "ADJD", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Der Welt verdammte Heucheleyen/", "tokens": ["Der", "Welt", "ver\u00b7damm\u00b7te", "Heu\u00b7che\u00b7le\u00b7yen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$("], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.6": {"text": "Die nehmen Tugend-Larven an.", "tokens": ["Die", "neh\u00b7men", "Tu\u00b7gen\u00b7dLa\u00b7rven", "an", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Wie kan ein redlich Hertz sich freuen", "tokens": ["Wie", "kan", "ein", "red\u00b7lich", "Hertz", "sich", "freu\u00b7en"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "VMFIN", "ART", "ADJD", "NN", "PRF", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Das unter ein solch Joch gethan?", "tokens": ["Das", "un\u00b7ter", "ein", "solch", "Joch", "ge\u00b7than", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "APPR", "ART", "PIAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Und wenn wir nun viel zubesitzen/", "tokens": ["Und", "wenn", "wir", "nun", "viel", "zu\u00b7be\u00b7sit\u00b7zen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "ADV", "VVINF", "$("], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Das Leben in Gefahr gewagt.", "tokens": ["Das", "Le\u00b7ben", "in", "Ge\u00b7fahr", "ge\u00b7wagt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Was kan es bey dem Hintritt n\u00fctzen/", "tokens": ["Was", "kan", "es", "bey", "dem", "Hin\u00b7tritt", "n\u00fct\u00b7zen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PPER", "APPR", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wenn uns die letzte Noth betagt?", "tokens": ["Wenn", "uns", "die", "letz\u00b7te", "Noth", "be\u00b7tagt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Da sehen wir da\u00df alles fl\u00fcchtig/", "tokens": ["Da", "se\u00b7hen", "wir", "da\u00df", "al\u00b7les", "fl\u00fcch\u00b7tig", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "KOUS", "PIS", "ADJD", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "So weit das Rad der Sonnen geht.", "tokens": ["So", "weit", "das", "Rad", "der", "Son\u00b7nen", "geht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ART", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Da\u00df unser H\u00e4nde Wercke nichtig", "tokens": ["Da\u00df", "un\u00b7ser", "H\u00e4n\u00b7de", "Wer\u00b7cke", "nich\u00b7tig"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPOSAT", "NN", "NN", "ADJD"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Und blo\u00df der Unbestand besteht.", "tokens": ["Und", "blo\u00df", "der", "Un\u00b7be\u00b7stand", "be\u00b7steht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Und w\u00fcnschen wir die grauen Haare?", "tokens": ["Und", "w\u00fcn\u00b7schen", "wir", "die", "grau\u00b7en", "Haa\u00b7re", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Das Alter ist ein schwerer Gast.", "tokens": ["Das", "Al\u00b7ter", "ist", "ein", "schwe\u00b7rer", "Gast", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Es prediget nur von der Bahre", "tokens": ["Es", "pre\u00b7di\u00b7get", "nur", "von", "der", "Bah\u00b7re"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "ART", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Und nennt das Leben eine Last.", "tokens": ["Und", "nennt", "das", "Le\u00b7ben", "ei\u00b7ne", "Last", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Das eben f\u00fchrt die jenen Tage/", "tokens": ["Das", "e\u00b7ben", "f\u00fchrt", "die", "je\u00b7nen", "Ta\u00b7ge", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "VVFIN", "ART", "PDAT", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "So keinem nicht gef\u00e4llig seyn.", "tokens": ["So", "kei\u00b7nem", "nicht", "ge\u00b7f\u00e4l\u00b7lig", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "PTKNEG", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Da man nur Jammer/ Angst und Plage", "tokens": ["Da", "man", "nur", "Jam\u00b7mer", "/", "Angst", "und", "Pla\u00b7ge"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "PIS", "ADV", "NN", "$(", "NN", "KON", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Vor Freuden-Fr\u00fcchte sammlet ein.", "tokens": ["Vor", "Freu\u00b7den\u00b7Fr\u00fcch\u00b7te", "samm\u00b7let", "ein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Und ob es k\u00f6stlich auch gewesen/", "tokens": ["Und", "ob", "es", "k\u00f6st\u00b7lich", "auch", "ge\u00b7we\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADJD", "ADV", "VAPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "So hat es M\u00fch und Noth verzehrt.", "tokens": ["So", "hat", "es", "M\u00fch", "und", "Noth", "ver\u00b7zehrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "NN", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wer wolt ihm nicht di\u00df auserlesen", "tokens": ["Wer", "wolt", "ihm", "nicht", "di\u00df", "au\u00b7ser\u00b7le\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "VMFIN", "PPER", "PTKNEG", "PDS", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Was uns die wahre Ruh beschert?", "tokens": ["Was", "uns", "die", "wah\u00b7re", "Ruh", "be\u00b7schert", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wer wolte nicht die Augen schliessen/", "tokens": ["Wer", "wol\u00b7te", "nicht", "die", "Au\u00b7gen", "schlies\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PTKNEG", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Umb dort den Himmel anzuschaun?", "tokens": ["Umb", "dort", "den", "Him\u00b7mel", "an\u00b7zu\u00b7schaun", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "ADV", "ART", "NN", "VVIZU", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "De\u00df Leibes Kercker seyn entrissen", "tokens": ["De\u00df", "Lei\u00b7bes", "Ker\u00b7cker", "seyn", "ent\u00b7ris\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "NN", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Und jene Friedens-St\u00e4dte baun?", "tokens": ["Und", "je\u00b7ne", "Frie\u00b7dens\u00b7St\u00e4d\u00b7te", "baun", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PDAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Das End-Ziel aller Angst und Schmertzen", "tokens": ["Das", "En\u00b7dZiel", "al\u00b7ler", "Angst", "und", "Schmert\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "PIAT", "NN", "KON", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Bleibt doch ein sanfft und seelig Tod.", "tokens": ["Bleibt", "doch", "ein", "sanfft", "und", "see\u00b7lig", "Tod", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "ADJD", "KON", "ADJD", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der Hingang zu dem Vater-Hertzen", "tokens": ["Der", "Hin\u00b7gang", "zu", "dem", "Va\u00b7ter\u00b7Hert\u00b7zen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die Reise zu dem wahren GOtt.", "tokens": ["Die", "Rei\u00b7se", "zu", "dem", "wah\u00b7ren", "Gott", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Das Freuden-Thor zu jenem Leben/", "tokens": ["Das", "Freu\u00b7den\u00b7Thor", "zu", "je\u00b7nem", "Le\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PDAT", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Und der Geburts-Tag wahrer Lust.", "tokens": ["Und", "der", "Ge\u00b7burts\u00b7Tag", "wah\u00b7rer", "Lust", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Die Sammlung wo die Heilgen schweben", "tokens": ["Die", "Samm\u00b7lung", "wo", "die", "Heil\u00b7gen", "schwe\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "PWAV", "ART", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Ein Labsal auf die Myrrhen-Kost.", "tokens": ["Ein", "Lab\u00b7sal", "auf", "die", "Myr\u00b7rhen\u00b7Kost", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Nun diesen Zweck hat auch ergriffen", "tokens": ["Nun", "die\u00b7sen", "Zweck", "hat", "auch", "er\u00b7grif\u00b7fen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "PDAT", "NN", "VAFIN", "ADV", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Herr Greif/ als auf sein Lebens-Ziel", "tokens": ["Herr", "Greif", "/", "als", "auf", "sein", "Le\u00b7bens\u00b7Ziel"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "NE", "$(", "KOKOM", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der Tod das W\u00fcrge-Beil geschliffen/", "tokens": ["Der", "Tod", "das", "W\u00fcr\u00b7ge\u00b7Beil", "ge\u00b7schlif\u00b7fen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und ihn die Mattigkeit befiel;", "tokens": ["Und", "ihn", "die", "Mat\u00b7tig\u00b7keit", "be\u00b7fiel", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Da\u00df er den Pfingst-Tag dort zu feyren", "tokens": ["Da\u00df", "er", "den", "Pfingst\u00b7Tag", "dort", "zu", "fey\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "NN", "ADV", "PTKZU", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Den heilgen Abend hier beschlo\u00df/", "tokens": ["Den", "heil\u00b7gen", "A\u00b7bend", "hier", "be\u00b7schlo\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und seine Seele wolte steuren", "tokens": ["Und", "sei\u00b7ne", "See\u00b7le", "wol\u00b7te", "steu\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "VMFIN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "In de\u00df Erl\u00f6sers Gnaden-Scho\u00df.", "tokens": ["In", "de\u00df", "Er\u00b7l\u00f6\u00b7sers", "Gna\u00b7den\u00b7Scho\u00df", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Sein Ruhm und ehrliches Verhalten/", "tokens": ["Sein", "Ruhm", "und", "ehr\u00b7li\u00b7ches", "Ver\u00b7hal\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "ADJA", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wird noch in vieler Hertzen bl\u00fchn.", "tokens": ["Wird", "noch", "in", "vie\u00b7ler", "Hert\u00b7zen", "bl\u00fchn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "APPR", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mu\u00df schon hier Fleisch und Blut erkalten", "tokens": ["Mu\u00df", "schon", "hier", "Fleisch", "und", "Blut", "er\u00b7kal\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "ADV", "ADV", "NN", "KON", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und Wust und Schimmel es beziehn/", "tokens": ["Und", "Wust", "und", "Schim\u00b7mel", "es", "be\u00b7ziehn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "KON", "NN", "PPER", "VVINF", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "So bleibt sein Name doch im Segen.", "tokens": ["So", "bleibt", "sein", "Na\u00b7me", "doch", "im", "Se\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Der Fromme kan nicht untergehn/", "tokens": ["Der", "From\u00b7me", "kan", "nicht", "un\u00b7ter\u00b7gehn", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PTKNEG", "VVINF", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Es will auff allen Weg und Stegen", "tokens": ["Es", "will", "auff", "al\u00b7len", "Weg", "und", "Ste\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "APPR", "PIAT", "NN", "KON", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Gott seinen Saamen noch erh\u00f6hn.", "tokens": ["Gott", "sei\u00b7nen", "Saa\u00b7men", "noch", "er\u00b7h\u00f6hn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Betr\u00fcbtste Frau/ wie herb und bitter/", "tokens": ["Be\u00b7tr\u00b7\u00fcbts\u00b7te", "Frau", "/", "wie", "herb", "und", "bit\u00b7ter", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$(", "PWAV", "ADJD", "KON", "ADJD", "$("], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Der Name Wittib bey ihr klingt;", "tokens": ["Der", "Na\u00b7me", "Wit\u00b7tib", "bey", "ihr", "klingt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da jetzt de\u00df Todes Ungewitter", "tokens": ["Da", "jetzt", "de\u00df", "To\u00b7des", "Un\u00b7ge\u00b7wit\u00b7ter"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "ART", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "So wol ihr Haus als Hertz umbringt.", "tokens": ["So", "wol", "ihr", "Haus", "als", "Hertz", "um\u00b7bringt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPOSAT", "NN", "KOUS", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "So glaube sie da\u00df nach dem Weinen", "tokens": ["So", "glau\u00b7be", "sie", "da\u00df", "nach", "dem", "Wei\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "KOUS", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Und au\u00dfgestandnem Seelen-Weh/", "tokens": ["Und", "au\u00df\u00b7ge\u00b7stand\u00b7nem", "See\u00b7len\u00b7Weh", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Jhr wlrd die Sonne wieder scheinen/", "tokens": ["Ihr", "wlrd", "die", "Son\u00b7ne", "wie\u00b7der", "schei\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Und da\u00df ihr neuer Trost aufgeh.", "tokens": ["Und", "da\u00df", "ihr", "neu\u00b7er", "Trost", "auf\u00b7geh", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPOSAT", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Jhr Eh-Herr zeucht mit Ruhm von hinnen/", "tokens": ["Ihr", "Eh\u00b7Herr", "zeucht", "mit", "Ruhm", "von", "hin\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "APPR", "NN", "APPR", "ADV", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die Gottesfurcht und Redligkeit", "tokens": ["Die", "Got\u00b7tes\u00b7furcht", "und", "Red\u00b7lig\u00b7keit"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "In seinem Wandel und Beginnen", "tokens": ["In", "sei\u00b7nem", "Wan\u00b7del", "und", "Be\u00b7gin\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "KON", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Sind auch im Tode sein Geleit\u2019.", "tokens": ["Sind", "auch", "im", "To\u00b7de", "sein", "Ge\u00b7leit'", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "APPRART", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Er ist ja gar zu wol geschieden/", "tokens": ["Er", "ist", "ja", "gar", "zu", "wol", "ge\u00b7schie\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "PTKA", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Und ausgegangen wie ein Licht/", "tokens": ["Und", "aus\u00b7ge\u00b7gan\u00b7gen", "wie", "ein", "Licht", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVPP", "KOKOM", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Zu der Zeit da ihm seinen Frieden", "tokens": ["Zu", "der", "Zeit", "da", "ihm", "sei\u00b7nen", "Frie\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "KOUS", "PPER", "PPOSAT", "NN"], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.8": {"text": "Und Beystand GOttes Mund verspricht.", "tokens": ["Und", "Beys\u00b7tand", "Got\u00b7tes", "Mund", "ver\u00b7spricht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "NN", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}