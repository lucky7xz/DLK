{"textgrid.poem.53148": {"metadata": {"author": {"name": "Dach, Simon", "birth": "N.A.", "death": "N.A."}, "title": "Aus dem Frantz\u00f6sischen: Lisandre au bord de nos ruisseaux", "genre": "verse", "period": "N.A.", "pub_year": 1632, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Lysander that umb unser Bach", "tokens": ["Ly\u00b7san\u00b7der", "that", "umb", "un\u00b7ser", "Bach"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Es dem Gereusch der Quellen nach,", "tokens": ["Es", "dem", "Ge\u00b7reusch", "der", "Quel\u00b7len", "nach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Er lie\u00df sein Spiel erschallen,", "tokens": ["Er", "lie\u00df", "sein", "Spiel", "er\u00b7schal\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Sang mit den V\u00f6glein ein vnd sprach:", "tokens": ["Sang", "mit", "den", "V\u00f6\u00b7glein", "ein", "vnd", "sprach", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "PTKVZ", "KON", "VVFIN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.5": {"text": "Du sch\u00f6nstes Mensch mang allen!", "tokens": ["Du", "sch\u00f6ns\u00b7tes", "Mensch", "mang", "al\u00b7len", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "VVFIN", "PIAT", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Nichts Sch\u00f6nes gleicht dir auff der Welt,", "tokens": ["Nichts", "Sch\u00f6\u00b7nes", "gleicht", "dir", "auff", "der", "Welt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "ADJA", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Carihte, die mir Satzung stellt,", "tokens": ["Ca\u00b7rih\u00b7te", ",", "die", "mir", "Sat\u00b7zung", "stellt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PRELS", "PPER", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "La\u00df dich mein Leid erbarmen,", "tokens": ["La\u00df", "dich", "mein", "Leid", "er\u00b7bar\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Schaw, wie mein Hertz dir Glauben h\u00e4lt", "tokens": ["Schaw", ",", "wie", "mein", "Hertz", "dir", "Glau\u00b7ben", "h\u00e4lt"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "KOKOM", "PPOSAT", "NN", "PPER", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Vnd sey geneigt mir Armen!", "tokens": ["Vnd", "sey", "ge\u00b7neigt", "mir", "Ar\u00b7men", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "VVPP", "PPER", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Stein, Fl\u00fcsse, W\u00e4lder, Berg' vnd Thal", "tokens": ["Stein", ",", "Fl\u00fcs\u00b7se", ",", "W\u00e4l\u00b7der", ",", "Ber\u00b7g'", "vnd", "Thal"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "NN", "$,", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Vnd wem ich t\u00e4glich tausent mal", "tokens": ["Vnd", "wem", "ich", "t\u00e4g\u00b7lich", "tau\u00b7sent", "mal"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWS", "PPER", "ADJD", "VVFIN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mein Elend kundt mus machen,", "tokens": ["Mein", "E\u00b7lend", "kundt", "mus", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PTKVZ", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Bewegt die Stimme meiner Quahl,", "tokens": ["Be\u00b7wegt", "die", "Stim\u00b7me", "mei\u00b7ner", "Quahl", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Dich aber sieht man lachen.", "tokens": ["Dich", "a\u00b7ber", "sieht", "man", "la\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "PIS", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Princessin meiner Freyheit, zwar", "tokens": ["Prin\u00b7ces\u00b7sin", "mei\u00b7ner", "Frey\u00b7heit", ",", "zwar"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["NN", "PPOSAT", "NN", "$,", "ADV"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Gestalt vnd Sanfftmuth lassen gar", "tokens": ["Ge\u00b7stalt", "vnd", "Sanfft\u00b7muth", "las\u00b7sen", "gar"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "KON", "NN", "VVFIN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sich nicht in Eintracht binden,", "tokens": ["Sich", "nicht", "in", "Ein\u00b7tracht", "bin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "PTKNEG", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Doch deinen Grimm wei\u00df ich f\u00fcrwar", "tokens": ["Doch", "dei\u00b7nen", "Grimm", "wei\u00df", "ich", "f\u00fcr\u00b7war"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NE", "VVFIN", "PPER", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Nicht l\u00e4nger zu empfinden.", "tokens": ["Nicht", "l\u00e4n\u00b7ger", "zu", "emp\u00b7fin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Erst wurden hie ohn unterla\u00df", "tokens": ["Erst", "wur\u00b7den", "hie", "ohn", "un\u00b7ter\u00b7la\u00df"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ADV", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Blumen durch mein Weinen nass,", "tokens": ["Die", "Blu\u00b7men", "durch", "mein", "Wei\u00b7nen", "nass", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Doch meiner Seelen Kertzen", "tokens": ["Doch", "mei\u00b7ner", "See\u00b7len", "Kert\u00b7zen"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Lescht weder Trost noch Thr\u00e4nen Maa\u00df,", "tokens": ["Lescht", "we\u00b7der", "Trost", "noch", "Thr\u00e4\u00b7nen", "Maa\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "ADV", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ohn Seufftzer aus dem Hertzen.", "tokens": ["Ohn", "Seufft\u00b7zer", "aus", "dem", "Hert\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Lysander that umb unser Bach", "tokens": ["Ly\u00b7san\u00b7der", "that", "umb", "un\u00b7ser", "Bach"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Es dem Gereusch der Quellen nach,", "tokens": ["Es", "dem", "Ge\u00b7reusch", "der", "Quel\u00b7len", "nach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Er lie\u00df sein Spiel erschallen,", "tokens": ["Er", "lie\u00df", "sein", "Spiel", "er\u00b7schal\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Sang mit den V\u00f6glein ein vnd sprach:", "tokens": ["Sang", "mit", "den", "V\u00f6\u00b7glein", "ein", "vnd", "sprach", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "PTKVZ", "KON", "VVFIN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.5": {"text": "Du sch\u00f6nstes Mensch mang allen!", "tokens": ["Du", "sch\u00f6ns\u00b7tes", "Mensch", "mang", "al\u00b7len", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "VVFIN", "PIAT", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Nichts Sch\u00f6nes gleicht dir auff der Welt,", "tokens": ["Nichts", "Sch\u00f6\u00b7nes", "gleicht", "dir", "auff", "der", "Welt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "ADJA", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Carihte, die mir Satzung stellt,", "tokens": ["Ca\u00b7rih\u00b7te", ",", "die", "mir", "Sat\u00b7zung", "stellt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PRELS", "PPER", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "La\u00df dich mein Leid erbarmen,", "tokens": ["La\u00df", "dich", "mein", "Leid", "er\u00b7bar\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Schaw, wie mein Hertz dir Glauben h\u00e4lt", "tokens": ["Schaw", ",", "wie", "mein", "Hertz", "dir", "Glau\u00b7ben", "h\u00e4lt"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "KOKOM", "PPOSAT", "NN", "PPER", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Vnd sey geneigt mir Armen!", "tokens": ["Vnd", "sey", "ge\u00b7neigt", "mir", "Ar\u00b7men", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "VVPP", "PPER", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Stein, Fl\u00fcsse, W\u00e4lder, Berg' vnd Thal", "tokens": ["Stein", ",", "Fl\u00fcs\u00b7se", ",", "W\u00e4l\u00b7der", ",", "Ber\u00b7g'", "vnd", "Thal"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "NN", "$,", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Vnd wem ich t\u00e4glich tausent mal", "tokens": ["Vnd", "wem", "ich", "t\u00e4g\u00b7lich", "tau\u00b7sent", "mal"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWS", "PPER", "ADJD", "VVFIN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mein Elend kundt mus machen,", "tokens": ["Mein", "E\u00b7lend", "kundt", "mus", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PTKVZ", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Bewegt die Stimme meiner Quahl,", "tokens": ["Be\u00b7wegt", "die", "Stim\u00b7me", "mei\u00b7ner", "Quahl", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Dich aber sieht man lachen.", "tokens": ["Dich", "a\u00b7ber", "sieht", "man", "la\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "PIS", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Princessin meiner Freyheit, zwar", "tokens": ["Prin\u00b7ces\u00b7sin", "mei\u00b7ner", "Frey\u00b7heit", ",", "zwar"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["NN", "PPOSAT", "NN", "$,", "ADV"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Gestalt vnd Sanfftmuth lassen gar", "tokens": ["Ge\u00b7stalt", "vnd", "Sanfft\u00b7muth", "las\u00b7sen", "gar"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "KON", "NN", "VVFIN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sich nicht in Eintracht binden,", "tokens": ["Sich", "nicht", "in", "Ein\u00b7tracht", "bin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "PTKNEG", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Doch deinen Grimm wei\u00df ich f\u00fcrwar", "tokens": ["Doch", "dei\u00b7nen", "Grimm", "wei\u00df", "ich", "f\u00fcr\u00b7war"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NE", "VVFIN", "PPER", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Nicht l\u00e4nger zu empfinden.", "tokens": ["Nicht", "l\u00e4n\u00b7ger", "zu", "emp\u00b7fin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "Erst wurden hie ohn unterla\u00df", "tokens": ["Erst", "wur\u00b7den", "hie", "ohn", "un\u00b7ter\u00b7la\u00df"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ADV", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Blumen durch mein Weinen nass,", "tokens": ["Die", "Blu\u00b7men", "durch", "mein", "Wei\u00b7nen", "nass", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Doch meiner Seelen Kertzen", "tokens": ["Doch", "mei\u00b7ner", "See\u00b7len", "Kert\u00b7zen"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Lescht weder Trost noch Thr\u00e4nen Maa\u00df,", "tokens": ["Lescht", "we\u00b7der", "Trost", "noch", "Thr\u00e4\u00b7nen", "Maa\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "ADV", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ohn Seufftzer aus dem Hertzen.", "tokens": ["Ohn", "Seufft\u00b7zer", "aus", "dem", "Hert\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}}}}