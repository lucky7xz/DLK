{"textgrid.poem.43941": {"metadata": {"author": {"name": "G\u00fcnther, Johann Christian", "birth": "N.A.", "death": "N.A."}, "title": "1L: Nun hab ich schon genug; schweig, trauriges Ger\u00fcchte.", "genre": "verse", "period": "N.A.", "pub_year": 1709, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Nun hab ich schon genug; schweig, trauriges Ger\u00fcchte.", "tokens": ["Nun", "hab", "ich", "schon", "ge\u00b7nug", ";", "schweig", ",", "trau\u00b7ri\u00b7ges", "Ge\u00b7r\u00fcch\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ADV", "$.", "VVFIN", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Das Herze sagt es mir, mein Kind sey nicht mehr mein.", "tokens": ["Das", "Her\u00b7ze", "sagt", "es", "mir", ",", "mein", "Kind", "sey", "nicht", "mehr", "mein", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "VVFIN", "PPER", "PPER", "$,", "PPOSAT", "NN", "VAFIN", "PTKNEG", "ADV", "PPOSAT", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der unverhofte Ri\u00df nimmt Regung und Gesichte", "tokens": ["Der", "un\u00b7ver\u00b7hof\u00b7te", "Ri\u00df", "nimmt", "Re\u00b7gung", "und", "Ge\u00b7sich\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Mit stummer Ungedult und bla\u00dfem Schr\u00f6cken ein.", "tokens": ["Mit", "stum\u00b7mer", "Un\u00b7ge\u00b7dult", "und", "bla\u00b7\u00dfem", "Schr\u00f6\u00b7cken", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "KON", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Mich deucht, ich h\u00f6re schon die neuen Hochzeitlieder,", "tokens": ["Mich", "deucht", ",", "ich", "h\u00f6\u00b7re", "schon", "die", "neu\u00b7en", "Hoch\u00b7zeit\u00b7lie\u00b7der", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VVFIN", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ja, ja, ich h\u00f6re schon der Hofnung Leichenklang;", "tokens": ["Ja", ",", "ja", ",", "ich", "h\u00f6\u00b7re", "schon", "der", "Hof\u00b7nung", "Lei\u00b7chen\u00b7klang", ";"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PTKANT", "$,", "PPER", "VVFIN", "ADV", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die Angst durchwandert mir das Marck der starcken Glieder,", "tokens": ["Die", "Angst", "durch\u00b7wan\u00b7dert", "mir", "das", "Marck", "der", "star\u00b7cken", "Glie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Um die sie kurz vorher die falschen Armen schlang.", "tokens": ["Um", "die", "sie", "kurz", "vor\u00b7her", "die", "fal\u00b7schen", "Ar\u00b7men", "schlang", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "ART", "PPER", "ADJD", "ADV", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Du Kind der Ewigkeit und Mutter alles Guten,", "tokens": ["Du", "Kind", "der", "E\u00b7wig\u00b7keit", "und", "Mut\u00b7ter", "al\u00b7les", "Gu\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "ART", "NN", "KON", "NN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "O Liebe, stehstu gern verliebten Dichtern bey,", "tokens": ["O", "Lie\u00b7be", ",", "steh\u00b7stu", "gern", "ver\u00b7lieb\u00b7ten", "Dich\u00b7tern", "bey", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "VVFIN", "ADV", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "So gieb, da Aug und Herz in s\u00fc\u00dfer Wehmuth bluten,", "tokens": ["So", "gieb", ",", "da", "Aug", "und", "Herz", "in", "s\u00fc\u00b7\u00dfer", "Weh\u00b7muth", "blu\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVIMP", "$,", "KOUS", "NN", "KON", "NN", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Da\u00df diese schwere Last nur noch ertr\u00e4glich sey.", "tokens": ["Da\u00df", "die\u00b7se", "schwe\u00b7re", "Last", "nur", "noch", "er\u00b7tr\u00e4g\u00b7lich", "sey", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDAT", "ADJA", "NN", "ADV", "ADV", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Du weist, ich diene dir mit unverf\u00e4lschtem Herzen,", "tokens": ["Du", "weist", ",", "ich", "die\u00b7ne", "dir", "mit", "un\u00b7ver\u00b7f\u00e4lschtem", "Her\u00b7zen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VVFIN", "PPER", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Du weist, ich habe stets das b\u00f6se Volck verflucht", "tokens": ["Du", "weist", ",", "ich", "ha\u00b7be", "stets", "das", "b\u00f6\u00b7se", "Volck", "ver\u00b7flucht"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VAFIN", "ADV", "ART", "ADJA", "NN", "VVPP"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und blos, das Elendweh im Leben zu verschmerzen,", "tokens": ["Und", "blos", ",", "das", "El\u00b7end\u00b7weh", "im", "Le\u00b7ben", "zu", "ver\u00b7schmer\u00b7zen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$,", "ART", "NN", "APPRART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ein Kind von frommer Art und gleicher Treu gesucht.", "tokens": ["Ein", "Kind", "von", "from\u00b7mer", "Art", "und", "glei\u00b7cher", "Treu", "ge\u00b7sucht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ADJA", "NN", "KON", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Wie thustu das an mir und st\u00fcrzest mein Vergn\u00fcgen,", "tokens": ["Wie", "thu\u00b7stu", "das", "an", "mir", "und", "st\u00fcr\u00b7zest", "mein", "Ver\u00b7gn\u00fc\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "ART", "APPR", "PPER", "KON", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Worauf ich so viel Zeit und M\u00fch und Flei\u00df gewand?", "tokens": ["Wo\u00b7rauf", "ich", "so", "viel", "Zeit", "und", "M\u00fch", "und", "Flei\u00df", "ge\u00b7wand", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PPER", "ADV", "PIAT", "NN", "KON", "NN", "KON", "NN", "VAPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Warum erlaubstu nicht, an dieser Brust zu liegen,", "tokens": ["Wa\u00b7rum", "er\u00b7laubs\u00b7tu", "nicht", ",", "an", "die\u00b7ser", "Brust", "zu", "lie\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PTKNEG", "$,", "APPR", "PDAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Mit der mich deine Macht so lang und starck verband?", "tokens": ["Mit", "der", "mich", "dei\u00b7ne", "Macht", "so", "lang", "und", "starck", "ver\u00b7band", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "PPOSAT", "NN", "ADV", "ADJD", "KON", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Ja, wenn mir alle Welt auf solchen Fall geschworen,", "tokens": ["Ja", ",", "wenn", "mir", "al\u00b7le", "Welt", "auf", "sol\u00b7chen", "Fall", "ge\u00b7schwo\u00b7ren", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "KOUS", "PPER", "PIAT", "NN", "APPR", "PIAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ja, wenn ein Engel selbst dergleichen prophezeit,", "tokens": ["Ja", ",", "wenn", "ein", "En\u00b7gel", "selbst", "derg\u00b7lei\u00b7chen", "pro\u00b7phe\u00b7zeit", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "KOUS", "ART", "NN", "ADV", "PIS", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "So h\u00e4tt ich wohl gedacht: Sie reden wie die Thoren", "tokens": ["So", "h\u00e4tt", "ich", "wohl", "ge\u00b7dacht", ":", "Sie", "re\u00b7den", "wie", "die", "Tho\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "VVPP", "$.", "PPER", "VVINF", "KOKOM", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und kennen wohl noch nicht der Liebe Z\u00e4rtligkeit.", "tokens": ["Und", "ken\u00b7nen", "wohl", "noch", "nicht", "der", "Lie\u00b7be", "Z\u00e4rt\u00b7lig\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ADV", "PTKNEG", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Ach allerliebstes Kind, so mu\u00df ich dir noch schreiben,", "tokens": ["Ach", "al\u00b7ler\u00b7liebs\u00b7tes", "Kind", ",", "so", "mu\u00df", "ich", "dir", "noch", "schrei\u00b7ben", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "ADJA", "NN", "$,", "ADV", "VMFIN", "PPER", "PPER", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Indem ich doch so bald mein Herz nicht trennen kan;", "tokens": ["In\u00b7dem", "ich", "doch", "so", "bald", "mein", "Herz", "nicht", "tren\u00b7nen", "kan", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "ADV", "PPOSAT", "NN", "PTKNEG", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wie magstu solchen Scherz mit Eid und Schw\u00fcren treiben,", "tokens": ["Wie", "mags\u00b7tu", "sol\u00b7chen", "Scherz", "mit", "Eid", "und", "Schw\u00fc\u00b7ren", "trei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "PIAT", "NN", "APPR", "NN", "KON", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und warum hastu so und noch an mir gethan?", "tokens": ["Und", "wa\u00b7rum", "has\u00b7tu", "so", "und", "noch", "an", "mir", "ge\u00b7than", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "VAFIN", "ADV", "KON", "ADV", "APPR", "PPER", "VVPP", "$."], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}}, "stanza.8": {"line.1": {"text": "An mir, an de\u00dfen Gunst dein irdisch Heil gehangen", "tokens": ["An", "mir", ",", "an", "de\u00b7\u00dfen", "Gunst", "dein", "ir\u00b7disch", "Heil", "ge\u00b7han\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPER", "$,", "APPR", "ART", "NN", "PPOSAT", "ADJD", "NN", "VVPP"], "meter": "+-+--+-+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.2": {"text": "Und der um dich sogar ein Spott der Misgunst hies,", "tokens": ["Und", "der", "um", "dich", "so\u00b7gar", "ein", "Spott", "der", "Mis\u00b7gunst", "hies", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "APPR", "PPER", "ADV", "ART", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "An mir, durch welchen du so vieler Noth entgangen,", "tokens": ["An", "mir", ",", "durch", "wel\u00b7chen", "du", "so", "vie\u00b7ler", "Noth", "ent\u00b7gan\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "$,", "APPR", "PWAT", "PPER", "ADV", "PIAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "An mir, der fast vor dich sein Auge nehmen lies.", "tokens": ["An", "mir", ",", "der", "fast", "vor", "dich", "sein", "Au\u00b7ge", "neh\u00b7men", "lies", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "$,", "PRELS", "ADV", "APPR", "PPER", "PPOSAT", "NN", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Bedencke doch nur dich, ich will von mir nichts sagen;", "tokens": ["Be\u00b7den\u00b7cke", "doch", "nur", "dich", ",", "ich", "will", "von", "mir", "nichts", "sa\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADV", "PPER", "$,", "PPER", "VMFIN", "APPR", "PPER", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wie ofters hat dein Mund (du weist, bey welcher Gruft,)", "tokens": ["Wie", "of\u00b7ters", "hat", "dein", "Mund", "(", "du", "weist", ",", "bey", "wel\u00b7cher", "Gruft", ",", ")"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["PWAV", "ADV", "VAFIN", "PPOSAT", "NN", "$(", "PPER", "VVFIN", "$,", "APPR", "PWAT", "NN", "$,", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der Eltern Asch und Staub, auf dem wir sicher lagen,", "tokens": ["Der", "El\u00b7tern", "Asch", "und", "Staub", ",", "auf", "dem", "wir", "si\u00b7cher", "la\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "KON", "NN", "$,", "APPR", "PRELS", "PPER", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Zum Zeugn\u00fc\u00df wahrer Treu mit Thr\u00e4nen angeruft!", "tokens": ["Zum", "Zeug\u00b7n\u00fc\u00df", "wah\u00b7rer", "Treu", "mit", "Thr\u00e4\u00b7nen", "an\u00b7ge\u00b7ruft", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADJA", "NN", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.10": {"line.1": {"text": "Geh in dich, falsches Kind, und frage dein Gem\u00fcthe;", "tokens": ["Geh", "in", "dich", ",", "fal\u00b7sches", "Kind", ",", "und", "fra\u00b7ge", "dein", "Ge\u00b7m\u00fc\u00b7the", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "PPER", "$,", "ADJA", "NN", "$,", "KON", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Dies, weis ich, wird vor mich ein frey Bek\u00e4ntn\u00fc\u00df thun,", "tokens": ["Dies", ",", "weis", "ich", ",", "wird", "vor", "mich", "ein", "frey", "Be\u00b7k\u00e4nt\u00b7n\u00fc\u00df", "thun", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "$,", "KOUS", "PPER", "$,", "VAFIN", "APPR", "PRF", "ART", "ADJD", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Mit was vor Ehrligkeit und nicht erkaufter G\u00fcte", "tokens": ["Mit", "was", "vor", "Ehr\u00b7lig\u00b7keit", "und", "nicht", "er\u00b7kauf\u00b7ter", "G\u00fc\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PRELS", "APPR", "NN", "KON", "PTKNEG", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Mein Herz allein gew\u00fcntscht, in deiner Schoos zu ruhn.", "tokens": ["Mein", "Herz", "al\u00b7lein", "ge\u00b7w\u00fcnt\u00b7scht", ",", "in", "dei\u00b7ner", "Schoos", "zu", "ruhn", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADV", "VVPP", "$,", "APPR", "PPOSAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.11": {"line.1": {"text": "Bedenck auch, was wir schon zusammen ausgestanden,", "tokens": ["Be\u00b7denck", "auch", ",", "was", "wir", "schon", "zu\u00b7sam\u00b7men", "aus\u00b7ge\u00b7stan\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "$,", "PRELS", "PPER", "ADV", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wie hart uns Neid und Gram und Eifersucht gequ\u00e4lt;", "tokens": ["Wie", "hart", "uns", "Neid", "und", "Gram", "und", "Ei\u00b7fer\u00b7sucht", "ge\u00b7qu\u00e4lt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "PPER", "NN", "KON", "NN", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wie manchmahl r\u00fchmtestu bey allen Ungl\u00fccksbanden,", "tokens": ["Wie", "manch\u00b7mahl", "r\u00fchm\u00b7tes\u00b7tu", "bey", "al\u00b7len", "Un\u00b7gl\u00fccks\u00b7ban\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "VVFIN", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Es w\u00e4re Philimen zu deinem Trost erwehlt!", "tokens": ["Es", "w\u00e4\u00b7re", "Phi\u00b7li\u00b7men", "zu", "dei\u00b7nem", "Trost", "er\u00b7wehlt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NN", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.12": {"line.1": {"text": "Wie sauer wurd es mir, dich anfangs zu gewinnen,", "tokens": ["Wie", "sau\u00b7er", "wurd", "es", "mir", ",", "dich", "an\u00b7fangs", "zu", "ge\u00b7win\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VAFIN", "PPER", "PPER", "$,", "PPER", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wie lange wurd ich nicht mit List herumgef\u00fchrt!", "tokens": ["Wie", "lan\u00b7ge", "wurd", "ich", "nicht", "mit", "List", "her\u00b7um\u00b7ge\u00b7f\u00fchrt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "VAFIN", "PPER", "PTKNEG", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "So viel der Thr\u00e4nen sind, die jezt aus Unmuth rinnen,", "tokens": ["So", "viel", "der", "Thr\u00e4\u00b7nen", "sind", ",", "die", "jezt", "aus", "Un\u00b7muth", "rin\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "NN", "VAFIN", "$,", "PRELS", "ADV", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So viel Mahl hat dir dort mein Ku\u00df das Herz ger\u00fchrt.", "tokens": ["So", "viel", "Mahl", "hat", "dir", "dort", "mein", "Ku\u00df", "das", "Herz", "ge\u00b7r\u00fchrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "VAFIN", "PPER", "ADV", "PPOSAT", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.13": {"line.1": {"text": "Ich troz auf kein Verdienst, so gut ich trozen m\u00f6chte,", "tokens": ["Ich", "troz", "auf", "kein", "Ver\u00b7dienst", ",", "so", "gut", "ich", "tro\u00b7zen", "m\u00f6ch\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PIAT", "NN", "$,", "ADV", "ADJD", "PPER", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ich bringe dieses nur aus guter Meinung vor:", "tokens": ["Ich", "brin\u00b7ge", "die\u00b7ses", "nur", "aus", "gu\u00b7ter", "Mei\u00b7nung", "vor", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PDAT", "ADV", "APPR", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wer sch\u00e4zte dazumahl dein Ansehn und Geschlechte,", "tokens": ["Wer", "sch\u00e4z\u00b7te", "da\u00b7zu\u00b7mahl", "dein", "An\u00b7sehn", "und", "Ge\u00b7schlech\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ADV", "PPOSAT", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Das vor der halben Stadt bereits sein Lob verlor?", "tokens": ["Das", "vor", "der", "hal\u00b7ben", "Stadt", "be\u00b7reits", "sein", "Lob", "ver\u00b7lor", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "APPR", "ART", "ADJA", "NN", "ADV", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.14": {"line.1": {"text": "Wer lehrte dich, dein Lob vern\u00fcnftig zu bedencken?", "tokens": ["Wer", "lehr\u00b7te", "dich", ",", "dein", "Lob", "ver\u00b7n\u00fcnf\u00b7tig", "zu", "be\u00b7den\u00b7cken", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "$,", "PPOSAT", "NN", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wer wies dich auf den Weg, der Menschen gl\u00fccklich macht?", "tokens": ["Wer", "wies", "dich", "auf", "den", "Weg", ",", "der", "Men\u00b7schen", "gl\u00fcck\u00b7lich", "macht", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PRF", "APPR", "ART", "NN", "$,", "ART", "NN", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wer lies sich deinen Gram bis zur Verzweiflung kr\u00e4ncken?", "tokens": ["Wer", "lies", "sich", "dei\u00b7nen", "Gram", "bis", "zur", "Ver\u00b7zwei\u00b7flung", "kr\u00e4n\u00b7cken", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PRF", "PPOSAT", "NN", "APPR", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wer hat dir den Geschmack der Liebe beygebracht?", "tokens": ["Wer", "hat", "dir", "den", "Ge\u00b7schmack", "der", "Lie\u00b7be", "bey\u00b7ge\u00b7bracht", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "ART", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.15": {"line.1": {"text": "Die Kranckheit warf dich hin, der Tod stund vor der Th\u00fcre,", "tokens": ["Die", "Kran\u00b7ck\u00b7heit", "warf", "dich", "hin", ",", "der", "Tod", "stund", "vor", "der", "Th\u00fc\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "PTKVZ", "$,", "ART", "NN", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Ich kam und hies gesund und lidt wohl mehr als du.", "tokens": ["Ich", "kam", "und", "hies", "ge\u00b7sund", "und", "lidt", "wohl", "mehr", "als", "du", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "ADJD", "KON", "VVFIN", "ADV", "ADV", "KOUS", "PPER", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "So oft ich mir die Zeit jezt ins Ged\u00e4chtn\u00fc\u00df f\u00fchre,", "tokens": ["So", "oft", "ich", "mir", "die", "Zeit", "jezt", "ins", "Ge\u00b7d\u00e4cht\u00b7n\u00fc\u00df", "f\u00fch\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "PPER", "ART", "NN", "ADV", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So ofters h\u00e4ngt mir noch ein Theil der Ohnmacht zu.", "tokens": ["So", "of\u00b7ters", "h\u00e4ngt", "mir", "noch", "ein", "Theil", "der", "Ohn\u00b7macht", "zu", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "ADV", "ART", "NN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.16": {"line.1": {"text": "Mein Helfen schlug nichts an, ich gieng in meine Kammer,", "tokens": ["Mein", "Hel\u00b7fen", "schlug", "nichts", "an", ",", "ich", "gieng", "in", "mei\u00b7ne", "Kam\u00b7mer", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PIS", "PTKVZ", "$,", "PPER", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Verschlo\u00df mich mit der Angst und warf mich auf die Knie", "tokens": ["Ver\u00b7schlo\u00df", "mich", "mit", "der", "Angst", "und", "warf", "mich", "auf", "die", "Knie"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PRF", "APPR", "ART", "NN", "KON", "VVFIN", "PRF", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und bat ich weis nicht was vor allzu gro\u00dfem Jammer,", "tokens": ["Und", "bat", "ich", "weis", "nicht", "was", "vor", "all\u00b7zu", "gro\u00b7\u00dfem", "Jam\u00b7mer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PTKVZ", "PTKNEG", "PWS", "APPR", "PTKA", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Denn eh ich mich besann, so war es wieder fr\u00fch.", "tokens": ["Denn", "eh", "ich", "mich", "be\u00b7sann", ",", "so", "war", "es", "wie\u00b7der", "fr\u00fch", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PRF", "VVFIN", "$,", "ADV", "VAFIN", "PPER", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.17": {"line.1": {"text": "Nun merck ich, da\u00df ich dort um meine Noth gebethen,", "tokens": ["Nun", "merck", "ich", ",", "da\u00df", "ich", "dort", "um", "mei\u00b7ne", "Noth", "ge\u00b7be\u00b7then", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "KOUS", "PPER", "ADV", "APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Um dich, um meine Noth, die mehr als Schwefel brennt;", "tokens": ["Um", "dich", ",", "um", "mei\u00b7ne", "Noth", ",", "die", "mehr", "als", "Schwe\u00b7fel", "brennt", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PPER", "$,", "KOUI", "PPOSAT", "NN", "$,", "PRELS", "PIS", "KOKOM", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ach, sollte deine Brunst so aus dem Glei\u00dfe treten,", "tokens": ["Ach", ",", "soll\u00b7te", "dei\u00b7ne", "Brunst", "so", "aus", "dem", "Glei\u00b7\u00dfe", "tre\u00b7ten", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "VMFIN", "PPOSAT", "NN", "ADV", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ach, warum hab ich dich dem Tode nicht geg\u00f6nnt?", "tokens": ["Ach", ",", "wa\u00b7rum", "hab", "ich", "dich", "dem", "To\u00b7de", "nicht", "ge\u00b7g\u00f6nnt", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "PWAV", "VAFIN", "PPER", "PRF", "ART", "NN", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.18": {"line.1": {"text": "Mir w\u00e4restu getreu, dir ohne Schuld gestorben,", "tokens": ["Mir", "w\u00e4\u00b7res\u00b7tu", "ge\u00b7treu", ",", "dir", "oh\u00b7ne", "Schuld", "ge\u00b7stor\u00b7ben", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "$,", "PPER", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Mein Seufzen h\u00e4tte dich in jene Welt gef\u00fchrt,", "tokens": ["Mein", "Seuf\u00b7zen", "h\u00e4t\u00b7te", "dich", "in", "je\u00b7ne", "Welt", "ge\u00b7f\u00fchrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "PPER", "APPR", "PDAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Es h\u00e4tte deine Treu ein ewig Lob erworben", "tokens": ["Es", "h\u00e4t\u00b7te", "dei\u00b7ne", "Treu", "ein", "e\u00b7wig", "Lob", "er\u00b7wor\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PPOSAT", "NN", "ART", "ADJD", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und selbst mein Wittwerflor dein Leichenkleid geziert.", "tokens": ["Und", "selbst", "mein", "Witt\u00b7wer\u00b7flor", "dein", "Lei\u00b7chen\u00b7kleid", "ge\u00b7ziert", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PPOSAT", "NN", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.19": {"line.1": {"text": "Verf\u00fchrteste der Welt, betrogne Leonore,", "tokens": ["Ver\u00b7f\u00fchr\u00b7tes\u00b7te", "der", "Welt", ",", "be\u00b7trog\u00b7ne", "Le\u00b7o\u00b7no\u00b7re", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$,", "VVFIN", "NE", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Bedenck, um was du dich mit dieser Falschheit bringst", "tokens": ["Be\u00b7denck", ",", "um", "was", "du", "dich", "mit", "die\u00b7ser", "Falschheit", "bringst"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "APPR", "PRELS", "PPER", "PRF", "APPR", "PDAT", "NN", "VVFIN"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.3": {"text": "Und ob du als ein Spott von meinem Musenchore", "tokens": ["Und", "ob", "du", "als", "ein", "Spott", "von", "mei\u00b7nem", "Mu\u00b7sen\u00b7cho\u00b7re"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "KOUS", "ART", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Nicht aus dem Paradies in Cabuls W\u00fcste springst.", "tokens": ["Nicht", "aus", "dem", "Pa\u00b7ra\u00b7dies", "in", "Ca\u00b7buls", "W\u00fcs\u00b7te", "springst", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "ART", "NN", "APPR", "NE", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.20": {"line.1": {"text": "Durch Eintracht w\u00e4re dir die Eh zum Himmel worden,", "tokens": ["Durch", "Ein\u00b7tracht", "w\u00e4\u00b7re", "dir", "die", "Eh", "zum", "Him\u00b7mel", "wor\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VAFIN", "PPER", "ART", "NN", "APPRART", "NN", "VAPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Hier h\u00e4ttestu das Marck der keuschen Brunst geschmeckt;", "tokens": ["Hier", "h\u00e4t\u00b7tes\u00b7tu", "das", "Marck", "der", "keu\u00b7schen", "Brunst", "ge\u00b7schmeckt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Du strahltest als ein Stern in jener Frauen Orden,", "tokens": ["Du", "strahl\u00b7test", "als", "ein", "Stern", "in", "je\u00b7ner", "Frau\u00b7en", "Or\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KOKOM", "ART", "NN", "APPR", "PDAT", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Dem unsre Poesie des Nachruhms Lorbeer steckt.", "tokens": ["Dem", "uns\u00b7re", "Poe\u00b7sie", "des", "Nach\u00b7ruhms", "Lor\u00b7beer", "steckt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "ART", "NN", "NE", "VVFIN", "$."], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}}, "stanza.21": {"line.1": {"text": "Steh n\u00e4chtlich einmahl auf und mi\u00df die hohe Ferne", "tokens": ["Steh", "n\u00e4cht\u00b7lich", "ein\u00b7mahl", "auf", "und", "mi\u00df", "die", "ho\u00b7he", "Fer\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "ADV", "PTKVZ", "KON", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und sieh den Milchweg an, der ist der Helden Haus;", "tokens": ["Und", "sieh", "den", "Milch\u00b7weg", "an", ",", "der", "ist", "der", "Hel\u00b7den", "Haus", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVIMP", "ART", "NN", "PTKVZ", "$,", "PRELS", "VAFIN", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Dein Nahme mehrte da den Glanz der holden Sterne,", "tokens": ["Dein", "Nah\u00b7me", "mehr\u00b7te", "da", "den", "Glanz", "der", "hol\u00b7den", "Ster\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ADV", "ART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ich las bereits den Plaz vor de\u00dfen Bildn\u00fc\u00df aus.", "tokens": ["Ich", "las", "be\u00b7reits", "den", "Plaz", "vor", "de\u00b7\u00dfen", "Bild\u00b7n\u00fc\u00df", "aus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+---+-+", "measure": "unknown.measure.penta"}}, "stanza.22": {"line.1": {"text": "Du bist vorhin gestraft, indem du mich entbehrest,", "tokens": ["Du", "bist", "vor\u00b7hin", "ge\u00b7straft", ",", "in\u00b7dem", "du", "mich", "ent\u00b7beh\u00b7rest", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "VVPP", "$,", "KOUS", "PPER", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Du strafest dich noch mehr durch deine neue Wahl,", "tokens": ["Du", "stra\u00b7fest", "dich", "noch", "mehr", "durch", "dei\u00b7ne", "neu\u00b7e", "Wahl", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ADV", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Bey der du auf der Welt schon in die H\u00f6lle f\u00e4hrest,", "tokens": ["Bey", "der", "du", "auf", "der", "Welt", "schon", "in", "die", "H\u00f6l\u00b7le", "f\u00e4h\u00b7rest", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "APPR", "ART", "NN", "ADV", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Aus welcher meine Treu dich so zu reden stahl.", "tokens": ["Aus", "wel\u00b7cher", "mei\u00b7ne", "Treu", "dich", "so", "zu", "re\u00b7den", "stahl", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPOSAT", "NN", "PPER", "ADV", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}}, "stanza.23": {"line.1": {"text": "Mit was vor Zuversicht und Augen und Gewi\u00dfen", "tokens": ["Mit", "was", "vor", "Zu\u00b7ver\u00b7sicht", "und", "Au\u00b7gen", "und", "Ge\u00b7wi\u00b7\u00dfen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PRELS", "APPR", "NN", "KON", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Getraustu dich hinfort mein Antliz anzusehn?", "tokens": ["Ge\u00b7traus\u00b7tu", "dich", "hin\u00b7fort", "mein", "Ant\u00b7liz", "an\u00b7zu\u00b7sehn", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "PPOSAT", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Was wirstu, sterb ich bald, vor Larven f\u00fcrchten m\u00fc\u00dfen!", "tokens": ["Was", "wirs\u00b7tu", ",", "sterb", "ich", "bald", ",", "vor", "Lar\u00b7ven", "f\u00fcrch\u00b7ten", "m\u00fc\u00b7\u00dfen", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "$,", "VVFIN", "PPER", "ADV", "$,", "APPR", "NN", "VVINF", "VMINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Geschieht's, so wi\u00dfe nur, es sey durch dich geschehn.", "tokens": ["Ge\u00b7schieht's", ",", "so", "wi\u00b7\u00dfe", "nur", ",", "es", "sey", "durch", "dich", "ge\u00b7schehn", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ADV", "VVFIN", "ADV", "$,", "PPER", "VAFIN", "APPR", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.24": {"line.1": {"text": "Dein Mops, gedenck an mich, wird mich an dir schon r\u00e4chen,", "tokens": ["Dein", "Mops", ",", "ge\u00b7denck", "an", "mich", ",", "wird", "mich", "an", "dir", "schon", "r\u00e4\u00b7chen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "VVIMP", "APPR", "PPER", "$,", "VAFIN", "PPER", "APPR", "PPER", "ADV", "VVINF", "$,"], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Sein Kopf ist bo\u00dfheitsvoll und wird ein Hencker seyn;", "tokens": ["Sein", "Kopf", "ist", "bo\u00df\u00b7heits\u00b7voll", "und", "wird", "ein", "Hen\u00b7cker", "seyn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADJD", "KON", "VAFIN", "ART", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Du wirst, wenn Tag und Nacht dich unter Sorgen schw\u00e4chen,", "tokens": ["Du", "wirst", ",", "wenn", "Tag", "und", "Nacht", "dich", "un\u00b7ter", "Sor\u00b7gen", "schw\u00e4\u00b7chen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "KOUS", "NN", "KON", "NN", "PRF", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Dein unbesonnen Werck, doch stets zu sp\u00e4t, bereun.", "tokens": ["Dein", "un\u00b7be\u00b7son\u00b7nen", "Werck", ",", "doch", "stets", "zu", "sp\u00e4t", ",", "be\u00b7re\u00b7un", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,", "ADV", "ADV", "PTKA", "ADJD", "$,", "VVINF", "$."], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}}, "stanza.25": {"line.1": {"text": "Alsdenn besinne dich auf G\u00e4rthen, Grab und Linden,", "tokens": ["Als\u00b7denn", "be\u00b7sin\u00b7ne", "dich", "auf", "G\u00e4r\u00b7then", ",", "Grab", "und", "Lin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "APPR", "NN", "$,", "NN", "KON", "NE", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Worunter meine Schoos dein schl\u00e4frig Haupt gewiegt;", "tokens": ["Wo\u00b7run\u00b7ter", "mei\u00b7ne", "Schoos", "dein", "schl\u00e4f\u00b7rig", "Haupt", "ge\u00b7wiegt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "PPOSAT", "ADJD", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Da wirstu mich nicht mehr auf jenem Felsen finden,", "tokens": ["Da", "wirs\u00b7tu", "mich", "nicht", "mehr", "auf", "je\u00b7nem", "Fel\u00b7sen", "fin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PTKNEG", "ADV", "APPR", "PDAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Auf welchem noch von uns ein Bundeszeichen liegt.", "tokens": ["Auf", "wel\u00b7chem", "noch", "von", "uns", "ein", "Bun\u00b7des\u00b7zei\u00b7chen", "liegt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "ADV", "APPR", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.26": {"line.1": {"text": "Die lezte Sommernacht wird nicht mehr wiederkommen;", "tokens": ["Die", "lez\u00b7te", "Som\u00b7mer\u00b7nacht", "wird", "nicht", "mehr", "wie\u00b7der\u00b7kom\u00b7men", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "PTKNEG", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Spiel, K\u00fc\u00dfe, Tanz und Vers und Str\u00e4u\u00dfer treuer Hand", "tokens": ["Spiel", ",", "K\u00fc\u00b7\u00dfe", ",", "Tanz", "und", "Vers", "und", "Str\u00e4u\u00b7\u00dfer", "treu\u00b7er", "Hand"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "NN", "$,", "NN", "KON", "NN", "KON", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Sind Sch\u00e4ze, welche dir der Raub der Zeit genommen,", "tokens": ["Sind", "Sch\u00e4\u00b7ze", ",", "wel\u00b7che", "dir", "der", "Raub", "der", "Zeit", "ge\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "$,", "PRELS", "PPER", "ART", "NN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Was sag ich? die du dir aus Falschheit selbst entwand.", "tokens": ["Was", "sag", "ich", "?", "die", "du", "dir", "aus", "Falschheit", "selbst", "ent\u00b7wand", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "$.", "PRELS", "PPER", "PPER", "APPR", "NN", "ADV", "VVFIN", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}}, "stanza.27": {"line.1": {"text": "Es hat mir wohl geahnt; denn kanstu dich besinnen,", "tokens": ["Es", "hat", "mir", "wohl", "ge\u00b7ahnt", ";", "denn", "kans\u00b7tu", "dich", "be\u00b7sin\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "VVPP", "$.", "KON", "VMFIN", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Bey welcher Garthenlust dein Ring den Finger band?", "tokens": ["Bey", "wel\u00b7cher", "Gar\u00b7then\u00b7lust", "dein", "Ring", "den", "Fin\u00b7ger", "band", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PWAT", "NN", "PPOSAT", "NN", "ART", "NN", "VVFIN", "$."], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.3": {"text": "Mein Auge fing dort nicht ohn Ursach an zu rinnen,", "tokens": ["Mein", "Au\u00b7ge", "fing", "dort", "nicht", "ohn", "Ur\u00b7sach", "an", "zu", "rin\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ADV", "PTKNEG", "APPR", "NN", "PTKVZ", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Dir aber fiel das Blut in Tropfen auf die Hand.", "tokens": ["Dir", "a\u00b7ber", "fiel", "das", "Blut", "in", "Trop\u00b7fen", "auf", "die", "Hand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "ART", "NN", "APPR", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.28": {"line.1": {"text": "Noch mehr, die nechste Nacht verlor ich dich im Traume", "tokens": ["Noch", "mehr", ",", "die", "nechs\u00b7te", "Nacht", "ver\u00b7lor", "ich", "dich", "im", "Trau\u00b7me"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "$,", "ART", "ADJA", "NN", "VVFIN", "PPER", "PRF", "APPRART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und weckte mich fast selbst durch Angst und Winseln auf;", "tokens": ["Und", "weck\u00b7te", "mich", "fast", "selbst", "durch", "Angst", "und", "Win\u00b7seln", "auf", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "ADV", "APPR", "NN", "KON", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der unverhofte Bruch von deinem liebsten Baume", "tokens": ["Der", "un\u00b7ver\u00b7hof\u00b7te", "Bruch", "von", "dei\u00b7nem", "liebs\u00b7ten", "Bau\u00b7me"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wies etwan auch vorher der Liebe kurzen Lauf.", "tokens": ["Wies", "et\u00b7wan", "auch", "vor\u00b7her", "der", "Lie\u00b7be", "kur\u00b7zen", "Lauf", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "ADV", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.29": {"line.1": {"text": "Sey da und sch\u00fcze vor, man habe dich gezwungen;", "tokens": ["Sey", "da", "und", "sch\u00fc\u00b7ze", "vor", ",", "man", "ha\u00b7be", "dich", "ge\u00b7zwun\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "KON", "VVFIN", "PTKVZ", "$,", "PIS", "VAFIN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der, die warhaftig liebt, hat Flehn und Zwang nichts an.", "tokens": ["Der", ",", "die", "war\u00b7haf\u00b7tig", "liebt", ",", "hat", "Flehn", "und", "Zwang", "nichts", "an", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "PRELS", "ADJD", "VVFIN", "$,", "VAFIN", "VVINF", "KON", "NN", "PIS", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Du selbst hast nicht gewollt, sonst w\u00e4r es wohl gelungen,", "tokens": ["Du", "selbst", "hast", "nicht", "ge\u00b7wollt", ",", "sonst", "w\u00e4r", "es", "wohl", "ge\u00b7lun\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VAFIN", "PTKNEG", "VMPP", "$,", "ADV", "VAFIN", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Indem doch Weiberlist viel Ausflucht machen kan.", "tokens": ["In\u00b7dem", "doch", "Wei\u00b7ber\u00b7list", "viel", "Aus\u00b7flucht", "ma\u00b7chen", "kan", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "NN", "PIAT", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.30": {"line.1": {"text": "Du daurest mich noch sehr, nicht weil du dies verdienest,", "tokens": ["Du", "dau\u00b7rest", "mich", "noch", "sehr", ",", "nicht", "weil", "du", "dies", "ver\u00b7die\u00b7nest", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ADV", "$,", "PTKNEG", "KOUS", "PPER", "PDS", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Blos weil mich die Natur zum Mitleid aufgelegt", "tokens": ["Blos", "weil", "mich", "die", "Na\u00b7tur", "zum", "Mit\u00b7leid", "auf\u00b7ge\u00b7legt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "KOUS", "PPER", "ART", "NN", "APPRART", "NN", "VVPP"], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.3": {"text": "Und weil mein Herz das Bild, in dem du ehrlich schienest,", "tokens": ["Und", "weil", "mein", "Herz", "das", "Bild", ",", "in", "dem", "du", "ehr\u00b7lich", "schie\u00b7nest", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPOSAT", "NN", "ART", "NN", "$,", "APPR", "PRELS", "PPER", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Aus gro\u00dfer Z\u00e4rtligkeit in seinem Blute tr\u00e4gt.", "tokens": ["Aus", "gro\u00b7\u00dfer", "Z\u00e4rt\u00b7lig\u00b7keit", "in", "sei\u00b7nem", "Blu\u00b7te", "tr\u00e4gt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.31": {"line.1": {"text": "Wie wird mir doch so angst, dir gute Nacht zu geben!", "tokens": ["Wie", "wird", "mir", "doch", "so", "angst", ",", "dir", "gu\u00b7te", "Nacht", "zu", "ge\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PPER", "ADV", "ADV", "VVPP", "$,", "PPER", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ist's m\u00f6glich, liebstes Kind, so kehre doch zur\u00fcck,", "tokens": ["Ist's", "m\u00f6g\u00b7lich", ",", "liebs\u00b7tes", "Kind", ",", "so", "keh\u00b7re", "doch", "zu\u00b7r\u00fcck", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADJD", "$,", "ADJA", "NN", "$,", "ADV", "VVFIN", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ich will dir gern verzeihn und noch vertrauter leben;", "tokens": ["Ich", "will", "dir", "gern", "ver\u00b7zeihn", "und", "noch", "ver\u00b7trau\u00b7ter", "le\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "VVINF", "KON", "ADV", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ach, wende dich nur um, hier ist der alte Blick.", "tokens": ["Ach", ",", "wen\u00b7de", "dich", "nur", "um", ",", "hier", "ist", "der", "al\u00b7te", "Blick", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "VVFIN", "PPER", "ADV", "PTKVZ", "$,", "ADV", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.32": {"line.1": {"text": "Der Himmel sieht sich Lust, sobald wir uns vertragen,", "tokens": ["Der", "Him\u00b7mel", "sieht", "sich", "Lust", ",", "so\u00b7bald", "wir", "uns", "ver\u00b7tra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PRF", "NN", "$,", "KOUS", "PPER", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ich selbst berede mich, du habest nichts gethan.", "tokens": ["Ich", "selbst", "be\u00b7re\u00b7de", "mich", ",", "du", "ha\u00b7best", "nichts", "ge\u00b7than", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "PPER", "$,", "PPER", "VAFIN", "PIS", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Bleib, Leonore, bleib! Du spottest meiner Klagen", "tokens": ["Bleib", ",", "Le\u00b7o\u00b7no\u00b7re", ",", "bleib", "!", "Du", "spot\u00b7test", "mei\u00b7ner", "Kla\u00b7gen"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$,", "NE", "$,", "VVFIN", "$.", "PPER", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und siehst mich nun nicht mehr mit deinen Augen an.", "tokens": ["Und", "siehst", "mich", "nun", "nicht", "mehr", "mit", "dei\u00b7nen", "Au\u00b7gen", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "PTKNEG", "ADV", "APPR", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.33": {"line.1": {"text": "Nun hab ich schon genug; schweig, trauriges Ger\u00fcchte.", "tokens": ["Nun", "hab", "ich", "schon", "ge\u00b7nug", ";", "schweig", ",", "trau\u00b7ri\u00b7ges", "Ge\u00b7r\u00fcch\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ADV", "$.", "VVFIN", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Das Herze sagt es mir, mein Kind sey nicht mehr mein.", "tokens": ["Das", "Her\u00b7ze", "sagt", "es", "mir", ",", "mein", "Kind", "sey", "nicht", "mehr", "mein", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "VVFIN", "PPER", "PPER", "$,", "PPOSAT", "NN", "VAFIN", "PTKNEG", "ADV", "PPOSAT", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der unverhofte Ri\u00df nimmt Regung und Gesichte", "tokens": ["Der", "un\u00b7ver\u00b7hof\u00b7te", "Ri\u00df", "nimmt", "Re\u00b7gung", "und", "Ge\u00b7sich\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Mit stummer Ungedult und bla\u00dfem Schr\u00f6cken ein.", "tokens": ["Mit", "stum\u00b7mer", "Un\u00b7ge\u00b7dult", "und", "bla\u00b7\u00dfem", "Schr\u00f6\u00b7cken", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "KON", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.34": {"line.1": {"text": "Mich deucht, ich h\u00f6re schon die neuen Hochzeitlieder,", "tokens": ["Mich", "deucht", ",", "ich", "h\u00f6\u00b7re", "schon", "die", "neu\u00b7en", "Hoch\u00b7zeit\u00b7lie\u00b7der", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VVFIN", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ja, ja, ich h\u00f6re schon der Hofnung Leichenklang;", "tokens": ["Ja", ",", "ja", ",", "ich", "h\u00f6\u00b7re", "schon", "der", "Hof\u00b7nung", "Lei\u00b7chen\u00b7klang", ";"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PTKANT", "$,", "PPER", "VVFIN", "ADV", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die Angst durchwandert mir das Marck der starcken Glieder,", "tokens": ["Die", "Angst", "durch\u00b7wan\u00b7dert", "mir", "das", "Marck", "der", "star\u00b7cken", "Glie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Um die sie kurz vorher die falschen Armen schlang.", "tokens": ["Um", "die", "sie", "kurz", "vor\u00b7her", "die", "fal\u00b7schen", "Ar\u00b7men", "schlang", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "ART", "PPER", "ADJD", "ADV", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.35": {"line.1": {"text": "Du Kind der Ewigkeit und Mutter alles Guten,", "tokens": ["Du", "Kind", "der", "E\u00b7wig\u00b7keit", "und", "Mut\u00b7ter", "al\u00b7les", "Gu\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "ART", "NN", "KON", "NN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "O Liebe, stehstu gern verliebten Dichtern bey,", "tokens": ["O", "Lie\u00b7be", ",", "steh\u00b7stu", "gern", "ver\u00b7lieb\u00b7ten", "Dich\u00b7tern", "bey", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "VVFIN", "ADV", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "So gieb, da Aug und Herz in s\u00fc\u00dfer Wehmuth bluten,", "tokens": ["So", "gieb", ",", "da", "Aug", "und", "Herz", "in", "s\u00fc\u00b7\u00dfer", "Weh\u00b7muth", "blu\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVIMP", "$,", "KOUS", "NN", "KON", "NN", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Da\u00df diese schwere Last nur noch ertr\u00e4glich sey.", "tokens": ["Da\u00df", "die\u00b7se", "schwe\u00b7re", "Last", "nur", "noch", "er\u00b7tr\u00e4g\u00b7lich", "sey", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDAT", "ADJA", "NN", "ADV", "ADV", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.36": {"line.1": {"text": "Du weist, ich diene dir mit unverf\u00e4lschtem Herzen,", "tokens": ["Du", "weist", ",", "ich", "die\u00b7ne", "dir", "mit", "un\u00b7ver\u00b7f\u00e4lschtem", "Her\u00b7zen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VVFIN", "PPER", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Du weist, ich habe stets das b\u00f6se Volck verflucht", "tokens": ["Du", "weist", ",", "ich", "ha\u00b7be", "stets", "das", "b\u00f6\u00b7se", "Volck", "ver\u00b7flucht"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VAFIN", "ADV", "ART", "ADJA", "NN", "VVPP"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und blos, das Elendweh im Leben zu verschmerzen,", "tokens": ["Und", "blos", ",", "das", "El\u00b7end\u00b7weh", "im", "Le\u00b7ben", "zu", "ver\u00b7schmer\u00b7zen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$,", "ART", "NN", "APPRART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ein Kind von frommer Art und gleicher Treu gesucht.", "tokens": ["Ein", "Kind", "von", "from\u00b7mer", "Art", "und", "glei\u00b7cher", "Treu", "ge\u00b7sucht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ADJA", "NN", "KON", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.37": {"line.1": {"text": "Wie thustu das an mir und st\u00fcrzest mein Vergn\u00fcgen,", "tokens": ["Wie", "thu\u00b7stu", "das", "an", "mir", "und", "st\u00fcr\u00b7zest", "mein", "Ver\u00b7gn\u00fc\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "ART", "APPR", "PPER", "KON", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Worauf ich so viel Zeit und M\u00fch und Flei\u00df gewand?", "tokens": ["Wo\u00b7rauf", "ich", "so", "viel", "Zeit", "und", "M\u00fch", "und", "Flei\u00df", "ge\u00b7wand", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PPER", "ADV", "PIAT", "NN", "KON", "NN", "KON", "NN", "VAPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Warum erlaubstu nicht, an dieser Brust zu liegen,", "tokens": ["Wa\u00b7rum", "er\u00b7laubs\u00b7tu", "nicht", ",", "an", "die\u00b7ser", "Brust", "zu", "lie\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PTKNEG", "$,", "APPR", "PDAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Mit der mich deine Macht so lang und starck verband?", "tokens": ["Mit", "der", "mich", "dei\u00b7ne", "Macht", "so", "lang", "und", "starck", "ver\u00b7band", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "PPOSAT", "NN", "ADV", "ADJD", "KON", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.38": {"line.1": {"text": "Ja, wenn mir alle Welt auf solchen Fall geschworen,", "tokens": ["Ja", ",", "wenn", "mir", "al\u00b7le", "Welt", "auf", "sol\u00b7chen", "Fall", "ge\u00b7schwo\u00b7ren", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "KOUS", "PPER", "PIAT", "NN", "APPR", "PIAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ja, wenn ein Engel selbst dergleichen prophezeit,", "tokens": ["Ja", ",", "wenn", "ein", "En\u00b7gel", "selbst", "derg\u00b7lei\u00b7chen", "pro\u00b7phe\u00b7zeit", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "KOUS", "ART", "NN", "ADV", "PIS", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "So h\u00e4tt ich wohl gedacht: Sie reden wie die Thoren", "tokens": ["So", "h\u00e4tt", "ich", "wohl", "ge\u00b7dacht", ":", "Sie", "re\u00b7den", "wie", "die", "Tho\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "VVPP", "$.", "PPER", "VVINF", "KOKOM", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und kennen wohl noch nicht der Liebe Z\u00e4rtligkeit.", "tokens": ["Und", "ken\u00b7nen", "wohl", "noch", "nicht", "der", "Lie\u00b7be", "Z\u00e4rt\u00b7lig\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ADV", "PTKNEG", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.39": {"line.1": {"text": "Ach allerliebstes Kind, so mu\u00df ich dir noch schreiben,", "tokens": ["Ach", "al\u00b7ler\u00b7liebs\u00b7tes", "Kind", ",", "so", "mu\u00df", "ich", "dir", "noch", "schrei\u00b7ben", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "ADJA", "NN", "$,", "ADV", "VMFIN", "PPER", "PPER", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Indem ich doch so bald mein Herz nicht trennen kan;", "tokens": ["In\u00b7dem", "ich", "doch", "so", "bald", "mein", "Herz", "nicht", "tren\u00b7nen", "kan", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "ADV", "PPOSAT", "NN", "PTKNEG", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wie magstu solchen Scherz mit Eid und Schw\u00fcren treiben,", "tokens": ["Wie", "mags\u00b7tu", "sol\u00b7chen", "Scherz", "mit", "Eid", "und", "Schw\u00fc\u00b7ren", "trei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "PIAT", "NN", "APPR", "NN", "KON", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und warum hastu so und noch an mir gethan?", "tokens": ["Und", "wa\u00b7rum", "has\u00b7tu", "so", "und", "noch", "an", "mir", "ge\u00b7than", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "VAFIN", "ADV", "KON", "ADV", "APPR", "PPER", "VVPP", "$."], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}}, "stanza.40": {"line.1": {"text": "An mir, an de\u00dfen Gunst dein irdisch Heil gehangen", "tokens": ["An", "mir", ",", "an", "de\u00b7\u00dfen", "Gunst", "dein", "ir\u00b7disch", "Heil", "ge\u00b7han\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPER", "$,", "APPR", "ART", "NN", "PPOSAT", "ADJD", "NN", "VVPP"], "meter": "+-+--+-+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.2": {"text": "Und der um dich sogar ein Spott der Misgunst hies,", "tokens": ["Und", "der", "um", "dich", "so\u00b7gar", "ein", "Spott", "der", "Mis\u00b7gunst", "hies", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "APPR", "PPER", "ADV", "ART", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "An mir, durch welchen du so vieler Noth entgangen,", "tokens": ["An", "mir", ",", "durch", "wel\u00b7chen", "du", "so", "vie\u00b7ler", "Noth", "ent\u00b7gan\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "$,", "APPR", "PWAT", "PPER", "ADV", "PIAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "An mir, der fast vor dich sein Auge nehmen lies.", "tokens": ["An", "mir", ",", "der", "fast", "vor", "dich", "sein", "Au\u00b7ge", "neh\u00b7men", "lies", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "$,", "PRELS", "ADV", "APPR", "PPER", "PPOSAT", "NN", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.41": {"line.1": {"text": "Bedencke doch nur dich, ich will von mir nichts sagen;", "tokens": ["Be\u00b7den\u00b7cke", "doch", "nur", "dich", ",", "ich", "will", "von", "mir", "nichts", "sa\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADV", "PPER", "$,", "PPER", "VMFIN", "APPR", "PPER", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wie ofters hat dein Mund (du weist, bey welcher Gruft,)", "tokens": ["Wie", "of\u00b7ters", "hat", "dein", "Mund", "(", "du", "weist", ",", "bey", "wel\u00b7cher", "Gruft", ",", ")"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["PWAV", "ADV", "VAFIN", "PPOSAT", "NN", "$(", "PPER", "VVFIN", "$,", "APPR", "PWAT", "NN", "$,", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der Eltern Asch und Staub, auf dem wir sicher lagen,", "tokens": ["Der", "El\u00b7tern", "Asch", "und", "Staub", ",", "auf", "dem", "wir", "si\u00b7cher", "la\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "KON", "NN", "$,", "APPR", "PRELS", "PPER", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Zum Zeugn\u00fc\u00df wahrer Treu mit Thr\u00e4nen angeruft!", "tokens": ["Zum", "Zeug\u00b7n\u00fc\u00df", "wah\u00b7rer", "Treu", "mit", "Thr\u00e4\u00b7nen", "an\u00b7ge\u00b7ruft", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADJA", "NN", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.42": {"line.1": {"text": "Geh in dich, falsches Kind, und frage dein Gem\u00fcthe;", "tokens": ["Geh", "in", "dich", ",", "fal\u00b7sches", "Kind", ",", "und", "fra\u00b7ge", "dein", "Ge\u00b7m\u00fc\u00b7the", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "PPER", "$,", "ADJA", "NN", "$,", "KON", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Dies, weis ich, wird vor mich ein frey Bek\u00e4ntn\u00fc\u00df thun,", "tokens": ["Dies", ",", "weis", "ich", ",", "wird", "vor", "mich", "ein", "frey", "Be\u00b7k\u00e4nt\u00b7n\u00fc\u00df", "thun", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "$,", "KOUS", "PPER", "$,", "VAFIN", "APPR", "PRF", "ART", "ADJD", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Mit was vor Ehrligkeit und nicht erkaufter G\u00fcte", "tokens": ["Mit", "was", "vor", "Ehr\u00b7lig\u00b7keit", "und", "nicht", "er\u00b7kauf\u00b7ter", "G\u00fc\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PRELS", "APPR", "NN", "KON", "PTKNEG", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Mein Herz allein gew\u00fcntscht, in deiner Schoos zu ruhn.", "tokens": ["Mein", "Herz", "al\u00b7lein", "ge\u00b7w\u00fcnt\u00b7scht", ",", "in", "dei\u00b7ner", "Schoos", "zu", "ruhn", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADV", "VVPP", "$,", "APPR", "PPOSAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.43": {"line.1": {"text": "Bedenck auch, was wir schon zusammen ausgestanden,", "tokens": ["Be\u00b7denck", "auch", ",", "was", "wir", "schon", "zu\u00b7sam\u00b7men", "aus\u00b7ge\u00b7stan\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "$,", "PRELS", "PPER", "ADV", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wie hart uns Neid und Gram und Eifersucht gequ\u00e4lt;", "tokens": ["Wie", "hart", "uns", "Neid", "und", "Gram", "und", "Ei\u00b7fer\u00b7sucht", "ge\u00b7qu\u00e4lt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "PPER", "NN", "KON", "NN", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wie manchmahl r\u00fchmtestu bey allen Ungl\u00fccksbanden,", "tokens": ["Wie", "manch\u00b7mahl", "r\u00fchm\u00b7tes\u00b7tu", "bey", "al\u00b7len", "Un\u00b7gl\u00fccks\u00b7ban\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "VVFIN", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Es w\u00e4re Philimen zu deinem Trost erwehlt!", "tokens": ["Es", "w\u00e4\u00b7re", "Phi\u00b7li\u00b7men", "zu", "dei\u00b7nem", "Trost", "er\u00b7wehlt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NN", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.44": {"line.1": {"text": "Wie sauer wurd es mir, dich anfangs zu gewinnen,", "tokens": ["Wie", "sau\u00b7er", "wurd", "es", "mir", ",", "dich", "an\u00b7fangs", "zu", "ge\u00b7win\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VAFIN", "PPER", "PPER", "$,", "PPER", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wie lange wurd ich nicht mit List herumgef\u00fchrt!", "tokens": ["Wie", "lan\u00b7ge", "wurd", "ich", "nicht", "mit", "List", "her\u00b7um\u00b7ge\u00b7f\u00fchrt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "VAFIN", "PPER", "PTKNEG", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "So viel der Thr\u00e4nen sind, die jezt aus Unmuth rinnen,", "tokens": ["So", "viel", "der", "Thr\u00e4\u00b7nen", "sind", ",", "die", "jezt", "aus", "Un\u00b7muth", "rin\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "NN", "VAFIN", "$,", "PRELS", "ADV", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So viel Mahl hat dir dort mein Ku\u00df das Herz ger\u00fchrt.", "tokens": ["So", "viel", "Mahl", "hat", "dir", "dort", "mein", "Ku\u00df", "das", "Herz", "ge\u00b7r\u00fchrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "VAFIN", "PPER", "ADV", "PPOSAT", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.45": {"line.1": {"text": "Ich troz auf kein Verdienst, so gut ich trozen m\u00f6chte,", "tokens": ["Ich", "troz", "auf", "kein", "Ver\u00b7dienst", ",", "so", "gut", "ich", "tro\u00b7zen", "m\u00f6ch\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PIAT", "NN", "$,", "ADV", "ADJD", "PPER", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ich bringe dieses nur aus guter Meinung vor:", "tokens": ["Ich", "brin\u00b7ge", "die\u00b7ses", "nur", "aus", "gu\u00b7ter", "Mei\u00b7nung", "vor", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PDAT", "ADV", "APPR", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wer sch\u00e4zte dazumahl dein Ansehn und Geschlechte,", "tokens": ["Wer", "sch\u00e4z\u00b7te", "da\u00b7zu\u00b7mahl", "dein", "An\u00b7sehn", "und", "Ge\u00b7schlech\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ADV", "PPOSAT", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Das vor der halben Stadt bereits sein Lob verlor?", "tokens": ["Das", "vor", "der", "hal\u00b7ben", "Stadt", "be\u00b7reits", "sein", "Lob", "ver\u00b7lor", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "APPR", "ART", "ADJA", "NN", "ADV", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.46": {"line.1": {"text": "Wer lehrte dich, dein Lob vern\u00fcnftig zu bedencken?", "tokens": ["Wer", "lehr\u00b7te", "dich", ",", "dein", "Lob", "ver\u00b7n\u00fcnf\u00b7tig", "zu", "be\u00b7den\u00b7cken", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "$,", "PPOSAT", "NN", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wer wies dich auf den Weg, der Menschen gl\u00fccklich macht?", "tokens": ["Wer", "wies", "dich", "auf", "den", "Weg", ",", "der", "Men\u00b7schen", "gl\u00fcck\u00b7lich", "macht", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PRF", "APPR", "ART", "NN", "$,", "ART", "NN", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wer lies sich deinen Gram bis zur Verzweiflung kr\u00e4ncken?", "tokens": ["Wer", "lies", "sich", "dei\u00b7nen", "Gram", "bis", "zur", "Ver\u00b7zwei\u00b7flung", "kr\u00e4n\u00b7cken", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PRF", "PPOSAT", "NN", "APPR", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wer hat dir den Geschmack der Liebe beygebracht?", "tokens": ["Wer", "hat", "dir", "den", "Ge\u00b7schmack", "der", "Lie\u00b7be", "bey\u00b7ge\u00b7bracht", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "ART", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.47": {"line.1": {"text": "Die Kranckheit warf dich hin, der Tod stund vor der Th\u00fcre,", "tokens": ["Die", "Kran\u00b7ck\u00b7heit", "warf", "dich", "hin", ",", "der", "Tod", "stund", "vor", "der", "Th\u00fc\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "PTKVZ", "$,", "ART", "NN", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Ich kam und hies gesund und lidt wohl mehr als du.", "tokens": ["Ich", "kam", "und", "hies", "ge\u00b7sund", "und", "lidt", "wohl", "mehr", "als", "du", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "ADJD", "KON", "VVFIN", "ADV", "ADV", "KOUS", "PPER", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "So oft ich mir die Zeit jezt ins Ged\u00e4chtn\u00fc\u00df f\u00fchre,", "tokens": ["So", "oft", "ich", "mir", "die", "Zeit", "jezt", "ins", "Ge\u00b7d\u00e4cht\u00b7n\u00fc\u00df", "f\u00fch\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "PPER", "ART", "NN", "ADV", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So ofters h\u00e4ngt mir noch ein Theil der Ohnmacht zu.", "tokens": ["So", "of\u00b7ters", "h\u00e4ngt", "mir", "noch", "ein", "Theil", "der", "Ohn\u00b7macht", "zu", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "ADV", "ART", "NN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.48": {"line.1": {"text": "Mein Helfen schlug nichts an, ich gieng in meine Kammer,", "tokens": ["Mein", "Hel\u00b7fen", "schlug", "nichts", "an", ",", "ich", "gieng", "in", "mei\u00b7ne", "Kam\u00b7mer", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PIS", "PTKVZ", "$,", "PPER", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Verschlo\u00df mich mit der Angst und warf mich auf die Knie", "tokens": ["Ver\u00b7schlo\u00df", "mich", "mit", "der", "Angst", "und", "warf", "mich", "auf", "die", "Knie"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PRF", "APPR", "ART", "NN", "KON", "VVFIN", "PRF", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und bat ich weis nicht was vor allzu gro\u00dfem Jammer,", "tokens": ["Und", "bat", "ich", "weis", "nicht", "was", "vor", "all\u00b7zu", "gro\u00b7\u00dfem", "Jam\u00b7mer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PTKVZ", "PTKNEG", "PWS", "APPR", "PTKA", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Denn eh ich mich besann, so war es wieder fr\u00fch.", "tokens": ["Denn", "eh", "ich", "mich", "be\u00b7sann", ",", "so", "war", "es", "wie\u00b7der", "fr\u00fch", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PRF", "VVFIN", "$,", "ADV", "VAFIN", "PPER", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.49": {"line.1": {"text": "Nun merck ich, da\u00df ich dort um meine Noth gebethen,", "tokens": ["Nun", "merck", "ich", ",", "da\u00df", "ich", "dort", "um", "mei\u00b7ne", "Noth", "ge\u00b7be\u00b7then", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "KOUS", "PPER", "ADV", "APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Um dich, um meine Noth, die mehr als Schwefel brennt;", "tokens": ["Um", "dich", ",", "um", "mei\u00b7ne", "Noth", ",", "die", "mehr", "als", "Schwe\u00b7fel", "brennt", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PPER", "$,", "KOUI", "PPOSAT", "NN", "$,", "PRELS", "PIS", "KOKOM", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ach, sollte deine Brunst so aus dem Glei\u00dfe treten,", "tokens": ["Ach", ",", "soll\u00b7te", "dei\u00b7ne", "Brunst", "so", "aus", "dem", "Glei\u00b7\u00dfe", "tre\u00b7ten", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "VMFIN", "PPOSAT", "NN", "ADV", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ach, warum hab ich dich dem Tode nicht geg\u00f6nnt?", "tokens": ["Ach", ",", "wa\u00b7rum", "hab", "ich", "dich", "dem", "To\u00b7de", "nicht", "ge\u00b7g\u00f6nnt", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "PWAV", "VAFIN", "PPER", "PRF", "ART", "NN", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.50": {"line.1": {"text": "Mir w\u00e4restu getreu, dir ohne Schuld gestorben,", "tokens": ["Mir", "w\u00e4\u00b7res\u00b7tu", "ge\u00b7treu", ",", "dir", "oh\u00b7ne", "Schuld", "ge\u00b7stor\u00b7ben", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "$,", "PPER", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Mein Seufzen h\u00e4tte dich in jene Welt gef\u00fchrt,", "tokens": ["Mein", "Seuf\u00b7zen", "h\u00e4t\u00b7te", "dich", "in", "je\u00b7ne", "Welt", "ge\u00b7f\u00fchrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "PPER", "APPR", "PDAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Es h\u00e4tte deine Treu ein ewig Lob erworben", "tokens": ["Es", "h\u00e4t\u00b7te", "dei\u00b7ne", "Treu", "ein", "e\u00b7wig", "Lob", "er\u00b7wor\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PPOSAT", "NN", "ART", "ADJD", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und selbst mein Wittwerflor dein Leichenkleid geziert.", "tokens": ["Und", "selbst", "mein", "Witt\u00b7wer\u00b7flor", "dein", "Lei\u00b7chen\u00b7kleid", "ge\u00b7ziert", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PPOSAT", "NN", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.51": {"line.1": {"text": "Verf\u00fchrteste der Welt, betrogne Leonore,", "tokens": ["Ver\u00b7f\u00fchr\u00b7tes\u00b7te", "der", "Welt", ",", "be\u00b7trog\u00b7ne", "Le\u00b7o\u00b7no\u00b7re", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$,", "VVFIN", "NE", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Bedenck, um was du dich mit dieser Falschheit bringst", "tokens": ["Be\u00b7denck", ",", "um", "was", "du", "dich", "mit", "die\u00b7ser", "Falschheit", "bringst"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "APPR", "PRELS", "PPER", "PRF", "APPR", "PDAT", "NN", "VVFIN"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.3": {"text": "Und ob du als ein Spott von meinem Musenchore", "tokens": ["Und", "ob", "du", "als", "ein", "Spott", "von", "mei\u00b7nem", "Mu\u00b7sen\u00b7cho\u00b7re"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "KOUS", "ART", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Nicht aus dem Paradies in Cabuls W\u00fcste springst.", "tokens": ["Nicht", "aus", "dem", "Pa\u00b7ra\u00b7dies", "in", "Ca\u00b7buls", "W\u00fcs\u00b7te", "springst", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "ART", "NN", "APPR", "NE", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.52": {"line.1": {"text": "Durch Eintracht w\u00e4re dir die Eh zum Himmel worden,", "tokens": ["Durch", "Ein\u00b7tracht", "w\u00e4\u00b7re", "dir", "die", "Eh", "zum", "Him\u00b7mel", "wor\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VAFIN", "PPER", "ART", "NN", "APPRART", "NN", "VAPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Hier h\u00e4ttestu das Marck der keuschen Brunst geschmeckt;", "tokens": ["Hier", "h\u00e4t\u00b7tes\u00b7tu", "das", "Marck", "der", "keu\u00b7schen", "Brunst", "ge\u00b7schmeckt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Du strahltest als ein Stern in jener Frauen Orden,", "tokens": ["Du", "strahl\u00b7test", "als", "ein", "Stern", "in", "je\u00b7ner", "Frau\u00b7en", "Or\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KOKOM", "ART", "NN", "APPR", "PDAT", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Dem unsre Poesie des Nachruhms Lorbeer steckt.", "tokens": ["Dem", "uns\u00b7re", "Poe\u00b7sie", "des", "Nach\u00b7ruhms", "Lor\u00b7beer", "steckt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "ART", "NN", "NE", "VVFIN", "$."], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}}, "stanza.53": {"line.1": {"text": "Steh n\u00e4chtlich einmahl auf und mi\u00df die hohe Ferne", "tokens": ["Steh", "n\u00e4cht\u00b7lich", "ein\u00b7mahl", "auf", "und", "mi\u00df", "die", "ho\u00b7he", "Fer\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "ADV", "PTKVZ", "KON", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und sieh den Milchweg an, der ist der Helden Haus;", "tokens": ["Und", "sieh", "den", "Milch\u00b7weg", "an", ",", "der", "ist", "der", "Hel\u00b7den", "Haus", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVIMP", "ART", "NN", "PTKVZ", "$,", "PRELS", "VAFIN", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Dein Nahme mehrte da den Glanz der holden Sterne,", "tokens": ["Dein", "Nah\u00b7me", "mehr\u00b7te", "da", "den", "Glanz", "der", "hol\u00b7den", "Ster\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ADV", "ART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ich las bereits den Plaz vor de\u00dfen Bildn\u00fc\u00df aus.", "tokens": ["Ich", "las", "be\u00b7reits", "den", "Plaz", "vor", "de\u00b7\u00dfen", "Bild\u00b7n\u00fc\u00df", "aus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+---+-+", "measure": "unknown.measure.penta"}}, "stanza.54": {"line.1": {"text": "Du bist vorhin gestraft, indem du mich entbehrest,", "tokens": ["Du", "bist", "vor\u00b7hin", "ge\u00b7straft", ",", "in\u00b7dem", "du", "mich", "ent\u00b7beh\u00b7rest", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "VVPP", "$,", "KOUS", "PPER", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Du strafest dich noch mehr durch deine neue Wahl,", "tokens": ["Du", "stra\u00b7fest", "dich", "noch", "mehr", "durch", "dei\u00b7ne", "neu\u00b7e", "Wahl", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ADV", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Bey der du auf der Welt schon in die H\u00f6lle f\u00e4hrest,", "tokens": ["Bey", "der", "du", "auf", "der", "Welt", "schon", "in", "die", "H\u00f6l\u00b7le", "f\u00e4h\u00b7rest", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "APPR", "ART", "NN", "ADV", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Aus welcher meine Treu dich so zu reden stahl.", "tokens": ["Aus", "wel\u00b7cher", "mei\u00b7ne", "Treu", "dich", "so", "zu", "re\u00b7den", "stahl", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPOSAT", "NN", "PPER", "ADV", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}}, "stanza.55": {"line.1": {"text": "Mit was vor Zuversicht und Augen und Gewi\u00dfen", "tokens": ["Mit", "was", "vor", "Zu\u00b7ver\u00b7sicht", "und", "Au\u00b7gen", "und", "Ge\u00b7wi\u00b7\u00dfen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PRELS", "APPR", "NN", "KON", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Getraustu dich hinfort mein Antliz anzusehn?", "tokens": ["Ge\u00b7traus\u00b7tu", "dich", "hin\u00b7fort", "mein", "Ant\u00b7liz", "an\u00b7zu\u00b7sehn", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "PPOSAT", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Was wirstu, sterb ich bald, vor Larven f\u00fcrchten m\u00fc\u00dfen!", "tokens": ["Was", "wirs\u00b7tu", ",", "sterb", "ich", "bald", ",", "vor", "Lar\u00b7ven", "f\u00fcrch\u00b7ten", "m\u00fc\u00b7\u00dfen", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "$,", "VVFIN", "PPER", "ADV", "$,", "APPR", "NN", "VVINF", "VMINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Geschieht's, so wi\u00dfe nur, es sey durch dich geschehn.", "tokens": ["Ge\u00b7schieht's", ",", "so", "wi\u00b7\u00dfe", "nur", ",", "es", "sey", "durch", "dich", "ge\u00b7schehn", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ADV", "VVFIN", "ADV", "$,", "PPER", "VAFIN", "APPR", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.56": {"line.1": {"text": "Dein Mops, gedenck an mich, wird mich an dir schon r\u00e4chen,", "tokens": ["Dein", "Mops", ",", "ge\u00b7denck", "an", "mich", ",", "wird", "mich", "an", "dir", "schon", "r\u00e4\u00b7chen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "VVIMP", "APPR", "PPER", "$,", "VAFIN", "PPER", "APPR", "PPER", "ADV", "VVINF", "$,"], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Sein Kopf ist bo\u00dfheitsvoll und wird ein Hencker seyn;", "tokens": ["Sein", "Kopf", "ist", "bo\u00df\u00b7heits\u00b7voll", "und", "wird", "ein", "Hen\u00b7cker", "seyn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADJD", "KON", "VAFIN", "ART", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Du wirst, wenn Tag und Nacht dich unter Sorgen schw\u00e4chen,", "tokens": ["Du", "wirst", ",", "wenn", "Tag", "und", "Nacht", "dich", "un\u00b7ter", "Sor\u00b7gen", "schw\u00e4\u00b7chen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "KOUS", "NN", "KON", "NN", "PRF", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Dein unbesonnen Werck, doch stets zu sp\u00e4t, bereun.", "tokens": ["Dein", "un\u00b7be\u00b7son\u00b7nen", "Werck", ",", "doch", "stets", "zu", "sp\u00e4t", ",", "be\u00b7re\u00b7un", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,", "ADV", "ADV", "PTKA", "ADJD", "$,", "VVINF", "$."], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}}, "stanza.57": {"line.1": {"text": "Alsdenn besinne dich auf G\u00e4rthen, Grab und Linden,", "tokens": ["Als\u00b7denn", "be\u00b7sin\u00b7ne", "dich", "auf", "G\u00e4r\u00b7then", ",", "Grab", "und", "Lin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "APPR", "NN", "$,", "NN", "KON", "NE", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Worunter meine Schoos dein schl\u00e4frig Haupt gewiegt;", "tokens": ["Wo\u00b7run\u00b7ter", "mei\u00b7ne", "Schoos", "dein", "schl\u00e4f\u00b7rig", "Haupt", "ge\u00b7wiegt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "PPOSAT", "ADJD", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Da wirstu mich nicht mehr auf jenem Felsen finden,", "tokens": ["Da", "wirs\u00b7tu", "mich", "nicht", "mehr", "auf", "je\u00b7nem", "Fel\u00b7sen", "fin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PTKNEG", "ADV", "APPR", "PDAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Auf welchem noch von uns ein Bundeszeichen liegt.", "tokens": ["Auf", "wel\u00b7chem", "noch", "von", "uns", "ein", "Bun\u00b7des\u00b7zei\u00b7chen", "liegt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "ADV", "APPR", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.58": {"line.1": {"text": "Die lezte Sommernacht wird nicht mehr wiederkommen;", "tokens": ["Die", "lez\u00b7te", "Som\u00b7mer\u00b7nacht", "wird", "nicht", "mehr", "wie\u00b7der\u00b7kom\u00b7men", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "PTKNEG", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Spiel, K\u00fc\u00dfe, Tanz und Vers und Str\u00e4u\u00dfer treuer Hand", "tokens": ["Spiel", ",", "K\u00fc\u00b7\u00dfe", ",", "Tanz", "und", "Vers", "und", "Str\u00e4u\u00b7\u00dfer", "treu\u00b7er", "Hand"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "NN", "$,", "NN", "KON", "NN", "KON", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Sind Sch\u00e4ze, welche dir der Raub der Zeit genommen,", "tokens": ["Sind", "Sch\u00e4\u00b7ze", ",", "wel\u00b7che", "dir", "der", "Raub", "der", "Zeit", "ge\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "$,", "PRELS", "PPER", "ART", "NN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Was sag ich? die du dir aus Falschheit selbst entwand.", "tokens": ["Was", "sag", "ich", "?", "die", "du", "dir", "aus", "Falschheit", "selbst", "ent\u00b7wand", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "$.", "PRELS", "PPER", "PPER", "APPR", "NN", "ADV", "VVFIN", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}}, "stanza.59": {"line.1": {"text": "Es hat mir wohl geahnt; denn kanstu dich besinnen,", "tokens": ["Es", "hat", "mir", "wohl", "ge\u00b7ahnt", ";", "denn", "kans\u00b7tu", "dich", "be\u00b7sin\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "VVPP", "$.", "KON", "VMFIN", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Bey welcher Garthenlust dein Ring den Finger band?", "tokens": ["Bey", "wel\u00b7cher", "Gar\u00b7then\u00b7lust", "dein", "Ring", "den", "Fin\u00b7ger", "band", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PWAT", "NN", "PPOSAT", "NN", "ART", "NN", "VVFIN", "$."], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.3": {"text": "Mein Auge fing dort nicht ohn Ursach an zu rinnen,", "tokens": ["Mein", "Au\u00b7ge", "fing", "dort", "nicht", "ohn", "Ur\u00b7sach", "an", "zu", "rin\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ADV", "PTKNEG", "APPR", "NN", "PTKVZ", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Dir aber fiel das Blut in Tropfen auf die Hand.", "tokens": ["Dir", "a\u00b7ber", "fiel", "das", "Blut", "in", "Trop\u00b7fen", "auf", "die", "Hand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "ART", "NN", "APPR", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.60": {"line.1": {"text": "Noch mehr, die nechste Nacht verlor ich dich im Traume", "tokens": ["Noch", "mehr", ",", "die", "nechs\u00b7te", "Nacht", "ver\u00b7lor", "ich", "dich", "im", "Trau\u00b7me"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "$,", "ART", "ADJA", "NN", "VVFIN", "PPER", "PRF", "APPRART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und weckte mich fast selbst durch Angst und Winseln auf;", "tokens": ["Und", "weck\u00b7te", "mich", "fast", "selbst", "durch", "Angst", "und", "Win\u00b7seln", "auf", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "ADV", "APPR", "NN", "KON", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der unverhofte Bruch von deinem liebsten Baume", "tokens": ["Der", "un\u00b7ver\u00b7hof\u00b7te", "Bruch", "von", "dei\u00b7nem", "liebs\u00b7ten", "Bau\u00b7me"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wies etwan auch vorher der Liebe kurzen Lauf.", "tokens": ["Wies", "et\u00b7wan", "auch", "vor\u00b7her", "der", "Lie\u00b7be", "kur\u00b7zen", "Lauf", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "ADV", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.61": {"line.1": {"text": "Sey da und sch\u00fcze vor, man habe dich gezwungen;", "tokens": ["Sey", "da", "und", "sch\u00fc\u00b7ze", "vor", ",", "man", "ha\u00b7be", "dich", "ge\u00b7zwun\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "KON", "VVFIN", "PTKVZ", "$,", "PIS", "VAFIN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der, die warhaftig liebt, hat Flehn und Zwang nichts an.", "tokens": ["Der", ",", "die", "war\u00b7haf\u00b7tig", "liebt", ",", "hat", "Flehn", "und", "Zwang", "nichts", "an", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "PRELS", "ADJD", "VVFIN", "$,", "VAFIN", "VVINF", "KON", "NN", "PIS", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Du selbst hast nicht gewollt, sonst w\u00e4r es wohl gelungen,", "tokens": ["Du", "selbst", "hast", "nicht", "ge\u00b7wollt", ",", "sonst", "w\u00e4r", "es", "wohl", "ge\u00b7lun\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VAFIN", "PTKNEG", "VMPP", "$,", "ADV", "VAFIN", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Indem doch Weiberlist viel Ausflucht machen kan.", "tokens": ["In\u00b7dem", "doch", "Wei\u00b7ber\u00b7list", "viel", "Aus\u00b7flucht", "ma\u00b7chen", "kan", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "NN", "PIAT", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.62": {"line.1": {"text": "Du daurest mich noch sehr, nicht weil du dies verdienest,", "tokens": ["Du", "dau\u00b7rest", "mich", "noch", "sehr", ",", "nicht", "weil", "du", "dies", "ver\u00b7die\u00b7nest", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ADV", "$,", "PTKNEG", "KOUS", "PPER", "PDS", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Blos weil mich die Natur zum Mitleid aufgelegt", "tokens": ["Blos", "weil", "mich", "die", "Na\u00b7tur", "zum", "Mit\u00b7leid", "auf\u00b7ge\u00b7legt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "KOUS", "PPER", "ART", "NN", "APPRART", "NN", "VVPP"], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.3": {"text": "Und weil mein Herz das Bild, in dem du ehrlich schienest,", "tokens": ["Und", "weil", "mein", "Herz", "das", "Bild", ",", "in", "dem", "du", "ehr\u00b7lich", "schie\u00b7nest", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPOSAT", "NN", "ART", "NN", "$,", "APPR", "PRELS", "PPER", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Aus gro\u00dfer Z\u00e4rtligkeit in seinem Blute tr\u00e4gt.", "tokens": ["Aus", "gro\u00b7\u00dfer", "Z\u00e4rt\u00b7lig\u00b7keit", "in", "sei\u00b7nem", "Blu\u00b7te", "tr\u00e4gt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.63": {"line.1": {"text": "Wie wird mir doch so angst, dir gute Nacht zu geben!", "tokens": ["Wie", "wird", "mir", "doch", "so", "angst", ",", "dir", "gu\u00b7te", "Nacht", "zu", "ge\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PPER", "ADV", "ADV", "VVPP", "$,", "PPER", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ist's m\u00f6glich, liebstes Kind, so kehre doch zur\u00fcck,", "tokens": ["Ist's", "m\u00f6g\u00b7lich", ",", "liebs\u00b7tes", "Kind", ",", "so", "keh\u00b7re", "doch", "zu\u00b7r\u00fcck", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADJD", "$,", "ADJA", "NN", "$,", "ADV", "VVFIN", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ich will dir gern verzeihn und noch vertrauter leben;", "tokens": ["Ich", "will", "dir", "gern", "ver\u00b7zeihn", "und", "noch", "ver\u00b7trau\u00b7ter", "le\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "VVINF", "KON", "ADV", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ach, wende dich nur um, hier ist der alte Blick.", "tokens": ["Ach", ",", "wen\u00b7de", "dich", "nur", "um", ",", "hier", "ist", "der", "al\u00b7te", "Blick", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "VVFIN", "PPER", "ADV", "PTKVZ", "$,", "ADV", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.64": {"line.1": {"text": "Der Himmel sieht sich Lust, sobald wir uns vertragen,", "tokens": ["Der", "Him\u00b7mel", "sieht", "sich", "Lust", ",", "so\u00b7bald", "wir", "uns", "ver\u00b7tra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PRF", "NN", "$,", "KOUS", "PPER", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ich selbst berede mich, du habest nichts gethan.", "tokens": ["Ich", "selbst", "be\u00b7re\u00b7de", "mich", ",", "du", "ha\u00b7best", "nichts", "ge\u00b7than", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "PPER", "$,", "PPER", "VAFIN", "PIS", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Bleib, Leonore, bleib! Du spottest meiner Klagen", "tokens": ["Bleib", ",", "Le\u00b7o\u00b7no\u00b7re", ",", "bleib", "!", "Du", "spot\u00b7test", "mei\u00b7ner", "Kla\u00b7gen"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$,", "NE", "$,", "VVFIN", "$.", "PPER", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und siehst mich nun nicht mehr mit deinen Augen an.", "tokens": ["Und", "siehst", "mich", "nun", "nicht", "mehr", "mit", "dei\u00b7nen", "Au\u00b7gen", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "PTKNEG", "ADV", "APPR", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}