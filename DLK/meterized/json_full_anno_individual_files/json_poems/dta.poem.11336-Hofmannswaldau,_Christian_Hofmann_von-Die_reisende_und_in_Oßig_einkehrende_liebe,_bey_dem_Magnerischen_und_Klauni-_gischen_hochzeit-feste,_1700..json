{"dta.poem.11336": {"metadata": {"author": {"name": "Hofmannswaldau, Christian Hofmann von", "birth": "N.A.", "death": "N.A."}, "title": "Die reisende und in O\u00dfig einkehrende liebe,  \n bey dem Magnerischen und Klauni-  \n gischen hochzeit-feste, 1700.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1709", "urn": "urn:nbn:de:kobv:b4-20283-5", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Die liebe, deren band die welt zusammen h\u00e4lt,", "tokens": ["Die", "lie\u00b7be", ",", "de\u00b7ren", "band", "die", "welt", "zu\u00b7sam\u00b7men", "h\u00e4lt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "VVFIN", "$,", "PDS", "VVFIN", "ART", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Durchlief in einem blick den gantzen kreis der erden:", "tokens": ["Durch\u00b7lief", "in", "ei\u00b7nem", "blick", "den", "gant\u00b7zen", "kreis", "der", "er\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "ART", "ADJA", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ach! sprach sie, soll mein reich itzt nicht erweitert werden?", "tokens": ["Ach", "!", "sprach", "sie", ",", "soll", "mein", "reich", "itzt", "nicht", "er\u00b7wei\u00b7tert", "wer\u00b7den", "?"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$.", "VVFIN", "PPER", "$,", "VMFIN", "PPOSAT", "ADJD", "ADV", "PTKNEG", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ich sehe hier die lust der neu-gebohrnen welt,", "tokens": ["Ich", "se\u00b7he", "hier", "die", "lust", "der", "neu\u00b7ge\u00b7bohr\u00b7nen", "welt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Da, wo der himmel selbst die gr\u00fcnen auen k\u00fcsset,", "tokens": ["Da", ",", "wo", "der", "him\u00b7mel", "selbst", "die", "gr\u00fc\u00b7nen", "au\u00b7en", "k\u00fcs\u00b7set", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PWAV", "ART", "NN", "ADV", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und seinen k\u00fchlen thau auf gras und blumen giesset.", "tokens": ["Und", "sei\u00b7nen", "k\u00fch\u00b7len", "thau", "auf", "gras", "und", "blu\u00b7men", "gies\u00b7set", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "APPR", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Die angenehme zeit begeistert diesen sinn,", "tokens": ["Die", "an\u00b7ge\u00b7neh\u00b7me", "zeit", "be\u00b7geis\u00b7tert", "die\u00b7sen", "sinn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ich will durch wald und feld, durch land und wasser reisen,", "tokens": ["Ich", "will", "durch", "wald", "und", "feld", ",", "durch", "land", "und", "was\u00b7ser", "rei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPR", "NN", "KON", "NN", "$,", "APPR", "NN", "KON", "PWS", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und dieses scepters macht der gantzen erden weisen.", "tokens": ["Und", "die\u00b7ses", "scep\u00b7ters", "macht", "der", "gant\u00b7zen", "er\u00b7den", "wei\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDAT", "NN", "VVFIN", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Jhr tauben! traget mich zu allen v\u00f6lckern hin!", "tokens": ["Ihr", "tau\u00b7ben", "!", "tra\u00b7get", "mich", "zu", "al\u00b7len", "v\u00f6l\u00b7ckern", "hin", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVINF", "$.", "VVFIN", "PPER", "APPR", "PIAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "So fuhr die liebe fort, wie pfeile von dem bogen,", "tokens": ["So", "fuhr", "die", "lie\u00b7be", "fort", ",", "wie", "pfei\u00b7le", "von", "dem", "bo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "VVFIN", "PTKVZ", "$,", "PWAV", "VVFIN", "APPR", "ART", "ADJA", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und hat so berg als thal mit ihrer gluth durchzogen.", "tokens": ["Und", "hat", "so", "berg", "als", "thal", "mit", "ih\u00b7rer", "gluth", "durch\u00b7zo\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "ADJD", "KOKOM", "VVFIN", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Jhr erster austritt war der guten hoffnung port,", "tokens": ["Ihr", "ers\u00b7ter", "aus\u00b7tritt", "war", "der", "gu\u00b7ten", "hoff\u00b7nung", "port", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VAFIN", "ART", "ADJA", "NN", "NE", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Sie kam in Africam, und sahe nichts als w\u00fcsten:", "tokens": ["Sie", "kam", "in", "A\u00b7fri\u00b7cam", ",", "und", "sa\u00b7he", "nichts", "als", "w\u00fcs\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NE", "$,", "KON", "VVFIN", "PIS", "KOKOM", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Hier, sprach sie, mag ein drach und keine liebe nisten!", "tokens": ["Hier", ",", "sprach", "sie", ",", "mag", "ein", "drach", "und", "kei\u00b7ne", "lie\u00b7be", "nis\u00b7ten", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "VVFIN", "PPER", "$,", "VMFIN", "ART", "ADV", "KON", "PIAT", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Sie gieng in Asien mit schnellen fl\u00fcgeln fort:", "tokens": ["Sie", "gieng", "in", "A\u00b7sien", "mit", "schnel\u00b7len", "fl\u00fc\u00b7geln", "fort", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NE", "APPR", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+----+-+-+", "measure": "dactylic.init"}, "line.5": {"text": "Auch hier ist, sagte sie, kein thron vor mich gesetzet,", "tokens": ["Auch", "hier", "ist", ",", "sag\u00b7te", "sie", ",", "kein", "thron", "vor", "mich", "ge\u00b7set\u00b7zet", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VAFIN", "$,", "VVFIN", "PPER", "$,", "PIAT", "NN", "APPR", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wo sich die grausamkeit mit eitel blute netzet.", "tokens": ["Wo", "sich", "die", "grau\u00b7sam\u00b7keit", "mit", "ei\u00b7tel", "blu\u00b7te", "net\u00b7zet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PRF", "ART", "NN", "APPR", "ADJD", "VVFIN", "NE", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Die fl\u00fcgel trugen sie bi\u00df in Americam,", "tokens": ["Die", "fl\u00fc\u00b7gel", "tru\u00b7gen", "sie", "bi\u00df", "in", "A\u00b7me\u00b7ri\u00b7cam", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADV", "APPR", "NE", "$,"], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Da lag das wilde volck in gold und silber-gr\u00fcfften:", "tokens": ["Da", "lag", "das", "wil\u00b7de", "volck", "in", "gold", "und", "sil\u00b7ber\u00b7gr\u00fcff\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Was werd ich, fragte sie, bey diesen tygern stifften?", "tokens": ["Was", "werd", "ich", ",", "frag\u00b7te", "sie", ",", "bey", "die\u00b7sen", "ty\u00b7gern", "stiff\u00b7ten", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "$,", "VVFIN", "PPER", "$,", "APPR", "PDAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Darauf sie ihren weg auch zu den insuln nahm;", "tokens": ["Da\u00b7rauf", "sie", "ih\u00b7ren", "weg", "auch", "zu", "den", "in\u00b7suln", "nahm", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PPER", "PPOSAT", "ADV", "ADV", "APPR", "ART", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-++-", "measure": "unknown.measure.hexa"}, "line.5": {"text": "Doch kein Canarien lie\u00df solchen zucker schmecken,", "tokens": ["Doch", "kein", "Ca\u00b7na\u00b7ri\u00b7en", "lie\u00df", "sol\u00b7chen", "zu\u00b7cker", "schme\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "VVFIN", "PIAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Dabey sie willens war, die tafel aufzudecken.", "tokens": ["Da\u00b7bey", "sie", "wil\u00b7lens", "war", ",", "die", "ta\u00b7fel", "auf\u00b7zu\u00b7de\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PAV", "PPER", "NN", "VAFIN", "$,", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Gl\u00fcck zu! du edles land! der l\u00e4nder paradie\u00df!", "tokens": ["Gl\u00fcck", "zu", "!", "du", "ed\u00b7les", "land", "!", "der", "l\u00e4n\u00b7der", "pa\u00b7ra\u00b7die\u00df", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "PTKVZ", "$.", "PPER", "ADJA", "NN", "$.", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "So rief sie freudig aus, als sie Europam sahe;", "tokens": ["So", "rief", "sie", "freu\u00b7dig", "aus", ",", "als", "sie", "Eu\u00b7ro\u00b7pam", "sa\u00b7he", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "PTKVZ", "$,", "KOUS", "PPER", "NE", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Bald setzte sie den fu\u00df bey Hereuls-s\u00e4ulen aus,", "tokens": ["Bald", "setz\u00b7te", "sie", "den", "fu\u00df", "bey", "Her\u00b7euls\u00b7s\u00e4u\u00b7len", "aus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "PTKVZ", "APPR", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ulyssens sch\u00f6ne stadt bekam die ersten blicke;", "tokens": ["U\u00b7lys\u00b7sens", "sch\u00f6\u00b7ne", "stadt", "be\u00b7kam", "die", "ers\u00b7ten", "bli\u00b7cke", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "VVFIN", "ART", "ADJA", "VVFIN", "$."], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.3": {"text": "Allein hier dachte man noch an den tod zur\u00fccke,", "tokens": ["Al\u00b7lein", "hier", "dach\u00b7te", "man", "noch", "an", "den", "tod", "zu\u00b7r\u00fc\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PIS", "ADV", "APPR", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Es deckte noch der boy das k\u00f6nigliche haus:", "tokens": ["Es", "deck\u00b7te", "noch", "der", "boy", "das", "k\u00f6\u00b7nig\u00b7li\u00b7che", "haus", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Don Petro hatte nur die einsamkeit erwehlet,", "tokens": ["Don", "Pe\u00b7tro", "hat\u00b7te", "nur", "die", "ein\u00b7sam\u00b7keit", "er\u00b7weh\u00b7let", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VAFIN", "ADV", "ART", "NN", "VVPP", "$,"], "meter": "++-+-+-+-+-+-", "measure": "unknown.measure.septa"}, "line.6": {"text": "Weil seine k\u00f6nigin dem tode sich verm\u00e4hlet.", "tokens": ["Weil", "sei\u00b7ne", "k\u00f6\u00b7ni\u00b7gin", "dem", "to\u00b7de", "sich", "ver\u00b7m\u00e4h\u00b7let", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "ART", "NN", "PRF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Drum gieng die liebe fort, und gr\u00fcssete Madrit:", "tokens": ["Drum", "gieng", "die", "lie\u00b7be", "fort", ",", "und", "gr\u00fcs\u00b7se\u00b7te", "Mad\u00b7rit", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "ART", "VVFIN", "PTKVZ", "$,", "KON", "ADJA", "NN", "$."], "meter": "-+-+-+-+--++", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Auch hier war schlechte lust, weil des monarchen leben", "tokens": ["Auch", "hier", "war", "schlech\u00b7te", "lust", ",", "weil", "des", "mon\u00b7ar\u00b7chen", "le\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "VAFIN", "ADJA", "NN", "$,", "KOUS", "ART", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der steten todes-furcht durch kranckheit \u00fcbergeben:", "tokens": ["Der", "ste\u00b7ten", "to\u00b7des\u00b7furcht", "durch", "kran\u00b7ck\u00b7heit", "\u00fc\u00b7ber\u00b7ge\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Nein, sprach sie, wo der tod, da geht die liebe quitt,", "tokens": ["Nein", ",", "sprach", "sie", ",", "wo", "der", "tod", ",", "da", "geht", "die", "lie\u00b7be", "quitt", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "VVFIN", "PPER", "$,", "PWAV", "ART", "NN", "$,", "ADV", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ich seegle nach Pari\u00df, wo sich vor meinen blicken", "tokens": ["Ich", "seeg\u00b7le", "nach", "Pa\u00b7ri\u00df", ",", "wo", "sich", "vor", "mei\u00b7nen", "bli\u00b7cken"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "NE", "$,", "PWAV", "PRF", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Der grosse Ludewig mu\u00df selber niederb\u00fccken.", "tokens": ["Der", "gros\u00b7se", "Lu\u00b7de\u00b7wig", "mu\u00df", "sel\u00b7ber", "nie\u00b7der\u00b7b\u00fc\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NE", "VMFIN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "Doch ihre hoffnung ward zu wasser und zu wind,", "tokens": ["Doch", "ih\u00b7re", "hoff\u00b7nung", "ward", "zu", "was\u00b7ser", "und", "zu", "wind", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VAFIN", "PTKA", "ADJD", "KON", "APPR", "NE", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Weil man nur lauter streit allhier im sinne f\u00fchrte,", "tokens": ["Weil", "man", "nur", "lau\u00b7ter", "streit", "all\u00b7hier", "im", "sin\u00b7ne", "f\u00fchr\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ADV", "PIAT", "NN", "ADV", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und den Maroccer-printz mit einem korbe zierte.", "tokens": ["Und", "den", "Ma\u00b7roc\u00b7cer\u00b7printz", "mit", "ei\u00b7nem", "kor\u00b7be", "zier\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "APPR", "ART", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Sie schwamm in Engeland, und fand ein labyrinth,", "tokens": ["Sie", "schwamm", "in", "En\u00b7ge\u00b7land", ",", "und", "fand", "ein", "la\u00b7by\u00b7rinth", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NE", "$,", "KON", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wo zwietracht ihren sitz im Parlament genommen,", "tokens": ["Wo", "zwiet\u00b7racht", "ih\u00b7ren", "sitz", "im", "Par\u00b7la\u00b7ment", "ge\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPOSAT", "NN", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und Wilhelms tapferkeit noch manchen feind bekommen.", "tokens": ["Und", "Wil\u00b7helms", "tap\u00b7fer\u00b7keit", "noch", "man\u00b7chen", "feind", "be\u00b7kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "NN", "ADV", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Wo wend ich, dachte sie, nun meine deichsel hin?", "tokens": ["Wo", "wend", "ich", ",", "dach\u00b7te", "sie", ",", "nun", "mei\u00b7ne", "deich\u00b7sel", "hin", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "KOUS", "PPER", "$,", "VVFIN", "PPER", "$,", "ADV", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die wellen trugen sie nach Amsterdam zur\u00fccke;", "tokens": ["Die", "wel\u00b7len", "tru\u00b7gen", "sie", "nach", "A\u00b7mster\u00b7dam", "zu\u00b7r\u00fc\u00b7cke", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "APPR", "NE", "PTKVZ", "$."], "meter": "-+-+-++-++-+-", "measure": "unknown.measure.septa"}, "line.3": {"text": "Alle in man gab ihr hier nicht allzuholde blicke:", "tokens": ["Al\u00b7le", "in", "man", "gab", "ihr", "hier", "nicht", "all\u00b7zu\u00b7hol\u00b7de", "bli\u00b7cke", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "APPR", "PIS", "VVFIN", "PPER", "ADV", "PTKNEG", "ADV", "VVFIN", "$."], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}, "line.4": {"text": "Die liebe, die hier wohnt, heist wucher und gewinn.", "tokens": ["Die", "lie\u00b7be", ",", "die", "hier", "wohnt", ",", "heist", "wu\u00b7cher", "und", "ge\u00b7winn", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "VVFIN", "$,", "PRELS", "ADV", "VVFIN", "$,", "VAFIN", "ADJD", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "So will ich dann, sprach sie, nach Norden \u00fcbergehen,", "tokens": ["So", "will", "ich", "dann", ",", "sprach", "sie", ",", "nach", "Nor\u00b7den", "\u00fc\u00b7ber\u00b7ge\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "$,", "VVFIN", "PPER", "$,", "APPR", "NN", "VVINF", "$,"], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.6": {"text": "Wer wei\u00df, wo gluth und muth mir wird zu dienste stehen.", "tokens": ["Wer", "wei\u00df", ",", "wo", "gluth", "und", "muth", "mir", "wird", "zu", "diens\u00b7te", "ste\u00b7hen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "$,", "PWAV", "NN", "KON", "NN", "PPER", "VAFIN", "APPR", "PDS", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.10": {"line.1": {"text": "Ach! aber was vor gluth traff sie in Hollstein an!", "tokens": ["Ach", "!", "a\u00b7ber", "was", "vor", "gluth", "traff", "sie", "in", "Holl\u00b7stein", "an", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$.", "KON", "PWS", "APPR", "NN", "VVFIN", "PPER", "APPR", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Da man auf T\u00f6nningen mit lauter blitzen spielte,", "tokens": ["Da", "man", "auf", "T\u00f6n\u00b7nin\u00b7gen", "mit", "lau\u00b7ter", "blit\u00b7zen", "spiel\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "APPR", "NN", "APPR", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+---+-+-+-", "measure": "unknown.measure.penta"}, "line.3": {"text": "Und h\u00e4user, thurm und wall der erden gleiche w\u00fchlte:", "tokens": ["Und", "h\u00e4u\u00b7ser", ",", "thurm", "und", "wall", "der", "er\u00b7den", "glei\u00b7che", "w\u00fchl\u00b7te", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "$,", "ADJD", "KON", "NN", "ART", "NN", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ist niemand, seufftzte sie, der dieses leschen kan?", "tokens": ["Ist", "nie\u00b7mand", ",", "seufftz\u00b7te", "sie", ",", "der", "die\u00b7ses", "le\u00b7schen", "kan", "?"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "$,", "VVFIN", "PPER", "$,", "PRELS", "PDAT", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "In Schweden sahe sie zwar hohe liebe keimen;", "tokens": ["In", "Schwe\u00b7den", "sa\u00b7he", "sie", "zwar", "ho\u00b7he", "lie\u00b7be", "kei\u00b7men", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VVFIN", "PPER", "ADV", "ADJA", "VVFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Die doch der krieges-gluth bald mu\u00df die stelle r\u00e4umen.", "tokens": ["Die", "doch", "der", "krie\u00b7ge\u00b7sgluth", "bald", "mu\u00df", "die", "stel\u00b7le", "r\u00e4u\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ART", "NN", "ADV", "VMFIN", "ART", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.11": {"line.1": {"text": "\u201cnach Polen komm ich nicht: Di\u00df war der liebe schlu\u00df;", "tokens": ["\u201c", "nach", "Po\u00b7len", "komm", "ich", "nicht", ":", "Di\u00df", "war", "der", "lie\u00b7be", "schlu\u00df", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "NE", "VVFIN", "PPER", "PTKNEG", "$.", "PDS", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "\u201eaugustus und sein volck mag sich vor Riga regen:", "tokens": ["\u201e", "au\u00b7gus\u00b7tus", "und", "sein", "volck", "mag", "sich", "vor", "Ri\u00b7ga", "re\u00b7gen", ":"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "NE", "KON", "PPOSAT", "NN", "VMFIN", "PRF", "APPR", "NE", "ADJA", "$."], "meter": "+-+-+-+--+-+-", "measure": "trochaic.hexa.relaxed"}, "line.3": {"text": "\u201enach Moscau will ich nicht, weil ich doch allerwegen,", "tokens": ["\u201e", "nach", "Mo\u00b7scau", "will", "ich", "nicht", ",", "weil", "ich", "doch", "al\u00b7ler\u00b7we\u00b7gen", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "NE", "VMFIN", "PPER", "PTKNEG", "$,", "KOUS", "PPER", "ADV", "ADV", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "\u201ekrieg, feuer, dampf und schwerd zur losung h\u00f6ren mu\u00df;", "tokens": ["\u201e", "krieg", ",", "feu\u00b7er", ",", "dampf", "und", "schwerd", "zur", "lo\u00b7sung", "h\u00f6\u00b7ren", "mu\u00df", ";"], "token_info": ["punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "$,", "ADJD", "$,", "PAV", "KON", "ADJD", "APPRART", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "\u201emag doch das schwartze meer mit rothem blute fliessen;", "tokens": ["\u201e", "mag", "doch", "das", "schwart\u00b7ze", "meer", "mit", "ro\u00b7them", "blu\u00b7te", "flies\u00b7sen", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VMFIN", "ADV", "ART", "ADJA", "NN", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "\u201emars mu\u00df entwaffnet seyn, will er die liebe k\u00fcssen.", "tokens": ["\u201e", "mars", "mu\u00df", "ent\u00b7waff\u00b7net", "seyn", ",", "will", "er", "die", "lie\u00b7be", "k\u00fcs\u00b7sen", "."], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PIS", "VMFIN", "VVPP", "VAINF", "$,", "VMFIN", "PPER", "ART", "ADJA", "VVINF", "$."], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}}, "stanza.12": {"line.1": {"text": "\u201cdir, dir, Germanien! vermeld ich meinen gru\u00df!", "tokens": ["\u201c", "dir", ",", "dir", ",", "Ger\u00b7ma\u00b7ni\u00b7en", "!", "ver\u00b7meld", "ich", "mei\u00b7nen", "gru\u00df", "!"], "token_info": ["punct", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "$,", "PPER", "$,", "NN", "$.", "VVFIN", "PPER", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "\u201ehab ich dir mein panier zu ehren aufgestecket.", "tokens": ["\u201e", "hab", "ich", "dir", "mein", "pa\u00b7nier", "zu", "eh\u00b7ren", "auf\u00b7ge\u00b7ste\u00b7cket", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VAFIN", "PPER", "PPER", "PPOSAT", "NN", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "\u201ejhr fl\u00fcgel, schwinget euch! und r\u00fcste dich, mein fu\u00df!", "tokens": ["\u201e", "jhr", "fl\u00fc\u00b7gel", ",", "schwin\u00b7get", "euch", "!", "und", "r\u00fcs\u00b7te", "dich", ",", "mein", "fu\u00df", "!"], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "PPOSAT", "NN", "$,", "VVFIN", "PPER", "$.", "KON", "VVFIN", "PPER", "$,", "PPOSAT", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "\u201eda\u00df ich bald h\u00f6chst-vergn\u00fcgt auf diesen grentzen stehe,", "tokens": ["\u201e", "da\u00df", "ich", "bald", "h\u00f6chst\u00b7ver\u00b7gn\u00fcgt", "auf", "die\u00b7sen", "grent\u00b7zen", "ste\u00b7he", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "PPER", "ADV", "ADJD", "APPR", "PDAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "\u201eund bey der fr\u00fchlings-lust auf lauter rosen gehe.", "tokens": ["\u201e", "und", "bey", "der", "fr\u00fch\u00b7lings\u00b7lust", "auf", "lau\u00b7ter", "ro\u00b7sen", "ge\u00b7he", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KON", "APPR", "ART", "NN", "APPR", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.13": {"line.1": {"text": "Kaum war es ausgeredt, als sie sich durch die lufft", "tokens": ["Kaum", "war", "es", "aus\u00b7ge\u00b7redt", ",", "als", "sie", "sich", "durch", "die", "lufft"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "VVPP", "$,", "KOUS", "PPER", "PRF", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Mit schneller fl\u00fcchtigkeit nach Teutschlands boden wandte,", "tokens": ["Mit", "schnel\u00b7ler", "fl\u00fcch\u00b7tig\u00b7keit", "nach", "Teutschlands", "bo\u00b7den", "wand\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "APPR", "NE", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Bald fand sie einen ort, wo gluth und liebe brannte.", "tokens": ["Bald", "fand", "sie", "ei\u00b7nen", "ort", ",", "wo", "gluth", "und", "lie\u00b7be", "brann\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "$,", "PWAV", "NN", "KON", "VVFIN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Begl\u00fccktes Brandenburg! wo diese stimme rufft:", "tokens": ["Be\u00b7gl\u00fcck\u00b7tes", "Bran\u00b7den\u00b7burg", "!", "wo", "die\u00b7se", "stim\u00b7me", "rufft", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$.", "PWAV", "PDS", "VVFIN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.14": {"line.1": {"text": "Hier go\u00df die liebe nun den st\u00e4rcksten balsam zu:", "tokens": ["Hier", "go\u00df", "die", "lie\u00b7be", "nun", "den", "st\u00e4rcks\u00b7ten", "bal\u00b7sam", "zu", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "VVFIN", "ADV", "ART", "ADJA", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Sie legte gluth zu gluth, und ketten zu den ketten:", "tokens": ["Sie", "leg\u00b7te", "gluth", "zu", "gluth", ",", "und", "ket\u00b7ten", "zu", "den", "ket\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "APPR", "NN", "$,", "KON", "VVFIN", "APPR", "ART", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Sie schm\u00fcckete das zelt mit lauter rosen-betten:", "tokens": ["Sie", "schm\u00fc\u00b7cke\u00b7te", "das", "zelt", "mit", "lau\u00b7ter", "ro\u00b7sen\u00b7bet\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PDS", "VVFIN", "APPR", "PIAT", "ADJA", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.15": {"line.1": {"text": "Als dieses und noch mehr die liebe hier gethan,", "tokens": ["Als", "die\u00b7ses", "und", "noch", "mehr", "die", "lie\u00b7be", "hier", "ge\u00b7than", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDAT", "KON", "ADV", "ADV", "ART", "VVFIN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "So eilete sie fort, ihr angenehmes wesen", "tokens": ["So", "ei\u00b7le\u00b7te", "sie", "fort", ",", "ihr", "an\u00b7ge\u00b7neh\u00b7mes", "we\u00b7sen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PTKVZ", "$,", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "An andern h\u00f6fen auch den printzen vorzulesen.", "tokens": ["An", "an\u00b7dern", "h\u00f6\u00b7fen", "auch", "den", "print\u00b7zen", "vor\u00b7zu\u00b7le\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "VVFIN", "ADV", "ART", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Vornehmlich setzte sie nach Oestreich ihre bahn:", "tokens": ["Vor\u00b7nehm\u00b7lich", "setz\u00b7te", "sie", "nach", "O\u00b7e\u00b7streich", "ih\u00b7re", "bahn", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "NE", "PPOSAT", "NN", "$."], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.16": {"line.1": {"text": "Doch da sie nun der weg nach seinem throne trug,", "tokens": ["Doch", "da", "sie", "nun", "der", "weg", "nach", "sei\u00b7nem", "thro\u00b7ne", "trug", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "ART", "ADV", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Fand sie in Schlesien ein dorff im thale liegen;", "tokens": ["Fand", "sie", "in", "Schle\u00b7si\u00b7en", "ein", "dorff", "im", "tha\u00b7le", "lie\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "NN", "ART", "NN", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ein schall und wohl-geruch, so durch die l\u00fcffte stiegen,", "tokens": ["Ein", "schall", "und", "wohl\u00b7ge\u00b7ruch", ",", "so", "durch", "die", "l\u00fcff\u00b7te", "stie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ADJD", "$,", "ADV", "APPR", "ART", "ADJA", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ergetzten ihren geist, und hemmten ihren flug,", "tokens": ["Er\u00b7getz\u00b7ten", "ih\u00b7ren", "geist", ",", "und", "hemm\u00b7ten", "ih\u00b7ren", "flug", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "$,", "KON", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Da\u00df sie sich allgemach in diese gegend wagte,", "tokens": ["Da\u00df", "sie", "sich", "all\u00b7ge\u00b7mach", "in", "die\u00b7se", "ge\u00b7gend", "wag\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ADV", "APPR", "PDAT", "VVPP", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und nach beschaffenheit desselben ortes fragte.", "tokens": ["Und", "nach", "be\u00b7schaf\u00b7fen\u00b7heit", "des\u00b7sel\u00b7ben", "or\u00b7tes", "frag\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "PDAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.17": {"line.1": {"text": "Man gab ihr den bericht: \u201cHier ist ein kleines land,", "tokens": ["Man", "gab", "ihr", "den", "be\u00b7richt", ":", "\u201c", "Hier", "ist", "ein", "klei\u00b7nes", "land", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "ART", "NN", "$.", "$(", "ADV", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.18": {"line.1": {"text": "Die liebe war erfreut, und w\u00fcnschte di\u00df dabey:", "tokens": ["Die", "lie\u00b7be", "war", "er\u00b7freut", ",", "und", "w\u00fcnschte", "di\u00df", "da\u00b7bey", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VAFIN", "ADJD", "$,", "KON", "VVFIN", "PDS", "PTKVZ", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.2": {"text": "\u201ces wachse dieses haus befreyt von leid und neide!", "tokens": ["\u201c", "es", "wach\u00b7se", "die\u00b7ses", "haus", "be\u00b7freyt", "von", "leid", "und", "nei\u00b7de", "!"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "PDAT", "NN", "VVPP", "APPR", "ADJD", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "\u201ewas aber, fragte sie, bedeutet diese freude?", "tokens": ["\u201e", "was", "a\u00b7ber", ",", "frag\u00b7te", "sie", ",", "be\u00b7deu\u00b7tet", "die\u00b7se", "freu\u00b7de", "?"], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "ADV", "$,", "VVFIN", "PPER", "$,", "VVFIN", "PDAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die antwort fiel darauf: Herr Wagner, dessen treu", "tokens": ["Die", "ant\u00b7wort", "fiel", "da\u00b7rauf", ":", "Herr", "Wag\u00b7ner", ",", "des\u00b7sen", "treu"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PAV", "$.", "NN", "NE", "$,", "PRELAT", "ADJD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Bey dieser herrschafft ihn zu einem Joseph setzet,", "tokens": ["Bey", "die\u00b7ser", "herr\u00b7schafft", "ihn", "zu", "ei\u00b7nem", "Jo\u00b7se\u00b7ph", "set\u00b7zet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "VVFIN", "PPER", "APPR", "ART", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "Wird heute diesen tag durch eine braut ergetzet.", "tokens": ["Wird", "heu\u00b7te", "die\u00b7sen", "tag", "durch", "ei\u00b7ne", "braut", "er\u00b7get\u00b7zet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PDAT", "NN", "APPR", "ART", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.19": {"line.1": {"text": "\u201cwohlan! versetzte sie, di\u00df ist, was mich vergn\u00fcgt;", "tokens": ["\u201c", "wo\u00b7hlan", "!", "ver\u00b7setz\u00b7te", "sie", ",", "di\u00df", "ist", ",", "was", "mich", "ver\u00b7gn\u00fcgt", ";"], "token_info": ["punct", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "$.", "VVFIN", "PPER", "$,", "PDS", "VAFIN", "$,", "PWS", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "\u201eapollo kennet ihn, und die ihm ist gewogen,", "tokens": ["\u201e", "a\u00b7pol\u00b7lo", "ken\u00b7net", "ihn", ",", "und", "die", "ihm", "ist", "ge\u00b7wo\u00b7gen", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "NE", "VVFIN", "PPER", "$,", "KON", "ART", "PPER", "VAFIN", "VVPP", "$,"], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.3": {"text": "\u201edie hat an meiner brust der tugend milch gesogen.", "tokens": ["\u201e", "die", "hat", "an", "mei\u00b7ner", "brust", "der", "tu\u00b7gend", "milch", "ge\u00b7so\u00b7gen", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PDS", "VAFIN", "APPR", "PPOSAT", "NN", "ART", "NN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Worauf sie alsobald sich in das schlo\u00df verf\u00fcgt:", "tokens": ["Wo\u00b7rauf", "sie", "al\u00b7so\u00b7bald", "sich", "in", "das", "schlo\u00df", "ver\u00b7f\u00fcgt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PPER", "ADV", "PRF", "APPR", "ART", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wo sie so wirth als gast mit holder anmuth k\u00fc\u00dfte,", "tokens": ["Wo", "sie", "so", "wirth", "als", "gast", "mit", "hol\u00b7der", "an\u00b7muth", "k\u00fc\u00df\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "ADJD", "KOKOM", "VVFIN", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und die verlobeten mit diesen worten gr\u00fc\u00dfte:", "tokens": ["Und", "die", "ver\u00b7lo\u00b7be\u00b7ten", "mit", "die\u00b7sen", "wor\u00b7ten", "gr\u00fc\u00df\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "APPR", "PDAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.20": {"line.1": {"text": "\u201cgl\u00fcck zu! dn edles paar! der himmel sey mit dir!", "tokens": ["\u201c", "gl\u00fcck", "zu", "!", "dn", "ed\u00b7les", "paar", "!", "der", "him\u00b7mel", "sey", "mit", "dir", "!"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVIMP", "PTKVZ", "$.", "ART", "ADJA", "NN", "$.", "ART", "NN", "VAFIN", "APPR", "PPER", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "\u201eder tag Felician verspricht dir lauter gl\u00fccke;", "tokens": ["\u201e", "der", "tag", "Fe\u00b7li\u00b7ci\u00b7an", "ver\u00b7spricht", "dir", "lau\u00b7ter", "gl\u00fc\u00b7cke", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "NE", "VVFIN", "PPER", "PIAT", "NN", "$."], "meter": "+-+--+-+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.3": {"text": "\u201ebegl\u00fccktes hochzeit-fest! begl\u00fcckte segens-blicke!", "tokens": ["\u201e", "be\u00b7gl\u00fcck\u00b7tes", "hoch\u00b7zeit\u00b7fest", "!", "be\u00b7gl\u00fcck\u00b7te", "se\u00b7gens\u00b7bli\u00b7cke", "!"], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "ADJA", "NN", "$.", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "\u201edie liebe selbsten kommt hier als ein gast zu dir:", "tokens": ["\u201e", "die", "lie\u00b7be", "selbs\u00b7ten", "kommt", "hier", "als", "ein", "gast", "zu", "dir", ":"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "ADJA", "ADJA", "VVFIN", "ADV", "KOUS", "ART", "ADV", "APPR", "PPER", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "\u201evergn\u00fcgung ist dein wirth: Was wilst du weiter sagen,", "tokens": ["\u201e", "ver\u00b7gn\u00fc\u00b7gung", "ist", "dein", "wirth", ":", "Was", "wilst", "du", "wei\u00b7ter", "sa\u00b7gen", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "VAFIN", "PPOSAT", "ADJD", "$.", "PWS", "VMFIN", "PPER", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "\u201ewenn gl\u00fcck und liebe dich ins hochzeit-bette tragen?", "tokens": ["\u201e", "wenn", "gl\u00fcck", "und", "lie\u00b7be", "dich", "ins", "hoch\u00b7zeit\u00b7bet\u00b7te", "tra\u00b7gen", "?"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "NN", "KON", "VVFIN", "PPER", "APPRART", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.21": {"line.1": {"text": "\u201cerfreuter br\u00e4utigam! sey du Felician!", "tokens": ["\u201c", "er\u00b7freu\u00b7ter", "br\u00e4u\u00b7ti\u00b7gam", "!", "sey", "du", "Fe\u00b7li\u00b7ci\u00b7an", "!"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "VVFIN", "$.", "VAFIN", "PPER", "NE", "$."], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "\u201eund sie Felicitas, die dich ans hertze schliesset!", "tokens": ["\u201e", "und", "sie", "Fe\u00b7li\u00b7ci\u00b7tas", ",", "die", "dich", "ans", "hert\u00b7ze", "schlies\u00b7set", "!"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KON", "PPER", "NN", "$,", "PRELS", "PRF", "APPRART", "NN", "VVFIN", "$."], "meter": "--+--+-+-+-+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "\u201eauf! liebet, \u00fcbet euch! auf! k\u00fcsset und geniesset!", "tokens": ["\u201e", "auf", "!", "lie\u00b7bet", ",", "\u00fc\u00b7bet", "euch", "!", "auf", "!", "k\u00fcs\u00b7set", "und", "ge\u00b7nies\u00b7set", "!"], "token_info": ["punct", "word", "punct", "word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PTKVZ", "$.", "VVFIN", "$,", "VVFIN", "PPER", "$.", "PTKVZ", "$.", "VVFIN", "KON", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "\u201eich aber schreibe di\u00df in eurer kammer an:", "tokens": ["\u201e", "ich", "a\u00b7ber", "schrei\u00b7be", "di\u00df", "in", "eu\u00b7rer", "kam\u00b7mer", "an", ":"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "ADV", "VVFIN", "PDS", "APPR", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "\u201ehier hat die treue sich mit reiner gunst verbunden!", "tokens": ["\u201e", "hier", "hat", "die", "treu\u00b7e", "sich", "mit", "rei\u00b7ner", "gunst", "ver\u00b7bun\u00b7den", "!"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VAFIN", "ART", "ADJA", "PRF", "APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "\u201eund als sie di\u00df gethan, so war sie auch verschwunden.", "tokens": ["\u201e", "und", "als", "sie", "di\u00df", "ge\u00b7than", ",", "so", "war", "sie", "auch", "ver\u00b7schwun\u00b7den", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KON", "KOUS", "PPER", "PDS", "VVPP", "$,", "ADV", "VAFIN", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}