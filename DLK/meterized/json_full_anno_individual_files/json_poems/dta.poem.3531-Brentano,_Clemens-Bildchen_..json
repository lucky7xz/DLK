{"dta.poem.3531": {"metadata": {"author": {"name": "Brentano, Clemens", "birth": "N.A.", "death": "N.A."}, "title": "Bildchen .", "genre": "Lyrik", "period": "N.A.", "pub_year": "1808", "urn": "urn:nbn:de:kobv:b4-20090519172", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Auf dieser Welt hab ich keine Freud,               ", "tokens": ["Auf", "die\u00b7ser", "Welt", "hab", "ich", "kei\u00b7ne", "Freud", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "VAFIN", "PPER", "PIAT", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Ich hab einen Schatz und der ist weit,", "tokens": ["Ich", "hab", "ei\u00b7nen", "Schatz", "und", "der", "ist", "weit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "KON", "ART", "VAFIN", "ADJD", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Er ist so weit, er ist nicht hier,", "tokens": ["Er", "ist", "so", "weit", ",", "er", "ist", "nicht", "hier", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "$,", "PPER", "VAFIN", "PTKNEG", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ach wenn ich bei mein Sch\u00e4tzgen w\u00e4r!", "tokens": ["Ach", "wenn", "ich", "bei", "mein", "Sch\u00e4tz\u00b7gen", "w\u00e4r", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "KOUS", "PPER", "APPR", "PPOSAT", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Ich kann nicht sitzen und kann nicht stehn,", "tokens": ["Ich", "kann", "nicht", "sit\u00b7zen", "und", "kann", "nicht", "stehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PTKNEG", "VVINF", "KON", "VMFIN", "PTKNEG", "VVINF", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Ich mu\u00df zu meinem Sch\u00e4tzgen gehn;", "tokens": ["Ich", "mu\u00df", "zu", "mei\u00b7nem", "Sch\u00e4tz\u00b7gen", "gehn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Zu meinem Schatz, da mu\u00df ich gehn,", "tokens": ["Zu", "mei\u00b7nem", "Schatz", ",", "da", "mu\u00df", "ich", "gehn", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "ADV", "VMFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und sollt ich vor dem Fenster stehn.", "tokens": ["Und", "sollt", "ich", "vor", "dem", "Fens\u00b7ter", "stehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Wer ist denn draussen, wer klopfet an?", "tokens": ["Wer", "ist", "denn", "draus\u00b7sen", ",", "wer", "klop\u00b7fet", "an", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ADV", "VVINF", "$,", "PWS", "VVFIN", "PTKVZ", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Der mich so leis aufwecken kann;", "tokens": ["Der", "mich", "so", "leis", "auf\u00b7we\u00b7cken", "kann", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "ADJD", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Es ist der Herzallerliebster dein,", "tokens": ["Es", "ist", "der", "Her\u00b7zal\u00b7ler\u00b7liebs\u00b7ter", "dein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "PPOSAT", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Steh auf, steh auf und la\u00df mich rein!", "tokens": ["Steh", "auf", ",", "steh", "auf", "und", "la\u00df", "mich", "rein", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "$,", "VVFIN", "PTKVZ", "KON", "VVIMP", "PPER", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Ich steh nicht auf, la\u00df dich nicht rein,", "tokens": ["Ich", "steh", "nicht", "auf", ",", "la\u00df", "dich", "nicht", "rein", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "PTKVZ", "$,", "VVIMP", "PPER", "PTKNEG", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Bis meine Eltern zu Bette seyn;", "tokens": ["Bis", "mei\u00b7ne", "El\u00b7tern", "zu", "Bet\u00b7te", "seyn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "APPR", "NN", "VAINF", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Wenn meine Eltern zu Bette seyn,", "tokens": ["Wenn", "mei\u00b7ne", "El\u00b7tern", "zu", "Bet\u00b7te", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "APPR", "NN", "VAINF", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "So steh ich auf und la\u00df dich rein.", "tokens": ["So", "steh", "ich", "auf", "und", "la\u00df", "dich", "rein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PTKVZ", "KON", "VVIMP", "PPER", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Was soll ich hier nun l\u00e4nger stehn,", "tokens": ["Was", "soll", "ich", "hier", "nun", "l\u00e4n\u00b7ger", "stehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PPER", "ADV", "ADV", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ich seh die Morgenr\u00f6th aufgehn;", "tokens": ["Ich", "seh", "die", "Mor\u00b7gen\u00b7r\u00f6th", "auf\u00b7gehn", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die Morgenr\u00f6th, zwey helle Stern,", "tokens": ["Die", "Mor\u00b7gen\u00b7r\u00f6th", ",", "zwey", "hel\u00b7le", "Stern", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "CARD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Bey meinem Schatz, da w\u00e4r ich gern.", "tokens": ["Bey", "mei\u00b7nem", "Schatz", ",", "da", "w\u00e4r", "ich", "gern", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "ADV", "VAFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Da stand sie auf und lie\u00df ihn ein,", "tokens": ["Da", "stand", "sie", "auf", "und", "lie\u00df", "ihn", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PTKVZ", "KON", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sie hei\u00dft ihn auch willkommen seyn;", "tokens": ["Sie", "hei\u00dft", "ihn", "auch", "will\u00b7kom\u00b7men", "seyn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sie reicht ihm die schneewei\u00dfe Hand,", "tokens": ["Sie", "reicht", "ihm", "die", "schnee\u00b7wei\u00b7\u00dfe", "Hand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Da f\u00e4ngt sie auch zu weinen an.", "tokens": ["Da", "f\u00e4ngt", "sie", "auch", "zu", "wei\u00b7nen", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "PTKZU", "VVINF", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Wein nicht, wein nicht mein Engelein!", "tokens": ["Wein", "nicht", ",", "wein", "nicht", "mein", "En\u00b7ge\u00b7lein", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKNEG", "$,", "PWAV", "PTKNEG", "PPOSAT", "NN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.2": {"text": "Aufs Jahr sollst du mein eigen seyn;", "tokens": ["Aufs", "Jahr", "sollst", "du", "mein", "ei\u00b7gen", "seyn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VMFIN", "PPER", "PPOSAT", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mein eigen sollst du werden gewi\u00df,", "tokens": ["Mein", "ei\u00b7gen", "sollst", "du", "wer\u00b7den", "ge\u00b7wi\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VMFIN", "PPER", "VAFIN", "ADV", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Sonst keine es auf Erden ist.", "tokens": ["Sonst", "kei\u00b7ne", "es", "auf", "Er\u00b7den", "ist", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "PPER", "APPR", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Ich zieh in Krieg auf gr\u00fcne Haid,", "tokens": ["Ich", "zieh", "in", "Krieg", "auf", "gr\u00fc\u00b7ne", "Haid", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Gr\u00fcne Haid die liegt von hier so weit,", "tokens": ["Gr\u00fc\u00b7ne", "Haid", "die", "liegt", "von", "hier", "so", "weit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ART", "VVFIN", "APPR", "ADV", "ADV", "ADJD", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Allwo die sch\u00f6nen Trompeten blasen;", "tokens": ["All\u00b7wo", "die", "sch\u00f6\u00b7nen", "Trom\u00b7pe\u00b7ten", "bla\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}, "line.4": {"text": "Da ist mein Haus von gr\u00fcnem Rasen.", "tokens": ["Da", "ist", "mein", "Haus", "von", "gr\u00fc\u00b7nem", "Ra\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPOSAT", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Ein Bildchen la\u00df ich mahlen mir,", "tokens": ["Ein", "Bild\u00b7chen", "la\u00df", "ich", "mah\u00b7len", "mir", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVIMP", "PPER", "VVFIN", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Auf meinem Herzen trag ichs hier;", "tokens": ["Auf", "mei\u00b7nem", "Her\u00b7zen", "trag", "ichs", "hier", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "PIS", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Darauf sollst du gemahlet seyn,", "tokens": ["Da\u00b7rauf", "sollst", "du", "ge\u00b7mah\u00b7let", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VMFIN", "PPER", "VVPP", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Da\u00df ich niemal vergesse dein.", "tokens": ["Da\u00df", "ich", "nie\u00b7mal", "ver\u00b7ges\u00b7se", "dein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VVFIN", "PPOSAT", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}}}}}