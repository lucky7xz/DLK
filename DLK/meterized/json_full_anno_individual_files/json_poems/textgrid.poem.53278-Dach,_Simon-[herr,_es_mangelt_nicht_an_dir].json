{"textgrid.poem.53278": {"metadata": {"author": {"name": "Dach, Simon", "birth": "N.A.", "death": "N.A."}, "title": "[herr, es mangelt nicht an dir]", "genre": "verse", "period": "N.A.", "pub_year": 1632, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Herr, es mangelt nicht an dir,", "tokens": ["Herr", ",", "es", "man\u00b7gelt", "nicht", "an", "dir", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PPER", "VVFIN", "PTKNEG", "APPR", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "T\u00e4glich schickstu zu vns Bohten,", "tokens": ["T\u00e4g\u00b7lich", "schicks\u00b7tu", "zu", "vns", "Boh\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "APPR", "PPER", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Klopffst an vnsrer Hertzen Th\u00fcr", "tokens": ["Klopffst", "an", "vns\u00b7rer", "Hert\u00b7zen", "Th\u00fcr"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "PPOSAT", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Durch die grosse Zahl der Todten:", "tokens": ["Durch", "die", "gros\u00b7se", "Zahl", "der", "Tod\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "T\u00e4glich senckt man Leichen ein", "tokens": ["T\u00e4g\u00b7lich", "senckt", "man", "Lei\u00b7chen", "ein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADJD", "VVFIN", "PIS", "NN", "ART"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Die vns heissen wache seyn.", "tokens": ["Die", "vns", "heis\u00b7sen", "wa\u00b7che", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVFIN", "ADJA", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Wie, wenn eine Wolcke treufft,", "tokens": ["Wie", ",", "wenn", "ei\u00b7ne", "Wol\u00b7cke", "treufft", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$,", "KOUS", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Es nicht gro\u00df gemerckt kan werden,", "tokens": ["Es", "nicht", "gro\u00df", "ge\u00b7merckt", "kan", "wer\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKNEG", "ADJD", "VVPP", "VMFIN", "VAINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df das Wasser sich verschl\u00e4ufft", "tokens": ["Da\u00df", "das", "Was\u00b7ser", "sich", "ver\u00b7schl\u00e4ufft"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "PRF", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "In den d\u00fcrren Schohs der Erden:", "tokens": ["In", "den", "d\u00fcr\u00b7ren", "Schohs", "der", "Er\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Also schluckt das weite Grab", "tokens": ["Al\u00b7so", "schluckt", "das", "wei\u00b7te", "Grab"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Vns, sein Mast-Vieh, stets hinab.", "tokens": ["Vns", ",", "sein", "Mast\u00b7Vieh", ",", "stets", "hin\u00b7ab", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "$,", "PPOSAT", "NN", "$,", "ADV", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "L\u00e4ssest Du nicht fort vnd fort", "tokens": ["L\u00e4s\u00b7sest", "Du", "nicht", "fort", "vnd", "fort"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "PTKNEG", "PTKVZ", "KON", "PTKVZ"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Vns Begr\u00e4bnis-Lieder singen?", "tokens": ["Vns", "Be\u00b7gr\u00e4b\u00b7nis\u00b7Lie\u00b7der", "sin\u00b7gen", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Machst, da\u00df t\u00e4glich hie vnd dort", "tokens": ["Machst", ",", "da\u00df", "t\u00e4g\u00b7lich", "hie", "vnd", "dort"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "$,", "KOUS", "ADJD", "ADV", "KON", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Trawrig alle Glocken klingen?", "tokens": ["Traw\u00b7rig", "al\u00b7le", "Glo\u00b7cken", "klin\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "PIAT", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Nur da\u00df ja ein jeder wol", "tokens": ["Nur", "da\u00df", "ja", "ein", "je\u00b7der", "wol"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "KOUS", "ADV", "ART", "PIS", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "An sein Ende dencken sol.", "tokens": ["An", "sein", "En\u00b7de", "den\u00b7cken", "sol", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Selig ist, der sich von hier", "tokens": ["Se\u00b7lig", "ist", ",", "der", "sich", "von", "hier"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "VAFIN", "$,", "PRELS", "PRF", "APPR", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Kan bey zeiten zu Dir wenden,", "tokens": ["Kan", "bey", "zei\u00b7ten", "zu", "Dir", "wen\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "APPR", "NN", "APPR", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Vnd nimbt seinen Tod von Dir", "tokens": ["Vnd", "nimbt", "sei\u00b7nen", "Tod", "von", "Dir"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "APPR", "PPER"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wie mit au\u00dfgestreckten H\u00e4nden,", "tokens": ["Wie", "mit", "au\u00df\u00b7ge\u00b7streck\u00b7ten", "H\u00e4n\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Nicht sich an der Welt vergafft,", "tokens": ["Nicht", "sich", "an", "der", "Welt", "ver\u00b7gafft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "PRF", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Vnd wird pl\u00f6tzlich hingerafft!", "tokens": ["Vnd", "wird", "pl\u00f6tz\u00b7lich", "hin\u00b7ge\u00b7rafft", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADJD", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Bring, Herr, vnsern Sinnen bey,", "tokens": ["Bring", ",", "Herr", ",", "vn\u00b7sern", "Sin\u00b7nen", "bey", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "NN", "$,", "KON", "NN", "PTKVZ", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Da\u00df sie kennen dieses Leben,", "tokens": ["Da\u00df", "sie", "ken\u00b7nen", "die\u00b7ses", "Le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "PDAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wie es gantz so eitel sey,", "tokens": ["Wie", "es", "gantz", "so", "ei\u00b7tel", "sey", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "ADV", "ADJD", "VAFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Vnd in jenes sich erheben,", "tokens": ["Vnd", "in", "je\u00b7nes", "sich", "er\u00b7he\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PDAT", "PRF", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Da kein Tod, kein Leid noch Pein", "tokens": ["Da", "kein", "Tod", ",", "kein", "Leid", "noch", "Pein"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "PIAT", "NN", "$,", "PIAT", "NN", "ADV", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Ewig wird zu finden seyn!", "tokens": ["E\u00b7wig", "wird", "zu", "fin\u00b7den", "seyn", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "PTKZU", "VVINF", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Herr, es mangelt nicht an dir,", "tokens": ["Herr", ",", "es", "man\u00b7gelt", "nicht", "an", "dir", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PPER", "VVFIN", "PTKNEG", "APPR", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "T\u00e4glich schickstu zu vns Bohten,", "tokens": ["T\u00e4g\u00b7lich", "schicks\u00b7tu", "zu", "vns", "Boh\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "APPR", "PPER", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Klopffst an vnsrer Hertzen Th\u00fcr", "tokens": ["Klopffst", "an", "vns\u00b7rer", "Hert\u00b7zen", "Th\u00fcr"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "PPOSAT", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Durch die grosse Zahl der Todten:", "tokens": ["Durch", "die", "gros\u00b7se", "Zahl", "der", "Tod\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "T\u00e4glich senckt man Leichen ein", "tokens": ["T\u00e4g\u00b7lich", "senckt", "man", "Lei\u00b7chen", "ein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADJD", "VVFIN", "PIS", "NN", "ART"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Die vns heissen wache seyn.", "tokens": ["Die", "vns", "heis\u00b7sen", "wa\u00b7che", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVFIN", "ADJA", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Wie, wenn eine Wolcke treufft,", "tokens": ["Wie", ",", "wenn", "ei\u00b7ne", "Wol\u00b7cke", "treufft", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$,", "KOUS", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Es nicht gro\u00df gemerckt kan werden,", "tokens": ["Es", "nicht", "gro\u00df", "ge\u00b7merckt", "kan", "wer\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKNEG", "ADJD", "VVPP", "VMFIN", "VAINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df das Wasser sich verschl\u00e4ufft", "tokens": ["Da\u00df", "das", "Was\u00b7ser", "sich", "ver\u00b7schl\u00e4ufft"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "PRF", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "In den d\u00fcrren Schohs der Erden:", "tokens": ["In", "den", "d\u00fcr\u00b7ren", "Schohs", "der", "Er\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Also schluckt das weite Grab", "tokens": ["Al\u00b7so", "schluckt", "das", "wei\u00b7te", "Grab"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Vns, sein Mast-Vieh, stets hinab.", "tokens": ["Vns", ",", "sein", "Mast\u00b7Vieh", ",", "stets", "hin\u00b7ab", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "$,", "PPOSAT", "NN", "$,", "ADV", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "L\u00e4ssest Du nicht fort vnd fort", "tokens": ["L\u00e4s\u00b7sest", "Du", "nicht", "fort", "vnd", "fort"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "PTKNEG", "PTKVZ", "KON", "PTKVZ"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Vns Begr\u00e4bnis-Lieder singen?", "tokens": ["Vns", "Be\u00b7gr\u00e4b\u00b7nis\u00b7Lie\u00b7der", "sin\u00b7gen", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Machst, da\u00df t\u00e4glich hie vnd dort", "tokens": ["Machst", ",", "da\u00df", "t\u00e4g\u00b7lich", "hie", "vnd", "dort"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "$,", "KOUS", "ADJD", "ADV", "KON", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Trawrig alle Glocken klingen?", "tokens": ["Traw\u00b7rig", "al\u00b7le", "Glo\u00b7cken", "klin\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "PIAT", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Nur da\u00df ja ein jeder wol", "tokens": ["Nur", "da\u00df", "ja", "ein", "je\u00b7der", "wol"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "KOUS", "ADV", "ART", "PIS", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "An sein Ende dencken sol.", "tokens": ["An", "sein", "En\u00b7de", "den\u00b7cken", "sol", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Selig ist, der sich von hier", "tokens": ["Se\u00b7lig", "ist", ",", "der", "sich", "von", "hier"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "VAFIN", "$,", "PRELS", "PRF", "APPR", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Kan bey zeiten zu Dir wenden,", "tokens": ["Kan", "bey", "zei\u00b7ten", "zu", "Dir", "wen\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "APPR", "NN", "APPR", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Vnd nimbt seinen Tod von Dir", "tokens": ["Vnd", "nimbt", "sei\u00b7nen", "Tod", "von", "Dir"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "APPR", "PPER"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wie mit au\u00dfgestreckten H\u00e4nden,", "tokens": ["Wie", "mit", "au\u00df\u00b7ge\u00b7streck\u00b7ten", "H\u00e4n\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Nicht sich an der Welt vergafft,", "tokens": ["Nicht", "sich", "an", "der", "Welt", "ver\u00b7gafft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "PRF", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Vnd wird pl\u00f6tzlich hingerafft!", "tokens": ["Vnd", "wird", "pl\u00f6tz\u00b7lich", "hin\u00b7ge\u00b7rafft", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADJD", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Bring, Herr, vnsern Sinnen bey,", "tokens": ["Bring", ",", "Herr", ",", "vn\u00b7sern", "Sin\u00b7nen", "bey", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "NN", "$,", "KON", "NN", "PTKVZ", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Da\u00df sie kennen dieses Leben,", "tokens": ["Da\u00df", "sie", "ken\u00b7nen", "die\u00b7ses", "Le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "PDAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wie es gantz so eitel sey,", "tokens": ["Wie", "es", "gantz", "so", "ei\u00b7tel", "sey", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "ADV", "ADJD", "VAFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Vnd in jenes sich erheben,", "tokens": ["Vnd", "in", "je\u00b7nes", "sich", "er\u00b7he\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PDAT", "PRF", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Da kein Tod, kein Leid noch Pein", "tokens": ["Da", "kein", "Tod", ",", "kein", "Leid", "noch", "Pein"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "PIAT", "NN", "$,", "PIAT", "NN", "ADV", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Ewig wird zu finden seyn!", "tokens": ["E\u00b7wig", "wird", "zu", "fin\u00b7den", "seyn", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "PTKZU", "VVINF", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}