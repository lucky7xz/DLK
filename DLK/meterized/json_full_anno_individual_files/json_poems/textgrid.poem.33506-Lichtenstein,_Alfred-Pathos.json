{"textgrid.poem.33506": {"metadata": {"author": {"name": "Lichtenstein, Alfred", "birth": "N.A.", "death": "N.A."}, "title": "Pathos", "genre": "verse", "period": "N.A.", "pub_year": 1911, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Du liebst mich nicht ... Ich hab dich nie gereizt ...", "tokens": ["Du", "liebst", "mich", "nicht", "...", "Ich", "hab", "dich", "nie", "ge\u00b7reizt", "..."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKNEG", "$(", "PPER", "VAFIN", "PPER", "ADV", "ADJD", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "War nie dein Typ ...", "tokens": ["War", "nie", "dein", "Typ", "..."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PPOSAT", "NN", "$("], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "Und meine harten Augen sind dir l\u00e4stig, Liebchen ...", "tokens": ["Und", "mei\u00b7ne", "har\u00b7ten", "Au\u00b7gen", "sind", "dir", "l\u00e4s\u00b7tig", ",", "Lieb\u00b7chen", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "VAFIN", "PPER", "ADJD", "$,", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ich bin dir viel zu finster. Und zu grob \u2013", "tokens": ["Ich", "bin", "dir", "viel", "zu", "fins\u00b7ter", ".", "Und", "zu", "grob", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "PTKA", "ADJD", "$.", "KON", "PTKA", "ADJD", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Und meine wei\u00dfen Z\u00e4hne blitzen so brutal", "tokens": ["Und", "mei\u00b7ne", "wei\u00b7\u00dfen", "Z\u00e4h\u00b7ne", "blit\u00b7zen", "so", "bru\u00b7tal"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "VVFIN", "ADV", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und meine blutgen Lippen sind so schrecklich sichlich.", "tokens": ["Und", "mei\u00b7ne", "blut\u00b7gen", "Lip\u00b7pen", "sind", "so", "schreck\u00b7lich", "sich\u00b7lich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "VAFIN", "ADV", "ADJD", "ADJD", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Ach, was du sagst \u2013 \u2013", "tokens": ["Ach", ",", "was", "du", "sagst", "\u2013", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["ITJ", "$,", "PWS", "PPER", "VVFIN", "$(", "$("], "meter": "-+-+", "measure": "iambic.di"}, "line.8": {"text": "Doch, du hast wirklich recht. Ich geb dich ... frei.", "tokens": ["Doch", ",", "du", "hast", "wirk\u00b7lich", "recht", ".", "Ich", "geb", "dich", "...", "frei", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "$,", "PPER", "VAFIN", "ADJD", "ADJD", "$.", "PPER", "VVFIN", "PPER", "$(", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "... Und morgen in der Fr\u00fch fahr ich zu einem Meer,", "tokens": ["...", "Und", "mor\u00b7gen", "in", "der", "Fr\u00fch", "fahr", "ich", "zu", "ei\u00b7nem", "Meer", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KON", "ADV", "APPR", "ART", "NN", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Das blau und ewig ist ...", "tokens": ["Das", "blau", "und", "e\u00b7wig", "ist", "..."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADJD", "KON", "ADJD", "VAFIN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.11": {"text": "Und liege da am Strand ...", "tokens": ["Und", "lie\u00b7ge", "da", "am", "Strand", "..."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "APPRART", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.12": {"text": "Und spiele l\u00e4chelnd, bis ein Tod mich greift,", "tokens": ["Und", "spie\u00b7le", "l\u00e4\u00b7chelnd", ",", "bis", "ein", "Tod", "mich", "greift", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "$,", "KOUS", "ART", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "Mit Sand und Sonne und mit einer wei\u00dfen", "tokens": ["Mit", "Sand", "und", "Son\u00b7ne", "und", "mit", "ei\u00b7ner", "wei\u00b7\u00dfen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN", "KON", "APPR", "ART", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.14": {"text": "Schlanken H\u00fcndin.", "tokens": ["Schlan\u00b7ken", "H\u00fcn\u00b7din", "."], "token_info": ["word", "word", "punct"], "pos": ["NN", "NN", "$."], "meter": "+-+-", "measure": "trochaic.di"}}, "stanza.2": {"line.1": {"text": "Du liebst mich nicht ... Ich hab dich nie gereizt ...", "tokens": ["Du", "liebst", "mich", "nicht", "...", "Ich", "hab", "dich", "nie", "ge\u00b7reizt", "..."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKNEG", "$(", "PPER", "VAFIN", "PPER", "ADV", "ADJD", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "War nie dein Typ ...", "tokens": ["War", "nie", "dein", "Typ", "..."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PPOSAT", "NN", "$("], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "Und meine harten Augen sind dir l\u00e4stig, Liebchen ...", "tokens": ["Und", "mei\u00b7ne", "har\u00b7ten", "Au\u00b7gen", "sind", "dir", "l\u00e4s\u00b7tig", ",", "Lieb\u00b7chen", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "VAFIN", "PPER", "ADJD", "$,", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ich bin dir viel zu finster. Und zu grob \u2013", "tokens": ["Ich", "bin", "dir", "viel", "zu", "fins\u00b7ter", ".", "Und", "zu", "grob", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "PTKA", "ADJD", "$.", "KON", "PTKA", "ADJD", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Und meine wei\u00dfen Z\u00e4hne blitzen so brutal", "tokens": ["Und", "mei\u00b7ne", "wei\u00b7\u00dfen", "Z\u00e4h\u00b7ne", "blit\u00b7zen", "so", "bru\u00b7tal"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "VVFIN", "ADV", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und meine blutgen Lippen sind so schrecklich sichlich.", "tokens": ["Und", "mei\u00b7ne", "blut\u00b7gen", "Lip\u00b7pen", "sind", "so", "schreck\u00b7lich", "sich\u00b7lich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "VAFIN", "ADV", "ADJD", "ADJD", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Ach, was du sagst \u2013 \u2013", "tokens": ["Ach", ",", "was", "du", "sagst", "\u2013", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["ITJ", "$,", "PWS", "PPER", "VVFIN", "$(", "$("], "meter": "-+-+", "measure": "iambic.di"}, "line.8": {"text": "Doch, du hast wirklich recht. Ich geb dich ... frei.", "tokens": ["Doch", ",", "du", "hast", "wirk\u00b7lich", "recht", ".", "Ich", "geb", "dich", "...", "frei", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "$,", "PPER", "VAFIN", "ADJD", "ADJD", "$.", "PPER", "VVFIN", "PPER", "$(", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "... Und morgen in der Fr\u00fch fahr ich zu einem Meer,", "tokens": ["...", "Und", "mor\u00b7gen", "in", "der", "Fr\u00fch", "fahr", "ich", "zu", "ei\u00b7nem", "Meer", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KON", "ADV", "APPR", "ART", "NN", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Das blau und ewig ist ...", "tokens": ["Das", "blau", "und", "e\u00b7wig", "ist", "..."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADJD", "KON", "ADJD", "VAFIN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.11": {"text": "Und liege da am Strand ...", "tokens": ["Und", "lie\u00b7ge", "da", "am", "Strand", "..."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "APPRART", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.12": {"text": "Und spiele l\u00e4chelnd, bis ein Tod mich greift,", "tokens": ["Und", "spie\u00b7le", "l\u00e4\u00b7chelnd", ",", "bis", "ein", "Tod", "mich", "greift", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "$,", "KOUS", "ART", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "Mit Sand und Sonne und mit einer wei\u00dfen", "tokens": ["Mit", "Sand", "und", "Son\u00b7ne", "und", "mit", "ei\u00b7ner", "wei\u00b7\u00dfen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN", "KON", "APPR", "ART", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.14": {"text": "Schlanken H\u00fcndin.", "tokens": ["Schlan\u00b7ken", "H\u00fcn\u00b7din", "."], "token_info": ["word", "word", "punct"], "pos": ["NN", "NN", "$."], "meter": "+-+-", "measure": "trochaic.di"}}}}}