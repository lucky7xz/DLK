{"dta.poem.21293": {"metadata": {"author": {"name": "Hagedorn, Friedrich von", "birth": "N.A.", "death": "N.A."}, "title": "Xv.  \n  Leichen-Carmen.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1752", "urn": "urn:nbn:de:kobv:b4-200905199117", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Herr Jost ist todt, der reiche Mann:", "tokens": ["Herr", "Jost", "ist", "todt", ",", "der", "rei\u00b7che", "Mann", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "NE", "VAFIN", "ADJD", "$,", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "W\u00e4r er nicht reich gewesen;", "tokens": ["W\u00e4r", "er", "nicht", "reich", "ge\u00b7we\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PTKNEG", "ADJD", "VAPP", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.3": {"text": "Wir w\u00fcrden, falls ich rathen kann,", "tokens": ["Wir", "w\u00fcr\u00b7den", ",", "falls", "ich", "ra\u00b7then", "kann", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "KOUS", "PPER", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Auf Jhn kein Carmen lesen.", "tokens": ["Auf", "Jhn", "kein", "Car\u00b7men", "le\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Sein hocherleuchteter Papa", "tokens": ["Sein", "ho\u00b7cher\u00b7leuch\u00b7te\u00b7ter", "Pa\u00b7pa"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Pflag Jhn oft selbst zu wiegen;", "tokens": ["Pflag", "Jhn", "oft", "selbst", "zu", "wie\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ADV", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Die tugendvolle Frau Mama", "tokens": ["Die", "tu\u00b7gend\u00b7vol\u00b7le", "Frau", "Ma\u00b7ma"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Erzog Jhn mit Vergn\u00fcgen.", "tokens": ["Er\u00b7zog", "Jhn", "mit", "Ver\u00b7gn\u00fc\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Er war ein rechter Springinsfeld", "tokens": ["Er", "war", "ein", "rech\u00b7ter", "Sprin\u00b7gins\u00b7feld"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Jm ersten bunten Kleide,", "tokens": ["Jm", "ers\u00b7ten", "bun\u00b7ten", "Klei\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und ward daher der jungen Welt", "tokens": ["Und", "ward", "da\u00b7her", "der", "jun\u00b7gen", "Welt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "PAV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und auch der Muhmen Freude.", "tokens": ["Und", "auch", "der", "Muh\u00b7men", "Freu\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Nur sieben Jahre war Er alt,", "tokens": ["Nur", "sie\u00b7ben", "Jah\u00b7re", "war", "Er", "alt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "CARD", "NN", "VAFIN", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Da wusst Er fast zu lesen;", "tokens": ["Da", "wusst", "Er", "fast", "zu", "le\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Und hieraus sieht ein jeder bald,", "tokens": ["Und", "hier\u00b7aus", "sieht", "ein", "je\u00b7der", "bald", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PAV", "VVFIN", "ART", "PIS", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Wie klug das Kind gewesen.", "tokens": ["Wie", "klug", "das", "Kind", "ge\u00b7we\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "ART", "NN", "VAPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Man hielte Seiner Jugend zart", "tokens": ["Man", "hiel\u00b7te", "Sei\u00b7ner", "Ju\u00b7gend", "zart"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "PPOSAT", "NN", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wohl zehn Informatores;", "tokens": ["Wohl", "zehn", "In\u00b7for\u00b7ma\u00b7to\u00b7res", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "CARD", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Die lehrten Jhn, nach mancher Art,", "tokens": ["Die", "lehr\u00b7ten", "Jhn", ",", "nach", "man\u00b7cher", "Art", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "$,", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Sprachen und die Mores.", "tokens": ["Die", "Spra\u00b7chen", "und", "die", "Mo\u00b7res", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Es lernte Jost ohn Unterla\u00df,", "tokens": ["Es", "lern\u00b7te", "Jost", "ohn", "Un\u00b7ter\u00b7la\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Da\u00df Jhm der Kopf fast rauchte:", "tokens": ["Da\u00df", "Jhm", "der", "Kopf", "fast", "rauch\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Kein Mutter-Kind studirte ba\u00df", "tokens": ["Kein", "Mut\u00b7ter\u00b7Kind", "stu\u00b7dir\u00b7te", "ba\u00df"], "token_info": ["word", "word", "word", "word"], "pos": ["PIAT", "NN", "VVFIN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Was es zu wissen brauchte.", "tokens": ["Was", "es", "zu", "wis\u00b7sen", "brauch\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Da eilt Er mit der jungen Magd", "tokens": ["Da", "eilt", "Er", "mit", "der", "jun\u00b7gen", "Magd"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "In manche Classen eben,", "tokens": ["In", "man\u00b7che", "Clas\u00b7sen", "e\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "ADV", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und f\u00fchrte, mit ihr, unverzagt,", "tokens": ["Und", "f\u00fchr\u00b7te", ",", "mit", "ihr", ",", "un\u00b7ver\u00b7zagt", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "APPR", "PPER", "$,", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ein exemplarisch Leben.", "tokens": ["Ein", "ex\u00b7emp\u00b7la\u00b7risch", "Le\u00b7ben", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Er glich dem edlen Garten-Klee,", "tokens": ["Er", "glich", "dem", "ed\u00b7len", "Gar\u00b7ten\u00b7Klee", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Der zeitig aufw\u00e4rts steiget,", "tokens": ["Der", "zei\u00b7tig", "auf\u00b7w\u00e4rts", "stei\u00b7get", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Und nicht der tr\u00e4gen Aloe,", "tokens": ["Und", "nicht", "der", "tr\u00e4\u00b7gen", "A\u00b7loe", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "ART", "ADJA", "NN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.8": {"text": "Die sp\u00e4te Bl\u00fchten zeiget.", "tokens": ["Die", "sp\u00e4\u00b7te", "Bl\u00fch\u00b7ten", "zei\u00b7get", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Doch, weil Er viel zu sinnreich war,", "tokens": ["Doch", ",", "weil", "Er", "viel", "zu", "sinn\u00b7reich", "war", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "PPER", "ADV", "PTKA", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Um nur gelehrt zu werden;", "tokens": ["Um", "nur", "ge\u00b7lehrt", "zu", "wer\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "ADV", "VVPP", "PTKZU", "VAINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "So ri\u00df Jhn bald der Eltern Paar", "tokens": ["So", "ri\u00df", "Jhn", "bald", "der", "El\u00b7tern", "Paar"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Aus allen Schul-Beschwerden.", "tokens": ["Aus", "al\u00b7len", "Schul\u00b7Be\u00b7schwer\u00b7den", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Sie sagten: Sohn! Seyd unser Trost!", "tokens": ["Sie", "sag\u00b7ten", ":", "Sohn", "!", "Seyd", "un\u00b7ser", "Trost", "!"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "NN", "$.", "VAIMP", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Vermehrt, was wir erworben!", "tokens": ["Ver\u00b7mehrt", ",", "was", "wir", "er\u00b7wor\u00b7ben", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "PRELS", "PPER", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Dann seyd Jhr nicht der erste Jost,", "tokens": ["Dann", "seyd", "Ihr", "nicht", "der", "ers\u00b7te", "Jost", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PTKNEG", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Der reich und stolz verstorben.", "tokens": ["Der", "reich", "und", "stolz", "ver\u00b7stor\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "KON", "ADJD", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Sogleich verging Jhm aller Dunst", "tokens": ["Sog\u00b7leich", "ver\u00b7ging", "Jhm", "al\u00b7ler", "Dunst"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Lateinscher alten Spr\u00fcche.", "tokens": ["La\u00b7tein\u00b7scher", "al\u00b7ten", "Spr\u00fc\u00b7che", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "ADJA", "NN", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.3": {"text": "Er fasste durch die Rechenkunst", "tokens": ["Er", "fass\u00b7te", "durch", "die", "Re\u00b7chen\u00b7kunst"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die allerschwersten Br\u00fcche.", "tokens": ["Die", "al\u00b7ler\u00b7schwers\u00b7ten", "Br\u00fc\u00b7che", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "O Einmal Eins! dich sah Er ein,", "tokens": ["O", "Ein\u00b7mal", "Eins", "!", "dich", "sah", "Er", "ein", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "NN", "$.", "PPER", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "So wie ein rechter Falke.", "tokens": ["So", "wie", "ein", "rech\u00b7ter", "Fal\u00b7ke", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Durch Handlung wirst du gl\u00fccklich seyn,", "tokens": ["Durch", "Hand\u00b7lung", "wirst", "du", "gl\u00fcck\u00b7lich", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VAFIN", "PPER", "ADJD", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Verk\u00fcndigt ihm Herr Halke.", "tokens": ["Ver\u00b7k\u00fcn\u00b7digt", "ihm", "Herr", "Hal\u00b7ke", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "NE", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Johannes Halke hatte Recht:", "tokens": ["Jo\u00b7han\u00b7nes", "Hal\u00b7ke", "hat\u00b7te", "Recht", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VAFIN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wer prophezeyt behender?", "tokens": ["Wer", "pro\u00b7phe\u00b7zeyt", "be\u00b7hen\u00b7der", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Die ihr mir etwa widersprecht,", "tokens": ["Die", "ihr", "mir", "et\u00b7wa", "wi\u00b7der\u00b7sprecht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Lest den Natur-Calender!", "tokens": ["Lest", "den", "Na\u00b7tur\u00b7Ca\u00b7len\u00b7der", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$."], "meter": "+--+---", "measure": "dactylic.di.plus"}, "line.5": {"text": "Seht, seht auf unsern Ehrenmann,", "tokens": ["Seht", ",", "seht", "auf", "un\u00b7sern", "Eh\u00b7ren\u00b7mann", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Den wir so sch\u00f6n begraben;", "tokens": ["Den", "wir", "so", "sch\u00f6n", "be\u00b7gra\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Wer sonst kein Beyspiel haben kann,", "tokens": ["Wer", "sonst", "kein", "Bey\u00b7spiel", "ha\u00b7ben", "kann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "PIAT", "NN", "VAINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Wird es an diesem haben!", "tokens": ["Wird", "es", "an", "die\u00b7sem", "ha\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPR", "PDAT", "VAINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Der Wohlerblasste ging auch, traun!", "tokens": ["Der", "Woh\u00b7ler\u00b7blass\u00b7te", "ging", "auch", ",", "traun", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "$,", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Auf nicht zu lange Reisen;", "tokens": ["Auf", "nicht", "zu", "lan\u00b7ge", "Rei\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PTKNEG", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Theils um die Fremde zu beschaun,", "tokens": ["Theils", "um", "die", "Frem\u00b7de", "zu", "be\u00b7schaun", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Theils um Sich ihr zu weisen.", "tokens": ["Theils", "um", "Sich", "ihr", "zu", "wei\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PRF", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "In Frankreich war Er ein Baron,", "tokens": ["In", "Fran\u00b7kreich", "war", "Er", "ein", "Ba\u00b7ron", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VAFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "In Holland Heer van Josten,", "tokens": ["In", "Hol\u00b7land", "Heer", "van", "Jos\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "NN", "NE", "NE", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Und zeigte Seines Vaters Sohn", "tokens": ["Und", "zeig\u00b7te", "Sei\u00b7nes", "Va\u00b7ters", "Sohn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "In S\u00fcden, Westen, Osten.", "tokens": ["In", "S\u00fc\u00b7den", ",", "Wes\u00b7ten", ",", "Os\u00b7ten", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "$,", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Er kannte wirklich weit und breit", "tokens": ["Er", "kann\u00b7te", "wirk\u00b7lich", "weit", "und", "breit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADJD", "ADJD", "KON", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Geheime Staats-Intrigues,", "tokens": ["Ge\u00b7hei\u00b7me", "Staats\u00b7In\u00b7tri\u00b7gues", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Und wusste ganz genau die Zeit", "tokens": ["Und", "wuss\u00b7te", "ganz", "ge\u00b7nau", "die", "Zeit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "ADJD", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Des dreyssigj\u00e4hrgen Krieges.", "tokens": ["Des", "dreys\u00b7sig\u00b7j\u00e4hr\u00b7gen", "Krie\u00b7ges", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Herr Jost bewies, als Knabe schon,", "tokens": ["Herr", "Jost", "be\u00b7wies", ",", "als", "Kna\u00b7be", "schon", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "NE", "VVFIN", "$,", "KOUS", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Bey vier Zusammenk\u00fcnften,", "tokens": ["Bey", "vier", "Zu\u00b7sam\u00b7men\u00b7k\u00fcnf\u00b7ten", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "CARD", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Der Sechste Carl sey nicht ein Sohn", "tokens": ["Der", "Sechs\u00b7te", "Carl", "sey", "nicht", "ein", "Sohn"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "NE", "VAFIN", "PTKNEG", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Von Kaiser Carl dem F\u00fcnften.", "tokens": ["Von", "Kai\u00b7ser", "Carl", "dem", "F\u00fcnf\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "NE", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "Er kam zur\u00fcck und lie\u00df sich sehn,", "tokens": ["Er", "kam", "zu\u00b7r\u00fcck", "und", "lie\u00df", "sich", "sehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKVZ", "KON", "VVFIN", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wo man Jhn sehen sollte.", "tokens": ["Wo", "man", "Jhn", "se\u00b7hen", "soll\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "PPER", "VVINF", "VMFIN", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.3": {"text": "Nun hie\u00df Er iedem klug und sch\u00f6n,", "tokens": ["Nun", "hie\u00df", "Er", "ie\u00b7dem", "klug", "und", "sch\u00f6n", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PIAT", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der Jhn so nennen wollte.", "tokens": ["Der", "Jhn", "so", "nen\u00b7nen", "woll\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Doch rieth man Jhm mit gutem Fug,", "tokens": ["Doch", "rieth", "man", "Jhm", "mit", "gu\u00b7tem", "Fug", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIS", "PPER", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Den ritterlichen Degen,", "tokens": ["Den", "rit\u00b7ter\u00b7li\u00b7chen", "De\u00b7gen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Den Er an Seiner Seite trug,", "tokens": ["Den", "Er", "an", "Sei\u00b7ner", "Sei\u00b7te", "trug", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Nur Sonntags anzulegen.", "tokens": ["Nur", "Sonn\u00b7tags", "an\u00b7zu\u00b7le\u00b7gen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVIZU", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "Das Werk der Handlung wohlgemuth", "tokens": ["Das", "Werk", "der", "Hand\u00b7lung", "wohl\u00b7ge\u00b7muth"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ward nun von Jhm begriffen.", "tokens": ["Ward", "nun", "von", "Jhm", "be\u00b7grif\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "APPR", "PPER", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Jhm tr\u00e4umte nur von Geld und Guth,", "tokens": ["Jhm", "tr\u00e4um\u00b7te", "nur", "von", "Geld", "und", "Guth", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Von Frachten und von Schiffen.", "tokens": ["Von", "Frach\u00b7ten", "und", "von", "Schif\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "APPR", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Gelehrte sucht\u2019 Er weiter nicht,", "tokens": ["Ge\u00b7lehr\u00b7te", "sucht'", "Er", "wei\u00b7ter", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "ADV", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Als etwa bey Processen;", "tokens": ["Als", "et\u00b7wa", "bey", "Pro\u00b7ces\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "APPR", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Sonst macht\u2019 Er ihnen ein Gesicht,", "tokens": ["Sonst", "macht'", "Er", "ih\u00b7nen", "ein", "Ge\u00b7sicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Als wollt\u2019 Er alle fressen.", "tokens": ["Als", "wollt'", "Er", "al\u00b7le", "fres\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VMFIN", "PPER", "PIS", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "Der Reich-Entschlafne wollte drauf", "tokens": ["Der", "Reich\u00b7Ent\u00b7schlaf\u00b7ne", "woll\u00b7te", "drauf"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "VMFIN", "PAV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sich doppelt reich durch Ehen,", "tokens": ["Sich", "dop\u00b7pelt", "reich", "durch", "E\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADJD", "ADJD", "APPR", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Ja Sich und Seinen Lebens-Lauf", "tokens": ["Ja", "Sich", "und", "Sei\u00b7nen", "Le\u00b7bens\u00b7Lauf"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PTKANT", "PRF", "KON", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "In echten Erben sehen.", "tokens": ["In", "ech\u00b7ten", "Er\u00b7ben", "se\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Madame starb Jhm pl\u00f6tzlich ab,", "tokens": ["Ma\u00b7da\u00b7me", "starb", "Jhm", "pl\u00f6tz\u00b7lich", "ab", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["FM", "VVFIN", "PPER", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Eh Er die andre freyte;", "tokens": ["Eh", "Er", "die", "and\u00b7re", "frey\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "ADJA", "$."], "meter": "---+-+-", "measure": "unknown.measure.di"}, "line.7": {"text": "Die dritte, die Sein Geld Jhm gab,", "tokens": ["Die", "drit\u00b7te", ",", "die", "Sein", "Geld", "Jhm", "gab", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "PRELS", "PPOSAT", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Beerdiget Jhn heute.", "tokens": ["Be\u00b7er\u00b7di\u00b7get", "Jhn", "heu\u00b7te", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "$."], "meter": "--+-+--", "measure": "anapaest.init"}}, "stanza.13": {"line.1": {"text": "Als Trauermann folgt Sein Herr Sohn", "tokens": ["Als", "Trau\u00b7er\u00b7mann", "folgt", "Sein", "Herr", "Sohn"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "NN", "VVFIN", "PPOSAT", "NN", "NN"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.2": {"text": "Mit Ellen-langem Flohre;", "tokens": ["Mit", "El\u00b7len\u00b7lan\u00b7gem", "Floh\u00b7re", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und vor Jhm singt die Schule schon", "tokens": ["Und", "vor", "Jhm", "singt", "die", "Schu\u00b7le", "schon"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "PPER", "VVFIN", "ART", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "In dem gewohnten Chore.", "tokens": ["In", "dem", "ge\u00b7wohn\u00b7ten", "Cho\u00b7re", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Der schwarzen M\u00e4ntel lange Zahl", "tokens": ["Der", "schwar\u00b7zen", "M\u00e4n\u00b7tel", "lan\u00b7ge", "Zahl"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Begleitet Jhn bey Paaren;", "tokens": ["Be\u00b7glei\u00b7tet", "Jhn", "bey", "Paa\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Er stirbt, doch nur ein einzigmal,", "tokens": ["Er", "stirbt", ",", "doch", "nur", "ein", "ein\u00b7zig\u00b7mal", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "ADV", "ADV", "ART", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Die Kosten zu ersparen.", "tokens": ["Die", "Kos\u00b7ten", "zu", "er\u00b7spa\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}}}}