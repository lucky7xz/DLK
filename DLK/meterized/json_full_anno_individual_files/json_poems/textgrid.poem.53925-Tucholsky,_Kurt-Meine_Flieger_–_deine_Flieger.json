{"textgrid.poem.53925": {"metadata": {"author": {"name": "Tucholsky, Kurt", "birth": "N.A.", "death": "N.A."}, "title": "Meine Flieger \u2013 deine Flieger", "genre": "verse", "period": "N.A.", "pub_year": 1912, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Unsere Flieger haben \u00fcber den Ozean gemacht \u2013", "tokens": ["Un\u00b7se\u00b7re", "Flie\u00b7ger", "ha\u00b7ben", "\u00fc\u00b7ber", "den", "O\u00b7ze\u00b7an", "ge\u00b7macht", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "APPR", "ART", "NN", "VVPP", "$("], "meter": "+--+-+-+--+-+-+", "measure": "iambic.septa.invert"}, "line.2": {"text": "deutsche Energie! deutsche Energie!", "tokens": ["deut\u00b7sche", "E\u00b7ner\u00b7gie", "!", "deut\u00b7sche", "E\u00b7ner\u00b7gie", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADJA", "NN", "$.", "ADJA", "NN", "$."], "meter": "+-+----+-+", "measure": "unknown.measure.tetra"}, "line.3": {"text": "Unsere Flieger hatten eine Schreckensnacht \u2013", "tokens": ["Un\u00b7se\u00b7re", "Flie\u00b7ger", "hat\u00b7ten", "ei\u00b7ne", "Schre\u00b7cken\u00b7snacht", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ART", "NN", "$("], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.4": {"text": "so was war noch nie! Hier ihre Biographie!", "tokens": ["so", "was", "war", "noch", "nie", "!", "Hier", "ih\u00b7re", "Bio\u00b7gra\u00b7phie", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PWS", "VAFIN", "ADV", "ADV", "$.", "ADV", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.5": {"text": "Kikeriki \u2013!", "tokens": ["Ki\u00b7ke\u00b7ri\u00b7ki", "\u2013", "!"], "token_info": ["word", "punct", "punct"], "pos": ["NE", "$(", "$."], "meter": "----", "measure": "unknown.measure.zero"}, "line.6": {"text": "Und wir br\u00fcllen, da\u00df es durch die Stra\u00dfen gellt:", "tokens": ["Und", "wir", "br\u00fcl\u00b7len", ",", "da\u00df", "es", "durch", "die", "Stra\u00b7\u00dfen", "gellt", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "$,", "KOUS", "PPER", "APPR", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.7": {"text": "\u00bbunsere Flieger sind die ersten auf der Welt!\u00ab", "tokens": ["\u00bb", "un\u00b7se\u00b7re", "Flie\u00b7ger", "sind", "die", "ers\u00b7ten", "auf", "der", "Welt", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPOSAT", "NN", "VAFIN", "ART", "ADJA", "APPR", "ART", "NN", "$.", "$("], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.8": {"text": "Eure Flieger sind ganz nette Leute \u2013", "tokens": ["Eu\u00b7re", "Flie\u00b7ger", "sind", "ganz", "net\u00b7te", "Leu\u00b7te", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADV", "ADJA", "NN", "$("], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.9": {"text": "aber kleingedruckt, auf der zweuten Seute.", "tokens": ["a\u00b7ber", "klein\u00b7ge\u00b7druckt", ",", "auf", "der", "zweu\u00b7ten", "Seu\u00b7te", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}}, "stanza.2": {"line.1": {"text": "Unsere Flieger sind der Stolz des Landes!", "tokens": ["Un\u00b7se\u00b7re", "Flie\u00b7ger", "sind", "der", "Stolz", "des", "Lan\u00b7des", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ART", "NN", "ART", "NN", "$."], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.2": {"text": "Vive la France! Quelle rumeur!", "tokens": ["Vi\u00b7ve", "la", "Fran\u00b7ce", "!", "Quel\u00b7le", "ru\u00b7meur", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "$.", "FM", "FM", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Unsere Flieger sind der Gipfel ihres Standes \u2013", "tokens": ["Un\u00b7se\u00b7re", "Flie\u00b7ger", "sind", "der", "Gip\u00b7fel", "ih\u00b7res", "Stan\u00b7des", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ART", "NN", "PPOSAT", "NN", "$("], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.4": {"text": "R\u00e9ception et la L\u00e9gion d'Honneur!", "tokens": ["R\u00e9\u00b7cep\u00b7ti\u00b7on", "et", "la", "L\u00e9\u00b7gi\u00b7on", "d'\u00b7Hon\u00b7neur", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["FM.fr", "FM.fr", "FM.fr", "FM.fr", "FM.fr", "$."], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Und dahinter stehn die Industrien,", "tokens": ["Und", "da\u00b7hin\u00b7ter", "stehn", "die", "In\u00b7dust\u00b7ri\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PAV", "VVFIN", "ART", "NN", "$,"], "meter": "--+-+--+--", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "und sie grinsen in Paris wie in Berlin . . .", "tokens": ["und", "sie", "grin\u00b7sen", "in", "Pa\u00b7ris", "wie", "in", "Ber\u00b7lin", ".", ".", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["KON", "PPER", "VVFIN", "APPR", "NE", "KOKOM", "APPR", "NE", "$.", "$.", "$."], "meter": "+-+-+-+-+++", "measure": "unknown.measure.septa"}, "line.7": {"text": "Eure Flieger sind ja schlie\u00dflich nur", "tokens": ["Eu\u00b7re", "Flie\u00b7ger", "sind", "ja", "schlie\u00df\u00b7lich", "nur"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VAFIN", "ADV", "ADV", "ADV"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.8": {"text": "eine kleine zweite Garnitur.", "tokens": ["ei\u00b7ne", "klei\u00b7ne", "zwei\u00b7te", "Gar\u00b7ni\u00b7tur", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.3": {"line.1": {"text": "Unsere Flieger fliegen heut nach Mexiko!", "tokens": ["Un\u00b7se\u00b7re", "Flie\u00b7ger", "flie\u00b7gen", "heut", "nach", "Me\u00b7xi\u00b7ko", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ADV", "APPR", "NE", "$."], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.2": {"text": "Gods own country \u2013 our America!", "tokens": ["Gods", "own", "coun\u00b7try", "\u2013", "our", "A\u00b7me\u00b7ri\u00b7ca", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "NE", "NE", "$(", "FM", "FM", "$."], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.3": {"text": "Unsere Flieger halten das Niveau \u2013", "tokens": ["Un\u00b7se\u00b7re", "Flie\u00b7ger", "hal\u00b7ten", "das", "Ni\u00b7vea\u00b7u", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ART", "NN", "$("], "meter": "+--+-+--+-+", "measure": "iambic.penta.invert"}, "line.4": {"text": "For the colonel:", "tokens": ["For", "the", "co\u00b7lo\u00b7nel", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "NE", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.5": {"text": "Hip, Hip, Hurra!", "tokens": ["Hip", ",", "Hip", ",", "Hur\u00b7ra", "!"], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["NE", "$,", "NE", "$,", "ITJ", "$."], "meter": "+-+-", "measure": "trochaic.di"}}, "stanza.4": {"line.1": {"text": "Jede Zeitung hat uns das gesagt:", "tokens": ["Je\u00b7de", "Zei\u00b7tung", "hat", "uns", "das", "ge\u00b7sagt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "PPER", "PDS", "VVPP", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Hat da einer einen Flug gewagt,", "tokens": ["Hat", "da", "ei\u00b7ner", "ei\u00b7nen", "Flug", "ge\u00b7wagt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "w\u00e4chst empor zum h\u00f6chsten Firmament", "tokens": ["w\u00e4chst", "em\u00b7por", "zum", "h\u00f6chs\u00b7ten", "Fir\u00b7ma\u00b7ment"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PTKVZ", "APPRART", "ADJA", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "noch der allerd\u00fcmmste Abonnent.", "tokens": ["noch", "der", "al\u00b7ler\u00b7d\u00fcmms\u00b7te", "A\u00b7bon\u00b7nent", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.5": {"text": "\u2013 \u00bbWeil du, Landsmann, doch aus gleichem Holz bist,", "tokens": ["\u2013", "\u00bb", "Weil", "du", ",", "Lands\u00b7mann", ",", "doch", "aus", "glei\u00b7chem", "Holz", "bist", ","], "token_info": ["punct", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "$(", "KOUS", "PPER", "$,", "NN", "$,", "ADV", "APPR", "ADJA", "NN", "VAFIN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.6": {"text": "bin auch ich ein Held, der johlend tanzt!\u00ab", "tokens": ["bin", "auch", "ich", "ein", "Held", ",", "der", "joh\u00b7lend", "tanzt", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["VAFIN", "ADV", "PPER", "ART", "NN", "$,", "PRELS", "ADJD", "VVFIN", "$.", "$("], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.7": {"text": "Sage mir, worauf du stolz bist,", "tokens": ["Sa\u00b7ge", "mir", ",", "wo\u00b7rauf", "du", "stolz", "bist", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "$,", "PWAV", "PPER", "ADJD", "VAFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "und ich sage dir, was du mir kannst.", "tokens": ["und", "ich", "sa\u00b7ge", "dir", ",", "was", "du", "mir", "kannst", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPER", "$,", "PWS", "PPER", "PPER", "VMFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.9": {"text": "Unsere Flieger! Unsere Flieger!", "tokens": ["Un\u00b7se\u00b7re", "Flie\u00b7ger", "!", "Un\u00b7se\u00b7re", "Flie\u00b7ger", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$.", "PPOSAT", "NN", "$."], "meter": "+--+-+--+-", "measure": "iambic.tetra.invert"}, "line.10": {"text": "Die sind Sieger! die sind Sieger!", "tokens": ["Die", "sind", "Sie\u00b7ger", "!", "die", "sind", "Sie\u00b7ger", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "NN", "$.", "ART", "VAFIN", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.11": {"text": "Eure Flieger, gar nicht zu vergleichen,", "tokens": ["Eu\u00b7re", "Flie\u00b7ger", ",", "gar", "nicht", "zu", "ver\u00b7glei\u00b7chen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "ADV", "PTKNEG", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.12": {"text": "k\u00f6nnen unsern nicht das Wasser reichen.", "tokens": ["k\u00f6n\u00b7nen", "un\u00b7sern", "nicht", "das", "Was\u00b7ser", "rei\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPOSAT", "PTKNEG", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.5": {"line.1": {"text": "Will der Stammtisch aller Welt nicht ohne Lust", "tokens": ["Will", "der", "Stamm\u00b7tisch", "al\u00b7ler", "Welt", "nicht", "oh\u00b7ne", "Lust"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "ART", "NN", "PIAT", "NN", "PTKNEG", "APPR", "NN"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}}, "stanza.6": {"line.1": {"text": "braucht er", "tokens": ["braucht", "er"], "token_info": ["word", "word"], "pos": ["VVFIN", "PPER"], "meter": "+-", "measure": "trochaic.single"}}, "stanza.7": {"line.1": {"text": "Unsere Flieger haben \u00fcber den Ozean gemacht \u2013", "tokens": ["Un\u00b7se\u00b7re", "Flie\u00b7ger", "ha\u00b7ben", "\u00fc\u00b7ber", "den", "O\u00b7ze\u00b7an", "ge\u00b7macht", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "APPR", "ART", "NN", "VVPP", "$("], "meter": "+--+-+-+--+-+-+", "measure": "iambic.septa.invert"}, "line.2": {"text": "deutsche Energie! deutsche Energie!", "tokens": ["deut\u00b7sche", "E\u00b7ner\u00b7gie", "!", "deut\u00b7sche", "E\u00b7ner\u00b7gie", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADJA", "NN", "$.", "ADJA", "NN", "$."], "meter": "+-+----+-+", "measure": "unknown.measure.tetra"}, "line.3": {"text": "Unsere Flieger hatten eine Schreckensnacht \u2013", "tokens": ["Un\u00b7se\u00b7re", "Flie\u00b7ger", "hat\u00b7ten", "ei\u00b7ne", "Schre\u00b7cken\u00b7snacht", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ART", "NN", "$("], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.4": {"text": "so was war noch nie! Hier ihre Biographie!", "tokens": ["so", "was", "war", "noch", "nie", "!", "Hier", "ih\u00b7re", "Bio\u00b7gra\u00b7phie", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PWS", "VAFIN", "ADV", "ADV", "$.", "ADV", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.5": {"text": "Kikeriki \u2013!", "tokens": ["Ki\u00b7ke\u00b7ri\u00b7ki", "\u2013", "!"], "token_info": ["word", "punct", "punct"], "pos": ["NE", "$(", "$."], "meter": "----", "measure": "unknown.measure.zero"}, "line.6": {"text": "Und wir br\u00fcllen, da\u00df es durch die Stra\u00dfen gellt:", "tokens": ["Und", "wir", "br\u00fcl\u00b7len", ",", "da\u00df", "es", "durch", "die", "Stra\u00b7\u00dfen", "gellt", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "$,", "KOUS", "PPER", "APPR", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.7": {"text": "\u00bbunsere Flieger sind die ersten auf der Welt!\u00ab", "tokens": ["\u00bb", "un\u00b7se\u00b7re", "Flie\u00b7ger", "sind", "die", "ers\u00b7ten", "auf", "der", "Welt", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPOSAT", "NN", "VAFIN", "ART", "ADJA", "APPR", "ART", "NN", "$.", "$("], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.8": {"text": "Eure Flieger sind ganz nette Leute \u2013", "tokens": ["Eu\u00b7re", "Flie\u00b7ger", "sind", "ganz", "net\u00b7te", "Leu\u00b7te", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADV", "ADJA", "NN", "$("], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.9": {"text": "aber kleingedruckt, auf der zweuten Seute.", "tokens": ["a\u00b7ber", "klein\u00b7ge\u00b7druckt", ",", "auf", "der", "zweu\u00b7ten", "Seu\u00b7te", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}}, "stanza.8": {"line.1": {"text": "Unsere Flieger sind der Stolz des Landes!", "tokens": ["Un\u00b7se\u00b7re", "Flie\u00b7ger", "sind", "der", "Stolz", "des", "Lan\u00b7des", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ART", "NN", "ART", "NN", "$."], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.2": {"text": "Vive la France! Quelle rumeur!", "tokens": ["Vi\u00b7ve", "la", "Fran\u00b7ce", "!", "Quel\u00b7le", "ru\u00b7meur", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "$.", "FM", "FM", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Unsere Flieger sind der Gipfel ihres Standes \u2013", "tokens": ["Un\u00b7se\u00b7re", "Flie\u00b7ger", "sind", "der", "Gip\u00b7fel", "ih\u00b7res", "Stan\u00b7des", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ART", "NN", "PPOSAT", "NN", "$("], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.4": {"text": "R\u00e9ception et la L\u00e9gion d'Honneur!", "tokens": ["R\u00e9\u00b7cep\u00b7ti\u00b7on", "et", "la", "L\u00e9\u00b7gi\u00b7on", "d'\u00b7Hon\u00b7neur", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["FM.fr", "FM.fr", "FM.fr", "FM.fr", "FM.fr", "$."], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Und dahinter stehn die Industrien,", "tokens": ["Und", "da\u00b7hin\u00b7ter", "stehn", "die", "In\u00b7dust\u00b7ri\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PAV", "VVFIN", "ART", "NN", "$,"], "meter": "--+-+--+--", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "und sie grinsen in Paris wie in Berlin . . .", "tokens": ["und", "sie", "grin\u00b7sen", "in", "Pa\u00b7ris", "wie", "in", "Ber\u00b7lin", ".", ".", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["KON", "PPER", "VVFIN", "APPR", "NE", "KOKOM", "APPR", "NE", "$.", "$.", "$."], "meter": "+-+-+-+-+++", "measure": "unknown.measure.septa"}, "line.7": {"text": "Eure Flieger sind ja schlie\u00dflich nur", "tokens": ["Eu\u00b7re", "Flie\u00b7ger", "sind", "ja", "schlie\u00df\u00b7lich", "nur"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VAFIN", "ADV", "ADV", "ADV"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.8": {"text": "eine kleine zweite Garnitur.", "tokens": ["ei\u00b7ne", "klei\u00b7ne", "zwei\u00b7te", "Gar\u00b7ni\u00b7tur", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.9": {"line.1": {"text": "Unsere Flieger fliegen heut nach Mexiko!", "tokens": ["Un\u00b7se\u00b7re", "Flie\u00b7ger", "flie\u00b7gen", "heut", "nach", "Me\u00b7xi\u00b7ko", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ADV", "APPR", "NE", "$."], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.2": {"text": "Gods own country \u2013 our America!", "tokens": ["Gods", "own", "coun\u00b7try", "\u2013", "our", "A\u00b7me\u00b7ri\u00b7ca", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "NE", "NE", "$(", "FM", "FM", "$."], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.3": {"text": "Unsere Flieger halten das Niveau \u2013", "tokens": ["Un\u00b7se\u00b7re", "Flie\u00b7ger", "hal\u00b7ten", "das", "Ni\u00b7vea\u00b7u", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ART", "NN", "$("], "meter": "+--+-+--+-+", "measure": "iambic.penta.invert"}, "line.4": {"text": "For the colonel:", "tokens": ["For", "the", "co\u00b7lo\u00b7nel", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "NE", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.5": {"text": "Hip, Hip, Hurra!", "tokens": ["Hip", ",", "Hip", ",", "Hur\u00b7ra", "!"], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["NE", "$,", "NE", "$,", "ITJ", "$."], "meter": "+-+-", "measure": "trochaic.di"}}, "stanza.10": {"line.1": {"text": "Jede Zeitung hat uns das gesagt:", "tokens": ["Je\u00b7de", "Zei\u00b7tung", "hat", "uns", "das", "ge\u00b7sagt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "PPER", "PDS", "VVPP", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Hat da einer einen Flug gewagt,", "tokens": ["Hat", "da", "ei\u00b7ner", "ei\u00b7nen", "Flug", "ge\u00b7wagt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "w\u00e4chst empor zum h\u00f6chsten Firmament", "tokens": ["w\u00e4chst", "em\u00b7por", "zum", "h\u00f6chs\u00b7ten", "Fir\u00b7ma\u00b7ment"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PTKVZ", "APPRART", "ADJA", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "noch der allerd\u00fcmmste Abonnent.", "tokens": ["noch", "der", "al\u00b7ler\u00b7d\u00fcmms\u00b7te", "A\u00b7bon\u00b7nent", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.5": {"text": "\u2013 \u00bbWeil du, Landsmann, doch aus gleichem Holz bist,", "tokens": ["\u2013", "\u00bb", "Weil", "du", ",", "Lands\u00b7mann", ",", "doch", "aus", "glei\u00b7chem", "Holz", "bist", ","], "token_info": ["punct", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "$(", "KOUS", "PPER", "$,", "NN", "$,", "ADV", "APPR", "ADJA", "NN", "VAFIN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.6": {"text": "bin auch ich ein Held, der johlend tanzt!\u00ab", "tokens": ["bin", "auch", "ich", "ein", "Held", ",", "der", "joh\u00b7lend", "tanzt", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["VAFIN", "ADV", "PPER", "ART", "NN", "$,", "PRELS", "ADJD", "VVFIN", "$.", "$("], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.7": {"text": "Sage mir, worauf du stolz bist,", "tokens": ["Sa\u00b7ge", "mir", ",", "wo\u00b7rauf", "du", "stolz", "bist", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "$,", "PWAV", "PPER", "ADJD", "VAFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "und ich sage dir, was du mir kannst.", "tokens": ["und", "ich", "sa\u00b7ge", "dir", ",", "was", "du", "mir", "kannst", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPER", "$,", "PWS", "PPER", "PPER", "VMFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.9": {"text": "Unsere Flieger! Unsere Flieger!", "tokens": ["Un\u00b7se\u00b7re", "Flie\u00b7ger", "!", "Un\u00b7se\u00b7re", "Flie\u00b7ger", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$.", "PPOSAT", "NN", "$."], "meter": "+--+-+--+-", "measure": "iambic.tetra.invert"}, "line.10": {"text": "Die sind Sieger! die sind Sieger!", "tokens": ["Die", "sind", "Sie\u00b7ger", "!", "die", "sind", "Sie\u00b7ger", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "NN", "$.", "ART", "VAFIN", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.11": {"text": "Eure Flieger, gar nicht zu vergleichen,", "tokens": ["Eu\u00b7re", "Flie\u00b7ger", ",", "gar", "nicht", "zu", "ver\u00b7glei\u00b7chen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "ADV", "PTKNEG", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.12": {"text": "k\u00f6nnen unsern nicht das Wasser reichen.", "tokens": ["k\u00f6n\u00b7nen", "un\u00b7sern", "nicht", "das", "Was\u00b7ser", "rei\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPOSAT", "PTKNEG", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.11": {"line.1": {"text": "Will der Stammtisch aller Welt nicht ohne Lust", "tokens": ["Will", "der", "Stamm\u00b7tisch", "al\u00b7ler", "Welt", "nicht", "oh\u00b7ne", "Lust"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "ART", "NN", "PIAT", "NN", "PTKNEG", "APPR", "NN"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}}, "stanza.12": {"line.1": {"text": "braucht er", "tokens": ["braucht", "er"], "token_info": ["word", "word"], "pos": ["VVFIN", "PPER"], "meter": "+-", "measure": "trochaic.single"}}}}}