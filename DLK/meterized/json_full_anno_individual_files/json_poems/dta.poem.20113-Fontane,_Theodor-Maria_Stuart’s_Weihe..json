{"dta.poem.20113": {"metadata": {"author": {"name": "Fontane, Theodor", "birth": "N.A.", "death": "N.A."}, "title": "Maria Stuart\u2019s Weihe.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1851", "urn": "urn:nbn:de:kobv:b4-200905191321", "language": ["de:0.57", "sv:0.42"], "booktitle": "Fontane, Theodor: Gedichte. Berlin, 1851."}, "poem": {"stanza.1": {"line.1": {"text": "Schlo\u00df Holyrood ist \u00f6d\u2019 und still,", "tokens": ["Schlo\u00df", "Ho\u00b7ly\u00b7rood", "ist", "\u00f6d'", "und", "still", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "VAFIN", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Nachtwind nur durchpfeift es schrill,", "tokens": ["Der", "Nacht\u00b7wind", "nur", "durch\u00b7pfeift", "es", "schrill", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVFIN", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Es klirrt kein Sporn in Hof und Hall\u2019,", "tokens": ["Es", "klirrt", "kein", "Sporn", "in", "Hof", "und", "Hall'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIAT", "NN", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Nur finstres Schweigen \u00fcberall.", "tokens": ["Nur", "finst\u00b7res", "Schwei\u00b7gen", "\u00fc\u00b7be\u00b7rall", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Da pl\u00f6tzlich schwebt, in luftgem Gang,", "tokens": ["Da", "pl\u00f6tz\u00b7lich", "schwebt", ",", "in", "luft\u00b7gem", "Gang", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein hohes Weib die Hall\u2019 entlang:", "tokens": ["Ein", "ho\u00b7hes", "Weib", "die", "Hall'", "ent\u00b7lang", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ihr klares Aug\u2019 strahlt ewig-jung", "tokens": ["Ihr", "kla\u00b7res", "Aug'", "strahlt", "e\u00b7wig\u00b7jung"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN", "VVFIN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Vom Feuer der Begeisterung.", "tokens": ["Vom", "Feu\u00b7er", "der", "Be\u00b7geis\u00b7te\u00b7rung", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Zu H\u00e4upten ihr gl\u00fcht Sternenschein,", "tokens": ["Zu", "H\u00e4up\u00b7ten", "ihr", "gl\u00fcht", "Ster\u00b7nen\u00b7schein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PPER", "VVFIN", "NN", "$,"], "meter": "-+--++-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Ihr Haar ist Gold, \u2014 wer mag sie sein?", "tokens": ["Ihr", "Haar", "ist", "Gold", ",", "wer", "mag", "sie", "sein", "?"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "NN", "$,", "$(", "PWS", "VMFIN", "PPER", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sie kommt, und bringt ihr Angebind", "tokens": ["Sie", "kommt", ",", "und", "bringt", "ihr", "An\u00b7ge\u00b7bind"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "KON", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Im Saale drin dem K\u00f6nigskind.", "tokens": ["Im", "Saa\u00b7le", "drin", "dem", "K\u00f6\u00b7nigs\u00b7kind", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Das K\u00f6nigskind das hei\u00dft ", "tokens": ["Das", "K\u00f6\u00b7nigs\u00b7kind", "das", "hei\u00dft"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "PDS", "VVFIN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Sie aber ist die ", "tokens": ["Sie", "a\u00b7ber", "ist", "die"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "ADV", "VAFIN", "ART"], "meter": "-+-+-", "measure": "iambic.di"}, "line.3": {"text": "Die neiget jetzt zur Wiege sich,", "tokens": ["Die", "nei\u00b7get", "jetzt", "zur", "Wie\u00b7ge", "sich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "APPRART", "NN", "PRF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und fl\u00fcstert ernst: \u201eich weihe Dich!\u201c", "tokens": ["Und", "fl\u00fcs\u00b7tert", "ernst", ":", "\u201e", "ich", "wei\u00b7he", "Dich", "!", "\u201c"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "ADJD", "$.", "$(", "PPER", "VVFIN", "PPER", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Sie fl\u00fcstert\u2019s kaum, da \u2014 still und stumm", "tokens": ["Sie", "fl\u00fcs\u00b7tert's", "kaum", ",", "da", "still", "und", "stumm"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "$,", "KOUS", "$(", "ADJD", "KON", "ADJD"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Entschwebet schon sie wiederum,", "tokens": ["Ent\u00b7schwe\u00b7bet", "schon", "sie", "wie\u00b7de\u00b7rum", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PPER", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und lachend schl\u00fcpfen lust\u2019ge Zwei", "tokens": ["Und", "la\u00b7chend", "schl\u00fcp\u00b7fen", "lust'\u00b7ge", "Zwei"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "VVINF", "VVFIN", "CARD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Jetzt in die Th\u00fcr, an ihr vorbei.", "tokens": ["Jetzt", "in", "die", "Th\u00fcr", ",", "an", "ihr", "vor\u00b7bei", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "$,", "APPR", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Die Eine strotzt von buntem Tand,", "tokens": ["Die", "Ei\u00b7ne", "strotzt", "von", "bun\u00b7tem", "Tand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein Spiegel blitzt in ihrer Hand,", "tokens": ["Ein", "Spie\u00b7gel", "blitzt", "in", "ih\u00b7rer", "Hand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Bald schaut sie sich und bald ihr Kleid,", "tokens": ["Bald", "schaut", "sie", "sich", "und", "bald", "ihr", "Kleid", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "KON", "ADV", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Das war die Dirne \u201e", "tokens": ["Das", "war", "die", "Dir\u00b7ne", "\u201e"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "$("], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.7": {"line.1": {"text": "Die Andre frech und \u00fcppig gar,", "tokens": ["Die", "And\u00b7re", "frech", "und", "\u00fcp\u00b7pig", "gar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "ADJD", "KON", "ADJD", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Tr\u00e4gt langes aufgel\u00f6stes Haar,", "tokens": ["Tr\u00e4gt", "lan\u00b7ges", "auf\u00b7ge\u00b7l\u00f6s\u00b7tes", "Haar", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ihr Aug\u2019 ist schwarz, nackt ihre Brust,", "tokens": ["Ihr", "Aug'", "ist", "schwarz", ",", "nackt", "ih\u00b7re", "Brust", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADJD", "$,", "ADJD", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Das war die Dirne \u201e", "tokens": ["Das", "war", "die", "Dir\u00b7ne", "\u201e"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "$("], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.8": {"line.1": {"text": "Sie neigen beid\u2019 zur Wiege sich,", "tokens": ["Sie", "nei\u00b7gen", "beid'", "zur", "Wie\u00b7ge", "sich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPRART", "NN", "PRF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und kichern hell: \u201ewir weihen Dich!\u201c", "tokens": ["Und", "ki\u00b7chern", "hell", ":", "\u201e", "wir", "wei\u00b7hen", "Dich", "!", "\u201c"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "ADJD", "$.", "$(", "PPER", "VVFIN", "PPER", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da huscht, \u2014 und ihre Wang\u2019 erblasst,", "tokens": ["Da", "huscht", ",", "und", "ih\u00b7re", "Wang'", "er\u00b7blasst", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "$(", "KON", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.4": {"text": "Rasch in den Saal ein dritter Gast.", "tokens": ["Rasch", "in", "den", "Saal", "ein", "drit\u00b7ter", "Gast", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "ART", "NN", "ART", "ADJA", "NN", "$."], "meter": "++-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Wie Schatten schleicht er an der Wand,", "tokens": ["Wie", "Schat\u00b7ten", "schleicht", "er", "an", "der", "Wand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sein Kleid ist roth, roth seine Hand,", "tokens": ["Sein", "Kleid", "ist", "roth", ",", "roth", "sei\u00b7ne", "Hand", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADJD", "$,", "ADJD", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Er schaut sich um, sein Auge sticht,", "tokens": ["Er", "schaut", "sich", "um", ",", "sein", "Au\u00b7ge", "sticht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "PTKVZ", "$,", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und messerscharf ist sein Gesicht.", "tokens": ["Und", "mes\u00b7ser\u00b7scharf", "ist", "sein", "Ge\u00b7sicht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VAFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Er neigt sich jetzt, und spricht das Wort:", "tokens": ["Er", "neigt", "sich", "jetzt", ",", "und", "spricht", "das", "Wort", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "ADV", "$,", "KON", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u201eich weihe Dich zu Blut und Mord!\u201c", "tokens": ["\u201e", "ich", "wei\u00b7he", "Dich", "zu", "Blut", "und", "Mord", "!", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPER", "VVFIN", "PPER", "APPR", "NN", "KON", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Aufschreit im Schlaf das K\u00f6nigskind,", "tokens": ["Auf\u00b7schreit", "im", "Schlaf", "das", "K\u00f6\u00b7nigs\u00b7kind", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPRART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und heller drau\u00dfen pfeift der Wind.", "tokens": ["Und", "hel\u00b7ler", "drau\u00b7\u00dfen", "pfeift", "der", "Wind", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "ADV", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Der Gast ist fort, doch her und hin", "tokens": ["Der", "Gast", "ist", "fort", ",", "doch", "her", "und", "hin"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "PTKVZ", "$,", "ADV", "PTKVZ", "KON", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wirft banger Traum die Schl\u00e4ferin,", "tokens": ["Wirft", "ban\u00b7ger", "Traum", "die", "Schl\u00e4\u00b7fe\u00b7rin", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Geweiht f\u00fcr\u2019s Leben schlummert sie", "tokens": ["Ge\u00b7weiht", "f\u00fcr's", "Le\u00b7ben", "schlum\u00b7mert", "sie"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "APPRART", "NN", "VVFIN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die sch\u00f6ne, schottische Marie.", "tokens": ["Die", "sch\u00f6\u00b7ne", ",", "schot\u00b7ti\u00b7sche", "Ma\u00b7rie", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "ADJA", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}