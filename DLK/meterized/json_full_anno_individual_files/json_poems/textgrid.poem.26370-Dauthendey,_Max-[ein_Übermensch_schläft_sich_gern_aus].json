{"textgrid.poem.26370": {"metadata": {"author": {"name": "Dauthendey, Max", "birth": "N.A.", "death": "N.A."}, "title": "[ein \u00dcbermensch schl\u00e4ft sich gern aus]", "genre": "verse", "period": "N.A.", "pub_year": 1892, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ein \u00dcbermensch schl\u00e4ft sich gern aus", "tokens": ["Ein", "\u00dc\u00b7ber\u00b7mensch", "schl\u00e4ft", "sich", "gern", "aus"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PRF", "ADV", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Den andern ist er doch voraus.", "tokens": ["Den", "an\u00b7dern", "ist", "er", "doch", "vo\u00b7raus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VAFIN", "PPER", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "So lag ich oft noch mittags da", "tokens": ["So", "lag", "ich", "oft", "noch", "mit\u00b7tags", "da"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ADV", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und wartete, was heut geschah.", "tokens": ["Und", "war\u00b7te\u00b7te", ",", "was", "heut", "ge\u00b7schah", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "PRELS", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Nur N\u00e4chte hatte ich genossen,", "tokens": ["Nur", "N\u00e4ch\u00b7te", "hat\u00b7te", "ich", "ge\u00b7nos\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "VAFIN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Doch von der Liebe, jener gro\u00dfen,", "tokens": ["Doch", "von", "der", "Lie\u00b7be", ",", "je\u00b7ner", "gro\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "$,", "PDAT", "ADJA", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Die auch am Tage bleiben soll,", "tokens": ["Die", "auch", "am", "Ta\u00b7ge", "blei\u00b7ben", "soll", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPRART", "NN", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Davon wu\u00dft' ich noch keinen Zoll,", "tokens": ["Da\u00b7von", "wu\u00dft'", "ich", "noch", "kei\u00b7nen", "Zoll", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "ADV", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Denn keiner von den sch\u00f6nen Frauen", "tokens": ["Denn", "kei\u00b7ner", "von", "den", "sch\u00f6\u00b7nen", "Frau\u00b7en"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PIS", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wollte ich noch f\u00fcrs Leben trauen.", "tokens": ["Woll\u00b7te", "ich", "noch", "f\u00fcrs", "Le\u00b7ben", "trau\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "APPRART", "NN", "VVINF", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}}, "stanza.6": {"line.1": {"text": "Die einen, ach, die sprachen tief,", "tokens": ["Die", "ei\u00b7nen", ",", "ach", ",", "die", "spra\u00b7chen", "tief", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "$,", "ITJ", "$,", "PRELS", "VVFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Bis jeder Fleischeswunsch entschlief,", "tokens": ["Bis", "je\u00b7der", "Flei\u00b7sches\u00b7wunsch", "ent\u00b7schlief", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Sie lie\u00dfen sich gern Schwestern nennen,", "tokens": ["Sie", "lie\u00b7\u00dfen", "sich", "gern", "Schwes\u00b7tern", "nen\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "ADV", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Um sich nicht ganz vom Mann zu trennen.", "tokens": ["Um", "sich", "nicht", "ganz", "vom", "Mann", "zu", "tren\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PRF", "PTKNEG", "ADV", "APPRART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Die andern, ach, das sind die Braven,", "tokens": ["Die", "an\u00b7dern", ",", "ach", ",", "das", "sind", "die", "Bra\u00b7ven", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "ITJ", "$,", "PDS", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die lieben gern nach Paragraphen;", "tokens": ["Die", "lie\u00b7ben", "gern", "nach", "Pa\u00b7ra\u00b7gra\u00b7phen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADV", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Sie sind's, die mehr als n\u00fctzlich sind", "tokens": ["Sie", "sin\u00b7d's", ",", "die", "mehr", "als", "n\u00fctz\u00b7lich", "sind"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "$,", "PRELS", "PIS", "KOKOM", "ADJD", "VAFIN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Und lieben statt dem Mann das Kind.", "tokens": ["Und", "lie\u00b7ben", "statt", "dem", "Mann", "das", "Kind", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Die Dritten trugen hoch den Busen", "tokens": ["Die", "Drit\u00b7ten", "tru\u00b7gen", "hoch", "den", "Bu\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "VVFIN", "ADJD", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und liebten durchsichtig die Blusen,", "tokens": ["Und", "lieb\u00b7ten", "durch\u00b7sich\u00b7tig", "die", "Blu\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "ART", "NN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.11": {"line.1": {"text": "Die sind zum Herzklopfen gemacht,", "tokens": ["Die", "sind", "zum", "Herz\u00b7klop\u00b7fen", "ge\u00b7macht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+---+", "measure": "unknown.measure.tri"}, "line.2": {"text": "Doch k\u00fcssen sie gern unbedacht.", "tokens": ["Doch", "k\u00fcs\u00b7sen", "sie", "gern", "un\u00b7be\u00b7dacht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "An jeder hat mich was gequ\u00e4lt.", "tokens": ["An", "je\u00b7der", "hat", "mich", "was", "ge\u00b7qu\u00e4lt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "VAFIN", "PPER", "PIS", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ach, wenn doch einer f\u00fcr mich w\u00e4hlt!", "tokens": ["Ach", ",", "wenn", "doch", "ei\u00b7ner", "f\u00fcr", "mich", "w\u00e4hlt", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "KOUS", "ADV", "PIS", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Weil dieses dann f\u00fcr mich geschah,", "tokens": ["Weil", "die\u00b7ses", "dann", "f\u00fcr", "mich", "ge\u00b7schah", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDS", "ADV", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Deshalb ist dies Kapitel da.", "tokens": ["Des\u00b7halb", "ist", "dies", "Ka\u00b7pi\u00b7tel", "da", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "PDS", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Sie war ein M\u00e4dchen stolz und rar,", "tokens": ["Sie", "war", "ein", "M\u00e4d\u00b7chen", "stolz", "und", "rar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Hochm\u00fctig war an ihr das Haar,", "tokens": ["Hoch\u00b7m\u00fc\u00b7tig", "war", "an", "ihr", "das", "Haar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "APPR", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "Das war aus Gold wie ein Dukat,", "tokens": ["Das", "war", "aus", "Gold", "wie", "ein", "Du\u00b7kat", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "APPR", "NN", "KOKOM", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Rein vierundzwanzig im Karat.", "tokens": ["Rein", "vie\u00b7rund\u00b7zwan\u00b7zig", "im", "Ka\u00b7rat", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "CARD", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "Ihr Auge flog ganz leicht ins Gr\u00fcn,", "tokens": ["Ihr", "Au\u00b7ge", "flog", "ganz", "leicht", "ins", "Gr\u00fcn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ADV", "ADJD", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wie Eidechsen, die stets entfliehn.", "tokens": ["Wie", "Ei\u00b7dech\u00b7sen", ",", "die", "stets", "ent\u00b7fliehn", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "$,", "PRELS", "ADV", "VVINF", "$."], "meter": "-+---+-+", "measure": "dactylic.init"}}, "stanza.17": {"line.1": {"text": "Und eilte man den Augen nach,", "tokens": ["Und", "eil\u00b7te", "man", "den", "Au\u00b7gen", "nach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIS", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "War's wie am Pol ein halb Jahr Tag.", "tokens": ["Wa\u00b7r's", "wie", "am", "Pol", "ein", "halb", "Jahr", "Tag", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "KOKOM", "APPRART", "NN", "ART", "ADJD", "NN", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.18": {"line.1": {"text": "Hell wie der Demant ", "tokens": ["Hell", "wie", "der", "De\u00b7mant"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "KOKOM", "ART", "NN"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.2": {"text": "Kam mir des M\u00e4dchens Seele vor.", "tokens": ["Kam", "mir", "des", "M\u00e4d\u00b7chens", "See\u00b7le", "vor", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "ART", "NN", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.19": {"line.1": {"text": "Ich habe sie nur angeschaut,", "tokens": ["Ich", "ha\u00b7be", "sie", "nur", "an\u00b7ge\u00b7schaut", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da war sie mir wie angetraut.", "tokens": ["Da", "war", "sie", "mir", "wie", "an\u00b7ge\u00b7traut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PPER", "KOKOM", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.20": {"line.1": {"text": "Ich sterbe, dacht' ich, St\u00fcck um St\u00fcck,", "tokens": ["Ich", "ster\u00b7be", ",", "dacht'", "ich", ",", "St\u00fcck", "um", "St\u00fcck", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "VVFIN", "PPER", "$,", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Gibt sie mir nicht den Blick zur\u00fcck,", "tokens": ["Gibt", "sie", "mir", "nicht", "den", "Blick", "zu\u00b7r\u00fcck", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "PTKNEG", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.21": {"line.1": {"text": "Doch sollte ich noch lange warten,", "tokens": ["Doch", "soll\u00b7te", "ich", "noch", "lan\u00b7ge", "war\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "ADV", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Denn man befand sich auf Irrfahrten.", "tokens": ["Denn", "man", "be\u00b7fand", "sich", "auf", "Irr\u00b7fahr\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "PRF", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.22": {"line.1": {"text": "Hatt' sie gesehn und ging wie immer", "tokens": ["Hatt'", "sie", "ge\u00b7sehn", "und", "ging", "wie", "im\u00b7mer"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "VVPP", "KON", "VVFIN", "KOKOM", "ADV"], "meter": "-+-+-+-++", "measure": "unknown.measure.penta"}, "line.2": {"text": "Nach Haus, da sa\u00df sie schon im Zimmer,", "tokens": ["Nach", "Haus", ",", "da", "sa\u00df", "sie", "schon", "im", "Zim\u00b7mer", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "ADV", "VVFIN", "PPER", "ADV", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.23": {"line.1": {"text": "Ihr Antlitz war in der Tapete,", "tokens": ["Ihr", "Ant\u00b7litz", "war", "in", "der", "Ta\u00b7pe\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Als wenn ich es bestellt mir h\u00e4tte,", "tokens": ["Als", "wenn", "ich", "es", "be\u00b7stellt", "mir", "h\u00e4t\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "PPER", "PPER", "VVFIN", "PPER", "VAFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.24": {"line.1": {"text": "Im Goldfischglas am Blumentisch", "tokens": ["Im", "Gold\u00b7fischglas", "am", "Blu\u00b7men\u00b7tisch"], "token_info": ["word", "word", "word", "word"], "pos": ["APPRART", "NN", "APPRART", "NN"], "meter": "-+--+--", "measure": "iambic.di.relaxed"}, "line.2": {"text": "Schwamm sie ganz klein als flinker Fisch,", "tokens": ["Schwamm", "sie", "ganz", "klein", "als", "flin\u00b7ker", "Fisch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "ADJD", "KOKOM", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.25": {"line.1": {"text": "Und nirgends war es mehr geheuer;", "tokens": ["Und", "nir\u00b7gends", "war", "es", "mehr", "ge\u00b7heu\u00b7er", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "PPER", "PIAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Im Ofen tanzte sie im Feuer,", "tokens": ["Im", "O\u00b7fen", "tanz\u00b7te", "sie", "im", "Feu\u00b7er", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PPER", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.26": {"line.1": {"text": "Sie sank als Schnee an meine Scheiben,", "tokens": ["Sie", "sank", "als", "Schnee", "an", "mei\u00b7ne", "Schei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KOUS", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ich konnt' nicht lesen mehr, nicht schreiben,", "tokens": ["Ich", "konnt'", "nicht", "le\u00b7sen", "mehr", ",", "nicht", "schrei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PTKNEG", "VVINF", "ADV", "$,", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.27": {"line.1": {"text": "Statt Buchstaben sah ich nur Haar,", "tokens": ["Statt", "Buch\u00b7sta\u00b7ben", "sah", "ich", "nur", "Haar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "VVFIN", "PPER", "ADV", "NN", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Weil sie von A bis Z da war.", "tokens": ["Weil", "sie", "von", "A", "bis", "Z", "da", "war", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NE", "APPR", "NN", "ADV", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.28": {"line.1": {"text": "Sie war mein Schatten, sa\u00df im Mond,", "tokens": ["Sie", "war", "mein", "Schat\u00b7ten", ",", "sa\u00df", "im", "Mond", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "NN", "$,", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "War \u00fcberall, wo sich's nur lohnt.", "tokens": ["War", "\u00fc\u00b7be\u00b7rall", ",", "wo", "sich's", "nur", "lohnt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "$,", "PWAV", "PIS", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.29": {"line.1": {"text": "Dieses Zusammensein allein", "tokens": ["Die\u00b7ses", "Zu\u00b7sam\u00b7men\u00b7sein", "al\u00b7lein"], "token_info": ["word", "word", "word"], "pos": ["PDAT", "NN", "ADV"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.2": {"text": "Ging tief auf meine Nerven ein,", "tokens": ["Ging", "tief", "auf", "mei\u00b7ne", "Ner\u00b7ven", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "APPR", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.30": {"line.1": {"text": "Und ich verlor den Appetit,", "tokens": ["Und", "ich", "ver\u00b7lor", "den", "Ap\u00b7pe\u00b7tit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mein Magen wollte nicht mehr mit,", "tokens": ["Mein", "Ma\u00b7gen", "woll\u00b7te", "nicht", "mehr", "mit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VMFIN", "PTKNEG", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.31": {"line.1": {"text": "Ich gab mein Fett in Tonnen her,", "tokens": ["Ich", "gab", "mein", "Fett", "in", "Ton\u00b7nen", "her", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "APPR", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und nur mein Herz blieb zentnerschwer.", "tokens": ["Und", "nur", "mein", "Herz", "blieb", "zent\u00b7ner\u00b7schwer", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PPOSAT", "NN", "VVFIN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.32": {"line.1": {"text": "Filzschuhe hat das Schicksel an,", "tokens": ["Filz\u00b7schu\u00b7he", "hat", "das", "Schick\u00b7sel", "an", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Weil man es gar nicht h\u00f6ren kann.", "tokens": ["Weil", "man", "es", "gar", "nicht", "h\u00f6\u00b7ren", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPER", "ADV", "PTKNEG", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.33": {"line.1": {"text": "Teilt es die Schicksalsschl\u00e4ge aus,", "tokens": ["Teilt", "es", "die", "Schick\u00b7sals\u00b7schl\u00e4\u00b7ge", "aus", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "PTKVZ", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Trifft es uns darum stets zu Haus.", "tokens": ["Trifft", "es", "uns", "da\u00b7rum", "stets", "zu", "Haus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "PAV", "ADV", "APPR", "NN", "$."], "meter": "+----+-+", "measure": "dactylic.init"}}, "stanza.34": {"line.1": {"text": "Ich sah die Dame meiner Wahl", "tokens": ["Ich", "sah", "die", "Da\u00b7me", "mei\u00b7ner", "Wahl"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u00d6fters in einem Lesesaal,", "tokens": ["\u00d6f\u00b7ters", "in", "ei\u00b7nem", "Le\u00b7se\u00b7saal", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.35": {"line.1": {"text": "Wo man f\u00fcr zwanzig Pfennig sa\u00df", "tokens": ["Wo", "man", "f\u00fcr", "zwan\u00b7zig", "Pfen\u00b7nig", "sa\u00df"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PIS", "APPR", "CARD", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und vieles mit den Augen las.", "tokens": ["Und", "vie\u00b7les", "mit", "den", "Au\u00b7gen", "las", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.36": {"line.1": {"text": "Sie \u00fcbersprang der B\u00fccher Lauf", "tokens": ["Sie", "\u00fc\u00b7bers\u00b7prang", "der", "B\u00fc\u00b7cher", "Lauf"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und schnitt mehr gern die Seiten auf.", "tokens": ["Und", "schnitt", "mehr", "gern", "die", "Sei\u00b7ten", "auf", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ADV", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.37": {"line.1": {"text": "Dazwischen sprachen wir ein Wort,", "tokens": ["Da\u00b7zwi\u00b7schen", "spra\u00b7chen", "wir", "ein", "Wort", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und jeder sah dann schleunigst fort.", "tokens": ["Und", "je\u00b7der", "sah", "dann", "schleu\u00b7nigst", "fort", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "ADV", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.38": {"line.1": {"text": "Doch finden sich noch andre ein,", "tokens": ["Doch", "fin\u00b7den", "sich", "noch", "and\u00b7re", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "ADV", "PIS", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So ist man nicht mehr so allein.", "tokens": ["So", "ist", "man", "nicht", "mehr", "so", "al\u00b7lein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIS", "PTKNEG", "ADV", "ADV", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.39": {"line.1": {"text": "Unter den andern ist P.T.,", "tokens": ["Un\u00b7ter", "den", "an\u00b7dern", "ist", "P.", "T.", ","], "token_info": ["word", "word", "word", "word", "abbreviation", "abbreviation", "punct"], "pos": ["APPR", "ART", "ADJA", "VAFIN", "NE", "NE", "$,"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.2": {"text": "Den ich dabei nicht gerne seh,", "tokens": ["Den", "ich", "da\u00b7bei", "nicht", "ger\u00b7ne", "seh", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "PAV", "PTKNEG", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.40": {"line.1": {"text": "Zu dreien ist die Liebe schwer,", "tokens": ["Zu", "drei\u00b7en", "ist", "die", "Lie\u00b7be", "schwer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "CARD", "VAFIN", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und einer geht dann nebenher.", "tokens": ["Und", "ei\u00b7ner", "geht", "dann", "ne\u00b7ben\u00b7her", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "ADV", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.41": {"line.1": {"text": "An einem Winternachmittag,", "tokens": ["An", "ei\u00b7nem", "Win\u00b7ter\u00b7nach\u00b7mit\u00b7tag", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Als Schnee auf allen D\u00e4chern lag,", "tokens": ["Als", "Schnee", "auf", "al\u00b7len", "D\u00e4\u00b7chern", "lag", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "APPR", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.42": {"line.1": {"text": "Wie Schnee war's mir gar hell im Sinn:", "tokens": ["Wie", "Schnee", "wa\u00b7r's", "mir", "gar", "hell", "im", "Sinn", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "VAFIN", "PPER", "ADV", "ADJD", "APPRART", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Vor mir da stund Frau K\u00f6nigin.", "tokens": ["Vor", "mir", "da", "stund", "Frau", "K\u00f6\u00b7ni\u00b7gin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ADV", "VVFIN", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.43": {"line.1": {"text": "Frau K\u00f6nigin hie\u00df jene Dame,", "tokens": ["Frau", "K\u00f6\u00b7ni\u00b7gin", "hie\u00df", "je\u00b7ne", "Da\u00b7me", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "VVFIN", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und besser pa\u00dfte ihr kein Name.", "tokens": ["Und", "bes\u00b7ser", "pa\u00df\u00b7te", "ihr", "kein", "Na\u00b7me", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "PPER", "PIAT", "NN", "$."], "meter": "-+-+-++-+", "measure": "unknown.measure.penta"}}, "stanza.44": {"line.1": {"text": "Ich traf sie just vor meiner T\u00fcr.", "tokens": ["Ich", "traf", "sie", "just", "vor", "mei\u00b7ner", "T\u00fcr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sie sagte just, sie wollt' zu mir.", "tokens": ["Sie", "sag\u00b7te", "just", ",", "sie", "wollt'", "zu", "mir", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "PPER", "VMFIN", "APPR", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.45": {"line.1": {"text": "Mir fiel vom Scheitel fast der Hut,", "tokens": ["Mir", "fiel", "vom", "Schei\u00b7tel", "fast", "der", "Hut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So hei\u00df scho\u00df mir ins Haar das Blut.", "tokens": ["So", "hei\u00df", "scho\u00df", "mir", "ins", "Haar", "das", "Blut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "PPER", "APPRART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.46": {"line.1": {"text": "Sie sagte mir ernst und bescheiden:", "tokens": ["Sie", "sag\u00b7te", "mir", "ernst", "und", "be\u00b7schei\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADJD", "KON", "ADJD", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "\u00bbich wei\u00df, Sie k\u00f6nnen P.T. leiden,", "tokens": ["\u00bb", "ich", "wei\u00df", ",", "Sie", "k\u00f6n\u00b7nen", "P.", "T.", "lei\u00b7den", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "abbreviation", "abbreviation", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "$,", "PPER", "VMFIN", "NE", "NE", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.47": {"line.1": {"text": "Er will sich heut mit mir verloben,", "tokens": ["Er", "will", "sich", "heut", "mit", "mir", "ver\u00b7lo\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PRF", "ADV", "APPR", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ich hab's auf morgen aufgeschoben.", "tokens": ["Ich", "hab's", "auf", "mor\u00b7gen", "auf\u00b7ge\u00b7scho\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "ADV", "VVIZU", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.48": {"line.1": {"text": "M\u00f6cht' fragen, halten Sie's f\u00fcr gut,", "tokens": ["M\u00f6cht'", "fra\u00b7gen", ",", "hal\u00b7ten", "Sie's", "f\u00fcr", "gut", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "VVINF", "$,", "ADJA", "NN", "APPR", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da man so kurz sich kennen tut?\u00ab", "tokens": ["Da", "man", "so", "kurz", "sich", "ken\u00b7nen", "tut", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PIS", "ADV", "ADJD", "PRF", "VVINF", "VVFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.49": {"line.1": {"text": "Der Schicksalschlag war eingetroffen,", "tokens": ["Der", "Schick\u00b7sal\u00b7schlag", "war", "ein\u00b7ge\u00b7trof\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Inwendig stand der Mund mir offen.", "tokens": ["In\u00b7wen\u00b7dig", "stand", "der", "Mund", "mir", "of\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "ART", "NN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.50": {"line.1": {"text": "Der Himmel schien mir aufgerissen,", "tokens": ["Der", "Him\u00b7mel", "schien", "mir", "auf\u00b7ge\u00b7ris\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Mein sch\u00f6nstes Ich hinausgeschmissen.", "tokens": ["Mein", "sch\u00f6ns\u00b7tes", "Ich", "hin\u00b7aus\u00b7ge\u00b7schmis\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.51": {"line.1": {"text": "Warum tr\u00e4gt man gest\u00e4rkte Kragen?", "tokens": ["Wa\u00b7rum", "tr\u00e4gt", "man", "ge\u00b7st\u00e4rk\u00b7te", "Kra\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PIS", "ADJA", "NN", "$."], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.2": {"text": "Man kann drin keine Wahrheit sagen.", "tokens": ["Man", "kann", "drin", "kei\u00b7ne", "Wahr\u00b7heit", "sa\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "ADV", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.52": {"line.1": {"text": "Galoschen, die zu weit am Schuh,", "tokens": ["Ga\u00b7lo\u00b7schen", ",", "die", "zu", "weit", "am", "Schuh", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PRELS", "PTKA", "ADJD", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Auch sie rauben die Wahrheitsruh.", "tokens": ["Auch", "sie", "rau\u00b7ben", "die", "Wahr\u00b7heits\u00b7ruh", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VVFIN", "ART", "NN", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}}, "stanza.53": {"line.1": {"text": "Kurz, man versteckt sich in Betrug,", "tokens": ["Kurz", ",", "man", "ver\u00b7steckt", "sich", "in", "Be\u00b7trug", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "PIS", "VVFIN", "PRF", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Denn Emballagen gibt's genug.", "tokens": ["Denn", "Em\u00b7bal\u00b7la\u00b7gen", "gibt's", "ge\u00b7nug", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.54": {"line.1": {"text": "Mein Hals, der wollte laut aufschrein,", "tokens": ["Mein", "Hals", ",", "der", "woll\u00b7te", "laut", "auf\u00b7schrein", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PRELS", "VMFIN", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Stehkragen, der sagte: nein.", "tokens": ["Der", "Steh\u00b7kra\u00b7gen", ",", "der", "sag\u00b7te", ":", "nein", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "VVFIN", "$.", "PTKANT", "$."], "meter": "-++--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.55": {"line.1": {"text": "Ich wollt' zum End' der Welt hingehn,", "tokens": ["Ich", "wollt'", "zum", "End'", "der", "Welt", "hin\u00b7gehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPRART", "NN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Doch die Galoschen blieben stehn.", "tokens": ["Doch", "die", "Ga\u00b7lo\u00b7schen", "blie\u00b7ben", "stehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.56": {"line.1": {"text": "Ich wollte rufen: nimm doch mich!", "tokens": ["Ich", "woll\u00b7te", "ru\u00b7fen", ":", "nimm", "doch", "mich", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "VVINF", "$.", "VVIMP", "ADV", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Doch tief verpackt lag still mein Ich.", "tokens": ["Doch", "tief", "ver\u00b7packt", "lag", "still", "mein", "Ich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVPP", "VVFIN", "ADJD", "PPOSAT", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.57": {"line.1": {"text": "Und da Entsagung edel klingt,", "tokens": ["Und", "da", "Ent\u00b7sa\u00b7gung", "e\u00b7del", "klingt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "NN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wenn einst davon die Nachwelt singt,", "tokens": ["Wenn", "einst", "da\u00b7von", "die", "Nach\u00b7welt", "singt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PAV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.58": {"line.1": {"text": "Lobt' ich den Freund, ganz wie ich sollte,", "tokens": ["Lobt'", "ich", "den", "Freund", ",", "ganz", "wie", "ich", "soll\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "$,", "ADV", "KOKOM", "PPER", "VMFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und wie er's ja auch haben wollte,", "tokens": ["Und", "wie", "er's", "ja", "auch", "ha\u00b7ben", "woll\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PIS", "ADV", "ADV", "VAINF", "VMFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.59": {"line.1": {"text": "Zeigt ihn in gl\u00e4nzender Parade,", "tokens": ["Zeigt", "ihn", "in", "gl\u00e4n\u00b7zen\u00b7der", "Pa\u00b7ra\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Nannte ihn meine Bundeslade.", "tokens": ["Nann\u00b7te", "ihn", "mei\u00b7ne", "Bun\u00b7des\u00b7la\u00b7de", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPOSAT", "NN", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}}, "stanza.60": {"line.1": {"text": "Ein Elefant ward aus der Laus.", "tokens": ["Ein", "E\u00b7le\u00b7fant", "ward", "aus", "der", "Laus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "K\u00f6nigin sah erstaunter aus.", "tokens": ["K\u00f6\u00b7ni\u00b7gin", "sah", "er\u00b7staun\u00b7ter", "aus", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ADJD", "PTKVZ", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.61": {"line.1": {"text": "So gern h\u00e4tt' ich getobt, verneint", "tokens": ["So", "gern", "h\u00e4tt'", "ich", "ge\u00b7tobt", ",", "ver\u00b7neint"], "token_info": ["word", "word", "word", "word", "word", "punct", "word"], "pos": ["ADV", "ADV", "VAFIN", "PPER", "VVPP", "$,", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und Balthasaren tief beweint,", "tokens": ["Und", "Balt\u00b7ha\u00b7sa\u00b7ren", "tief", "be\u00b7weint", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.62": {"line.1": {"text": "Doch \u00f6fters spiel' ich jene Rollen,", "tokens": ["Doch", "\u00f6f\u00b7ters", "spiel'", "ich", "je\u00b7ne", "Rol\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die keine andern spielen wollen,", "tokens": ["Die", "kei\u00b7ne", "an\u00b7dern", "spie\u00b7len", "wol\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "PIS", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.63": {"line.1": {"text": "Denn ich war niemals G\u00f6tterknecht:", "tokens": ["Denn", "ich", "war", "nie\u00b7mals", "G\u00f6t\u00b7ter\u00b7knecht", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "ADV", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Was ich nicht soll, tu ich erst recht.", "tokens": ["Was", "ich", "nicht", "soll", ",", "tu", "ich", "erst", "recht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "PTKNEG", "VMFIN", "$,", "VVFIN", "PPER", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.64": {"line.1": {"text": "Ich sprach dann noch: \u00bbFrau K\u00f6nigin,", "tokens": ["Ich", "sprach", "dann", "noch", ":", "\u00bb", "Frau", "K\u00f6\u00b7ni\u00b7gin", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "$.", "$(", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Gehn Sie noch heut zu P.T. hin,", "tokens": ["Gehn", "Sie", "noch", "heut", "zu", "P.", "T.", "hin", ","], "token_info": ["word", "word", "word", "word", "word", "abbreviation", "abbreviation", "word", "punct"], "pos": ["NN", "PPER", "ADV", "ADV", "APPR", "NE", "NE", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.65": {"line.1": {"text": "Und da sich noch kein andrer fand,", "tokens": ["Und", "da", "sich", "noch", "kein", "an\u00b7drer", "fand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PRF", "ADV", "PIAT", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Reichen Sie dreist ihm Ihre Hand.", "tokens": ["Rei\u00b7chen", "Sie", "dreist", "ihm", "Ih\u00b7re", "Hand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "VVFIN", "PPER", "PPOSAT", "NN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.66": {"line.1": {"text": "Verloben ist meist ein Riskieren,", "tokens": ["Ver\u00b7lo\u00b7ben", "ist", "meist", "ein", "Ris\u00b7kie\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Es wird nicht besser vom Genieren.", "tokens": ["Es", "wird", "nicht", "bes\u00b7ser", "vom", "Ge\u00b7nie\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKNEG", "ADJD", "APPRART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.67": {"line.1": {"text": "Sie sollen sich noch heut verloben, \u2013", "tokens": ["Sie", "sol\u00b7len", "sich", "noch", "heut", "ver\u00b7lo\u00b7ben", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VMFIN", "PRF", "ADV", "ADV", "VVPP", "$,", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Verzeihung, ich verga\u00df was oben.\u00ab", "tokens": ["Ver\u00b7zei\u00b7hung", ",", "ich", "ver\u00b7ga\u00df", "was", "o\u00b7ben", ".", "\u00ab"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "$,", "PPER", "VVFIN", "PWS", "ADV", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.68": {"line.1": {"text": "Leis hie\u00df ich sie so weitergehen,", "tokens": ["Leis", "hie\u00df", "ich", "sie", "so", "wei\u00b7ter\u00b7ge\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "PPER", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Denn meine Seele hatte Wehen,", "tokens": ["Denn", "mei\u00b7ne", "See\u00b7le", "hat\u00b7te", "We\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VAFIN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.69": {"line.1": {"text": "Und ich stieg schwer zu meinem Zimmer,", "tokens": ["Und", "ich", "stieg", "schwer", "zu", "mei\u00b7nem", "Zim\u00b7mer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ADJD", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die M\u00f6bel zeigten Tr\u00e4nenschimmer.", "tokens": ["Die", "M\u00f6\u00b7bel", "zeig\u00b7ten", "Tr\u00e4\u00b7nen\u00b7schim\u00b7mer", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.70": {"line.1": {"text": "Wenn sich etwas ins Aug' verirrt,", "tokens": ["Wenn", "sich", "et\u00b7was", "ins", "Aug'", "ver\u00b7irrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "ADV", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sieht man die Gegend irisiert.", "tokens": ["Sieht", "man", "die", "Ge\u00b7gend", "i\u00b7ri\u00b7siert", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.71": {"line.1": {"text": "Ich putze \u00f6fters meine Nase;", "tokens": ["Ich", "put\u00b7ze", "\u00f6f\u00b7ters", "mei\u00b7ne", "Na\u00b7se", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Kalt war sie wie 'ne Totenvase.", "tokens": ["Kalt", "war", "sie", "wie", "'ne", "To\u00b7ten\u00b7va\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "KOKOM", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.72": {"line.1": {"text": "Auch du ein Brutus, dacht' ich, Beste!", "tokens": ["Auch", "du", "ein", "Bru\u00b7tus", ",", "dacht'", "ich", ",", "Bes\u00b7te", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "PPER", "ART", "NE", "$,", "VVFIN", "PPER", "$,", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Hell sprang etwas auf meine Weste.", "tokens": ["Hell", "sprang", "et\u00b7was", "auf", "mei\u00b7ne", "Wes\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PIS", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.73": {"line.1": {"text": "Ach Leid, du bist oft menschengro\u00df,", "tokens": ["Ach", "Leid", ",", "du", "bist", "oft", "men\u00b7schen\u00b7gro\u00df", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "NN", "$,", "PPER", "VAFIN", "ADV", "ADJD", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.2": {"text": "Doch kleine Tr\u00e4nen weinst du blo\u00df,", "tokens": ["Doch", "klei\u00b7ne", "Tr\u00e4\u00b7nen", "weinst", "du", "blo\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "VVFIN", "PPER", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.74": {"line.1": {"text": "Und sieht man deinen kleinen zu,", "tokens": ["Und", "sieht", "man", "dei\u00b7nen", "klei\u00b7nen", "zu", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIS", "PPOSAT", "ADJA", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So wird man Null und bekommt Ruh'.", "tokens": ["So", "wird", "man", "Null", "und", "be\u00b7kommt", "Ruh'", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIS", "NN", "KON", "VVFIN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.75": {"line.1": {"text": "Ein \u00dcbermensch schl\u00e4ft sich gern aus", "tokens": ["Ein", "\u00dc\u00b7ber\u00b7mensch", "schl\u00e4ft", "sich", "gern", "aus"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PRF", "ADV", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Den andern ist er doch voraus.", "tokens": ["Den", "an\u00b7dern", "ist", "er", "doch", "vo\u00b7raus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VAFIN", "PPER", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.76": {"line.1": {"text": "So lag ich oft noch mittags da", "tokens": ["So", "lag", "ich", "oft", "noch", "mit\u00b7tags", "da"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ADV", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und wartete, was heut geschah.", "tokens": ["Und", "war\u00b7te\u00b7te", ",", "was", "heut", "ge\u00b7schah", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "PRELS", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.77": {"line.1": {"text": "Nur N\u00e4chte hatte ich genossen,", "tokens": ["Nur", "N\u00e4ch\u00b7te", "hat\u00b7te", "ich", "ge\u00b7nos\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "VAFIN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Doch von der Liebe, jener gro\u00dfen,", "tokens": ["Doch", "von", "der", "Lie\u00b7be", ",", "je\u00b7ner", "gro\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "$,", "PDAT", "ADJA", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.78": {"line.1": {"text": "Die auch am Tage bleiben soll,", "tokens": ["Die", "auch", "am", "Ta\u00b7ge", "blei\u00b7ben", "soll", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPRART", "NN", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Davon wu\u00dft' ich noch keinen Zoll,", "tokens": ["Da\u00b7von", "wu\u00dft'", "ich", "noch", "kei\u00b7nen", "Zoll", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "ADV", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.79": {"line.1": {"text": "Denn keiner von den sch\u00f6nen Frauen", "tokens": ["Denn", "kei\u00b7ner", "von", "den", "sch\u00f6\u00b7nen", "Frau\u00b7en"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PIS", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wollte ich noch f\u00fcrs Leben trauen.", "tokens": ["Woll\u00b7te", "ich", "noch", "f\u00fcrs", "Le\u00b7ben", "trau\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "APPRART", "NN", "VVINF", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}}, "stanza.80": {"line.1": {"text": "Die einen, ach, die sprachen tief,", "tokens": ["Die", "ei\u00b7nen", ",", "ach", ",", "die", "spra\u00b7chen", "tief", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "$,", "ITJ", "$,", "PRELS", "VVFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Bis jeder Fleischeswunsch entschlief,", "tokens": ["Bis", "je\u00b7der", "Flei\u00b7sches\u00b7wunsch", "ent\u00b7schlief", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.81": {"line.1": {"text": "Sie lie\u00dfen sich gern Schwestern nennen,", "tokens": ["Sie", "lie\u00b7\u00dfen", "sich", "gern", "Schwes\u00b7tern", "nen\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "ADV", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Um sich nicht ganz vom Mann zu trennen.", "tokens": ["Um", "sich", "nicht", "ganz", "vom", "Mann", "zu", "tren\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PRF", "PTKNEG", "ADV", "APPRART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.82": {"line.1": {"text": "Die andern, ach, das sind die Braven,", "tokens": ["Die", "an\u00b7dern", ",", "ach", ",", "das", "sind", "die", "Bra\u00b7ven", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "ITJ", "$,", "PDS", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die lieben gern nach Paragraphen;", "tokens": ["Die", "lie\u00b7ben", "gern", "nach", "Pa\u00b7ra\u00b7gra\u00b7phen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADV", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.83": {"line.1": {"text": "Sie sind's, die mehr als n\u00fctzlich sind", "tokens": ["Sie", "sin\u00b7d's", ",", "die", "mehr", "als", "n\u00fctz\u00b7lich", "sind"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "$,", "PRELS", "PIS", "KOKOM", "ADJD", "VAFIN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Und lieben statt dem Mann das Kind.", "tokens": ["Und", "lie\u00b7ben", "statt", "dem", "Mann", "das", "Kind", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.84": {"line.1": {"text": "Die Dritten trugen hoch den Busen", "tokens": ["Die", "Drit\u00b7ten", "tru\u00b7gen", "hoch", "den", "Bu\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "VVFIN", "ADJD", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und liebten durchsichtig die Blusen,", "tokens": ["Und", "lieb\u00b7ten", "durch\u00b7sich\u00b7tig", "die", "Blu\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "ART", "NN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.85": {"line.1": {"text": "Die sind zum Herzklopfen gemacht,", "tokens": ["Die", "sind", "zum", "Herz\u00b7klop\u00b7fen", "ge\u00b7macht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+---+", "measure": "unknown.measure.tri"}, "line.2": {"text": "Doch k\u00fcssen sie gern unbedacht.", "tokens": ["Doch", "k\u00fcs\u00b7sen", "sie", "gern", "un\u00b7be\u00b7dacht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.86": {"line.1": {"text": "An jeder hat mich was gequ\u00e4lt.", "tokens": ["An", "je\u00b7der", "hat", "mich", "was", "ge\u00b7qu\u00e4lt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "VAFIN", "PPER", "PIS", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ach, wenn doch einer f\u00fcr mich w\u00e4hlt!", "tokens": ["Ach", ",", "wenn", "doch", "ei\u00b7ner", "f\u00fcr", "mich", "w\u00e4hlt", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "KOUS", "ADV", "PIS", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.87": {"line.1": {"text": "Weil dieses dann f\u00fcr mich geschah,", "tokens": ["Weil", "die\u00b7ses", "dann", "f\u00fcr", "mich", "ge\u00b7schah", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDS", "ADV", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Deshalb ist dies Kapitel da.", "tokens": ["Des\u00b7halb", "ist", "dies", "Ka\u00b7pi\u00b7tel", "da", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "PDS", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.88": {"line.1": {"text": "Sie war ein M\u00e4dchen stolz und rar,", "tokens": ["Sie", "war", "ein", "M\u00e4d\u00b7chen", "stolz", "und", "rar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Hochm\u00fctig war an ihr das Haar,", "tokens": ["Hoch\u00b7m\u00fc\u00b7tig", "war", "an", "ihr", "das", "Haar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "APPR", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.89": {"line.1": {"text": "Das war aus Gold wie ein Dukat,", "tokens": ["Das", "war", "aus", "Gold", "wie", "ein", "Du\u00b7kat", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "APPR", "NN", "KOKOM", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Rein vierundzwanzig im Karat.", "tokens": ["Rein", "vie\u00b7rund\u00b7zwan\u00b7zig", "im", "Ka\u00b7rat", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "CARD", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.90": {"line.1": {"text": "Ihr Auge flog ganz leicht ins Gr\u00fcn,", "tokens": ["Ihr", "Au\u00b7ge", "flog", "ganz", "leicht", "ins", "Gr\u00fcn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ADV", "ADJD", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wie Eidechsen, die stets entfliehn.", "tokens": ["Wie", "Ei\u00b7dech\u00b7sen", ",", "die", "stets", "ent\u00b7fliehn", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "$,", "PRELS", "ADV", "VVINF", "$."], "meter": "-+---+-+", "measure": "dactylic.init"}}, "stanza.91": {"line.1": {"text": "Und eilte man den Augen nach,", "tokens": ["Und", "eil\u00b7te", "man", "den", "Au\u00b7gen", "nach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIS", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "War's wie am Pol ein halb Jahr Tag.", "tokens": ["Wa\u00b7r's", "wie", "am", "Pol", "ein", "halb", "Jahr", "Tag", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "KOKOM", "APPRART", "NN", "ART", "ADJD", "NN", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.92": {"line.1": {"text": "Hell wie der Demant ", "tokens": ["Hell", "wie", "der", "De\u00b7mant"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "KOKOM", "ART", "NN"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.2": {"text": "Kam mir des M\u00e4dchens Seele vor.", "tokens": ["Kam", "mir", "des", "M\u00e4d\u00b7chens", "See\u00b7le", "vor", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "ART", "NN", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.93": {"line.1": {"text": "Ich habe sie nur angeschaut,", "tokens": ["Ich", "ha\u00b7be", "sie", "nur", "an\u00b7ge\u00b7schaut", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da war sie mir wie angetraut.", "tokens": ["Da", "war", "sie", "mir", "wie", "an\u00b7ge\u00b7traut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PPER", "KOKOM", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.94": {"line.1": {"text": "Ich sterbe, dacht' ich, St\u00fcck um St\u00fcck,", "tokens": ["Ich", "ster\u00b7be", ",", "dacht'", "ich", ",", "St\u00fcck", "um", "St\u00fcck", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "VVFIN", "PPER", "$,", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Gibt sie mir nicht den Blick zur\u00fcck,", "tokens": ["Gibt", "sie", "mir", "nicht", "den", "Blick", "zu\u00b7r\u00fcck", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "PTKNEG", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.95": {"line.1": {"text": "Doch sollte ich noch lange warten,", "tokens": ["Doch", "soll\u00b7te", "ich", "noch", "lan\u00b7ge", "war\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "ADV", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Denn man befand sich auf Irrfahrten.", "tokens": ["Denn", "man", "be\u00b7fand", "sich", "auf", "Irr\u00b7fahr\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "PRF", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.96": {"line.1": {"text": "Hatt' sie gesehn und ging wie immer", "tokens": ["Hatt'", "sie", "ge\u00b7sehn", "und", "ging", "wie", "im\u00b7mer"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "VVPP", "KON", "VVFIN", "KOKOM", "ADV"], "meter": "-+-+-+-++", "measure": "unknown.measure.penta"}, "line.2": {"text": "Nach Haus, da sa\u00df sie schon im Zimmer,", "tokens": ["Nach", "Haus", ",", "da", "sa\u00df", "sie", "schon", "im", "Zim\u00b7mer", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "ADV", "VVFIN", "PPER", "ADV", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.97": {"line.1": {"text": "Ihr Antlitz war in der Tapete,", "tokens": ["Ihr", "Ant\u00b7litz", "war", "in", "der", "Ta\u00b7pe\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Als wenn ich es bestellt mir h\u00e4tte,", "tokens": ["Als", "wenn", "ich", "es", "be\u00b7stellt", "mir", "h\u00e4t\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "PPER", "PPER", "VVFIN", "PPER", "VAFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.98": {"line.1": {"text": "Im Goldfischglas am Blumentisch", "tokens": ["Im", "Gold\u00b7fischglas", "am", "Blu\u00b7men\u00b7tisch"], "token_info": ["word", "word", "word", "word"], "pos": ["APPRART", "NN", "APPRART", "NN"], "meter": "-+--+--", "measure": "iambic.di.relaxed"}, "line.2": {"text": "Schwamm sie ganz klein als flinker Fisch,", "tokens": ["Schwamm", "sie", "ganz", "klein", "als", "flin\u00b7ker", "Fisch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "ADJD", "KOKOM", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.99": {"line.1": {"text": "Und nirgends war es mehr geheuer;", "tokens": ["Und", "nir\u00b7gends", "war", "es", "mehr", "ge\u00b7heu\u00b7er", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "PPER", "PIAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Im Ofen tanzte sie im Feuer,", "tokens": ["Im", "O\u00b7fen", "tanz\u00b7te", "sie", "im", "Feu\u00b7er", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PPER", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.100": {"line.1": {"text": "Sie sank als Schnee an meine Scheiben,", "tokens": ["Sie", "sank", "als", "Schnee", "an", "mei\u00b7ne", "Schei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KOUS", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ich konnt' nicht lesen mehr, nicht schreiben,", "tokens": ["Ich", "konnt'", "nicht", "le\u00b7sen", "mehr", ",", "nicht", "schrei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PTKNEG", "VVINF", "ADV", "$,", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.101": {"line.1": {"text": "Statt Buchstaben sah ich nur Haar,", "tokens": ["Statt", "Buch\u00b7sta\u00b7ben", "sah", "ich", "nur", "Haar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "VVFIN", "PPER", "ADV", "NN", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Weil sie von A bis Z da war.", "tokens": ["Weil", "sie", "von", "A", "bis", "Z", "da", "war", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NE", "APPR", "NN", "ADV", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.102": {"line.1": {"text": "Sie war mein Schatten, sa\u00df im Mond,", "tokens": ["Sie", "war", "mein", "Schat\u00b7ten", ",", "sa\u00df", "im", "Mond", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "NN", "$,", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "War \u00fcberall, wo sich's nur lohnt.", "tokens": ["War", "\u00fc\u00b7be\u00b7rall", ",", "wo", "sich's", "nur", "lohnt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "$,", "PWAV", "PIS", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.103": {"line.1": {"text": "Dieses Zusammensein allein", "tokens": ["Die\u00b7ses", "Zu\u00b7sam\u00b7men\u00b7sein", "al\u00b7lein"], "token_info": ["word", "word", "word"], "pos": ["PDAT", "NN", "ADV"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.2": {"text": "Ging tief auf meine Nerven ein,", "tokens": ["Ging", "tief", "auf", "mei\u00b7ne", "Ner\u00b7ven", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "APPR", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.104": {"line.1": {"text": "Und ich verlor den Appetit,", "tokens": ["Und", "ich", "ver\u00b7lor", "den", "Ap\u00b7pe\u00b7tit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mein Magen wollte nicht mehr mit,", "tokens": ["Mein", "Ma\u00b7gen", "woll\u00b7te", "nicht", "mehr", "mit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VMFIN", "PTKNEG", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.105": {"line.1": {"text": "Ich gab mein Fett in Tonnen her,", "tokens": ["Ich", "gab", "mein", "Fett", "in", "Ton\u00b7nen", "her", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "APPR", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und nur mein Herz blieb zentnerschwer.", "tokens": ["Und", "nur", "mein", "Herz", "blieb", "zent\u00b7ner\u00b7schwer", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PPOSAT", "NN", "VVFIN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.106": {"line.1": {"text": "Filzschuhe hat das Schicksel an,", "tokens": ["Filz\u00b7schu\u00b7he", "hat", "das", "Schick\u00b7sel", "an", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Weil man es gar nicht h\u00f6ren kann.", "tokens": ["Weil", "man", "es", "gar", "nicht", "h\u00f6\u00b7ren", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPER", "ADV", "PTKNEG", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.107": {"line.1": {"text": "Teilt es die Schicksalsschl\u00e4ge aus,", "tokens": ["Teilt", "es", "die", "Schick\u00b7sals\u00b7schl\u00e4\u00b7ge", "aus", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "PTKVZ", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Trifft es uns darum stets zu Haus.", "tokens": ["Trifft", "es", "uns", "da\u00b7rum", "stets", "zu", "Haus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "PAV", "ADV", "APPR", "NN", "$."], "meter": "+----+-+", "measure": "dactylic.init"}}, "stanza.108": {"line.1": {"text": "Ich sah die Dame meiner Wahl", "tokens": ["Ich", "sah", "die", "Da\u00b7me", "mei\u00b7ner", "Wahl"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u00d6fters in einem Lesesaal,", "tokens": ["\u00d6f\u00b7ters", "in", "ei\u00b7nem", "Le\u00b7se\u00b7saal", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.109": {"line.1": {"text": "Wo man f\u00fcr zwanzig Pfennig sa\u00df", "tokens": ["Wo", "man", "f\u00fcr", "zwan\u00b7zig", "Pfen\u00b7nig", "sa\u00df"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PIS", "APPR", "CARD", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und vieles mit den Augen las.", "tokens": ["Und", "vie\u00b7les", "mit", "den", "Au\u00b7gen", "las", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.110": {"line.1": {"text": "Sie \u00fcbersprang der B\u00fccher Lauf", "tokens": ["Sie", "\u00fc\u00b7bers\u00b7prang", "der", "B\u00fc\u00b7cher", "Lauf"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und schnitt mehr gern die Seiten auf.", "tokens": ["Und", "schnitt", "mehr", "gern", "die", "Sei\u00b7ten", "auf", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ADV", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.111": {"line.1": {"text": "Dazwischen sprachen wir ein Wort,", "tokens": ["Da\u00b7zwi\u00b7schen", "spra\u00b7chen", "wir", "ein", "Wort", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und jeder sah dann schleunigst fort.", "tokens": ["Und", "je\u00b7der", "sah", "dann", "schleu\u00b7nigst", "fort", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "ADV", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.112": {"line.1": {"text": "Doch finden sich noch andre ein,", "tokens": ["Doch", "fin\u00b7den", "sich", "noch", "and\u00b7re", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "ADV", "PIS", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So ist man nicht mehr so allein.", "tokens": ["So", "ist", "man", "nicht", "mehr", "so", "al\u00b7lein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIS", "PTKNEG", "ADV", "ADV", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.113": {"line.1": {"text": "Unter den andern ist P.T.,", "tokens": ["Un\u00b7ter", "den", "an\u00b7dern", "ist", "P.", "T.", ","], "token_info": ["word", "word", "word", "word", "abbreviation", "abbreviation", "punct"], "pos": ["APPR", "ART", "ADJA", "VAFIN", "NE", "NE", "$,"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.2": {"text": "Den ich dabei nicht gerne seh,", "tokens": ["Den", "ich", "da\u00b7bei", "nicht", "ger\u00b7ne", "seh", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "PAV", "PTKNEG", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.114": {"line.1": {"text": "Zu dreien ist die Liebe schwer,", "tokens": ["Zu", "drei\u00b7en", "ist", "die", "Lie\u00b7be", "schwer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "CARD", "VAFIN", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und einer geht dann nebenher.", "tokens": ["Und", "ei\u00b7ner", "geht", "dann", "ne\u00b7ben\u00b7her", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "ADV", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.115": {"line.1": {"text": "An einem Winternachmittag,", "tokens": ["An", "ei\u00b7nem", "Win\u00b7ter\u00b7nach\u00b7mit\u00b7tag", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Als Schnee auf allen D\u00e4chern lag,", "tokens": ["Als", "Schnee", "auf", "al\u00b7len", "D\u00e4\u00b7chern", "lag", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "APPR", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.116": {"line.1": {"text": "Wie Schnee war's mir gar hell im Sinn:", "tokens": ["Wie", "Schnee", "wa\u00b7r's", "mir", "gar", "hell", "im", "Sinn", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "VAFIN", "PPER", "ADV", "ADJD", "APPRART", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Vor mir da stund Frau K\u00f6nigin.", "tokens": ["Vor", "mir", "da", "stund", "Frau", "K\u00f6\u00b7ni\u00b7gin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ADV", "VVFIN", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.117": {"line.1": {"text": "Frau K\u00f6nigin hie\u00df jene Dame,", "tokens": ["Frau", "K\u00f6\u00b7ni\u00b7gin", "hie\u00df", "je\u00b7ne", "Da\u00b7me", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "VVFIN", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und besser pa\u00dfte ihr kein Name.", "tokens": ["Und", "bes\u00b7ser", "pa\u00df\u00b7te", "ihr", "kein", "Na\u00b7me", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "PPER", "PIAT", "NN", "$."], "meter": "-+-+-++-+", "measure": "unknown.measure.penta"}}, "stanza.118": {"line.1": {"text": "Ich traf sie just vor meiner T\u00fcr.", "tokens": ["Ich", "traf", "sie", "just", "vor", "mei\u00b7ner", "T\u00fcr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sie sagte just, sie wollt' zu mir.", "tokens": ["Sie", "sag\u00b7te", "just", ",", "sie", "wollt'", "zu", "mir", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "PPER", "VMFIN", "APPR", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.119": {"line.1": {"text": "Mir fiel vom Scheitel fast der Hut,", "tokens": ["Mir", "fiel", "vom", "Schei\u00b7tel", "fast", "der", "Hut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So hei\u00df scho\u00df mir ins Haar das Blut.", "tokens": ["So", "hei\u00df", "scho\u00df", "mir", "ins", "Haar", "das", "Blut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "PPER", "APPRART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.120": {"line.1": {"text": "Sie sagte mir ernst und bescheiden:", "tokens": ["Sie", "sag\u00b7te", "mir", "ernst", "und", "be\u00b7schei\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADJD", "KON", "ADJD", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "\u00bbich wei\u00df, Sie k\u00f6nnen P.T. leiden,", "tokens": ["\u00bb", "ich", "wei\u00df", ",", "Sie", "k\u00f6n\u00b7nen", "P.", "T.", "lei\u00b7den", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "abbreviation", "abbreviation", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "$,", "PPER", "VMFIN", "NE", "NE", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.121": {"line.1": {"text": "Er will sich heut mit mir verloben,", "tokens": ["Er", "will", "sich", "heut", "mit", "mir", "ver\u00b7lo\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PRF", "ADV", "APPR", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ich hab's auf morgen aufgeschoben.", "tokens": ["Ich", "hab's", "auf", "mor\u00b7gen", "auf\u00b7ge\u00b7scho\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "ADV", "VVIZU", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.122": {"line.1": {"text": "M\u00f6cht' fragen, halten Sie's f\u00fcr gut,", "tokens": ["M\u00f6cht'", "fra\u00b7gen", ",", "hal\u00b7ten", "Sie's", "f\u00fcr", "gut", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "VVINF", "$,", "ADJA", "NN", "APPR", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da man so kurz sich kennen tut?\u00ab", "tokens": ["Da", "man", "so", "kurz", "sich", "ken\u00b7nen", "tut", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PIS", "ADV", "ADJD", "PRF", "VVINF", "VVFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.123": {"line.1": {"text": "Der Schicksalschlag war eingetroffen,", "tokens": ["Der", "Schick\u00b7sal\u00b7schlag", "war", "ein\u00b7ge\u00b7trof\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Inwendig stand der Mund mir offen.", "tokens": ["In\u00b7wen\u00b7dig", "stand", "der", "Mund", "mir", "of\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "ART", "NN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.124": {"line.1": {"text": "Der Himmel schien mir aufgerissen,", "tokens": ["Der", "Him\u00b7mel", "schien", "mir", "auf\u00b7ge\u00b7ris\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Mein sch\u00f6nstes Ich hinausgeschmissen.", "tokens": ["Mein", "sch\u00f6ns\u00b7tes", "Ich", "hin\u00b7aus\u00b7ge\u00b7schmis\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.125": {"line.1": {"text": "Warum tr\u00e4gt man gest\u00e4rkte Kragen?", "tokens": ["Wa\u00b7rum", "tr\u00e4gt", "man", "ge\u00b7st\u00e4rk\u00b7te", "Kra\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PIS", "ADJA", "NN", "$."], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.2": {"text": "Man kann drin keine Wahrheit sagen.", "tokens": ["Man", "kann", "drin", "kei\u00b7ne", "Wahr\u00b7heit", "sa\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "ADV", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.126": {"line.1": {"text": "Galoschen, die zu weit am Schuh,", "tokens": ["Ga\u00b7lo\u00b7schen", ",", "die", "zu", "weit", "am", "Schuh", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PRELS", "PTKA", "ADJD", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Auch sie rauben die Wahrheitsruh.", "tokens": ["Auch", "sie", "rau\u00b7ben", "die", "Wahr\u00b7heits\u00b7ruh", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VVFIN", "ART", "NN", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}}, "stanza.127": {"line.1": {"text": "Kurz, man versteckt sich in Betrug,", "tokens": ["Kurz", ",", "man", "ver\u00b7steckt", "sich", "in", "Be\u00b7trug", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "PIS", "VVFIN", "PRF", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Denn Emballagen gibt's genug.", "tokens": ["Denn", "Em\u00b7bal\u00b7la\u00b7gen", "gibt's", "ge\u00b7nug", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.128": {"line.1": {"text": "Mein Hals, der wollte laut aufschrein,", "tokens": ["Mein", "Hals", ",", "der", "woll\u00b7te", "laut", "auf\u00b7schrein", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PRELS", "VMFIN", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Stehkragen, der sagte: nein.", "tokens": ["Der", "Steh\u00b7kra\u00b7gen", ",", "der", "sag\u00b7te", ":", "nein", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "VVFIN", "$.", "PTKANT", "$."], "meter": "-++--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.129": {"line.1": {"text": "Ich wollt' zum End' der Welt hingehn,", "tokens": ["Ich", "wollt'", "zum", "End'", "der", "Welt", "hin\u00b7gehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPRART", "NN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Doch die Galoschen blieben stehn.", "tokens": ["Doch", "die", "Ga\u00b7lo\u00b7schen", "blie\u00b7ben", "stehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.130": {"line.1": {"text": "Ich wollte rufen: nimm doch mich!", "tokens": ["Ich", "woll\u00b7te", "ru\u00b7fen", ":", "nimm", "doch", "mich", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "VVINF", "$.", "VVIMP", "ADV", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Doch tief verpackt lag still mein Ich.", "tokens": ["Doch", "tief", "ver\u00b7packt", "lag", "still", "mein", "Ich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVPP", "VVFIN", "ADJD", "PPOSAT", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.131": {"line.1": {"text": "Und da Entsagung edel klingt,", "tokens": ["Und", "da", "Ent\u00b7sa\u00b7gung", "e\u00b7del", "klingt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "NN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wenn einst davon die Nachwelt singt,", "tokens": ["Wenn", "einst", "da\u00b7von", "die", "Nach\u00b7welt", "singt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PAV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.132": {"line.1": {"text": "Lobt' ich den Freund, ganz wie ich sollte,", "tokens": ["Lobt'", "ich", "den", "Freund", ",", "ganz", "wie", "ich", "soll\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "$,", "ADV", "KOKOM", "PPER", "VMFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und wie er's ja auch haben wollte,", "tokens": ["Und", "wie", "er's", "ja", "auch", "ha\u00b7ben", "woll\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PIS", "ADV", "ADV", "VAINF", "VMFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.133": {"line.1": {"text": "Zeigt ihn in gl\u00e4nzender Parade,", "tokens": ["Zeigt", "ihn", "in", "gl\u00e4n\u00b7zen\u00b7der", "Pa\u00b7ra\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Nannte ihn meine Bundeslade.", "tokens": ["Nann\u00b7te", "ihn", "mei\u00b7ne", "Bun\u00b7des\u00b7la\u00b7de", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPOSAT", "NN", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}}, "stanza.134": {"line.1": {"text": "Ein Elefant ward aus der Laus.", "tokens": ["Ein", "E\u00b7le\u00b7fant", "ward", "aus", "der", "Laus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "K\u00f6nigin sah erstaunter aus.", "tokens": ["K\u00f6\u00b7ni\u00b7gin", "sah", "er\u00b7staun\u00b7ter", "aus", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ADJD", "PTKVZ", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.135": {"line.1": {"text": "So gern h\u00e4tt' ich getobt, verneint", "tokens": ["So", "gern", "h\u00e4tt'", "ich", "ge\u00b7tobt", ",", "ver\u00b7neint"], "token_info": ["word", "word", "word", "word", "word", "punct", "word"], "pos": ["ADV", "ADV", "VAFIN", "PPER", "VVPP", "$,", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und Balthasaren tief beweint,", "tokens": ["Und", "Balt\u00b7ha\u00b7sa\u00b7ren", "tief", "be\u00b7weint", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.136": {"line.1": {"text": "Doch \u00f6fters spiel' ich jene Rollen,", "tokens": ["Doch", "\u00f6f\u00b7ters", "spiel'", "ich", "je\u00b7ne", "Rol\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die keine andern spielen wollen,", "tokens": ["Die", "kei\u00b7ne", "an\u00b7dern", "spie\u00b7len", "wol\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "PIS", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.137": {"line.1": {"text": "Denn ich war niemals G\u00f6tterknecht:", "tokens": ["Denn", "ich", "war", "nie\u00b7mals", "G\u00f6t\u00b7ter\u00b7knecht", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "ADV", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Was ich nicht soll, tu ich erst recht.", "tokens": ["Was", "ich", "nicht", "soll", ",", "tu", "ich", "erst", "recht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "PTKNEG", "VMFIN", "$,", "VVFIN", "PPER", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.138": {"line.1": {"text": "Ich sprach dann noch: \u00bbFrau K\u00f6nigin,", "tokens": ["Ich", "sprach", "dann", "noch", ":", "\u00bb", "Frau", "K\u00f6\u00b7ni\u00b7gin", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "$.", "$(", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Gehn Sie noch heut zu P.T. hin,", "tokens": ["Gehn", "Sie", "noch", "heut", "zu", "P.", "T.", "hin", ","], "token_info": ["word", "word", "word", "word", "word", "abbreviation", "abbreviation", "word", "punct"], "pos": ["NN", "PPER", "ADV", "ADV", "APPR", "NE", "NE", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.139": {"line.1": {"text": "Und da sich noch kein andrer fand,", "tokens": ["Und", "da", "sich", "noch", "kein", "an\u00b7drer", "fand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PRF", "ADV", "PIAT", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Reichen Sie dreist ihm Ihre Hand.", "tokens": ["Rei\u00b7chen", "Sie", "dreist", "ihm", "Ih\u00b7re", "Hand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "VVFIN", "PPER", "PPOSAT", "NN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.140": {"line.1": {"text": "Verloben ist meist ein Riskieren,", "tokens": ["Ver\u00b7lo\u00b7ben", "ist", "meist", "ein", "Ris\u00b7kie\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Es wird nicht besser vom Genieren.", "tokens": ["Es", "wird", "nicht", "bes\u00b7ser", "vom", "Ge\u00b7nie\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKNEG", "ADJD", "APPRART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.141": {"line.1": {"text": "Sie sollen sich noch heut verloben, \u2013", "tokens": ["Sie", "sol\u00b7len", "sich", "noch", "heut", "ver\u00b7lo\u00b7ben", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VMFIN", "PRF", "ADV", "ADV", "VVPP", "$,", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Verzeihung, ich verga\u00df was oben.\u00ab", "tokens": ["Ver\u00b7zei\u00b7hung", ",", "ich", "ver\u00b7ga\u00df", "was", "o\u00b7ben", ".", "\u00ab"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "$,", "PPER", "VVFIN", "PWS", "ADV", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.142": {"line.1": {"text": "Leis hie\u00df ich sie so weitergehen,", "tokens": ["Leis", "hie\u00df", "ich", "sie", "so", "wei\u00b7ter\u00b7ge\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "PPER", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Denn meine Seele hatte Wehen,", "tokens": ["Denn", "mei\u00b7ne", "See\u00b7le", "hat\u00b7te", "We\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VAFIN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.143": {"line.1": {"text": "Und ich stieg schwer zu meinem Zimmer,", "tokens": ["Und", "ich", "stieg", "schwer", "zu", "mei\u00b7nem", "Zim\u00b7mer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ADJD", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die M\u00f6bel zeigten Tr\u00e4nenschimmer.", "tokens": ["Die", "M\u00f6\u00b7bel", "zeig\u00b7ten", "Tr\u00e4\u00b7nen\u00b7schim\u00b7mer", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.144": {"line.1": {"text": "Wenn sich etwas ins Aug' verirrt,", "tokens": ["Wenn", "sich", "et\u00b7was", "ins", "Aug'", "ver\u00b7irrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "ADV", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sieht man die Gegend irisiert.", "tokens": ["Sieht", "man", "die", "Ge\u00b7gend", "i\u00b7ri\u00b7siert", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.145": {"line.1": {"text": "Ich putze \u00f6fters meine Nase;", "tokens": ["Ich", "put\u00b7ze", "\u00f6f\u00b7ters", "mei\u00b7ne", "Na\u00b7se", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Kalt war sie wie 'ne Totenvase.", "tokens": ["Kalt", "war", "sie", "wie", "'ne", "To\u00b7ten\u00b7va\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "KOKOM", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.146": {"line.1": {"text": "Auch du ein Brutus, dacht' ich, Beste!", "tokens": ["Auch", "du", "ein", "Bru\u00b7tus", ",", "dacht'", "ich", ",", "Bes\u00b7te", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "PPER", "ART", "NE", "$,", "VVFIN", "PPER", "$,", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Hell sprang etwas auf meine Weste.", "tokens": ["Hell", "sprang", "et\u00b7was", "auf", "mei\u00b7ne", "Wes\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PIS", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.147": {"line.1": {"text": "Ach Leid, du bist oft menschengro\u00df,", "tokens": ["Ach", "Leid", ",", "du", "bist", "oft", "men\u00b7schen\u00b7gro\u00df", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "NN", "$,", "PPER", "VAFIN", "ADV", "ADJD", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.2": {"text": "Doch kleine Tr\u00e4nen weinst du blo\u00df,", "tokens": ["Doch", "klei\u00b7ne", "Tr\u00e4\u00b7nen", "weinst", "du", "blo\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "VVFIN", "PPER", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.148": {"line.1": {"text": "Und sieht man deinen kleinen zu,", "tokens": ["Und", "sieht", "man", "dei\u00b7nen", "klei\u00b7nen", "zu", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIS", "PPOSAT", "ADJA", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So wird man Null und bekommt Ruh'.", "tokens": ["So", "wird", "man", "Null", "und", "be\u00b7kommt", "Ruh'", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIS", "NN", "KON", "VVFIN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}