{"textgrid.poem.53135": {"metadata": {"author": {"name": "Dach, Simon", "birth": "N.A.", "death": "N.A."}, "title": "1L: Werd ich, Herr, dir auch entfallen", "genre": "verse", "period": "N.A.", "pub_year": 1632, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Werd ich, Herr, dir auch entfallen", "tokens": ["Werd", "ich", ",", "Herr", ",", "dir", "auch", "ent\u00b7fal\u00b7len"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["VAFIN", "PPER", "$,", "NN", "$,", "PPER", "ADV", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Bey der Au\u00dfgab auff Martin?", "tokens": ["Bey", "der", "Au\u00df\u00b7gab", "auff", "Mar\u00b7tin", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "NE", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.3": {"text": "La\u00df mein Gnadengeld mich ziehn,", "tokens": ["La\u00df", "mein", "Gna\u00b7den\u00b7geld", "mich", "ziehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPOSAT", "NN", "PPER", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Ich bedarff es ja f\u00fcr allen,", "tokens": ["Ich", "be\u00b7darff", "es", "ja", "f\u00fcr", "al\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "APPR", "PIAT", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Traw es mir, ich leide Noht,", "tokens": ["Traw", "es", "mir", ",", "ich", "lei\u00b7de", "Noht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PPER", "$,", "PPER", "VVFIN", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Vnd geniesse kaum noch Brod.", "tokens": ["Vnd", "ge\u00b7nies\u00b7se", "kaum", "noch", "Brod", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ADV", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Sol ich von den Schulden sagen,", "tokens": ["Sol", "ich", "von", "den", "Schul\u00b7den", "sa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Die durch Centnerschwere Last", "tokens": ["Die", "durch", "Cent\u00b7ner\u00b7schwe\u00b7re", "Last"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "APPR", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Mir nicht g\u00f6nnen Ruh noch Rast", "tokens": ["Mir", "nicht", "g\u00f6n\u00b7nen", "Ruh", "noch", "Rast"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "PTKNEG", "VVINF", "NN", "ADV", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Vnd mich n\u00e4cht- vnd t\u00e4glich nagen?", "tokens": ["Vnd", "mich", "n\u00e4cht", "vnd", "t\u00e4g\u00b7lich", "na\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "TRUNC", "KON", "ADJD", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "O ein Creutz, das hoch betr\u00fcbt", "tokens": ["O", "ein", "Creutz", ",", "das", "hoch", "be\u00b7tr\u00fcbt"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["NE", "ART", "NN", "$,", "PRELS", "ADJD", "VVPP"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Den, der Ehr vnd Tugend liebt!", "tokens": ["Den", ",", "der", "Ehr", "vnd", "Tu\u00b7gend", "liebt", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ART", "NN", "KON", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Obs vnd Laub ist von den B\u00e4umen,", "tokens": ["Obs", "vnd", "Laub", "ist", "von", "den", "B\u00e4u\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VAFIN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sturm vnd K\u00e4lte treten an,", "tokens": ["Sturm", "vnd", "K\u00e4l\u00b7te", "tre\u00b7ten", "an", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VVFIN", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Vnd der Hirt eilt, wie er kan,", "tokens": ["Vnd", "der", "Hirt", "eilt", ",", "wie", "er", "kan", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "$,", "PWAV", "PPER", "VMFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wald, Gep\u00fcsch vnd Feld zu r\u00e4umen,", "tokens": ["Wald", ",", "Ge\u00b7p\u00fcsch", "vnd", "Feld", "zu", "r\u00e4u\u00b7men", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "KON", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Ich auch gehe vor da\u00df Thor", "tokens": ["Ich", "auch", "ge\u00b7he", "vor", "da\u00df", "Thor"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "VVFIN", "APPR", "KOUS", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Nicht so offt mehr al\u00df zuvor.", "tokens": ["Nicht", "so", "offt", "mehr", "al\u00df", "zu\u00b7vor", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "ADV", "PIAT", "KOKOM", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "K\u00fcch vnd Heerdt ist zu versorgen,", "tokens": ["K\u00fcch", "vnd", "Heerdt", "ist", "zu", "ver\u00b7sor\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VAFIN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Holtz vnd Vnterhalt gebricht,", "tokens": ["Holtz", "vnd", "Vn\u00b7ter\u00b7halt", "ge\u00b7bricht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Denn von Renten leb ich nicht,", "tokens": ["Denn", "von", "Ren\u00b7ten", "leb", "ich", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "VVFIN", "PPER", "PTKNEG", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Soll ich aber weiter borgen?", "tokens": ["Soll", "ich", "a\u00b7ber", "wei\u00b7ter", "bor\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "ADV", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Besser lauff ich in der Zeit,", "tokens": ["Bes\u00b7ser", "lauff", "ich", "in", "der", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Vnd das Thor ist mir nicht weit.", "tokens": ["Vnd", "das", "Thor", "ist", "mir", "nicht", "weit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VAFIN", "PPER", "PTKNEG", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Hilff mir, Herr, au\u00df diesen N\u00f6hten", "tokens": ["Hilff", "mir", ",", "Herr", ",", "au\u00df", "die\u00b7sen", "N\u00f6h\u00b7ten"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["NN", "PPER", "$,", "NN", "$,", "APPR", "PDAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Vnd versichre dich dabey,", "tokens": ["Vnd", "ver\u00b7sich\u00b7re", "dich", "da\u00b7bey", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "PAV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df es Helden r\u00fchmlich sey", "tokens": ["Da\u00df", "es", "Hel\u00b7den", "r\u00fchm\u00b7lich", "sey"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "NN", "ADJD", "VAFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Gunst erweisen vn\u00df Poeten,", "tokens": ["Gunst", "er\u00b7wei\u00b7sen", "vn\u00df", "Po\u00b7et\u00b7en", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVINF", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Denn der Nachwelt zeig ich an", "tokens": ["Denn", "der", "Nach\u00b7welt", "zeig", "ich", "an"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "VVFIN", "PPER", "PTKVZ"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Alles, wa\u00df du mir gethan.", "tokens": ["Al\u00b7les", ",", "wa\u00df", "du", "mir", "ge\u00b7than", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "$,", "KOUS", "PPER", "PPER", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Werd ich, Herr, dir auch entfallen", "tokens": ["Werd", "ich", ",", "Herr", ",", "dir", "auch", "ent\u00b7fal\u00b7len"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["VAFIN", "PPER", "$,", "NN", "$,", "PPER", "ADV", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Bey der Au\u00dfgab auff Martin?", "tokens": ["Bey", "der", "Au\u00df\u00b7gab", "auff", "Mar\u00b7tin", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "NE", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.3": {"text": "La\u00df mein Gnadengeld mich ziehn,", "tokens": ["La\u00df", "mein", "Gna\u00b7den\u00b7geld", "mich", "ziehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPOSAT", "NN", "PPER", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Ich bedarff es ja f\u00fcr allen,", "tokens": ["Ich", "be\u00b7darff", "es", "ja", "f\u00fcr", "al\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "APPR", "PIAT", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Traw es mir, ich leide Noht,", "tokens": ["Traw", "es", "mir", ",", "ich", "lei\u00b7de", "Noht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PPER", "$,", "PPER", "VVFIN", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Vnd geniesse kaum noch Brod.", "tokens": ["Vnd", "ge\u00b7nies\u00b7se", "kaum", "noch", "Brod", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ADV", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Sol ich von den Schulden sagen,", "tokens": ["Sol", "ich", "von", "den", "Schul\u00b7den", "sa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Die durch Centnerschwere Last", "tokens": ["Die", "durch", "Cent\u00b7ner\u00b7schwe\u00b7re", "Last"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "APPR", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Mir nicht g\u00f6nnen Ruh noch Rast", "tokens": ["Mir", "nicht", "g\u00f6n\u00b7nen", "Ruh", "noch", "Rast"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "PTKNEG", "VVINF", "NN", "ADV", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Vnd mich n\u00e4cht- vnd t\u00e4glich nagen?", "tokens": ["Vnd", "mich", "n\u00e4cht", "vnd", "t\u00e4g\u00b7lich", "na\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "TRUNC", "KON", "ADJD", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "O ein Creutz, das hoch betr\u00fcbt", "tokens": ["O", "ein", "Creutz", ",", "das", "hoch", "be\u00b7tr\u00fcbt"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["NE", "ART", "NN", "$,", "PRELS", "ADJD", "VVPP"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Den, der Ehr vnd Tugend liebt!", "tokens": ["Den", ",", "der", "Ehr", "vnd", "Tu\u00b7gend", "liebt", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ART", "NN", "KON", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Obs vnd Laub ist von den B\u00e4umen,", "tokens": ["Obs", "vnd", "Laub", "ist", "von", "den", "B\u00e4u\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VAFIN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sturm vnd K\u00e4lte treten an,", "tokens": ["Sturm", "vnd", "K\u00e4l\u00b7te", "tre\u00b7ten", "an", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VVFIN", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Vnd der Hirt eilt, wie er kan,", "tokens": ["Vnd", "der", "Hirt", "eilt", ",", "wie", "er", "kan", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "$,", "PWAV", "PPER", "VMFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wald, Gep\u00fcsch vnd Feld zu r\u00e4umen,", "tokens": ["Wald", ",", "Ge\u00b7p\u00fcsch", "vnd", "Feld", "zu", "r\u00e4u\u00b7men", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "KON", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Ich auch gehe vor da\u00df Thor", "tokens": ["Ich", "auch", "ge\u00b7he", "vor", "da\u00df", "Thor"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "VVFIN", "APPR", "KOUS", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Nicht so offt mehr al\u00df zuvor.", "tokens": ["Nicht", "so", "offt", "mehr", "al\u00df", "zu\u00b7vor", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "ADV", "PIAT", "KOKOM", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "K\u00fcch vnd Heerdt ist zu versorgen,", "tokens": ["K\u00fcch", "vnd", "Heerdt", "ist", "zu", "ver\u00b7sor\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VAFIN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Holtz vnd Vnterhalt gebricht,", "tokens": ["Holtz", "vnd", "Vn\u00b7ter\u00b7halt", "ge\u00b7bricht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Denn von Renten leb ich nicht,", "tokens": ["Denn", "von", "Ren\u00b7ten", "leb", "ich", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "VVFIN", "PPER", "PTKNEG", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Soll ich aber weiter borgen?", "tokens": ["Soll", "ich", "a\u00b7ber", "wei\u00b7ter", "bor\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "ADV", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Besser lauff ich in der Zeit,", "tokens": ["Bes\u00b7ser", "lauff", "ich", "in", "der", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Vnd das Thor ist mir nicht weit.", "tokens": ["Vnd", "das", "Thor", "ist", "mir", "nicht", "weit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VAFIN", "PPER", "PTKNEG", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Hilff mir, Herr, au\u00df diesen N\u00f6hten", "tokens": ["Hilff", "mir", ",", "Herr", ",", "au\u00df", "die\u00b7sen", "N\u00f6h\u00b7ten"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["NN", "PPER", "$,", "NN", "$,", "APPR", "PDAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Vnd versichre dich dabey,", "tokens": ["Vnd", "ver\u00b7sich\u00b7re", "dich", "da\u00b7bey", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "PAV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df es Helden r\u00fchmlich sey", "tokens": ["Da\u00df", "es", "Hel\u00b7den", "r\u00fchm\u00b7lich", "sey"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "NN", "ADJD", "VAFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Gunst erweisen vn\u00df Poeten,", "tokens": ["Gunst", "er\u00b7wei\u00b7sen", "vn\u00df", "Po\u00b7et\u00b7en", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVINF", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Denn der Nachwelt zeig ich an", "tokens": ["Denn", "der", "Nach\u00b7welt", "zeig", "ich", "an"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "VVFIN", "PPER", "PTKVZ"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Alles, wa\u00df du mir gethan.", "tokens": ["Al\u00b7les", ",", "wa\u00df", "du", "mir", "ge\u00b7than", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "$,", "KOUS", "PPER", "PPER", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}