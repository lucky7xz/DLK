{"textgrid.poem.26414": {"metadata": {"author": {"name": "Dauthendey, Max", "birth": "N.A.", "death": "N.A."}, "title": "Venusinens Nachtabenteuer im Kolosseum bei der Katze Schmeichelspeichel und im Palatinum", "genre": "verse", "period": "N.A.", "pub_year": 1892, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Sp\u00e4t im Mondscheintaumel", "tokens": ["Sp\u00e4t", "im", "Mond\u00b7schein\u00b7tau\u00b7mel"], "token_info": ["word", "word", "word"], "pos": ["ADJD", "APPRART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Wandelt Venusine", "tokens": ["Wan\u00b7delt", "Ve\u00b7nu\u00b7si\u00b7ne"], "token_info": ["word", "word"], "pos": ["VVFIN", "NE"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Durch des Kolosseums", "tokens": ["Durch", "des", "Ko\u00b7los\u00b7se\u00b7ums"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Alte Prachtruine,", "tokens": ["Al\u00b7te", "Prach\u00b7tru\u00b7i\u00b7ne", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.2": {"line.1": {"text": "Geht durch Mondscheinflecken", "tokens": ["Geht", "durch", "Mond\u00b7schein\u00b7fle\u00b7cken"], "token_info": ["word", "word", "word"], "pos": ["VVFIN", "APPR", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "\u00dcber Steinkadaver,", "tokens": ["\u00dc\u00b7ber", "Stein\u00b7ka\u00b7da\u00b7ver", ","], "token_info": ["word", "word", "punct"], "pos": ["APPR", "NE", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Die voll Zeiten stecken.", "tokens": ["Die", "voll", "Zei\u00b7ten", "ste\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.3": {"line.1": {"text": "In der Kaiserloge,", "tokens": ["In", "der", "Kai\u00b7ser\u00b7lo\u00b7ge", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Wo einst Neros Tatze", "tokens": ["Wo", "einst", "Ne\u00b7ros", "Tat\u00b7ze"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "ADV", "NE", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Auf der Br\u00fcstung spielte,", "tokens": ["Auf", "der", "Br\u00fcs\u00b7tung", "spiel\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Sa\u00df da eine Katze.", "tokens": ["Sa\u00df", "da", "ei\u00b7ne", "Kat\u00b7ze", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.4": {"line.1": {"text": "Sie war vor Jahrtausend", "tokens": ["Sie", "war", "vor", "Jahr\u00b7tau\u00b7send"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "APPR", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Stolz in Rom Het\u00e4re; \u2013", "tokens": ["Stolz", "in", "Rom", "He\u00b7t\u00e4\u00b7re", ";", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "APPR", "NE", "NE", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Heute M\u00e4use mausend.", "tokens": ["Heu\u00b7te", "M\u00e4u\u00b7se", "mau\u00b7send", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "NN", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.5": {"line.1": {"text": "Venus sie zu kosen", "tokens": ["Ve\u00b7nus", "sie", "zu", "ko\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "PPER", "PTKZU", "VVINF"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Streichelt ihren R\u00fccken.", "tokens": ["Strei\u00b7chelt", "ih\u00b7ren", "R\u00fc\u00b7cken", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Doch wer kannte jemals", "tokens": ["Doch", "wer", "kann\u00b7te", "je\u00b7mals"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PWS", "VVFIN", "ADV"], "meter": "+---+-", "measure": "dactylic.init"}, "line.4": {"text": "Aller Katzen T\u00fccken!", "tokens": ["Al\u00b7ler", "Kat\u00b7zen", "T\u00fc\u00b7cken", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.6": {"line.1": {"text": "Pfauchend b\u00f6s in Miene", "tokens": ["Pfau\u00b7chend", "b\u00f6s", "in", "Mie\u00b7ne"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJD", "ADJD", "APPR", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Bei\u00dft die Katz den Daumen", "tokens": ["Bei\u00dft", "die", "Katz", "den", "Dau\u00b7men"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "NN", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Ab der Venusine.", "tokens": ["Ab", "der", "Ve\u00b7nu\u00b7si\u00b7ne", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$."], "meter": "+---+-", "measure": "dactylic.init"}}, "stanza.7": {"line.1": {"text": "W\u00fcchs er nicht der G\u00f6ttin", "tokens": ["W\u00fcchs", "er", "nicht", "der", "G\u00f6t\u00b7tin"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "PPER", "PTKNEG", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Neu nach kurzer Weile,", "tokens": ["Neu", "nach", "kur\u00b7zer", "Wei\u00b7le", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "W\u00e4r' sie nicht mehr Venus", "tokens": ["W\u00e4r'", "sie", "nicht", "mehr", "Ve\u00b7nus"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "PTKNEG", "PIAT", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Gleich nach dieser Zeile.", "tokens": ["Gleich", "nach", "die\u00b7ser", "Zei\u00b7le", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PDAT", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.8": {"line.1": {"text": "Doch er wuchs ihr wieder. \u2013", "tokens": ["Doch", "er", "wuchs", "ihr", "wie\u00b7der", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPER", "ADV", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Staunend dr\u00fcckt die Katze", "tokens": ["Stau\u00b7nend", "dr\u00fcckt", "die", "Kat\u00b7ze"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJD", "VVFIN", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Zu die Augenlider. \u2013", "tokens": ["Zu", "die", "Au\u00b7gen\u00b7li\u00b7der", ".", "\u2013"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["APPR", "ART", "NN", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.9": {"line.1": {"text": "\u00bbsag was dich so kr\u00e4nkte", "tokens": ["\u00bb", "sag", "was", "dich", "so", "kr\u00e4nk\u00b7te"], "token_info": ["punct", "word", "word", "word", "word", "word"], "pos": ["$(", "VVFIN", "PWS", "PPER", "ADV", "VVFIN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Da\u00df Du mich gebissen?\u00ab", "tokens": ["Da\u00df", "Du", "mich", "ge\u00b7bis\u00b7sen", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PPER", "PRF", "VVPP", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Fragte Venusine", "tokens": ["Frag\u00b7te", "Ve\u00b7nu\u00b7si\u00b7ne"], "token_info": ["word", "word"], "pos": ["ADJA", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Jene aufs Gewissen.", "tokens": ["Je\u00b7ne", "aufs", "Ge\u00b7wis\u00b7sen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PDAT", "APPRART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.10": {"line.1": {"text": "Diese nur miaute", "tokens": ["Die\u00b7se", "nur", "mi\u00b7au\u00b7te"], "token_info": ["word", "word", "word"], "pos": ["PDS", "ADV", "VVFIN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Und sich als Het\u00e4re", "tokens": ["Und", "sich", "als", "He\u00b7t\u00e4\u00b7re"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PRF", "KOUS", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Nicht sofort vertraute.", "tokens": ["Nicht", "so\u00b7fort", "ver\u00b7trau\u00b7te", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.11": {"line.1": {"text": "Denn die Katze f\u00fcrchtet", "tokens": ["Denn", "die", "Kat\u00b7ze", "f\u00fcrch\u00b7tet"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "VVFIN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Nichts so sehr auf Erden,", "tokens": ["Nichts", "so", "sehr", "auf", "Er\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "ADV", "ADV", "APPR", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Als heut unter Menschen", "tokens": ["Als", "heut", "un\u00b7ter", "Men\u00b7schen"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ADV", "APPR", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Nochmals Mensch zu werden.", "tokens": ["Noch\u00b7mals", "Mensch", "zu", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "PTKZU", "VAINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.12": {"line.1": {"text": "Schwieg darum verlegen,", "tokens": ["Schwieg", "da\u00b7rum", "ver\u00b7le\u00b7gen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PAV", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Lie\u00df sich nur mit M\u00fche", "tokens": ["Lie\u00df", "sich", "nur", "mit", "M\u00fc\u00b7he"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PRF", "ADV", "APPR", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Zu der Red' bewegen.", "tokens": ["Zu", "der", "Red'", "be\u00b7we\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.13": {"line.1": {"text": "\u00bbschmeichelspeichel hei\u00dfe", "tokens": ["\u00bb", "schmei\u00b7chel\u00b7spei\u00b7chel", "hei\u00b7\u00dfe"], "token_info": ["punct", "word", "word"], "pos": ["$(", "ADJD", "VVFIN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Heut' ich unter Katzen.", "tokens": ["Heut'", "ich", "un\u00b7ter", "Kat\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "APPR", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Wohn' im Kollosseum,", "tokens": ["Wohn'", "im", "Kol\u00b7los\u00b7se\u00b7um", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "$,"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "Wo mich M\u00e4uslein atzen.", "tokens": ["Wo", "mich", "M\u00e4us\u00b7lein", "at\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "NN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.14": {"line.1": {"text": "M\u00e4uslein sind wie Christen,", "tokens": ["M\u00e4us\u00b7lein", "sind", "wie", "Chris\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "KOKOM", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Die schon vor dem Tode", "tokens": ["Die", "schon", "vor", "dem", "To\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "APPR", "ART", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Dunkelleben fristen.", "tokens": ["Dun\u00b7kel\u00b7le\u00b7ben", "fris\u00b7ten", "."], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.15": {"line.1": {"text": "Sa\u00df im Kolosseum.", "tokens": ["Sa\u00df", "im", "Ko\u00b7los\u00b7se\u00b7um", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "APPRART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "War \u2013 ich darf mir's trauen,", "tokens": ["War", "\u2013", "ich", "darf", "mir's", "trau\u00b7en", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "$(", "PPER", "VMFIN", "PIS", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Heut noch laut zu sagen \u2013", "tokens": ["Heut", "noch", "laut", "zu", "sa\u00b7gen", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADJD", "PTKZU", "VVINF", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "G\u00f6ttin unter Frauen.", "tokens": ["G\u00f6t\u00b7tin", "un\u00b7ter", "Frau\u00b7en", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.16": {"line.1": {"text": "Nero selbst, der Kaiser,", "tokens": ["Ne\u00b7ro", "selbst", ",", "der", "Kai\u00b7ser", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "ADV", "$,", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Sprach bei meinem Eintritt", "tokens": ["Sprach", "bei", "mei\u00b7nem", "Ein\u00b7tritt"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "In die Loge leiser.", "tokens": ["In", "die", "Lo\u00b7ge", "lei\u00b7ser", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADJD", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.17": {"line.1": {"text": "Einen jungen Tiger", "tokens": ["Ei\u00b7nen", "jun\u00b7gen", "Ti\u00b7ger"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Hatt' ich aufgezogen.", "tokens": ["Hatt'", "ich", "auf\u00b7ge\u00b7zo\u00b7gen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Diesem Tiere war ich", "tokens": ["Die\u00b7sem", "Tie\u00b7re", "war", "ich"], "token_info": ["word", "word", "word", "word"], "pos": ["PDAT", "NN", "VAFIN", "PPER"], "meter": "+-+-++", "measure": "unknown.measure.tetra"}, "line.4": {"text": "Inbr\u00fcnstig gewogen.", "tokens": ["In\u00b7br\u00fcns\u00b7tig", "ge\u00b7wo\u00b7gen", "."], "token_info": ["word", "word", "punct"], "pos": ["ADJD", "VVPP", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.18": {"line.1": {"text": "Niemand ich mehr brauchte,", "tokens": ["Nie\u00b7mand", "ich", "mehr", "brauch\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "PPER", "ADV", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Sprang er auf mein Lager,", "tokens": ["Sprang", "er", "auf", "mein", "La\u00b7ger", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Und sein Zunglapp rauchte.", "tokens": ["Und", "sein", "Zun\u00b7glapp", "rauch\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.19": {"line.1": {"text": "Bei den Venusspielen,", "tokens": ["Bei", "den", "Ve\u00b7nus\u00b7spie\u00b7len", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Wo man auch auf Frauen", "tokens": ["Wo", "man", "auch", "auf", "Frau\u00b7en"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "PIS", "ADV", "APPR", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Geile Tiere hetzte,", "tokens": ["Gei\u00b7le", "Tie\u00b7re", "hetz\u00b7te", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "NN", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Wollt der Kaiser schauen", "tokens": ["Wollt", "der", "Kai\u00b7ser", "schau\u00b7en"], "token_info": ["word", "word", "word", "word"], "pos": ["VMFIN", "ART", "NN", "VVINF"], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.20": {"line.1": {"text": "Meinen jungen Tiger", "tokens": ["Mei\u00b7nen", "jun\u00b7gen", "Ti\u00b7ger"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "\u00dcber alle Bestien", "tokens": ["\u00dc\u00b7ber", "al\u00b7le", "Be\u00b7sti\u00b7en"], "token_info": ["word", "word", "word"], "pos": ["APPR", "PIAT", "NN"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "Als des Tages Sieger.", "tokens": ["Als", "des", "Ta\u00b7ges", "Sie\u00b7ger", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.21": {"line.1": {"text": "Herrlich war die Hitze,", "tokens": ["Herr\u00b7lich", "war", "die", "Hit\u00b7ze", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Wie mein Tiger t\u00f6tet'", "tokens": ["Wie", "mein", "Ti\u00b7ger", "t\u00f6\u00b7tet'"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "PPOSAT", "NN", "VVFIN"], "meter": "--+--+", "measure": "anapaest.di.plus"}, "line.3": {"text": "B\u00e4ren und die L\u00f6wen", "tokens": ["B\u00e4\u00b7ren", "und", "die", "L\u00f6\u00b7wen"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "KON", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Und mit Blut sich r\u00f6tet.", "tokens": ["Und", "mit", "Blut", "sich", "r\u00f6\u00b7tet", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "PRF", "VVFIN", "$."], "meter": "--+-+-", "measure": "anapaest.init"}}, "stanza.22": {"line.1": {"text": "Doch die Jungfrau'n r\u00fchrte", "tokens": ["Doch", "die", "Jung\u00b7frau'n", "r\u00fchr\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "VVFIN"], "meter": "--+-+-", "measure": "anapaest.init"}, "line.2": {"text": "Er nicht an am Kleide,", "tokens": ["Er", "nicht", "an", "am", "Klei\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKNEG", "APPR", "APPRART", "NN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Weil sein Herz mich sp\u00fcrte.", "tokens": ["Weil", "sein", "Herz", "mich", "sp\u00fcr\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "PPER", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.23": {"line.1": {"text": "Wohl gab's leises Murren,", "tokens": ["Wohl", "gab's", "lei\u00b7ses", "Mur\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADJA", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Als er sich nicht regte,", "tokens": ["Als", "er", "sich", "nicht", "reg\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "PTKNEG", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Ohne Liebesregung", "tokens": ["Oh\u00b7ne", "Lie\u00b7bes\u00b7re\u00b7gung"], "token_info": ["word", "word"], "pos": ["APPR", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "In die Sonn' sich legte,", "tokens": ["In", "die", "Sonn'", "sich", "leg\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PRF", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.24": {"line.1": {"text": "Und die Jungfrau'n schonte,", "tokens": ["Und", "die", "Jung\u00b7frau'n", "schon\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "$,"], "meter": "--+-+-", "measure": "anapaest.init"}, "line.2": {"text": "Auf zur Loge blinzelt,", "tokens": ["Auf", "zur", "Lo\u00b7ge", "blin\u00b7zelt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "APPRART", "NN", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Wo ich Beifall lohnte.", "tokens": ["Wo", "ich", "Bei\u00b7fall", "lohn\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "NN", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.25": {"line.1": {"text": "Wenn ein Tier nicht h\u00f6rte,", "tokens": ["Wenn", "ein", "Tier", "nicht", "h\u00f6r\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "PTKNEG", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Mu\u00dft' man's t\u00f6ten lassen.", "tokens": ["Mu\u00dft'", "man's", "t\u00f6\u00b7ten", "las\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIS", "VVINF", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Niemand dachte diesmal", "tokens": ["Nie\u00b7mand", "dach\u00b7te", "dies\u00b7mal"], "token_info": ["word", "word", "word"], "pos": ["PIS", "VVFIN", "ADV"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "Den Entschlu\u00df zu fassen.", "tokens": ["Den", "Ent\u00b7schlu\u00df", "zu", "fas\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKZU", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.26": {"line.1": {"text": "Alles klatscht aufs Neue,", "tokens": ["Al\u00b7les", "klatscht", "aufs", "Neu\u00b7e", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "APPRART", "ADJA", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Lacht nach meiner Loge,", "tokens": ["Lacht", "nach", "mei\u00b7ner", "Lo\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Gratuliert zur Treue.", "tokens": ["Gra\u00b7tu\u00b7liert", "zur", "Treu\u00b7e", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "APPRART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.27": {"line.1": {"text": "Nur der Sitte wegen", "tokens": ["Nur", "der", "Sit\u00b7te", "we\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "APPR"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Sprangen Gladiatoren", "tokens": ["Spran\u00b7gen", "Gla\u00b7di\u00b7a\u00b7to\u00b7ren"], "token_info": ["word", "word"], "pos": ["NN", "NN"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.3": {"text": "Hin zu meinem Tiger,", "tokens": ["Hin", "zu", "mei\u00b7nem", "Ti\u00b7ger", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Fa\u00dften seine Ohren.", "tokens": ["Fa\u00df\u00b7ten", "sei\u00b7ne", "Oh\u00b7ren", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.28": {"line.1": {"text": "Schauten nach der Mitte", "tokens": ["Schau\u00b7ten", "nach", "der", "Mit\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "APPR", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Auf die Kaiserloge,", "tokens": ["Auf", "die", "Kai\u00b7ser\u00b7lo\u00b7ge", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Denn auch das war Sitte.", "tokens": ["Denn", "auch", "das", "war", "Sit\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PDS", "VAFIN", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.29": {"line.1": {"text": "Hob sich Nero's Daumen,", "tokens": ["Hob", "sich", "Nero's", "Dau\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "NE", "NN", "$,"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Hie\u00df das: la\u00dft ihn leben!", "tokens": ["Hie\u00df", "das", ":", "la\u00dft", "ihn", "le\u00b7ben", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "$(", "VVIMP", "PPER", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Senkt' er ihn, so konnte", "tokens": ["Senkt'", "er", "ihn", ",", "so", "konn\u00b7te"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["VVFIN", "PPER", "PPER", "$,", "ADV", "VMFIN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Man den Tod gleich geben.", "tokens": ["Man", "den", "Tod", "gleich", "ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "ART", "NN", "ADV", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.30": {"line.1": {"text": "Doch auch Vesta's Frauen", "tokens": ["Doch", "auch", "Ve\u00b7sta's", "Frau\u00b7en"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ADV", "NE", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Hattens Recht der Daumen \u2013", "tokens": ["Hat\u00b7tens", "Recht", "der", "Dau\u00b7men", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "ART", "NN", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Nie war dort zu trauen.", "tokens": ["Nie", "war", "dort", "zu", "trau\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "PTKZU", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.31": {"line.1": {"text": "Nero hebt den Daumen", "tokens": ["Ne\u00b7ro", "hebt", "den", "Dau\u00b7men"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "VVFIN", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Und entl\u00e4\u00dft den Tiger.", "tokens": ["Und", "ent\u00b7l\u00e4\u00dft", "den", "Ti\u00b7ger", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Beifall br\u00fcllts Geb\u00e4ude", "tokens": ["Bei\u00b7fall", "br\u00fcllts", "Ge\u00b7b\u00e4u\u00b7de"], "token_info": ["word", "word", "word"], "pos": ["PIAT", "ADJA", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Meinem flotten Sieger.", "tokens": ["Mei\u00b7nem", "flot\u00b7ten", "Sie\u00b7ger", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.32": {"line.1": {"text": "Doch ich mit Erbleichen", "tokens": ["Doch", "ich", "mit", "Er\u00b7blei\u00b7chen"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PPER", "APPR", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Seh': die Priesterinnen", "tokens": ["Seh'", ":", "die", "Pries\u00b7te\u00b7rin\u00b7nen"], "token_info": ["word", "punct", "word", "word"], "pos": ["VVFIN", "$.", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Gebens Todeszeichen, \u2013", "tokens": ["Ge\u00b7bens", "To\u00b7des\u00b7zei\u00b7chen", ",", "\u2013"], "token_info": ["word", "word", "punct", "punct"], "pos": ["NN", "NN", "$,", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.33": {"line.1": {"text": "Senken ihre Daumen, \u2013", "tokens": ["Sen\u00b7ken", "ih\u00b7re", "Dau\u00b7men", ",", "\u2013"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["NN", "PPOSAT", "NN", "$,", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Und die Schwerter blinken.", "tokens": ["Und", "die", "Schwer\u00b7ter", "blin\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Wie ein Lamm so schuldlos", "tokens": ["Wie", "ein", "Lamm", "so", "schuld\u00b7los"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "ART", "NN", "ADV", "ADJD"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "Mu\u00dft' mein Tiger sinken.", "tokens": ["Mu\u00dft'", "mein", "Ti\u00b7ger", "sin\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPOSAT", "NN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.34": {"line.1": {"text": "Einen Schrei zerknicke", "tokens": ["Ei\u00b7nen", "Schrei", "zer\u00b7kni\u00b7cke"], "token_info": ["word", "word", "word"], "pos": ["ART", "NN", "VVFIN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Ich im Halse, st\u00fcrze,", "tokens": ["Ich", "im", "Hal\u00b7se", ",", "st\u00fcr\u00b7ze", ","], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "APPRART", "NN", "$,", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Brech' mir das Genicke.", "tokens": ["Brech'", "mir", "das", "Ge\u00b7ni\u00b7cke", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.35": {"line.1": {"text": "Kann's noch nicht vertragen,", "tokens": ["Kann's", "noch", "nicht", "ver\u00b7tra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "PTKNEG", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Heut nach Tausend Jahren:", "tokens": ["Heut", "nach", "Tau\u00b7send", "Jah\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "CARD", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "F\u00fchl' ich einen Daumen", "tokens": ["F\u00fchl'", "ich", "ei\u00b7nen", "Dau\u00b7men"], "token_info": ["word", "word", "word", "word"], "pos": ["VVIMP", "PPER", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "\u00dcber meinen Haaren,", "tokens": ["\u00dc\u00b7ber", "mei\u00b7nen", "Haa\u00b7ren", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.36": {"line.1": {"text": "Weckt mich Brunst zum Tiger,", "tokens": ["Weckt", "mich", "Brunst", "zum", "Ti\u00b7ger", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "APPRART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Den ich einst umhalste, \u2013", "tokens": ["Den", "ich", "einst", "um\u00b7hals\u00b7te", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "PPER", "ADV", "VVFIN", "$,", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Ewig bleibt er Sieger.\u00ab", "tokens": ["E\u00b7wig", "bleibt", "er", "Sie\u00b7ger", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VVFIN", "PPER", "NN", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.37": {"line.1": {"text": "\u00bbschmeichelspeichel, h\u00f6re:", "tokens": ["\u00bb", "schmei\u00b7chel\u00b7spei\u00b7chel", ",", "h\u00f6\u00b7re", ":"], "token_info": ["punct", "word", "punct", "word", "punct"], "pos": ["$(", "ADJD", "$,", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Trugst Du niemals wieder", "tokens": ["Trugst", "Du", "nie\u00b7mals", "wie\u00b7der"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "ADV"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Seit den Heidenzeiten", "tokens": ["Seit", "den", "Hei\u00b7den\u00b7zei\u00b7ten"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Neue Menschenglieder?", "tokens": ["Neu\u00b7e", "Men\u00b7schen\u00b7glie\u00b7der", "?"], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.38": {"line.1": {"text": "Dieses m\u00f6cht' ich fragen,", "tokens": ["Die\u00b7ses", "m\u00f6cht'", "ich", "fra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PPER", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Wenn Erinnerungen", "tokens": ["Wenn", "E\u00b7rin\u00b7ne\u00b7run\u00b7gen"], "token_info": ["word", "word"], "pos": ["KOUS", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Deine Ruh nicht plagen?\u00ab", "tokens": ["Dei\u00b7ne", "Ruh", "nicht", "pla\u00b7gen", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["PPOSAT", "NN", "PTKNEG", "VVFIN", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.39": {"line.1": {"text": "\u00bbach, die neuen Zeiten,\u00ab", "tokens": ["\u00bb", "ach", ",", "die", "neu\u00b7en", "Zei\u00b7ten", ",", "\u00ab"], "token_info": ["punct", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ITJ", "$,", "ART", "ADJA", "NN", "$,", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Sprach gedehnt die Katze,", "tokens": ["Sprach", "ge\u00b7dehnt", "die", "Kat\u00b7ze", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVPP", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Und sie schnitt zum Monde", "tokens": ["Und", "sie", "schnitt", "zum", "Mon\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "APPRART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Spuckend eine Fratze,", "tokens": ["Spu\u00b7ckend", "ei\u00b7ne", "Frat\u00b7ze", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.40": {"line.1": {"text": "\u00bbsind nicht das auf Erden.", "tokens": ["\u00bb", "sind", "nicht", "das", "auf", "Er\u00b7den", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VAFIN", "PTKNEG", "ART", "APPR", "NN", "$."], "meter": "--+-+-", "measure": "anapaest.init"}, "line.2": {"text": "War noch einmal Menschin,", "tokens": ["War", "noch", "ein\u00b7mal", "Men\u00b7schin", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "NN", "$,"], "meter": "-++-+-", "measure": "unknown.measure.tri"}, "line.3": {"text": "M\u00f6cht's nicht nochmals werden.", "tokens": ["M\u00f6cht's", "nicht", "noch\u00b7mals", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "PTKNEG", "ADV", "VAINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.41": {"line.1": {"text": "Sa\u00df in Hintergassen,", "tokens": ["Sa\u00df", "in", "Hin\u00b7ter\u00b7gas\u00b7sen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Nicht mehr in Pal\u00e4sten.", "tokens": ["Nicht", "mehr", "in", "Pa\u00b7l\u00e4s\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "APPR", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Sittenpolizisten", "tokens": ["Sit\u00b7ten\u00b7po\u00b7li\u00b7zis\u00b7ten"], "token_info": ["word"], "pos": ["NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Jetzt die Luft verpesten.", "tokens": ["Jetzt", "die", "Luft", "ver\u00b7pes\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.42": {"line.1": {"text": "Und die Lieb' konnt' nimmer", "tokens": ["Und", "die", "Lieb'", "konnt'", "nim\u00b7mer"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "VMFIN", "ADV"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Niemals richtig bl\u00fchen,", "tokens": ["Nie\u00b7mals", "rich\u00b7tig", "bl\u00fc\u00b7hen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "\u00c4ngstlich war man immer.", "tokens": ["\u00c4ngst\u00b7lich", "war", "man", "im\u00b7mer", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "PIS", "ADV", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.43": {"line.1": {"text": "Niedrig war mein Wirken.", "tokens": ["Nied\u00b7rig", "war", "mein", "Wir\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "PPOSAT", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.44": {"line.1": {"text": "Und ich stahl mir Leben,", "tokens": ["Und", "ich", "stahl", "mir", "Le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPER", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Wie und wo ich konnte;", "tokens": ["Wie", "und", "wo", "ich", "konn\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "KON", "PWAV", "PPER", "VMFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Eckel sa\u00df daneben.", "tokens": ["E\u00b7ckel", "sa\u00df", "da\u00b7ne\u00b7ben", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PAV", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.45": {"line.1": {"text": "Eckel vor den Menschen", "tokens": ["E\u00b7ckel", "vor", "den", "Men\u00b7schen"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "APPR", "ART", "NN"], "meter": "----+-", "measure": "unknown.measure.single"}, "line.2": {"text": "Hat mich nicht verlassen,", "tokens": ["Hat", "mich", "nicht", "ver\u00b7las\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PTKNEG", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Die den Leib, der liebte,", "tokens": ["Die", "den", "Leib", ",", "der", "lieb\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "$,", "PRELS", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Spotteten und hassen.", "tokens": ["Spot\u00b7te\u00b7ten", "und", "has\u00b7sen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.46": {"line.1": {"text": "Leidenschaft tat fehlen.", "tokens": ["Lei\u00b7den\u00b7schaft", "tat", "feh\u00b7len", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ADJD", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Heut die \u00e4rmsten Leute", "tokens": ["Heut", "die", "\u00e4rms\u00b7ten", "Leu\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ART", "ADJA", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Br\u00fcsten sich mit Seelen.", "tokens": ["Br\u00fcs\u00b7ten", "sich", "mit", "See\u00b7len", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "APPR", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.47": {"line.1": {"text": "Konnte nie mehr lieben.", "tokens": ["Konn\u00b7te", "nie", "mehr", "lie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "ADV", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Unter meinen G\u00e4sten", "tokens": ["Un\u00b7ter", "mei\u00b7nen", "G\u00e4s\u00b7ten"], "token_info": ["word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "War ein Offizierlein,", "tokens": ["War", "ein", "Of\u00b7fi\u00b7zier\u00b7lein", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "$,"], "meter": "--+--+", "measure": "anapaest.di.plus"}, "line.4": {"text": "Einer von den Besten.", "tokens": ["Ei\u00b7ner", "von", "den", "Bes\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "APPR", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.48": {"line.1": {"text": "Ohne mir's zu sagen,", "tokens": ["Oh\u00b7ne", "mir's", "zu", "sa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Tat er'n Abschied nehmen \u2013", "tokens": ["Tat", "er'n", "Ab\u00b7schied", "neh\u00b7men", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADJA", "NN", "VVINF", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Konnt' mich doch erst fragen.", "tokens": ["Konnt'", "mich", "doch", "erst", "fra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "ADV", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.49": {"line.1": {"text": "Kommt da eines Abends", "tokens": ["Kommt", "da", "ei\u00b7nes", "A\u00b7bends"], "token_info": ["word", "word", "word", "word"], "pos": ["VVIMP", "ADV", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Ohne Epauletten,", "tokens": ["Oh\u00b7ne", "E\u00b7pau\u00b7let\u00b7ten", ","], "token_info": ["word", "word", "punct"], "pos": ["APPR", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "War Zivil geworden, \u2013", "tokens": ["War", "Zi\u00b7vil", "ge\u00b7wor\u00b7den", ",", "\u2013"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["VAFIN", "NN", "VAPP", "$,", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Nichts war mehr zu retten.", "tokens": ["Nichts", "war", "mehr", "zu", "ret\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.50": {"line.1": {"text": "Sagte: ", "tokens": ["Sag\u00b7te", ":"], "token_info": ["word", "punct"], "pos": ["VVFIN", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.2": {"text": "Da\u00df sein Weib ich w\u00fcrde,", "tokens": ["Da\u00df", "sein", "Weib", "ich", "w\u00fcr\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "PPER", "VAFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Schied er von dem Degen.", "tokens": ["Schied", "er", "von", "dem", "De\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.51": {"line.1": {"text": "Nichts war mehr am Menschen,", "tokens": ["Nichts", "war", "mehr", "am", "Men\u00b7schen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "ADV", "APPRART", "NN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Als er seine Seele", "tokens": ["Als", "er", "sei\u00b7ne", "See\u00b7le"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PPOSAT", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Ohne Schneid und Degen", "tokens": ["Oh\u00b7ne", "Schneid", "und", "De\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Anbot mit Gequ\u00e4le.", "tokens": ["An\u00b7bot", "mit", "Ge\u00b7qu\u00e4\u00b7le", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.52": {"line.1": {"text": "Kannte nie die Frauen,", "tokens": ["Kann\u00b7te", "nie", "die", "Frau\u00b7en", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Die erst auf die ", "tokens": ["Die", "erst", "auf", "die"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADV", "APPR", "ART"], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "Dann auf ", "tokens": ["Dann", "auf"], "token_info": ["word", "word"], "pos": ["ADV", "APPR"], "meter": "-+", "measure": "iambic.single"}}, "stanza.53": {"line.1": {"text": "Hat sich auch erschossen \u2013", "tokens": ["Hat", "sich", "auch", "er\u00b7schos\u00b7sen", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PRF", "ADV", "VVPP", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Gleich sind sie beim Tode \u2013", "tokens": ["Gleich", "sind", "sie", "beim", "To\u00b7de", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "APPRART", "NN", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Fl\u00fcchten in die Gr\u00e4ber.", "tokens": ["Fl\u00fcch\u00b7ten", "in", "die", "Gr\u00e4\u00b7ber", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Allgemein ist's Mode.", "tokens": ["All\u00b7ge\u00b7mein", "ist's", "Mo\u00b7de", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.54": {"line.1": {"text": "Fr\u00fcher nur die Schlemmer", "tokens": ["Fr\u00fc\u00b7her", "nur", "die", "Schlem\u00b7mer"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "ADV", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Gift zum Nachtisch nahmen \u2013", "tokens": ["Gift", "zum", "Nach\u00b7tisch", "nah\u00b7men", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPRART", "NN", "VVFIN", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Jetzt tut's jeder Kr\u00e4mer.\u00ab", "tokens": ["Jetzt", "tut's", "je\u00b7der", "Kr\u00e4\u00b7mer", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VVFIN", "PIAT", "NN", "$.", "$("], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.55": {"line.1": {"text": "Venus h\u00f6rt nicht l\u00e4nger,", "tokens": ["Ve\u00b7nus", "h\u00f6rt", "nicht", "l\u00e4n\u00b7ger", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PTKNEG", "ADJD", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Was die Katze wu\u00dfte,", "tokens": ["Was", "die", "Kat\u00b7ze", "wu\u00df\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Weil ihr Ohr in Spannung", "tokens": ["Weil", "ihr", "Ohr", "in", "Span\u00b7nung"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPOSAT", "NN", "APPR", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Anderm lauschen mu\u00dfte.", "tokens": ["An\u00b7derm", "lau\u00b7schen", "mu\u00df\u00b7te", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PIS", "VVINF", "VMFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.56": {"line.1": {"text": "Durch die Nacht drang Schreien", "tokens": ["Durch", "die", "Nacht", "drang", "Schrei\u00b7en"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "VVFIN", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Nah vom Palatinum,", "tokens": ["Nah", "vom", "Pa\u00b7la\u00b7ti\u00b7num", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPRART", "NN", "$,"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.3": {"text": "Wie ein Kampf von Zweien.", "tokens": ["Wie", "ein", "Kampf", "von", "Zwei\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "APPR", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.57": {"line.1": {"text": "Eine M\u00e4dchenstimme,", "tokens": ["Ei\u00b7ne", "M\u00e4d\u00b7chen\u00b7stim\u00b7me", ","], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Eines Mannes Toben,", "tokens": ["Ei\u00b7nes", "Man\u00b7nes", "To\u00b7ben", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Und die Sterne zittern", "tokens": ["Und", "die", "Ster\u00b7ne", "zit\u00b7tern"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "VVINF"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "In dem Himmel oben.", "tokens": ["In", "dem", "Him\u00b7mel", "o\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADV", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.58": {"line.1": {"text": "Scheu durch die Ruinen", "tokens": ["Scheu", "durch", "die", "Ru\u00b7i\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "APPR", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Flieht die R\u00f6merkatze", "tokens": ["Flieht", "die", "R\u00f6\u00b7mer\u00b7kat\u00b7ze"], "token_info": ["word", "word", "word"], "pos": ["VVFIN", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Fort von Venusinen.", "tokens": ["Fort", "von", "Ve\u00b7nu\u00b7si\u00b7nen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "$."], "meter": "+-----", "measure": "dactylic.init"}}, "stanza.59": {"line.1": {"text": "Alle Quadern kriegen", "tokens": ["Al\u00b7le", "Qua\u00b7dern", "krie\u00b7gen"], "token_info": ["word", "word", "word"], "pos": ["PIAT", "NN", "VVINF"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Menschliche Gesichter,", "tokens": ["Menschli\u00b7che", "Ge\u00b7sich\u00b7ter", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$,"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Und sie alle r\u00fccken", "tokens": ["Und", "sie", "al\u00b7le", "r\u00fc\u00b7cken"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PPER", "PIS", "VVINF"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Unterm Moose dichter.", "tokens": ["Un\u00b7term", "Moo\u00b7se", "dich\u00b7ter."], "token_info": ["word", "word", "abbreviation"], "pos": ["PPOSAT", "NN", "NE"], "meter": "+-+-", "measure": "trochaic.di"}}, "stanza.60": {"line.1": {"text": "Venusine ahnte,", "tokens": ["Ve\u00b7nu\u00b7si\u00b7ne", "ahn\u00b7te", ","], "token_info": ["word", "word", "punct"], "pos": ["NE", "VVFIN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Da\u00df sich dort ein dunkel", "tokens": ["Da\u00df", "sich", "dort", "ein", "dun\u00b7kel"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PRF", "ADV", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Schicksal Wege bahnte.", "tokens": ["Schick\u00b7sal", "We\u00b7ge", "bahn\u00b7te", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "NN", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.61": {"line.1": {"text": "Mond hing wie die Perlen,", "tokens": ["Mond", "hing", "wie", "die", "Per\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "KOKOM", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Welche Tr\u00e4nen bringen,", "tokens": ["Wel\u00b7che", "Tr\u00e4\u00b7nen", "brin\u00b7gen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PWAT", "NN", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "\u00dcberm Sack des Dunkels,", "tokens": ["\u00dc\u00b7berm", "Sack", "des", "Dun\u00b7kels", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Drinnen Schreie ringen.", "tokens": ["Drin\u00b7nen", "Schrei\u00b7e", "rin\u00b7gen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.62": {"line.1": {"text": "Venus eilte schneller", "tokens": ["Ve\u00b7nus", "eil\u00b7te", "schnel\u00b7ler"], "token_info": ["word", "word", "word"], "pos": ["NE", "VVFIN", "ADJA"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Zum Palatiumh\u00fcgel,", "tokens": ["Zum", "Pa\u00b7la\u00b7ti\u00b7um\u00b7h\u00fc\u00b7gel", ","], "token_info": ["word", "word", "punct"], "pos": ["APPRART", "NN", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.3": {"text": "Der ein Haufen Keller.", "tokens": ["Der", "ein", "Hau\u00b7fen", "Kel\u00b7ler", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.63": {"line.1": {"text": "Fiebrig stinkt dort Erde", "tokens": ["Fieb\u00b7rig", "stinkt", "dort", "Er\u00b7de"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJD", "VVFIN", "ADV", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Unter Mosaiken,", "tokens": ["Un\u00b7ter", "Mo\u00b7sai\u00b7ken", ","], "token_info": ["word", "word", "punct"], "pos": ["APPR", "NN", "$,"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Die wie bunte Augen", "tokens": ["Die", "wie", "bun\u00b7te", "Au\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "KOKOM", "ADJA", "NN"], "meter": "--+-+-", "measure": "anapaest.init"}, "line.4": {"text": "Toter Freude blicken.", "tokens": ["To\u00b7ter", "Freu\u00b7de", "bli\u00b7cken", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.64": {"line.1": {"text": "Wo einst Duft von \u00d6len", "tokens": ["Wo", "einst", "Duft", "von", "\u00d6\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "ADV", "NN", "APPR", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Und von Narden rauchte,", "tokens": ["Und", "von", "Nar\u00b7den", "rauch\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Stehn verpestet H\u00f6hlen.", "tokens": ["Stehn", "ver\u00b7pes\u00b7tet", "H\u00f6h\u00b7len", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.65": {"line.1": {"text": "Venus sucht und findet", "tokens": ["Ve\u00b7nus", "sucht", "und", "fin\u00b7det"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "VVFIN", "KON", "VVFIN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Nur vom Kampf die Schreie.", "tokens": ["Nur", "vom", "Kampf", "die", "Schrei\u00b7e", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Selbst dem G\u00f6tterauge", "tokens": ["Selbst", "dem", "G\u00f6t\u00b7ter\u00b7au\u00b7ge"], "token_info": ["word", "word", "word"], "pos": ["ADV", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.66": {"line.1": {"text": "K\u00e4mpfen, denkt die Venus,", "tokens": ["K\u00e4mp\u00b7fen", ",", "denkt", "die", "Ve\u00b7nus", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "ART", "NN", "$,"], "meter": "+-+--+", "measure": "iambic.tri.chol"}}, "stanza.67": {"line.1": {"text": "Jeder Gott auf Erden", "tokens": ["Je\u00b7der", "Gott", "auf", "Er\u00b7den"], "token_info": ["word", "word", "word", "word"], "pos": ["PIAT", "NN", "APPR", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Und auch G\u00f6tterfrauen", "tokens": ["Und", "auch", "G\u00f6t\u00b7ter\u00b7frau\u00b7en"], "token_info": ["word", "word", "word"], "pos": ["KON", "ADV", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "K\u00f6nnen Unsichtbarstes,", "tokens": ["K\u00f6n\u00b7nen", "Un\u00b7sicht\u00b7bars\u00b7tes", ","], "token_info": ["word", "word", "punct"], "pos": ["VMFIN", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Sichtbar machend, schauen.", "tokens": ["Sicht\u00b7bar", "ma\u00b7chend", ",", "schau\u00b7en", "."], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["ADJD", "VVPP", "$,", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.68": {"line.1": {"text": "Ebenso der ", "tokens": ["E\u00b7ben\u00b7so", "der"], "token_info": ["word", "word"], "pos": ["ADV", "ART"], "meter": "+-+-", "measure": "trochaic.di"}, "line.2": {"text": "Der sich ehrlich schindet.", "tokens": ["Der", "sich", "ehr\u00b7lich", "schin\u00b7det", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "ADJD", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.69": {"line.1": {"text": "Um sich je zu zeigen.", "tokens": ["Um", "sich", "je", "zu", "zei\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PRF", "ADV", "PTKZU", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Und von jeher eigen.", "tokens": ["Und", "von", "je\u00b7her", "ei\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ADV", "ADJD", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.70": {"line.1": {"text": "\u00dcber ihr Bestehen", "tokens": ["\u00dc\u00b7ber", "ihr", "Be\u00b7ste\u00b7hen"], "token_info": ["word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Oft die G\u00f6tter zweifeln,", "tokens": ["Oft", "die", "G\u00f6t\u00b7ter", "zwei\u00b7feln", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.71": {"line.1": {"text": "Venus sucht und findet,", "tokens": ["Ve\u00b7nus", "sucht", "und", "fin\u00b7det", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Wo der Kampf statthatte,", "tokens": ["Wo", "der", "Kampf", "statt\u00b7hat\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Von der armen Psyche", "tokens": ["Von", "der", "ar\u00b7men", "Psy\u00b7che"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Was vom Feigenblatte.", "tokens": ["Was", "vom", "Fei\u00b7gen\u00b7blat\u00b7te", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PWS", "APPRART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.72": {"line.1": {"text": "Und auf einem Sockel", "tokens": ["Und", "auf", "ei\u00b7nem", "So\u00b7ckel"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Lag vom Teufel schneidig,", "tokens": ["Lag", "vom", "Teu\u00b7fel", "schnei\u00b7dig", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPRART", "NN", "ADJD", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Heil auch, das Monokel.", "tokens": ["Heil", "auch", ",", "das", "Mo\u00b7no\u00b7kel", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "ADV", "$,", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.73": {"line.1": {"text": "\u00bbfr\u00e4ulein!\u00ab schrie der Teufel,", "tokens": ["\u00bb", "fr\u00e4u\u00b7lein", "!", "\u00ab", "schrie", "der", "Teu\u00b7fel", ","], "token_info": ["punct", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PTKVZ", "$.", "$(", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "\u00bbanstand hatt' ich leider.", "tokens": ["\u00bb", "an\u00b7stand", "hatt'", "ich", "lei\u00b7der", "."], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "VAFIN", "PPER", "ADV", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Trug zum Stelldicheine", "tokens": ["Trug", "zum", "Stell\u00b7dich\u00b7ei\u00b7ne"], "token_info": ["word", "word", "word"], "pos": ["NN", "APPRART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Strikt hier meine Kleider.", "tokens": ["Strikt", "hier", "mei\u00b7ne", "Klei\u00b7der", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PPOSAT", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.74": {"line.1": {"text": "Wenn sie ohne gehen,", "tokens": ["Wenn", "sie", "oh\u00b7ne", "ge\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Weckt das meine Wollust \u2013", "tokens": ["Weckt", "das", "mei\u00b7ne", "Wol\u00b7lust", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "PPOSAT", "NN", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Was sollt' sonst geschehen?\u00ab", "tokens": ["Was", "sollt'", "sonst", "ge\u00b7sche\u00b7hen", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["PWS", "VMFIN", "ADV", "VVPP", "$.", "$("], "meter": "++--+-", "measure": "trochaic.tri.relaxed"}}, "stanza.75": {"line.1": {"text": "Darauf schrie die Psyche:", "tokens": ["Da\u00b7rauf", "schrie", "die", "Psy\u00b7che", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "ART", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "\u00bballes ist gelogen!", "tokens": ["\u00bb", "al\u00b7les", "ist", "ge\u00b7lo\u00b7gen", "!"], "token_info": ["punct", "word", "word", "word", "punct"], "pos": ["$(", "PIS", "VAFIN", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Hab mich f\u00fcr die Sch\u00f6nheit", "tokens": ["Hab", "mich", "f\u00fcr", "die", "Sch\u00f6n\u00b7heit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "PPER", "APPR", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Einzig ausgezogen.", "tokens": ["Ein\u00b7zig", "aus\u00b7ge\u00b7zo\u00b7gen", "."], "token_info": ["word", "word", "punct"], "pos": ["ADJD", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.76": {"line.1": {"text": "Sie sind eben wilder,", "tokens": ["Sie", "sind", "e\u00b7ben", "wil\u00b7der", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJA", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Leben nur dem Fleische,", "tokens": ["Le\u00b7ben", "nur", "dem", "Flei\u00b7sche", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Nicht f\u00fcr Kunst und Bilder.\u00ab", "tokens": ["Nicht", "f\u00fcr", "Kunst", "und", "Bil\u00b7der", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PTKNEG", "APPR", "NN", "KON", "NN", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.77": {"line.1": {"text": "\u00bbteufel!\u00ab schrie der Teufel,", "tokens": ["\u00bb", "teu\u00b7fel", "!", "\u00ab", "schrie", "der", "Teu\u00b7fel", ","], "token_info": ["punct", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "NE", "$.", "$(", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "\u00bbwenn Sie mich doch kennen,", "tokens": ["\u00bb", "wenn", "Sie", "mich", "doch", "ken\u00b7nen", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "PPER", "PRF", "ADV", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Wundert's mich im Stillen,", "tokens": ["Wun\u00b7dert's", "mich", "im", "Stil\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPRART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Da\u00df Sie nach mir rennen!\u00ab", "tokens": ["Da\u00df", "Sie", "nach", "mir", "ren\u00b7nen", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PPER", "APPR", "PPER", "VVFIN", "$.", "$("], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.78": {"line.1": {"text": "\u00bbbin ich Kuh mit Eutern", "tokens": ["\u00bb", "bin", "ich", "Kuh", "mit", "Eu\u00b7tern"], "token_info": ["punct", "word", "word", "word", "word", "word"], "pos": ["$(", "VAFIN", "PPER", "NN", "APPR", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Die man packt?\u00ab schrie Psyche.", "tokens": ["Die", "man", "packt", "?", "\u00ab", "schrie", "Psy\u00b7che", "."], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["ART", "PIS", "VVFIN", "$.", "$(", "VVFIN", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "\u00bbnur Dich wollt' ich l\u00e4utern!\u00ab", "tokens": ["\u00bb", "nur", "Dich", "wollt'", "ich", "l\u00e4u\u00b7tern", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADV", "PPER", "VMFIN", "PPER", "VVINF", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.79": {"line.1": {"text": "\u00bbnun von Ihren Eutern", "tokens": ["\u00bb", "nun", "von", "Ih\u00b7ren", "Eu\u00b7tern"], "token_info": ["punct", "word", "word", "word", "word"], "pos": ["$(", "ADV", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "War nicht viel zu merken.", "tokens": ["War", "nicht", "viel", "zu", "mer\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PTKNEG", "ADV", "PTKZU", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Nicht mal eine Fliege", "tokens": ["Nicht", "mal", "ei\u00b7ne", "Flie\u00b7ge"], "token_info": ["word", "word", "word", "word"], "pos": ["PTKNEG", "ADV", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "K\u00f6nnte sich dran st\u00e4rken.", "tokens": ["K\u00f6nn\u00b7te", "sich", "dran", "st\u00e4r\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PRF", "PAV", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.80": {"line.1": {"text": "Sch\u00f6nheit soll nicht leiden:", "tokens": ["Sch\u00f6n\u00b7heit", "soll", "nicht", "lei\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "PTKNEG", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Werde mich jetzt l\u00e4utern", "tokens": ["Wer\u00b7de", "mich", "jetzt", "l\u00e4u\u00b7tern"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "ADV", "VVINF"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Und mich auch entkleiden.", "tokens": ["Und", "mich", "auch", "ent\u00b7klei\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ADV", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.81": {"line.1": {"text": "Wenn die Damen nackend", "tokens": ["Wenn", "die", "Da\u00b7men", "na\u00b7ckend"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "VVPP"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "F\u00fcr die Kunst einstehen,", "tokens": ["F\u00fcr", "die", "Kunst", "ein\u00b7ste\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVIZU", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Warum sollen M\u00e4nner", "tokens": ["Wa\u00b7rum", "sol\u00b7len", "M\u00e4n\u00b7ner"], "token_info": ["word", "word", "word"], "pos": ["PWAV", "PIAT", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "H\u00e4\u00dflichkeit begehen?", "tokens": ["H\u00e4\u00df\u00b7lich\u00b7keit", "be\u00b7ge\u00b7hen", "?"], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.82": {"line.1": {"text": "M\u00e4nnerbrust und Nacken", "tokens": ["M\u00e4n\u00b7ner\u00b7brust", "und", "Na\u00b7cken"], "token_info": ["word", "word", "word"], "pos": ["NN", "KON", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "K\u00f6nnen auch erbauen. \u2013", "tokens": ["K\u00f6n\u00b7nen", "auch", "er\u00b7bau\u00b7en", ".", "\u2013"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["VMFIN", "ADV", "VVINF", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Soll ich mehr auspacken?\u00ab", "tokens": ["Soll", "ich", "mehr", "aus\u00b7pa\u00b7cken", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["VMFIN", "PPER", "ADV", "VVINF", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.83": {"line.1": {"text": "Keine Worte darauf", "tokens": ["Kei\u00b7ne", "Wor\u00b7te", "da\u00b7rauf"], "token_info": ["word", "word", "word"], "pos": ["PIAT", "NN", "PAV"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Von der Psyche lauten.", "tokens": ["Von", "der", "Psy\u00b7che", "lau\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Heimlich ist sie worden,", "tokens": ["Heim\u00b7lich", "ist", "sie", "wor\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PPER", "VAPP", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Nur die Tr\u00e4nen tauten.", "tokens": ["Nur", "die", "Tr\u00e4\u00b7nen", "tau\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.84": {"line.1": {"text": "Dies der Venus wegen,", "tokens": ["Dies", "der", "Ve\u00b7nus", "we\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "ART", "NN", "APPR", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Die sie jetzt entdeckte:", "tokens": ["Die", "sie", "jetzt", "ent\u00b7deck\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Die macht sie verlegen.", "tokens": ["Die", "macht", "sie", "ver\u00b7le\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "VVINF", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.85": {"line.1": {"text": "Venus hat den Teufel", "tokens": ["Ve\u00b7nus", "hat", "den", "Teu\u00b7fel"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "VAFIN", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Endlich hier gefunden.", "tokens": ["End\u00b7lich", "hier", "ge\u00b7fun\u00b7den", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Psyche wollt's verhindern", "tokens": ["Psy\u00b7che", "wollt's", "ver\u00b7hin\u00b7dern"], "token_info": ["word", "word", "word"], "pos": ["NN", "VMFIN", "VVINF"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Seit Millionen Stunden.", "tokens": ["Seit", "Mil\u00b7lion\u00b7en", "Stun\u00b7den", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.86": {"line.1": {"text": "Psyche ward es inne:", "tokens": ["Psy\u00b7che", "ward", "es", "in\u00b7ne", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "PTKVZ", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "In die offnen Arme", "tokens": ["In", "die", "off\u00b7nen", "Ar\u00b7me"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Flog ihm Venusine.", "tokens": ["Flog", "ihm", "Ve\u00b7nu\u00b7si\u00b7ne", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NE", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.87": {"line.1": {"text": "Als er'n Rock ablegte,", "tokens": ["Als", "er'n", "Rock", "ab\u00b7leg\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+--", "measure": "unknown.measure.di"}, "line.2": {"text": "Konnt ihn Venus sehen.", "tokens": ["Konnt", "ihn", "Ve\u00b7nus", "se\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Herrlich tat der Nackte", "tokens": ["Herr\u00b7lich", "tat", "der", "Nack\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJD", "VVFIN", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Auf Ruinen stehen,", "tokens": ["Auf", "Ru\u00b7i\u00b7nen", "ste\u00b7hen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "$,"], "meter": "+---+-", "measure": "dactylic.init"}}, "stanza.88": {"line.1": {"text": "Nackend im Palaste,", "tokens": ["Na\u00b7ckend", "im", "Pa\u00b7las\u00b7te", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVPP", "APPRART", "NN", "$,"], "meter": "--+-+-", "measure": "anapaest.init"}, "line.2": {"text": "Wo er gleich den G\u00f6ttern", "tokens": ["Wo", "er", "gleich", "den", "G\u00f6t\u00b7tern"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "ADV", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Vor Jahrtausend' pra\u00dfte.", "tokens": ["Vor", "Jahr\u00b7tau\u00b7send'", "pra\u00df\u00b7te", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.89": {"line.1": {"text": "Psyche seufzt zum Monde,", "tokens": ["Psy\u00b7che", "seufzt", "zum", "Mon\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "APPRART", "NE", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Der sie zu sich holte,", "tokens": ["Der", "sie", "zu", "sich", "hol\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "PRF", "VVFIN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Kam nie mehr zur Erde,", "tokens": ["Kam", "nie", "mehr", "zur", "Er\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "ADV", "APPRART", "NN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "Weil sie nicht mehr wollte.", "tokens": ["Weil", "sie", "nicht", "mehr", "woll\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "ADV", "VMFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.90": {"line.1": {"text": "Doch an Venusine", "tokens": ["Doch", "an", "Ve\u00b7nu\u00b7si\u00b7ne"], "token_info": ["word", "word", "word"], "pos": ["KON", "APPR", "NE"], "meter": "-+-+--", "measure": "unknown.measure.di"}, "line.2": {"text": "Freute sich der Teufel", "tokens": ["Freu\u00b7te", "sich", "der", "Teu\u00b7fel"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PRF", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Mit entz\u00fcckter Miene.", "tokens": ["Mit", "ent\u00b7z\u00fcck\u00b7ter", "Mie\u00b7ne", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.91": {"line.1": {"text": "Sp\u00e4t im Mondscheintaumel", "tokens": ["Sp\u00e4t", "im", "Mond\u00b7schein\u00b7tau\u00b7mel"], "token_info": ["word", "word", "word"], "pos": ["ADJD", "APPRART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Wandelt Venusine", "tokens": ["Wan\u00b7delt", "Ve\u00b7nu\u00b7si\u00b7ne"], "token_info": ["word", "word"], "pos": ["VVFIN", "NE"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Durch des Kolosseums", "tokens": ["Durch", "des", "Ko\u00b7los\u00b7se\u00b7ums"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Alte Prachtruine,", "tokens": ["Al\u00b7te", "Prach\u00b7tru\u00b7i\u00b7ne", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.92": {"line.1": {"text": "Geht durch Mondscheinflecken", "tokens": ["Geht", "durch", "Mond\u00b7schein\u00b7fle\u00b7cken"], "token_info": ["word", "word", "word"], "pos": ["VVFIN", "APPR", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "\u00dcber Steinkadaver,", "tokens": ["\u00dc\u00b7ber", "Stein\u00b7ka\u00b7da\u00b7ver", ","], "token_info": ["word", "word", "punct"], "pos": ["APPR", "NE", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Die voll Zeiten stecken.", "tokens": ["Die", "voll", "Zei\u00b7ten", "ste\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.93": {"line.1": {"text": "In der Kaiserloge,", "tokens": ["In", "der", "Kai\u00b7ser\u00b7lo\u00b7ge", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Wo einst Neros Tatze", "tokens": ["Wo", "einst", "Ne\u00b7ros", "Tat\u00b7ze"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "ADV", "NE", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Auf der Br\u00fcstung spielte,", "tokens": ["Auf", "der", "Br\u00fcs\u00b7tung", "spiel\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Sa\u00df da eine Katze.", "tokens": ["Sa\u00df", "da", "ei\u00b7ne", "Kat\u00b7ze", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.94": {"line.1": {"text": "Sie war vor Jahrtausend", "tokens": ["Sie", "war", "vor", "Jahr\u00b7tau\u00b7send"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "APPR", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Stolz in Rom Het\u00e4re; \u2013", "tokens": ["Stolz", "in", "Rom", "He\u00b7t\u00e4\u00b7re", ";", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "APPR", "NE", "NE", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Heute M\u00e4use mausend.", "tokens": ["Heu\u00b7te", "M\u00e4u\u00b7se", "mau\u00b7send", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "NN", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.95": {"line.1": {"text": "Venus sie zu kosen", "tokens": ["Ve\u00b7nus", "sie", "zu", "ko\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "PPER", "PTKZU", "VVINF"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Streichelt ihren R\u00fccken.", "tokens": ["Strei\u00b7chelt", "ih\u00b7ren", "R\u00fc\u00b7cken", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Doch wer kannte jemals", "tokens": ["Doch", "wer", "kann\u00b7te", "je\u00b7mals"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PWS", "VVFIN", "ADV"], "meter": "+---+-", "measure": "dactylic.init"}, "line.4": {"text": "Aller Katzen T\u00fccken!", "tokens": ["Al\u00b7ler", "Kat\u00b7zen", "T\u00fc\u00b7cken", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.96": {"line.1": {"text": "Pfauchend b\u00f6s in Miene", "tokens": ["Pfau\u00b7chend", "b\u00f6s", "in", "Mie\u00b7ne"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJD", "ADJD", "APPR", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Bei\u00dft die Katz den Daumen", "tokens": ["Bei\u00dft", "die", "Katz", "den", "Dau\u00b7men"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "NN", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Ab der Venusine.", "tokens": ["Ab", "der", "Ve\u00b7nu\u00b7si\u00b7ne", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$."], "meter": "+---+-", "measure": "dactylic.init"}}, "stanza.97": {"line.1": {"text": "W\u00fcchs er nicht der G\u00f6ttin", "tokens": ["W\u00fcchs", "er", "nicht", "der", "G\u00f6t\u00b7tin"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "PPER", "PTKNEG", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Neu nach kurzer Weile,", "tokens": ["Neu", "nach", "kur\u00b7zer", "Wei\u00b7le", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "W\u00e4r' sie nicht mehr Venus", "tokens": ["W\u00e4r'", "sie", "nicht", "mehr", "Ve\u00b7nus"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "PTKNEG", "PIAT", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Gleich nach dieser Zeile.", "tokens": ["Gleich", "nach", "die\u00b7ser", "Zei\u00b7le", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PDAT", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.98": {"line.1": {"text": "Doch er wuchs ihr wieder. \u2013", "tokens": ["Doch", "er", "wuchs", "ihr", "wie\u00b7der", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPER", "ADV", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Staunend dr\u00fcckt die Katze", "tokens": ["Stau\u00b7nend", "dr\u00fcckt", "die", "Kat\u00b7ze"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJD", "VVFIN", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Zu die Augenlider. \u2013", "tokens": ["Zu", "die", "Au\u00b7gen\u00b7li\u00b7der", ".", "\u2013"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["APPR", "ART", "NN", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.99": {"line.1": {"text": "\u00bbsag was dich so kr\u00e4nkte", "tokens": ["\u00bb", "sag", "was", "dich", "so", "kr\u00e4nk\u00b7te"], "token_info": ["punct", "word", "word", "word", "word", "word"], "pos": ["$(", "VVFIN", "PWS", "PPER", "ADV", "VVFIN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Da\u00df Du mich gebissen?\u00ab", "tokens": ["Da\u00df", "Du", "mich", "ge\u00b7bis\u00b7sen", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PPER", "PRF", "VVPP", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Fragte Venusine", "tokens": ["Frag\u00b7te", "Ve\u00b7nu\u00b7si\u00b7ne"], "token_info": ["word", "word"], "pos": ["ADJA", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Jene aufs Gewissen.", "tokens": ["Je\u00b7ne", "aufs", "Ge\u00b7wis\u00b7sen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PDAT", "APPRART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.100": {"line.1": {"text": "Diese nur miaute", "tokens": ["Die\u00b7se", "nur", "mi\u00b7au\u00b7te"], "token_info": ["word", "word", "word"], "pos": ["PDS", "ADV", "VVFIN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Und sich als Het\u00e4re", "tokens": ["Und", "sich", "als", "He\u00b7t\u00e4\u00b7re"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PRF", "KOUS", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Nicht sofort vertraute.", "tokens": ["Nicht", "so\u00b7fort", "ver\u00b7trau\u00b7te", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.101": {"line.1": {"text": "Denn die Katze f\u00fcrchtet", "tokens": ["Denn", "die", "Kat\u00b7ze", "f\u00fcrch\u00b7tet"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "VVFIN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Nichts so sehr auf Erden,", "tokens": ["Nichts", "so", "sehr", "auf", "Er\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "ADV", "ADV", "APPR", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Als heut unter Menschen", "tokens": ["Als", "heut", "un\u00b7ter", "Men\u00b7schen"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ADV", "APPR", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Nochmals Mensch zu werden.", "tokens": ["Noch\u00b7mals", "Mensch", "zu", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "PTKZU", "VAINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.102": {"line.1": {"text": "Schwieg darum verlegen,", "tokens": ["Schwieg", "da\u00b7rum", "ver\u00b7le\u00b7gen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PAV", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Lie\u00df sich nur mit M\u00fche", "tokens": ["Lie\u00df", "sich", "nur", "mit", "M\u00fc\u00b7he"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PRF", "ADV", "APPR", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Zu der Red' bewegen.", "tokens": ["Zu", "der", "Red'", "be\u00b7we\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.103": {"line.1": {"text": "\u00bbschmeichelspeichel hei\u00dfe", "tokens": ["\u00bb", "schmei\u00b7chel\u00b7spei\u00b7chel", "hei\u00b7\u00dfe"], "token_info": ["punct", "word", "word"], "pos": ["$(", "ADJD", "VVFIN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Heut' ich unter Katzen.", "tokens": ["Heut'", "ich", "un\u00b7ter", "Kat\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "APPR", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Wohn' im Kollosseum,", "tokens": ["Wohn'", "im", "Kol\u00b7los\u00b7se\u00b7um", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "$,"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "Wo mich M\u00e4uslein atzen.", "tokens": ["Wo", "mich", "M\u00e4us\u00b7lein", "at\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "NN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.104": {"line.1": {"text": "M\u00e4uslein sind wie Christen,", "tokens": ["M\u00e4us\u00b7lein", "sind", "wie", "Chris\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "KOKOM", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Die schon vor dem Tode", "tokens": ["Die", "schon", "vor", "dem", "To\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "APPR", "ART", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Dunkelleben fristen.", "tokens": ["Dun\u00b7kel\u00b7le\u00b7ben", "fris\u00b7ten", "."], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.105": {"line.1": {"text": "Sa\u00df im Kolosseum.", "tokens": ["Sa\u00df", "im", "Ko\u00b7los\u00b7se\u00b7um", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "APPRART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "War \u2013 ich darf mir's trauen,", "tokens": ["War", "\u2013", "ich", "darf", "mir's", "trau\u00b7en", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "$(", "PPER", "VMFIN", "PIS", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Heut noch laut zu sagen \u2013", "tokens": ["Heut", "noch", "laut", "zu", "sa\u00b7gen", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADJD", "PTKZU", "VVINF", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "G\u00f6ttin unter Frauen.", "tokens": ["G\u00f6t\u00b7tin", "un\u00b7ter", "Frau\u00b7en", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.106": {"line.1": {"text": "Nero selbst, der Kaiser,", "tokens": ["Ne\u00b7ro", "selbst", ",", "der", "Kai\u00b7ser", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "ADV", "$,", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Sprach bei meinem Eintritt", "tokens": ["Sprach", "bei", "mei\u00b7nem", "Ein\u00b7tritt"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "In die Loge leiser.", "tokens": ["In", "die", "Lo\u00b7ge", "lei\u00b7ser", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADJD", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.107": {"line.1": {"text": "Einen jungen Tiger", "tokens": ["Ei\u00b7nen", "jun\u00b7gen", "Ti\u00b7ger"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Hatt' ich aufgezogen.", "tokens": ["Hatt'", "ich", "auf\u00b7ge\u00b7zo\u00b7gen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Diesem Tiere war ich", "tokens": ["Die\u00b7sem", "Tie\u00b7re", "war", "ich"], "token_info": ["word", "word", "word", "word"], "pos": ["PDAT", "NN", "VAFIN", "PPER"], "meter": "+-+-++", "measure": "unknown.measure.tetra"}, "line.4": {"text": "Inbr\u00fcnstig gewogen.", "tokens": ["In\u00b7br\u00fcns\u00b7tig", "ge\u00b7wo\u00b7gen", "."], "token_info": ["word", "word", "punct"], "pos": ["ADJD", "VVPP", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.108": {"line.1": {"text": "Niemand ich mehr brauchte,", "tokens": ["Nie\u00b7mand", "ich", "mehr", "brauch\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "PPER", "ADV", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Sprang er auf mein Lager,", "tokens": ["Sprang", "er", "auf", "mein", "La\u00b7ger", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Und sein Zunglapp rauchte.", "tokens": ["Und", "sein", "Zun\u00b7glapp", "rauch\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.109": {"line.1": {"text": "Bei den Venusspielen,", "tokens": ["Bei", "den", "Ve\u00b7nus\u00b7spie\u00b7len", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Wo man auch auf Frauen", "tokens": ["Wo", "man", "auch", "auf", "Frau\u00b7en"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "PIS", "ADV", "APPR", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Geile Tiere hetzte,", "tokens": ["Gei\u00b7le", "Tie\u00b7re", "hetz\u00b7te", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "NN", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Wollt der Kaiser schauen", "tokens": ["Wollt", "der", "Kai\u00b7ser", "schau\u00b7en"], "token_info": ["word", "word", "word", "word"], "pos": ["VMFIN", "ART", "NN", "VVINF"], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.110": {"line.1": {"text": "Meinen jungen Tiger", "tokens": ["Mei\u00b7nen", "jun\u00b7gen", "Ti\u00b7ger"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "\u00dcber alle Bestien", "tokens": ["\u00dc\u00b7ber", "al\u00b7le", "Be\u00b7sti\u00b7en"], "token_info": ["word", "word", "word"], "pos": ["APPR", "PIAT", "NN"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "Als des Tages Sieger.", "tokens": ["Als", "des", "Ta\u00b7ges", "Sie\u00b7ger", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.111": {"line.1": {"text": "Herrlich war die Hitze,", "tokens": ["Herr\u00b7lich", "war", "die", "Hit\u00b7ze", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Wie mein Tiger t\u00f6tet'", "tokens": ["Wie", "mein", "Ti\u00b7ger", "t\u00f6\u00b7tet'"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "PPOSAT", "NN", "VVFIN"], "meter": "--+--+", "measure": "anapaest.di.plus"}, "line.3": {"text": "B\u00e4ren und die L\u00f6wen", "tokens": ["B\u00e4\u00b7ren", "und", "die", "L\u00f6\u00b7wen"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "KON", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Und mit Blut sich r\u00f6tet.", "tokens": ["Und", "mit", "Blut", "sich", "r\u00f6\u00b7tet", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "PRF", "VVFIN", "$."], "meter": "--+-+-", "measure": "anapaest.init"}}, "stanza.112": {"line.1": {"text": "Doch die Jungfrau'n r\u00fchrte", "tokens": ["Doch", "die", "Jung\u00b7frau'n", "r\u00fchr\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "VVFIN"], "meter": "--+-+-", "measure": "anapaest.init"}, "line.2": {"text": "Er nicht an am Kleide,", "tokens": ["Er", "nicht", "an", "am", "Klei\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKNEG", "APPR", "APPRART", "NN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Weil sein Herz mich sp\u00fcrte.", "tokens": ["Weil", "sein", "Herz", "mich", "sp\u00fcr\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "PPER", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.113": {"line.1": {"text": "Wohl gab's leises Murren,", "tokens": ["Wohl", "gab's", "lei\u00b7ses", "Mur\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADJA", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Als er sich nicht regte,", "tokens": ["Als", "er", "sich", "nicht", "reg\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "PTKNEG", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Ohne Liebesregung", "tokens": ["Oh\u00b7ne", "Lie\u00b7bes\u00b7re\u00b7gung"], "token_info": ["word", "word"], "pos": ["APPR", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "In die Sonn' sich legte,", "tokens": ["In", "die", "Sonn'", "sich", "leg\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PRF", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.114": {"line.1": {"text": "Und die Jungfrau'n schonte,", "tokens": ["Und", "die", "Jung\u00b7frau'n", "schon\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "$,"], "meter": "--+-+-", "measure": "anapaest.init"}, "line.2": {"text": "Auf zur Loge blinzelt,", "tokens": ["Auf", "zur", "Lo\u00b7ge", "blin\u00b7zelt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "APPRART", "NN", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Wo ich Beifall lohnte.", "tokens": ["Wo", "ich", "Bei\u00b7fall", "lohn\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "NN", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.115": {"line.1": {"text": "Wenn ein Tier nicht h\u00f6rte,", "tokens": ["Wenn", "ein", "Tier", "nicht", "h\u00f6r\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "PTKNEG", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Mu\u00dft' man's t\u00f6ten lassen.", "tokens": ["Mu\u00dft'", "man's", "t\u00f6\u00b7ten", "las\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIS", "VVINF", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Niemand dachte diesmal", "tokens": ["Nie\u00b7mand", "dach\u00b7te", "dies\u00b7mal"], "token_info": ["word", "word", "word"], "pos": ["PIS", "VVFIN", "ADV"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "Den Entschlu\u00df zu fassen.", "tokens": ["Den", "Ent\u00b7schlu\u00df", "zu", "fas\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKZU", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.116": {"line.1": {"text": "Alles klatscht aufs Neue,", "tokens": ["Al\u00b7les", "klatscht", "aufs", "Neu\u00b7e", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "APPRART", "ADJA", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Lacht nach meiner Loge,", "tokens": ["Lacht", "nach", "mei\u00b7ner", "Lo\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Gratuliert zur Treue.", "tokens": ["Gra\u00b7tu\u00b7liert", "zur", "Treu\u00b7e", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "APPRART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.117": {"line.1": {"text": "Nur der Sitte wegen", "tokens": ["Nur", "der", "Sit\u00b7te", "we\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "APPR"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Sprangen Gladiatoren", "tokens": ["Spran\u00b7gen", "Gla\u00b7di\u00b7a\u00b7to\u00b7ren"], "token_info": ["word", "word"], "pos": ["NN", "NN"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.3": {"text": "Hin zu meinem Tiger,", "tokens": ["Hin", "zu", "mei\u00b7nem", "Ti\u00b7ger", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Fa\u00dften seine Ohren.", "tokens": ["Fa\u00df\u00b7ten", "sei\u00b7ne", "Oh\u00b7ren", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.118": {"line.1": {"text": "Schauten nach der Mitte", "tokens": ["Schau\u00b7ten", "nach", "der", "Mit\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "APPR", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Auf die Kaiserloge,", "tokens": ["Auf", "die", "Kai\u00b7ser\u00b7lo\u00b7ge", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Denn auch das war Sitte.", "tokens": ["Denn", "auch", "das", "war", "Sit\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PDS", "VAFIN", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.119": {"line.1": {"text": "Hob sich Nero's Daumen,", "tokens": ["Hob", "sich", "Nero's", "Dau\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "NE", "NN", "$,"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Hie\u00df das: la\u00dft ihn leben!", "tokens": ["Hie\u00df", "das", ":", "la\u00dft", "ihn", "le\u00b7ben", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "$(", "VVIMP", "PPER", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Senkt' er ihn, so konnte", "tokens": ["Senkt'", "er", "ihn", ",", "so", "konn\u00b7te"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["VVFIN", "PPER", "PPER", "$,", "ADV", "VMFIN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Man den Tod gleich geben.", "tokens": ["Man", "den", "Tod", "gleich", "ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "ART", "NN", "ADV", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.120": {"line.1": {"text": "Doch auch Vesta's Frauen", "tokens": ["Doch", "auch", "Ve\u00b7sta's", "Frau\u00b7en"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ADV", "NE", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Hattens Recht der Daumen \u2013", "tokens": ["Hat\u00b7tens", "Recht", "der", "Dau\u00b7men", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "ART", "NN", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Nie war dort zu trauen.", "tokens": ["Nie", "war", "dort", "zu", "trau\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "PTKZU", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.121": {"line.1": {"text": "Nero hebt den Daumen", "tokens": ["Ne\u00b7ro", "hebt", "den", "Dau\u00b7men"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "VVFIN", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Und entl\u00e4\u00dft den Tiger.", "tokens": ["Und", "ent\u00b7l\u00e4\u00dft", "den", "Ti\u00b7ger", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Beifall br\u00fcllts Geb\u00e4ude", "tokens": ["Bei\u00b7fall", "br\u00fcllts", "Ge\u00b7b\u00e4u\u00b7de"], "token_info": ["word", "word", "word"], "pos": ["PIAT", "ADJA", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Meinem flotten Sieger.", "tokens": ["Mei\u00b7nem", "flot\u00b7ten", "Sie\u00b7ger", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.122": {"line.1": {"text": "Doch ich mit Erbleichen", "tokens": ["Doch", "ich", "mit", "Er\u00b7blei\u00b7chen"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PPER", "APPR", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Seh': die Priesterinnen", "tokens": ["Seh'", ":", "die", "Pries\u00b7te\u00b7rin\u00b7nen"], "token_info": ["word", "punct", "word", "word"], "pos": ["VVFIN", "$.", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Gebens Todeszeichen, \u2013", "tokens": ["Ge\u00b7bens", "To\u00b7des\u00b7zei\u00b7chen", ",", "\u2013"], "token_info": ["word", "word", "punct", "punct"], "pos": ["NN", "NN", "$,", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.123": {"line.1": {"text": "Senken ihre Daumen, \u2013", "tokens": ["Sen\u00b7ken", "ih\u00b7re", "Dau\u00b7men", ",", "\u2013"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["NN", "PPOSAT", "NN", "$,", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Und die Schwerter blinken.", "tokens": ["Und", "die", "Schwer\u00b7ter", "blin\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Wie ein Lamm so schuldlos", "tokens": ["Wie", "ein", "Lamm", "so", "schuld\u00b7los"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "ART", "NN", "ADV", "ADJD"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "Mu\u00dft' mein Tiger sinken.", "tokens": ["Mu\u00dft'", "mein", "Ti\u00b7ger", "sin\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPOSAT", "NN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.124": {"line.1": {"text": "Einen Schrei zerknicke", "tokens": ["Ei\u00b7nen", "Schrei", "zer\u00b7kni\u00b7cke"], "token_info": ["word", "word", "word"], "pos": ["ART", "NN", "VVFIN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Ich im Halse, st\u00fcrze,", "tokens": ["Ich", "im", "Hal\u00b7se", ",", "st\u00fcr\u00b7ze", ","], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "APPRART", "NN", "$,", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Brech' mir das Genicke.", "tokens": ["Brech'", "mir", "das", "Ge\u00b7ni\u00b7cke", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.125": {"line.1": {"text": "Kann's noch nicht vertragen,", "tokens": ["Kann's", "noch", "nicht", "ver\u00b7tra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "PTKNEG", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Heut nach Tausend Jahren:", "tokens": ["Heut", "nach", "Tau\u00b7send", "Jah\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "CARD", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "F\u00fchl' ich einen Daumen", "tokens": ["F\u00fchl'", "ich", "ei\u00b7nen", "Dau\u00b7men"], "token_info": ["word", "word", "word", "word"], "pos": ["VVIMP", "PPER", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "\u00dcber meinen Haaren,", "tokens": ["\u00dc\u00b7ber", "mei\u00b7nen", "Haa\u00b7ren", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.126": {"line.1": {"text": "Weckt mich Brunst zum Tiger,", "tokens": ["Weckt", "mich", "Brunst", "zum", "Ti\u00b7ger", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "APPRART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Den ich einst umhalste, \u2013", "tokens": ["Den", "ich", "einst", "um\u00b7hals\u00b7te", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "PPER", "ADV", "VVFIN", "$,", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Ewig bleibt er Sieger.\u00ab", "tokens": ["E\u00b7wig", "bleibt", "er", "Sie\u00b7ger", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VVFIN", "PPER", "NN", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.127": {"line.1": {"text": "\u00bbschmeichelspeichel, h\u00f6re:", "tokens": ["\u00bb", "schmei\u00b7chel\u00b7spei\u00b7chel", ",", "h\u00f6\u00b7re", ":"], "token_info": ["punct", "word", "punct", "word", "punct"], "pos": ["$(", "ADJD", "$,", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Trugst Du niemals wieder", "tokens": ["Trugst", "Du", "nie\u00b7mals", "wie\u00b7der"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "ADV"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Seit den Heidenzeiten", "tokens": ["Seit", "den", "Hei\u00b7den\u00b7zei\u00b7ten"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Neue Menschenglieder?", "tokens": ["Neu\u00b7e", "Men\u00b7schen\u00b7glie\u00b7der", "?"], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.128": {"line.1": {"text": "Dieses m\u00f6cht' ich fragen,", "tokens": ["Die\u00b7ses", "m\u00f6cht'", "ich", "fra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PPER", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Wenn Erinnerungen", "tokens": ["Wenn", "E\u00b7rin\u00b7ne\u00b7run\u00b7gen"], "token_info": ["word", "word"], "pos": ["KOUS", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Deine Ruh nicht plagen?\u00ab", "tokens": ["Dei\u00b7ne", "Ruh", "nicht", "pla\u00b7gen", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["PPOSAT", "NN", "PTKNEG", "VVFIN", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.129": {"line.1": {"text": "\u00bbach, die neuen Zeiten,\u00ab", "tokens": ["\u00bb", "ach", ",", "die", "neu\u00b7en", "Zei\u00b7ten", ",", "\u00ab"], "token_info": ["punct", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ITJ", "$,", "ART", "ADJA", "NN", "$,", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Sprach gedehnt die Katze,", "tokens": ["Sprach", "ge\u00b7dehnt", "die", "Kat\u00b7ze", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVPP", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Und sie schnitt zum Monde", "tokens": ["Und", "sie", "schnitt", "zum", "Mon\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "APPRART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Spuckend eine Fratze,", "tokens": ["Spu\u00b7ckend", "ei\u00b7ne", "Frat\u00b7ze", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.130": {"line.1": {"text": "\u00bbsind nicht das auf Erden.", "tokens": ["\u00bb", "sind", "nicht", "das", "auf", "Er\u00b7den", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VAFIN", "PTKNEG", "ART", "APPR", "NN", "$."], "meter": "--+-+-", "measure": "anapaest.init"}, "line.2": {"text": "War noch einmal Menschin,", "tokens": ["War", "noch", "ein\u00b7mal", "Men\u00b7schin", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "NN", "$,"], "meter": "-++-+-", "measure": "unknown.measure.tri"}, "line.3": {"text": "M\u00f6cht's nicht nochmals werden.", "tokens": ["M\u00f6cht's", "nicht", "noch\u00b7mals", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "PTKNEG", "ADV", "VAINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.131": {"line.1": {"text": "Sa\u00df in Hintergassen,", "tokens": ["Sa\u00df", "in", "Hin\u00b7ter\u00b7gas\u00b7sen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Nicht mehr in Pal\u00e4sten.", "tokens": ["Nicht", "mehr", "in", "Pa\u00b7l\u00e4s\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "APPR", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Sittenpolizisten", "tokens": ["Sit\u00b7ten\u00b7po\u00b7li\u00b7zis\u00b7ten"], "token_info": ["word"], "pos": ["NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Jetzt die Luft verpesten.", "tokens": ["Jetzt", "die", "Luft", "ver\u00b7pes\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.132": {"line.1": {"text": "Und die Lieb' konnt' nimmer", "tokens": ["Und", "die", "Lieb'", "konnt'", "nim\u00b7mer"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "VMFIN", "ADV"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Niemals richtig bl\u00fchen,", "tokens": ["Nie\u00b7mals", "rich\u00b7tig", "bl\u00fc\u00b7hen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "\u00c4ngstlich war man immer.", "tokens": ["\u00c4ngst\u00b7lich", "war", "man", "im\u00b7mer", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "PIS", "ADV", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.133": {"line.1": {"text": "Niedrig war mein Wirken.", "tokens": ["Nied\u00b7rig", "war", "mein", "Wir\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "PPOSAT", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.134": {"line.1": {"text": "Und ich stahl mir Leben,", "tokens": ["Und", "ich", "stahl", "mir", "Le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPER", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Wie und wo ich konnte;", "tokens": ["Wie", "und", "wo", "ich", "konn\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "KON", "PWAV", "PPER", "VMFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Eckel sa\u00df daneben.", "tokens": ["E\u00b7ckel", "sa\u00df", "da\u00b7ne\u00b7ben", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PAV", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.135": {"line.1": {"text": "Eckel vor den Menschen", "tokens": ["E\u00b7ckel", "vor", "den", "Men\u00b7schen"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "APPR", "ART", "NN"], "meter": "----+-", "measure": "unknown.measure.single"}, "line.2": {"text": "Hat mich nicht verlassen,", "tokens": ["Hat", "mich", "nicht", "ver\u00b7las\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PTKNEG", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Die den Leib, der liebte,", "tokens": ["Die", "den", "Leib", ",", "der", "lieb\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "$,", "PRELS", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Spotteten und hassen.", "tokens": ["Spot\u00b7te\u00b7ten", "und", "has\u00b7sen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.136": {"line.1": {"text": "Leidenschaft tat fehlen.", "tokens": ["Lei\u00b7den\u00b7schaft", "tat", "feh\u00b7len", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ADJD", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Heut die \u00e4rmsten Leute", "tokens": ["Heut", "die", "\u00e4rms\u00b7ten", "Leu\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ART", "ADJA", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Br\u00fcsten sich mit Seelen.", "tokens": ["Br\u00fcs\u00b7ten", "sich", "mit", "See\u00b7len", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "APPR", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.137": {"line.1": {"text": "Konnte nie mehr lieben.", "tokens": ["Konn\u00b7te", "nie", "mehr", "lie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "ADV", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Unter meinen G\u00e4sten", "tokens": ["Un\u00b7ter", "mei\u00b7nen", "G\u00e4s\u00b7ten"], "token_info": ["word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "War ein Offizierlein,", "tokens": ["War", "ein", "Of\u00b7fi\u00b7zier\u00b7lein", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "$,"], "meter": "--+--+", "measure": "anapaest.di.plus"}, "line.4": {"text": "Einer von den Besten.", "tokens": ["Ei\u00b7ner", "von", "den", "Bes\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "APPR", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.138": {"line.1": {"text": "Ohne mir's zu sagen,", "tokens": ["Oh\u00b7ne", "mir's", "zu", "sa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Tat er'n Abschied nehmen \u2013", "tokens": ["Tat", "er'n", "Ab\u00b7schied", "neh\u00b7men", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADJA", "NN", "VVINF", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Konnt' mich doch erst fragen.", "tokens": ["Konnt'", "mich", "doch", "erst", "fra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "ADV", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.139": {"line.1": {"text": "Kommt da eines Abends", "tokens": ["Kommt", "da", "ei\u00b7nes", "A\u00b7bends"], "token_info": ["word", "word", "word", "word"], "pos": ["VVIMP", "ADV", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Ohne Epauletten,", "tokens": ["Oh\u00b7ne", "E\u00b7pau\u00b7let\u00b7ten", ","], "token_info": ["word", "word", "punct"], "pos": ["APPR", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "War Zivil geworden, \u2013", "tokens": ["War", "Zi\u00b7vil", "ge\u00b7wor\u00b7den", ",", "\u2013"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["VAFIN", "NN", "VAPP", "$,", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Nichts war mehr zu retten.", "tokens": ["Nichts", "war", "mehr", "zu", "ret\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.140": {"line.1": {"text": "Sagte: ", "tokens": ["Sag\u00b7te", ":"], "token_info": ["word", "punct"], "pos": ["VVFIN", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.2": {"text": "Da\u00df sein Weib ich w\u00fcrde,", "tokens": ["Da\u00df", "sein", "Weib", "ich", "w\u00fcr\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "PPER", "VAFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Schied er von dem Degen.", "tokens": ["Schied", "er", "von", "dem", "De\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.141": {"line.1": {"text": "Nichts war mehr am Menschen,", "tokens": ["Nichts", "war", "mehr", "am", "Men\u00b7schen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "ADV", "APPRART", "NN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Als er seine Seele", "tokens": ["Als", "er", "sei\u00b7ne", "See\u00b7le"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PPOSAT", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Ohne Schneid und Degen", "tokens": ["Oh\u00b7ne", "Schneid", "und", "De\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Anbot mit Gequ\u00e4le.", "tokens": ["An\u00b7bot", "mit", "Ge\u00b7qu\u00e4\u00b7le", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.142": {"line.1": {"text": "Kannte nie die Frauen,", "tokens": ["Kann\u00b7te", "nie", "die", "Frau\u00b7en", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Die erst auf die ", "tokens": ["Die", "erst", "auf", "die"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADV", "APPR", "ART"], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "Dann auf ", "tokens": ["Dann", "auf"], "token_info": ["word", "word"], "pos": ["ADV", "APPR"], "meter": "-+", "measure": "iambic.single"}}, "stanza.143": {"line.1": {"text": "Hat sich auch erschossen \u2013", "tokens": ["Hat", "sich", "auch", "er\u00b7schos\u00b7sen", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PRF", "ADV", "VVPP", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Gleich sind sie beim Tode \u2013", "tokens": ["Gleich", "sind", "sie", "beim", "To\u00b7de", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "APPRART", "NN", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Fl\u00fcchten in die Gr\u00e4ber.", "tokens": ["Fl\u00fcch\u00b7ten", "in", "die", "Gr\u00e4\u00b7ber", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Allgemein ist's Mode.", "tokens": ["All\u00b7ge\u00b7mein", "ist's", "Mo\u00b7de", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.144": {"line.1": {"text": "Fr\u00fcher nur die Schlemmer", "tokens": ["Fr\u00fc\u00b7her", "nur", "die", "Schlem\u00b7mer"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "ADV", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Gift zum Nachtisch nahmen \u2013", "tokens": ["Gift", "zum", "Nach\u00b7tisch", "nah\u00b7men", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPRART", "NN", "VVFIN", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Jetzt tut's jeder Kr\u00e4mer.\u00ab", "tokens": ["Jetzt", "tut's", "je\u00b7der", "Kr\u00e4\u00b7mer", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VVFIN", "PIAT", "NN", "$.", "$("], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.145": {"line.1": {"text": "Venus h\u00f6rt nicht l\u00e4nger,", "tokens": ["Ve\u00b7nus", "h\u00f6rt", "nicht", "l\u00e4n\u00b7ger", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PTKNEG", "ADJD", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Was die Katze wu\u00dfte,", "tokens": ["Was", "die", "Kat\u00b7ze", "wu\u00df\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Weil ihr Ohr in Spannung", "tokens": ["Weil", "ihr", "Ohr", "in", "Span\u00b7nung"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPOSAT", "NN", "APPR", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Anderm lauschen mu\u00dfte.", "tokens": ["An\u00b7derm", "lau\u00b7schen", "mu\u00df\u00b7te", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PIS", "VVINF", "VMFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.146": {"line.1": {"text": "Durch die Nacht drang Schreien", "tokens": ["Durch", "die", "Nacht", "drang", "Schrei\u00b7en"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "VVFIN", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Nah vom Palatinum,", "tokens": ["Nah", "vom", "Pa\u00b7la\u00b7ti\u00b7num", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPRART", "NN", "$,"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.3": {"text": "Wie ein Kampf von Zweien.", "tokens": ["Wie", "ein", "Kampf", "von", "Zwei\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "APPR", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.147": {"line.1": {"text": "Eine M\u00e4dchenstimme,", "tokens": ["Ei\u00b7ne", "M\u00e4d\u00b7chen\u00b7stim\u00b7me", ","], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Eines Mannes Toben,", "tokens": ["Ei\u00b7nes", "Man\u00b7nes", "To\u00b7ben", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Und die Sterne zittern", "tokens": ["Und", "die", "Ster\u00b7ne", "zit\u00b7tern"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "VVINF"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "In dem Himmel oben.", "tokens": ["In", "dem", "Him\u00b7mel", "o\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADV", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.148": {"line.1": {"text": "Scheu durch die Ruinen", "tokens": ["Scheu", "durch", "die", "Ru\u00b7i\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "APPR", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Flieht die R\u00f6merkatze", "tokens": ["Flieht", "die", "R\u00f6\u00b7mer\u00b7kat\u00b7ze"], "token_info": ["word", "word", "word"], "pos": ["VVFIN", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Fort von Venusinen.", "tokens": ["Fort", "von", "Ve\u00b7nu\u00b7si\u00b7nen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "$."], "meter": "+-----", "measure": "dactylic.init"}}, "stanza.149": {"line.1": {"text": "Alle Quadern kriegen", "tokens": ["Al\u00b7le", "Qua\u00b7dern", "krie\u00b7gen"], "token_info": ["word", "word", "word"], "pos": ["PIAT", "NN", "VVINF"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Menschliche Gesichter,", "tokens": ["Menschli\u00b7che", "Ge\u00b7sich\u00b7ter", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$,"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Und sie alle r\u00fccken", "tokens": ["Und", "sie", "al\u00b7le", "r\u00fc\u00b7cken"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PPER", "PIS", "VVINF"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Unterm Moose dichter.", "tokens": ["Un\u00b7term", "Moo\u00b7se", "dich\u00b7ter."], "token_info": ["word", "word", "abbreviation"], "pos": ["PPOSAT", "NN", "NE"], "meter": "+-+-", "measure": "trochaic.di"}}, "stanza.150": {"line.1": {"text": "Venusine ahnte,", "tokens": ["Ve\u00b7nu\u00b7si\u00b7ne", "ahn\u00b7te", ","], "token_info": ["word", "word", "punct"], "pos": ["NE", "VVFIN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Da\u00df sich dort ein dunkel", "tokens": ["Da\u00df", "sich", "dort", "ein", "dun\u00b7kel"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PRF", "ADV", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Schicksal Wege bahnte.", "tokens": ["Schick\u00b7sal", "We\u00b7ge", "bahn\u00b7te", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "NN", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.151": {"line.1": {"text": "Mond hing wie die Perlen,", "tokens": ["Mond", "hing", "wie", "die", "Per\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "KOKOM", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Welche Tr\u00e4nen bringen,", "tokens": ["Wel\u00b7che", "Tr\u00e4\u00b7nen", "brin\u00b7gen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PWAT", "NN", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "\u00dcberm Sack des Dunkels,", "tokens": ["\u00dc\u00b7berm", "Sack", "des", "Dun\u00b7kels", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Drinnen Schreie ringen.", "tokens": ["Drin\u00b7nen", "Schrei\u00b7e", "rin\u00b7gen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.152": {"line.1": {"text": "Venus eilte schneller", "tokens": ["Ve\u00b7nus", "eil\u00b7te", "schnel\u00b7ler"], "token_info": ["word", "word", "word"], "pos": ["NE", "VVFIN", "ADJA"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Zum Palatiumh\u00fcgel,", "tokens": ["Zum", "Pa\u00b7la\u00b7ti\u00b7um\u00b7h\u00fc\u00b7gel", ","], "token_info": ["word", "word", "punct"], "pos": ["APPRART", "NN", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.3": {"text": "Der ein Haufen Keller.", "tokens": ["Der", "ein", "Hau\u00b7fen", "Kel\u00b7ler", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.153": {"line.1": {"text": "Fiebrig stinkt dort Erde", "tokens": ["Fieb\u00b7rig", "stinkt", "dort", "Er\u00b7de"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJD", "VVFIN", "ADV", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Unter Mosaiken,", "tokens": ["Un\u00b7ter", "Mo\u00b7sai\u00b7ken", ","], "token_info": ["word", "word", "punct"], "pos": ["APPR", "NN", "$,"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Die wie bunte Augen", "tokens": ["Die", "wie", "bun\u00b7te", "Au\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "KOKOM", "ADJA", "NN"], "meter": "--+-+-", "measure": "anapaest.init"}, "line.4": {"text": "Toter Freude blicken.", "tokens": ["To\u00b7ter", "Freu\u00b7de", "bli\u00b7cken", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.154": {"line.1": {"text": "Wo einst Duft von \u00d6len", "tokens": ["Wo", "einst", "Duft", "von", "\u00d6\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "ADV", "NN", "APPR", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Und von Narden rauchte,", "tokens": ["Und", "von", "Nar\u00b7den", "rauch\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Stehn verpestet H\u00f6hlen.", "tokens": ["Stehn", "ver\u00b7pes\u00b7tet", "H\u00f6h\u00b7len", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.155": {"line.1": {"text": "Venus sucht und findet", "tokens": ["Ve\u00b7nus", "sucht", "und", "fin\u00b7det"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "VVFIN", "KON", "VVFIN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Nur vom Kampf die Schreie.", "tokens": ["Nur", "vom", "Kampf", "die", "Schrei\u00b7e", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Selbst dem G\u00f6tterauge", "tokens": ["Selbst", "dem", "G\u00f6t\u00b7ter\u00b7au\u00b7ge"], "token_info": ["word", "word", "word"], "pos": ["ADV", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.156": {"line.1": {"text": "K\u00e4mpfen, denkt die Venus,", "tokens": ["K\u00e4mp\u00b7fen", ",", "denkt", "die", "Ve\u00b7nus", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "ART", "NN", "$,"], "meter": "+-+--+", "measure": "iambic.tri.chol"}}, "stanza.157": {"line.1": {"text": "Jeder Gott auf Erden", "tokens": ["Je\u00b7der", "Gott", "auf", "Er\u00b7den"], "token_info": ["word", "word", "word", "word"], "pos": ["PIAT", "NN", "APPR", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Und auch G\u00f6tterfrauen", "tokens": ["Und", "auch", "G\u00f6t\u00b7ter\u00b7frau\u00b7en"], "token_info": ["word", "word", "word"], "pos": ["KON", "ADV", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "K\u00f6nnen Unsichtbarstes,", "tokens": ["K\u00f6n\u00b7nen", "Un\u00b7sicht\u00b7bars\u00b7tes", ","], "token_info": ["word", "word", "punct"], "pos": ["VMFIN", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Sichtbar machend, schauen.", "tokens": ["Sicht\u00b7bar", "ma\u00b7chend", ",", "schau\u00b7en", "."], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["ADJD", "VVPP", "$,", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.158": {"line.1": {"text": "Ebenso der ", "tokens": ["E\u00b7ben\u00b7so", "der"], "token_info": ["word", "word"], "pos": ["ADV", "ART"], "meter": "+-+-", "measure": "trochaic.di"}, "line.2": {"text": "Der sich ehrlich schindet.", "tokens": ["Der", "sich", "ehr\u00b7lich", "schin\u00b7det", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "ADJD", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.159": {"line.1": {"text": "Um sich je zu zeigen.", "tokens": ["Um", "sich", "je", "zu", "zei\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PRF", "ADV", "PTKZU", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Und von jeher eigen.", "tokens": ["Und", "von", "je\u00b7her", "ei\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ADV", "ADJD", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.160": {"line.1": {"text": "\u00dcber ihr Bestehen", "tokens": ["\u00dc\u00b7ber", "ihr", "Be\u00b7ste\u00b7hen"], "token_info": ["word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Oft die G\u00f6tter zweifeln,", "tokens": ["Oft", "die", "G\u00f6t\u00b7ter", "zwei\u00b7feln", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.161": {"line.1": {"text": "Venus sucht und findet,", "tokens": ["Ve\u00b7nus", "sucht", "und", "fin\u00b7det", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Wo der Kampf statthatte,", "tokens": ["Wo", "der", "Kampf", "statt\u00b7hat\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Von der armen Psyche", "tokens": ["Von", "der", "ar\u00b7men", "Psy\u00b7che"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Was vom Feigenblatte.", "tokens": ["Was", "vom", "Fei\u00b7gen\u00b7blat\u00b7te", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PWS", "APPRART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.162": {"line.1": {"text": "Und auf einem Sockel", "tokens": ["Und", "auf", "ei\u00b7nem", "So\u00b7ckel"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Lag vom Teufel schneidig,", "tokens": ["Lag", "vom", "Teu\u00b7fel", "schnei\u00b7dig", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPRART", "NN", "ADJD", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Heil auch, das Monokel.", "tokens": ["Heil", "auch", ",", "das", "Mo\u00b7no\u00b7kel", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "ADV", "$,", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.163": {"line.1": {"text": "\u00bbfr\u00e4ulein!\u00ab schrie der Teufel,", "tokens": ["\u00bb", "fr\u00e4u\u00b7lein", "!", "\u00ab", "schrie", "der", "Teu\u00b7fel", ","], "token_info": ["punct", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PTKVZ", "$.", "$(", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "\u00bbanstand hatt' ich leider.", "tokens": ["\u00bb", "an\u00b7stand", "hatt'", "ich", "lei\u00b7der", "."], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "VAFIN", "PPER", "ADV", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Trug zum Stelldicheine", "tokens": ["Trug", "zum", "Stell\u00b7dich\u00b7ei\u00b7ne"], "token_info": ["word", "word", "word"], "pos": ["NN", "APPRART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Strikt hier meine Kleider.", "tokens": ["Strikt", "hier", "mei\u00b7ne", "Klei\u00b7der", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PPOSAT", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.164": {"line.1": {"text": "Wenn sie ohne gehen,", "tokens": ["Wenn", "sie", "oh\u00b7ne", "ge\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Weckt das meine Wollust \u2013", "tokens": ["Weckt", "das", "mei\u00b7ne", "Wol\u00b7lust", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "PPOSAT", "NN", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Was sollt' sonst geschehen?\u00ab", "tokens": ["Was", "sollt'", "sonst", "ge\u00b7sche\u00b7hen", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["PWS", "VMFIN", "ADV", "VVPP", "$.", "$("], "meter": "++--+-", "measure": "trochaic.tri.relaxed"}}, "stanza.165": {"line.1": {"text": "Darauf schrie die Psyche:", "tokens": ["Da\u00b7rauf", "schrie", "die", "Psy\u00b7che", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "ART", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "\u00bballes ist gelogen!", "tokens": ["\u00bb", "al\u00b7les", "ist", "ge\u00b7lo\u00b7gen", "!"], "token_info": ["punct", "word", "word", "word", "punct"], "pos": ["$(", "PIS", "VAFIN", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Hab mich f\u00fcr die Sch\u00f6nheit", "tokens": ["Hab", "mich", "f\u00fcr", "die", "Sch\u00f6n\u00b7heit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "PPER", "APPR", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Einzig ausgezogen.", "tokens": ["Ein\u00b7zig", "aus\u00b7ge\u00b7zo\u00b7gen", "."], "token_info": ["word", "word", "punct"], "pos": ["ADJD", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.166": {"line.1": {"text": "Sie sind eben wilder,", "tokens": ["Sie", "sind", "e\u00b7ben", "wil\u00b7der", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJA", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Leben nur dem Fleische,", "tokens": ["Le\u00b7ben", "nur", "dem", "Flei\u00b7sche", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Nicht f\u00fcr Kunst und Bilder.\u00ab", "tokens": ["Nicht", "f\u00fcr", "Kunst", "und", "Bil\u00b7der", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PTKNEG", "APPR", "NN", "KON", "NN", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.167": {"line.1": {"text": "\u00bbteufel!\u00ab schrie der Teufel,", "tokens": ["\u00bb", "teu\u00b7fel", "!", "\u00ab", "schrie", "der", "Teu\u00b7fel", ","], "token_info": ["punct", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "NE", "$.", "$(", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "\u00bbwenn Sie mich doch kennen,", "tokens": ["\u00bb", "wenn", "Sie", "mich", "doch", "ken\u00b7nen", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "PPER", "PRF", "ADV", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Wundert's mich im Stillen,", "tokens": ["Wun\u00b7dert's", "mich", "im", "Stil\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPRART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Da\u00df Sie nach mir rennen!\u00ab", "tokens": ["Da\u00df", "Sie", "nach", "mir", "ren\u00b7nen", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PPER", "APPR", "PPER", "VVFIN", "$.", "$("], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.168": {"line.1": {"text": "\u00bbbin ich Kuh mit Eutern", "tokens": ["\u00bb", "bin", "ich", "Kuh", "mit", "Eu\u00b7tern"], "token_info": ["punct", "word", "word", "word", "word", "word"], "pos": ["$(", "VAFIN", "PPER", "NN", "APPR", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Die man packt?\u00ab schrie Psyche.", "tokens": ["Die", "man", "packt", "?", "\u00ab", "schrie", "Psy\u00b7che", "."], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["ART", "PIS", "VVFIN", "$.", "$(", "VVFIN", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "\u00bbnur Dich wollt' ich l\u00e4utern!\u00ab", "tokens": ["\u00bb", "nur", "Dich", "wollt'", "ich", "l\u00e4u\u00b7tern", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADV", "PPER", "VMFIN", "PPER", "VVINF", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.169": {"line.1": {"text": "\u00bbnun von Ihren Eutern", "tokens": ["\u00bb", "nun", "von", "Ih\u00b7ren", "Eu\u00b7tern"], "token_info": ["punct", "word", "word", "word", "word"], "pos": ["$(", "ADV", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "War nicht viel zu merken.", "tokens": ["War", "nicht", "viel", "zu", "mer\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PTKNEG", "ADV", "PTKZU", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Nicht mal eine Fliege", "tokens": ["Nicht", "mal", "ei\u00b7ne", "Flie\u00b7ge"], "token_info": ["word", "word", "word", "word"], "pos": ["PTKNEG", "ADV", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "K\u00f6nnte sich dran st\u00e4rken.", "tokens": ["K\u00f6nn\u00b7te", "sich", "dran", "st\u00e4r\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PRF", "PAV", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.170": {"line.1": {"text": "Sch\u00f6nheit soll nicht leiden:", "tokens": ["Sch\u00f6n\u00b7heit", "soll", "nicht", "lei\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "PTKNEG", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Werde mich jetzt l\u00e4utern", "tokens": ["Wer\u00b7de", "mich", "jetzt", "l\u00e4u\u00b7tern"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "ADV", "VVINF"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Und mich auch entkleiden.", "tokens": ["Und", "mich", "auch", "ent\u00b7klei\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ADV", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.171": {"line.1": {"text": "Wenn die Damen nackend", "tokens": ["Wenn", "die", "Da\u00b7men", "na\u00b7ckend"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "VVPP"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "F\u00fcr die Kunst einstehen,", "tokens": ["F\u00fcr", "die", "Kunst", "ein\u00b7ste\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVIZU", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Warum sollen M\u00e4nner", "tokens": ["Wa\u00b7rum", "sol\u00b7len", "M\u00e4n\u00b7ner"], "token_info": ["word", "word", "word"], "pos": ["PWAV", "PIAT", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "H\u00e4\u00dflichkeit begehen?", "tokens": ["H\u00e4\u00df\u00b7lich\u00b7keit", "be\u00b7ge\u00b7hen", "?"], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.172": {"line.1": {"text": "M\u00e4nnerbrust und Nacken", "tokens": ["M\u00e4n\u00b7ner\u00b7brust", "und", "Na\u00b7cken"], "token_info": ["word", "word", "word"], "pos": ["NN", "KON", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "K\u00f6nnen auch erbauen. \u2013", "tokens": ["K\u00f6n\u00b7nen", "auch", "er\u00b7bau\u00b7en", ".", "\u2013"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["VMFIN", "ADV", "VVINF", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Soll ich mehr auspacken?\u00ab", "tokens": ["Soll", "ich", "mehr", "aus\u00b7pa\u00b7cken", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["VMFIN", "PPER", "ADV", "VVINF", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.173": {"line.1": {"text": "Keine Worte darauf", "tokens": ["Kei\u00b7ne", "Wor\u00b7te", "da\u00b7rauf"], "token_info": ["word", "word", "word"], "pos": ["PIAT", "NN", "PAV"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Von der Psyche lauten.", "tokens": ["Von", "der", "Psy\u00b7che", "lau\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Heimlich ist sie worden,", "tokens": ["Heim\u00b7lich", "ist", "sie", "wor\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PPER", "VAPP", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Nur die Tr\u00e4nen tauten.", "tokens": ["Nur", "die", "Tr\u00e4\u00b7nen", "tau\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.174": {"line.1": {"text": "Dies der Venus wegen,", "tokens": ["Dies", "der", "Ve\u00b7nus", "we\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "ART", "NN", "APPR", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Die sie jetzt entdeckte:", "tokens": ["Die", "sie", "jetzt", "ent\u00b7deck\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Die macht sie verlegen.", "tokens": ["Die", "macht", "sie", "ver\u00b7le\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "VVINF", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.175": {"line.1": {"text": "Venus hat den Teufel", "tokens": ["Ve\u00b7nus", "hat", "den", "Teu\u00b7fel"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "VAFIN", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Endlich hier gefunden.", "tokens": ["End\u00b7lich", "hier", "ge\u00b7fun\u00b7den", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Psyche wollt's verhindern", "tokens": ["Psy\u00b7che", "wollt's", "ver\u00b7hin\u00b7dern"], "token_info": ["word", "word", "word"], "pos": ["NN", "VMFIN", "VVINF"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Seit Millionen Stunden.", "tokens": ["Seit", "Mil\u00b7lion\u00b7en", "Stun\u00b7den", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.176": {"line.1": {"text": "Psyche ward es inne:", "tokens": ["Psy\u00b7che", "ward", "es", "in\u00b7ne", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "PTKVZ", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "In die offnen Arme", "tokens": ["In", "die", "off\u00b7nen", "Ar\u00b7me"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Flog ihm Venusine.", "tokens": ["Flog", "ihm", "Ve\u00b7nu\u00b7si\u00b7ne", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NE", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.177": {"line.1": {"text": "Als er'n Rock ablegte,", "tokens": ["Als", "er'n", "Rock", "ab\u00b7leg\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+--", "measure": "unknown.measure.di"}, "line.2": {"text": "Konnt ihn Venus sehen.", "tokens": ["Konnt", "ihn", "Ve\u00b7nus", "se\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Herrlich tat der Nackte", "tokens": ["Herr\u00b7lich", "tat", "der", "Nack\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJD", "VVFIN", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Auf Ruinen stehen,", "tokens": ["Auf", "Ru\u00b7i\u00b7nen", "ste\u00b7hen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "$,"], "meter": "+---+-", "measure": "dactylic.init"}}, "stanza.178": {"line.1": {"text": "Nackend im Palaste,", "tokens": ["Na\u00b7ckend", "im", "Pa\u00b7las\u00b7te", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVPP", "APPRART", "NN", "$,"], "meter": "--+-+-", "measure": "anapaest.init"}, "line.2": {"text": "Wo er gleich den G\u00f6ttern", "tokens": ["Wo", "er", "gleich", "den", "G\u00f6t\u00b7tern"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "ADV", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Vor Jahrtausend' pra\u00dfte.", "tokens": ["Vor", "Jahr\u00b7tau\u00b7send'", "pra\u00df\u00b7te", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.179": {"line.1": {"text": "Psyche seufzt zum Monde,", "tokens": ["Psy\u00b7che", "seufzt", "zum", "Mon\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "APPRART", "NE", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Der sie zu sich holte,", "tokens": ["Der", "sie", "zu", "sich", "hol\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "PRF", "VVFIN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Kam nie mehr zur Erde,", "tokens": ["Kam", "nie", "mehr", "zur", "Er\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "ADV", "APPRART", "NN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "Weil sie nicht mehr wollte.", "tokens": ["Weil", "sie", "nicht", "mehr", "woll\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "ADV", "VMFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.180": {"line.1": {"text": "Doch an Venusine", "tokens": ["Doch", "an", "Ve\u00b7nu\u00b7si\u00b7ne"], "token_info": ["word", "word", "word"], "pos": ["KON", "APPR", "NE"], "meter": "-+-+--", "measure": "unknown.measure.di"}, "line.2": {"text": "Freute sich der Teufel", "tokens": ["Freu\u00b7te", "sich", "der", "Teu\u00b7fel"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PRF", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Mit entz\u00fcckter Miene.", "tokens": ["Mit", "ent\u00b7z\u00fcck\u00b7ter", "Mie\u00b7ne", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}}}}