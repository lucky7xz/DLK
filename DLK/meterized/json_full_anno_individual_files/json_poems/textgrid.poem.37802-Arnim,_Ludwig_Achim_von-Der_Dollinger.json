{"textgrid.poem.37802": {"metadata": {"author": {"name": "Arnim, Ludwig Achim von", "birth": "N.A.", "death": "N.A."}, "title": "Der Dollinger", "genre": "verse", "period": "N.A.", "pub_year": 1806, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Es ritt ein T\u00fcrk aus T\u00fcrkenland,", "tokens": ["Es", "ritt", "ein", "T\u00fcrk", "aus", "T\u00fcr\u00b7ken\u00b7land", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Er ritt gen Regensburg in die Stadt,", "tokens": ["Er", "ritt", "gen", "Re\u00b7gens\u00b7burg", "in", "die", "Stadt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NE", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Da Stechen ward, vom Stechen ward er wohl bekandt.", "tokens": ["Da", "Ste\u00b7chen", "ward", ",", "vom", "Ste\u00b7chen", "ward", "er", "wohl", "be\u00b7kandt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "VAFIN", "$,", "APPRART", "NN", "VAFIN", "PPER", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Da ritt er vor des Kaysers Th\u00fcr,", "tokens": ["Da", "ritt", "er", "vor", "des", "Kay\u00b7sers", "Th\u00fcr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "\u00bbist jemand hier, der komm herf\u00fcr,", "tokens": ["\u00bb", "ist", "je\u00b7mand", "hier", ",", "der", "komm", "her\u00b7f\u00fcr", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "VAFIN", "PIS", "ADV", "$,", "PRELS", "VVFIN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Der stechen will um Leib und Seel, um Gut und Ehr", "tokens": ["Der", "ste\u00b7chen", "will", "um", "Leib", "und", "Seel", ",", "um", "Gut", "und", "Ehr"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "VVINF", "VMFIN", "APPR", "NN", "KON", "NN", "$,", "KOUI", "ADJD", "KON", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und da\u00df dem Teufel die Seele w\u00e4r.\u00ab", "tokens": ["Und", "da\u00df", "dem", "Teu\u00b7fel", "die", "See\u00b7le", "w\u00e4r", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "ART", "NN", "VAFIN", "$.", "$("], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Da waren die Stecher all verschwiegen,", "tokens": ["Da", "wa\u00b7ren", "die", "Ste\u00b7cher", "all", "ver\u00b7schwie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "PIAT", "ADJA", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "Keiner wollt dem T\u00fcrken nicht obliegen,", "tokens": ["Kei\u00b7ner", "wollt", "dem", "T\u00fcr\u00b7ken", "nicht", "ob\u00b7lie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "ART", "NN", "PTKNEG", "VVINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.10": {"text": "Dem leidigen Mann", "tokens": ["Dem", "lei\u00b7di\u00b7gen", "Mann"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.11": {"text": "Der so treflich stechen kann.", "tokens": ["Der", "so", "tref\u00b7lich", "ste\u00b7chen", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJD", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.12": {"text": "Da sprach der Kayser zorniglich:", "tokens": ["Da", "sprach", "der", "Kay\u00b7ser", "zor\u00b7nig\u00b7lich", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "\u00bbwie steht mein Hof so l\u00e4sterlich,", "tokens": ["\u00bb", "wie", "steht", "mein", "Hof", "so", "l\u00e4s\u00b7ter\u00b7lich", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWAV", "VVFIN", "PPOSAT", "NN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Hab ich kein Mann,", "tokens": ["Hab", "ich", "kein", "Mann", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PIAT", "NN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.15": {"text": "Der stechen kann", "tokens": ["Der", "ste\u00b7chen", "kann"], "token_info": ["word", "word", "word"], "pos": ["ART", "VVINF", "VMFIN"], "meter": "-+-+", "measure": "iambic.di"}, "line.16": {"text": "Um Leib und Seel, um Gut und Ehr,", "tokens": ["Um", "Leib", "und", "Seel", ",", "um", "Gut", "und", "Ehr", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "NN", "KON", "NN", "$,", "KOUI", "ADJD", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "Und da\u00df unserm Herrn die Seele w\u00e4r?\u00ab", "tokens": ["Und", "da\u00df", "un\u00b7serm", "Herrn", "die", "See\u00b7le", "w\u00e4r", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "KOUS", "PPOSAT", "NN", "ART", "NN", "VAFIN", "$.", "$("], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.18": {"text": "Da sprang der Dollinger hervor,", "tokens": ["Da", "sprang", "der", "Dol\u00b7lin\u00b7ger", "her\u00b7vor", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.19": {"text": "\u00bbwohl um, wohl um, ich mu\u00df hervor,", "tokens": ["\u00bb", "wohl", "um", ",", "wohl", "um", ",", "ich", "mu\u00df", "her\u00b7vor", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "PTKVZ", "$,", "ADV", "PTKVZ", "$,", "PPER", "VMFIN", "PTKVZ", "$,"], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.20": {"text": "An den leidigen Mann,", "tokens": ["An", "den", "lei\u00b7di\u00b7gen", "Mann", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "--+--+", "measure": "anapaest.di.plus"}, "line.21": {"text": "Der so treflich stechen kann.\u00ab", "tokens": ["Der", "so", "tref\u00b7lich", "ste\u00b7chen", "kann", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "ADV", "ADJD", "VVINF", "VMFIN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.22": {"text": "Die f\u00fchrten gegen einander", "tokens": ["Die", "f\u00fchr\u00b7ten", "ge\u00b7gen", "ein\u00b7an\u00b7der"], "token_info": ["word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "APPR", "PRF"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.23": {"text": "Zwey scharfe Speer,", "tokens": ["Zwey", "schar\u00b7fe", "Speer", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["CARD", "ADJA", "NN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.24": {"text": "Das Eine ging hin, das Andere her.", "tokens": ["Das", "Ei\u00b7ne", "ging", "hin", ",", "das", "An\u00b7de\u00b7re", "her", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "PIS", "VVFIN", "PTKVZ", "$,", "PRELS", "PIS", "PTKVZ", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.25": {"text": "Da stach der T\u00fcrk den Dollinger ab,", "tokens": ["Da", "stach", "der", "T\u00fcrk", "den", "Dol\u00b7lin\u00b7ger", "ab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.26": {"text": "Da\u00df er an dem R\u00fccken lag.", "tokens": ["Da\u00df", "er", "an", "dem", "R\u00fc\u00b7cken", "lag", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.27": {"text": "\u00bbo Jesu Christ steh mir jetzt bey,", "tokens": ["\u00bb", "o", "Je\u00b7su", "Christ", "steh", "mir", "jetzt", "bey", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "FM", "NE", "NE", "VVFIN", "PPER", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.28": {"text": "Steck mir ein Zweig, sind ihrer drey.", "tokens": ["Steck", "mir", "ein", "Zweig", ",", "sind", "ih\u00b7rer", "drey", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ART", "NN", "$,", "VAFIN", "PPOSAT", "CARD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.29": {"text": "Bin ich allein, und f\u00fchr mein Seel ins Himmelreich.\u00ab", "tokens": ["Bin", "ich", "al\u00b7lein", ",", "und", "f\u00fchr", "mein", "Seel", "ins", "Him\u00b7mel\u00b7reich", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VAFIN", "PPER", "ADV", "$,", "KON", "VVFIN", "PPOSAT", "NN", "APPRART", "NN", "$.", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "Da ritt der Kayser zum Dollinger so behend,", "tokens": ["Da", "ritt", "der", "Kay\u00b7ser", "zum", "Dol\u00b7lin\u00b7ger", "so", "be\u00b7hend", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPRART", "NN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.31": {"text": "Er f\u00fchrt ein Kreutz in seiner H\u00e4nd,", "tokens": ["Er", "f\u00fchrt", "ein", "Kreutz", "in", "sei\u00b7ner", "H\u00e4nd", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.32": {"text": "Er strichs dem Dollinger \u00fcbern Mund", "tokens": ["Er", "strichs", "dem", "Dol\u00b7lin\u00b7ger", "\u00fc\u00b7bern", "Mund"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPRART", "NN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.33": {"text": "Der Dollinger sprang auf, war frisch und gesund.", "tokens": ["Der", "Dol\u00b7lin\u00b7ger", "sprang", "auf", ",", "war", "frisch", "und", "ge\u00b7sund", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "$,", "VAFIN", "ADJD", "KON", "ADJD", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.34": {"text": "Da stach der Dollinger den T\u00fcrken ab,", "tokens": ["Da", "stach", "der", "Dol\u00b7lin\u00b7ger", "den", "T\u00fcr\u00b7ken", "ab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.35": {"text": "Da\u00df er auf dem R\u00fccken lag.", "tokens": ["Da\u00df", "er", "auf", "dem", "R\u00fc\u00b7cken", "lag", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.36": {"text": "\u00bbdu ber\u00fchmter Teufel nun steh ihm bey.", "tokens": ["\u00bb", "du", "be\u00b7r\u00fchm\u00b7ter", "Teu\u00b7fel", "nun", "steh", "ihm", "bey", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "ADJA", "NN", "ADV", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.37": {"text": "Sind ihrer drey, bin ich allein", "tokens": ["Sind", "ih\u00b7rer", "drey", ",", "bin", "ich", "al\u00b7lein"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["VAFIN", "PPOSAT", "CARD", "$,", "VAFIN", "PPER", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.38": {"text": "Und f\u00fchr sein Seel in die bittere Pein.\u00ab", "tokens": ["Und", "f\u00fchr", "sein", "Seel", "in", "die", "bit\u00b7te\u00b7re", "Pein", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "APPR", "ART", "ADJA", "NN", "$.", "$("], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}}, "stanza.2": {"line.1": {"text": "Es ritt ein T\u00fcrk aus T\u00fcrkenland,", "tokens": ["Es", "ritt", "ein", "T\u00fcrk", "aus", "T\u00fcr\u00b7ken\u00b7land", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Er ritt gen Regensburg in die Stadt,", "tokens": ["Er", "ritt", "gen", "Re\u00b7gens\u00b7burg", "in", "die", "Stadt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NE", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Da Stechen ward, vom Stechen ward er wohl bekandt.", "tokens": ["Da", "Ste\u00b7chen", "ward", ",", "vom", "Ste\u00b7chen", "ward", "er", "wohl", "be\u00b7kandt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "VAFIN", "$,", "APPRART", "NN", "VAFIN", "PPER", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Da ritt er vor des Kaysers Th\u00fcr,", "tokens": ["Da", "ritt", "er", "vor", "des", "Kay\u00b7sers", "Th\u00fcr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "\u00bbist jemand hier, der komm herf\u00fcr,", "tokens": ["\u00bb", "ist", "je\u00b7mand", "hier", ",", "der", "komm", "her\u00b7f\u00fcr", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "VAFIN", "PIS", "ADV", "$,", "PRELS", "VVFIN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Der stechen will um Leib und Seel, um Gut und Ehr", "tokens": ["Der", "ste\u00b7chen", "will", "um", "Leib", "und", "Seel", ",", "um", "Gut", "und", "Ehr"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "VVINF", "VMFIN", "APPR", "NN", "KON", "NN", "$,", "KOUI", "ADJD", "KON", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und da\u00df dem Teufel die Seele w\u00e4r.\u00ab", "tokens": ["Und", "da\u00df", "dem", "Teu\u00b7fel", "die", "See\u00b7le", "w\u00e4r", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "ART", "NN", "VAFIN", "$.", "$("], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Da waren die Stecher all verschwiegen,", "tokens": ["Da", "wa\u00b7ren", "die", "Ste\u00b7cher", "all", "ver\u00b7schwie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "PIAT", "ADJA", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "Keiner wollt dem T\u00fcrken nicht obliegen,", "tokens": ["Kei\u00b7ner", "wollt", "dem", "T\u00fcr\u00b7ken", "nicht", "ob\u00b7lie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "ART", "NN", "PTKNEG", "VVINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.10": {"text": "Dem leidigen Mann", "tokens": ["Dem", "lei\u00b7di\u00b7gen", "Mann"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.11": {"text": "Der so treflich stechen kann.", "tokens": ["Der", "so", "tref\u00b7lich", "ste\u00b7chen", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJD", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.12": {"text": "Da sprach der Kayser zorniglich:", "tokens": ["Da", "sprach", "der", "Kay\u00b7ser", "zor\u00b7nig\u00b7lich", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "\u00bbwie steht mein Hof so l\u00e4sterlich,", "tokens": ["\u00bb", "wie", "steht", "mein", "Hof", "so", "l\u00e4s\u00b7ter\u00b7lich", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWAV", "VVFIN", "PPOSAT", "NN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Hab ich kein Mann,", "tokens": ["Hab", "ich", "kein", "Mann", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PIAT", "NN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.15": {"text": "Der stechen kann", "tokens": ["Der", "ste\u00b7chen", "kann"], "token_info": ["word", "word", "word"], "pos": ["ART", "VVINF", "VMFIN"], "meter": "-+-+", "measure": "iambic.di"}, "line.16": {"text": "Um Leib und Seel, um Gut und Ehr,", "tokens": ["Um", "Leib", "und", "Seel", ",", "um", "Gut", "und", "Ehr", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "NN", "KON", "NN", "$,", "KOUI", "ADJD", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "Und da\u00df unserm Herrn die Seele w\u00e4r?\u00ab", "tokens": ["Und", "da\u00df", "un\u00b7serm", "Herrn", "die", "See\u00b7le", "w\u00e4r", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "KOUS", "PPOSAT", "NN", "ART", "NN", "VAFIN", "$.", "$("], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.18": {"text": "Da sprang der Dollinger hervor,", "tokens": ["Da", "sprang", "der", "Dol\u00b7lin\u00b7ger", "her\u00b7vor", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.19": {"text": "\u00bbwohl um, wohl um, ich mu\u00df hervor,", "tokens": ["\u00bb", "wohl", "um", ",", "wohl", "um", ",", "ich", "mu\u00df", "her\u00b7vor", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "PTKVZ", "$,", "ADV", "PTKVZ", "$,", "PPER", "VMFIN", "PTKVZ", "$,"], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.20": {"text": "An den leidigen Mann,", "tokens": ["An", "den", "lei\u00b7di\u00b7gen", "Mann", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "--+--+", "measure": "anapaest.di.plus"}, "line.21": {"text": "Der so treflich stechen kann.\u00ab", "tokens": ["Der", "so", "tref\u00b7lich", "ste\u00b7chen", "kann", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "ADV", "ADJD", "VVINF", "VMFIN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.22": {"text": "Die f\u00fchrten gegen einander", "tokens": ["Die", "f\u00fchr\u00b7ten", "ge\u00b7gen", "ein\u00b7an\u00b7der"], "token_info": ["word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "APPR", "PRF"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.23": {"text": "Zwey scharfe Speer,", "tokens": ["Zwey", "schar\u00b7fe", "Speer", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["CARD", "ADJA", "NN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.24": {"text": "Das Eine ging hin, das Andere her.", "tokens": ["Das", "Ei\u00b7ne", "ging", "hin", ",", "das", "An\u00b7de\u00b7re", "her", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "PIS", "VVFIN", "PTKVZ", "$,", "PRELS", "PIS", "PTKVZ", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.25": {"text": "Da stach der T\u00fcrk den Dollinger ab,", "tokens": ["Da", "stach", "der", "T\u00fcrk", "den", "Dol\u00b7lin\u00b7ger", "ab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.26": {"text": "Da\u00df er an dem R\u00fccken lag.", "tokens": ["Da\u00df", "er", "an", "dem", "R\u00fc\u00b7cken", "lag", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.27": {"text": "\u00bbo Jesu Christ steh mir jetzt bey,", "tokens": ["\u00bb", "o", "Je\u00b7su", "Christ", "steh", "mir", "jetzt", "bey", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "FM", "NE", "NE", "VVFIN", "PPER", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.28": {"text": "Steck mir ein Zweig, sind ihrer drey.", "tokens": ["Steck", "mir", "ein", "Zweig", ",", "sind", "ih\u00b7rer", "drey", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ART", "NN", "$,", "VAFIN", "PPOSAT", "CARD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.29": {"text": "Bin ich allein, und f\u00fchr mein Seel ins Himmelreich.\u00ab", "tokens": ["Bin", "ich", "al\u00b7lein", ",", "und", "f\u00fchr", "mein", "Seel", "ins", "Him\u00b7mel\u00b7reich", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VAFIN", "PPER", "ADV", "$,", "KON", "VVFIN", "PPOSAT", "NN", "APPRART", "NN", "$.", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "Da ritt der Kayser zum Dollinger so behend,", "tokens": ["Da", "ritt", "der", "Kay\u00b7ser", "zum", "Dol\u00b7lin\u00b7ger", "so", "be\u00b7hend", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPRART", "NN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.31": {"text": "Er f\u00fchrt ein Kreutz in seiner H\u00e4nd,", "tokens": ["Er", "f\u00fchrt", "ein", "Kreutz", "in", "sei\u00b7ner", "H\u00e4nd", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.32": {"text": "Er strichs dem Dollinger \u00fcbern Mund", "tokens": ["Er", "strichs", "dem", "Dol\u00b7lin\u00b7ger", "\u00fc\u00b7bern", "Mund"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPRART", "NN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.33": {"text": "Der Dollinger sprang auf, war frisch und gesund.", "tokens": ["Der", "Dol\u00b7lin\u00b7ger", "sprang", "auf", ",", "war", "frisch", "und", "ge\u00b7sund", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "$,", "VAFIN", "ADJD", "KON", "ADJD", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.34": {"text": "Da stach der Dollinger den T\u00fcrken ab,", "tokens": ["Da", "stach", "der", "Dol\u00b7lin\u00b7ger", "den", "T\u00fcr\u00b7ken", "ab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.35": {"text": "Da\u00df er auf dem R\u00fccken lag.", "tokens": ["Da\u00df", "er", "auf", "dem", "R\u00fc\u00b7cken", "lag", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.36": {"text": "\u00bbdu ber\u00fchmter Teufel nun steh ihm bey.", "tokens": ["\u00bb", "du", "be\u00b7r\u00fchm\u00b7ter", "Teu\u00b7fel", "nun", "steh", "ihm", "bey", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "ADJA", "NN", "ADV", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.37": {"text": "Sind ihrer drey, bin ich allein", "tokens": ["Sind", "ih\u00b7rer", "drey", ",", "bin", "ich", "al\u00b7lein"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["VAFIN", "PPOSAT", "CARD", "$,", "VAFIN", "PPER", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.38": {"text": "Und f\u00fchr sein Seel in die bittere Pein.\u00ab", "tokens": ["Und", "f\u00fchr", "sein", "Seel", "in", "die", "bit\u00b7te\u00b7re", "Pein", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "APPR", "ART", "ADJA", "NN", "$.", "$("], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}}}}}