{"textgrid.poem.26579": {"metadata": {"author": {"name": "Saar, Ferdinand von", "birth": "N.A.", "death": "N.A."}, "title": "1L: Der Nachmittag war gl\u00fchend hei\u00df. Ich sa\u00df", "genre": "verse", "period": "N.A.", "pub_year": 1869, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Der Nachmittag war gl\u00fchend hei\u00df. Ich sa\u00df", "tokens": ["Der", "Nach\u00b7mit\u00b7tag", "war", "gl\u00fc\u00b7hend", "hei\u00df", ".", "Ich", "sa\u00df"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ADJD", "ADJD", "$.", "PPER", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "In eines Wirthes menschenleerem Garten;", "tokens": ["In", "ei\u00b7nes", "Wirt\u00b7hes", "men\u00b7schen\u00b7lee\u00b7rem", "Gar\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Gedankenvoll, beim kaum ber\u00fchrten Glas,", "tokens": ["Ge\u00b7dan\u00b7ken\u00b7voll", ",", "beim", "kaum", "be\u00b7r\u00fchr\u00b7ten", "Glas", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "APPRART", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Wollt' ich des Abends K\u00fchlung hier erwarten.", "tokens": ["Wollt'", "ich", "des", "A\u00b7bends", "K\u00fch\u00b7lung", "hier", "er\u00b7war\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ART", "NN", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Still durch die Wipfel strich ein schw\u00fcler Hauch,", "tokens": ["Still", "durch", "die", "Wip\u00b7fel", "strich", "ein", "schw\u00fc\u00b7ler", "Hauch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "ART", "NN", "ADJD", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Ged\u00e4mpft erklang des Stra\u00dfenl\u00e4rmes Wogen;", "tokens": ["Ge\u00b7d\u00e4mpft", "er\u00b7klang", "des", "Stra\u00b7\u00dfen\u00b7l\u00e4r\u00b7mes", "Wo\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Nach Krume zwitschernd, wie es Sperlingsbrauch,", "tokens": ["Nach", "Kru\u00b7me", "zwit\u00b7schernd", ",", "wie", "es", "Sper\u00b7lings\u00b7brauch", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVPP", "$,", "PWAV", "PPER", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Kam ab und zu ein kleiner Gast geflogen.", "tokens": ["Kam", "ab", "und", "zu", "ein", "klei\u00b7ner", "Gast", "ge\u00b7flo\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PTKVZ", "KON", "APPR", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Da h\u00f6rt' ich pl\u00f6tzlich nahen Doppeltritt \u2013", "tokens": ["Da", "h\u00f6rt'", "ich", "pl\u00f6tz\u00b7lich", "na\u00b7hen", "Dop\u00b7pel\u00b7tritt", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Und zwei Gestalten, hoch und schlank, erschienen:", "tokens": ["Und", "zwei", "Ge\u00b7stal\u00b7ten", ",", "hoch", "und", "schlank", ",", "er\u00b7schie\u00b7nen", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "CARD", "NN", "$,", "ADJD", "KON", "VVFIN", "$,", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Ein junges Paar, mit raschem, leichtem Schritt,", "tokens": ["Ein", "jun\u00b7ges", "Paar", ",", "mit", "ra\u00b7schem", ",", "leich\u00b7tem", "Schritt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "APPR", "ADJA", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Mit hellen Augen und mit klugen Mienen.", "tokens": ["Mit", "hel\u00b7len", "Au\u00b7gen", "und", "mit", "klu\u00b7gen", "Mie\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "KON", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Er fast ein J\u00fcngling noch. Mit breitem Rande", "tokens": ["Er", "fast", "ein", "J\u00fcng\u00b7ling", "noch", ".", "Mit", "brei\u00b7tem", "Ran\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "ADV", "ART", "NN", "ADV", "$.", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Sa\u00df l\u00e4ssig ihm der Hut auf dunklen Locken;", "tokens": ["Sa\u00df", "l\u00e4s\u00b7sig", "ihm", "der", "Hut", "auf", "dunk\u00b7len", "Lo\u00b7cken", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "PPER", "ART", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Zartbusig sie; auf lichtere Gewande", "tokens": ["Zart\u00b7bu\u00b7sig", "sie", ";", "auf", "lich\u00b7te\u00b7re", "Ge\u00b7wan\u00b7de"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ADJD", "PPER", "$.", "APPR", "ADJA", "NN"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Fiel blond ihr Haar, so wie der Flachs vom Rocken.", "tokens": ["Fiel", "blond", "ihr", "Haar", ",", "so", "wie", "der", "Flachs", "vom", "Ro\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "PPOSAT", "NN", "$,", "ADV", "KOKOM", "ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "Sie sah'n mich nicht und setzten sich zur Rast \u2013", "tokens": ["Sie", "sah'n", "mich", "nicht", "und", "setz\u00b7ten", "sich", "zur", "Rast", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKNEG", "KON", "VVFIN", "PRF", "APPRART", "NN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Man merkte wohl, sie seien noch nicht Gatten \u2013", "tokens": ["Man", "merk\u00b7te", "wohl", ",", "sie", "sei\u00b7en", "noch", "nicht", "Gat\u00b7ten", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ADV", "$,", "PPER", "VAFIN", "ADV", "PTKNEG", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Nach kurzem W\u00e4hlen mit zufried'ner Hast", "tokens": ["Nach", "kur\u00b7zem", "W\u00e4h\u00b7len", "mit", "zu\u00b7frie\u00b7d'\u00b7ner", "Hast"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.4": {"text": "Gleich in des n\u00e4chsten Baumes breiten Schatten.", "tokens": ["Gleich", "in", "des", "n\u00e4chs\u00b7ten", "Bau\u00b7mes", "brei\u00b7ten", "Schat\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "Nachdem sie sich mit raschem Trunk erfrischt,", "tokens": ["Nach\u00b7dem", "sie", "sich", "mit", "ra\u00b7schem", "Trunk", "er\u00b7frischt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Und auch vom Brod gebrochen einen Bissen,", "tokens": ["Und", "auch", "vom", "Brod", "ge\u00b7bro\u00b7chen", "ei\u00b7nen", "Bis\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPRART", "NN", "VVPP", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Lag schon ein Buch vor ihnen aufgetischt \u2013", "tokens": ["Lag", "schon", "ein", "Buch", "vor", "ih\u00b7nen", "auf\u00b7ge\u00b7tischt", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ART", "NN", "APPR", "PPER", "VVPP", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Ein gro\u00dfes Buch, zerlesen und zersplissen.", "tokens": ["Ein", "gro\u00b7\u00dfes", "Buch", ",", "zer\u00b7le\u00b7sen", "und", "zer\u00b7splis\u00b7sen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "VVPP", "KON", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.7": {"line.1": {"text": "Von \u00bbLanzelot\u00ab und von \u00bbGinevra\u00ab war,", "tokens": ["Von", "\u00bb", "Lan\u00b7ze\u00b7lot", "\u00ab", "und", "von", "\u00bb", "Gi\u00b7nev\u00b7ra", "\u00ab", "war", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["APPR", "$(", "NN", "$(", "KON", "APPR", "$(", "NE", "$(", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Das sah man, nichts in diesem Buch zu lesen;", "tokens": ["Das", "sah", "man", ",", "nichts", "in", "die\u00b7sem", "Buch", "zu", "le\u00b7sen", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PIS", "$,", "PIS", "APPR", "PDAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Dem Kennerblicke ward sofort auch klar,", "tokens": ["Dem", "Ken\u00b7ner\u00b7bli\u00b7cke", "ward", "so\u00b7fort", "auch", "klar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Da\u00df es ein Werk der Wissenschaft gewesen.", "tokens": ["Da\u00df", "es", "ein", "Werk", "der", "Wis\u00b7sen\u00b7schaft", "ge\u00b7we\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "ART", "NN", "VAPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.8": {"line.1": {"text": "Vielleicht von Darwin oder Stuart Mill \u2013", "tokens": ["Viel\u00b7leicht", "von", "Dar\u00b7win", "o\u00b7der", "Stu\u00b7art", "Mill", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NE", "KON", "NE", "NE", "$("], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Wie \u00e4ndern sich, so dacht' ich, doch die Zeiten,", "tokens": ["Wie", "\u00e4n\u00b7dern", "sich", ",", "so", "dacht'", "ich", ",", "doch", "die", "Zei\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PRF", "$,", "ADV", "VVFIN", "PPER", "$,", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Indessen Jene, leidenschaftlich still,", "tokens": ["In\u00b7des\u00b7sen", "Je\u00b7ne", ",", "lei\u00b7den\u00b7schaft\u00b7lich", "still", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Herniederseh'n auf eng bedruckte Seiten.", "tokens": ["Her\u00b7nie\u00b7der\u00b7seh'n", "auf", "eng", "be\u00b7druck\u00b7te", "Sei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ADJD", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.9": {"line.1": {"text": "Und er, so wie in unbewu\u00dftem Thun,", "tokens": ["Und", "er", ",", "so", "wie", "in", "un\u00b7be\u00b7wu\u00df\u00b7tem", "Thun", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "$,", "ADV", "KOKOM", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Die Hand nur legt auf ihre schmale, feine \u2013", "tokens": ["Die", "Hand", "nur", "legt", "auf", "ih\u00b7re", "schma\u00b7le", ",", "fei\u00b7ne", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVFIN", "APPR", "PPOSAT", "ADJA", "$,", "ADJA", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und sie, wie um beim Lesen auszuruh'n,", "tokens": ["Und", "sie", ",", "wie", "um", "beim", "Le\u00b7sen", "aus\u00b7zu\u00b7ruh'n", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "$,", "PWAV", "APPR", "APPRART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Die zarte Wange sanft lehnt an die seine.", "tokens": ["Die", "zar\u00b7te", "Wan\u00b7ge", "sanft", "lehnt", "an", "die", "sei\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADJD", "VVFIN", "APPR", "PRELS", "PPOSAT", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.10": {"line.1": {"text": "Mir aber ward der Anblick zum Gedicht,", "tokens": ["Mir", "a\u00b7ber", "ward", "der", "An\u00b7blick", "zum", "Ge\u00b7dicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VAFIN", "ART", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Zu einem neuen hohen Lied der Liebe,", "tokens": ["Zu", "ei\u00b7nem", "neu\u00b7en", "ho\u00b7hen", "Lied", "der", "Lie\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "ADJA", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Da ich verkl\u00e4rt sah von des Geistes Licht", "tokens": ["Da", "ich", "ver\u00b7kl\u00e4rt", "sah", "von", "des", "Geis\u00b7tes", "Licht"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "VVPP", "VVFIN", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Auf Erden schon den dunkelsten der Triebe.", "tokens": ["Auf", "Er\u00b7den", "schon", "den", "dun\u00b7kels\u00b7ten", "der", "Trie\u00b7be", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADV", "ART", "ADJA", "ART", "NN", "$."], "meter": "-+-+-+---+-", "measure": "unknown.measure.tetra"}}, "stanza.11": {"line.1": {"text": "Und mich erhebend, tief bewegt und leis',", "tokens": ["Und", "mich", "er\u00b7he\u00b7bend", ",", "tief", "be\u00b7wegt", "und", "leis'", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVPP", "$,", "ADJD", "VVPP", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Ging ich hinweg mit Schritten, kaum zu h\u00f6ren,", "tokens": ["Ging", "ich", "hin\u00b7weg", "mit", "Schrit\u00b7ten", ",", "kaum", "zu", "h\u00f6\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "APPR", "NN", "$,", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Um solcher Herzen reinen Zauberkreis", "tokens": ["Um", "sol\u00b7cher", "Her\u00b7zen", "rei\u00b7nen", "Zau\u00b7ber\u00b7kreis"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUI", "PIAT", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Und diese heil'ge Feier nicht zu st\u00f6ren.", "tokens": ["Und", "die\u00b7se", "heil'\u00b7ge", "Fei\u00b7er", "nicht", "zu", "st\u00f6\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDAT", "ADJA", "NN", "PTKNEG", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.12": {"line.1": {"text": "Der Nachmittag war gl\u00fchend hei\u00df. Ich sa\u00df", "tokens": ["Der", "Nach\u00b7mit\u00b7tag", "war", "gl\u00fc\u00b7hend", "hei\u00df", ".", "Ich", "sa\u00df"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ADJD", "ADJD", "$.", "PPER", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "In eines Wirthes menschenleerem Garten;", "tokens": ["In", "ei\u00b7nes", "Wirt\u00b7hes", "men\u00b7schen\u00b7lee\u00b7rem", "Gar\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Gedankenvoll, beim kaum ber\u00fchrten Glas,", "tokens": ["Ge\u00b7dan\u00b7ken\u00b7voll", ",", "beim", "kaum", "be\u00b7r\u00fchr\u00b7ten", "Glas", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "APPRART", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Wollt' ich des Abends K\u00fchlung hier erwarten.", "tokens": ["Wollt'", "ich", "des", "A\u00b7bends", "K\u00fch\u00b7lung", "hier", "er\u00b7war\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ART", "NN", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.13": {"line.1": {"text": "Still durch die Wipfel strich ein schw\u00fcler Hauch,", "tokens": ["Still", "durch", "die", "Wip\u00b7fel", "strich", "ein", "schw\u00fc\u00b7ler", "Hauch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "ART", "NN", "ADJD", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Ged\u00e4mpft erklang des Stra\u00dfenl\u00e4rmes Wogen;", "tokens": ["Ge\u00b7d\u00e4mpft", "er\u00b7klang", "des", "Stra\u00b7\u00dfen\u00b7l\u00e4r\u00b7mes", "Wo\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Nach Krume zwitschernd, wie es Sperlingsbrauch,", "tokens": ["Nach", "Kru\u00b7me", "zwit\u00b7schernd", ",", "wie", "es", "Sper\u00b7lings\u00b7brauch", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVPP", "$,", "PWAV", "PPER", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Kam ab und zu ein kleiner Gast geflogen.", "tokens": ["Kam", "ab", "und", "zu", "ein", "klei\u00b7ner", "Gast", "ge\u00b7flo\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PTKVZ", "KON", "APPR", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.14": {"line.1": {"text": "Da h\u00f6rt' ich pl\u00f6tzlich nahen Doppeltritt \u2013", "tokens": ["Da", "h\u00f6rt'", "ich", "pl\u00f6tz\u00b7lich", "na\u00b7hen", "Dop\u00b7pel\u00b7tritt", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Und zwei Gestalten, hoch und schlank, erschienen:", "tokens": ["Und", "zwei", "Ge\u00b7stal\u00b7ten", ",", "hoch", "und", "schlank", ",", "er\u00b7schie\u00b7nen", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "CARD", "NN", "$,", "ADJD", "KON", "VVFIN", "$,", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Ein junges Paar, mit raschem, leichtem Schritt,", "tokens": ["Ein", "jun\u00b7ges", "Paar", ",", "mit", "ra\u00b7schem", ",", "leich\u00b7tem", "Schritt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "APPR", "ADJA", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Mit hellen Augen und mit klugen Mienen.", "tokens": ["Mit", "hel\u00b7len", "Au\u00b7gen", "und", "mit", "klu\u00b7gen", "Mie\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "KON", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.15": {"line.1": {"text": "Er fast ein J\u00fcngling noch. Mit breitem Rande", "tokens": ["Er", "fast", "ein", "J\u00fcng\u00b7ling", "noch", ".", "Mit", "brei\u00b7tem", "Ran\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "ADV", "ART", "NN", "ADV", "$.", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Sa\u00df l\u00e4ssig ihm der Hut auf dunklen Locken;", "tokens": ["Sa\u00df", "l\u00e4s\u00b7sig", "ihm", "der", "Hut", "auf", "dunk\u00b7len", "Lo\u00b7cken", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "PPER", "ART", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Zartbusig sie; auf lichtere Gewande", "tokens": ["Zart\u00b7bu\u00b7sig", "sie", ";", "auf", "lich\u00b7te\u00b7re", "Ge\u00b7wan\u00b7de"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ADJD", "PPER", "$.", "APPR", "ADJA", "NN"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Fiel blond ihr Haar, so wie der Flachs vom Rocken.", "tokens": ["Fiel", "blond", "ihr", "Haar", ",", "so", "wie", "der", "Flachs", "vom", "Ro\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "PPOSAT", "NN", "$,", "ADV", "KOKOM", "ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.16": {"line.1": {"text": "Sie sah'n mich nicht und setzten sich zur Rast \u2013", "tokens": ["Sie", "sah'n", "mich", "nicht", "und", "setz\u00b7ten", "sich", "zur", "Rast", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKNEG", "KON", "VVFIN", "PRF", "APPRART", "NN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Man merkte wohl, sie seien noch nicht Gatten \u2013", "tokens": ["Man", "merk\u00b7te", "wohl", ",", "sie", "sei\u00b7en", "noch", "nicht", "Gat\u00b7ten", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ADV", "$,", "PPER", "VAFIN", "ADV", "PTKNEG", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Nach kurzem W\u00e4hlen mit zufried'ner Hast", "tokens": ["Nach", "kur\u00b7zem", "W\u00e4h\u00b7len", "mit", "zu\u00b7frie\u00b7d'\u00b7ner", "Hast"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.4": {"text": "Gleich in des n\u00e4chsten Baumes breiten Schatten.", "tokens": ["Gleich", "in", "des", "n\u00e4chs\u00b7ten", "Bau\u00b7mes", "brei\u00b7ten", "Schat\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.17": {"line.1": {"text": "Nachdem sie sich mit raschem Trunk erfrischt,", "tokens": ["Nach\u00b7dem", "sie", "sich", "mit", "ra\u00b7schem", "Trunk", "er\u00b7frischt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Und auch vom Brod gebrochen einen Bissen,", "tokens": ["Und", "auch", "vom", "Brod", "ge\u00b7bro\u00b7chen", "ei\u00b7nen", "Bis\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPRART", "NN", "VVPP", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Lag schon ein Buch vor ihnen aufgetischt \u2013", "tokens": ["Lag", "schon", "ein", "Buch", "vor", "ih\u00b7nen", "auf\u00b7ge\u00b7tischt", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ART", "NN", "APPR", "PPER", "VVPP", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Ein gro\u00dfes Buch, zerlesen und zersplissen.", "tokens": ["Ein", "gro\u00b7\u00dfes", "Buch", ",", "zer\u00b7le\u00b7sen", "und", "zer\u00b7splis\u00b7sen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "VVPP", "KON", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.18": {"line.1": {"text": "Von \u00bbLanzelot\u00ab und von \u00bbGinevra\u00ab war,", "tokens": ["Von", "\u00bb", "Lan\u00b7ze\u00b7lot", "\u00ab", "und", "von", "\u00bb", "Gi\u00b7nev\u00b7ra", "\u00ab", "war", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["APPR", "$(", "NN", "$(", "KON", "APPR", "$(", "NE", "$(", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Das sah man, nichts in diesem Buch zu lesen;", "tokens": ["Das", "sah", "man", ",", "nichts", "in", "die\u00b7sem", "Buch", "zu", "le\u00b7sen", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PIS", "$,", "PIS", "APPR", "PDAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Dem Kennerblicke ward sofort auch klar,", "tokens": ["Dem", "Ken\u00b7ner\u00b7bli\u00b7cke", "ward", "so\u00b7fort", "auch", "klar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Da\u00df es ein Werk der Wissenschaft gewesen.", "tokens": ["Da\u00df", "es", "ein", "Werk", "der", "Wis\u00b7sen\u00b7schaft", "ge\u00b7we\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "ART", "NN", "VAPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.19": {"line.1": {"text": "Vielleicht von Darwin oder Stuart Mill \u2013", "tokens": ["Viel\u00b7leicht", "von", "Dar\u00b7win", "o\u00b7der", "Stu\u00b7art", "Mill", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NE", "KON", "NE", "NE", "$("], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Wie \u00e4ndern sich, so dacht' ich, doch die Zeiten,", "tokens": ["Wie", "\u00e4n\u00b7dern", "sich", ",", "so", "dacht'", "ich", ",", "doch", "die", "Zei\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PRF", "$,", "ADV", "VVFIN", "PPER", "$,", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Indessen Jene, leidenschaftlich still,", "tokens": ["In\u00b7des\u00b7sen", "Je\u00b7ne", ",", "lei\u00b7den\u00b7schaft\u00b7lich", "still", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Herniederseh'n auf eng bedruckte Seiten.", "tokens": ["Her\u00b7nie\u00b7der\u00b7seh'n", "auf", "eng", "be\u00b7druck\u00b7te", "Sei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ADJD", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.20": {"line.1": {"text": "Und er, so wie in unbewu\u00dftem Thun,", "tokens": ["Und", "er", ",", "so", "wie", "in", "un\u00b7be\u00b7wu\u00df\u00b7tem", "Thun", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "$,", "ADV", "KOKOM", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Die Hand nur legt auf ihre schmale, feine \u2013", "tokens": ["Die", "Hand", "nur", "legt", "auf", "ih\u00b7re", "schma\u00b7le", ",", "fei\u00b7ne", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVFIN", "APPR", "PPOSAT", "ADJA", "$,", "ADJA", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und sie, wie um beim Lesen auszuruh'n,", "tokens": ["Und", "sie", ",", "wie", "um", "beim", "Le\u00b7sen", "aus\u00b7zu\u00b7ruh'n", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "$,", "PWAV", "APPR", "APPRART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Die zarte Wange sanft lehnt an die seine.", "tokens": ["Die", "zar\u00b7te", "Wan\u00b7ge", "sanft", "lehnt", "an", "die", "sei\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADJD", "VVFIN", "APPR", "PRELS", "PPOSAT", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.21": {"line.1": {"text": "Mir aber ward der Anblick zum Gedicht,", "tokens": ["Mir", "a\u00b7ber", "ward", "der", "An\u00b7blick", "zum", "Ge\u00b7dicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VAFIN", "ART", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Zu einem neuen hohen Lied der Liebe,", "tokens": ["Zu", "ei\u00b7nem", "neu\u00b7en", "ho\u00b7hen", "Lied", "der", "Lie\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "ADJA", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Da ich verkl\u00e4rt sah von des Geistes Licht", "tokens": ["Da", "ich", "ver\u00b7kl\u00e4rt", "sah", "von", "des", "Geis\u00b7tes", "Licht"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "VVPP", "VVFIN", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Auf Erden schon den dunkelsten der Triebe.", "tokens": ["Auf", "Er\u00b7den", "schon", "den", "dun\u00b7kels\u00b7ten", "der", "Trie\u00b7be", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADV", "ART", "ADJA", "ART", "NN", "$."], "meter": "-+-+-+---+-", "measure": "unknown.measure.tetra"}}, "stanza.22": {"line.1": {"text": "Und mich erhebend, tief bewegt und leis',", "tokens": ["Und", "mich", "er\u00b7he\u00b7bend", ",", "tief", "be\u00b7wegt", "und", "leis'", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVPP", "$,", "ADJD", "VVPP", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Ging ich hinweg mit Schritten, kaum zu h\u00f6ren,", "tokens": ["Ging", "ich", "hin\u00b7weg", "mit", "Schrit\u00b7ten", ",", "kaum", "zu", "h\u00f6\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "APPR", "NN", "$,", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Um solcher Herzen reinen Zauberkreis", "tokens": ["Um", "sol\u00b7cher", "Her\u00b7zen", "rei\u00b7nen", "Zau\u00b7ber\u00b7kreis"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUI", "PIAT", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Und diese heil'ge Feier nicht zu st\u00f6ren.", "tokens": ["Und", "die\u00b7se", "heil'\u00b7ge", "Fei\u00b7er", "nicht", "zu", "st\u00f6\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDAT", "ADJA", "NN", "PTKNEG", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}}}}