{"textgrid.poem.48233": {"metadata": {"author": {"name": "Fontane, Theodor", "birth": "N.A.", "death": "N.A."}, "title": "Unsre \u00bbdeutsche Frau\u00ab", "genre": "verse", "period": "N.A.", "pub_year": 1890, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Hierlandes ist unsre \u00bbdeutsche Frau\u00ab", "tokens": ["Hier\u00b7lan\u00b7des", "ist", "uns\u00b7re", "\u00bb", "deut\u00b7sche", "Frau", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PPOSAT", "$(", "ADJA", "NN", "$("], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Noch immer aus Friesack oder Bernau,", "tokens": ["Noch", "im\u00b7mer", "aus", "Frie\u00b7sack", "o\u00b7der", "Bern\u00b7au", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "NE", "KON", "NE", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Nur dem Kleinen gilt ihre Respektbezeigung,", "tokens": ["Nur", "dem", "Klei\u00b7nen", "gilt", "ih\u00b7re", "Res\u00b7pekt\u00b7be\u00b7zei\u00b7gung", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.4": {"text": "Aus Not nicht, nein, aus purer Neigung,", "tokens": ["Aus", "Not", "nicht", ",", "nein", ",", "aus", "pu\u00b7rer", "Nei\u00b7gung", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PTKNEG", "$,", "PTKANT", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Uralte Themen uralter Epochen", "tokens": ["Ur\u00b7al\u00b7te", "The\u00b7men", "ur\u00b7al\u00b7ter", "E\u00b7po\u00b7chen"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJA", "NN", "ADJA", "NN"], "meter": "+--+-++--+-", "measure": "iambic.penta.invert"}, "line.6": {"text": "Werden am liebsten durchgesprochen:", "tokens": ["Wer\u00b7den", "am", "liebs\u00b7ten", "durch\u00b7ge\u00b7spro\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PTKA", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Die K\u00fcche, die W\u00e4sche, die Wohnung \u2013 und dann", "tokens": ["Die", "K\u00fc\u00b7che", ",", "die", "W\u00e4\u00b7sche", ",", "die", "Woh\u00b7nung", "\u2013", "und", "dann"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "$,", "ART", "NN", "$,", "ART", "NN", "$(", "KON", "ADV"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.8": {"text": "(unersch\u00f6pfliches Thema) \u00bbmein Mann, mein Mann\u00ab.", "tokens": ["(", "un\u00b7er\u00b7sch\u00f6pf\u00b7li\u00b7ches", "The\u00b7ma", ")", "\u00bb", "mein", "Mann", ",", "mein", "Mann", "\u00ab", "."], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["$(", "ADJA", "NN", "$(", "$(", "PPOSAT", "NN", "$,", "PPOSAT", "NN", "$(", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}}, "stanza.2": {"line.1": {"text": "\u00bbmein Mann ist eigentlich viel zu gut,", "tokens": ["\u00bb", "mein", "Mann", "ist", "ei\u00b7gent\u00b7lich", "viel", "zu", "gut", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPOSAT", "NN", "VAFIN", "ADV", "ADV", "PTKA", "ADJD", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Und kommt er mal gegen mich in Wut,", "tokens": ["Und", "kommt", "er", "mal", "ge\u00b7gen", "mich", "in", "Wut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "APPR", "PRF", "APPR", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Ist es immer blo\u00df wegen der dummen Dinger,", "tokens": ["Ist", "es", "im\u00b7mer", "blo\u00df", "we\u00b7gen", "der", "dum\u00b7men", "Din\u00b7ger", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ADV", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-++--+-+-", "measure": "trochaic.hexa.relaxed"}, "line.4": {"text": "Denen sieht er alles durch die Finger;", "tokens": ["De\u00b7nen", "sieht", "er", "al\u00b7les", "durch", "die", "Fin\u00b7ger", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "PIS", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.5": {"text": "Eine Vierzehnj\u00e4hrige nennt er \u203aSie\u2039,", "tokens": ["Ei\u00b7ne", "Vier\u00b7zehn\u00b7j\u00e4h\u00b7ri\u00b7ge", "nennt", "er", "\u203a", "Sie", "\u2039", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "$(", "PPER", "$(", "$,"], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.6": {"text": "Mittwochs hat er Skatpartie.", "tokens": ["Mitt\u00b7wochs", "hat", "er", "Skat\u00b7par\u00b7tie", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Da w\u00fcrd' ich nun gern ins Theater gehn,", "tokens": ["Da", "w\u00fcrd'", "ich", "nun", "gern", "ins", "The\u00b7a\u00b7ter", "gehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ADV", "APPRART", "NN", "VVINF", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.8": {"text": "Aber, am Ende, was soll man sehn?", "tokens": ["A\u00b7ber", ",", "am", "En\u00b7de", ",", "was", "soll", "man", "sehn", "?"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "APPRART", "NN", "$,", "PWS", "VMFIN", "PIS", "VVINF", "$."], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.9": {"text": "\u203asodoms Ende\u2039 gilt ja f\u00fcr unmoralisch,", "tokens": ["\u203a", "so\u00b7doms", "En\u00b7de", "\u2039", "gilt", "ja", "f\u00fcr", "un\u00b7mo\u00b7ra\u00b7lisch", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJA", "NN", "$(", "VVFIN", "ADV", "APPR", "ADJD", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.10": {"text": "Schiller ist mir zu theatralisch", "tokens": ["Schil\u00b7ler", "ist", "mir", "zu", "the\u00b7at\u00b7ra\u00b7lisch"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "VAFIN", "PPER", "PTKA", "ADJD"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.11": {"text": "Und macht immer sch\u00f6ne Worte nur \u2013", "tokens": ["Und", "macht", "im\u00b7mer", "sch\u00f6\u00b7ne", "Wor\u00b7te", "nur", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ADJA", "NN", "ADV", "$("], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.12": {"text": "Das Beste bleibt doch freie Natur:", "tokens": ["Das", "Bes\u00b7te", "bleibt", "doch", "frei\u00b7e", "Na\u00b7tur", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "ADJA", "NN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.13": {"text": "Am Gro\u00dfen Stern auf den Kaiser warten,", "tokens": ["Am", "Gro\u00b7\u00dfen", "Stern", "auf", "den", "Kai\u00b7ser", "war\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.14": {"text": "Konzert im Zoologischen Garten,", "tokens": ["Kon\u00b7zert", "im", "Zoo\u00b7lo\u00b7gi\u00b7schen", "Gar\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "Flamingo, B\u00fcffel, Pelikan,", "tokens": ["Fla\u00b7min\u00b7go", ",", "B\u00fcf\u00b7fel", ",", "Pe\u00b7li\u00b7kan", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["NE", "$,", "NN", "$,", "NE", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.16": {"text": "Und Abends (zum Spargel) kommt \u203amein Mann\u2039", "tokens": ["Und", "A\u00b7bends", "(", "zum", "Spar\u00b7gel", ")", "kommt", "\u203a", "mein", "Mann", "\u2039"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["KON", "NN", "$(", "APPRART", "NN", "$(", "VVFIN", "$(", "PPOSAT", "NN", "$("], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.17": {"text": "Und Rudolf auch, und die Zeit vergeht,", "tokens": ["Und", "Ru\u00b7dolf", "auch", ",", "und", "die", "Zeit", "ver\u00b7geht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "ADV", "$,", "KON", "ART", "NN", "VVFIN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.18": {"text": "Und der liebe Mond am Himmel steht.\u00ab", "tokens": ["Und", "der", "lie\u00b7be", "Mond", "am", "Him\u00b7mel", "steht", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "APPRART", "NN", "VVFIN", "$.", "$("], "meter": "--+-+-+-+", "measure": "anapaest.init"}}, "stanza.3": {"line.1": {"text": "Hierlandes ist unsre \u00bbdeutsche Frau\u00ab", "tokens": ["Hier\u00b7lan\u00b7des", "ist", "uns\u00b7re", "\u00bb", "deut\u00b7sche", "Frau", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PPOSAT", "$(", "ADJA", "NN", "$("], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Noch immer aus Friesack oder Bernau,", "tokens": ["Noch", "im\u00b7mer", "aus", "Frie\u00b7sack", "o\u00b7der", "Bern\u00b7au", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "NE", "KON", "NE", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Nur dem Kleinen gilt ihre Respektbezeigung,", "tokens": ["Nur", "dem", "Klei\u00b7nen", "gilt", "ih\u00b7re", "Res\u00b7pekt\u00b7be\u00b7zei\u00b7gung", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.4": {"text": "Aus Not nicht, nein, aus purer Neigung,", "tokens": ["Aus", "Not", "nicht", ",", "nein", ",", "aus", "pu\u00b7rer", "Nei\u00b7gung", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PTKNEG", "$,", "PTKANT", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Uralte Themen uralter Epochen", "tokens": ["Ur\u00b7al\u00b7te", "The\u00b7men", "ur\u00b7al\u00b7ter", "E\u00b7po\u00b7chen"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJA", "NN", "ADJA", "NN"], "meter": "+--+-++--+-", "measure": "iambic.penta.invert"}, "line.6": {"text": "Werden am liebsten durchgesprochen:", "tokens": ["Wer\u00b7den", "am", "liebs\u00b7ten", "durch\u00b7ge\u00b7spro\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PTKA", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Die K\u00fcche, die W\u00e4sche, die Wohnung \u2013 und dann", "tokens": ["Die", "K\u00fc\u00b7che", ",", "die", "W\u00e4\u00b7sche", ",", "die", "Woh\u00b7nung", "\u2013", "und", "dann"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "$,", "ART", "NN", "$,", "ART", "NN", "$(", "KON", "ADV"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.8": {"text": "(unersch\u00f6pfliches Thema) \u00bbmein Mann, mein Mann\u00ab.", "tokens": ["(", "un\u00b7er\u00b7sch\u00f6pf\u00b7li\u00b7ches", "The\u00b7ma", ")", "\u00bb", "mein", "Mann", ",", "mein", "Mann", "\u00ab", "."], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["$(", "ADJA", "NN", "$(", "$(", "PPOSAT", "NN", "$,", "PPOSAT", "NN", "$(", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}}, "stanza.4": {"line.1": {"text": "\u00bbmein Mann ist eigentlich viel zu gut,", "tokens": ["\u00bb", "mein", "Mann", "ist", "ei\u00b7gent\u00b7lich", "viel", "zu", "gut", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPOSAT", "NN", "VAFIN", "ADV", "ADV", "PTKA", "ADJD", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Und kommt er mal gegen mich in Wut,", "tokens": ["Und", "kommt", "er", "mal", "ge\u00b7gen", "mich", "in", "Wut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "APPR", "PRF", "APPR", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Ist es immer blo\u00df wegen der dummen Dinger,", "tokens": ["Ist", "es", "im\u00b7mer", "blo\u00df", "we\u00b7gen", "der", "dum\u00b7men", "Din\u00b7ger", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ADV", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-++--+-+-", "measure": "trochaic.hexa.relaxed"}, "line.4": {"text": "Denen sieht er alles durch die Finger;", "tokens": ["De\u00b7nen", "sieht", "er", "al\u00b7les", "durch", "die", "Fin\u00b7ger", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "PIS", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.5": {"text": "Eine Vierzehnj\u00e4hrige nennt er \u203aSie\u2039,", "tokens": ["Ei\u00b7ne", "Vier\u00b7zehn\u00b7j\u00e4h\u00b7ri\u00b7ge", "nennt", "er", "\u203a", "Sie", "\u2039", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "$(", "PPER", "$(", "$,"], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.6": {"text": "Mittwochs hat er Skatpartie.", "tokens": ["Mitt\u00b7wochs", "hat", "er", "Skat\u00b7par\u00b7tie", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Da w\u00fcrd' ich nun gern ins Theater gehn,", "tokens": ["Da", "w\u00fcrd'", "ich", "nun", "gern", "ins", "The\u00b7a\u00b7ter", "gehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ADV", "APPRART", "NN", "VVINF", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.8": {"text": "Aber, am Ende, was soll man sehn?", "tokens": ["A\u00b7ber", ",", "am", "En\u00b7de", ",", "was", "soll", "man", "sehn", "?"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "APPRART", "NN", "$,", "PWS", "VMFIN", "PIS", "VVINF", "$."], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.9": {"text": "\u203asodoms Ende\u2039 gilt ja f\u00fcr unmoralisch,", "tokens": ["\u203a", "so\u00b7doms", "En\u00b7de", "\u2039", "gilt", "ja", "f\u00fcr", "un\u00b7mo\u00b7ra\u00b7lisch", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJA", "NN", "$(", "VVFIN", "ADV", "APPR", "ADJD", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.10": {"text": "Schiller ist mir zu theatralisch", "tokens": ["Schil\u00b7ler", "ist", "mir", "zu", "the\u00b7at\u00b7ra\u00b7lisch"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "VAFIN", "PPER", "PTKA", "ADJD"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.11": {"text": "Und macht immer sch\u00f6ne Worte nur \u2013", "tokens": ["Und", "macht", "im\u00b7mer", "sch\u00f6\u00b7ne", "Wor\u00b7te", "nur", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ADJA", "NN", "ADV", "$("], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.12": {"text": "Das Beste bleibt doch freie Natur:", "tokens": ["Das", "Bes\u00b7te", "bleibt", "doch", "frei\u00b7e", "Na\u00b7tur", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "ADJA", "NN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.13": {"text": "Am Gro\u00dfen Stern auf den Kaiser warten,", "tokens": ["Am", "Gro\u00b7\u00dfen", "Stern", "auf", "den", "Kai\u00b7ser", "war\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.14": {"text": "Konzert im Zoologischen Garten,", "tokens": ["Kon\u00b7zert", "im", "Zoo\u00b7lo\u00b7gi\u00b7schen", "Gar\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "Flamingo, B\u00fcffel, Pelikan,", "tokens": ["Fla\u00b7min\u00b7go", ",", "B\u00fcf\u00b7fel", ",", "Pe\u00b7li\u00b7kan", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["NE", "$,", "NN", "$,", "NE", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.16": {"text": "Und Abends (zum Spargel) kommt \u203amein Mann\u2039", "tokens": ["Und", "A\u00b7bends", "(", "zum", "Spar\u00b7gel", ")", "kommt", "\u203a", "mein", "Mann", "\u2039"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["KON", "NN", "$(", "APPRART", "NN", "$(", "VVFIN", "$(", "PPOSAT", "NN", "$("], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.17": {"text": "Und Rudolf auch, und die Zeit vergeht,", "tokens": ["Und", "Ru\u00b7dolf", "auch", ",", "und", "die", "Zeit", "ver\u00b7geht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "ADV", "$,", "KON", "ART", "NN", "VVFIN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.18": {"text": "Und der liebe Mond am Himmel steht.\u00ab", "tokens": ["Und", "der", "lie\u00b7be", "Mond", "am", "Him\u00b7mel", "steht", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "APPRART", "NN", "VVFIN", "$.", "$("], "meter": "--+-+-+-+", "measure": "anapaest.init"}}}}}