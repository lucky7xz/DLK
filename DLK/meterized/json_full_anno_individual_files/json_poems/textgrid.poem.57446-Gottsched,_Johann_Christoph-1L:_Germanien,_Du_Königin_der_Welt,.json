{"textgrid.poem.57446": {"metadata": {"author": {"name": "Gottsched, Johann Christoph", "birth": "N.A.", "death": "N.A."}, "title": "1L: Germanien, Du K\u00f6nigin der Welt,", "genre": "verse", "period": "N.A.", "pub_year": 1733, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Germanien, Du K\u00f6nigin der Welt,", "tokens": ["Ger\u00b7ma\u00b7ni\u00b7en", ",", "Du", "K\u00f6\u00b7ni\u00b7gin", "der", "Welt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PPER", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Vor deren Thron sich hundert V\u00f6lcker schmiegen,", "tokens": ["Vor", "de\u00b7ren", "Thron", "sich", "hun\u00b7dert", "V\u00f6l\u00b7cker", "schmie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELAT", "NN", "PRF", "CARD", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Auf deren Winck sich tausend F\u00fcrsten biegen,", "tokens": ["Auf", "de\u00b7ren", "Win\u00b7ck", "sich", "tau\u00b7send", "F\u00fcrs\u00b7ten", "bie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELAT", "NN", "PRF", "CARD", "NN", "VVFIN", "$,"], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Der Ost und West geb\u00fcckt zu Fusse f\u00e4llt;", "tokens": ["Der", "Ost", "und", "West", "ge\u00b7b\u00fcckt", "zu", "Fus\u00b7se", "f\u00e4llt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "VVPP", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Verschm\u00e4he nicht die Lob-Schrifft Deiner Thaten:", "tokens": ["Ver\u00b7schm\u00e4\u00b7he", "nicht", "die", "Lob\u00b7Schrifft", "Dei\u00b7ner", "Tha\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "ART", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Indem Dein Ruhm noch t\u00e4glich h\u00f6her steigt,", "tokens": ["In\u00b7dem", "Dein", "Ruhm", "noch", "t\u00e4g\u00b7lich", "h\u00f6\u00b7her", "steigt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "ADV", "ADJD", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Und allen Neid erboster Nachbarn beugt,", "tokens": ["Und", "al\u00b7len", "Neid", "er\u00b7bos\u00b7ter", "Nach\u00b7barn", "beugt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "L\u00e4\u00dft Ph\u00f6bus mir ein Helden-Lied gerathen.", "tokens": ["L\u00e4\u00dft", "Ph\u00f6\u00b7bus", "mir", "ein", "Hel\u00b7den\u00b7Lied", "ge\u00b7ra\u00b7then", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "PPER", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Wer ehret nicht der R\u00f6mer K\u00e4yser-Thron?", "tokens": ["Wer", "eh\u00b7ret", "nicht", "der", "R\u00f6\u00b7mer", "K\u00e4y\u00b7ser\u00b7Thron", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PTKNEG", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Und der mu\u00df Dir ein ewig Erbtheil werden.", "tokens": ["Und", "der", "mu\u00df", "Dir", "ein", "e\u00b7wig", "E\u00b7rbtheil", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "VMFIN", "PPER", "ART", "ADJD", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Wer kennt nicht Wien, das neue Rom der Erden,", "tokens": ["Wer", "kennt", "nicht", "Wi\u00b7en", ",", "das", "neu\u00b7e", "Rom", "der", "Er\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PTKNEG", "NE", "$,", "ART", "ADJA", "NE", "ART", "NN", "$,"], "meter": "-+----+-+-+-", "measure": "dactylic.init"}, "line.4": {"text": "Und unsern Carl, den tapfern Helden-Sohn?", "tokens": ["Und", "un\u00b7sern", "Carl", ",", "den", "tap\u00b7fern", "Hel\u00b7den\u00b7Sohn", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NE", "$,", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Die Gallier und die den Tagus trincken,", "tokens": ["Die", "Gal\u00b7lier", "und", "die", "den", "Ta\u00b7gus", "trin\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.6": {"text": "Der kalte Belt, der Scyth und Muselmann,", "tokens": ["Der", "kal\u00b7te", "Belt", ",", "der", "Scyth", "und", "Mu\u00b7sel\u00b7mann", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Sehn seinen Glantz mit reger Ehrfurcht an,", "tokens": ["Sehn", "sei\u00b7nen", "Glantz", "mit", "re\u00b7ger", "Ehr\u00b7furcht", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "APPR", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Und zittern schon vor seiner Schwerdter Blincken.", "tokens": ["Und", "zit\u00b7tern", "schon", "vor", "sei\u00b7ner", "Schwerd\u00b7ter", "Blin\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "APPR", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Der edle Rhein wei\u00df Franckreichs Phantasey", "tokens": ["Der", "ed\u00b7le", "Rhein", "wei\u00df", "Fran\u00b7ck\u00b7reichs", "Phan\u00b7ta\u00b7sey"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NE", "VVFIN", "NE", "NE"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Noch unverr\u00fcckt das letzte Ziel zu stecken.", "tokens": ["Noch", "un\u00b7ver\u00b7r\u00fcckt", "das", "letz\u00b7te", "Ziel", "zu", "ste\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ART", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "So lange Kehl und Philippsburg ihn decken,", "tokens": ["So", "lan\u00b7ge", "Kehl", "und", "Phi\u00b7lipps\u00b7burg", "ihn", "de\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "KON", "NE", "PPER", "VVINF", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Verlacht er stets die fremde Sclaverey.", "tokens": ["Ver\u00b7lacht", "er", "stets", "die", "frem\u00b7de", "Scla\u00b7ve\u00b7rey", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Die Donau darf den Fessel-freyen R\u00fccken,", "tokens": ["Die", "Do\u00b7nau", "darf", "den", "Fes\u00b7sel\u00b7freyen", "R\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "VMFIN", "ART", "NN", "NN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Nicht mehr so weit in Achmets Herrschafft sehn,", "tokens": ["Nicht", "mehr", "so", "weit", "in", "Ach\u00b7mets", "Herr\u00b7schafft", "sehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "ADV", "ADJD", "APPR", "NE", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Und kan die Fluth mit freyern Wirbeln drehn,", "tokens": ["Und", "kan", "die", "Fluth", "mit", "frey\u00b7ern", "Wir\u00b7beln", "drehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ART", "NN", "APPR", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Sie siebenfach ins schwartze Meer zu schicken.", "tokens": ["Sie", "sie\u00b7ben\u00b7fach", "ins", "schwart\u00b7ze", "Meer", "zu", "schi\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PRF", "APPRART", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Giebt Deutschland nicht der Europ\u00e4er Welt,", "tokens": ["Giebt", "Deutschland", "nicht", "der", "Eu\u00b7ro\u00b7p\u00e4\u00b7er", "Welt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "PTKNEG", "ART", "NN", "NN", "$,"], "meter": "----+-+-+", "measure": "unknown.measure.tri"}, "line.2": {"text": "Fast jedes Haupt die V\u00f6lcker zu regieren?", "tokens": ["Fast", "je\u00b7des", "Haupt", "die", "V\u00f6l\u00b7cker", "zu", "re\u00b7gie\u00b7ren", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Ein deutscher Printz mu\u00df Schwedens Zepter f\u00fchren;", "tokens": ["Ein", "deut\u00b7scher", "Printz", "mu\u00df", "Schwe\u00b7dens", "Zep\u00b7ter", "f\u00fch\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VMFIN", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Sarmatien beherrscht ein deutscher Held.", "tokens": ["Sar\u00b7ma\u00b7ti\u00b7en", "be\u00b7herrscht", "ein", "deut\u00b7scher", "Held", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Noch neulich hat der Engell\u00e4nder Krone", "tokens": ["Noch", "neu\u00b7lich", "hat", "der", "En\u00b7gel\u00b7l\u00e4n\u00b7der", "Kro\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "VAFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Hannovers Haupt recht K\u00f6niglich geschm\u00fcckt:", "tokens": ["Han\u00b7no\u00b7vers", "Haupt", "recht", "K\u00f6\u00b7nig\u00b7lich", "ge\u00b7schm\u00fcckt", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "ADJD", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Hesperien und Servien erblickt,", "tokens": ["Hes\u00b7pe\u00b7ri\u00b7en", "und", "Ser\u00b7vi\u00b7en", "er\u00b7blickt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "NE", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Sein h\u00f6chstes Wohl auf Deutschlands K\u00e4yser-Throne.", "tokens": ["Sein", "h\u00f6chs\u00b7tes", "Wohl", "auf", "Deutschlands", "K\u00e4y\u00b7ser\u00b7Thro\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "APPR", "NE", "NE", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.5": {"line.1": {"text": "Man sp\u00fcrt ja noch der Deutschen Sprache Rest,", "tokens": ["Man", "sp\u00fcrt", "ja", "noch", "der", "Deut\u00b7schen", "Spra\u00b7che", "Rest", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ADV", "ADV", "ART", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "So weit das Schwerdt Germaniens gedrungen;", "tokens": ["So", "weit", "das", "Schwerdt", "Ger\u00b7ma\u00b7ni\u00b7ens", "ge\u00b7drun\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ART", "NN", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Europa h\u00f6rt von aller V\u00f6lcker Zungen,", "tokens": ["Eu\u00b7ro\u00b7pa", "h\u00f6rt", "von", "al\u00b7ler", "V\u00f6l\u00b7cker", "Zun\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPR", "PIAT", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Was uns der Nord bis I\u00dfland h\u00f6ren l\u00e4\u00dft.", "tokens": ["Was", "uns", "der", "Nord", "bis", "I\u00df\u00b7land", "h\u00f6\u00b7ren", "l\u00e4\u00dft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ART", "NN", "APPR", "NE", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Von Griechenland bis zu den Portugiesen", "tokens": ["Von", "Grie\u00b7chen\u00b7land", "bis", "zu", "den", "Por\u00b7tu\u00b7gie\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NE", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Trifft man die Spur der deutschen Mund-Art an.", "tokens": ["Trifft", "man", "die", "Spur", "der", "deut\u00b7schen", "Mun\u00b7dArt", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ART", "NN", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Ja was noch mehr! der Perser Ispahan,", "tokens": ["Ja", "was", "noch", "mehr", "!", "der", "Per\u00b7ser", "Is\u00b7pa\u00b7han", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKANT", "PWS", "ADV", "ADV", "$.", "ART", "NN", "NE", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Hat auch davon die Proben aufgewiesen.", "tokens": ["Hat", "auch", "da\u00b7von", "die", "Pro\u00b7ben", "auf\u00b7ge\u00b7wie\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PAV", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "Was seh ich dort? Die Helden grauer Zeit", "tokens": ["Was", "seh", "ich", "dort", "?", "Die", "Hel\u00b7den", "grau\u00b7er", "Zeit"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "$.", "ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Die Cimbrer sinds, die Welschland sonst erstritten;", "tokens": ["Die", "Cim\u00b7brer", "sinds", ",", "die", "Wel\u00b7schland", "sonst", "er\u00b7strit\u00b7ten", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "$,", "ART", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Der Angeln Heer, der Trost-bedr\u00e4ngter Britten:", "tokens": ["Der", "An\u00b7geln", "Heer", ",", "der", "Trost\u00b7be\u00b7dr\u00e4ng\u00b7ter", "Brit\u00b7ten", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$,", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Die Welt erschrack vor beyder Tapferkeit.", "tokens": ["Die", "Welt", "er\u00b7schrack", "vor", "bey\u00b7der", "Tap\u00b7fer\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Besch\u00e4mtes Rom, kanst du Carthago zwingen,", "tokens": ["Be\u00b7sch\u00e4m\u00b7tes", "Rom", ",", "kanst", "du", "Car\u00b7tha\u00b7go", "zwin\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "VMFIN", "PPER", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "So zwing einmahl der Deutschen Helden Brust.", "tokens": ["So", "zwing", "ein\u00b7mahl", "der", "Deut\u00b7schen", "Hel\u00b7den", "Brust", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "ART", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Umsonst, umsonst! Verg\u00f6tterter August,", "tokens": ["Um\u00b7sonst", ",", "um\u00b7sonst", "!", "Ver\u00b7g\u00f6t\u00b7ter\u00b7ter", "Au\u00b7gust", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "$,", "ADV", "$.", "NN", "NN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Dein Reich verf\u00e4llt von deutscher V\u00f6lcker Klingen.", "tokens": ["Dein", "Reich", "ver\u00b7f\u00e4llt", "von", "deut\u00b7scher", "V\u00f6l\u00b7cker", "Klin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "APPR", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.7": {"line.1": {"text": "Ihr Adler flieht! dafern ihr Zuflucht wi\u00dft,", "tokens": ["Ihr", "Ad\u00b7ler", "flieht", "!", "da\u00b7fern", "ihr", "Zu\u00b7flucht", "wi\u00dft", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "$.", "KOUS", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Wo Herrmann schl\u00e4gt, da wei\u00df man nicht zu schonen.", "tokens": ["Wo", "Herr\u00b7mann", "schl\u00e4gt", ",", "da", "wei\u00df", "man", "nicht", "zu", "scho\u00b7nen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NE", "VVFIN", "$,", "ADV", "VVFIN", "PIS", "PTKNEG", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Erwegt den Fall so vieler Legionen,", "tokens": ["Er\u00b7wegt", "den", "Fall", "so", "vie\u00b7ler", "Le\u00b7gi\u00b7o\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ADV", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Die Varus dort so sch\u00e4ndlich eingeb\u00fc\u00dft.", "tokens": ["Die", "Va\u00b7rus", "dort", "so", "sch\u00e4nd\u00b7lich", "ein\u00b7ge\u00b7b\u00fc\u00dft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "ADV", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Was regt sich hier? Ein Heer der Alemannen", "tokens": ["Was", "regt", "sich", "hier", "?", "Ein", "Heer", "der", "A\u00b7le\u00b7man\u00b7nen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "PRF", "ADV", "$.", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Bahnt sich den Weg zu Herkuls Seulen hin;", "tokens": ["Bahnt", "sich", "den", "Weg", "zu", "Her\u00b7kuls", "Seu\u00b7len", "hin", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ART", "NN", "APPR", "NE", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Selbst Africa wird Deutschland zum Gewinn,", "tokens": ["Selbst", "A\u00b7fri\u00b7ca", "wird", "Deutschland", "zum", "Ge\u00b7winn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NE", "VAFIN", "NE", "APPRART", "NN", "$,"], "meter": "--+--+--+", "measure": "anapaest.tri.plus"}, "line.8": {"text": "Und l\u00e4\u00dft den Hals ins Joch der Vandaln spannen.", "tokens": ["Und", "l\u00e4\u00dft", "den", "Hals", "ins", "Joch", "der", "Van\u00b7daln", "span\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "APPRART", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.8": {"line.1": {"text": "Wo bleibt o Rom, der theur-erkaufte Ruhm,", "tokens": ["Wo", "bleibt", "o", "Rom", ",", "der", "theur\u00b7er\u00b7kauf\u00b7te", "Ruhm", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "FM", "NE", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Den Julius in Gallien erfochten?", "tokens": ["Den", "Ju\u00b7lius", "in", "Gal\u00b7li\u00b7en", "er\u00b7foch\u00b7ten", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "APPR", "NE", "VVFIN", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Der Lorber-Krantz, den sich sein Arm geflochten,", "tokens": ["Der", "Lor\u00b7ber\u00b7Krantz", ",", "den", "sich", "sein", "Arm", "ge\u00b7floch\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PRF", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Wird unverhofft der Deutschen Eigenthum.", "tokens": ["Wird", "un\u00b7ver\u00b7hofft", "der", "Deut\u00b7schen", "Ei\u00b7gen\u00b7thum", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Ein Fr\u00e4nckisch Heer zerschl\u00e4gt die Ehren-Seulen,", "tokens": ["Ein", "Fr\u00e4n\u00b7ckisch", "Heer", "zer\u00b7schl\u00e4gt", "die", "Eh\u00b7ren\u00b7Seu\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Tilgt C\u00e4sars Lob und Sieges-M\u00e4hler aus.", "tokens": ["Tilgt", "C\u00e4\u00b7sars", "Lob", "und", "Sie\u00b7ges\u00b7M\u00e4h\u00b7ler", "aus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "NN", "KON", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Sein Stoltz verdients, da\u00df Schatten, Nacht und Graus,", "tokens": ["Sein", "Stoltz", "ver\u00b7dients", ",", "da\u00df", "Schat\u00b7ten", ",", "Nacht", "und", "Graus", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "$,", "KOUS", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Der Herrsch-Begier ein schimpflich Grab ertheilen.", "tokens": ["Der", "Herr\u00b7schBe\u00b7gier", "ein", "schimpf\u00b7lich", "Grab", "er\u00b7thei\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "ADJD", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.9": {"line.1": {"text": "Pannonien, Illyrien, Tyrol,", "tokens": ["Pan\u00b7no\u00b7ni\u00b7en", ",", "Il\u00b7ly\u00b7ri\u00b7en", ",", "Ty\u00b7rol", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["NE", "$,", "NE", "$,", "NE", "$,"], "meter": "+-+-+-++-+", "measure": "unknown.measure.hexa"}, "line.2": {"text": "Erschrack vor euch ihr unbesiegten Gothen!", "tokens": ["Er\u00b7schrack", "vor", "euch", "ihr", "un\u00b7be\u00b7sieg\u00b7ten", "Go\u00b7then", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPER", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Wie bebte Rom als Gensrichs Waffen drohten?", "tokens": ["Wie", "beb\u00b7te", "Rom", "als", "Gens\u00b7richs", "Waf\u00b7fen", "droh\u00b7ten", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "NE", "KOUS", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Wie sch\u00fctterte das feste Capitol?", "tokens": ["Wie", "sch\u00fct\u00b7ter\u00b7te", "das", "fes\u00b7te", "Ca\u00b7pi\u00b7tol", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Der Alpen Eis, so an den Himmel r\u00fchret,", "tokens": ["Der", "Al\u00b7pen", "Eis", ",", "so", "an", "den", "Him\u00b7mel", "r\u00fch\u00b7ret", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$,", "ADV", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Verhindert nicht der Deutschen Uberfall;", "tokens": ["Ver\u00b7hin\u00b7dert", "nicht", "der", "Deut\u00b7schen", "U\u00b7ber\u00b7fall", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Der Longobard, ein andrer Hannibal,", "tokens": ["Der", "Lon\u00b7go\u00b7bard", ",", "ein", "an\u00b7drer", "Han\u00b7ni\u00b7bal", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NE", "$,", "ART", "ADJA", "NE", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Hat Steg und Bahn von neuem ausgesp\u00fcret.", "tokens": ["Hat", "Steg", "und", "Bahn", "von", "neu\u00b7em", "aus\u00b7ge\u00b7sp\u00fc\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "KON", "NN", "APPR", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.10": {"line.1": {"text": "Auf, grosser Carl! Thuiscons \u00e4chter Sohn,", "tokens": ["Auf", ",", "gros\u00b7ser", "Carl", "!", "Thu\u00b7is\u00b7cons", "\u00e4ch\u00b7ter", "Sohn", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "$,", "ADJA", "NE", "$.", "NE", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Auf! r\u00fcste dich, gepriesnes Haupt der Francken,", "tokens": ["Auf", "!", "r\u00fcs\u00b7te", "dich", ",", "ge\u00b7pri\u00b7es\u00b7nes", "Haupt", "der", "Fran\u00b7cken", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "$.", "VVFIN", "PPER", "$,", "ADJA", "NN", "ART", "NN", "$,"], "meter": "-+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Der R\u00f6mer Reich wird dir sein Wohl verdancken,", "tokens": ["Der", "R\u00f6\u00b7mer", "Reich", "wird", "dir", "sein", "Wohl", "ver\u00b7dan\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "PPER", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Besteige nur den alten K\u00e4yser-Thron.", "tokens": ["Be\u00b7stei\u00b7ge", "nur", "den", "al\u00b7ten", "K\u00e4y\u00b7ser\u00b7Thron", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Wie sich das Gold der Flammen-reichen Sonnen", "tokens": ["Wie", "sich", "das", "Gold", "der", "Flam\u00b7men\u00b7rei\u00b7chen", "Son\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PRF", "ART", "NN", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Nach finstrer Nacht mit hellerm Schimmer zeigt,", "tokens": ["Nach", "finst\u00b7rer", "Nacht", "mit", "hel\u00b7lerm", "Schim\u00b7mer", "zeigt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Als wenn es sp\u00e4t in Thetis Arme steigt,", "tokens": ["Als", "wenn", "es", "sp\u00e4t", "in", "The\u00b7tis", "Ar\u00b7me", "steigt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "PPER", "ADJD", "APPR", "NE", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "So viel hat Rom durch unsern Carl gewonnen.", "tokens": ["So", "viel", "hat", "Rom", "durch", "un\u00b7sern", "Carl", "ge\u00b7won\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VAFIN", "NE", "APPR", "PPOSAT", "NE", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.11": {"line.1": {"text": "Genug o Mars, von Deutscher Sieger Muth", "tokens": ["Ge\u00b7nug", "o", "Mars", ",", "von", "Deut\u00b7scher", "Sie\u00b7ger", "Muth"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "FM", "NN", "$,", "APPR", "ADJA", "NN", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Germanien, genug von Deinen Waffen;", "tokens": ["Ger\u00b7ma\u00b7ni\u00b7en", ",", "ge\u00b7nug", "von", "Dei\u00b7nen", "Waf\u00b7fen", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Kan Witz und Kunst Dir keinen Ruhm verschaffen,", "tokens": ["Kan", "Witz", "und", "Kunst", "Dir", "kei\u00b7nen", "Ruhm", "ver\u00b7schaf\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "NN", "KON", "NN", "PPER", "PIAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Was hilft die Macht? was n\u00fctzt dir Stahl und Gluth?", "tokens": ["Was", "hilft", "die", "Macht", "?", "was", "n\u00fctzt", "dir", "Stahl", "und", "Gluth", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ART", "NN", "$.", "PWS", "VVFIN", "PPER", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Das ist die Art der wildesten Barbaren,", "tokens": ["Das", "ist", "die", "Art", "der", "wil\u00b7des\u00b7ten", "Bar\u00b7ba\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+---+-", "measure": "unknown.measure.tetra"}, "line.6": {"text": "An F\u00e4usten starck und schwach am Geiste seyn:", "tokens": ["An", "F\u00e4us\u00b7ten", "starck", "und", "schwach", "am", "Geis\u00b7te", "seyn", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADJD", "KON", "ADJD", "APPRART", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Ihr Musen kommt, und helft mir selber ein,", "tokens": ["Ihr", "Mu\u00b7sen", "kommt", ",", "und", "helft", "mir", "sel\u00b7ber", "ein", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "$,", "KON", "VVFIN", "PPER", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Und lehrt und sagt, wie klug die Deutschen waren.", "tokens": ["Und", "lehrt", "und", "sagt", ",", "wie", "klug", "die", "Deut\u00b7schen", "wa\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "KON", "VVFIN", "$,", "PWAV", "ADJD", "ART", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.12": {"line.1": {"text": "Ich h\u00f6re schon geborstner Bomben Knall,", "tokens": ["Ich", "h\u00f6\u00b7re", "schon", "ge\u00b7borst\u00b7ner", "Bom\u00b7ben", "Knall", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Der Erd-Kreis bebt vom Donner der Carthaunen,", "tokens": ["Der", "Erd\u00b7Kreis", "bebt", "vom", "Don\u00b7ner", "der", "Car\u00b7thau\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPRART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Ihr Blitz und Dampf setzt alles in Erstaunen,", "tokens": ["Ihr", "Blitz", "und", "Dampf", "setzt", "al\u00b7les", "in", "Er\u00b7stau\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "NN", "VVFIN", "PIS", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Hier springt ein Thurm, dort sincket Thor und Wall.", "tokens": ["Hier", "springt", "ein", "Thurm", ",", "dort", "sin\u00b7cket", "Thor", "und", "Wall", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$,", "ADV", "VVFIN", "NN", "KON", "NE", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Leiht Jupiter den Menschen Keil und Blitze?", "tokens": ["Leiht", "Ju\u00b7pi\u00b7ter", "den", "Men\u00b7schen", "Keil", "und", "Blit\u00b7ze", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "ART", "NN", "NN", "KON", "NN", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.6": {"text": "Er\u00f6fnet sich der H\u00f6llen w\u00fcster Schlund?", "tokens": ["Er\u00b7\u00f6f\u00b7net", "sich", "der", "H\u00f6l\u00b7len", "w\u00fcs\u00b7ter", "Schlund", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "O w\u00fcrden mir die neuen G\u00f6tter kund!", "tokens": ["O", "w\u00fcr\u00b7den", "mir", "die", "neu\u00b7en", "G\u00f6t\u00b7ter", "kund", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PPER", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Die Deutschen sinds, durch Pulver und Gesch\u00fctze.", "tokens": ["Die", "Deut\u00b7schen", "sinds", ",", "durch", "Pul\u00b7ver", "und", "Ge\u00b7sch\u00fct\u00b7ze", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "$,", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.13": {"line.1": {"text": "O Seltne Kunst! Die gr\u00f6\u00dfre Wunder zeigt,", "tokens": ["O", "Selt\u00b7ne", "Kunst", "!", "Die", "gr\u00f6\u00df\u00b7re", "Wun\u00b7der", "zeigt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$.", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Als alle Pracht bejahrter Seltenheiten.", "tokens": ["Als", "al\u00b7le", "Pracht", "be\u00b7jahr\u00b7ter", "Sel\u00b7ten\u00b7hei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Ihr seyd besch\u00e4mt, ihr K\u00fcnstler alter Zeiten,", "tokens": ["Ihr", "seyd", "be\u00b7sch\u00e4mt", ",", "ihr", "K\u00fcnst\u00b7ler", "al\u00b7ter", "Zei\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "$,", "PPOSAT", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Da Deutschland euch noch t\u00e4glich \u00fcbersteigt.", "tokens": ["Da", "Deutschland", "euch", "noch", "t\u00e4g\u00b7lich", "\u00fc\u00b7bers\u00b7teigt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "PPER", "ADV", "ADJD", "VVPP", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Selbst das Metall wohl eingeschw\u00e4rtzter Schrifften,", "tokens": ["Selbst", "das", "Me\u00b7tall", "wohl", "ein\u00b7ge\u00b7schw\u00e4rtz\u00b7ter", "Schriff\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "ADV", "ADJA", "NN", "$,"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.6": {"text": "So diesen Reim auf tausend Bl\u00e4tter dr\u00fcckt,", "tokens": ["So", "die\u00b7sen", "Reim", "auf", "tau\u00b7send", "Bl\u00e4t\u00b7ter", "dr\u00fcckt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PDAT", "NN", "APPR", "CARD", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Und meinen Kiel der Zeiten Wuth entr\u00fcckt,", "tokens": ["Und", "mei\u00b7nen", "Kiel", "der", "Zei\u00b7ten", "Wuth", "ent\u00b7r\u00fcckt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "ART", "NN", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Das, das kan uns ein ewig Denckmahl stifften.", "tokens": ["Das", ",", "das", "kan", "uns", "ein", "e\u00b7wig", "Denck\u00b7mahl", "stiff\u00b7ten", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "$,", "PDS", "VMFIN", "PPER", "ART", "ADJD", "NN", "VVFIN", "$."], "meter": "-+---+-+-+-", "measure": "dactylic.init"}}, "stanza.14": {"line.1": {"text": "Wer hat den Bau der Himmel umgekehrt,", "tokens": ["Wer", "hat", "den", "Bau", "der", "Him\u00b7mel", "um\u00b7ge\u00b7kehrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ART", "NN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Dem Erden-Ball den Mittel-Punct entzogen,", "tokens": ["Dem", "Er\u00b7den\u00b7Ball", "den", "Mit\u00b7tel\u00b7Punct", "ent\u00b7zo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "So da\u00df er itzt in l\u00e4nglicht-runden Bogen,", "tokens": ["So", "da\u00df", "er", "itzt", "in", "l\u00e4ng\u00b7licht\u00b7run\u00b7den", "Bo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PPER", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Von Jahr zu Jahr die feste Sonn umf\u00e4hrt?", "tokens": ["Von", "Jahr", "zu", "Jahr", "die", "fes\u00b7te", "Sonn", "um\u00b7f\u00e4hrt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "NN", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Wer r\u00e4umte doch den Wust Crystallner Kreise,", "tokens": ["Wer", "r\u00e4um\u00b7te", "doch", "den", "Wust", "Crys\u00b7tall\u00b7ner", "Krei\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ADV", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Mit starcker Faust aus der gestirnten Lufft?", "tokens": ["Mit", "star\u00b7cker", "Faust", "aus", "der", "ge\u00b7stirn\u00b7ten", "Lufft", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Ihr V\u00f6lcker merckts, denn gantz Europa rufft:", "tokens": ["Ihr", "V\u00f6l\u00b7cker", "merckts", ",", "denn", "gantz", "Eu\u00b7ro\u00b7pa", "rufft", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "$,", "KON", "ADV", "NE", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Ein Deutscher thats, Copernicus der Weise.", "tokens": ["Ein", "Deut\u00b7scher", "thats", ",", "Co\u00b7per\u00b7ni\u00b7cus", "der", "Wei\u00b7se", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "NE", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.15": {"line.1": {"text": "Er war dein Sohn, Du deutsches Preussen-Land?", "tokens": ["Er", "war", "dein", "Sohn", ",", "Du", "deut\u00b7sches", "Preus\u00b7sen\u00b7Land", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "NN", "$,", "PPER", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Und hat sich selbst und deinen Ruhm erhoben.", "tokens": ["Und", "hat", "sich", "selbst", "und", "dei\u00b7nen", "Ruhm", "er\u00b7ho\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PRF", "ADV", "KON", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Vergi\u00df nur nicht auch Hevels Flei\u00df zu loben,", "tokens": ["Ver\u00b7gi\u00df", "nur", "nicht", "auch", "He\u00b7vels", "Flei\u00df", "zu", "lo\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ADV", "PTKNEG", "ADV", "NE", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Der das Gestirn in neue Bilder band.", "tokens": ["Der", "das", "Ge\u00b7stirn", "in", "neu\u00b7e", "Bil\u00b7der", "band", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.5": {"text": "Vor Kepplern mu\u00df ein Archimedes weichen,", "tokens": ["Vor", "Kep\u00b7plern", "mu\u00df", "ein", "Ar\u00b7chi\u00b7me\u00b7des", "wei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VMFIN", "ART", "NN", "VVINF", "$,"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.6": {"text": "Was Huygens uns von tausend Welten lehrt,", "tokens": ["Was", "Huy\u00b7gens", "uns", "von", "tau\u00b7send", "Wel\u00b7ten", "lehrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NE", "PPER", "APPR", "CARD", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "War gleichfalls sonst den Menschen unerh\u00f6rt,", "tokens": ["War", "gleich\u00b7falls", "sonst", "den", "Men\u00b7schen", "un\u00b7er\u00b7h\u00f6rt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Wer denckt sich nun den Deutschen zu vergleichen?", "tokens": ["Wer", "denckt", "sich", "nun", "den", "Deut\u00b7schen", "zu", "ver\u00b7glei\u00b7chen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PRF", "ADV", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.16": {"line.1": {"text": "Vergebens prahlt ein stoltzer Pythagor,", "tokens": ["Ver\u00b7ge\u00b7bens", "prahlt", "ein", "stolt\u00b7zer", "Py\u00b7tha\u00b7gor", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NE", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Die Harmonie des Himmels-Laufs zu wissen.", "tokens": ["Die", "Har\u00b7mo\u00b7nie", "des", "Him\u00b7mels\u00b7Laufs", "zu", "wis\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Dis Lob wird ihm von deutscher Hand entrissen,", "tokens": ["Dis", "Lob", "wird", "ihm", "von", "deut\u00b7scher", "Hand", "ent\u00b7ris\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "NN", "VAFIN", "PPER", "APPR", "ADJA", "NN", "VVPP", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Germanien verlacht sein leises Ohr.", "tokens": ["Ger\u00b7ma\u00b7ni\u00b7en", "ver\u00b7lacht", "sein", "lei\u00b7ses", "Ohr", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Sein Zauber-Klang bewegter Himmels-Spheren,", "tokens": ["Sein", "Zau\u00b7ber\u00b7Klang", "be\u00b7weg\u00b7ter", "Him\u00b7mels\u00b7S\u00b7phe\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Was war er sonst, als ein gelehrter Traum?", "tokens": ["Was", "war", "er", "sonst", ",", "als", "ein", "ge\u00b7lehr\u00b7ter", "Traum", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "ADV", "$,", "KOUS", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Uns zeigt itzund der Himmel weiten Raum,", "tokens": ["Uns", "zeigt", "it\u00b7zund", "der", "Him\u00b7mel", "wei\u00b7ten", "Raum", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Ein doppelt Glas empor gestreckter R\u00f6hren.", "tokens": ["Ein", "dop\u00b7pelt", "Glas", "em\u00b7por", "ge\u00b7streck\u00b7ter", "R\u00f6h\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "PTKVZ", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.17": {"line.1": {"text": "Die Wei\u00dfheit kam, der Europ\u00e4er-Welt,", "tokens": ["Die", "Wei\u00df\u00b7heit", "kam", ",", "der", "Eu\u00b7ro\u00b7p\u00e4\u00b7er\u00b7Welt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Ein eintzig Haupt zum Lehrer vorzusetzen:", "tokens": ["Ein", "eint\u00b7zig", "Haupt", "zum", "Leh\u00b7rer", "vor\u00b7zu\u00b7set\u00b7zen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Gleich hub sie an die Deutschen hochzusch\u00e4tzen,", "tokens": ["Gleich", "hub", "sie", "an", "die", "Deut\u00b7schen", "hoch\u00b7zu\u00b7sch\u00e4t\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Weil ihr Verstand fast alles in sich h\u00e4lt.", "tokens": ["Weil", "ihr", "Ver\u00b7stand", "fast", "al\u00b7les", "in", "sich", "h\u00e4lt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "ADV", "PIS", "APPR", "PRF", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Ein Leibnitz trotzt den Frantzen und den Britten,", "tokens": ["Ein", "Leib\u00b7nitz", "trotzt", "den", "Frant\u00b7zen", "und", "den", "Brit\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "KON", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Was hat er nicht vor Wunder ausgedacht!", "tokens": ["Was", "hat", "er", "nicht", "vor", "Wun\u00b7der", "aus\u00b7ge\u00b7dacht", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "PTKNEG", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Die Rechnung blo\u00df die er hervor gebracht,", "tokens": ["Die", "Rech\u00b7nung", "blo\u00df", "die", "er", "her\u00b7vor", "ge\u00b7bracht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "PRELS", "PPER", "PTKVZ", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Hat uns den Preis der Wissenschafft erstritten.", "tokens": ["Hat", "uns", "den", "Preis", "der", "Wis\u00b7sen\u00b7schafft", "er\u00b7strit\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.18": {"line.1": {"text": "Uns Deutschen danckts, ihr Priester der Natur,", "tokens": ["Uns", "Deut\u00b7schen", "dan\u00b7ckts", ",", "ihr", "Pries\u00b7ter", "der", "Na\u00b7tur", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "ADV", "$,", "PPOSAT", "NN", "ART", "NN", "$,"], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Der ihr so weit ins Heiligthum gedrungen;", "tokens": ["Der", "ihr", "so", "weit", "ins", "Hei\u00b7lig\u00b7thum", "ge\u00b7drun\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "ADJD", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Es ist euch blos durch deutschen Witz gelungen,", "tokens": ["Es", "ist", "euch", "blos", "durch", "deut\u00b7schen", "Witz", "ge\u00b7lun\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "APPR", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Wer half euch sonst im Forschen auf die Spur?", "tokens": ["Wer", "half", "euch", "sonst", "im", "For\u00b7schen", "auf", "die", "Spur", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "APPRART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Wenn Gericke die Lufft-Pump ausgesonnen,", "tokens": ["Wenn", "Ge\u00b7ri\u00b7cke", "die", "Lufft\u00b7Pump", "aus\u00b7ge\u00b7son\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "ART", "NN", "VVINF", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.6": {"text": "Wenn Tschirnhaus Stahl durch Spiegel schmeltzen lehrt,", "tokens": ["Wenn", "Tschirn\u00b7haus", "Stahl", "durch", "Spie\u00b7gel", "schmelt\u00b7zen", "lehrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "NN", "APPR", "NN", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Wenn Sturm und Wolf die Wissenschafften mehrt;", "tokens": ["Wenn", "Sturm", "und", "Wolf", "die", "Wis\u00b7sen\u00b7schaff\u00b7ten", "mehrt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "NE", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Wer hat uns denn den Vorzug abgewonnen?", "tokens": ["Wer", "hat", "uns", "denn", "den", "Vor\u00b7zug", "ab\u00b7ge\u00b7won\u00b7nen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "ADV", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.19": {"line.1": {"text": "Sch\u00e4mt euch nur nicht, ihr Dichter deutscher Zucht,", "tokens": ["Sch\u00e4mt", "euch", "nur", "nicht", ",", "ihr", "Dich\u00b7ter", "deut\u00b7scher", "Zucht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "PTKNEG", "$,", "PPOSAT", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Was legt ihr doch die bl\u00f6den Fl\u00f6ten nieder?", "tokens": ["Was", "legt", "ihr", "doch", "die", "bl\u00f6\u00b7den", "Fl\u00f6\u00b7ten", "nie\u00b7der", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Die Musen selbst begeistern eure Lieder,", "tokens": ["Die", "Mu\u00b7sen", "selbst", "be\u00b7geis\u00b7tern", "eu\u00b7re", "Lie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und Ph\u00f6bus nennt sie seiner Triebe Frucht.", "tokens": ["Und", "Ph\u00f6\u00b7bus", "nennt", "sie", "sei\u00b7ner", "Trie\u00b7be", "Frucht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "VVFIN", "PPER", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Besang Homer den Eifer von Atriden,", "tokens": ["Be\u00b7sang", "Ho\u00b7mer", "den", "Ei\u00b7fer", "von", "At\u00b7ri\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "ART", "NN", "APPR", "NE", "$,"], "meter": "-++--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Beschrieb Virgil Aeneens Helden-Zug:", "tokens": ["Be\u00b7schrieb", "Vir\u00b7gil", "A\u00b7e\u00b7neens", "Hel\u00b7den\u00b7Zug", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "NE", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "So hat die Welt der Fabeln l\u00e4ngst genug;", "tokens": ["So", "hat", "die", "Welt", "der", "Fa\u00b7beln", "l\u00e4ngst", "ge\u00b7nug", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "ART", "NN", "ADV", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Euch Deutschen ist der Wahrheit Lob beschieden.", "tokens": ["Euch", "Deut\u00b7schen", "ist", "der", "Wahr\u00b7heit", "Lob", "be\u00b7schie\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "VAFIN", "ART", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.20": {"line.1": {"text": "Was Opitz, Dach, und Hofmannswaldaus Rohr,", "tokens": ["Was", "O\u00b7pitz", ",", "Dach", ",", "und", "Hof\u00b7manns\u00b7wald\u00b7aus", "Rohr", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "NE", "$,", "NN", "$,", "KON", "NN", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Was Lohensteins und Amthors Mund gesungen,", "tokens": ["Was", "Lo\u00b7hen\u00b7steins", "und", "Am\u00b7thors", "Mund", "ge\u00b7sun\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NE", "KON", "NN", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Wie Canitz schrieb, wie G\u00fcnthers Lied geklungen,", "tokens": ["Wie", "Ca\u00b7nitz", "schrieb", ",", "wie", "G\u00fcn\u00b7thers", "Lied", "ge\u00b7klun\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NE", "VVFIN", "$,", "PWAV", "NE", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "H\u00e4lt Ph\u00f6bus selbst den jungen Dichtern vor.", "tokens": ["H\u00e4lt", "Ph\u00f6\u00b7bus", "selbst", "den", "jun\u00b7gen", "Dich\u00b7tern", "vor", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "ADV", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Steht Neukirch nicht im Deutschen Musen-Tempel,", "tokens": ["Steht", "Neu\u00b7kirch", "nicht", "im", "Deut\u00b7schen", "Mu\u00b7sen\u00b7Tem\u00b7pel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "PTKNEG", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Wie K\u00f6nig, Pietsch und Wentzel oben an?", "tokens": ["Wie", "K\u00f6\u00b7nig", ",", "Pietsch", "und", "Went\u00b7zel", "o\u00b7ben", "an", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "$,", "NN", "KON", "NN", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Philanders Kiel und jenen Alster-Schwan", "tokens": ["Phi\u00b7lan\u00b7ders", "Kiel", "und", "je\u00b7nen", "Als\u00b7ter\u00b7Schwan"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "NE", "KON", "PDAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Erwehlt die Welt sich k\u00fcnftig zum Exempel.", "tokens": ["Er\u00b7wehlt", "die", "Welt", "sich", "k\u00fcnf\u00b7tig", "zum", "Ex\u00b7em\u00b7pel", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "PRF", "ADJD", "APPRART", "NN", "$."], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}}, "stanza.21": {"line.1": {"text": "Es r\u00fchme sich so Welschland als Athen,", "tokens": ["Es", "r\u00fch\u00b7me", "sich", "so", "Wel\u00b7schland", "als", "A\u00b7then", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "ADV", "NN", "KOKOM", "NE", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Und selbst Paris im Bauen, Mahlen, Singen;", "tokens": ["Und", "selbst", "Pa\u00b7ris", "im", "Bau\u00b7en", ",", "Mah\u00b7len", ",", "Sin\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["KON", "ADV", "NE", "APPRART", "NN", "$,", "NN", "$,", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Der Deutschen Witz kan ihren Stoltz bezwingen,", "tokens": ["Der", "Deut\u00b7schen", "Witz", "kan", "ih\u00b7ren", "Stoltz", "be\u00b7zwin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VMFIN", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und sch\u00e4mt sich fast den Wett-Streit einzugehn.", "tokens": ["Und", "sch\u00e4mt", "sich", "fast", "den", "Wet\u00b7tStreit", "ein\u00b7zu\u00b7gehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "ADV", "ART", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Ersann nicht Sturm, die Ordnung deutscher Seulen?", "tokens": ["Er\u00b7sann", "nicht", "Sturm", ",", "die", "Ord\u00b7nung", "deut\u00b7scher", "Seu\u00b7len", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKNEG", "NN", "$,", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Ist Telemann und Hendel nicht bekannt?", "tokens": ["Ist", "Te\u00b7le\u00b7mann", "und", "Hen\u00b7del", "nicht", "be\u00b7kannt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "KON", "NN", "PTKNEG", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Des Hollbeins Kunst und Kranachs Zauber-Hand,", "tokens": ["Des", "Holl\u00b7beins", "Kunst", "und", "Kra\u00b7nachs", "Zau\u00b7ber\u00b7Hand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "KON", "NN", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Wird Zeuxes selbst den Sieges-Krantz ertheilen.", "tokens": ["Wird", "Zeu\u00b7xes", "selbst", "den", "Sie\u00b7ges\u00b7Krantz", "er\u00b7thei\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NE", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.22": {"line.1": {"text": "Batavien! wenn dein verwegner Mast,", "tokens": ["Ba\u00b7ta\u00b7vi\u00b7en", "!", "wenn", "dein", "ver\u00b7weg\u00b7ner", "Mast", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "KOUS", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Bey Sturm und Fluth den Ocean durchflogen;", "tokens": ["Bey", "Sturm", "und", "Fluth", "den", "O\u00b7cean", "durch\u00b7flo\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Wenn dein Compa\u00df der Inden Meer durchzogen;", "tokens": ["Wenn", "dein", "Com\u00b7pa\u00df", "der", "In\u00b7den", "Meer", "durch\u00b7zo\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Ja wenn du gar die Welt umsegelt hast;", "tokens": ["Ja", "wenn", "du", "gar", "die", "Welt", "um\u00b7se\u00b7gelt", "hast", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "KOUS", "PPER", "ADV", "ART", "NN", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "So schreibe doch auf Flaggen, Bort und Seile,", "tokens": ["So", "schrei\u00b7be", "doch", "auf", "Flag\u00b7gen", ",", "Bort", "und", "Sei\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "APPR", "NN", "$,", "NE", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Da\u00df Belgier gebohrne Deutschen seyn;", "tokens": ["Da\u00df", "Bel\u00b7gier", "ge\u00b7bohr\u00b7ne", "Deut\u00b7schen", "seyn", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "ADJA", "NN", "VAINF", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Der Schiffahrt Ruhm geh\u00f6rt nicht dir allein,", "tokens": ["Der", "Schif\u00b7fahrt", "Ruhm", "ge\u00b7h\u00f6rt", "nicht", "dir", "al\u00b7lein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "PTKNEG", "PPER", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Er wird zugleich Germanien zu Theile.", "tokens": ["Er", "wird", "zu\u00b7gleich", "Ger\u00b7ma\u00b7ni\u00b7en", "zu", "Thei\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.23": {"line.1": {"text": "So steigt dein Preis, erh\u00f6htes Vaterland!", "tokens": ["So", "steigt", "dein", "Preis", ",", "er\u00b7h\u00f6h\u00b7tes", "Va\u00b7ter\u00b7land", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "So schallt dein Lob bey fernen Nationen,", "tokens": ["So", "schallt", "dein", "Lob", "bey", "fer\u00b7nen", "Na\u00b7ti\u00b7o\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "In aller Welt, wo irgend Menschen wohnen,", "tokens": ["In", "al\u00b7ler", "Welt", ",", "wo", "ir\u00b7gend", "Men\u00b7schen", "woh\u00b7nen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "$,", "PWAV", "ADV", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Ist Deutschland mehr als sonst ein Volck bekannt.", "tokens": ["Ist", "Deutschland", "mehr", "als", "sonst", "ein", "Volck", "be\u00b7kannt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NE", "PIAT", "KOKOM", "ADV", "ART", "NN", "PTKVZ", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Es kennen dich die Africaner-Mohren,", "tokens": ["Es", "ken\u00b7nen", "dich", "die", "Af\u00b7ri\u00b7ca\u00b7ner\u00b7Moh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "In Japans Reich, in Siam, Bengala,", "tokens": ["In", "Ja\u00b7pans", "Reich", ",", "in", "Si\u00b7am", ",", "Ben\u00b7ga\u00b7la", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "NE", "NE", "$,", "APPR", "NE", "$,", "NE", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "In Malabar, und gantz America", "tokens": ["In", "Ma\u00b7la\u00b7bar", ",", "und", "gantz", "A\u00b7me\u00b7ri\u00b7ca"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "NE", "$,", "KON", "ADV", "NE"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Erf\u00fcllt dein Ruhm der Indianer Ohren.", "tokens": ["Er\u00b7f\u00fcllt", "dein", "Ruhm", "der", "In\u00b7di\u00b7a\u00b7ner", "Oh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.24": {"line.1": {"text": "Germanien, Du K\u00f6nigin der Welt,", "tokens": ["Ger\u00b7ma\u00b7ni\u00b7en", ",", "Du", "K\u00f6\u00b7ni\u00b7gin", "der", "Welt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PPER", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Vor deren Thron sich hundert V\u00f6lcker schmiegen,", "tokens": ["Vor", "de\u00b7ren", "Thron", "sich", "hun\u00b7dert", "V\u00f6l\u00b7cker", "schmie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELAT", "NN", "PRF", "CARD", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Auf deren Winck sich tausend F\u00fcrsten biegen,", "tokens": ["Auf", "de\u00b7ren", "Win\u00b7ck", "sich", "tau\u00b7send", "F\u00fcrs\u00b7ten", "bie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELAT", "NN", "PRF", "CARD", "NN", "VVFIN", "$,"], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Der Ost und West geb\u00fcckt zu Fusse f\u00e4llt;", "tokens": ["Der", "Ost", "und", "West", "ge\u00b7b\u00fcckt", "zu", "Fus\u00b7se", "f\u00e4llt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "VVPP", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Verschm\u00e4he nicht die Lob-Schrifft Deiner Thaten:", "tokens": ["Ver\u00b7schm\u00e4\u00b7he", "nicht", "die", "Lob\u00b7Schrifft", "Dei\u00b7ner", "Tha\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "ART", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Indem Dein Ruhm noch t\u00e4glich h\u00f6her steigt,", "tokens": ["In\u00b7dem", "Dein", "Ruhm", "noch", "t\u00e4g\u00b7lich", "h\u00f6\u00b7her", "steigt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "ADV", "ADJD", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Und allen Neid erboster Nachbarn beugt,", "tokens": ["Und", "al\u00b7len", "Neid", "er\u00b7bos\u00b7ter", "Nach\u00b7barn", "beugt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "L\u00e4\u00dft Ph\u00f6bus mir ein Helden-Lied gerathen.", "tokens": ["L\u00e4\u00dft", "Ph\u00f6\u00b7bus", "mir", "ein", "Hel\u00b7den\u00b7Lied", "ge\u00b7ra\u00b7then", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "PPER", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.25": {"line.1": {"text": "Wer ehret nicht der R\u00f6mer K\u00e4yser-Thron?", "tokens": ["Wer", "eh\u00b7ret", "nicht", "der", "R\u00f6\u00b7mer", "K\u00e4y\u00b7ser\u00b7Thron", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PTKNEG", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Und der mu\u00df Dir ein ewig Erbtheil werden.", "tokens": ["Und", "der", "mu\u00df", "Dir", "ein", "e\u00b7wig", "E\u00b7rbtheil", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "VMFIN", "PPER", "ART", "ADJD", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Wer kennt nicht Wien, das neue Rom der Erden,", "tokens": ["Wer", "kennt", "nicht", "Wi\u00b7en", ",", "das", "neu\u00b7e", "Rom", "der", "Er\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PTKNEG", "NE", "$,", "ART", "ADJA", "NE", "ART", "NN", "$,"], "meter": "-+----+-+-+-", "measure": "dactylic.init"}, "line.4": {"text": "Und unsern Carl, den tapfern Helden-Sohn?", "tokens": ["Und", "un\u00b7sern", "Carl", ",", "den", "tap\u00b7fern", "Hel\u00b7den\u00b7Sohn", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NE", "$,", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Die Gallier und die den Tagus trincken,", "tokens": ["Die", "Gal\u00b7lier", "und", "die", "den", "Ta\u00b7gus", "trin\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.6": {"text": "Der kalte Belt, der Scyth und Muselmann,", "tokens": ["Der", "kal\u00b7te", "Belt", ",", "der", "Scyth", "und", "Mu\u00b7sel\u00b7mann", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Sehn seinen Glantz mit reger Ehrfurcht an,", "tokens": ["Sehn", "sei\u00b7nen", "Glantz", "mit", "re\u00b7ger", "Ehr\u00b7furcht", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "APPR", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Und zittern schon vor seiner Schwerdter Blincken.", "tokens": ["Und", "zit\u00b7tern", "schon", "vor", "sei\u00b7ner", "Schwerd\u00b7ter", "Blin\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "APPR", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.26": {"line.1": {"text": "Der edle Rhein wei\u00df Franckreichs Phantasey", "tokens": ["Der", "ed\u00b7le", "Rhein", "wei\u00df", "Fran\u00b7ck\u00b7reichs", "Phan\u00b7ta\u00b7sey"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NE", "VVFIN", "NE", "NE"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Noch unverr\u00fcckt das letzte Ziel zu stecken.", "tokens": ["Noch", "un\u00b7ver\u00b7r\u00fcckt", "das", "letz\u00b7te", "Ziel", "zu", "ste\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ART", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "So lange Kehl und Philippsburg ihn decken,", "tokens": ["So", "lan\u00b7ge", "Kehl", "und", "Phi\u00b7lipps\u00b7burg", "ihn", "de\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "KON", "NE", "PPER", "VVINF", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Verlacht er stets die fremde Sclaverey.", "tokens": ["Ver\u00b7lacht", "er", "stets", "die", "frem\u00b7de", "Scla\u00b7ve\u00b7rey", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Die Donau darf den Fessel-freyen R\u00fccken,", "tokens": ["Die", "Do\u00b7nau", "darf", "den", "Fes\u00b7sel\u00b7freyen", "R\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "VMFIN", "ART", "NN", "NN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Nicht mehr so weit in Achmets Herrschafft sehn,", "tokens": ["Nicht", "mehr", "so", "weit", "in", "Ach\u00b7mets", "Herr\u00b7schafft", "sehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "ADV", "ADJD", "APPR", "NE", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Und kan die Fluth mit freyern Wirbeln drehn,", "tokens": ["Und", "kan", "die", "Fluth", "mit", "frey\u00b7ern", "Wir\u00b7beln", "drehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ART", "NN", "APPR", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Sie siebenfach ins schwartze Meer zu schicken.", "tokens": ["Sie", "sie\u00b7ben\u00b7fach", "ins", "schwart\u00b7ze", "Meer", "zu", "schi\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PRF", "APPRART", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.27": {"line.1": {"text": "Giebt Deutschland nicht der Europ\u00e4er Welt,", "tokens": ["Giebt", "Deutschland", "nicht", "der", "Eu\u00b7ro\u00b7p\u00e4\u00b7er", "Welt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "PTKNEG", "ART", "NN", "NN", "$,"], "meter": "----+-+-+", "measure": "unknown.measure.tri"}, "line.2": {"text": "Fast jedes Haupt die V\u00f6lcker zu regieren?", "tokens": ["Fast", "je\u00b7des", "Haupt", "die", "V\u00f6l\u00b7cker", "zu", "re\u00b7gie\u00b7ren", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Ein deutscher Printz mu\u00df Schwedens Zepter f\u00fchren;", "tokens": ["Ein", "deut\u00b7scher", "Printz", "mu\u00df", "Schwe\u00b7dens", "Zep\u00b7ter", "f\u00fch\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VMFIN", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Sarmatien beherrscht ein deutscher Held.", "tokens": ["Sar\u00b7ma\u00b7ti\u00b7en", "be\u00b7herrscht", "ein", "deut\u00b7scher", "Held", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Noch neulich hat der Engell\u00e4nder Krone", "tokens": ["Noch", "neu\u00b7lich", "hat", "der", "En\u00b7gel\u00b7l\u00e4n\u00b7der", "Kro\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "VAFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Hannovers Haupt recht K\u00f6niglich geschm\u00fcckt:", "tokens": ["Han\u00b7no\u00b7vers", "Haupt", "recht", "K\u00f6\u00b7nig\u00b7lich", "ge\u00b7schm\u00fcckt", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "ADJD", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Hesperien und Servien erblickt,", "tokens": ["Hes\u00b7pe\u00b7ri\u00b7en", "und", "Ser\u00b7vi\u00b7en", "er\u00b7blickt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "NE", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Sein h\u00f6chstes Wohl auf Deutschlands K\u00e4yser-Throne.", "tokens": ["Sein", "h\u00f6chs\u00b7tes", "Wohl", "auf", "Deutschlands", "K\u00e4y\u00b7ser\u00b7Thro\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "APPR", "NE", "NE", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.28": {"line.1": {"text": "Man sp\u00fcrt ja noch der Deutschen Sprache Rest,", "tokens": ["Man", "sp\u00fcrt", "ja", "noch", "der", "Deut\u00b7schen", "Spra\u00b7che", "Rest", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ADV", "ADV", "ART", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "So weit das Schwerdt Germaniens gedrungen;", "tokens": ["So", "weit", "das", "Schwerdt", "Ger\u00b7ma\u00b7ni\u00b7ens", "ge\u00b7drun\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ART", "NN", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Europa h\u00f6rt von aller V\u00f6lcker Zungen,", "tokens": ["Eu\u00b7ro\u00b7pa", "h\u00f6rt", "von", "al\u00b7ler", "V\u00f6l\u00b7cker", "Zun\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPR", "PIAT", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Was uns der Nord bis I\u00dfland h\u00f6ren l\u00e4\u00dft.", "tokens": ["Was", "uns", "der", "Nord", "bis", "I\u00df\u00b7land", "h\u00f6\u00b7ren", "l\u00e4\u00dft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ART", "NN", "APPR", "NE", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Von Griechenland bis zu den Portugiesen", "tokens": ["Von", "Grie\u00b7chen\u00b7land", "bis", "zu", "den", "Por\u00b7tu\u00b7gie\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NE", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Trifft man die Spur der deutschen Mund-Art an.", "tokens": ["Trifft", "man", "die", "Spur", "der", "deut\u00b7schen", "Mun\u00b7dArt", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ART", "NN", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Ja was noch mehr! der Perser Ispahan,", "tokens": ["Ja", "was", "noch", "mehr", "!", "der", "Per\u00b7ser", "Is\u00b7pa\u00b7han", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKANT", "PWS", "ADV", "ADV", "$.", "ART", "NN", "NE", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Hat auch davon die Proben aufgewiesen.", "tokens": ["Hat", "auch", "da\u00b7von", "die", "Pro\u00b7ben", "auf\u00b7ge\u00b7wie\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PAV", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.29": {"line.1": {"text": "Was seh ich dort? Die Helden grauer Zeit", "tokens": ["Was", "seh", "ich", "dort", "?", "Die", "Hel\u00b7den", "grau\u00b7er", "Zeit"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "$.", "ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Die Cimbrer sinds, die Welschland sonst erstritten;", "tokens": ["Die", "Cim\u00b7brer", "sinds", ",", "die", "Wel\u00b7schland", "sonst", "er\u00b7strit\u00b7ten", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "$,", "ART", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Der Angeln Heer, der Trost-bedr\u00e4ngter Britten:", "tokens": ["Der", "An\u00b7geln", "Heer", ",", "der", "Trost\u00b7be\u00b7dr\u00e4ng\u00b7ter", "Brit\u00b7ten", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$,", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Die Welt erschrack vor beyder Tapferkeit.", "tokens": ["Die", "Welt", "er\u00b7schrack", "vor", "bey\u00b7der", "Tap\u00b7fer\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Besch\u00e4mtes Rom, kanst du Carthago zwingen,", "tokens": ["Be\u00b7sch\u00e4m\u00b7tes", "Rom", ",", "kanst", "du", "Car\u00b7tha\u00b7go", "zwin\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "VMFIN", "PPER", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "So zwing einmahl der Deutschen Helden Brust.", "tokens": ["So", "zwing", "ein\u00b7mahl", "der", "Deut\u00b7schen", "Hel\u00b7den", "Brust", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "ART", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Umsonst, umsonst! Verg\u00f6tterter August,", "tokens": ["Um\u00b7sonst", ",", "um\u00b7sonst", "!", "Ver\u00b7g\u00f6t\u00b7ter\u00b7ter", "Au\u00b7gust", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "$,", "ADV", "$.", "NN", "NN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Dein Reich verf\u00e4llt von deutscher V\u00f6lcker Klingen.", "tokens": ["Dein", "Reich", "ver\u00b7f\u00e4llt", "von", "deut\u00b7scher", "V\u00f6l\u00b7cker", "Klin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "APPR", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.30": {"line.1": {"text": "Ihr Adler flieht! dafern ihr Zuflucht wi\u00dft,", "tokens": ["Ihr", "Ad\u00b7ler", "flieht", "!", "da\u00b7fern", "ihr", "Zu\u00b7flucht", "wi\u00dft", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "$.", "KOUS", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Wo Herrmann schl\u00e4gt, da wei\u00df man nicht zu schonen.", "tokens": ["Wo", "Herr\u00b7mann", "schl\u00e4gt", ",", "da", "wei\u00df", "man", "nicht", "zu", "scho\u00b7nen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NE", "VVFIN", "$,", "ADV", "VVFIN", "PIS", "PTKNEG", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Erwegt den Fall so vieler Legionen,", "tokens": ["Er\u00b7wegt", "den", "Fall", "so", "vie\u00b7ler", "Le\u00b7gi\u00b7o\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ADV", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Die Varus dort so sch\u00e4ndlich eingeb\u00fc\u00dft.", "tokens": ["Die", "Va\u00b7rus", "dort", "so", "sch\u00e4nd\u00b7lich", "ein\u00b7ge\u00b7b\u00fc\u00dft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "ADV", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Was regt sich hier? Ein Heer der Alemannen", "tokens": ["Was", "regt", "sich", "hier", "?", "Ein", "Heer", "der", "A\u00b7le\u00b7man\u00b7nen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "PRF", "ADV", "$.", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Bahnt sich den Weg zu Herkuls Seulen hin;", "tokens": ["Bahnt", "sich", "den", "Weg", "zu", "Her\u00b7kuls", "Seu\u00b7len", "hin", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ART", "NN", "APPR", "NE", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Selbst Africa wird Deutschland zum Gewinn,", "tokens": ["Selbst", "A\u00b7fri\u00b7ca", "wird", "Deutschland", "zum", "Ge\u00b7winn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NE", "VAFIN", "NE", "APPRART", "NN", "$,"], "meter": "--+--+--+", "measure": "anapaest.tri.plus"}, "line.8": {"text": "Und l\u00e4\u00dft den Hals ins Joch der Vandaln spannen.", "tokens": ["Und", "l\u00e4\u00dft", "den", "Hals", "ins", "Joch", "der", "Van\u00b7daln", "span\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "APPRART", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.31": {"line.1": {"text": "Wo bleibt o Rom, der theur-erkaufte Ruhm,", "tokens": ["Wo", "bleibt", "o", "Rom", ",", "der", "theur\u00b7er\u00b7kauf\u00b7te", "Ruhm", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "FM", "NE", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Den Julius in Gallien erfochten?", "tokens": ["Den", "Ju\u00b7lius", "in", "Gal\u00b7li\u00b7en", "er\u00b7foch\u00b7ten", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "APPR", "NE", "VVFIN", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Der Lorber-Krantz, den sich sein Arm geflochten,", "tokens": ["Der", "Lor\u00b7ber\u00b7Krantz", ",", "den", "sich", "sein", "Arm", "ge\u00b7floch\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PRF", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Wird unverhofft der Deutschen Eigenthum.", "tokens": ["Wird", "un\u00b7ver\u00b7hofft", "der", "Deut\u00b7schen", "Ei\u00b7gen\u00b7thum", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Ein Fr\u00e4nckisch Heer zerschl\u00e4gt die Ehren-Seulen,", "tokens": ["Ein", "Fr\u00e4n\u00b7ckisch", "Heer", "zer\u00b7schl\u00e4gt", "die", "Eh\u00b7ren\u00b7Seu\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Tilgt C\u00e4sars Lob und Sieges-M\u00e4hler aus.", "tokens": ["Tilgt", "C\u00e4\u00b7sars", "Lob", "und", "Sie\u00b7ges\u00b7M\u00e4h\u00b7ler", "aus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "NN", "KON", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Sein Stoltz verdients, da\u00df Schatten, Nacht und Graus,", "tokens": ["Sein", "Stoltz", "ver\u00b7dients", ",", "da\u00df", "Schat\u00b7ten", ",", "Nacht", "und", "Graus", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "$,", "KOUS", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Der Herrsch-Begier ein schimpflich Grab ertheilen.", "tokens": ["Der", "Herr\u00b7schBe\u00b7gier", "ein", "schimpf\u00b7lich", "Grab", "er\u00b7thei\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "ADJD", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.32": {"line.1": {"text": "Pannonien, Illyrien, Tyrol,", "tokens": ["Pan\u00b7no\u00b7ni\u00b7en", ",", "Il\u00b7ly\u00b7ri\u00b7en", ",", "Ty\u00b7rol", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["NE", "$,", "NE", "$,", "NE", "$,"], "meter": "+-+-+-++-+", "measure": "unknown.measure.hexa"}, "line.2": {"text": "Erschrack vor euch ihr unbesiegten Gothen!", "tokens": ["Er\u00b7schrack", "vor", "euch", "ihr", "un\u00b7be\u00b7sieg\u00b7ten", "Go\u00b7then", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPER", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Wie bebte Rom als Gensrichs Waffen drohten?", "tokens": ["Wie", "beb\u00b7te", "Rom", "als", "Gens\u00b7richs", "Waf\u00b7fen", "droh\u00b7ten", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "NE", "KOUS", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Wie sch\u00fctterte das feste Capitol?", "tokens": ["Wie", "sch\u00fct\u00b7ter\u00b7te", "das", "fes\u00b7te", "Ca\u00b7pi\u00b7tol", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Der Alpen Eis, so an den Himmel r\u00fchret,", "tokens": ["Der", "Al\u00b7pen", "Eis", ",", "so", "an", "den", "Him\u00b7mel", "r\u00fch\u00b7ret", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$,", "ADV", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Verhindert nicht der Deutschen Uberfall;", "tokens": ["Ver\u00b7hin\u00b7dert", "nicht", "der", "Deut\u00b7schen", "U\u00b7ber\u00b7fall", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Der Longobard, ein andrer Hannibal,", "tokens": ["Der", "Lon\u00b7go\u00b7bard", ",", "ein", "an\u00b7drer", "Han\u00b7ni\u00b7bal", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NE", "$,", "ART", "ADJA", "NE", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Hat Steg und Bahn von neuem ausgesp\u00fcret.", "tokens": ["Hat", "Steg", "und", "Bahn", "von", "neu\u00b7em", "aus\u00b7ge\u00b7sp\u00fc\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "KON", "NN", "APPR", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.33": {"line.1": {"text": "Auf, grosser Carl! Thuiscons \u00e4chter Sohn,", "tokens": ["Auf", ",", "gros\u00b7ser", "Carl", "!", "Thu\u00b7is\u00b7cons", "\u00e4ch\u00b7ter", "Sohn", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "$,", "ADJA", "NE", "$.", "NE", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Auf! r\u00fcste dich, gepriesnes Haupt der Francken,", "tokens": ["Auf", "!", "r\u00fcs\u00b7te", "dich", ",", "ge\u00b7pri\u00b7es\u00b7nes", "Haupt", "der", "Fran\u00b7cken", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "$.", "VVFIN", "PPER", "$,", "ADJA", "NN", "ART", "NN", "$,"], "meter": "-+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Der R\u00f6mer Reich wird dir sein Wohl verdancken,", "tokens": ["Der", "R\u00f6\u00b7mer", "Reich", "wird", "dir", "sein", "Wohl", "ver\u00b7dan\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "PPER", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Besteige nur den alten K\u00e4yser-Thron.", "tokens": ["Be\u00b7stei\u00b7ge", "nur", "den", "al\u00b7ten", "K\u00e4y\u00b7ser\u00b7Thron", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Wie sich das Gold der Flammen-reichen Sonnen", "tokens": ["Wie", "sich", "das", "Gold", "der", "Flam\u00b7men\u00b7rei\u00b7chen", "Son\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PRF", "ART", "NN", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Nach finstrer Nacht mit hellerm Schimmer zeigt,", "tokens": ["Nach", "finst\u00b7rer", "Nacht", "mit", "hel\u00b7lerm", "Schim\u00b7mer", "zeigt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Als wenn es sp\u00e4t in Thetis Arme steigt,", "tokens": ["Als", "wenn", "es", "sp\u00e4t", "in", "The\u00b7tis", "Ar\u00b7me", "steigt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "PPER", "ADJD", "APPR", "NE", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "So viel hat Rom durch unsern Carl gewonnen.", "tokens": ["So", "viel", "hat", "Rom", "durch", "un\u00b7sern", "Carl", "ge\u00b7won\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VAFIN", "NE", "APPR", "PPOSAT", "NE", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.34": {"line.1": {"text": "Genug o Mars, von Deutscher Sieger Muth", "tokens": ["Ge\u00b7nug", "o", "Mars", ",", "von", "Deut\u00b7scher", "Sie\u00b7ger", "Muth"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "FM", "NN", "$,", "APPR", "ADJA", "NN", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Germanien, genug von Deinen Waffen;", "tokens": ["Ger\u00b7ma\u00b7ni\u00b7en", ",", "ge\u00b7nug", "von", "Dei\u00b7nen", "Waf\u00b7fen", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Kan Witz und Kunst Dir keinen Ruhm verschaffen,", "tokens": ["Kan", "Witz", "und", "Kunst", "Dir", "kei\u00b7nen", "Ruhm", "ver\u00b7schaf\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "NN", "KON", "NN", "PPER", "PIAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Was hilft die Macht? was n\u00fctzt dir Stahl und Gluth?", "tokens": ["Was", "hilft", "die", "Macht", "?", "was", "n\u00fctzt", "dir", "Stahl", "und", "Gluth", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ART", "NN", "$.", "PWS", "VVFIN", "PPER", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Das ist die Art der wildesten Barbaren,", "tokens": ["Das", "ist", "die", "Art", "der", "wil\u00b7des\u00b7ten", "Bar\u00b7ba\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+---+-", "measure": "unknown.measure.tetra"}, "line.6": {"text": "An F\u00e4usten starck und schwach am Geiste seyn:", "tokens": ["An", "F\u00e4us\u00b7ten", "starck", "und", "schwach", "am", "Geis\u00b7te", "seyn", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADJD", "KON", "ADJD", "APPRART", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Ihr Musen kommt, und helft mir selber ein,", "tokens": ["Ihr", "Mu\u00b7sen", "kommt", ",", "und", "helft", "mir", "sel\u00b7ber", "ein", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "$,", "KON", "VVFIN", "PPER", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Und lehrt und sagt, wie klug die Deutschen waren.", "tokens": ["Und", "lehrt", "und", "sagt", ",", "wie", "klug", "die", "Deut\u00b7schen", "wa\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "KON", "VVFIN", "$,", "PWAV", "ADJD", "ART", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.35": {"line.1": {"text": "Ich h\u00f6re schon geborstner Bomben Knall,", "tokens": ["Ich", "h\u00f6\u00b7re", "schon", "ge\u00b7borst\u00b7ner", "Bom\u00b7ben", "Knall", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Der Erd-Kreis bebt vom Donner der Carthaunen,", "tokens": ["Der", "Erd\u00b7Kreis", "bebt", "vom", "Don\u00b7ner", "der", "Car\u00b7thau\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPRART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Ihr Blitz und Dampf setzt alles in Erstaunen,", "tokens": ["Ihr", "Blitz", "und", "Dampf", "setzt", "al\u00b7les", "in", "Er\u00b7stau\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "NN", "VVFIN", "PIS", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Hier springt ein Thurm, dort sincket Thor und Wall.", "tokens": ["Hier", "springt", "ein", "Thurm", ",", "dort", "sin\u00b7cket", "Thor", "und", "Wall", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$,", "ADV", "VVFIN", "NN", "KON", "NE", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Leiht Jupiter den Menschen Keil und Blitze?", "tokens": ["Leiht", "Ju\u00b7pi\u00b7ter", "den", "Men\u00b7schen", "Keil", "und", "Blit\u00b7ze", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "ART", "NN", "NN", "KON", "NN", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.6": {"text": "Er\u00f6fnet sich der H\u00f6llen w\u00fcster Schlund?", "tokens": ["Er\u00b7\u00f6f\u00b7net", "sich", "der", "H\u00f6l\u00b7len", "w\u00fcs\u00b7ter", "Schlund", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "O w\u00fcrden mir die neuen G\u00f6tter kund!", "tokens": ["O", "w\u00fcr\u00b7den", "mir", "die", "neu\u00b7en", "G\u00f6t\u00b7ter", "kund", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PPER", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Die Deutschen sinds, durch Pulver und Gesch\u00fctze.", "tokens": ["Die", "Deut\u00b7schen", "sinds", ",", "durch", "Pul\u00b7ver", "und", "Ge\u00b7sch\u00fct\u00b7ze", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "$,", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.36": {"line.1": {"text": "O Seltne Kunst! Die gr\u00f6\u00dfre Wunder zeigt,", "tokens": ["O", "Selt\u00b7ne", "Kunst", "!", "Die", "gr\u00f6\u00df\u00b7re", "Wun\u00b7der", "zeigt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$.", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Als alle Pracht bejahrter Seltenheiten.", "tokens": ["Als", "al\u00b7le", "Pracht", "be\u00b7jahr\u00b7ter", "Sel\u00b7ten\u00b7hei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Ihr seyd besch\u00e4mt, ihr K\u00fcnstler alter Zeiten,", "tokens": ["Ihr", "seyd", "be\u00b7sch\u00e4mt", ",", "ihr", "K\u00fcnst\u00b7ler", "al\u00b7ter", "Zei\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "$,", "PPOSAT", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Da Deutschland euch noch t\u00e4glich \u00fcbersteigt.", "tokens": ["Da", "Deutschland", "euch", "noch", "t\u00e4g\u00b7lich", "\u00fc\u00b7bers\u00b7teigt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "PPER", "ADV", "ADJD", "VVPP", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Selbst das Metall wohl eingeschw\u00e4rtzter Schrifften,", "tokens": ["Selbst", "das", "Me\u00b7tall", "wohl", "ein\u00b7ge\u00b7schw\u00e4rtz\u00b7ter", "Schriff\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "ADV", "ADJA", "NN", "$,"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.6": {"text": "So diesen Reim auf tausend Bl\u00e4tter dr\u00fcckt,", "tokens": ["So", "die\u00b7sen", "Reim", "auf", "tau\u00b7send", "Bl\u00e4t\u00b7ter", "dr\u00fcckt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PDAT", "NN", "APPR", "CARD", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Und meinen Kiel der Zeiten Wuth entr\u00fcckt,", "tokens": ["Und", "mei\u00b7nen", "Kiel", "der", "Zei\u00b7ten", "Wuth", "ent\u00b7r\u00fcckt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "ART", "NN", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Das, das kan uns ein ewig Denckmahl stifften.", "tokens": ["Das", ",", "das", "kan", "uns", "ein", "e\u00b7wig", "Denck\u00b7mahl", "stiff\u00b7ten", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "$,", "PDS", "VMFIN", "PPER", "ART", "ADJD", "NN", "VVFIN", "$."], "meter": "-+---+-+-+-", "measure": "dactylic.init"}}, "stanza.37": {"line.1": {"text": "Wer hat den Bau der Himmel umgekehrt,", "tokens": ["Wer", "hat", "den", "Bau", "der", "Him\u00b7mel", "um\u00b7ge\u00b7kehrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ART", "NN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Dem Erden-Ball den Mittel-Punct entzogen,", "tokens": ["Dem", "Er\u00b7den\u00b7Ball", "den", "Mit\u00b7tel\u00b7Punct", "ent\u00b7zo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "So da\u00df er itzt in l\u00e4nglicht-runden Bogen,", "tokens": ["So", "da\u00df", "er", "itzt", "in", "l\u00e4ng\u00b7licht\u00b7run\u00b7den", "Bo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PPER", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Von Jahr zu Jahr die feste Sonn umf\u00e4hrt?", "tokens": ["Von", "Jahr", "zu", "Jahr", "die", "fes\u00b7te", "Sonn", "um\u00b7f\u00e4hrt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "NN", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Wer r\u00e4umte doch den Wust Crystallner Kreise,", "tokens": ["Wer", "r\u00e4um\u00b7te", "doch", "den", "Wust", "Crys\u00b7tall\u00b7ner", "Krei\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ADV", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Mit starcker Faust aus der gestirnten Lufft?", "tokens": ["Mit", "star\u00b7cker", "Faust", "aus", "der", "ge\u00b7stirn\u00b7ten", "Lufft", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Ihr V\u00f6lcker merckts, denn gantz Europa rufft:", "tokens": ["Ihr", "V\u00f6l\u00b7cker", "merckts", ",", "denn", "gantz", "Eu\u00b7ro\u00b7pa", "rufft", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "$,", "KON", "ADV", "NE", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Ein Deutscher thats, Copernicus der Weise.", "tokens": ["Ein", "Deut\u00b7scher", "thats", ",", "Co\u00b7per\u00b7ni\u00b7cus", "der", "Wei\u00b7se", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "NE", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.38": {"line.1": {"text": "Er war dein Sohn, Du deutsches Preussen-Land?", "tokens": ["Er", "war", "dein", "Sohn", ",", "Du", "deut\u00b7sches", "Preus\u00b7sen\u00b7Land", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "NN", "$,", "PPER", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Und hat sich selbst und deinen Ruhm erhoben.", "tokens": ["Und", "hat", "sich", "selbst", "und", "dei\u00b7nen", "Ruhm", "er\u00b7ho\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PRF", "ADV", "KON", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Vergi\u00df nur nicht auch Hevels Flei\u00df zu loben,", "tokens": ["Ver\u00b7gi\u00df", "nur", "nicht", "auch", "He\u00b7vels", "Flei\u00df", "zu", "lo\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ADV", "PTKNEG", "ADV", "NE", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Der das Gestirn in neue Bilder band.", "tokens": ["Der", "das", "Ge\u00b7stirn", "in", "neu\u00b7e", "Bil\u00b7der", "band", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.5": {"text": "Vor Kepplern mu\u00df ein Archimedes weichen,", "tokens": ["Vor", "Kep\u00b7plern", "mu\u00df", "ein", "Ar\u00b7chi\u00b7me\u00b7des", "wei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VMFIN", "ART", "NN", "VVINF", "$,"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.6": {"text": "Was Huygens uns von tausend Welten lehrt,", "tokens": ["Was", "Huy\u00b7gens", "uns", "von", "tau\u00b7send", "Wel\u00b7ten", "lehrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NE", "PPER", "APPR", "CARD", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "War gleichfalls sonst den Menschen unerh\u00f6rt,", "tokens": ["War", "gleich\u00b7falls", "sonst", "den", "Men\u00b7schen", "un\u00b7er\u00b7h\u00f6rt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Wer denckt sich nun den Deutschen zu vergleichen?", "tokens": ["Wer", "denckt", "sich", "nun", "den", "Deut\u00b7schen", "zu", "ver\u00b7glei\u00b7chen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PRF", "ADV", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.39": {"line.1": {"text": "Vergebens prahlt ein stoltzer Pythagor,", "tokens": ["Ver\u00b7ge\u00b7bens", "prahlt", "ein", "stolt\u00b7zer", "Py\u00b7tha\u00b7gor", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NE", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Die Harmonie des Himmels-Laufs zu wissen.", "tokens": ["Die", "Har\u00b7mo\u00b7nie", "des", "Him\u00b7mels\u00b7Laufs", "zu", "wis\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Dis Lob wird ihm von deutscher Hand entrissen,", "tokens": ["Dis", "Lob", "wird", "ihm", "von", "deut\u00b7scher", "Hand", "ent\u00b7ris\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "NN", "VAFIN", "PPER", "APPR", "ADJA", "NN", "VVPP", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Germanien verlacht sein leises Ohr.", "tokens": ["Ger\u00b7ma\u00b7ni\u00b7en", "ver\u00b7lacht", "sein", "lei\u00b7ses", "Ohr", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Sein Zauber-Klang bewegter Himmels-Spheren,", "tokens": ["Sein", "Zau\u00b7ber\u00b7Klang", "be\u00b7weg\u00b7ter", "Him\u00b7mels\u00b7S\u00b7phe\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Was war er sonst, als ein gelehrter Traum?", "tokens": ["Was", "war", "er", "sonst", ",", "als", "ein", "ge\u00b7lehr\u00b7ter", "Traum", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "ADV", "$,", "KOUS", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Uns zeigt itzund der Himmel weiten Raum,", "tokens": ["Uns", "zeigt", "it\u00b7zund", "der", "Him\u00b7mel", "wei\u00b7ten", "Raum", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Ein doppelt Glas empor gestreckter R\u00f6hren.", "tokens": ["Ein", "dop\u00b7pelt", "Glas", "em\u00b7por", "ge\u00b7streck\u00b7ter", "R\u00f6h\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "PTKVZ", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.40": {"line.1": {"text": "Die Wei\u00dfheit kam, der Europ\u00e4er-Welt,", "tokens": ["Die", "Wei\u00df\u00b7heit", "kam", ",", "der", "Eu\u00b7ro\u00b7p\u00e4\u00b7er\u00b7Welt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Ein eintzig Haupt zum Lehrer vorzusetzen:", "tokens": ["Ein", "eint\u00b7zig", "Haupt", "zum", "Leh\u00b7rer", "vor\u00b7zu\u00b7set\u00b7zen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Gleich hub sie an die Deutschen hochzusch\u00e4tzen,", "tokens": ["Gleich", "hub", "sie", "an", "die", "Deut\u00b7schen", "hoch\u00b7zu\u00b7sch\u00e4t\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Weil ihr Verstand fast alles in sich h\u00e4lt.", "tokens": ["Weil", "ihr", "Ver\u00b7stand", "fast", "al\u00b7les", "in", "sich", "h\u00e4lt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "ADV", "PIS", "APPR", "PRF", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Ein Leibnitz trotzt den Frantzen und den Britten,", "tokens": ["Ein", "Leib\u00b7nitz", "trotzt", "den", "Frant\u00b7zen", "und", "den", "Brit\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "KON", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Was hat er nicht vor Wunder ausgedacht!", "tokens": ["Was", "hat", "er", "nicht", "vor", "Wun\u00b7der", "aus\u00b7ge\u00b7dacht", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "PTKNEG", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Die Rechnung blo\u00df die er hervor gebracht,", "tokens": ["Die", "Rech\u00b7nung", "blo\u00df", "die", "er", "her\u00b7vor", "ge\u00b7bracht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "PRELS", "PPER", "PTKVZ", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Hat uns den Preis der Wissenschafft erstritten.", "tokens": ["Hat", "uns", "den", "Preis", "der", "Wis\u00b7sen\u00b7schafft", "er\u00b7strit\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.41": {"line.1": {"text": "Uns Deutschen danckts, ihr Priester der Natur,", "tokens": ["Uns", "Deut\u00b7schen", "dan\u00b7ckts", ",", "ihr", "Pries\u00b7ter", "der", "Na\u00b7tur", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "ADV", "$,", "PPOSAT", "NN", "ART", "NN", "$,"], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Der ihr so weit ins Heiligthum gedrungen;", "tokens": ["Der", "ihr", "so", "weit", "ins", "Hei\u00b7lig\u00b7thum", "ge\u00b7drun\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "ADJD", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Es ist euch blos durch deutschen Witz gelungen,", "tokens": ["Es", "ist", "euch", "blos", "durch", "deut\u00b7schen", "Witz", "ge\u00b7lun\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "APPR", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Wer half euch sonst im Forschen auf die Spur?", "tokens": ["Wer", "half", "euch", "sonst", "im", "For\u00b7schen", "auf", "die", "Spur", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "APPRART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Wenn Gericke die Lufft-Pump ausgesonnen,", "tokens": ["Wenn", "Ge\u00b7ri\u00b7cke", "die", "Lufft\u00b7Pump", "aus\u00b7ge\u00b7son\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "ART", "NN", "VVINF", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.6": {"text": "Wenn Tschirnhaus Stahl durch Spiegel schmeltzen lehrt,", "tokens": ["Wenn", "Tschirn\u00b7haus", "Stahl", "durch", "Spie\u00b7gel", "schmelt\u00b7zen", "lehrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "NN", "APPR", "NN", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Wenn Sturm und Wolf die Wissenschafften mehrt;", "tokens": ["Wenn", "Sturm", "und", "Wolf", "die", "Wis\u00b7sen\u00b7schaff\u00b7ten", "mehrt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "NE", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Wer hat uns denn den Vorzug abgewonnen?", "tokens": ["Wer", "hat", "uns", "denn", "den", "Vor\u00b7zug", "ab\u00b7ge\u00b7won\u00b7nen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "ADV", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.42": {"line.1": {"text": "Sch\u00e4mt euch nur nicht, ihr Dichter deutscher Zucht,", "tokens": ["Sch\u00e4mt", "euch", "nur", "nicht", ",", "ihr", "Dich\u00b7ter", "deut\u00b7scher", "Zucht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "PTKNEG", "$,", "PPOSAT", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Was legt ihr doch die bl\u00f6den Fl\u00f6ten nieder?", "tokens": ["Was", "legt", "ihr", "doch", "die", "bl\u00f6\u00b7den", "Fl\u00f6\u00b7ten", "nie\u00b7der", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Die Musen selbst begeistern eure Lieder,", "tokens": ["Die", "Mu\u00b7sen", "selbst", "be\u00b7geis\u00b7tern", "eu\u00b7re", "Lie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und Ph\u00f6bus nennt sie seiner Triebe Frucht.", "tokens": ["Und", "Ph\u00f6\u00b7bus", "nennt", "sie", "sei\u00b7ner", "Trie\u00b7be", "Frucht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "VVFIN", "PPER", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Besang Homer den Eifer von Atriden,", "tokens": ["Be\u00b7sang", "Ho\u00b7mer", "den", "Ei\u00b7fer", "von", "At\u00b7ri\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "ART", "NN", "APPR", "NE", "$,"], "meter": "-++--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Beschrieb Virgil Aeneens Helden-Zug:", "tokens": ["Be\u00b7schrieb", "Vir\u00b7gil", "A\u00b7e\u00b7neens", "Hel\u00b7den\u00b7Zug", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "NE", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "So hat die Welt der Fabeln l\u00e4ngst genug;", "tokens": ["So", "hat", "die", "Welt", "der", "Fa\u00b7beln", "l\u00e4ngst", "ge\u00b7nug", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "ART", "NN", "ADV", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Euch Deutschen ist der Wahrheit Lob beschieden.", "tokens": ["Euch", "Deut\u00b7schen", "ist", "der", "Wahr\u00b7heit", "Lob", "be\u00b7schie\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "VAFIN", "ART", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.43": {"line.1": {"text": "Was Opitz, Dach, und Hofmannswaldaus Rohr,", "tokens": ["Was", "O\u00b7pitz", ",", "Dach", ",", "und", "Hof\u00b7manns\u00b7wald\u00b7aus", "Rohr", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "NE", "$,", "NN", "$,", "KON", "NN", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Was Lohensteins und Amthors Mund gesungen,", "tokens": ["Was", "Lo\u00b7hen\u00b7steins", "und", "Am\u00b7thors", "Mund", "ge\u00b7sun\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NE", "KON", "NN", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Wie Canitz schrieb, wie G\u00fcnthers Lied geklungen,", "tokens": ["Wie", "Ca\u00b7nitz", "schrieb", ",", "wie", "G\u00fcn\u00b7thers", "Lied", "ge\u00b7klun\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NE", "VVFIN", "$,", "PWAV", "NE", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "H\u00e4lt Ph\u00f6bus selbst den jungen Dichtern vor.", "tokens": ["H\u00e4lt", "Ph\u00f6\u00b7bus", "selbst", "den", "jun\u00b7gen", "Dich\u00b7tern", "vor", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "ADV", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Steht Neukirch nicht im Deutschen Musen-Tempel,", "tokens": ["Steht", "Neu\u00b7kirch", "nicht", "im", "Deut\u00b7schen", "Mu\u00b7sen\u00b7Tem\u00b7pel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "PTKNEG", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Wie K\u00f6nig, Pietsch und Wentzel oben an?", "tokens": ["Wie", "K\u00f6\u00b7nig", ",", "Pietsch", "und", "Went\u00b7zel", "o\u00b7ben", "an", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "$,", "NN", "KON", "NN", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Philanders Kiel und jenen Alster-Schwan", "tokens": ["Phi\u00b7lan\u00b7ders", "Kiel", "und", "je\u00b7nen", "Als\u00b7ter\u00b7Schwan"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "NE", "KON", "PDAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Erwehlt die Welt sich k\u00fcnftig zum Exempel.", "tokens": ["Er\u00b7wehlt", "die", "Welt", "sich", "k\u00fcnf\u00b7tig", "zum", "Ex\u00b7em\u00b7pel", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "PRF", "ADJD", "APPRART", "NN", "$."], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}}, "stanza.44": {"line.1": {"text": "Es r\u00fchme sich so Welschland als Athen,", "tokens": ["Es", "r\u00fch\u00b7me", "sich", "so", "Wel\u00b7schland", "als", "A\u00b7then", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "ADV", "NN", "KOKOM", "NE", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Und selbst Paris im Bauen, Mahlen, Singen;", "tokens": ["Und", "selbst", "Pa\u00b7ris", "im", "Bau\u00b7en", ",", "Mah\u00b7len", ",", "Sin\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["KON", "ADV", "NE", "APPRART", "NN", "$,", "NN", "$,", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Der Deutschen Witz kan ihren Stoltz bezwingen,", "tokens": ["Der", "Deut\u00b7schen", "Witz", "kan", "ih\u00b7ren", "Stoltz", "be\u00b7zwin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VMFIN", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und sch\u00e4mt sich fast den Wett-Streit einzugehn.", "tokens": ["Und", "sch\u00e4mt", "sich", "fast", "den", "Wet\u00b7tStreit", "ein\u00b7zu\u00b7gehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "ADV", "ART", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Ersann nicht Sturm, die Ordnung deutscher Seulen?", "tokens": ["Er\u00b7sann", "nicht", "Sturm", ",", "die", "Ord\u00b7nung", "deut\u00b7scher", "Seu\u00b7len", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKNEG", "NN", "$,", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Ist Telemann und Hendel nicht bekannt?", "tokens": ["Ist", "Te\u00b7le\u00b7mann", "und", "Hen\u00b7del", "nicht", "be\u00b7kannt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "KON", "NN", "PTKNEG", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Des Hollbeins Kunst und Kranachs Zauber-Hand,", "tokens": ["Des", "Holl\u00b7beins", "Kunst", "und", "Kra\u00b7nachs", "Zau\u00b7ber\u00b7Hand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "KON", "NN", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Wird Zeuxes selbst den Sieges-Krantz ertheilen.", "tokens": ["Wird", "Zeu\u00b7xes", "selbst", "den", "Sie\u00b7ges\u00b7Krantz", "er\u00b7thei\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NE", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.45": {"line.1": {"text": "Batavien! wenn dein verwegner Mast,", "tokens": ["Ba\u00b7ta\u00b7vi\u00b7en", "!", "wenn", "dein", "ver\u00b7weg\u00b7ner", "Mast", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "KOUS", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Bey Sturm und Fluth den Ocean durchflogen;", "tokens": ["Bey", "Sturm", "und", "Fluth", "den", "O\u00b7cean", "durch\u00b7flo\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Wenn dein Compa\u00df der Inden Meer durchzogen;", "tokens": ["Wenn", "dein", "Com\u00b7pa\u00df", "der", "In\u00b7den", "Meer", "durch\u00b7zo\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Ja wenn du gar die Welt umsegelt hast;", "tokens": ["Ja", "wenn", "du", "gar", "die", "Welt", "um\u00b7se\u00b7gelt", "hast", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "KOUS", "PPER", "ADV", "ART", "NN", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "So schreibe doch auf Flaggen, Bort und Seile,", "tokens": ["So", "schrei\u00b7be", "doch", "auf", "Flag\u00b7gen", ",", "Bort", "und", "Sei\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "APPR", "NN", "$,", "NE", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Da\u00df Belgier gebohrne Deutschen seyn;", "tokens": ["Da\u00df", "Bel\u00b7gier", "ge\u00b7bohr\u00b7ne", "Deut\u00b7schen", "seyn", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "ADJA", "NN", "VAINF", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Der Schiffahrt Ruhm geh\u00f6rt nicht dir allein,", "tokens": ["Der", "Schif\u00b7fahrt", "Ruhm", "ge\u00b7h\u00f6rt", "nicht", "dir", "al\u00b7lein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "PTKNEG", "PPER", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Er wird zugleich Germanien zu Theile.", "tokens": ["Er", "wird", "zu\u00b7gleich", "Ger\u00b7ma\u00b7ni\u00b7en", "zu", "Thei\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.46": {"line.1": {"text": "So steigt dein Preis, erh\u00f6htes Vaterland!", "tokens": ["So", "steigt", "dein", "Preis", ",", "er\u00b7h\u00f6h\u00b7tes", "Va\u00b7ter\u00b7land", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "So schallt dein Lob bey fernen Nationen,", "tokens": ["So", "schallt", "dein", "Lob", "bey", "fer\u00b7nen", "Na\u00b7ti\u00b7o\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "In aller Welt, wo irgend Menschen wohnen,", "tokens": ["In", "al\u00b7ler", "Welt", ",", "wo", "ir\u00b7gend", "Men\u00b7schen", "woh\u00b7nen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "$,", "PWAV", "ADV", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Ist Deutschland mehr als sonst ein Volck bekannt.", "tokens": ["Ist", "Deutschland", "mehr", "als", "sonst", "ein", "Volck", "be\u00b7kannt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NE", "PIAT", "KOKOM", "ADV", "ART", "NN", "PTKVZ", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Es kennen dich die Africaner-Mohren,", "tokens": ["Es", "ken\u00b7nen", "dich", "die", "Af\u00b7ri\u00b7ca\u00b7ner\u00b7Moh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "In Japans Reich, in Siam, Bengala,", "tokens": ["In", "Ja\u00b7pans", "Reich", ",", "in", "Si\u00b7am", ",", "Ben\u00b7ga\u00b7la", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "NE", "NE", "$,", "APPR", "NE", "$,", "NE", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "In Malabar, und gantz America", "tokens": ["In", "Ma\u00b7la\u00b7bar", ",", "und", "gantz", "A\u00b7me\u00b7ri\u00b7ca"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "NE", "$,", "KON", "ADV", "NE"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Erf\u00fcllt dein Ruhm der Indianer Ohren.", "tokens": ["Er\u00b7f\u00fcllt", "dein", "Ruhm", "der", "In\u00b7di\u00b7a\u00b7ner", "Oh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}}}}