{"textgrid.poem.63937": {"metadata": {"author": {"name": "Zachari\u00e4, Justus Friedrich Wilhelm", "birth": "N.A.", "death": "N.A."}, "title": "Der Esel und der Stier", "genre": "verse", "period": "N.A.", "pub_year": 1751, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Der Esel ging einst auf der Weide", "tokens": ["Der", "E\u00b7sel", "ging", "einst", "auf", "der", "Wei\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Mit einem Stier; da h\u00f6rten beide", "tokens": ["Mit", "ei\u00b7nem", "Stier", ";", "da", "h\u00f6r\u00b7ten", "bei\u00b7de"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "$.", "ADV", "VVFIN", "PIS"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Viel L\u00e4rm, als wie von einem Heer,", "tokens": ["Viel", "L\u00e4rm", ",", "als", "wie", "von", "ei\u00b7nem", "Heer", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "$,", "KOUS", "KOKOM", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und in den D\u00f6rfern rund umher", "tokens": ["Und", "in", "den", "D\u00f6r\u00b7fern", "rund", "um\u00b7her"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "ADJD", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Zu Sturm mit allen Glocken l\u00e4uten.", "tokens": ["Zu", "Sturm", "mit", "al\u00b7len", "Glo\u00b7cken", "l\u00e4u\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Was (sprach Herr Heinz) mag das bedeuten?", "tokens": ["Was", "(", "sprach", "Herr", "Heinz", ")", "mag", "das", "be\u00b7deu\u00b7ten", "?"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "$(", "VVFIN", "NN", "NE", "$(", "VMFIN", "PDS", "VVINF", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.7": {"text": "Ach, Freund, (erwiedert ihm der Stier)", "tokens": ["Ach", ",", "Freund", ",", "(", "er\u00b7wie\u00b7dert", "ihm", "der", "Stier", ")"], "token_info": ["word", "punct", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "NN", "$,", "$(", "VVFIN", "PPER", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Ich zitt're schon, der Feind ist hier!", "tokens": ["Ich", "zitt'\u00b7re", "schon", ",", "der", "Feind", "ist", "hier", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "ART", "NN", "VAFIN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "La\u00df uns sogleich von hinnen fliehn,", "tokens": ["La\u00df", "uns", "sog\u00b7leich", "von", "hin\u00b7nen", "fliehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ADV", "APPR", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Bis da\u00df die Pl\u00fcnd'rer weiter ziehn;", "tokens": ["Bis", "da\u00df", "die", "Pl\u00fcn\u00b7d'\u00b7rer", "wei\u00b7ter", "ziehn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "KOUS", "ART", "NN", "ADV", "VVINF", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.11": {"text": "Bek\u00e4men sie uns hier zu fassen,", "tokens": ["Be\u00b7k\u00e4\u00b7men", "sie", "uns", "hier", "zu", "fas\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Wir m\u00fc\u00dften Beide Haare lassen.", "tokens": ["Wir", "m\u00fc\u00df\u00b7ten", "Bei\u00b7de", "Haa\u00b7re", "las\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Der Esel sprach hierauf: Ei nun!", "tokens": ["Der", "E\u00b7sel", "sprach", "hier\u00b7auf", ":", "Ei", "nun", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PAV", "$.", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Willst du entfliehn, das kannst du thun.", "tokens": ["Willst", "du", "ent\u00b7fliehn", ",", "das", "kannst", "du", "thun", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "VVINF", "$,", "PDS", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Dir grauet, da\u00df du wirst erstochen,", "tokens": ["Dir", "grau\u00b7et", ",", "da\u00df", "du", "wirst", "er\u00b7sto\u00b7chen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "PPER", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "Und sie dich schlachten, schinden, kochen,", "tokens": ["Und", "sie", "dich", "schlach\u00b7ten", ",", "schin\u00b7den", ",", "ko\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["KON", "PPER", "PPER", "VVFIN", "$,", "VVFIN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.17": {"text": "Vor diesem Allen bin ich frei.", "tokens": ["Vor", "die\u00b7sem", "Al\u00b7len", "bin", "ich", "frei", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "VAFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.18": {"text": "Mein Schicksal bleibt stets einerlei,", "tokens": ["Mein", "Schick\u00b7sal", "bleibt", "stets", "ei\u00b7ner\u00b7lei", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ADV", "PIS", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "Und ich mu\u00df unter gleichen Plagen", "tokens": ["Und", "ich", "mu\u00df", "un\u00b7ter", "glei\u00b7chen", "Pla\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VMFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.20": {"text": "Die S\u00e4cke doch zur M\u00fchle tragen.", "tokens": ["Die", "S\u00e4\u00b7cke", "doch", "zur", "M\u00fch\u00b7le", "tra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.21": {"text": "Kalt siebt sehr oft der Unterthan", "tokens": ["Kalt", "siebt", "sehr", "oft", "der", "Un\u00b7ter\u00b7than"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "ADV", "ADV", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.22": {"text": "Den Feind sich seinen Grenzen nahn.", "tokens": ["Den", "Feind", "sich", "sei\u00b7nen", "Gren\u00b7zen", "nahn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PRF", "PPOSAT", "NN", "ADJA", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.23": {"text": "Er wei\u00df, ihm bleibet Sklaverei,", "tokens": ["Er", "wei\u00df", ",", "ihm", "blei\u00b7bet", "Skla\u00b7ve\u00b7rei", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VVFIN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.24": {"text": "Sein Sieger sey auch wer er sey.", "tokens": ["Sein", "Sie\u00b7ger", "sey", "auch", "wer", "er", "sey", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADV", "PWS", "PPER", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Der Esel ging einst auf der Weide", "tokens": ["Der", "E\u00b7sel", "ging", "einst", "auf", "der", "Wei\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Mit einem Stier; da h\u00f6rten beide", "tokens": ["Mit", "ei\u00b7nem", "Stier", ";", "da", "h\u00f6r\u00b7ten", "bei\u00b7de"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "$.", "ADV", "VVFIN", "PIS"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Viel L\u00e4rm, als wie von einem Heer,", "tokens": ["Viel", "L\u00e4rm", ",", "als", "wie", "von", "ei\u00b7nem", "Heer", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "$,", "KOUS", "KOKOM", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und in den D\u00f6rfern rund umher", "tokens": ["Und", "in", "den", "D\u00f6r\u00b7fern", "rund", "um\u00b7her"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "ADJD", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Zu Sturm mit allen Glocken l\u00e4uten.", "tokens": ["Zu", "Sturm", "mit", "al\u00b7len", "Glo\u00b7cken", "l\u00e4u\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Was (sprach Herr Heinz) mag das bedeuten?", "tokens": ["Was", "(", "sprach", "Herr", "Heinz", ")", "mag", "das", "be\u00b7deu\u00b7ten", "?"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "$(", "VVFIN", "NN", "NE", "$(", "VMFIN", "PDS", "VVINF", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.7": {"text": "Ach, Freund, (erwiedert ihm der Stier)", "tokens": ["Ach", ",", "Freund", ",", "(", "er\u00b7wie\u00b7dert", "ihm", "der", "Stier", ")"], "token_info": ["word", "punct", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "NN", "$,", "$(", "VVFIN", "PPER", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Ich zitt're schon, der Feind ist hier!", "tokens": ["Ich", "zitt'\u00b7re", "schon", ",", "der", "Feind", "ist", "hier", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "ART", "NN", "VAFIN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "La\u00df uns sogleich von hinnen fliehn,", "tokens": ["La\u00df", "uns", "sog\u00b7leich", "von", "hin\u00b7nen", "fliehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ADV", "APPR", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Bis da\u00df die Pl\u00fcnd'rer weiter ziehn;", "tokens": ["Bis", "da\u00df", "die", "Pl\u00fcn\u00b7d'\u00b7rer", "wei\u00b7ter", "ziehn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "KOUS", "ART", "NN", "ADV", "VVINF", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.11": {"text": "Bek\u00e4men sie uns hier zu fassen,", "tokens": ["Be\u00b7k\u00e4\u00b7men", "sie", "uns", "hier", "zu", "fas\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Wir m\u00fc\u00dften Beide Haare lassen.", "tokens": ["Wir", "m\u00fc\u00df\u00b7ten", "Bei\u00b7de", "Haa\u00b7re", "las\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Der Esel sprach hierauf: Ei nun!", "tokens": ["Der", "E\u00b7sel", "sprach", "hier\u00b7auf", ":", "Ei", "nun", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PAV", "$.", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Willst du entfliehn, das kannst du thun.", "tokens": ["Willst", "du", "ent\u00b7fliehn", ",", "das", "kannst", "du", "thun", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "VVINF", "$,", "PDS", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Dir grauet, da\u00df du wirst erstochen,", "tokens": ["Dir", "grau\u00b7et", ",", "da\u00df", "du", "wirst", "er\u00b7sto\u00b7chen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "PPER", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "Und sie dich schlachten, schinden, kochen,", "tokens": ["Und", "sie", "dich", "schlach\u00b7ten", ",", "schin\u00b7den", ",", "ko\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["KON", "PPER", "PPER", "VVFIN", "$,", "VVFIN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.17": {"text": "Vor diesem Allen bin ich frei.", "tokens": ["Vor", "die\u00b7sem", "Al\u00b7len", "bin", "ich", "frei", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "VAFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.18": {"text": "Mein Schicksal bleibt stets einerlei,", "tokens": ["Mein", "Schick\u00b7sal", "bleibt", "stets", "ei\u00b7ner\u00b7lei", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ADV", "PIS", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "Und ich mu\u00df unter gleichen Plagen", "tokens": ["Und", "ich", "mu\u00df", "un\u00b7ter", "glei\u00b7chen", "Pla\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VMFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.20": {"text": "Die S\u00e4cke doch zur M\u00fchle tragen.", "tokens": ["Die", "S\u00e4\u00b7cke", "doch", "zur", "M\u00fch\u00b7le", "tra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.21": {"text": "Kalt siebt sehr oft der Unterthan", "tokens": ["Kalt", "siebt", "sehr", "oft", "der", "Un\u00b7ter\u00b7than"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "ADV", "ADV", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.22": {"text": "Den Feind sich seinen Grenzen nahn.", "tokens": ["Den", "Feind", "sich", "sei\u00b7nen", "Gren\u00b7zen", "nahn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PRF", "PPOSAT", "NN", "ADJA", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.23": {"text": "Er wei\u00df, ihm bleibet Sklaverei,", "tokens": ["Er", "wei\u00df", ",", "ihm", "blei\u00b7bet", "Skla\u00b7ve\u00b7rei", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VVFIN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.24": {"text": "Sein Sieger sey auch wer er sey.", "tokens": ["Sein", "Sie\u00b7ger", "sey", "auch", "wer", "er", "sey", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADV", "PWS", "PPER", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}