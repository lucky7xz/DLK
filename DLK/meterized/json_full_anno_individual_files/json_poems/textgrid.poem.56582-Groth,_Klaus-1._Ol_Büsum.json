{"textgrid.poem.56582": {"metadata": {"author": {"name": "Groth, Klaus", "birth": "N.A.", "death": "N.A."}, "title": "1. Ol B\u00fcsum", "genre": "verse", "period": "N.A.", "pub_year": 1859, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ol B\u00fcsen liggt int wille Haff,", "tokens": ["Ol", "B\u00fc\u00b7sen", "liggt", "int", "wil\u00b7le", "Haff", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "VVFIN", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "De Floth de keem un w\u00f6hl en Graff.", "tokens": ["De", "Floth", "de", "keem", "un", "w\u00f6hl", "en", "Graff", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "De Floth de keem un sp\u00f6l un sp\u00f6l,", "tokens": ["De", "Floth", "de", "keem", "un", "sp\u00f6l", "un", "sp\u00f6l", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.fr", "FM.fr", "FM.fr", "FM.fr", "FM.fr", "FM.fr", "FM.fr", "FM.fr", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Bet se de Insel \u00fcnner w\u00f6hl.", "tokens": ["Bet", "se", "de", "In\u00b7sel", "\u00fcn\u00b7ner", "w\u00f6hl", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.3": {"line.1": {"text": "Dar blev keen Steen, dar blev keen Pahl,", "tokens": ["Dar", "blev", "ke\u00b7en", "Steen", ",", "dar", "blev", "ke\u00b7en", "Pahl", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ADJD", "VVFIN", "NN", "$,", "PTKVZ", "VVFIN", "PIAT", "NN", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Dat Water sch\u0153l dat all hendal.", "tokens": ["Dat", "Wa\u00b7ter", "sch\u0153l", "dat", "all", "hen\u00b7dal", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "PIAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Dar weer keen Beest, dar weer keen Hund,", "tokens": ["Dar", "weer", "ke\u00b7en", "Beest", ",", "dar", "weer", "ke\u00b7en", "Hund", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ADJD", "VVFIN", "NE", "$,", "PAV", "ADJD", "VVFIN", "NN", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "De liggt nu all in depen Grund.", "tokens": ["De", "liggt", "nu", "all", "in", "de\u00b7pen", "Grund", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADV", "PIAT", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Un Allens, wat der l\u0119v un lach,", "tokens": ["Un", "Al\u00b7lens", ",", "wat", "der", "l\u0119v", "un", "lach", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "PRELS", "ART", "FM", "FM", "VVFIN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Dat deck de See mit depe Nach.", "tokens": ["Dat", "deck", "de", "See", "mit", "de\u00b7pe", "Nach", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Mit\u00fcnner in de holle Ebb", "tokens": ["Mi\u00b7t\u00fcn\u00b7ner", "in", "de", "hol\u00b7le", "Ebb"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "NE", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So s\u00fcht man vunne H\u00fcs' de K\u00f6pp.", "tokens": ["So", "s\u00fcht", "man", "vun\u00b7ne", "H\u00fcs'", "de", "K\u00f6pp", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "VVFIN", "NE", "NE", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Denn dukt de Thorn herut ut Sand,", "tokens": ["Denn", "dukt", "de", "Thorn", "he\u00b7rut", "ut", "Sand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "FM", "FM", "FM", "FM", "FM", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "As weert en Finger vun en Hand.", "tokens": ["As", "weert", "en", "Fin\u00b7ger", "vun", "en", "Hand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "FM", "FM", "FM", "FM", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Denn h\u00f6rt man sach de Klocken klingn,", "tokens": ["Denn", "h\u00f6rt", "man", "sach", "de", "Klo\u00b7cken", "klingn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIS", "VVFIN", "NE", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Denn h\u00f6rt man sach de Kanter singn,", "tokens": ["Denn", "h\u00f6rt", "man", "sach", "de", "Kan\u00b7ter", "singn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIS", "FM.fr", "FM.fr", "FM.fr", "FM.fr", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Denn geit dat lisen d\u0153r de Luft:", "tokens": ["Denn", "geit", "dat", "li\u00b7sen", "d\u0153r", "de", "Luft", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ART", "NN", "NE", "NE", "NN", "$."], "meter": "-----+-+", "measure": "unknown.measure.di"}, "line.2": {"text": "\u00bbbegrabt den Leib in seine Gruft.\u00ab", "tokens": ["\u00bb", "be\u00b7grabt", "den", "Leib", "in", "sei\u00b7ne", "Gruft", ".", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VVFIN", "ART", "NN", "APPR", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Ol B\u00fcsen liggt int wille Haff,", "tokens": ["Ol", "B\u00fc\u00b7sen", "liggt", "int", "wil\u00b7le", "Haff", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "VVFIN", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "De Floth de keem un w\u00f6hl en Graff.", "tokens": ["De", "Floth", "de", "keem", "un", "w\u00f6hl", "en", "Graff", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "De Floth de keem un sp\u00f6l un sp\u00f6l,", "tokens": ["De", "Floth", "de", "keem", "un", "sp\u00f6l", "un", "sp\u00f6l", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.fr", "FM.fr", "FM.fr", "FM.fr", "FM.fr", "FM.fr", "FM.fr", "FM.fr", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Bet se de Insel \u00fcnner w\u00f6hl.", "tokens": ["Bet", "se", "de", "In\u00b7sel", "\u00fcn\u00b7ner", "w\u00f6hl", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.12": {"line.1": {"text": "Dar blev keen Steen, dar blev keen Pahl,", "tokens": ["Dar", "blev", "ke\u00b7en", "Steen", ",", "dar", "blev", "ke\u00b7en", "Pahl", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ADJD", "VVFIN", "NN", "$,", "PTKVZ", "VVFIN", "PIAT", "NN", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Dat Water sch\u0153l dat all hendal.", "tokens": ["Dat", "Wa\u00b7ter", "sch\u0153l", "dat", "all", "hen\u00b7dal", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "PIAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Dar weer keen Beest, dar weer keen Hund,", "tokens": ["Dar", "weer", "ke\u00b7en", "Beest", ",", "dar", "weer", "ke\u00b7en", "Hund", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ADJD", "VVFIN", "NE", "$,", "PAV", "ADJD", "VVFIN", "NN", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "De liggt nu all in depen Grund.", "tokens": ["De", "liggt", "nu", "all", "in", "de\u00b7pen", "Grund", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADV", "PIAT", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Un Allens, wat der l\u0119v un lach,", "tokens": ["Un", "Al\u00b7lens", ",", "wat", "der", "l\u0119v", "un", "lach", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "PRELS", "ART", "FM", "FM", "VVFIN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Dat deck de See mit depe Nach.", "tokens": ["Dat", "deck", "de", "See", "mit", "de\u00b7pe", "Nach", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "Mit\u00fcnner in de holle Ebb", "tokens": ["Mi\u00b7t\u00fcn\u00b7ner", "in", "de", "hol\u00b7le", "Ebb"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "NE", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So s\u00fcht man vunne H\u00fcs' de K\u00f6pp.", "tokens": ["So", "s\u00fcht", "man", "vun\u00b7ne", "H\u00fcs'", "de", "K\u00f6pp", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "VVFIN", "NE", "NE", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "Denn dukt de Thorn herut ut Sand,", "tokens": ["Denn", "dukt", "de", "Thorn", "he\u00b7rut", "ut", "Sand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "FM", "FM", "FM", "FM", "FM", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "As weert en Finger vun en Hand.", "tokens": ["As", "weert", "en", "Fin\u00b7ger", "vun", "en", "Hand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "FM", "FM", "FM", "FM", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.17": {"line.1": {"text": "Denn h\u00f6rt man sach de Klocken klingn,", "tokens": ["Denn", "h\u00f6rt", "man", "sach", "de", "Klo\u00b7cken", "klingn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIS", "VVFIN", "NE", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Denn h\u00f6rt man sach de Kanter singn,", "tokens": ["Denn", "h\u00f6rt", "man", "sach", "de", "Kan\u00b7ter", "singn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIS", "FM.fr", "FM.fr", "FM.fr", "FM.fr", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.18": {"line.1": {"text": "Denn geit dat lisen d\u0153r de Luft:", "tokens": ["Denn", "geit", "dat", "li\u00b7sen", "d\u0153r", "de", "Luft", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ART", "NN", "NE", "NE", "NN", "$."], "meter": "-----+-+", "measure": "unknown.measure.di"}, "line.2": {"text": "\u00bbbegrabt den Leib in seine Gruft.\u00ab", "tokens": ["\u00bb", "be\u00b7grabt", "den", "Leib", "in", "sei\u00b7ne", "Gruft", ".", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VVFIN", "ART", "NN", "APPR", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}