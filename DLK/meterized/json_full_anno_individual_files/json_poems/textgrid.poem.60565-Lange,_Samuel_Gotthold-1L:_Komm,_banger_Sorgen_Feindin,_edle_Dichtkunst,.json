{"textgrid.poem.60565": {"metadata": {"author": {"name": "Lange, Samuel Gotthold", "birth": "N.A.", "death": "N.A."}, "title": "1L: Komm, banger Sorgen Feindin, edle Dichtkunst,", "genre": "verse", "period": "N.A.", "pub_year": 1746, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Komm, banger Sorgen Feindin, edle Dichtkunst,", "tokens": ["Komm", ",", "ban\u00b7ger", "Sor\u00b7gen", "Fein\u00b7din", ",", "ed\u00b7le", "Dicht\u00b7kunst", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "$,", "ADJA", "NN", "NN", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Komm, du, den meisten unbekannte Tugend,", "tokens": ["Komm", ",", "du", ",", "den", "meis\u00b7ten", "un\u00b7be\u00b7kann\u00b7te", "Tu\u00b7gend", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PPER", "$,", "ART", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Komm, du, von wenigen erfahrne Freundschaft,", "tokens": ["Komm", ",", "du", ",", "von", "we\u00b7ni\u00b7gen", "er\u00b7fahr\u00b7ne", "Freund\u00b7schaft", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PPER", "$,", "APPR", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "F\u00fchr auch itzt den Kiel.", "tokens": ["F\u00fchr", "auch", "itzt", "den", "Kiel", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ADV", "ART", "NE", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.2": {"line.1": {"text": "Die kluge Nachwelt lobt einst meine Einsicht,", "tokens": ["Die", "klu\u00b7ge", "Nach\u00b7welt", "lobt", "einst", "mei\u00b7ne", "Ein\u00b7sicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ADV", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Wenn sie, mein Thirsis, meine Liebe lieset,", "tokens": ["Wenn", "sie", ",", "mein", "Thir\u00b7sis", ",", "mei\u00b7ne", "Lie\u00b7be", "lie\u00b7set", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "PPOSAT", "NN", "$,", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Mit der ich gegen meine Doris brenne,", "tokens": ["Mit", "der", "ich", "ge\u00b7gen", "mei\u00b7ne", "Do\u00b7ris", "bren\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "APPR", "PPOSAT", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und dir eigen bin.", "tokens": ["Und", "dir", "ei\u00b7gen", "bin", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ADJD", "VAFIN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.3": {"line.1": {"text": "Das Schicksal ist dem heissen Wunsch gehorsam,", "tokens": ["Das", "Schick\u00b7sal", "ist", "dem", "heis\u00b7sen", "Wunsch", "ge\u00b7hor\u00b7sam", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ART", "ADJA", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Uns trennen nicht so vieler Stunden Schritte,", "tokens": ["Uns", "tren\u00b7nen", "nicht", "so", "vie\u00b7ler", "Stun\u00b7den", "Schrit\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "ADV", "PIAT", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Als Jahre wir uns treu und z\u00e4rtlich liebten,", "tokens": ["Als", "Jah\u00b7re", "wir", "uns", "treu", "und", "z\u00e4rt\u00b7lich", "lieb\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "PPER", "PRF", "ADJD", "KON", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Uns trent kaum der Tod.", "tokens": ["Uns", "trent", "kaum", "der", "Tod", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}}, "stanza.4": {"line.1": {"text": "Ein Weiser sorgt nicht f\u00fcr sein k\u00fcnftig Gl\u00fccke,", "tokens": ["Ein", "Wei\u00b7ser", "sorgt", "nicht", "f\u00fcr", "sein", "k\u00fcnf\u00b7tig", "Gl\u00fc\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKNEG", "APPR", "PPOSAT", "ADJD", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die Treue gegen Eltern wird belohnet;", "tokens": ["Die", "Treu\u00b7e", "ge\u00b7gen", "El\u00b7tern", "wird", "be\u00b7loh\u00b7net", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "VAFIN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Aeneens Schultern, die den Vater trugen,", "tokens": ["A\u00b7e\u00b7neens", "Schul\u00b7tern", ",", "die", "den", "Va\u00b7ter", "tru\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "PRELS", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Deckte der Purpur.", "tokens": ["Deck\u00b7te", "der", "Pur\u00b7pur", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$."], "meter": "+-+++", "measure": "unknown.measure.tetra"}}, "stanza.5": {"line.1": {"text": "Der durch sein Vaterhertze gegen Br\u00fcder", "tokens": ["Der", "durch", "sein", "Va\u00b7ter\u00b7hert\u00b7ze", "ge\u00b7gen", "Br\u00fc\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "PPOSAT", "NN", "APPR", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Bekannte Procul lebt durch alle Zeiten;", "tokens": ["Be\u00b7kann\u00b7te", "Pro\u00b7cul", "lebt", "durch", "al\u00b7le", "Zei\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "VVFIN", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Ihn tr\u00e4gt auf Fl\u00fcgeln, die Verwesung meiden,", "tokens": ["Ihn", "tr\u00e4gt", "auf", "Fl\u00fc\u00b7geln", ",", "die", "Ver\u00b7we\u00b7sung", "mei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "$,", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Der bleibende Ruf.", "tokens": ["Der", "blei\u00b7ben\u00b7de", "Ruf", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}}, "stanza.6": {"line.1": {"text": "Die Ewigkeit, befreyt vom Unvollkommnen,", "tokens": ["Die", "E\u00b7wig\u00b7keit", ",", "be\u00b7freyt", "vom", "Un\u00b7voll\u00b7komm\u00b7nen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "VVPP", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Erwartet uns, wenn wir der Welt gedienet,", "tokens": ["Er\u00b7war\u00b7tet", "uns", ",", "wenn", "wir", "der", "Welt", "ge\u00b7die\u00b7net", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "KOUS", "PPER", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Wenn dich die Tugenden schon hier gekr\u00f6net,", "tokens": ["Wenn", "dich", "die", "Tu\u00b7gen\u00b7den", "schon", "hier", "ge\u00b7kr\u00f6\u00b7net", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "ADV", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Mit demselben Arm.", "tokens": ["Mit", "dem\u00b7sel\u00b7ben", "Arm", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.7": {"line.1": {"text": "Wir sehn den Bacchus nicht auf fernen Klippen", "tokens": ["Wir", "sehn", "den", "Bac\u00b7chus", "nicht", "auf", "fer\u00b7nen", "Klip\u00b7pen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NE", "PTKNEG", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die Nymphen lehren; Nicht die spitzen Ohren", "tokens": ["Die", "Nym\u00b7phen", "leh\u00b7ren", ";", "Nicht", "die", "spit\u00b7zen", "Oh\u00b7ren"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVINF", "$.", "PTKNEG", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Des ziegenf\u00fc\u00dfigen Satyrs; Wir kennen", "tokens": ["Des", "zie\u00b7gen\u00b7f\u00fc\u00b7\u00dfi\u00b7gen", "Sa\u00b7tyrs", ";", "Wir", "ken\u00b7nen"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["ART", "ADJA", "NN", "$.", "PPER", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Nicht den bessern Wein.", "tokens": ["Nicht", "den", "bes\u00b7sern", "Wein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ART", "ADJA", "NN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.8": {"line.1": {"text": "Doch sehn wir oft, wenn ein beliebtes Rasen", "tokens": ["Doch", "sehn", "wir", "oft", ",", "wenn", "ein", "be\u00b7lieb\u00b7tes", "Ra\u00b7sen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "ADV", "$,", "KOUS", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Uns teuscht, wir h\u00f6ren in dem heilgen Haine,", "tokens": ["Uns", "teu\u00b7scht", ",", "wir", "h\u00f6\u00b7ren", "in", "dem", "heil\u00b7gen", "Hai\u00b7ne", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "$,", "PPER", "VVFIN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Die Gottheit, wenn sie in dem k\u00fchlen wandelt,", "tokens": ["Die", "Got\u00b7theit", ",", "wenn", "sie", "in", "dem", "k\u00fch\u00b7len", "wan\u00b7delt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "KOUS", "PPER", "APPR", "ART", "ADJA", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "An sanften B\u00e4chen.", "tokens": ["An", "sanf\u00b7ten", "B\u00e4\u00b7chen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.9": {"line.1": {"text": "In deinem nicht wie Glas durchsichtgen Hertzen", "tokens": ["In", "dei\u00b7nem", "nicht", "wie", "Glas", "durch\u00b7sicht\u00b7gen", "Hert\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "PTKNEG", "KOKOM", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Entsch\u00fctt ich mich auch der geheimsten Sorgen.", "tokens": ["Ent\u00b7sch\u00fctt", "ich", "mich", "auch", "der", "ge\u00b7heims\u00b7ten", "Sor\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Ich halte dir dein menschliches zu gute,", "tokens": ["Ich", "hal\u00b7te", "dir", "dein", "menschli\u00b7ches", "zu", "gu\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PPOSAT", "ADJA", "APPR", "ADJA", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Wie du meines deckst.", "tokens": ["Wie", "du", "mei\u00b7nes", "deckst", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PPOSAT", "VVFIN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.10": {"line.1": {"text": "Wenn mir Horatz erscheint, schreib ich erhitzet.", "tokens": ["Wenn", "mir", "Ho\u00b7ratz", "er\u00b7scheint", ",", "schreib", "ich", "er\u00b7hit\u00b7zet", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NN", "VVFIN", "$,", "VVFIN", "PPER", "VVFIN", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.2": {"text": "Mit frecher Wuth, und mehr verwegnen Sohlen", "tokens": ["Mit", "fre\u00b7cher", "Wuth", ",", "und", "mehr", "ver\u00b7weg\u00b7nen", "Soh\u00b7len"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "$,", "KON", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Dr\u00fcck ich die Spur, bin k\u00fchn dir nachzueilen,", "tokens": ["Dr\u00fcck", "ich", "die", "Spur", ",", "bin", "k\u00fchn", "dir", "nach\u00b7zu\u00b7ei\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ART", "NN", "$,", "VAFIN", "ADJD", "PPER", "VVIZU", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Ja dich zu reitzen.", "tokens": ["Ja", "dich", "zu", "reit\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKANT", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.11": {"line.1": {"text": "Mit mindrer Wuth, doch sichrer deiner St\u00e4rcke,", "tokens": ["Mit", "mind\u00b7rer", "Wuth", ",", "doch", "sich\u00b7rer", "dei\u00b7ner", "St\u00e4r\u00b7cke", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "KON", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Verachtend g\u00fctig tr\u00e4gest du mich Schwachen,", "tokens": ["Ver\u00b7ach\u00b7tend", "g\u00fc\u00b7tig", "tr\u00e4\u00b7gest", "du", "mich", "Schwa\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "ADJD", "VVFIN", "PPER", "PRF", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Senckst dich mit Gro\u00dfmuth bis zu mir hernieder,", "tokens": ["Senckst", "dich", "mit", "Gro\u00df\u00b7muth", "bis", "zu", "mir", "her\u00b7nie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "APPR", "NN", "APPR", "APPR", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und schreibest mir gleich.", "tokens": ["Und", "schrei\u00b7best", "mir", "gleich", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}}, "stanza.12": {"line.1": {"text": "Erstaunt, so wenig Widerstand zu finden,", "tokens": ["Er\u00b7staunt", ",", "so", "we\u00b7nig", "Wi\u00b7der\u00b7stand", "zu", "fin\u00b7den", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "ADV", "PIAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und durch die Schmach besch\u00e4mt, noch mehr erhitzet,", "tokens": ["Und", "durch", "die", "Schmach", "be\u00b7sch\u00e4mt", ",", "noch", "mehr", "er\u00b7hit\u00b7zet", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVPP", "$,", "ADV", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Beweg ich dich, mit w\u00fcrdigern Gedichten", "tokens": ["Be\u00b7weg", "ich", "dich", ",", "mit", "w\u00fcr\u00b7di\u00b7gern", "Ge\u00b7dich\u00b7ten"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "PPER", "PRF", "$,", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Mich zu belehren.", "tokens": ["Mich", "zu", "be\u00b7leh\u00b7ren", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "PTKZU", "VVINF", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.13": {"line.1": {"text": "Ein junger Leu reitzt so, wenn er die Klauen", "tokens": ["Ein", "jun\u00b7ger", "Leu", "reitzt", "so", ",", "wenn", "er", "die", "Klau\u00b7en"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ADV", "$,", "KOUS", "PPER", "ART", "NN"], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Und Z\u00e4hne f\u00fchlt, den st\u00e4rckern Spielgesellen,", "tokens": ["Und", "Z\u00e4h\u00b7ne", "f\u00fchlt", ",", "den", "st\u00e4r\u00b7ckern", "Spiel\u00b7ge\u00b7sel\u00b7len", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Lacht dessen Gro\u00dfmuth, fordert ernstes K\u00e4mpfen,", "tokens": ["Lacht", "des\u00b7sen", "Gro\u00df\u00b7muth", ",", "for\u00b7dert", "erns\u00b7tes", "K\u00e4mp\u00b7fen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PDS", "NN", "$,", "VVFIN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und erlieget gern.", "tokens": ["Und", "er\u00b7lie\u00b7get", "gern", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.14": {"line.1": {"text": "O du, nach Gott und Doris, h\u00f6chst Geliebter,", "tokens": ["O", "du", ",", "nach", "Gott", "und", "Do\u00b7ris", ",", "h\u00f6chst", "Ge\u00b7lieb\u00b7ter", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "APPR", "NN", "KON", "NE", "$,", "ADV", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "So lang ich bin, kan dich kein Ungl\u00fcck treffen;", "tokens": ["So", "lang", "ich", "bin", ",", "kan", "dich", "kein", "Un\u00b7gl\u00fcck", "tref\u00b7fen", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "VAFIN", "$,", "VMFIN", "PPER", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Ich w\u00fcrde mit dir eh das letzte theilen,", "tokens": ["Ich", "w\u00fcr\u00b7de", "mit", "dir", "eh", "das", "letz\u00b7te", "thei\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "PPER", "KOUS", "ART", "ADJA", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Als dich verlassen.", "tokens": ["Als", "dich", "ver\u00b7las\u00b7sen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVINF", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.15": {"line.1": {"text": "Die Tugend kan den wahren Ruhm wohl dulden:", "tokens": ["Die", "Tu\u00b7gend", "kan", "den", "wah\u00b7ren", "Ruhm", "wohl", "dul\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "ART", "ADJA", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ich lobe deine Kunst, noch mehr dein Hertze.", "tokens": ["Ich", "lo\u00b7be", "dei\u00b7ne", "Kunst", ",", "noch", "mehr", "dein", "Hert\u00b7ze", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "$,", "ADV", "ADV", "PPOSAT", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "R\u00fchm, was allein mich deiner w\u00fcrdig machet,", "tokens": ["R\u00fchm", ",", "was", "al\u00b7lein", "mich", "dei\u00b7ner", "w\u00fcr\u00b7dig", "ma\u00b7chet", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PRELS", "ADV", "PPER", "PPOSAT", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Da\u00df ich dich sch\u00e4tze.", "tokens": ["Da\u00df", "ich", "dich", "sch\u00e4t\u00b7ze", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "VVFIN", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.16": {"line.1": {"text": "Die sp\u00e4te Welt belehr ich durch die Dichtkunst,", "tokens": ["Die", "sp\u00e4\u00b7te", "Welt", "be\u00b7lehr", "ich", "durch", "die", "Dicht\u00b7kunst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die auch gekr\u00f6nte Laster nie wird preisen,", "tokens": ["Die", "auch", "ge\u00b7kr\u00f6n\u00b7te", "Las\u00b7ter", "nie", "wird", "prei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJA", "NN", "ADV", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Wie meiner Doris Treu, und deine Freundschaft", "tokens": ["Wie", "mei\u00b7ner", "Do\u00b7ris", "Treu", ",", "und", "dei\u00b7ne", "Freund\u00b7schaft"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWAV", "PPOSAT", "NE", "NN", "$,", "KON", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Mein Leben begl\u00fcckt.", "tokens": ["Mein", "Le\u00b7ben", "be\u00b7gl\u00fcckt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVPP", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}}, "stanza.17": {"line.1": {"text": "Itzt leg ich mich in ihre zarten Arme,", "tokens": ["Itzt", "leg", "ich", "mich", "in", "ih\u00b7re", "zar\u00b7ten", "Ar\u00b7me", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die sie dir zum Willkommen oft gereichet.", "tokens": ["Die", "sie", "dir", "zum", "Will\u00b7kom\u00b7men", "oft", "ge\u00b7rei\u00b7chet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PPER", "APPRART", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "La\u00df, wenn du lebest, keinen von uns beyden", "tokens": ["La\u00df", ",", "wenn", "du", "le\u00b7best", ",", "kei\u00b7nen", "von", "uns", "bey\u00b7den"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVIMP", "$,", "KOUS", "PPER", "VVFIN", "$,", "PIAT", "APPR", "PPER", "PIAT"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Ohne Klage-Lied.", "tokens": ["Oh\u00b7ne", "Kla\u00b7ge\u00b7Lied", "."], "token_info": ["word", "word", "punct"], "pos": ["APPR", "NN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.18": {"line.1": {"text": "Mit h\u00e4uffigen und schuldgen Thr\u00e4nen netze", "tokens": ["Mit", "h\u00e4uf\u00b7fi\u00b7gen", "und", "schuld\u00b7gen", "Thr\u00e4\u00b7nen", "net\u00b7ze"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "KON", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Bey blassem Angesicht die werthen Leichen,", "tokens": ["Bey", "blas\u00b7sem", "An\u00b7ge\u00b7sicht", "die", "wert\u00b7hen", "Lei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und schreibe kein Gedicht ohn diese Namen:", "tokens": ["Und", "schrei\u00b7be", "kein", "Ge\u00b7dicht", "ohn", "die\u00b7se", "Na\u00b7men", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIAT", "NN", "APPR", "PDAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Damon und Doris.", "tokens": ["Da\u00b7mon", "und", "Do\u00b7ris", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "KON", "NE", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.19": {"line.1": {"text": "Komm, banger Sorgen Feindin, edle Dichtkunst,", "tokens": ["Komm", ",", "ban\u00b7ger", "Sor\u00b7gen", "Fein\u00b7din", ",", "ed\u00b7le", "Dicht\u00b7kunst", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "$,", "ADJA", "NN", "NN", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Komm, du, den meisten unbekannte Tugend,", "tokens": ["Komm", ",", "du", ",", "den", "meis\u00b7ten", "un\u00b7be\u00b7kann\u00b7te", "Tu\u00b7gend", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PPER", "$,", "ART", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Komm, du, von wenigen erfahrne Freundschaft,", "tokens": ["Komm", ",", "du", ",", "von", "we\u00b7ni\u00b7gen", "er\u00b7fahr\u00b7ne", "Freund\u00b7schaft", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PPER", "$,", "APPR", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "F\u00fchr auch itzt den Kiel.", "tokens": ["F\u00fchr", "auch", "itzt", "den", "Kiel", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ADV", "ART", "NE", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.20": {"line.1": {"text": "Die kluge Nachwelt lobt einst meine Einsicht,", "tokens": ["Die", "klu\u00b7ge", "Nach\u00b7welt", "lobt", "einst", "mei\u00b7ne", "Ein\u00b7sicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ADV", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Wenn sie, mein Thirsis, meine Liebe lieset,", "tokens": ["Wenn", "sie", ",", "mein", "Thir\u00b7sis", ",", "mei\u00b7ne", "Lie\u00b7be", "lie\u00b7set", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "PPOSAT", "NN", "$,", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Mit der ich gegen meine Doris brenne,", "tokens": ["Mit", "der", "ich", "ge\u00b7gen", "mei\u00b7ne", "Do\u00b7ris", "bren\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "APPR", "PPOSAT", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und dir eigen bin.", "tokens": ["Und", "dir", "ei\u00b7gen", "bin", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ADJD", "VAFIN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.21": {"line.1": {"text": "Das Schicksal ist dem heissen Wunsch gehorsam,", "tokens": ["Das", "Schick\u00b7sal", "ist", "dem", "heis\u00b7sen", "Wunsch", "ge\u00b7hor\u00b7sam", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ART", "ADJA", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Uns trennen nicht so vieler Stunden Schritte,", "tokens": ["Uns", "tren\u00b7nen", "nicht", "so", "vie\u00b7ler", "Stun\u00b7den", "Schrit\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "ADV", "PIAT", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Als Jahre wir uns treu und z\u00e4rtlich liebten,", "tokens": ["Als", "Jah\u00b7re", "wir", "uns", "treu", "und", "z\u00e4rt\u00b7lich", "lieb\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "PPER", "PRF", "ADJD", "KON", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Uns trent kaum der Tod.", "tokens": ["Uns", "trent", "kaum", "der", "Tod", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}}, "stanza.22": {"line.1": {"text": "Ein Weiser sorgt nicht f\u00fcr sein k\u00fcnftig Gl\u00fccke,", "tokens": ["Ein", "Wei\u00b7ser", "sorgt", "nicht", "f\u00fcr", "sein", "k\u00fcnf\u00b7tig", "Gl\u00fc\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKNEG", "APPR", "PPOSAT", "ADJD", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die Treue gegen Eltern wird belohnet;", "tokens": ["Die", "Treu\u00b7e", "ge\u00b7gen", "El\u00b7tern", "wird", "be\u00b7loh\u00b7net", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "VAFIN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Aeneens Schultern, die den Vater trugen,", "tokens": ["A\u00b7e\u00b7neens", "Schul\u00b7tern", ",", "die", "den", "Va\u00b7ter", "tru\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "PRELS", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Deckte der Purpur.", "tokens": ["Deck\u00b7te", "der", "Pur\u00b7pur", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$."], "meter": "+-+++", "measure": "unknown.measure.tetra"}}, "stanza.23": {"line.1": {"text": "Der durch sein Vaterhertze gegen Br\u00fcder", "tokens": ["Der", "durch", "sein", "Va\u00b7ter\u00b7hert\u00b7ze", "ge\u00b7gen", "Br\u00fc\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "PPOSAT", "NN", "APPR", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Bekannte Procul lebt durch alle Zeiten;", "tokens": ["Be\u00b7kann\u00b7te", "Pro\u00b7cul", "lebt", "durch", "al\u00b7le", "Zei\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "VVFIN", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Ihn tr\u00e4gt auf Fl\u00fcgeln, die Verwesung meiden,", "tokens": ["Ihn", "tr\u00e4gt", "auf", "Fl\u00fc\u00b7geln", ",", "die", "Ver\u00b7we\u00b7sung", "mei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "$,", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Der bleibende Ruf.", "tokens": ["Der", "blei\u00b7ben\u00b7de", "Ruf", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}}, "stanza.24": {"line.1": {"text": "Die Ewigkeit, befreyt vom Unvollkommnen,", "tokens": ["Die", "E\u00b7wig\u00b7keit", ",", "be\u00b7freyt", "vom", "Un\u00b7voll\u00b7komm\u00b7nen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "VVPP", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Erwartet uns, wenn wir der Welt gedienet,", "tokens": ["Er\u00b7war\u00b7tet", "uns", ",", "wenn", "wir", "der", "Welt", "ge\u00b7die\u00b7net", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "KOUS", "PPER", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Wenn dich die Tugenden schon hier gekr\u00f6net,", "tokens": ["Wenn", "dich", "die", "Tu\u00b7gen\u00b7den", "schon", "hier", "ge\u00b7kr\u00f6\u00b7net", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "ADV", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Mit demselben Arm.", "tokens": ["Mit", "dem\u00b7sel\u00b7ben", "Arm", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.25": {"line.1": {"text": "Wir sehn den Bacchus nicht auf fernen Klippen", "tokens": ["Wir", "sehn", "den", "Bac\u00b7chus", "nicht", "auf", "fer\u00b7nen", "Klip\u00b7pen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NE", "PTKNEG", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die Nymphen lehren; Nicht die spitzen Ohren", "tokens": ["Die", "Nym\u00b7phen", "leh\u00b7ren", ";", "Nicht", "die", "spit\u00b7zen", "Oh\u00b7ren"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVINF", "$.", "PTKNEG", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Des ziegenf\u00fc\u00dfigen Satyrs; Wir kennen", "tokens": ["Des", "zie\u00b7gen\u00b7f\u00fc\u00b7\u00dfi\u00b7gen", "Sa\u00b7tyrs", ";", "Wir", "ken\u00b7nen"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["ART", "ADJA", "NN", "$.", "PPER", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Nicht den bessern Wein.", "tokens": ["Nicht", "den", "bes\u00b7sern", "Wein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ART", "ADJA", "NN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.26": {"line.1": {"text": "Doch sehn wir oft, wenn ein beliebtes Rasen", "tokens": ["Doch", "sehn", "wir", "oft", ",", "wenn", "ein", "be\u00b7lieb\u00b7tes", "Ra\u00b7sen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "ADV", "$,", "KOUS", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Uns teuscht, wir h\u00f6ren in dem heilgen Haine,", "tokens": ["Uns", "teu\u00b7scht", ",", "wir", "h\u00f6\u00b7ren", "in", "dem", "heil\u00b7gen", "Hai\u00b7ne", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "$,", "PPER", "VVFIN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Die Gottheit, wenn sie in dem k\u00fchlen wandelt,", "tokens": ["Die", "Got\u00b7theit", ",", "wenn", "sie", "in", "dem", "k\u00fch\u00b7len", "wan\u00b7delt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "KOUS", "PPER", "APPR", "ART", "ADJA", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "An sanften B\u00e4chen.", "tokens": ["An", "sanf\u00b7ten", "B\u00e4\u00b7chen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.27": {"line.1": {"text": "In deinem nicht wie Glas durchsichtgen Hertzen", "tokens": ["In", "dei\u00b7nem", "nicht", "wie", "Glas", "durch\u00b7sicht\u00b7gen", "Hert\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "PTKNEG", "KOKOM", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Entsch\u00fctt ich mich auch der geheimsten Sorgen.", "tokens": ["Ent\u00b7sch\u00fctt", "ich", "mich", "auch", "der", "ge\u00b7heims\u00b7ten", "Sor\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Ich halte dir dein menschliches zu gute,", "tokens": ["Ich", "hal\u00b7te", "dir", "dein", "menschli\u00b7ches", "zu", "gu\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PPOSAT", "ADJA", "APPR", "ADJA", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Wie du meines deckst.", "tokens": ["Wie", "du", "mei\u00b7nes", "deckst", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PPOSAT", "VVFIN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.28": {"line.1": {"text": "Wenn mir Horatz erscheint, schreib ich erhitzet.", "tokens": ["Wenn", "mir", "Ho\u00b7ratz", "er\u00b7scheint", ",", "schreib", "ich", "er\u00b7hit\u00b7zet", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NN", "VVFIN", "$,", "VVFIN", "PPER", "VVFIN", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.2": {"text": "Mit frecher Wuth, und mehr verwegnen Sohlen", "tokens": ["Mit", "fre\u00b7cher", "Wuth", ",", "und", "mehr", "ver\u00b7weg\u00b7nen", "Soh\u00b7len"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "$,", "KON", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Dr\u00fcck ich die Spur, bin k\u00fchn dir nachzueilen,", "tokens": ["Dr\u00fcck", "ich", "die", "Spur", ",", "bin", "k\u00fchn", "dir", "nach\u00b7zu\u00b7ei\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ART", "NN", "$,", "VAFIN", "ADJD", "PPER", "VVIZU", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Ja dich zu reitzen.", "tokens": ["Ja", "dich", "zu", "reit\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKANT", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.29": {"line.1": {"text": "Mit mindrer Wuth, doch sichrer deiner St\u00e4rcke,", "tokens": ["Mit", "mind\u00b7rer", "Wuth", ",", "doch", "sich\u00b7rer", "dei\u00b7ner", "St\u00e4r\u00b7cke", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "KON", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Verachtend g\u00fctig tr\u00e4gest du mich Schwachen,", "tokens": ["Ver\u00b7ach\u00b7tend", "g\u00fc\u00b7tig", "tr\u00e4\u00b7gest", "du", "mich", "Schwa\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "ADJD", "VVFIN", "PPER", "PRF", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Senckst dich mit Gro\u00dfmuth bis zu mir hernieder,", "tokens": ["Senckst", "dich", "mit", "Gro\u00df\u00b7muth", "bis", "zu", "mir", "her\u00b7nie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "APPR", "NN", "APPR", "APPR", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und schreibest mir gleich.", "tokens": ["Und", "schrei\u00b7best", "mir", "gleich", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}}, "stanza.30": {"line.1": {"text": "Erstaunt, so wenig Widerstand zu finden,", "tokens": ["Er\u00b7staunt", ",", "so", "we\u00b7nig", "Wi\u00b7der\u00b7stand", "zu", "fin\u00b7den", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "ADV", "PIAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und durch die Schmach besch\u00e4mt, noch mehr erhitzet,", "tokens": ["Und", "durch", "die", "Schmach", "be\u00b7sch\u00e4mt", ",", "noch", "mehr", "er\u00b7hit\u00b7zet", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVPP", "$,", "ADV", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Beweg ich dich, mit w\u00fcrdigern Gedichten", "tokens": ["Be\u00b7weg", "ich", "dich", ",", "mit", "w\u00fcr\u00b7di\u00b7gern", "Ge\u00b7dich\u00b7ten"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "PPER", "PRF", "$,", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Mich zu belehren.", "tokens": ["Mich", "zu", "be\u00b7leh\u00b7ren", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "PTKZU", "VVINF", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.31": {"line.1": {"text": "Ein junger Leu reitzt so, wenn er die Klauen", "tokens": ["Ein", "jun\u00b7ger", "Leu", "reitzt", "so", ",", "wenn", "er", "die", "Klau\u00b7en"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ADV", "$,", "KOUS", "PPER", "ART", "NN"], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Und Z\u00e4hne f\u00fchlt, den st\u00e4rckern Spielgesellen,", "tokens": ["Und", "Z\u00e4h\u00b7ne", "f\u00fchlt", ",", "den", "st\u00e4r\u00b7ckern", "Spiel\u00b7ge\u00b7sel\u00b7len", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Lacht dessen Gro\u00dfmuth, fordert ernstes K\u00e4mpfen,", "tokens": ["Lacht", "des\u00b7sen", "Gro\u00df\u00b7muth", ",", "for\u00b7dert", "erns\u00b7tes", "K\u00e4mp\u00b7fen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PDS", "NN", "$,", "VVFIN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und erlieget gern.", "tokens": ["Und", "er\u00b7lie\u00b7get", "gern", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.32": {"line.1": {"text": "O du, nach Gott und Doris, h\u00f6chst Geliebter,", "tokens": ["O", "du", ",", "nach", "Gott", "und", "Do\u00b7ris", ",", "h\u00f6chst", "Ge\u00b7lieb\u00b7ter", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "APPR", "NN", "KON", "NE", "$,", "ADV", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "So lang ich bin, kan dich kein Ungl\u00fcck treffen;", "tokens": ["So", "lang", "ich", "bin", ",", "kan", "dich", "kein", "Un\u00b7gl\u00fcck", "tref\u00b7fen", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "VAFIN", "$,", "VMFIN", "PPER", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Ich w\u00fcrde mit dir eh das letzte theilen,", "tokens": ["Ich", "w\u00fcr\u00b7de", "mit", "dir", "eh", "das", "letz\u00b7te", "thei\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "PPER", "KOUS", "ART", "ADJA", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Als dich verlassen.", "tokens": ["Als", "dich", "ver\u00b7las\u00b7sen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVINF", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.33": {"line.1": {"text": "Die Tugend kan den wahren Ruhm wohl dulden:", "tokens": ["Die", "Tu\u00b7gend", "kan", "den", "wah\u00b7ren", "Ruhm", "wohl", "dul\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "ART", "ADJA", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ich lobe deine Kunst, noch mehr dein Hertze.", "tokens": ["Ich", "lo\u00b7be", "dei\u00b7ne", "Kunst", ",", "noch", "mehr", "dein", "Hert\u00b7ze", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "$,", "ADV", "ADV", "PPOSAT", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "R\u00fchm, was allein mich deiner w\u00fcrdig machet,", "tokens": ["R\u00fchm", ",", "was", "al\u00b7lein", "mich", "dei\u00b7ner", "w\u00fcr\u00b7dig", "ma\u00b7chet", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PRELS", "ADV", "PPER", "PPOSAT", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Da\u00df ich dich sch\u00e4tze.", "tokens": ["Da\u00df", "ich", "dich", "sch\u00e4t\u00b7ze", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "VVFIN", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.34": {"line.1": {"text": "Die sp\u00e4te Welt belehr ich durch die Dichtkunst,", "tokens": ["Die", "sp\u00e4\u00b7te", "Welt", "be\u00b7lehr", "ich", "durch", "die", "Dicht\u00b7kunst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die auch gekr\u00f6nte Laster nie wird preisen,", "tokens": ["Die", "auch", "ge\u00b7kr\u00f6n\u00b7te", "Las\u00b7ter", "nie", "wird", "prei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJA", "NN", "ADV", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Wie meiner Doris Treu, und deine Freundschaft", "tokens": ["Wie", "mei\u00b7ner", "Do\u00b7ris", "Treu", ",", "und", "dei\u00b7ne", "Freund\u00b7schaft"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWAV", "PPOSAT", "NE", "NN", "$,", "KON", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Mein Leben begl\u00fcckt.", "tokens": ["Mein", "Le\u00b7ben", "be\u00b7gl\u00fcckt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVPP", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}}, "stanza.35": {"line.1": {"text": "Itzt leg ich mich in ihre zarten Arme,", "tokens": ["Itzt", "leg", "ich", "mich", "in", "ih\u00b7re", "zar\u00b7ten", "Ar\u00b7me", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die sie dir zum Willkommen oft gereichet.", "tokens": ["Die", "sie", "dir", "zum", "Will\u00b7kom\u00b7men", "oft", "ge\u00b7rei\u00b7chet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PPER", "APPRART", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "La\u00df, wenn du lebest, keinen von uns beyden", "tokens": ["La\u00df", ",", "wenn", "du", "le\u00b7best", ",", "kei\u00b7nen", "von", "uns", "bey\u00b7den"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVIMP", "$,", "KOUS", "PPER", "VVFIN", "$,", "PIAT", "APPR", "PPER", "PIAT"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Ohne Klage-Lied.", "tokens": ["Oh\u00b7ne", "Kla\u00b7ge\u00b7Lied", "."], "token_info": ["word", "word", "punct"], "pos": ["APPR", "NN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.36": {"line.1": {"text": "Mit h\u00e4uffigen und schuldgen Thr\u00e4nen netze", "tokens": ["Mit", "h\u00e4uf\u00b7fi\u00b7gen", "und", "schuld\u00b7gen", "Thr\u00e4\u00b7nen", "net\u00b7ze"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "KON", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Bey blassem Angesicht die werthen Leichen,", "tokens": ["Bey", "blas\u00b7sem", "An\u00b7ge\u00b7sicht", "die", "wert\u00b7hen", "Lei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und schreibe kein Gedicht ohn diese Namen:", "tokens": ["Und", "schrei\u00b7be", "kein", "Ge\u00b7dicht", "ohn", "die\u00b7se", "Na\u00b7men", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIAT", "NN", "APPR", "PDAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Damon und Doris.", "tokens": ["Da\u00b7mon", "und", "Do\u00b7ris", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "KON", "NE", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}}}}}