{"dta.poem.1353": {"metadata": {"author": {"name": "Abschatz, Hans Assmann von", "birth": "N.A.", "death": "N.A."}, "title": "Das beste Andencken.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1704", "urn": "urn:nbn:de:kobv:b4-200905199889", "language": ["de:0.99"], "booktitle": "Abschatz, Hans Assmann von: Poetische Ubersetzungen und Gedichte. Leipzig, 1704."}, "poem": {"stanza.1": {"line.1": {"text": "Was ist/ o Himmels-F\u00fcrst/ der Mensch/ die Hand voll\nKoth/", "tokens": ["Was", "ist", "/", "o", "Him\u00b7mels\u00b7F\u00fcrst", "/", "der", "Mensch", "/", "die", "Hand", "voll", "Koth", "/"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "$(", "FM", "NN", "$(", "ART", "NN", "$(", "ART", "NN", "ADJD", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Da\u00df du ihm unverdient so holde Liebe schenckest?", "tokens": ["Da\u00df", "du", "ihm", "un\u00b7ver\u00b7di\u00b7ent", "so", "hol\u00b7de", "Lie\u00b7be", "schen\u00b7ckest", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "ADJD", "ADV", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Was treibt dich/ grosser GOTT/", "tokens": ["Was", "treibt", "dich", "/", "gros\u00b7ser", "GoTT", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "$(", "ADJA", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Da\u00df du so v\u00e4terlich an Adams Erben denckest?", "tokens": ["Da\u00df", "du", "so", "v\u00e4\u00b7ter\u00b7lich", "an", "A\u00b7dams", "Er\u00b7ben", "den\u00b7ckest", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "APPR", "NE", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Auff Erden ruht dein Fu\u00df/ im Himmel ist dein Thron/", "tokens": ["Auff", "Er\u00b7den", "ruht", "dein", "Fu\u00df", "/", "im", "Him\u00b7mel", "ist", "dein", "Thron", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PPOSAT", "NN", "$(", "APPRART", "NN", "VAFIN", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Du bist der Heilige/ der Starcke/ der Gerechte/", "tokens": ["Du", "bist", "der", "Hei\u00b7li\u00b7ge", "/", "der", "Star\u00b7cke", "/", "der", "Ge\u00b7rech\u00b7te", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "$(", "ART", "NN", "$(", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der Mensch ist spr\u00f6der Thon/", "tokens": ["Der", "Mensch", "ist", "spr\u00f6\u00b7der", "Thon", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJA", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Befleckt/ ohnm\u00e4chtig/ kranck/ ein s\u00fcndliches Geschlechte.", "tokens": ["Be\u00b7fleckt", "/", "ohn\u00b7m\u00e4ch\u00b7tig", "/", "kranck", "/", "ein", "s\u00fcnd\u00b7li\u00b7ches", "Ge\u00b7schlech\u00b7te", "."], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVPP", "$(", "ADJD", "$(", "ADJD", "$(", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Doch h\u00e4ltstu \u00fcber ihm gen\u00e4dig Aug\u2019 und Hand/", "tokens": ["Doch", "h\u00e4lts\u00b7tu", "\u00fc\u00b7ber", "ihm", "ge\u00b7n\u00e4\u00b7dig", "Aug'", "und", "Hand", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PPER", "ADJD", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Es wallet gegen ihm dein brennendes Gem\u00fctte/", "tokens": ["Es", "wal\u00b7let", "ge\u00b7gen", "ihm", "dein", "bren\u00b7nen\u00b7des", "Ge\u00b7m\u00fct\u00b7te", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPER", "PPOSAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Dein Sohn ist selbst das Pfand", "tokens": ["Dein", "Sohn", "ist", "selbst", "das", "Pfand"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VAFIN", "ADV", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Der ungef\u00e4rbten Huld/ ein Zeuge deiner G\u00fctte.", "tokens": ["Der", "un\u00b7ge\u00b7f\u00e4rb\u00b7ten", "Huld", "/", "ein", "Zeu\u00b7ge", "dei\u00b7ner", "G\u00fct\u00b7te", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$(", "ART", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Wie aber denckt/ o GOtt! der schn\u00f6de Mensch an dich/", "tokens": ["Wie", "a\u00b7ber", "denckt", "/", "o", "Gott", "!", "der", "schn\u00f6\u00b7de", "Mensch", "an", "dich", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "VVFIN", "$(", "FM", "NN", "$.", "ART", "ADJA", "NN", "APPR", "PPER", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Hier ist nur Undanck und Vergessenheit zu finden/", "tokens": ["Hier", "ist", "nur", "Un\u00b7danck", "und", "Ver\u00b7ges\u00b7sen\u00b7heit", "zu", "fin\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "NN", "KON", "NN", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Erforsch ich selber mich/", "tokens": ["Er\u00b7forsch", "ich", "sel\u00b7ber", "mich", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "PPER", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "So seh ich alle Spur der Danckbarkeit verschwinden.", "tokens": ["So", "seh", "ich", "al\u00b7le", "Spur", "der", "Dan\u00b7ck\u00b7bar\u00b7keit", "ver\u00b7schwin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PIAT", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}}, "stanza.5": {"line.1": {"text": "Ich denck am meisten/ wie mirs zeitlich gehe wohl/", "tokens": ["Ich", "denck", "am", "meis\u00b7ten", "/", "wie", "mirs", "zeit\u00b7lich", "ge\u00b7he", "wohl", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "PIS", "$(", "KOKOM", "NE", "ADJD", "VVFIN", "ADV", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und lasse hin und her zerstreute Sinnen wancken;", "tokens": ["Und", "las\u00b7se", "hin", "und", "her", "zer\u00b7streu\u00b7te", "Sin\u00b7nen", "wan\u00b7cken", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKVZ", "KON", "ADV", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Was ich bedencken soll/", "tokens": ["Was", "ich", "be\u00b7den\u00b7cken", "soll", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVINF", "VMFIN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Drauff richt ich offtermahls nur fl\u00fcchtige Gedancken.", "tokens": ["Drauff", "richt", "ich", "off\u00b7ter\u00b7mahls", "nur", "fl\u00fcch\u00b7ti\u00b7ge", "Ge\u00b7dan\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "ADV", "ADV", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Ich bin mir wenig Lieb\u2019 und Treu zu dir bewust/", "tokens": ["Ich", "bin", "mir", "we\u00b7nig", "Lieb'", "und", "Treu", "zu", "dir", "be\u00b7wust", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "PIAT", "NN", "KON", "NN", "APPR", "PPER", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Drum mu\u00df mich schwartze Reu\u2019 und bange Furcht bekr\u00e4ncken/", "tokens": ["Drum", "mu\u00df", "mich", "schwart\u00b7ze", "Reu'", "und", "ban\u00b7ge", "Furcht", "be\u00b7kr\u00e4n\u00b7cken", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VMFIN", "PPER", "VVFIN", "NE", "KON", "ADJD", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Es kocht in meiner Brust", "tokens": ["Es", "kocht", "in", "mei\u00b7ner", "Brust"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Geh\u00e4uffter S\u00fcnden Schuld/ betr\u00fcbtes Angedencken.", "tokens": ["Ge\u00b7h\u00e4uff\u00b7ter", "S\u00fcn\u00b7den", "Schuld", "/", "be\u00b7tr\u00fcb\u00b7tes", "An\u00b7ge\u00b7den\u00b7cken", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADJA", "NN", "NN", "$(", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Ich leider! bins/ der dich/ o Heyland/ band und schlug/", "tokens": ["Ich", "lei\u00b7der", "!", "bins", "/", "der", "dich", "/", "o", "Hey\u00b7land", "/", "band", "und", "schlug", "/"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "$.", "VAFIN", "$(", "PRELS", "PPER", "$(", "FM", "NN", "$(", "VVFIN", "KON", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der dein ge\u00e4ngstes Haubt mit S\u00fcnden-Dornen rizte/", "tokens": ["Der", "dein", "ge\u00b7\u00e4ngs\u00b7tes", "Haubt", "mit", "S\u00fcn\u00b7den\u00b7Dor\u00b7nen", "riz\u00b7te", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "ADJA", "NN", "APPR", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Dir Holtz zum Creutze trug/", "tokens": ["Dir", "Holtz", "zum", "Creut\u00b7ze", "trug", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "APPRART", "NN", "VVFIN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Und selbst f\u00fcr Hand und Fu\u00df die scharffen N\u00e4gel spizte.", "tokens": ["Und", "selbst", "f\u00fcr", "Hand", "und", "Fu\u00df", "die", "scharf\u00b7fen", "N\u00e4\u00b7gel", "spiz\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "NN", "KON", "NN", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "Ach HErr/ gedencke nicht die Schulden junger Zeit/", "tokens": ["Ach", "Herr", "/", "ge\u00b7den\u00b7cke", "nicht", "die", "Schul\u00b7den", "jun\u00b7ger", "Zeit", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "NN", "$(", "VVFIN", "PTKNEG", "ART", "NN", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Roch wie ich war bedacht das S\u00fcnden-Maa\u00df zu f\u00fcllen/", "tokens": ["Roch", "wie", "ich", "war", "be\u00b7dacht", "das", "S\u00fcn\u00b7den\u00b7Maa\u00df", "zu", "f\u00fcl\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "PPER", "VAFIN", "VVPP", "ART", "NN", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Denck in Barmhertzigkeit", "tokens": ["Denck", "in", "Barm\u00b7hert\u00b7zig\u00b7keit"], "token_info": ["word", "word", "word"], "pos": ["NE", "APPR", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Denckst du in Gnaden mein/ so bin ich wohl bedacht/", "tokens": ["Denckst", "du", "in", "Gna\u00b7den", "mein", "/", "so", "bin", "ich", "wohl", "be\u00b7dacht", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "NN", "PPOSAT", "$(", "ADV", "VAFIN", "PPER", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Mein Frevel aber bleibt in Ewigkeit vergessen.", "tokens": ["Mein", "Fre\u00b7vel", "a\u00b7ber", "bleibt", "in", "E\u00b7wig\u00b7keit", "ver\u00b7ges\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADV", "VVFIN", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Nun Erde gutte Nacht!", "tokens": ["Nun", "Er\u00b7de", "gut\u00b7te", "Nacht", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Ich dencke nur an den/ des Liebe nicht zu messen.", "tokens": ["Ich", "den\u00b7cke", "nur", "an", "den", "/", "des", "Lie\u00b7be", "nicht", "zu", "mes\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "ART", "$(", "ART", "NN", "PTKNEG", "PTKZU", "VVINF", "$."], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}}}}}