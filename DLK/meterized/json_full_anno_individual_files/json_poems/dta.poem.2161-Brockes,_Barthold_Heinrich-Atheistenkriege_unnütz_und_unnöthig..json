{"dta.poem.2161": {"metadata": {"author": {"name": "Brockes, Barthold Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "Atheistenkriege unn\u00fctz und  \n unn\u00f6thig.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1748", "urn": "urn:nbn:de:kobv:b4-200905198553", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Die Ursach, warum itzt die Lehren,", "tokens": ["Die", "Ur\u00b7sach", ",", "wa\u00b7rum", "itzt", "die", "Leh\u00b7ren", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PWAV", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die Atheisten zu bekehren,", "tokens": ["Die", "A\u00b7theis\u00b7ten", "zu", "be\u00b7keh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Sich fast an allen Orten h\u00e4ufen,", "tokens": ["Sich", "fast", "an", "al\u00b7len", "Or\u00b7ten", "h\u00e4u\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADV", "APPR", "PIAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Kann ich nicht gar zu wohl begreifen,", "tokens": ["Kann", "ich", "nicht", "gar", "zu", "wohl", "be\u00b7grei\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PTKNEG", "ADV", "APPR", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Da doch so viel, als wie man h\u00f6rt,", "tokens": ["Da", "doch", "so", "viel", ",", "als", "wie", "man", "h\u00f6rt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "ADV", "$,", "KOUS", "PWAV", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Sich ihre Schaar nicht eben mehrt.", "tokens": ["Sich", "ih\u00b7re", "Schaar", "nicht", "e\u00b7ben", "mehrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "PPOSAT", "NN", "PTKNEG", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Ja sollte letzters auch geschehen,", "tokens": ["Ja", "soll\u00b7te", "letz\u00b7ters", "auch", "ge\u00b7sche\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "VMFIN", "PIS", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Ist es noch ungewi\u00df, ob selbe nicht entstehen", "tokens": ["Ist", "es", "noch", "un\u00b7ge\u00b7wi\u00df", ",", "ob", "sel\u00b7be", "nicht", "ent\u00b7ste\u00b7hen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "ADV", "ADJD", "$,", "KOUS", "ADJA", "PTKNEG", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Dadurch, da\u00df man, was Gott, so wunderlich erkl\u00e4rt.", "tokens": ["Da\u00b7durch", ",", "da\u00df", "man", ",", "was", "Gott", ",", "so", "wun\u00b7der\u00b7lich", "er\u00b7kl\u00e4rt", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PAV", "$,", "KOUS", "PIS", "$,", "PRELS", "NN", "$,", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Es scheint, wenn wir es recht ergr\u00fcnden,", "tokens": ["Es", "scheint", ",", "wenn", "wir", "es", "recht", "er\u00b7gr\u00fcn\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "PPER", "PPER", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Da\u00df, wenn die\u00df ohne Noth geschicht,", "tokens": ["Da\u00df", ",", "wenn", "die\u00df", "oh\u00b7ne", "Noth", "ge\u00b7schicht", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$,", "KOUS", "PDS", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Mehr Stolz als Nutz darinn zu finden;", "tokens": ["Mehr", "Stolz", "als", "Nutz", "da\u00b7rinn", "zu", "fin\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "KOUS", "NN", "PAV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Wer braucht beym Sonnenstral ein Licht?", "tokens": ["Wer", "braucht", "beym", "Son\u00b7nen\u00b7stral", "ein", "Licht", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "APPRART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Man glaubt, die Sprache der Natur", "tokens": ["Man", "glaubt", ",", "die", "Spra\u00b7che", "der", "Na\u00b7tur"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "$,", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Sey, gegen unsre Schl\u00fcsse, nur", "tokens": ["Sey", ",", "ge\u00b7gen", "uns\u00b7re", "Schl\u00fcs\u00b7se", ",", "nur"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word"], "pos": ["VAFIN", "$,", "APPR", "PPOSAT", "NN", "$,", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Ein unverst\u00e4ndlich dunkles Wesen,", "tokens": ["Ein", "un\u00b7ver\u00b7st\u00e4nd\u00b7lich", "dunk\u00b7les", "We\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.17": {"text": "Und, sonder unsrer Schl\u00fcsse Kraft,", "tokens": ["Und", ",", "son\u00b7der", "uns\u00b7rer", "Schl\u00fcs\u00b7se", "Kraft", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KON", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.18": {"text": "Das Kreaturbuch nicht zu lesen.", "tokens": ["Das", "Kre\u00b7a\u00b7tur\u00b7buch", "nicht", "zu", "le\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKNEG", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.19": {"text": "Da in der Geister Eigenschaft", "tokens": ["Da", "in", "der", "Geis\u00b7ter", "Ei\u00b7gen\u00b7schaft"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.20": {"text": "Doch ganz verschiedene Gedanken,", "tokens": ["Doch", "ganz", "ver\u00b7schie\u00b7de\u00b7ne", "Ge\u00b7dan\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.21": {"text": "Ein \u00e4rgerlichs best\u00e4ndigs Zanken,", "tokens": ["Ein", "\u00e4r\u00b7ger\u00b7lichs", "be\u00b7st\u00e4n\u00b7digs", "Zan\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.22": {"text": "Und nichts als Jrrungen entstehn,", "tokens": ["Und", "nichts", "als", "Jr\u00b7run\u00b7gen", "ent\u00b7stehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "KOKOM", "NN", "VVINF", "$,"], "meter": "-+-++--+", "measure": "iambic.tetra.chol"}, "line.23": {"text": "Wie leider! \u00fcberall zu sehn.", "tokens": ["Wie", "lei\u00b7der", "!", "\u00fc\u00b7be\u00b7rall", "zu", "sehn", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "$.", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.24": {"text": "Wann in den wunderbaren Werken", "tokens": ["Wann", "in", "den", "wun\u00b7der\u00b7ba\u00b7ren", "Wer\u00b7ken"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.25": {"text": "Der Sch\u00f6pfer \u00fcberall zu merken,", "tokens": ["Der", "Sch\u00f6p\u00b7fer", "\u00fc\u00b7be\u00b7rall", "zu", "mer\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.26": {"text": "Er selbst sich \u00fcberall entdeckt;", "tokens": ["Er", "selbst", "sich", "\u00fc\u00b7be\u00b7rall", "ent\u00b7deckt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "PRF", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.27": {"text": "So scheint, als ob in dem Betragen,", "tokens": ["So", "scheint", ",", "als", "ob", "in", "dem", "Be\u00b7tra\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "KOKOM", "KOUS", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.28": {"text": "Von andrer Schwachheit nichts zu sagen,", "tokens": ["Von", "an\u00b7drer", "Schwach\u00b7heit", "nichts", "zu", "sa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "PIS", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.29": {"text": "Kein andrer Grund als dieser steckt:", "tokens": ["Kein", "an\u00b7drer", "Grund", "als", "die\u00b7ser", "steckt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "KOKOM", "PDS", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.30": {"text": "Ein jeder scheint sich zu bem\u00fchn,", "tokens": ["Ein", "je\u00b7der", "scheint", "sich", "zu", "be\u00b7m\u00fchn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VVFIN", "PRF", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.31": {"text": "Mehr seinen Geist hervorzuziehn,", "tokens": ["Mehr", "sei\u00b7nen", "Geist", "her\u00b7vor\u00b7zu\u00b7ziehn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.32": {"text": "Als Gottes Wesen zu bewehren.", "tokens": ["Als", "Got\u00b7tes", "We\u00b7sen", "zu", "be\u00b7weh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.33": {"text": "Ein jeder will mit seinem Geist,", "tokens": ["Ein", "je\u00b7der", "will", "mit", "sei\u00b7nem", "Geist", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VMFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.34": {"text": "Was sich an allen Orten weist,", "tokens": ["Was", "sich", "an", "al\u00b7len", "Or\u00b7ten", "weist", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PRF", "APPR", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.35": {"text": "Was mehr als sonnenklar, erkl\u00e4ren.", "tokens": ["Was", "mehr", "als", "son\u00b7nen\u00b7klar", ",", "er\u00b7kl\u00e4\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PWS", "PIS", "KOKOM", "ADJD", "$,", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.36": {"text": "Es k\u00f6mmt ein solch Betragen mir", "tokens": ["Es", "k\u00f6mmt", "ein", "solch", "Be\u00b7tra\u00b7gen", "mir"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "PIAT", "NN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.37": {"text": "Fast in der That nicht anders f\u00fcr,", "tokens": ["Fast", "in", "der", "That", "nicht", "an\u00b7ders", "f\u00fcr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "PTKNEG", "ADV", "APPR", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.38": {"text": "Als wenn ein Kind, mit klugen Lehren,", "tokens": ["Als", "wenn", "ein", "Kind", ",", "mit", "klu\u00b7gen", "Leh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "ART", "NN", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.39": {"text": "Mit einer langen Schl\u00fcsse Reih,", "tokens": ["Mit", "ei\u00b7ner", "lan\u00b7gen", "Schl\u00fcs\u00b7se", "Reih", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.40": {"text": "Will aus dem A. B. C. erkl\u00e4ren,", "tokens": ["Will", "aus", "dem", "A.", "B.", "C.", "er\u00b7kl\u00e4\u00b7ren", ","], "token_info": ["word", "word", "word", "abbreviation", "abbreviation", "abbreviation", "word", "punct"], "pos": ["VMFIN", "APPR", "ART", "APPRART", "NN", "NE", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.41": {"text": "Da\u00df es zu Mittag, Mittag sey.", "tokens": ["Da\u00df", "es", "zu", "Mit\u00b7tag", ",", "Mit\u00b7tag", "sey", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NN", "$,", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}