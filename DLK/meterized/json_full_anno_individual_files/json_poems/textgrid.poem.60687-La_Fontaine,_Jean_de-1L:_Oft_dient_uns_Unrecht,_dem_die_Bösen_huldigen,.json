{"textgrid.poem.60687": {"metadata": {"author": {"name": "La Fontaine, Jean de", "birth": "N.A.", "death": "N.A."}, "title": "1L: Oft dient uns Unrecht, dem die B\u00f6sen huldigen,", "genre": "verse", "period": "N.A.", "pub_year": 1658, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Oft dient uns Unrecht, dem die B\u00f6sen huldigen,", "tokens": ["Oft", "dient", "uns", "Un\u00b7recht", ",", "dem", "die", "B\u00f6\u00b7sen", "hul\u00b7di\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "NN", "$,", "PRELS", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+--", "measure": "unknown.measure.penta"}, "line.2": {"text": "Die eignen \u00dcbeltaten zu entschuldigen.", "tokens": ["Die", "eig\u00b7nen", "\u00dc\u00b7bel\u00b7ta\u00b7ten", "zu", "ent\u00b7schul\u00b7di\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Dies aber ist der Welt Gesetz und Brauch:", "tokens": ["Dies", "a\u00b7ber", "ist", "der", "Welt", "Ge\u00b7setz", "und", "Brauch", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "VAFIN", "ART", "NN", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Willst du geschont sein, schone andre auch.", "tokens": ["Willst", "du", "ge\u00b7schont", "sein", ",", "scho\u00b7ne", "and\u00b7re", "auch", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "VVPP", "VAINF", "$,", "VVFIN", "PIS", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Ein Landmann fing mit seinen Netzen V\u00f6gelein.", "tokens": ["Ein", "Land\u00b7mann", "fing", "mit", "sei\u00b7nen", "Net\u00b7zen", "V\u00f6\u00b7ge\u00b7lein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Er lockte eine Lerche an. Ein Habicht fuhr", "tokens": ["Er", "lock\u00b7te", "ei\u00b7ne", "Ler\u00b7che", "an", ".", "Ein", "Ha\u00b7bicht", "fuhr"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "PTKVZ", "$.", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Von Himmelsh\u00f6he nieder auf die Flur,", "tokens": ["Von", "Him\u00b7mels\u00b7h\u00f6\u00b7he", "nie\u00b7der", "auf", "die", "Flur", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PTKVZ", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Ein schneller Sto\u00df, die S\u00e4ngerin war sein;", "tokens": ["Ein", "schnel\u00b7ler", "Sto\u00df", ",", "die", "S\u00e4n\u00b7ge\u00b7rin", "war", "sein", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "NN", "VAFIN", "VAINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Noch eh sie in der b\u00f6sen Falle,", "tokens": ["Noch", "eh", "sie", "in", "der", "b\u00f6\u00b7sen", "Fal\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PPER", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Sp\u00fcrt sie des Habichts scharfe Kralle.", "tokens": ["Sp\u00fcrt", "sie", "des", "Ha\u00b7bichts", "schar\u00b7fe", "Kral\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Er will sie rupfen und sich niedersetzen,", "tokens": ["Er", "will", "sie", "rup\u00b7fen", "und", "sich", "nie\u00b7der\u00b7set\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "VVINF", "KON", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Da f\u00e4ngt er selbst sich in den Netzen.", "tokens": ["Da", "f\u00e4ngt", "er", "selbst", "sich", "in", "den", "Net\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "PRF", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "In seiner Sprache flehte er den Landmann an:", "tokens": ["In", "sei\u00b7ner", "Spra\u00b7che", "fleh\u00b7te", "er", "den", "Land\u00b7mann", "an", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "PPER", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "\u00bbla\u00df mich, ich hab dir nie etwas zuleid getan!\u00ab", "tokens": ["\u00bb", "la\u00df", "mich", ",", "ich", "hab", "dir", "nie", "et\u00b7was", "zu\u00b7leid", "ge\u00b7tan", "!", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VVIMP", "PPER", "$,", "PPER", "VAFIN", "PPER", "ADV", "ADV", "ADJD", "VVPP", "$.", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Der Vogelsteller drauf: \u00bbWas aber tat denn dir", "tokens": ["Der", "Vo\u00b7gel\u00b7stel\u00b7ler", "drauf", ":", "\u00bb", "Was", "a\u00b7ber", "tat", "denn", "dir"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "PTKVZ", "$.", "$(", "PWS", "ADV", "VVFIN", "KON", "PPER"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Zuleide dieses kleine Tier?\u00ab", "tokens": ["Zu\u00b7lei\u00b7de", "die\u00b7ses", "klei\u00b7ne", "Tier", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "PDAT", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Oft dient uns Unrecht, dem die B\u00f6sen huldigen,", "tokens": ["Oft", "dient", "uns", "Un\u00b7recht", ",", "dem", "die", "B\u00f6\u00b7sen", "hul\u00b7di\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "NN", "$,", "PRELS", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+--", "measure": "unknown.measure.penta"}, "line.2": {"text": "Die eignen \u00dcbeltaten zu entschuldigen.", "tokens": ["Die", "eig\u00b7nen", "\u00dc\u00b7bel\u00b7ta\u00b7ten", "zu", "ent\u00b7schul\u00b7di\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Dies aber ist der Welt Gesetz und Brauch:", "tokens": ["Dies", "a\u00b7ber", "ist", "der", "Welt", "Ge\u00b7setz", "und", "Brauch", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "VAFIN", "ART", "NN", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Willst du geschont sein, schone andre auch.", "tokens": ["Willst", "du", "ge\u00b7schont", "sein", ",", "scho\u00b7ne", "and\u00b7re", "auch", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "VVPP", "VAINF", "$,", "VVFIN", "PIS", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Ein Landmann fing mit seinen Netzen V\u00f6gelein.", "tokens": ["Ein", "Land\u00b7mann", "fing", "mit", "sei\u00b7nen", "Net\u00b7zen", "V\u00f6\u00b7ge\u00b7lein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Er lockte eine Lerche an. Ein Habicht fuhr", "tokens": ["Er", "lock\u00b7te", "ei\u00b7ne", "Ler\u00b7che", "an", ".", "Ein", "Ha\u00b7bicht", "fuhr"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "PTKVZ", "$.", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Von Himmelsh\u00f6he nieder auf die Flur,", "tokens": ["Von", "Him\u00b7mels\u00b7h\u00f6\u00b7he", "nie\u00b7der", "auf", "die", "Flur", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PTKVZ", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Ein schneller Sto\u00df, die S\u00e4ngerin war sein;", "tokens": ["Ein", "schnel\u00b7ler", "Sto\u00df", ",", "die", "S\u00e4n\u00b7ge\u00b7rin", "war", "sein", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "NN", "VAFIN", "VAINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Noch eh sie in der b\u00f6sen Falle,", "tokens": ["Noch", "eh", "sie", "in", "der", "b\u00f6\u00b7sen", "Fal\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PPER", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Sp\u00fcrt sie des Habichts scharfe Kralle.", "tokens": ["Sp\u00fcrt", "sie", "des", "Ha\u00b7bichts", "schar\u00b7fe", "Kral\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Er will sie rupfen und sich niedersetzen,", "tokens": ["Er", "will", "sie", "rup\u00b7fen", "und", "sich", "nie\u00b7der\u00b7set\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "VVINF", "KON", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Da f\u00e4ngt er selbst sich in den Netzen.", "tokens": ["Da", "f\u00e4ngt", "er", "selbst", "sich", "in", "den", "Net\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "PRF", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "In seiner Sprache flehte er den Landmann an:", "tokens": ["In", "sei\u00b7ner", "Spra\u00b7che", "fleh\u00b7te", "er", "den", "Land\u00b7mann", "an", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "PPER", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "\u00bbla\u00df mich, ich hab dir nie etwas zuleid getan!\u00ab", "tokens": ["\u00bb", "la\u00df", "mich", ",", "ich", "hab", "dir", "nie", "et\u00b7was", "zu\u00b7leid", "ge\u00b7tan", "!", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VVIMP", "PPER", "$,", "PPER", "VAFIN", "PPER", "ADV", "ADV", "ADJD", "VVPP", "$.", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Der Vogelsteller drauf: \u00bbWas aber tat denn dir", "tokens": ["Der", "Vo\u00b7gel\u00b7stel\u00b7ler", "drauf", ":", "\u00bb", "Was", "a\u00b7ber", "tat", "denn", "dir"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "PTKVZ", "$.", "$(", "PWS", "ADV", "VVFIN", "KON", "PPER"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Zuleide dieses kleine Tier?\u00ab", "tokens": ["Zu\u00b7lei\u00b7de", "die\u00b7ses", "klei\u00b7ne", "Tier", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "PDAT", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}