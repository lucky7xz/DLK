{"dta.poem.3934": {"metadata": {"author": {"name": "Spindler, Christian Gotthold", "birth": "N.A.", "death": "N.A."}, "title": "24) Schreiben an ein Frauenzimmer,  \n  im Nahmen eines andern, \u00fcber ihnen bekannte  \n  Affai ren.", "genre": "Lyrik, Drama", "period": "N.A.", "pub_year": "1745", "urn": "urn:nbn:de:kobv:b4-20581-9", "language": ["de:0.99"], "booktitle": "Spindler, Christian Gotthold: Unschuldige Jugend-Fr\u00fcchte. Leipzig, 1745."}, "poem": {"stanza.1": {"line.1": {"text": "M\u00e4gdgen sind ein Wunder-Ding,", "tokens": ["M\u00e4gd\u00b7gen", "sind", "ein", "Wun\u00b7der\u00b7Ding", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Gleichwie unter Dichter-Reimen,", "tokens": ["Gleich\u00b7wie", "un\u00b7ter", "Dich\u00b7ter\u00b7Rei\u00b7men", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Allemahl nicht jede flinck;", "tokens": ["Al\u00b7le\u00b7mahl", "nicht", "je\u00b7de", "flinck", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKNEG", "PIAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Gleichwie unter guten B\u00e4umen", "tokens": ["Gleich\u00b7wie", "un\u00b7ter", "gu\u00b7ten", "B\u00e4u\u00b7men"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Viel unzehlich krumme stehn,", "tokens": ["Viel", "un\u00b7zeh\u00b7lich", "krum\u00b7me", "stehn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "VVINF", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Kan man es an M\u00e4gdgen sehn.", "tokens": ["Kan", "man", "es", "an", "M\u00e4gd\u00b7gen", "sehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIS", "PPER", "APPR", "NN", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Jungfer Base, du wirsts mercken,", "tokens": ["Jung\u00b7fer", "Ba\u00b7se", ",", "du", "wirsts", "mer\u00b7cken", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "PPER", "VAFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Und mir meinen Satz best\u00e4rcken.", "tokens": ["Und", "mir", "mei\u00b7nen", "Satz", "be\u00b7st\u00e4r\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "PPOSAT", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Viele M\u00e4gdgen sind nun so,", "tokens": ["Vie\u00b7le", "M\u00e4gd\u00b7gen", "sind", "nun", "so", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "ADV", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Bey dem hellen Wohlstands-Schimmer", "tokens": ["Bey", "dem", "hel\u00b7len", "Wohl\u00b7stands\u00b7Schim\u00b7mer"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Sind sie lustig, hertzlich froh,", "tokens": ["Sind", "sie", "lus\u00b7tig", ",", "hertz\u00b7lich", "froh", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADJD", "$,", "ADV", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Aber wenn das Frauenzimmer", "tokens": ["A\u00b7ber", "wenn", "das", "Frau\u00b7en\u00b7zim\u00b7mer"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "KOUS", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Eine Unfalls-Distel sticht,", "tokens": ["Ei\u00b7ne", "Un\u00b7falls\u00b7Dis\u00b7tel", "sticht", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Kennt sie keinen Menschen nicht,", "tokens": ["Kennt", "sie", "kei\u00b7nen", "Men\u00b7schen", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PIAT", "NN", "PTKNEG", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Da f\u00e4ngt sie recht an zu plappern,", "tokens": ["Da", "f\u00e4ngt", "sie", "recht", "an", "zu", "plap\u00b7pern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "PTKVZ", "PTKZU", "VVINF", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "Wie die rischen M\u00fchlen klappern.", "tokens": ["Wie", "die", "ri\u00b7schen", "M\u00fch\u00b7len", "klap\u00b7pern", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Vor viel Klugheit gar zu klug", "tokens": ["Vor", "viel", "Klug\u00b7heit", "gar", "zu", "klug"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PIAT", "NN", "ADV", "PTKA", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "K\u00f6nnen sie nichts \u00fcberlegen,", "tokens": ["K\u00f6n\u00b7nen", "sie", "nichts", "\u00fc\u00b7berl\u00b7e\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PIS", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und sie bringt der Selbst-Betrug", "tokens": ["Und", "sie", "bringt", "der", "Selbst\u00b7Be\u00b7trug"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Aus der Trauffe in den Regen.", "tokens": ["Aus", "der", "Trauf\u00b7fe", "in", "den", "Re\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Viele tragen sich zur Schau,", "tokens": ["Vie\u00b7le", "tra\u00b7gen", "sich", "zur", "Schau", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PRF", "APPRART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Wie ein aufgeblasner Pfau,", "tokens": ["Wie", "ein", "auf\u00b7ge\u00b7blas\u00b7ner", "Pfau", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Und Clarinde r\u00fcmpfft das N\u00e4sgen,", "tokens": ["Und", "Cla\u00b7rin\u00b7de", "r\u00fcmpfft", "das", "N\u00e4s\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "VVFIN", "ART", "NN", "$,"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.8": {"text": "Wie ein abgeschmacktes H\u00e4sgen.", "tokens": ["Wie", "ein", "ab\u00b7ge\u00b7schmack\u00b7tes", "H\u00e4s\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "O! sie pipen wie ein Huhn,", "tokens": ["O", "!", "sie", "pi\u00b7pen", "wie", "ein", "Huhn", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "PPER", "VVINF", "KOKOM", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Viele legen sich aufs Naschen,", "tokens": ["Vie\u00b7le", "le\u00b7gen", "sich", "aufs", "Na\u00b7schen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PRF", "APPRART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Die so gar verzumpen thun,", "tokens": ["Die", "so", "gar", "ver\u00b7zum\u00b7pen", "thun", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADV", "VVINF", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Lieben reich gef\u00fcllte Flaschen.", "tokens": ["Lie\u00b7ben", "reich", "ge\u00b7f\u00fcll\u00b7te", "Fla\u00b7schen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "ADJD", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Doris, die zu spitzig ist,", "tokens": ["Do\u00b7ris", ",", "die", "zu", "spit\u00b7zig", "ist", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PRELS", "PTKA", "ADJD", "VAFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Die betr\u00fcgt ihr eigner Mist,", "tokens": ["Die", "be\u00b7tr\u00fcgt", "ihr", "eig\u00b7ner", "Mist", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Denn die Liebe sey ihr Schaden,", "tokens": ["Denn", "die", "Lie\u00b7be", "sey", "ihr", "Scha\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Da soll Sanct Andreas rathen.", "tokens": ["Da", "soll", "Sanct", "A\u00b7ndre\u00b7as", "ra\u00b7then", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "VVFIN", "NE", "VVFIN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.5": {"line.1": {"text": "Du weist schon wohin es zielt,", "tokens": ["Du", "weist", "schon", "wo\u00b7hin", "es", "zielt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PWAV", "PPER", "VVFIN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Freundin! du kennst diese Possen.", "tokens": ["Freun\u00b7din", "!", "du", "kennst", "die\u00b7se", "Pos\u00b7sen", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "PPER", "VVFIN", "PDAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Da mein M\u00fcthgen l\u00e4ngst gek\u00fchlt,", "tokens": ["Da", "mein", "M\u00fcth\u00b7gen", "l\u00e4ngst", "ge\u00b7k\u00fchlt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "ADV", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Nun so sey der Brief geschlossen.", "tokens": ["Nun", "so", "sey", "der", "Brief", "ge\u00b7schlos\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VAFIN", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Du fliehst diesen Narren-Tand,", "tokens": ["Du", "fliehst", "die\u00b7sen", "Nar\u00b7ren\u00b7Tand", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PDAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Dir ists l\u00e4ngstens schon bekannt,", "tokens": ["Dir", "ists", "l\u00e4ngs\u00b7tens", "schon", "be\u00b7kannt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Also wirst du auch bey Zeiten", "tokens": ["Al\u00b7so", "wirst", "du", "auch", "bey", "Zei\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Dieser Falschen Thun vermeiden.", "tokens": ["Die\u00b7ser", "Fal\u00b7schen", "Thun", "ver\u00b7mei\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDAT", "ADJA", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}}}}