{"textgrid.poem.62635": {"metadata": {"author": {"name": "Z\u00e4unemann, Sidonia Hedwig", "birth": "N.A.", "death": "N.A."}, "title": "Auf Herrn Magister Kunads Namens-Tag", "genre": "verse", "period": "N.A.", "pub_year": 1727, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Bellonens stolz- und k\u00fchner Mund", "tokens": ["Bel\u00b7lo\u00b7nens", "stolz", "und", "k\u00fch\u00b7ner", "Mund"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "TRUNC", "KON", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Spricht oft mit Hochmuths-vollen Mienen:", "tokens": ["Spricht", "oft", "mit", "Hoch\u00b7muths\u00b7vol\u00b7len", "Mie\u00b7nen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Durch mich wird jedes Herz verwundt,", "tokens": ["Durch", "mich", "wird", "je\u00b7des", "Herz", "ver\u00b7wundt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VAFIN", "PIAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mit Ehrfurcht sucht man mir zu dienen.", "tokens": ["Mit", "Ehr\u00b7furcht", "sucht", "man", "mir", "zu", "die\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PIS", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Sie ruft: Sophiens Kinder-Chor", "tokens": ["Sie", "ruft", ":", "So\u00b7phi\u00b7ens", "Kin\u00b7der\u00b7Chor"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["PPER", "VVFIN", "$.", "NE", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Geht meinen S\u00f6hnen niemahls vor.", "tokens": ["Geht", "mei\u00b7nen", "S\u00f6h\u00b7nen", "nie\u00b7mahls", "vor", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Bellona schweig! la\u00df die\u00df nicht h\u00f6ren.", "tokens": ["Bel\u00b7lo\u00b7na", "schweig", "!", "la\u00df", "die\u00df", "nicht", "h\u00f6\u00b7ren", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "$.", "VVIMP", "PDS", "PTKNEG", "VVINF", "$."], "meter": "+---+--+-", "measure": "trochaic.tri.relaxed"}, "line.8": {"text": "Ich r\u00fchme deiner Diener Schaar;", "tokens": ["Ich", "r\u00fch\u00b7me", "dei\u00b7ner", "Die\u00b7ner", "Schaar", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Und gleichwohl sag ich offenbar:", "tokens": ["Und", "gleich\u00b7wohl", "sag", "ich", "of\u00b7fen\u00b7bar", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Man mu\u00df weit mehr Sophien h\u00f6ren.", "tokens": ["Man", "mu\u00df", "weit", "mehr", "So\u00b7phi\u00b7en", "h\u00f6\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "ADJD", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Man kan den Namen, tapfrer Held,", "tokens": ["Man", "kan", "den", "Na\u00b7men", ",", "tapf\u00b7rer", "Held", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "ART", "NN", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Durch k\u00fchne Faust durch Sto\u00df und Waffen,", "tokens": ["Durch", "k\u00fch\u00b7ne", "Faust", "durch", "Sto\u00df", "und", "Waf\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "In der Belagrung und im Feld,", "tokens": ["In", "der", "Be\u00b7la\u00b7grung", "und", "im", "Feld", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "KON", "APPRART", "NN", "$,"], "meter": "+--++--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Bey einer Schlacht sich leicht verschaffen;", "tokens": ["Bey", "ei\u00b7ner", "Schlacht", "sich", "leicht", "ver\u00b7schaf\u00b7fen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PRF", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Wie oft bringt die Verzweifelung,", "tokens": ["Wie", "oft", "bringt", "die", "Ver\u00b7zwei\u00b7fe\u00b7lung", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "VVFIN", "ART", "NN", "$,"], "meter": "-++--+--", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Dem Herzen eine Aenderung:", "tokens": ["Dem", "Her\u00b7zen", "ei\u00b7ne", "A\u00b7en\u00b7de\u00b7rung", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$."], "meter": "-+-+--+--", "measure": "iambic.tri.relaxed"}, "line.7": {"text": "Man eilet mit verwegnen Sinnen", "tokens": ["Man", "ei\u00b7let", "mit", "ver\u00b7weg\u00b7nen", "Sin\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Bellonens Opfer-Heerd zu sehn,", "tokens": ["Bel\u00b7lo\u00b7nens", "Op\u00b7fer\u00b7He\u00b7erd", "zu", "sehn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "PTKZU", "VVINF", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.9": {"text": "Und Andachts-voll davor zu stehn,", "tokens": ["Und", "An\u00b7dachts\u00b7voll", "da\u00b7vor", "zu", "stehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "PAV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Den Helden-Namen zu gewinnen.", "tokens": ["Den", "Hel\u00b7den\u00b7Na\u00b7men", "zu", "ge\u00b7win\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Verzweiflung mehrt der Helden-Zahl,", "tokens": ["Ver\u00b7zwei\u00b7flung", "mehrt", "der", "Hel\u00b7den\u00b7Zahl", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein b\u00f6ser Sinn macht viel Soldaten.", "tokens": ["Ein", "b\u00f6\u00b7ser", "Sinn", "macht", "viel", "Sol\u00b7da\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PIAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Man siehet ja unzehlich mahl,", "tokens": ["Man", "sie\u00b7het", "ja", "un\u00b7zeh\u00b7lich", "mahl", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ADV", "ADJD", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wie viel auf diesen Schlu\u00df gerathen:", "tokens": ["Wie", "viel", "auf", "die\u00b7sen", "Schlu\u00df", "ge\u00b7ra\u00b7then", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "APPR", "PDAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Doch bey Sophien gehts nicht an,", "tokens": ["Doch", "bey", "So\u00b7phi\u00b7en", "gehts", "nicht", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NE", "VVFIN", "PTKNEG", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Kein Mensch darf sich derselben nah'n,", "tokens": ["Kein", "Mensch", "darf", "sich", "der\u00b7sel\u00b7ben", "nah'n", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VMFIN", "PRF", "PDAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Den die Verzweiflung eingenommen.", "tokens": ["Den", "die", "Ver\u00b7zwei\u00b7flung", "ein\u00b7ge\u00b7nom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Was folgt? Sophiens treuer Knecht,", "tokens": ["Was", "folgt", "?", "So\u00b7phi\u00b7ens", "treu\u00b7er", "Knecht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "$.", "NE", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Mu\u00df \u00fcberall das Vorzugs-Recht", "tokens": ["Mu\u00df", "\u00fc\u00b7be\u00b7rall", "das", "Vor\u00b7zugs\u00b7Recht"], "token_info": ["word", "word", "word", "word"], "pos": ["VMFIN", "ADV", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Vor einen tapfern Held bekommen.", "tokens": ["Vor", "ei\u00b7nen", "tap\u00b7fern", "Held", "be\u00b7kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Trotz immer zu, du Helden-Geist,", "tokens": ["Trotz", "im\u00b7mer", "zu", ",", "du", "Hel\u00b7den\u00b7Geist", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ADV", "PTKVZ", "$,", "PPER", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Auf M\u00fch und Schwei\u00df und Streit und Wachen.", "tokens": ["Auf", "M\u00fch", "und", "Schwei\u00df", "und", "Streit", "und", "Wa\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "KON", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Ich schw\u00f6re, wer ein Weiser heist,", "tokens": ["Ich", "schw\u00f6\u00b7re", ",", "wer", "ein", "Wei\u00b7ser", "heist", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PWS", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der l\u00e4chelt \u00fcber diese Sachen.", "tokens": ["Der", "l\u00e4\u00b7chelt", "\u00fc\u00b7ber", "die\u00b7se", "Sa\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPR", "PDAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Wie viele Jahre bringt man zu;", "tokens": ["Wie", "vie\u00b7le", "Jah\u00b7re", "bringt", "man", "zu", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIAT", "NN", "VVFIN", "PIS", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wie oft verk\u00fcrzt man seine Ruh;", "tokens": ["Wie", "oft", "ver\u00b7k\u00fcrzt", "man", "sei\u00b7ne", "Ruh", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "VVFIN", "PIS", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Wie viele B\u00fccher mu\u00df man wissen;", "tokens": ["Wie", "vie\u00b7le", "B\u00fc\u00b7cher", "mu\u00df", "man", "wis\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIAT", "NN", "VMFIN", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Wie mancher Wort-Streit stellt sich ein,", "tokens": ["Wie", "man\u00b7cher", "Wor\u00b7tStreit", "stellt", "sich", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIAT", "NN", "VVFIN", "PRF", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Bevor wir in dem Stande seyn,", "tokens": ["Be\u00b7vor", "wir", "in", "dem", "Stan\u00b7de", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ART", "NN", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Sophiens Purpur-Saum zu k\u00fcssen?", "tokens": ["So\u00b7phi\u00b7ens", "Pur\u00b7pur\u00b7Saum", "zu", "k\u00fcs\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Doch wird ihr sch\u00f6ner Hermelin", "tokens": ["Doch", "wird", "ihr", "sch\u00f6\u00b7ner", "Her\u00b7me\u00b7lin"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Oft durch das St\u00fcmper-Volk beflecket.", "tokens": ["Oft", "durch", "das", "St\u00fcm\u00b7per\u00b7Volk", "be\u00b7fle\u00b7cket", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Viel wollen ihr den Ruhm entziehn,", "tokens": ["Viel", "wol\u00b7len", "ihr", "den", "Ruhm", "ent\u00b7ziehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Weil sie den Thorheits-Grund entdecket.", "tokens": ["Weil", "sie", "den", "Thor\u00b7heits\u00b7Grund", "ent\u00b7de\u00b7cket", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Ihr L\u00e4strer der Philosophie,", "tokens": ["Ihr", "L\u00e4st\u00b7rer", "der", "Phi\u00b7lo\u00b7so\u00b7phie", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Schweigt! geht und beuget eure Knie", "tokens": ["Schweigt", "!", "geht", "und", "beu\u00b7get", "eu\u00b7re", "Knie"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "$.", "VVFIN", "KON", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Vor ihrem hoch-erhabnen Sitze;", "tokens": ["Vor", "ih\u00b7rem", "hoch\u00b7er\u00b7hab\u00b7nen", "Sit\u00b7ze", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Was nutzt das L\u00e4stern ohn Versuch;", "tokens": ["Was", "nutzt", "das", "L\u00e4s\u00b7tern", "ohn", "Ver\u00b7such", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ART", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Thut einen Blick ins Biebel-Buch,", "tokens": ["Thut", "ei\u00b7nen", "Blick", "ins", "Bie\u00b7bel\u00b7Buch", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ART", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Und merkt, worzu die Weisheit n\u00fctze.", "tokens": ["Und", "merkt", ",", "wor\u00b7zu", "die", "Weis\u00b7heit", "n\u00fct\u00b7ze", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "PWAV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Hier seht ihr, wie das Licht der Welt,", "tokens": ["Hier", "seht", "ihr", ",", "wie", "das", "Licht", "der", "Welt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "PWAV", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wenn seine Gegner S\u00e4tze brachten,", "tokens": ["Wenn", "sei\u00b7ne", "Geg\u00b7ner", "S\u00e4t\u00b7ze", "brach\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "(die mancher Thor vor gr\u00fcndlich h\u00e4lt,)", "tokens": ["(", "die", "man\u00b7cher", "Thor", "vor", "gr\u00fcnd\u00b7lich", "h\u00e4lt", ",", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ART", "PIAT", "NN", "APPR", "ADJD", "VVFIN", "$,", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Damit sie ihn zu Schanden machten;", "tokens": ["Da\u00b7mit", "sie", "ihn", "zu", "Schan\u00b7den", "mach\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Wie er sie, sag ich, \u00fcberf\u00fchrt,", "tokens": ["Wie", "er", "sie", ",", "sag", "ich", ",", "\u00fc\u00b7berf\u00b7\u00fchrt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["PWAV", "PPER", "PPER", "$,", "VVFIN", "PPER", "$,", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Mit Gottes Wort, das kr\u00e4ftig r\u00fchrt,", "tokens": ["Mit", "Got\u00b7tes", "Wort", ",", "das", "kr\u00e4f\u00b7tig", "r\u00fchrt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "NN", "$,", "PRELS", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Wie auch mit Philosophschen Gr\u00fcnden.", "tokens": ["Wie", "auch", "mit", "Phi\u00b7lo\u00b7soph\u00b7schen", "Gr\u00fcn\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Seht nur des Heylands Vortrag an,", "tokens": ["Seht", "nur", "des", "Hey\u00b7lands", "Vor\u00b7trag", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Wie er so b\u00fcndig schliessen kan;", "tokens": ["Wie", "er", "so", "b\u00fcn\u00b7dig", "schlies\u00b7sen", "kan", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "ADJD", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Wer mag wohl einen Fehler finden?", "tokens": ["Wer", "mag", "wohl", "ei\u00b7nen", "Feh\u00b7ler", "fin\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Der Heyden Lehrer Paulus zeugt,", "tokens": ["Der", "Hey\u00b7den", "Leh\u00b7rer", "Pau\u00b7lus", "zeugt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Er habe bey des Geistes Gaben,", "tokens": ["Er", "ha\u00b7be", "bey", "des", "Geis\u00b7tes", "Ga\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Die Weisheit, so die Herzen neigt,", "tokens": ["Die", "Weis\u00b7heit", ",", "so", "die", "Her\u00b7zen", "neigt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Nicht ausgetilget, noch vergraben.", "tokens": ["Nicht", "aus\u00b7ge\u00b7til\u00b7get", ",", "noch", "ver\u00b7gra\u00b7ben", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PTKNEG", "VVFIN", "$,", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Wie mancher tolle Secten Schwarm", "tokens": ["Wie", "man\u00b7cher", "tol\u00b7le", "Sec\u00b7ten", "Schwarm"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "PIAT", "ADJA", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Fiel durch des klugen Lehrers Arm,", "tokens": ["Fiel", "durch", "des", "klu\u00b7gen", "Leh\u00b7rers", "Arm", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Der sich mit Weisheit ausger\u00fcstet.", "tokens": ["Der", "sich", "mit", "Weis\u00b7heit", "aus\u00b7ge\u00b7r\u00fcs\u00b7tet", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "So, da\u00df der Feind das Feld verlie\u00df,", "tokens": ["So", ",", "da\u00df", "der", "Feind", "das", "Feld", "ver\u00b7lie\u00df", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "ART", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "So bald er seinen Satz bewie\u00df,", "tokens": ["So", "bald", "er", "sei\u00b7nen", "Satz", "be\u00b7wie\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "So sehr er sich zuvor gebr\u00fcstet.", "tokens": ["So", "sehr", "er", "sich", "zu\u00b7vor", "ge\u00b7br\u00fcs\u00b7tet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "PRF", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Wo gr\u00fcndliche Gelehrsamkeit", "tokens": ["Wo", "gr\u00fcnd\u00b7li\u00b7che", "Ge\u00b7lehr\u00b7sam\u00b7keit"], "token_info": ["word", "word", "word"], "pos": ["PWAV", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Kirchen-V\u00e4ter Herz nicht f\u00fchret,", "tokens": ["Der", "Kir\u00b7chen\u00b7V\u00e4\u00b7ter", "Herz", "nicht", "f\u00fch\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Da glaubt der Feind zu jederzeit,", "tokens": ["Da", "glaubt", "der", "Feind", "zu", "je\u00b7der\u00b7zeit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPR", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Da\u00df seine Thorheit triumphiret.", "tokens": ["Da\u00df", "sei\u00b7ne", "Thor\u00b7heit", "tri\u00b7um\u00b7phi\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Er meint, der falschen Lehren-Zahl,", "tokens": ["Er", "meint", ",", "der", "fal\u00b7schen", "Leh\u00b7ren\u00b7Zahl", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Sey ihm noch nicht ein einzig mahl", "tokens": ["Sey", "ihm", "noch", "nicht", "ein", "ein\u00b7zig", "mahl"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "ADV", "PTKNEG", "ART", "ADJD", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Gezeigt, erkl\u00e4rt und aufgedecket.", "tokens": ["Ge\u00b7zeigt", ",", "er\u00b7kl\u00e4rt", "und", "auf\u00b7ge\u00b7de\u00b7cket", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "VVPP", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "So lang man nicht Beweise bringt,", "tokens": ["So", "lang", "man", "nicht", "Be\u00b7wei\u00b7se", "bringt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PIS", "PTKNEG", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Und seinen Feind dadurch bezwingt,", "tokens": ["Und", "sei\u00b7nen", "Feind", "da\u00b7durch", "be\u00b7zwingt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "PAV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "So wird er niemahls abgeschrecket.", "tokens": ["So", "wird", "er", "nie\u00b7mahls", "ab\u00b7ge\u00b7schre\u00b7cket", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Ruhm, Vortheil, Nutzen, Heil und Gl\u00fcck", "tokens": ["Ruhm", ",", "Vor\u00b7theil", ",", "Nut\u00b7zen", ",", "Heil", "und", "Gl\u00fcck"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "NN", "$,", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Kan die\u00df der Kirch zu wege bringen!", "tokens": ["Kan", "die\u00df", "der", "Kirch", "zu", "we\u00b7ge", "brin\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PDS", "ART", "NN", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Der b\u00f6se Sinn, der Bo\u00dfheit Strick,", "tokens": ["Der", "b\u00f6\u00b7se", "Sinn", ",", "der", "Bo\u00df\u00b7heit", "Strick", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wird aufgel\u00f6\u00dft und mu\u00df zerspringen.", "tokens": ["Wird", "auf\u00b7ge\u00b7l\u00f6\u00dft", "und", "mu\u00df", "zer\u00b7sprin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "VVPP", "KON", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Hierdurch mehrt sich der Weisen Zunft.", "tokens": ["Hier\u00b7durch", "mehrt", "sich", "der", "Wei\u00b7sen", "Zunft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PRF", "ART", "NN", "NN", "$."], "meter": "-+---+-+", "measure": "dactylic.init"}, "line.6": {"text": "Die edle Freyheit der Vernunft,", "tokens": ["Die", "ed\u00b7le", "Frey\u00b7heit", "der", "Ver\u00b7nunft", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Giebt Anla\u00df vieles zuergr\u00fcnden.", "tokens": ["Giebt", "An\u00b7la\u00df", "vie\u00b7les", "zu\u00b7er\u00b7gr\u00fcn\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Wer recht und gr\u00fcndlich schliesen kan", "tokens": ["Wer", "recht", "und", "gr\u00fcnd\u00b7lich", "schlie\u00b7sen", "kan"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "ADJD", "KON", "ADJD", "VVINF", "VMFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Nimt alles nach der Wahrheit an,", "tokens": ["Nimt", "al\u00b7les", "nach", "der", "Wahr\u00b7heit", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "APPR", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Und l\u00e4\u00dft sich nicht die Augen binden.", "tokens": ["Und", "l\u00e4\u00dft", "sich", "nicht", "die", "Au\u00b7gen", "bin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "PTKNEG", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Es wird durch die Gelehrsamkeit", "tokens": ["Es", "wird", "durch", "die", "Ge\u00b7lehr\u00b7sam\u00b7keit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das Wort des H\u00f6chsten rein erkl\u00e4ret,", "tokens": ["Das", "Wort", "des", "H\u00f6chs\u00b7ten", "rein", "er\u00b7kl\u00e4\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Die Ordnung und Bescheidenheit,", "tokens": ["Die", "Ord\u00b7nung", "und", "Be\u00b7schei\u00b7den\u00b7heit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wird nimmermehr dadurch gest\u00f6hret.", "tokens": ["Wird", "nim\u00b7mer\u00b7mehr", "da\u00b7durch", "ge\u00b7st\u00f6h\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PAV", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Durch sie erliegt der Feinde Schaar;", "tokens": ["Durch", "sie", "er\u00b7liegt", "der", "Fein\u00b7de", "Schaar", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVFIN", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wo nicht, so wird doch offenbar,", "tokens": ["Wo", "nicht", ",", "so", "wird", "doch", "of\u00b7fen\u00b7bar", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PTKNEG", "$,", "ADV", "VAFIN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Da\u00df ihre Macht sehr abgenommen.", "tokens": ["Da\u00df", "ih\u00b7re", "Macht", "sehr", "ab\u00b7ge\u00b7nom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Wer sie mit reinen Herzen liebt,", "tokens": ["Wer", "sie", "mit", "rei\u00b7nen", "Her\u00b7zen", "liebt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Und sich in ihren Lehren \u00fcbt,", "tokens": ["Und", "sich", "in", "ih\u00b7ren", "Leh\u00b7ren", "\u00fcbt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Kan auf den h\u00f6chsten Gipfel kommen.", "tokens": ["Kan", "auf", "den", "h\u00f6chs\u00b7ten", "Gip\u00b7fel", "kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "APPR", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Ihr Philosophen alter Zeit!", "tokens": ["Ihr", "Phi\u00b7lo\u00b7so\u00b7phen", "al\u00b7ter", "Zeit", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wie nah kommt ihr der Christen Lehre?", "tokens": ["Wie", "nah", "kommt", "ihr", "der", "Chris\u00b7ten", "Leh\u00b7re", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VVFIN", "PPER", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Man kennet eure W\u00fcrdigkeit", "tokens": ["Man", "ken\u00b7net", "eu\u00b7re", "W\u00fcr\u00b7dig\u00b7keit"], "token_info": ["word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und darum schm\u00fcckt euch Ruhm und Ehre.", "tokens": ["Und", "da\u00b7rum", "schm\u00fcckt", "euch", "Ruhm", "und", "Eh\u00b7re", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PAV", "VVFIN", "PPER", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Hat eure Rede nicht mit Macht,", "tokens": ["Hat", "eu\u00b7re", "Re\u00b7de", "nicht", "mit", "Macht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "PTKNEG", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Die Be\u00dfrung derer Sitten bracht?", "tokens": ["Die", "Be\u00df\u00b7rung", "de\u00b7rer", "Sit\u00b7ten", "bracht", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PDS", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Ihr Stoicker gebt ein Exempel", "tokens": ["Ihr", "Stoi\u00b7cker", "gebt", "ein", "Ex\u00b7em\u00b7pel"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Der Herzen, die kein irdisch Gut", "tokens": ["Der", "Her\u00b7zen", ",", "die", "kein", "ir\u00b7disch", "Gut"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Bezwingt. O fest gesetzter Muth!", "tokens": ["Be\u00b7zwingt", ".", "O", "fest", "ge\u00b7setz\u00b7ter", "Muth", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$.", "NE", "ADJD", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Ihr unterst\u00fctzt den Weisheits-Tempel.", "tokens": ["Ihr", "un\u00b7ter\u00b7st\u00fctzt", "den", "Weis\u00b7heits\u00b7Tem\u00b7pel", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "La\u00df Pittacus, la\u00df Seneca,", "tokens": ["La\u00df", "Pit\u00b7ta\u00b7cus", ",", "la\u00df", "Se\u00b7ne\u00b7ca", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["VVIMP", "NE", "$,", "VVIMP", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "La\u00df Socrates dich kl\u00e4rlich sehen.", "tokens": ["La\u00df", "So\u00b7cra\u00b7tes", "dich", "kl\u00e4r\u00b7lich", "se\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "NE", "PPER", "ADJD", "VVINF", "$."], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "Ihr kommt den Lehren oft sehr nah,", "tokens": ["Ihr", "kommt", "den", "Leh\u00b7ren", "oft", "sehr", "nah", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADV", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die in dem heilgen Buche stehen.", "tokens": ["Die", "in", "dem", "heil\u00b7gen", "Bu\u00b7che", "ste\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Cratippi werthes Garten-Werk,", "tokens": ["Cra\u00b7tip\u00b7pi", "wert\u00b7hes", "Gar\u00b7ten\u00b7Werk", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "War des Pompeji Augenmerk,", "tokens": ["War", "des", "Pom\u00b7pe\u00b7ji", "Au\u00b7gen\u00b7merk", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und ward durch jenes s\u00fcsse Worte", "tokens": ["Und", "ward", "durch", "je\u00b7nes", "s\u00fcs\u00b7se", "Wor\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "APPR", "PDAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Fast in ein Paradie\u00df verkehrt;", "tokens": ["Fast", "in", "ein", "Pa\u00b7ra\u00b7die\u00df", "ver\u00b7kehrt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Ihr Weisen, was ihr sonst gelehrt,", "tokens": ["Ihr", "Wei\u00b7sen", ",", "was", "ihr", "sonst", "ge\u00b7lehrt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PWS", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Das liebt man noch an jedem Orte.", "tokens": ["Das", "liebt", "man", "noch", "an", "je\u00b7dem", "Or\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PIS", "ADV", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Durch eure Weisheit forschet ihr", "tokens": ["Durch", "eu\u00b7re", "Weis\u00b7heit", "for\u00b7schet", "ihr"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Nach dem, der was aus nichts bereitet.", "tokens": ["Nach", "dem", ",", "der", "was", "aus", "nichts", "be\u00b7rei\u00b7tet", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "$,", "PRELS", "PIS", "APPR", "PIS", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Ihr Morgen-L\u00e4nder kommt herf\u00fcr,", "tokens": ["Ihr", "Mor\u00b7gen\u00b7L\u00e4n\u00b7der", "kommt", "her\u00b7f\u00fcr", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und saget, was der Stern bedeutet,", "tokens": ["Und", "sa\u00b7get", ",", "was", "der", "Stern", "be\u00b7deu\u00b7tet", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "PRELS", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Den ihr in eurem Land gesehn!", "tokens": ["Den", "ihr", "in", "eu\u00b7rem", "Land", "ge\u00b7sehn", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ihr m\u00fc\u00dft darauf nach Salem gehn,", "tokens": ["Ihr", "m\u00fc\u00dft", "da\u00b7rauf", "nach", "Sa\u00b7lem", "gehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PAV", "APPR", "NE", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Ihr kommt und fragt, wo in der Wiege,", "tokens": ["Ihr", "kommt", "und", "fragt", ",", "wo", "in", "der", "Wie\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "$,", "PWAV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Der Griechen und der Heyden Heil,", "tokens": ["Der", "Grie\u00b7chen", "und", "der", "Hey\u00b7den", "Heil", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Der S\u00fcnder Trost, der Frommen Theil,", "tokens": ["Der", "S\u00fcn\u00b7der", "Trost", ",", "der", "From\u00b7men", "Theil", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$,", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Der neugebohrne K\u00f6nig liege?", "tokens": ["Der", "neu\u00b7ge\u00b7bohr\u00b7ne", "K\u00f6\u00b7nig", "lie\u00b7ge", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "O Dioni\u00df! dein Herze schlo\u00df", "tokens": ["O", "Dio\u00b7ni\u00df", "!", "dein", "Her\u00b7ze", "schlo\u00df"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["NE", "NN", "$.", "PPOSAT", "NN", "VVFIN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Als du den Nebel wahrgenommen,", "tokens": ["Als", "du", "den", "Ne\u00b7bel", "wahr\u00b7ge\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "(da Blut aus Christi Seite flo\u00df,", "tokens": ["(", "da", "Blut", "aus", "Chris\u00b7ti", "Sei\u00b7te", "flo\u00df", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "NN", "APPR", "NE", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und er ans Kreutzes-Stamm gekommen:)", "tokens": ["Und", "er", "ans", "Kreut\u00b7zes\u00b7Stamm", "ge\u00b7kom\u00b7men", ":)"], "token_info": ["word", "word", "word", "word", "word", "emoticon"], "pos": ["KON", "PPER", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Es m\u00fcsse bey dem duncklen Schein", "tokens": ["Es", "m\u00fcs\u00b7se", "bey", "dem", "dunck\u00b7len", "Schein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Der h\u00f6chste Gott be\u00e4ngstget seyn,", "tokens": ["Der", "h\u00f6chs\u00b7te", "Gott", "be\u00b7\u00e4ngst\u00b7get", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVPP", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und jetzt den Tod mit Schmerzen leiden.", "tokens": ["Und", "jetzt", "den", "Tod", "mit", "Schmer\u00b7zen", "lei\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Du ruftest deiner Weisen Schaar,", "tokens": ["Du", "ruf\u00b7test", "dei\u00b7ner", "Wei\u00b7sen", "Schaar", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Du sprachst: baut einen Beth-Altar,", "tokens": ["Du", "sprachst", ":", "baut", "ei\u00b7nen", "Beth\u00b7Al\u00b7tar", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Gott stirbt: er mu\u00df von hinnen scheiden.", "tokens": ["Gott", "stirbt", ":", "er", "mu\u00df", "von", "hin\u00b7nen", "schei\u00b7den", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "$.", "PPER", "VMFIN", "APPR", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "Kein Fall, kein Ungl\u00fcck, Angst, noch Noth", "tokens": ["Kein", "Fall", ",", "kein", "Un\u00b7gl\u00fcck", ",", "Angst", ",", "noch", "Noth"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["PIAT", "NN", "$,", "PIAT", "NN", "$,", "NN", "$,", "ADV", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Macht weiser Leute Herzen m\u00fcrbe.", "tokens": ["Macht", "wei\u00b7ser", "Leu\u00b7te", "Her\u00b7zen", "m\u00fcr\u00b7be", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJA", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Wenn das Verh\u00e4ngni\u00df schm\u00e4ht und droht,", "tokens": ["Wenn", "das", "Ver\u00b7h\u00e4ng\u00b7ni\u00df", "schm\u00e4ht", "und", "droht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So w\u00fcnscht doch keiner, da\u00df er st\u00fcrbe;", "tokens": ["So", "w\u00fcnscht", "doch", "kei\u00b7ner", ",", "da\u00df", "er", "st\u00fcr\u00b7be", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "PIS", "$,", "KOUS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Ihr steht und lacht zu aller Pein,", "tokens": ["Ihr", "steht", "und", "lacht", "zu", "al\u00b7ler", "Pein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Nehmt Schierlings-Saft mit Freuden ein.", "tokens": ["Nehmt", "Schier\u00b7lings\u00b7Saft", "mit", "Freu\u00b7den", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "APPR", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Liegt Socrates in Todes-Z\u00fcgen,", "tokens": ["Liegt", "So\u00b7cra\u00b7tes", "in", "To\u00b7des\u00b7Z\u00fc\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "APPR", "NN", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.8": {"text": "So lehrt er noch, wie man mit Macht", "tokens": ["So", "lehrt", "er", "noch", ",", "wie", "man", "mit", "Macht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "$,", "PWAV", "PIS", "APPR", "NN"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.9": {"text": "Den Tod und seine Faust veracht.", "tokens": ["Den", "Tod", "und", "sei\u00b7ne", "Faust", "ver\u00b7acht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Die Furcht kunt \u00fcber ihn nicht siegen.", "tokens": ["Die", "Furcht", "kunt", "\u00fc\u00b7ber", "ihn", "nicht", "sie\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "APPR", "PPER", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "Schaut, wie Philippens Lust sich mehrt,", "tokens": ["Schaut", ",", "wie", "Phil\u00b7ip\u00b7pens", "Lust", "sich", "mehrt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PWAV", "NE", "NN", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dieweil sein Prinz zu solchen Stunden,", "tokens": ["Die\u00b7weil", "sein", "Prinz", "zu", "sol\u00b7chen", "Stun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Da Aristotels Zunge lehrt,", "tokens": ["Da", "A\u00b7ris\u00b7to\u00b7tels", "Zun\u00b7ge", "lehrt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sich auf der Erden eingefunden.", "tokens": ["Sich", "auf", "der", "Er\u00b7den", "ein\u00b7ge\u00b7fun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Die\u00df macht uns Alexanders Mund", "tokens": ["Die\u00df", "macht", "uns", "A\u00b7lex\u00b7an\u00b7ders", "Mund"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "PPER", "NE", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Durch seinen eignen Ausspruch kund.", "tokens": ["Durch", "sei\u00b7nen", "eig\u00b7nen", "Aus\u00b7spruch", "kund", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Er ehrte ihn, wie sichs geb\u00fchrte.", "tokens": ["Er", "ehr\u00b7te", "ihn", ",", "wie", "sichs", "ge\u00b7b\u00fchr\u00b7te", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$,", "PWAV", "PIS", "VVFIN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.8": {"text": "Er war ihm fast noch mehr geneigt,", "tokens": ["Er", "war", "ihm", "fast", "noch", "mehr", "ge\u00b7neigt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "ADV", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Als dem, der ihn vorher gezeugt,", "tokens": ["Als", "dem", ",", "der", "ihn", "vor\u00b7her", "ge\u00b7zeugt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "$,", "PRELS", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Dieweil er ihn zur Weisheit f\u00fchrte.", "tokens": ["Die\u00b7weil", "er", "ihn", "zur", "Weis\u00b7heit", "f\u00fchr\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.17": {"line.1": {"text": "Gedenke Cr\u00f6sus! doch nur nicht", "tokens": ["Ge\u00b7den\u00b7ke", "Cr\u00f6\u00b7sus", "!", "doch", "nur", "nicht"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["NN", "NE", "$.", "ADV", "ADV", "PTKNEG"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Den Philosophen h\u00f6nsch zu fluchen.", "tokens": ["Den", "Phi\u00b7lo\u00b7so\u00b7phen", "h\u00f6nsch", "zu", "flu\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Ihr Sinn, Verstand und Geistes-Licht,", "tokens": ["Ihr", "Sinn", ",", "Ver\u00b7stand", "und", "Geis\u00b7tes\u00b7Licht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "L\u00e4\u00dft sich mit R\u00e4tzeln nicht versuchen.", "tokens": ["L\u00e4\u00dft", "sich", "mit", "R\u00e4t\u00b7zeln", "nicht", "ver\u00b7su\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "APPR", "NN", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Halt Alexander! halt nur ein!", "tokens": ["Halt", "A\u00b7lex\u00b7an\u00b7der", "!", "halt", "nur", "ein", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVIMP", "NE", "$.", "VVFIN", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Die Weisen m\u00f6chten st\u00e4rker seyn;", "tokens": ["Die", "Wei\u00b7sen", "m\u00f6ch\u00b7ten", "st\u00e4r\u00b7ker", "seyn", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Erk\u00fchn dich nicht mit deinen Fragen:", "tokens": ["Er\u00b7k\u00fchn", "dich", "nicht", "mit", "dei\u00b7nen", "Fra\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKNEG", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Die Gordschen Knoten k\u00f6nnen sie", "tokens": ["Die", "Gord\u00b7schen", "Kno\u00b7ten", "k\u00f6n\u00b7nen", "sie"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VMFIN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Mit ihrer Weisheit, ohne M\u00fch,", "tokens": ["Mit", "ih\u00b7rer", "Weis\u00b7heit", ",", "oh\u00b7ne", "M\u00fch", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "KOUI", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Zergliedern und gar leicht zerschlagen.", "tokens": ["Zer\u00b7glie\u00b7dern", "und", "gar", "leicht", "zer\u00b7schla\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "ADV", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.18": {"line.1": {"text": "Euch Klugen hat das Alterthum,", "tokens": ["Euch", "Klu\u00b7gen", "hat", "das", "Al\u00b7ter\u00b7thum", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Viel Ehren-S\u00e4ulen aufgebauet;", "tokens": ["Viel", "Eh\u00b7ren\u00b7S\u00e4u\u00b7len", "auf\u00b7ge\u00b7bau\u00b7et", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "So, da\u00df man eures Namens Ruhm", "tokens": ["So", ",", "da\u00df", "man", "eu\u00b7res", "Na\u00b7mens", "Ruhm"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "$,", "KOUS", "PIS", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Nach euren Moder noch geschauet.", "tokens": ["Nach", "eu\u00b7ren", "Mo\u00b7der", "noch", "ge\u00b7schau\u00b7et", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Recht so! ihr seyd dergleichen werth,", "tokens": ["Recht", "so", "!", "ihr", "seyd", "derg\u00b7lei\u00b7chen", "werth", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "$.", "PPER", "VAFIN", "PIS", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Man thut was Billigkeit begehrt.", "tokens": ["Man", "thut", "was", "Bil\u00b7lig\u00b7keit", "be\u00b7gehrt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PIS", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Allein ihr Weisen unsrer Zeiten:", "tokens": ["Al\u00b7lein", "ihr", "Wei\u00b7sen", "uns\u00b7rer", "Zei\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Euch hat so manche sch\u00f6ne Schrift,", "tokens": ["Euch", "hat", "so", "man\u00b7che", "sch\u00f6\u00b7ne", "Schrift", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Ein gr\u00f6\u00dfres Ehren-Maal gestift:", "tokens": ["Ein", "gr\u00f6\u00df\u00b7res", "Eh\u00b7ren\u00b7Maal", "ge\u00b7stift", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Die\u00df kan euch h\u00f6hern Ruhm bereiten.", "tokens": ["Die\u00df", "kan", "euch", "h\u00f6\u00b7hern", "Ruhm", "be\u00b7rei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PPER", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.19": {"line.1": {"text": "Brich an erw\u00fcnschtes Tages-Licht!", "tokens": ["Brich", "an", "er\u00b7w\u00fcnschtes", "Ta\u00b7ges\u00b7Licht", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "ADJA", "NN", "$."], "meter": "+---+-+", "measure": "dactylic.init"}, "line.2": {"text": "Willkommen angenehmer Morgen!", "tokens": ["Will\u00b7kom\u00b7men", "an\u00b7ge\u00b7neh\u00b7mer", "Mor\u00b7gen", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "An dem Sophiens Zunge spricht;", "tokens": ["An", "dem", "So\u00b7phi\u00b7ens", "Zun\u00b7ge", "spricht", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Jetzt weis ich nichts von Angst und Sorgen:", "tokens": ["Jetzt", "weis", "ich", "nichts", "von", "Angst", "und", "Sor\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKVZ", "PPER", "PIS", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Denn ", "tokens": ["Denn"], "token_info": ["word"], "pos": ["KON"], "meter": "+", "measure": "single.up"}, "line.6": {"text": "Erblicket heut sein ", "tokens": ["Er\u00b7bli\u00b7cket", "heut", "sein"], "token_info": ["word", "word", "word"], "pos": ["VVFIN", "ADV", "PPOSAT"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.7": {"text": "Mein Sohn, von dem die kl\u00fcgsten M\u00e4nner", "tokens": ["Mein", "Sohn", ",", "von", "dem", "die", "kl\u00fcgs\u00b7ten", "M\u00e4n\u00b7ner"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "$,", "APPR", "PRELS", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Mit Wahrheit sagen: Dieser lehrt,", "tokens": ["Mit", "Wahr\u00b7heit", "sa\u00b7gen", ":", "Die\u00b7ser", "lehrt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "NN", "VVINF", "$.", "PDS", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Wie man mich w\u00fcrdiglich verehrt.", "tokens": ["Wie", "man", "mich", "w\u00fcr\u00b7dig\u00b7lich", "ver\u00b7ehrt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "PRF", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Er ist ein grosser Weisheits-Kenner.", "tokens": ["Er", "ist", "ein", "gros\u00b7ser", "Weis\u00b7heits\u00b7Ken\u00b7ner", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.20": {"line.1": {"text": "Wie labt mich die Philosophie!", "tokens": ["Wie", "labt", "mich", "die", "Phi\u00b7lo\u00b7so\u00b7phie", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wie reitzet mich dein k\u00fcnstlich Reimen!", "tokens": ["Wie", "reit\u00b7zet", "mich", "dein", "k\u00fcnst\u00b7lich", "Rei\u00b7men", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "PPOSAT", "ADJD", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Wohlan! so soll die Poesie,", "tokens": ["Wo\u00b7hlan", "!", "so", "soll", "die", "Poe\u00b7sie", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$.", "ADV", "VMFIN", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Die zwar noch roh, sich doch nicht s\u00e4umen:", "tokens": ["Die", "zwar", "noch", "roh", ",", "sich", "doch", "nicht", "s\u00e4u\u00b7men", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADV", "ADJD", "$,", "PRF", "ADV", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Wenn sie auf ", "tokens": ["Wenn", "sie", "auf"], "token_info": ["word", "word", "word"], "pos": ["KOUS", "PPER", "APPR"], "meter": "+-+", "measure": "trochaic.di"}, "line.6": {"text": "Dir ein Gedichte bringen mag,", "tokens": ["Dir", "ein", "Ge\u00b7dich\u00b7te", "brin\u00b7gen", "mag", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Komm, sieh mit g\u00fctgen Augen an,", "tokens": ["Komm", ",", "sieh", "mit", "g\u00fct\u00b7gen", "Au\u00b7gen", "an", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "VVIMP", "APPR", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Was ich aus Schuldigkeit gethan,", "tokens": ["Was", "ich", "aus", "Schul\u00b7dig\u00b7keit", "ge\u00b7than", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Und dir anjetzo zugeschrieben.", "tokens": ["Und", "dir", "an\u00b7je\u00b7tzo", "zu\u00b7ge\u00b7schrie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.21": {"line.1": {"text": "Was w\u00fcnsch ich? nein ich w\u00fcnsche nicht!", "tokens": ["Was", "w\u00fcnsch", "ich", "?", "nein", "ich", "w\u00fcn\u00b7sche", "nicht", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "$.", "PTKANT", "PPER", "VVFIN", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Denn, wer wie du die Weisheit liebet,", "tokens": ["Denn", ",", "wer", "wie", "du", "die", "Weis\u00b7heit", "lie\u00b7bet", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "PWS", "KOKOM", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Der schaut des Gl\u00fcckes Angesicht:", "tokens": ["Der", "schaut", "des", "Gl\u00fc\u00b7ckes", "An\u00b7ge\u00b7sicht", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sich durch sich selbst die Wohlfarth giebet.", "tokens": ["Sich", "durch", "sich", "selbst", "die", "Wohl\u00b7farth", "gie\u00b7bet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "PRF", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Zum Schlusse setzt Sidonia:", "tokens": ["Zum", "Schlus\u00b7se", "setzt", "Si\u00b7do\u00b7nia", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "NE", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.6": {"text": "Weil ", "tokens": ["Weil"], "token_info": ["word"], "pos": ["KOUS"], "meter": "+", "measure": "single.up"}, "line.7": {"text": "So wird mein Geist mit Lust umgeben:", "tokens": ["So", "wird", "mein", "Geist", "mit", "Lust", "um\u00b7ge\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPOSAT", "NN", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Sophia und das Musen-Chor", "tokens": ["So\u00b7phia", "und", "das", "Mu\u00b7sen\u00b7Chor"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "KON", "ART", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.9": {"text": "Geht mir in Lustbarkeiten vor:", "tokens": ["Geht", "mir", "in", "Lust\u00b7bar\u00b7kei\u00b7ten", "vor", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Man ruft: ", "tokens": ["Man", "ruft", ":"], "token_info": ["word", "word", "punct"], "pos": ["PIS", "VVFIN", "$."], "meter": "-+", "measure": "iambic.single"}}, "stanza.22": {"line.1": {"text": "Bellonens stolz- und k\u00fchner Mund", "tokens": ["Bel\u00b7lo\u00b7nens", "stolz", "und", "k\u00fch\u00b7ner", "Mund"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "TRUNC", "KON", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Spricht oft mit Hochmuths-vollen Mienen:", "tokens": ["Spricht", "oft", "mit", "Hoch\u00b7muths\u00b7vol\u00b7len", "Mie\u00b7nen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Durch mich wird jedes Herz verwundt,", "tokens": ["Durch", "mich", "wird", "je\u00b7des", "Herz", "ver\u00b7wundt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VAFIN", "PIAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mit Ehrfurcht sucht man mir zu dienen.", "tokens": ["Mit", "Ehr\u00b7furcht", "sucht", "man", "mir", "zu", "die\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PIS", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Sie ruft: Sophiens Kinder-Chor", "tokens": ["Sie", "ruft", ":", "So\u00b7phi\u00b7ens", "Kin\u00b7der\u00b7Chor"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["PPER", "VVFIN", "$.", "NE", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Geht meinen S\u00f6hnen niemahls vor.", "tokens": ["Geht", "mei\u00b7nen", "S\u00f6h\u00b7nen", "nie\u00b7mahls", "vor", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Bellona schweig! la\u00df die\u00df nicht h\u00f6ren.", "tokens": ["Bel\u00b7lo\u00b7na", "schweig", "!", "la\u00df", "die\u00df", "nicht", "h\u00f6\u00b7ren", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "$.", "VVIMP", "PDS", "PTKNEG", "VVINF", "$."], "meter": "+---+--+-", "measure": "trochaic.tri.relaxed"}, "line.8": {"text": "Ich r\u00fchme deiner Diener Schaar;", "tokens": ["Ich", "r\u00fch\u00b7me", "dei\u00b7ner", "Die\u00b7ner", "Schaar", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Und gleichwohl sag ich offenbar:", "tokens": ["Und", "gleich\u00b7wohl", "sag", "ich", "of\u00b7fen\u00b7bar", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Man mu\u00df weit mehr Sophien h\u00f6ren.", "tokens": ["Man", "mu\u00df", "weit", "mehr", "So\u00b7phi\u00b7en", "h\u00f6\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "ADJD", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.23": {"line.1": {"text": "Man kan den Namen, tapfrer Held,", "tokens": ["Man", "kan", "den", "Na\u00b7men", ",", "tapf\u00b7rer", "Held", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "ART", "NN", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Durch k\u00fchne Faust durch Sto\u00df und Waffen,", "tokens": ["Durch", "k\u00fch\u00b7ne", "Faust", "durch", "Sto\u00df", "und", "Waf\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "In der Belagrung und im Feld,", "tokens": ["In", "der", "Be\u00b7la\u00b7grung", "und", "im", "Feld", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "KON", "APPRART", "NN", "$,"], "meter": "+--++--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Bey einer Schlacht sich leicht verschaffen;", "tokens": ["Bey", "ei\u00b7ner", "Schlacht", "sich", "leicht", "ver\u00b7schaf\u00b7fen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PRF", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Wie oft bringt die Verzweifelung,", "tokens": ["Wie", "oft", "bringt", "die", "Ver\u00b7zwei\u00b7fe\u00b7lung", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "VVFIN", "ART", "NN", "$,"], "meter": "-++--+--", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Dem Herzen eine Aenderung:", "tokens": ["Dem", "Her\u00b7zen", "ei\u00b7ne", "A\u00b7en\u00b7de\u00b7rung", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$."], "meter": "-+-+--+--", "measure": "iambic.tri.relaxed"}, "line.7": {"text": "Man eilet mit verwegnen Sinnen", "tokens": ["Man", "ei\u00b7let", "mit", "ver\u00b7weg\u00b7nen", "Sin\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Bellonens Opfer-Heerd zu sehn,", "tokens": ["Bel\u00b7lo\u00b7nens", "Op\u00b7fer\u00b7He\u00b7erd", "zu", "sehn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "PTKZU", "VVINF", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.9": {"text": "Und Andachts-voll davor zu stehn,", "tokens": ["Und", "An\u00b7dachts\u00b7voll", "da\u00b7vor", "zu", "stehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "PAV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Den Helden-Namen zu gewinnen.", "tokens": ["Den", "Hel\u00b7den\u00b7Na\u00b7men", "zu", "ge\u00b7win\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.24": {"line.1": {"text": "Verzweiflung mehrt der Helden-Zahl,", "tokens": ["Ver\u00b7zwei\u00b7flung", "mehrt", "der", "Hel\u00b7den\u00b7Zahl", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein b\u00f6ser Sinn macht viel Soldaten.", "tokens": ["Ein", "b\u00f6\u00b7ser", "Sinn", "macht", "viel", "Sol\u00b7da\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PIAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Man siehet ja unzehlich mahl,", "tokens": ["Man", "sie\u00b7het", "ja", "un\u00b7zeh\u00b7lich", "mahl", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ADV", "ADJD", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wie viel auf diesen Schlu\u00df gerathen:", "tokens": ["Wie", "viel", "auf", "die\u00b7sen", "Schlu\u00df", "ge\u00b7ra\u00b7then", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "APPR", "PDAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Doch bey Sophien gehts nicht an,", "tokens": ["Doch", "bey", "So\u00b7phi\u00b7en", "gehts", "nicht", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NE", "VVFIN", "PTKNEG", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Kein Mensch darf sich derselben nah'n,", "tokens": ["Kein", "Mensch", "darf", "sich", "der\u00b7sel\u00b7ben", "nah'n", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VMFIN", "PRF", "PDAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Den die Verzweiflung eingenommen.", "tokens": ["Den", "die", "Ver\u00b7zwei\u00b7flung", "ein\u00b7ge\u00b7nom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Was folgt? Sophiens treuer Knecht,", "tokens": ["Was", "folgt", "?", "So\u00b7phi\u00b7ens", "treu\u00b7er", "Knecht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "$.", "NE", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Mu\u00df \u00fcberall das Vorzugs-Recht", "tokens": ["Mu\u00df", "\u00fc\u00b7be\u00b7rall", "das", "Vor\u00b7zugs\u00b7Recht"], "token_info": ["word", "word", "word", "word"], "pos": ["VMFIN", "ADV", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Vor einen tapfern Held bekommen.", "tokens": ["Vor", "ei\u00b7nen", "tap\u00b7fern", "Held", "be\u00b7kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.25": {"line.1": {"text": "Trotz immer zu, du Helden-Geist,", "tokens": ["Trotz", "im\u00b7mer", "zu", ",", "du", "Hel\u00b7den\u00b7Geist", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ADV", "PTKVZ", "$,", "PPER", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Auf M\u00fch und Schwei\u00df und Streit und Wachen.", "tokens": ["Auf", "M\u00fch", "und", "Schwei\u00df", "und", "Streit", "und", "Wa\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "KON", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Ich schw\u00f6re, wer ein Weiser heist,", "tokens": ["Ich", "schw\u00f6\u00b7re", ",", "wer", "ein", "Wei\u00b7ser", "heist", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PWS", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der l\u00e4chelt \u00fcber diese Sachen.", "tokens": ["Der", "l\u00e4\u00b7chelt", "\u00fc\u00b7ber", "die\u00b7se", "Sa\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPR", "PDAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Wie viele Jahre bringt man zu;", "tokens": ["Wie", "vie\u00b7le", "Jah\u00b7re", "bringt", "man", "zu", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIAT", "NN", "VVFIN", "PIS", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wie oft verk\u00fcrzt man seine Ruh;", "tokens": ["Wie", "oft", "ver\u00b7k\u00fcrzt", "man", "sei\u00b7ne", "Ruh", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "VVFIN", "PIS", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Wie viele B\u00fccher mu\u00df man wissen;", "tokens": ["Wie", "vie\u00b7le", "B\u00fc\u00b7cher", "mu\u00df", "man", "wis\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIAT", "NN", "VMFIN", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Wie mancher Wort-Streit stellt sich ein,", "tokens": ["Wie", "man\u00b7cher", "Wor\u00b7tStreit", "stellt", "sich", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIAT", "NN", "VVFIN", "PRF", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Bevor wir in dem Stande seyn,", "tokens": ["Be\u00b7vor", "wir", "in", "dem", "Stan\u00b7de", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ART", "NN", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Sophiens Purpur-Saum zu k\u00fcssen?", "tokens": ["So\u00b7phi\u00b7ens", "Pur\u00b7pur\u00b7Saum", "zu", "k\u00fcs\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.26": {"line.1": {"text": "Doch wird ihr sch\u00f6ner Hermelin", "tokens": ["Doch", "wird", "ihr", "sch\u00f6\u00b7ner", "Her\u00b7me\u00b7lin"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Oft durch das St\u00fcmper-Volk beflecket.", "tokens": ["Oft", "durch", "das", "St\u00fcm\u00b7per\u00b7Volk", "be\u00b7fle\u00b7cket", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Viel wollen ihr den Ruhm entziehn,", "tokens": ["Viel", "wol\u00b7len", "ihr", "den", "Ruhm", "ent\u00b7ziehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Weil sie den Thorheits-Grund entdecket.", "tokens": ["Weil", "sie", "den", "Thor\u00b7heits\u00b7Grund", "ent\u00b7de\u00b7cket", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Ihr L\u00e4strer der Philosophie,", "tokens": ["Ihr", "L\u00e4st\u00b7rer", "der", "Phi\u00b7lo\u00b7so\u00b7phie", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Schweigt! geht und beuget eure Knie", "tokens": ["Schweigt", "!", "geht", "und", "beu\u00b7get", "eu\u00b7re", "Knie"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "$.", "VVFIN", "KON", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Vor ihrem hoch-erhabnen Sitze;", "tokens": ["Vor", "ih\u00b7rem", "hoch\u00b7er\u00b7hab\u00b7nen", "Sit\u00b7ze", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Was nutzt das L\u00e4stern ohn Versuch;", "tokens": ["Was", "nutzt", "das", "L\u00e4s\u00b7tern", "ohn", "Ver\u00b7such", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ART", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Thut einen Blick ins Biebel-Buch,", "tokens": ["Thut", "ei\u00b7nen", "Blick", "ins", "Bie\u00b7bel\u00b7Buch", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ART", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Und merkt, worzu die Weisheit n\u00fctze.", "tokens": ["Und", "merkt", ",", "wor\u00b7zu", "die", "Weis\u00b7heit", "n\u00fct\u00b7ze", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "PWAV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.27": {"line.1": {"text": "Hier seht ihr, wie das Licht der Welt,", "tokens": ["Hier", "seht", "ihr", ",", "wie", "das", "Licht", "der", "Welt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "PWAV", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wenn seine Gegner S\u00e4tze brachten,", "tokens": ["Wenn", "sei\u00b7ne", "Geg\u00b7ner", "S\u00e4t\u00b7ze", "brach\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "(die mancher Thor vor gr\u00fcndlich h\u00e4lt,)", "tokens": ["(", "die", "man\u00b7cher", "Thor", "vor", "gr\u00fcnd\u00b7lich", "h\u00e4lt", ",", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ART", "PIAT", "NN", "APPR", "ADJD", "VVFIN", "$,", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Damit sie ihn zu Schanden machten;", "tokens": ["Da\u00b7mit", "sie", "ihn", "zu", "Schan\u00b7den", "mach\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Wie er sie, sag ich, \u00fcberf\u00fchrt,", "tokens": ["Wie", "er", "sie", ",", "sag", "ich", ",", "\u00fc\u00b7berf\u00b7\u00fchrt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["PWAV", "PPER", "PPER", "$,", "VVFIN", "PPER", "$,", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Mit Gottes Wort, das kr\u00e4ftig r\u00fchrt,", "tokens": ["Mit", "Got\u00b7tes", "Wort", ",", "das", "kr\u00e4f\u00b7tig", "r\u00fchrt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "NN", "$,", "PRELS", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Wie auch mit Philosophschen Gr\u00fcnden.", "tokens": ["Wie", "auch", "mit", "Phi\u00b7lo\u00b7soph\u00b7schen", "Gr\u00fcn\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Seht nur des Heylands Vortrag an,", "tokens": ["Seht", "nur", "des", "Hey\u00b7lands", "Vor\u00b7trag", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Wie er so b\u00fcndig schliessen kan;", "tokens": ["Wie", "er", "so", "b\u00fcn\u00b7dig", "schlies\u00b7sen", "kan", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "ADJD", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Wer mag wohl einen Fehler finden?", "tokens": ["Wer", "mag", "wohl", "ei\u00b7nen", "Feh\u00b7ler", "fin\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.28": {"line.1": {"text": "Der Heyden Lehrer Paulus zeugt,", "tokens": ["Der", "Hey\u00b7den", "Leh\u00b7rer", "Pau\u00b7lus", "zeugt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Er habe bey des Geistes Gaben,", "tokens": ["Er", "ha\u00b7be", "bey", "des", "Geis\u00b7tes", "Ga\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Die Weisheit, so die Herzen neigt,", "tokens": ["Die", "Weis\u00b7heit", ",", "so", "die", "Her\u00b7zen", "neigt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Nicht ausgetilget, noch vergraben.", "tokens": ["Nicht", "aus\u00b7ge\u00b7til\u00b7get", ",", "noch", "ver\u00b7gra\u00b7ben", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PTKNEG", "VVFIN", "$,", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Wie mancher tolle Secten Schwarm", "tokens": ["Wie", "man\u00b7cher", "tol\u00b7le", "Sec\u00b7ten", "Schwarm"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "PIAT", "ADJA", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Fiel durch des klugen Lehrers Arm,", "tokens": ["Fiel", "durch", "des", "klu\u00b7gen", "Leh\u00b7rers", "Arm", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Der sich mit Weisheit ausger\u00fcstet.", "tokens": ["Der", "sich", "mit", "Weis\u00b7heit", "aus\u00b7ge\u00b7r\u00fcs\u00b7tet", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "So, da\u00df der Feind das Feld verlie\u00df,", "tokens": ["So", ",", "da\u00df", "der", "Feind", "das", "Feld", "ver\u00b7lie\u00df", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "ART", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "So bald er seinen Satz bewie\u00df,", "tokens": ["So", "bald", "er", "sei\u00b7nen", "Satz", "be\u00b7wie\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "So sehr er sich zuvor gebr\u00fcstet.", "tokens": ["So", "sehr", "er", "sich", "zu\u00b7vor", "ge\u00b7br\u00fcs\u00b7tet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "PRF", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.29": {"line.1": {"text": "Wo gr\u00fcndliche Gelehrsamkeit", "tokens": ["Wo", "gr\u00fcnd\u00b7li\u00b7che", "Ge\u00b7lehr\u00b7sam\u00b7keit"], "token_info": ["word", "word", "word"], "pos": ["PWAV", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Kirchen-V\u00e4ter Herz nicht f\u00fchret,", "tokens": ["Der", "Kir\u00b7chen\u00b7V\u00e4\u00b7ter", "Herz", "nicht", "f\u00fch\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Da glaubt der Feind zu jederzeit,", "tokens": ["Da", "glaubt", "der", "Feind", "zu", "je\u00b7der\u00b7zeit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPR", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Da\u00df seine Thorheit triumphiret.", "tokens": ["Da\u00df", "sei\u00b7ne", "Thor\u00b7heit", "tri\u00b7um\u00b7phi\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Er meint, der falschen Lehren-Zahl,", "tokens": ["Er", "meint", ",", "der", "fal\u00b7schen", "Leh\u00b7ren\u00b7Zahl", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Sey ihm noch nicht ein einzig mahl", "tokens": ["Sey", "ihm", "noch", "nicht", "ein", "ein\u00b7zig", "mahl"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "ADV", "PTKNEG", "ART", "ADJD", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Gezeigt, erkl\u00e4rt und aufgedecket.", "tokens": ["Ge\u00b7zeigt", ",", "er\u00b7kl\u00e4rt", "und", "auf\u00b7ge\u00b7de\u00b7cket", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "VVPP", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "So lang man nicht Beweise bringt,", "tokens": ["So", "lang", "man", "nicht", "Be\u00b7wei\u00b7se", "bringt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PIS", "PTKNEG", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Und seinen Feind dadurch bezwingt,", "tokens": ["Und", "sei\u00b7nen", "Feind", "da\u00b7durch", "be\u00b7zwingt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "PAV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "So wird er niemahls abgeschrecket.", "tokens": ["So", "wird", "er", "nie\u00b7mahls", "ab\u00b7ge\u00b7schre\u00b7cket", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.30": {"line.1": {"text": "Ruhm, Vortheil, Nutzen, Heil und Gl\u00fcck", "tokens": ["Ruhm", ",", "Vor\u00b7theil", ",", "Nut\u00b7zen", ",", "Heil", "und", "Gl\u00fcck"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "NN", "$,", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Kan die\u00df der Kirch zu wege bringen!", "tokens": ["Kan", "die\u00df", "der", "Kirch", "zu", "we\u00b7ge", "brin\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PDS", "ART", "NN", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Der b\u00f6se Sinn, der Bo\u00dfheit Strick,", "tokens": ["Der", "b\u00f6\u00b7se", "Sinn", ",", "der", "Bo\u00df\u00b7heit", "Strick", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wird aufgel\u00f6\u00dft und mu\u00df zerspringen.", "tokens": ["Wird", "auf\u00b7ge\u00b7l\u00f6\u00dft", "und", "mu\u00df", "zer\u00b7sprin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "VVPP", "KON", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Hierdurch mehrt sich der Weisen Zunft.", "tokens": ["Hier\u00b7durch", "mehrt", "sich", "der", "Wei\u00b7sen", "Zunft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PRF", "ART", "NN", "NN", "$."], "meter": "-+---+-+", "measure": "dactylic.init"}, "line.6": {"text": "Die edle Freyheit der Vernunft,", "tokens": ["Die", "ed\u00b7le", "Frey\u00b7heit", "der", "Ver\u00b7nunft", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Giebt Anla\u00df vieles zuergr\u00fcnden.", "tokens": ["Giebt", "An\u00b7la\u00df", "vie\u00b7les", "zu\u00b7er\u00b7gr\u00fcn\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Wer recht und gr\u00fcndlich schliesen kan", "tokens": ["Wer", "recht", "und", "gr\u00fcnd\u00b7lich", "schlie\u00b7sen", "kan"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "ADJD", "KON", "ADJD", "VVINF", "VMFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Nimt alles nach der Wahrheit an,", "tokens": ["Nimt", "al\u00b7les", "nach", "der", "Wahr\u00b7heit", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "APPR", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Und l\u00e4\u00dft sich nicht die Augen binden.", "tokens": ["Und", "l\u00e4\u00dft", "sich", "nicht", "die", "Au\u00b7gen", "bin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "PTKNEG", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.31": {"line.1": {"text": "Es wird durch die Gelehrsamkeit", "tokens": ["Es", "wird", "durch", "die", "Ge\u00b7lehr\u00b7sam\u00b7keit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das Wort des H\u00f6chsten rein erkl\u00e4ret,", "tokens": ["Das", "Wort", "des", "H\u00f6chs\u00b7ten", "rein", "er\u00b7kl\u00e4\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Die Ordnung und Bescheidenheit,", "tokens": ["Die", "Ord\u00b7nung", "und", "Be\u00b7schei\u00b7den\u00b7heit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wird nimmermehr dadurch gest\u00f6hret.", "tokens": ["Wird", "nim\u00b7mer\u00b7mehr", "da\u00b7durch", "ge\u00b7st\u00f6h\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PAV", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Durch sie erliegt der Feinde Schaar;", "tokens": ["Durch", "sie", "er\u00b7liegt", "der", "Fein\u00b7de", "Schaar", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVFIN", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wo nicht, so wird doch offenbar,", "tokens": ["Wo", "nicht", ",", "so", "wird", "doch", "of\u00b7fen\u00b7bar", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PTKNEG", "$,", "ADV", "VAFIN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Da\u00df ihre Macht sehr abgenommen.", "tokens": ["Da\u00df", "ih\u00b7re", "Macht", "sehr", "ab\u00b7ge\u00b7nom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Wer sie mit reinen Herzen liebt,", "tokens": ["Wer", "sie", "mit", "rei\u00b7nen", "Her\u00b7zen", "liebt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Und sich in ihren Lehren \u00fcbt,", "tokens": ["Und", "sich", "in", "ih\u00b7ren", "Leh\u00b7ren", "\u00fcbt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Kan auf den h\u00f6chsten Gipfel kommen.", "tokens": ["Kan", "auf", "den", "h\u00f6chs\u00b7ten", "Gip\u00b7fel", "kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "APPR", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.32": {"line.1": {"text": "Ihr Philosophen alter Zeit!", "tokens": ["Ihr", "Phi\u00b7lo\u00b7so\u00b7phen", "al\u00b7ter", "Zeit", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wie nah kommt ihr der Christen Lehre?", "tokens": ["Wie", "nah", "kommt", "ihr", "der", "Chris\u00b7ten", "Leh\u00b7re", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VVFIN", "PPER", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Man kennet eure W\u00fcrdigkeit", "tokens": ["Man", "ken\u00b7net", "eu\u00b7re", "W\u00fcr\u00b7dig\u00b7keit"], "token_info": ["word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und darum schm\u00fcckt euch Ruhm und Ehre.", "tokens": ["Und", "da\u00b7rum", "schm\u00fcckt", "euch", "Ruhm", "und", "Eh\u00b7re", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PAV", "VVFIN", "PPER", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Hat eure Rede nicht mit Macht,", "tokens": ["Hat", "eu\u00b7re", "Re\u00b7de", "nicht", "mit", "Macht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "PTKNEG", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Die Be\u00dfrung derer Sitten bracht?", "tokens": ["Die", "Be\u00df\u00b7rung", "de\u00b7rer", "Sit\u00b7ten", "bracht", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PDS", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Ihr Stoicker gebt ein Exempel", "tokens": ["Ihr", "Stoi\u00b7cker", "gebt", "ein", "Ex\u00b7em\u00b7pel"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Der Herzen, die kein irdisch Gut", "tokens": ["Der", "Her\u00b7zen", ",", "die", "kein", "ir\u00b7disch", "Gut"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Bezwingt. O fest gesetzter Muth!", "tokens": ["Be\u00b7zwingt", ".", "O", "fest", "ge\u00b7setz\u00b7ter", "Muth", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$.", "NE", "ADJD", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Ihr unterst\u00fctzt den Weisheits-Tempel.", "tokens": ["Ihr", "un\u00b7ter\u00b7st\u00fctzt", "den", "Weis\u00b7heits\u00b7Tem\u00b7pel", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.33": {"line.1": {"text": "La\u00df Pittacus, la\u00df Seneca,", "tokens": ["La\u00df", "Pit\u00b7ta\u00b7cus", ",", "la\u00df", "Se\u00b7ne\u00b7ca", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["VVIMP", "NE", "$,", "VVIMP", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "La\u00df Socrates dich kl\u00e4rlich sehen.", "tokens": ["La\u00df", "So\u00b7cra\u00b7tes", "dich", "kl\u00e4r\u00b7lich", "se\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "NE", "PPER", "ADJD", "VVINF", "$."], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "Ihr kommt den Lehren oft sehr nah,", "tokens": ["Ihr", "kommt", "den", "Leh\u00b7ren", "oft", "sehr", "nah", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADV", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die in dem heilgen Buche stehen.", "tokens": ["Die", "in", "dem", "heil\u00b7gen", "Bu\u00b7che", "ste\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Cratippi werthes Garten-Werk,", "tokens": ["Cra\u00b7tip\u00b7pi", "wert\u00b7hes", "Gar\u00b7ten\u00b7Werk", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "War des Pompeji Augenmerk,", "tokens": ["War", "des", "Pom\u00b7pe\u00b7ji", "Au\u00b7gen\u00b7merk", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und ward durch jenes s\u00fcsse Worte", "tokens": ["Und", "ward", "durch", "je\u00b7nes", "s\u00fcs\u00b7se", "Wor\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "APPR", "PDAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Fast in ein Paradie\u00df verkehrt;", "tokens": ["Fast", "in", "ein", "Pa\u00b7ra\u00b7die\u00df", "ver\u00b7kehrt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Ihr Weisen, was ihr sonst gelehrt,", "tokens": ["Ihr", "Wei\u00b7sen", ",", "was", "ihr", "sonst", "ge\u00b7lehrt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PWS", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Das liebt man noch an jedem Orte.", "tokens": ["Das", "liebt", "man", "noch", "an", "je\u00b7dem", "Or\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PIS", "ADV", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.34": {"line.1": {"text": "Durch eure Weisheit forschet ihr", "tokens": ["Durch", "eu\u00b7re", "Weis\u00b7heit", "for\u00b7schet", "ihr"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Nach dem, der was aus nichts bereitet.", "tokens": ["Nach", "dem", ",", "der", "was", "aus", "nichts", "be\u00b7rei\u00b7tet", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "$,", "PRELS", "PIS", "APPR", "PIS", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Ihr Morgen-L\u00e4nder kommt herf\u00fcr,", "tokens": ["Ihr", "Mor\u00b7gen\u00b7L\u00e4n\u00b7der", "kommt", "her\u00b7f\u00fcr", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und saget, was der Stern bedeutet,", "tokens": ["Und", "sa\u00b7get", ",", "was", "der", "Stern", "be\u00b7deu\u00b7tet", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "PRELS", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Den ihr in eurem Land gesehn!", "tokens": ["Den", "ihr", "in", "eu\u00b7rem", "Land", "ge\u00b7sehn", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ihr m\u00fc\u00dft darauf nach Salem gehn,", "tokens": ["Ihr", "m\u00fc\u00dft", "da\u00b7rauf", "nach", "Sa\u00b7lem", "gehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PAV", "APPR", "NE", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Ihr kommt und fragt, wo in der Wiege,", "tokens": ["Ihr", "kommt", "und", "fragt", ",", "wo", "in", "der", "Wie\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "$,", "PWAV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Der Griechen und der Heyden Heil,", "tokens": ["Der", "Grie\u00b7chen", "und", "der", "Hey\u00b7den", "Heil", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Der S\u00fcnder Trost, der Frommen Theil,", "tokens": ["Der", "S\u00fcn\u00b7der", "Trost", ",", "der", "From\u00b7men", "Theil", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$,", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Der neugebohrne K\u00f6nig liege?", "tokens": ["Der", "neu\u00b7ge\u00b7bohr\u00b7ne", "K\u00f6\u00b7nig", "lie\u00b7ge", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.35": {"line.1": {"text": "O Dioni\u00df! dein Herze schlo\u00df", "tokens": ["O", "Dio\u00b7ni\u00df", "!", "dein", "Her\u00b7ze", "schlo\u00df"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["NE", "NN", "$.", "PPOSAT", "NN", "VVFIN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Als du den Nebel wahrgenommen,", "tokens": ["Als", "du", "den", "Ne\u00b7bel", "wahr\u00b7ge\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "(da Blut aus Christi Seite flo\u00df,", "tokens": ["(", "da", "Blut", "aus", "Chris\u00b7ti", "Sei\u00b7te", "flo\u00df", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "NN", "APPR", "NE", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und er ans Kreutzes-Stamm gekommen:)", "tokens": ["Und", "er", "ans", "Kreut\u00b7zes\u00b7Stamm", "ge\u00b7kom\u00b7men", ":)"], "token_info": ["word", "word", "word", "word", "word", "emoticon"], "pos": ["KON", "PPER", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Es m\u00fcsse bey dem duncklen Schein", "tokens": ["Es", "m\u00fcs\u00b7se", "bey", "dem", "dunck\u00b7len", "Schein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Der h\u00f6chste Gott be\u00e4ngstget seyn,", "tokens": ["Der", "h\u00f6chs\u00b7te", "Gott", "be\u00b7\u00e4ngst\u00b7get", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVPP", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und jetzt den Tod mit Schmerzen leiden.", "tokens": ["Und", "jetzt", "den", "Tod", "mit", "Schmer\u00b7zen", "lei\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Du ruftest deiner Weisen Schaar,", "tokens": ["Du", "ruf\u00b7test", "dei\u00b7ner", "Wei\u00b7sen", "Schaar", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Du sprachst: baut einen Beth-Altar,", "tokens": ["Du", "sprachst", ":", "baut", "ei\u00b7nen", "Beth\u00b7Al\u00b7tar", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Gott stirbt: er mu\u00df von hinnen scheiden.", "tokens": ["Gott", "stirbt", ":", "er", "mu\u00df", "von", "hin\u00b7nen", "schei\u00b7den", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "$.", "PPER", "VMFIN", "APPR", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.36": {"line.1": {"text": "Kein Fall, kein Ungl\u00fcck, Angst, noch Noth", "tokens": ["Kein", "Fall", ",", "kein", "Un\u00b7gl\u00fcck", ",", "Angst", ",", "noch", "Noth"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["PIAT", "NN", "$,", "PIAT", "NN", "$,", "NN", "$,", "ADV", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Macht weiser Leute Herzen m\u00fcrbe.", "tokens": ["Macht", "wei\u00b7ser", "Leu\u00b7te", "Her\u00b7zen", "m\u00fcr\u00b7be", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJA", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Wenn das Verh\u00e4ngni\u00df schm\u00e4ht und droht,", "tokens": ["Wenn", "das", "Ver\u00b7h\u00e4ng\u00b7ni\u00df", "schm\u00e4ht", "und", "droht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So w\u00fcnscht doch keiner, da\u00df er st\u00fcrbe;", "tokens": ["So", "w\u00fcnscht", "doch", "kei\u00b7ner", ",", "da\u00df", "er", "st\u00fcr\u00b7be", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "PIS", "$,", "KOUS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Ihr steht und lacht zu aller Pein,", "tokens": ["Ihr", "steht", "und", "lacht", "zu", "al\u00b7ler", "Pein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Nehmt Schierlings-Saft mit Freuden ein.", "tokens": ["Nehmt", "Schier\u00b7lings\u00b7Saft", "mit", "Freu\u00b7den", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "APPR", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Liegt Socrates in Todes-Z\u00fcgen,", "tokens": ["Liegt", "So\u00b7cra\u00b7tes", "in", "To\u00b7des\u00b7Z\u00fc\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "APPR", "NN", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.8": {"text": "So lehrt er noch, wie man mit Macht", "tokens": ["So", "lehrt", "er", "noch", ",", "wie", "man", "mit", "Macht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "$,", "PWAV", "PIS", "APPR", "NN"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.9": {"text": "Den Tod und seine Faust veracht.", "tokens": ["Den", "Tod", "und", "sei\u00b7ne", "Faust", "ver\u00b7acht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Die Furcht kunt \u00fcber ihn nicht siegen.", "tokens": ["Die", "Furcht", "kunt", "\u00fc\u00b7ber", "ihn", "nicht", "sie\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "APPR", "PPER", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.37": {"line.1": {"text": "Schaut, wie Philippens Lust sich mehrt,", "tokens": ["Schaut", ",", "wie", "Phil\u00b7ip\u00b7pens", "Lust", "sich", "mehrt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PWAV", "NE", "NN", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dieweil sein Prinz zu solchen Stunden,", "tokens": ["Die\u00b7weil", "sein", "Prinz", "zu", "sol\u00b7chen", "Stun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Da Aristotels Zunge lehrt,", "tokens": ["Da", "A\u00b7ris\u00b7to\u00b7tels", "Zun\u00b7ge", "lehrt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sich auf der Erden eingefunden.", "tokens": ["Sich", "auf", "der", "Er\u00b7den", "ein\u00b7ge\u00b7fun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Die\u00df macht uns Alexanders Mund", "tokens": ["Die\u00df", "macht", "uns", "A\u00b7lex\u00b7an\u00b7ders", "Mund"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "PPER", "NE", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Durch seinen eignen Ausspruch kund.", "tokens": ["Durch", "sei\u00b7nen", "eig\u00b7nen", "Aus\u00b7spruch", "kund", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Er ehrte ihn, wie sichs geb\u00fchrte.", "tokens": ["Er", "ehr\u00b7te", "ihn", ",", "wie", "sichs", "ge\u00b7b\u00fchr\u00b7te", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$,", "PWAV", "PIS", "VVFIN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.8": {"text": "Er war ihm fast noch mehr geneigt,", "tokens": ["Er", "war", "ihm", "fast", "noch", "mehr", "ge\u00b7neigt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "ADV", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Als dem, der ihn vorher gezeugt,", "tokens": ["Als", "dem", ",", "der", "ihn", "vor\u00b7her", "ge\u00b7zeugt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "$,", "PRELS", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Dieweil er ihn zur Weisheit f\u00fchrte.", "tokens": ["Die\u00b7weil", "er", "ihn", "zur", "Weis\u00b7heit", "f\u00fchr\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.38": {"line.1": {"text": "Gedenke Cr\u00f6sus! doch nur nicht", "tokens": ["Ge\u00b7den\u00b7ke", "Cr\u00f6\u00b7sus", "!", "doch", "nur", "nicht"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["NN", "NE", "$.", "ADV", "ADV", "PTKNEG"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Den Philosophen h\u00f6nsch zu fluchen.", "tokens": ["Den", "Phi\u00b7lo\u00b7so\u00b7phen", "h\u00f6nsch", "zu", "flu\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Ihr Sinn, Verstand und Geistes-Licht,", "tokens": ["Ihr", "Sinn", ",", "Ver\u00b7stand", "und", "Geis\u00b7tes\u00b7Licht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "L\u00e4\u00dft sich mit R\u00e4tzeln nicht versuchen.", "tokens": ["L\u00e4\u00dft", "sich", "mit", "R\u00e4t\u00b7zeln", "nicht", "ver\u00b7su\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "APPR", "NN", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Halt Alexander! halt nur ein!", "tokens": ["Halt", "A\u00b7lex\u00b7an\u00b7der", "!", "halt", "nur", "ein", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVIMP", "NE", "$.", "VVFIN", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Die Weisen m\u00f6chten st\u00e4rker seyn;", "tokens": ["Die", "Wei\u00b7sen", "m\u00f6ch\u00b7ten", "st\u00e4r\u00b7ker", "seyn", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Erk\u00fchn dich nicht mit deinen Fragen:", "tokens": ["Er\u00b7k\u00fchn", "dich", "nicht", "mit", "dei\u00b7nen", "Fra\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKNEG", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Die Gordschen Knoten k\u00f6nnen sie", "tokens": ["Die", "Gord\u00b7schen", "Kno\u00b7ten", "k\u00f6n\u00b7nen", "sie"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VMFIN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Mit ihrer Weisheit, ohne M\u00fch,", "tokens": ["Mit", "ih\u00b7rer", "Weis\u00b7heit", ",", "oh\u00b7ne", "M\u00fch", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "KOUI", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Zergliedern und gar leicht zerschlagen.", "tokens": ["Zer\u00b7glie\u00b7dern", "und", "gar", "leicht", "zer\u00b7schla\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "ADV", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.39": {"line.1": {"text": "Euch Klugen hat das Alterthum,", "tokens": ["Euch", "Klu\u00b7gen", "hat", "das", "Al\u00b7ter\u00b7thum", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Viel Ehren-S\u00e4ulen aufgebauet;", "tokens": ["Viel", "Eh\u00b7ren\u00b7S\u00e4u\u00b7len", "auf\u00b7ge\u00b7bau\u00b7et", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "So, da\u00df man eures Namens Ruhm", "tokens": ["So", ",", "da\u00df", "man", "eu\u00b7res", "Na\u00b7mens", "Ruhm"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "$,", "KOUS", "PIS", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Nach euren Moder noch geschauet.", "tokens": ["Nach", "eu\u00b7ren", "Mo\u00b7der", "noch", "ge\u00b7schau\u00b7et", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Recht so! ihr seyd dergleichen werth,", "tokens": ["Recht", "so", "!", "ihr", "seyd", "derg\u00b7lei\u00b7chen", "werth", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "$.", "PPER", "VAFIN", "PIS", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Man thut was Billigkeit begehrt.", "tokens": ["Man", "thut", "was", "Bil\u00b7lig\u00b7keit", "be\u00b7gehrt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PIS", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Allein ihr Weisen unsrer Zeiten:", "tokens": ["Al\u00b7lein", "ihr", "Wei\u00b7sen", "uns\u00b7rer", "Zei\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Euch hat so manche sch\u00f6ne Schrift,", "tokens": ["Euch", "hat", "so", "man\u00b7che", "sch\u00f6\u00b7ne", "Schrift", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Ein gr\u00f6\u00dfres Ehren-Maal gestift:", "tokens": ["Ein", "gr\u00f6\u00df\u00b7res", "Eh\u00b7ren\u00b7Maal", "ge\u00b7stift", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Die\u00df kan euch h\u00f6hern Ruhm bereiten.", "tokens": ["Die\u00df", "kan", "euch", "h\u00f6\u00b7hern", "Ruhm", "be\u00b7rei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PPER", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.40": {"line.1": {"text": "Brich an erw\u00fcnschtes Tages-Licht!", "tokens": ["Brich", "an", "er\u00b7w\u00fcnschtes", "Ta\u00b7ges\u00b7Licht", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "ADJA", "NN", "$."], "meter": "+---+-+", "measure": "dactylic.init"}, "line.2": {"text": "Willkommen angenehmer Morgen!", "tokens": ["Will\u00b7kom\u00b7men", "an\u00b7ge\u00b7neh\u00b7mer", "Mor\u00b7gen", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "An dem Sophiens Zunge spricht;", "tokens": ["An", "dem", "So\u00b7phi\u00b7ens", "Zun\u00b7ge", "spricht", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Jetzt weis ich nichts von Angst und Sorgen:", "tokens": ["Jetzt", "weis", "ich", "nichts", "von", "Angst", "und", "Sor\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKVZ", "PPER", "PIS", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Denn ", "tokens": ["Denn"], "token_info": ["word"], "pos": ["KON"], "meter": "+", "measure": "single.up"}, "line.6": {"text": "Erblicket heut sein ", "tokens": ["Er\u00b7bli\u00b7cket", "heut", "sein"], "token_info": ["word", "word", "word"], "pos": ["VVFIN", "ADV", "PPOSAT"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.7": {"text": "Mein Sohn, von dem die kl\u00fcgsten M\u00e4nner", "tokens": ["Mein", "Sohn", ",", "von", "dem", "die", "kl\u00fcgs\u00b7ten", "M\u00e4n\u00b7ner"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "$,", "APPR", "PRELS", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Mit Wahrheit sagen: Dieser lehrt,", "tokens": ["Mit", "Wahr\u00b7heit", "sa\u00b7gen", ":", "Die\u00b7ser", "lehrt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "NN", "VVINF", "$.", "PDS", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Wie man mich w\u00fcrdiglich verehrt.", "tokens": ["Wie", "man", "mich", "w\u00fcr\u00b7dig\u00b7lich", "ver\u00b7ehrt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "PRF", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Er ist ein grosser Weisheits-Kenner.", "tokens": ["Er", "ist", "ein", "gros\u00b7ser", "Weis\u00b7heits\u00b7Ken\u00b7ner", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.41": {"line.1": {"text": "Wie labt mich die Philosophie!", "tokens": ["Wie", "labt", "mich", "die", "Phi\u00b7lo\u00b7so\u00b7phie", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wie reitzet mich dein k\u00fcnstlich Reimen!", "tokens": ["Wie", "reit\u00b7zet", "mich", "dein", "k\u00fcnst\u00b7lich", "Rei\u00b7men", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "PPOSAT", "ADJD", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Wohlan! so soll die Poesie,", "tokens": ["Wo\u00b7hlan", "!", "so", "soll", "die", "Poe\u00b7sie", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$.", "ADV", "VMFIN", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Die zwar noch roh, sich doch nicht s\u00e4umen:", "tokens": ["Die", "zwar", "noch", "roh", ",", "sich", "doch", "nicht", "s\u00e4u\u00b7men", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADV", "ADJD", "$,", "PRF", "ADV", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Wenn sie auf ", "tokens": ["Wenn", "sie", "auf"], "token_info": ["word", "word", "word"], "pos": ["KOUS", "PPER", "APPR"], "meter": "+-+", "measure": "trochaic.di"}, "line.6": {"text": "Dir ein Gedichte bringen mag,", "tokens": ["Dir", "ein", "Ge\u00b7dich\u00b7te", "brin\u00b7gen", "mag", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Komm, sieh mit g\u00fctgen Augen an,", "tokens": ["Komm", ",", "sieh", "mit", "g\u00fct\u00b7gen", "Au\u00b7gen", "an", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "VVIMP", "APPR", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Was ich aus Schuldigkeit gethan,", "tokens": ["Was", "ich", "aus", "Schul\u00b7dig\u00b7keit", "ge\u00b7than", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Und dir anjetzo zugeschrieben.", "tokens": ["Und", "dir", "an\u00b7je\u00b7tzo", "zu\u00b7ge\u00b7schrie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.42": {"line.1": {"text": "Was w\u00fcnsch ich? nein ich w\u00fcnsche nicht!", "tokens": ["Was", "w\u00fcnsch", "ich", "?", "nein", "ich", "w\u00fcn\u00b7sche", "nicht", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "$.", "PTKANT", "PPER", "VVFIN", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Denn, wer wie du die Weisheit liebet,", "tokens": ["Denn", ",", "wer", "wie", "du", "die", "Weis\u00b7heit", "lie\u00b7bet", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "PWS", "KOKOM", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Der schaut des Gl\u00fcckes Angesicht:", "tokens": ["Der", "schaut", "des", "Gl\u00fc\u00b7ckes", "An\u00b7ge\u00b7sicht", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sich durch sich selbst die Wohlfarth giebet.", "tokens": ["Sich", "durch", "sich", "selbst", "die", "Wohl\u00b7farth", "gie\u00b7bet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "PRF", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Zum Schlusse setzt Sidonia:", "tokens": ["Zum", "Schlus\u00b7se", "setzt", "Si\u00b7do\u00b7nia", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "NE", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.6": {"text": "Weil ", "tokens": ["Weil"], "token_info": ["word"], "pos": ["KOUS"], "meter": "+", "measure": "single.up"}, "line.7": {"text": "So wird mein Geist mit Lust umgeben:", "tokens": ["So", "wird", "mein", "Geist", "mit", "Lust", "um\u00b7ge\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPOSAT", "NN", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Sophia und das Musen-Chor", "tokens": ["So\u00b7phia", "und", "das", "Mu\u00b7sen\u00b7Chor"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "KON", "ART", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.9": {"text": "Geht mir in Lustbarkeiten vor:", "tokens": ["Geht", "mir", "in", "Lust\u00b7bar\u00b7kei\u00b7ten", "vor", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Man ruft: ", "tokens": ["Man", "ruft", ":"], "token_info": ["word", "word", "punct"], "pos": ["PIS", "VVFIN", "$."], "meter": "-+", "measure": "iambic.single"}}}}}