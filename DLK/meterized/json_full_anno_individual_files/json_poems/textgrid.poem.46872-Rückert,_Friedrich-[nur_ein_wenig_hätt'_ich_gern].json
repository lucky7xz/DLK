{"textgrid.poem.46872": {"metadata": {"author": {"name": "R\u00fcckert, Friedrich", "birth": "N.A.", "death": "N.A."}, "title": "[nur ein wenig h\u00e4tt' ich gern]", "genre": "verse", "period": "N.A.", "pub_year": 1827, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "\u00bbnur ein wenig h\u00e4tt' ich gern", "tokens": ["\u00bb", "nur", "ein", "we\u00b7nig", "h\u00e4tt'", "ich", "gern"], "token_info": ["punct", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "ADV", "ART", "PIS", "VAFIN", "PPER", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Licht in diesen Finsternissen;", "tokens": ["Licht", "in", "die\u00b7sen", "Fins\u00b7ter\u00b7nis\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PDAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wenn du's wei\u00dft, o la\u00df mich's wissen,", "tokens": ["Wenn", "du's", "wei\u00dft", ",", "o", "la\u00df", "mich's", "wis\u00b7sen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "VVFIN", "$,", "FM", "FM", "FM", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wo nun unsre Lieben sind.", "tokens": ["Wo", "nun", "uns\u00b7re", "Lie\u00b7ben", "sind", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "PPOSAT", "ADJA", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Ob vielleicht von Stern zu Stern", "tokens": ["Ob", "viel\u00b7leicht", "von", "Stern", "zu", "Stern"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "APPR", "NN", "APPR", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Sie durchs Unermessne wandern,", "tokens": ["Sie", "durchs", "Un\u00b7er\u00b7mess\u00b7ne", "wan\u00b7dern", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "APPRART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Immer uns voraus am andern", "tokens": ["Im\u00b7mer", "uns", "vo\u00b7raus", "am", "an\u00b7dern"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "PPER", "ADV", "APPRART", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ort, als wo man sucht sein Kind?", "tokens": ["Ort", ",", "als", "wo", "man", "sucht", "sein", "Kind", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KOUS", "PWAV", "PIS", "VVFIN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Lehre dies mich, da\u00df ich's lern',", "tokens": ["Leh\u00b7re", "dies", "mich", ",", "da\u00df", "ich's", "lern'", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "PDS", "PPER", "$,", "KOUS", "PIS", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Ob uns nicht die R\u00e4ume trennen?", "tokens": ["Ob", "uns", "nicht", "die", "R\u00e4u\u00b7me", "tren\u00b7nen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Ohne dort uns zu erkennen,", "tokens": ["Oh\u00b7ne", "dort", "uns", "zu", "er\u00b7ken\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "PPER", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "W\u00e4ren wir im Lichte blind.\u00ab", "tokens": ["W\u00e4\u00b7ren", "wir", "im", "Lich\u00b7te", "blind", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VAFIN", "PPER", "APPRART", "NN", "ADJD", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Preis im ew'gen Licht dem Herrn!", "tokens": ["Preis", "im", "ew'\u00b7gen", "Licht", "dem", "Herrn", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPRART", "ADJA", "NN", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Aber uns im Staub la\u00df glauben,", "tokens": ["A\u00b7ber", "uns", "im", "Staub", "la\u00df", "glau\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "APPRART", "NN", "VVIMP", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df nicht Zeit- noch Weltraum rauben", "tokens": ["Da\u00df", "nicht", "Zeit", "noch", "Welt\u00b7raum", "rau\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PTKNEG", "TRUNC", "KON", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Einer Mutter kann ihr Kind.", "tokens": ["Ei\u00b7ner", "Mut\u00b7ter", "kann", "ihr", "Kind", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Nichts ist nah und nichts ist fern,", "tokens": ["Nichts", "ist", "nah", "und", "nichts", "ist", "fern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "ADJD", "KON", "PIS", "VAFIN", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Wo gefallen sind die Schranken,", "tokens": ["Wo", "ge\u00b7fal\u00b7len", "sind", "die", "Schran\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVPP", "VAFIN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wie schon hier uns im Gedanken,", "tokens": ["Wie", "schon", "hier", "uns", "im", "Ge\u00b7dan\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "ADV", "PPER", "APPRART", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Die wir lieben, nahe sind.", "tokens": ["Die", "wir", "lie\u00b7ben", ",", "na\u00b7he", "sind", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "PPER", "VVFIN", "$,", "ADJD", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "\u00bbnur ein wenig h\u00e4tt' ich gern", "tokens": ["\u00bb", "nur", "ein", "we\u00b7nig", "h\u00e4tt'", "ich", "gern"], "token_info": ["punct", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "ADV", "ART", "PIS", "VAFIN", "PPER", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Licht in diesen Finsternissen;", "tokens": ["Licht", "in", "die\u00b7sen", "Fins\u00b7ter\u00b7nis\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PDAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wenn du's wei\u00dft, o la\u00df mich's wissen,", "tokens": ["Wenn", "du's", "wei\u00dft", ",", "o", "la\u00df", "mich's", "wis\u00b7sen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "VVFIN", "$,", "FM", "FM", "FM", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wo nun unsre Lieben sind.", "tokens": ["Wo", "nun", "uns\u00b7re", "Lie\u00b7ben", "sind", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "PPOSAT", "ADJA", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Ob vielleicht von Stern zu Stern", "tokens": ["Ob", "viel\u00b7leicht", "von", "Stern", "zu", "Stern"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "APPR", "NN", "APPR", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Sie durchs Unermessne wandern,", "tokens": ["Sie", "durchs", "Un\u00b7er\u00b7mess\u00b7ne", "wan\u00b7dern", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "APPRART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Immer uns voraus am andern", "tokens": ["Im\u00b7mer", "uns", "vo\u00b7raus", "am", "an\u00b7dern"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "PPER", "ADV", "APPRART", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ort, als wo man sucht sein Kind?", "tokens": ["Ort", ",", "als", "wo", "man", "sucht", "sein", "Kind", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KOUS", "PWAV", "PIS", "VVFIN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Lehre dies mich, da\u00df ich's lern',", "tokens": ["Leh\u00b7re", "dies", "mich", ",", "da\u00df", "ich's", "lern'", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "PDS", "PPER", "$,", "KOUS", "PIS", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Ob uns nicht die R\u00e4ume trennen?", "tokens": ["Ob", "uns", "nicht", "die", "R\u00e4u\u00b7me", "tren\u00b7nen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Ohne dort uns zu erkennen,", "tokens": ["Oh\u00b7ne", "dort", "uns", "zu", "er\u00b7ken\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "PPER", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "W\u00e4ren wir im Lichte blind.\u00ab", "tokens": ["W\u00e4\u00b7ren", "wir", "im", "Lich\u00b7te", "blind", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VAFIN", "PPER", "APPRART", "NN", "ADJD", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Preis im ew'gen Licht dem Herrn!", "tokens": ["Preis", "im", "ew'\u00b7gen", "Licht", "dem", "Herrn", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPRART", "ADJA", "NN", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Aber uns im Staub la\u00df glauben,", "tokens": ["A\u00b7ber", "uns", "im", "Staub", "la\u00df", "glau\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "APPRART", "NN", "VVIMP", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df nicht Zeit- noch Weltraum rauben", "tokens": ["Da\u00df", "nicht", "Zeit", "noch", "Welt\u00b7raum", "rau\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PTKNEG", "TRUNC", "KON", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Einer Mutter kann ihr Kind.", "tokens": ["Ei\u00b7ner", "Mut\u00b7ter", "kann", "ihr", "Kind", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Nichts ist nah und nichts ist fern,", "tokens": ["Nichts", "ist", "nah", "und", "nichts", "ist", "fern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "ADJD", "KON", "PIS", "VAFIN", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Wo gefallen sind die Schranken,", "tokens": ["Wo", "ge\u00b7fal\u00b7len", "sind", "die", "Schran\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVPP", "VAFIN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wie schon hier uns im Gedanken,", "tokens": ["Wie", "schon", "hier", "uns", "im", "Ge\u00b7dan\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "ADV", "PPER", "APPRART", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Die wir lieben, nahe sind.", "tokens": ["Die", "wir", "lie\u00b7ben", ",", "na\u00b7he", "sind", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "PPER", "VVFIN", "$,", "ADJD", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}