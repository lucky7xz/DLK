{"textgrid.poem.54961": {"metadata": {"author": {"name": "Dusch, Johann Jakob", "birth": "N.A.", "death": "N.A."}, "title": "1L: Om, wie lange k\u00e4mpft, im ungerechten Kriege,", "genre": "verse", "period": "N.A.", "pub_year": 1756, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Om, wie lange k\u00e4mpft, im ungerechten Kriege,", "tokens": ["Om", ",", "wie", "lan\u00b7ge", "k\u00e4mpft", ",", "im", "un\u00b7ge\u00b7rech\u00b7ten", "Krie\u00b7ge", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PWAV", "ADV", "VVFIN", "$,", "APPRART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.2": {"text": "Der Mensch mit der Vernunft, und freut sich b\u00f6ser Siege?", "tokens": ["Der", "Mensch", "mit", "der", "Ver\u00b7nunft", ",", "und", "freut", "sich", "b\u00f6\u00b7ser", "Sie\u00b7ge", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$,", "KON", "VVFIN", "PRF", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Zum Tode, rief Athen, wer bessre G\u00f6tter lehrt,", "tokens": ["Zum", "To\u00b7de", ",", "rief", "A\u00b7then", ",", "wer", "bess\u00b7re", "G\u00f6t\u00b7ter", "lehrt", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "VVFIN", "NE", "$,", "PWS", "VVFIN", "NN", "VVFIN", "$,"], "meter": "-+-+---+-+-+", "measure": "unknown.measure.penta"}, "line.4": {"text": "Und unsrer V\u00e4ter Brauch, und den Altar zerst\u00f6rt!", "tokens": ["Und", "uns\u00b7rer", "V\u00e4\u00b7ter", "Brauch", ",", "und", "den", "Al\u00b7tar", "zer\u00b7st\u00f6rt", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "NN", "$,", "KON", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und schau, das reine Bild der Weisheit und der Liebe", "tokens": ["Und", "schau", ",", "das", "rei\u00b7ne", "Bild", "der", "Weis\u00b7heit", "und", "der", "Lie\u00b7be"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PTKVZ", "$,", "ART", "ADJA", "NN", "ART", "NN", "KON", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wird zu der Schmach verdammt, und stirbt den Tod der Diebe.", "tokens": ["Wird", "zu", "der", "Schmach", "ver\u00b7dammt", ",", "und", "stirbt", "den", "Tod", "der", "Die\u00b7be", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "ART", "NN", "VVPP", "$,", "KON", "VVFIN", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Dem Weisen, den das Loos der Misseth\u00e4ter trifft,", "tokens": ["Dem", "Wei\u00b7sen", ",", "den", "das", "Loos", "der", "Mis\u00b7set\u00b7h\u00e4\u00b7ter", "trifft", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ART", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Reicht man kaum Bettelbrodt", "tokens": ["Reicht", "man", "kaum", "Bet\u00b7tel\u00b7brodt"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PIS", "ADV", "NN"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.9": {"text": "Ein lehrender Esop trug, seiner Zeit zur Schande,", "tokens": ["Ein", "leh\u00b7ren\u00b7der", "E\u00b7sop", "trug", ",", "sei\u00b7ner", "Zeit", "zur", "Schan\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,", "PPOSAT", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Des reichen P\u00f6bels Joch, und Epiktet die Bande.", "tokens": ["Des", "rei\u00b7chen", "P\u00f6\u00b7bels", "Joch", ",", "und", "E\u00b7pik\u00b7tet", "die", "Ban\u00b7de", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NE", "$,", "KON", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.11": {"text": "Dies war der Weisen Gl\u00fcck von allen Zeiten her;", "tokens": ["Dies", "war", "der", "Wei\u00b7sen", "Gl\u00fcck", "von", "al\u00b7len", "Zei\u00b7ten", "her", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "NN", "APPR", "PIAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Und unsre Zeit erstaunt, und wird nicht billiger.", "tokens": ["Und", "uns\u00b7re", "Zeit", "er\u00b7staunt", ",", "und", "wird", "nicht", "bil\u00b7li\u00b7ger", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVPP", "$,", "KON", "VAFIN", "PTKNEG", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Der Hof zieht T\u00e4nzer an, und n\u00e4hret M\u00fc\u00dfigg\u00e4nger,", "tokens": ["Der", "Hof", "zieht", "T\u00e4n\u00b7zer", "an", ",", "und", "n\u00e4h\u00b7ret", "M\u00fc\u00b7\u00dfig\u00b7g\u00e4n\u00b7ger", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "NN", "PTKVZ", "$,", "KON", "VVFIN", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "J\u00e4gt einen Weisen fort, und m\u00e4stet zwanzig S\u00e4nger.", "tokens": ["J\u00e4gt", "ei\u00b7nen", "Wei\u00b7sen", "fort", ",", "und", "m\u00e4s\u00b7tet", "zwan\u00b7zig", "S\u00e4n\u00b7ger", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "PTKVZ", "$,", "KON", "VVFIN", "CARD", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Die D\u00fcrftigkeit verl\u00f6scht dem Weisen, da er wacht,", "tokens": ["Die", "D\u00fcrf\u00b7tig\u00b7keit", "ver\u00b7l\u00f6scht", "dem", "Wei\u00b7sen", ",", "da", "er", "wacht", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "$,", "KOUS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Die Lampe, die den Kreis der Erden heller macht,", "tokens": ["Die", "Lam\u00b7pe", ",", "die", "den", "Kreis", "der", "Er\u00b7den", "hel\u00b7ler", "macht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ART", "NN", "ART", "NN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Umsonst rieth sein Verstand mehr, als Orakel rathen,", "tokens": ["Um\u00b7sonst", "rieth", "sein", "Ver\u00b7stand", "mehr", ",", "als", "O\u00b7ra\u00b7kel", "ra\u00b7then", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "ADV", "$,", "KOUS", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Gab im Lycurg Gesetz, und focht in C\u00e4sars Thaten:", "tokens": ["Gab", "im", "Ly\u00b7curg", "Ge\u00b7setz", ",", "und", "focht", "in", "C\u00e4\u00b7sars", "Tha\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPRART", "NN", "NN", "$,", "KON", "VVFIN", "APPR", "NE", "NN", "$."], "meter": "+-+--+-+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.19": {"text": "Regierte im Hugen der Sterne wandelnd Heer,", "tokens": ["Re\u00b7gier\u00b7te", "im", "Hu\u00b7gen", "der", "Ster\u00b7ne", "wan\u00b7delnd", "Heer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPRART", "NN", "ART", "NN", "VVPP", "NN", "$,"], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.20": {"text": "Fand im Colon die Bahn durchs ungepfl\u00fcgte Meer;", "tokens": ["Fand", "im", "Co\u00b7lon", "die", "Bahn", "durchs", "un\u00b7ge\u00b7pfl\u00fcg\u00b7te", "Meer", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPRART", "NN", "ART", "NN", "APPRART", "ADJA", "NN", "$."], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.21": {"text": "Umsonst ins Herz der Welt stieg er durch Felsenwunden,", "tokens": ["Um\u00b7sonst", "ins", "Herz", "der", "Welt", "stieg", "er", "durch", "Fel\u00b7sen\u00b7wun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "ART", "NN", "VVFIN", "PPER", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Und hat, selbst arm zu seyn, f\u00fcr Narren Gold gefunden.", "tokens": ["Und", "hat", ",", "selbst", "arm", "zu", "seyn", ",", "f\u00fcr", "Nar\u00b7ren", "Gold", "ge\u00b7fun\u00b7den", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "$,", "ADV", "ADJD", "PTKZU", "VAINF", "$,", "APPR", "NN", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Begl\u00fcckt, wenn man den Geist, der seine Fl\u00fcgel regt,", "tokens": ["Be\u00b7gl\u00fcckt", ",", "wenn", "man", "den", "Geist", ",", "der", "sei\u00b7ne", "Fl\u00fc\u00b7gel", "regt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "KOUS", "PIS", "ART", "NN", "$,", "PRELS", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Noch in die Schulen st\u00f6\u00dft, und dort an Ketten legt.", "tokens": ["Noch", "in", "die", "Schu\u00b7len", "st\u00f6\u00dft", ",", "und", "dort", "an", "Ket\u00b7ten", "legt", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "VVFIN", "$,", "KON", "ADV", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Dort mu\u00df er in das Glei\u00df der alten Lehrer treten,", "tokens": ["Dort", "mu\u00df", "er", "in", "das", "Glei\u00df", "der", "al\u00b7ten", "Leh\u00b7rer", "tre\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "APPR", "ART", "NN", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Und selbst nicht vor sich sehn, getreuer nachzubeten:", "tokens": ["Und", "selbst", "nicht", "vor", "sich", "sehn", ",", "ge\u00b7treu\u00b7er", "nach\u00b7zu\u00b7be\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ADV", "PTKNEG", "APPR", "PRF", "VVINF", "$,", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Mu\u00df wider die Vernunft aus fremden L\u00e4ndern schreyn,", "tokens": ["Mu\u00df", "wi\u00b7der", "die", "Ver\u00b7nunft", "aus", "frem\u00b7den", "L\u00e4n\u00b7dern", "schreyn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "APPR", "ART", "NN", "APPR", "ADJA", "NN", "VAINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Cartesisch in Paris, in Halle wolfisch seyn.", "tokens": ["Car\u00b7te\u00b7sisch", "in", "Pa\u00b7ris", ",", "in", "Hal\u00b7le", "wol\u00b7fisch", "seyn", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "NE", "$,", "APPR", "NE", "ADJD", "VAINF", "$."], "meter": "+----+-+-+-+", "measure": "dactylic.init"}, "line.29": {"text": "Die Mode und der Wahn ertheilt der Welt Befehle,", "tokens": ["Die", "Mo\u00b7de", "und", "der", "Wahn", "er\u00b7theilt", "der", "Welt", "Be\u00b7feh\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "VVFIN", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "Die eine f\u00fcr den Leib, der andre f\u00fcr die Seele.", "tokens": ["Die", "ei\u00b7ne", "f\u00fcr", "den", "Leib", ",", "der", "and\u00b7re", "f\u00fcr", "die", "See\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "APPR", "ART", "NN", "$,", "PRELS", "PIS", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Der Heilige vermischt den Weisen mit den Sp\u00f6ttern,", "tokens": ["Der", "Hei\u00b7li\u00b7ge", "ver\u00b7mischt", "den", "Wei\u00b7sen", "mit", "den", "Sp\u00f6t\u00b7tern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Denkt seiner nur im Grimm, und spricht zu ihm aus Wettern.", "tokens": ["Denkt", "sei\u00b7ner", "nur", "im", "Grimm", ",", "und", "spricht", "zu", "ihm", "aus", "Wet\u00b7tern", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "ADV", "APPRART", "NE", "$,", "KON", "VVFIN", "APPR", "PPER", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Verdank es der Geburt am Elbstrom, oder Rhein;", "tokens": ["Ver\u00b7dank", "es", "der", "Ge\u00b7burt", "am", "E\u00b7lbstrom", ",", "o\u00b7der", "Rhein", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "APPRART", "NN", "$,", "KON", "NE", "$."], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Am Euphrat w\u00fcrd er selbst ein Feind der Christen seyn,", "tokens": ["Am", "Eu\u00b7ph\u00b7rat", "w\u00fcrd", "er", "selbst", "ein", "Feind", "der", "Chris\u00b7ten", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NE", "VAFIN", "PPER", "ADV", "ART", "NN", "ART", "NN", "VAINF", "$,"], "meter": "+---+-+-+-+-+", "measure": "dactylic.init"}, "line.5": {"text": "Vernunft, schreyt er, ist blind; und darf sich nichts erk\u00fchnen,", "tokens": ["Ver\u00b7nunft", ",", "schreyt", "er", ",", "ist", "blind", ";", "und", "darf", "sich", "nichts", "er\u00b7k\u00fch\u00b7nen", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "PPER", "$,", "VAFIN", "ADJD", "$.", "KON", "VMFIN", "PRF", "PIS", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Der Glauben geht gewi\u00df; er herrsche, sie soll dienen!", "tokens": ["Der", "Glau\u00b7ben", "geht", "ge\u00b7wi\u00df", ";", "er", "herr\u00b7sche", ",", "sie", "soll", "die\u00b7nen", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "$.", "PPER", "VVFIN", "$,", "PPER", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Setz ihn in Asien, erzogen im Koran,", "tokens": ["Setz", "ihn", "in", "A\u00b7sien", ",", "er\u00b7zo\u00b7gen", "im", "Ko\u00b7ran", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "NE", "$,", "VVPP", "APPRART", "NN", "$,"], "meter": "+--+--+-+-+", "measure": "dactylic.di.plus"}, "line.8": {"text": "Und sag, was spr\u00e4ch er wohl, spr\u00e4ch er als Muselmann?", "tokens": ["Und", "sag", ",", "was", "spr\u00e4ch", "er", "wohl", ",", "spr\u00e4ch", "er", "als", "Mu\u00b7sel\u00b7mann", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "PWS", "VVFIN", "PPER", "ADV", "$,", "VVFIN", "PPER", "KOUS", "NN", "$."], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.9": {"text": "Mit eben der Vernunft, die ihn den wahren Lehren", "tokens": ["Mit", "e\u00b7ben", "der", "Ver\u00b7nunft", ",", "die", "ihn", "den", "wah\u00b7ren", "Leh\u00b7ren"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADV", "ART", "NN", "$,", "PRELS", "PPER", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Blind unterworfen hat, k\u00f6nnt er dem Irrthum schw\u00f6ren.", "tokens": ["Blind", "un\u00b7ter\u00b7wor\u00b7fen", "hat", ",", "k\u00f6nnt", "er", "dem", "Irr\u00b7thum", "schw\u00f6\u00b7ren", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVPP", "VAFIN", "$,", "VVFIN", "PPER", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "H\u00f6r, was der Redner sagt, der die Gerichte stimmt,", "tokens": ["H\u00f6r", ",", "was", "der", "Red\u00b7ner", "sagt", ",", "der", "die", "Ge\u00b7rich\u00b7te", "stimmt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PRELS", "ART", "NN", "VVFIN", "$,", "PRELS", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und oft, statt der Vernunft, sein Geld zu H\u00fclfe nimmt:", "tokens": ["Und", "oft", ",", "statt", "der", "Ver\u00b7nunft", ",", "sein", "Geld", "zu", "H\u00fcl\u00b7fe", "nimmt", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$,", "KOUI", "ART", "NN", "$,", "PPOSAT", "NN", "APPR", "NN", "VVFIN", "$."], "meter": "-+---+-+-+-+", "measure": "dactylic.init"}, "line.3": {"text": "Hier schweige mit Vernunft! was n\u00fctzt ein leer Geschw\u00e4tze?", "tokens": ["Hier", "schwei\u00b7ge", "mit", "Ver\u00b7nunft", "!", "was", "n\u00fctzt", "ein", "leer", "Ge\u00b7schw\u00e4t\u00b7ze", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "NN", "$.", "PWS", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So will der Landesherr, so wollen die Gesetze.", "tokens": ["So", "will", "der", "Lan\u00b7des\u00b7herr", ",", "so", "wol\u00b7len", "die", "Ge\u00b7set\u00b7ze", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "NN", "$,", "ADV", "VMFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und wer gab dis Gesetz? Vielleicht ein Eigensinn,", "tokens": ["Und", "wer", "gab", "dis", "Ge\u00b7setz", "?", "Viel\u00b7leicht", "ein", "Ei\u00b7gen\u00b7sinn", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VVFIN", "PDS", "NN", "$.", "ADV", "ART", "NN", "$,"], "meter": "--+--+-+-+-+", "measure": "anapaest.di.plus"}, "line.6": {"text": "Ein Narr, ein Kammerdiener, und eine Buhlerin.", "tokens": ["Ein", "Narr", ",", "ein", "Kam\u00b7mer\u00b7die\u00b7ner", ",", "und", "ei\u00b7ne", "Buh\u00b7le\u00b7rin", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "$,", "KON", "ART", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.7": {"text": "Der Schulmann ohne Geist, von Hochmuth aufgeblasen,", "tokens": ["Der", "Schul\u00b7mann", "oh\u00b7ne", "Geist", ",", "von", "Hoch\u00b7muth", "auf\u00b7ge\u00b7bla\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "$,", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Kennt von der ersten Welt die Kleidung und die Phrasen.", "tokens": ["Kennt", "von", "der", "ers\u00b7ten", "Welt", "die", "Klei\u00b7dung", "und", "die", "Phra\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "ADJA", "NN", "ART", "NN", "KON", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Vergn\u00fcgt, wenn er mit Schwei\u00df, der seine Stirn benetzt,", "tokens": ["Ver\u00b7gn\u00fcgt", ",", "wenn", "er", "mit", "Schwei\u00df", ",", "der", "sei\u00b7ne", "Stirn", "be\u00b7netzt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "KOUS", "PPER", "APPR", "NN", "$,", "PRELS", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Virgilens Troja l\u00f6scht, und ihn in Wasser setzt:", "tokens": ["Vir\u00b7gi\u00b7lens", "Tro\u00b7ja", "l\u00f6scht", ",", "und", "ihn", "in", "Was\u00b7ser", "setzt", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VVFIN", "$,", "KON", "PPER", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Vernunft ist nicht sein Theil: was brauchts der Kunst zu denken,", "tokens": ["Ver\u00b7nunft", "ist", "nicht", "sein", "Theil", ":", "was", "brauchts", "der", "Kunst", "zu", "den\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PTKNEG", "PPOSAT", "NN", "$.", "PWS", "VVFIN", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Um in Gelehrsamkeit zw\u00f6lf Dichter zu ertr\u00e4nken?", "tokens": ["Um", "in", "Ge\u00b7lehr\u00b7sam\u00b7keit", "zw\u00f6lf", "Dich\u00b7ter", "zu", "er\u00b7tr\u00e4n\u00b7ken", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "APPR", "NN", "CARD", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Ihm, der allein den Geist der Prisciane fa\u00dft,", "tokens": ["Ihm", ",", "der", "al\u00b7lein", "den", "Geist", "der", "Pri\u00b7sci\u00b7a\u00b7ne", "fa\u00dft", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PRELS", "ADV", "ART", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Wird Lock ein Schw\u00e4tzer seyn, und Newton ein Phantast.", "tokens": ["Wird", "Lock", "ein", "Schw\u00e4t\u00b7zer", "seyn", ",", "und", "New\u00b7ton", "ein", "Phan\u00b7tast", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "ART", "NN", "VAINF", "$,", "KON", "NE", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Und doch hat die Vernunft, die alle drey beleidigt,", "tokens": ["Und", "doch", "hat", "die", "Ver\u00b7nunft", ",", "die", "al\u00b7le", "drey", "be\u00b7lei\u00b7digt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "ART", "NN", "$,", "PRELS", "PIAT", "CARD", "VVPP", "$,"], "meter": "-+---+-+-+-+-", "measure": "dactylic.init"}, "line.16": {"text": "Das Christenthum gesch\u00fctzt, und den Altar vertheidigt;", "tokens": ["Das", "Chris\u00b7ten\u00b7thum", "ge\u00b7sch\u00fctzt", ",", "und", "den", "Al\u00b7tar", "ver\u00b7thei\u00b7digt", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "$,", "KON", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Sie stellte Recht und Heil im Dracon wieder her,", "tokens": ["Sie", "stell\u00b7te", "Recht", "und", "Heil", "im", "Dra\u00b7con", "wie\u00b7der", "her", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "KON", "NN", "APPRART", "NN", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Vertrat im Tullius, und sang in dem Homer.", "tokens": ["Ver\u00b7trat", "im", "Tul\u00b7li\u00b7us", ",", "und", "sang", "in", "dem", "Ho\u00b7mer", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPRART", "NN", "$,", "KON", "VVFIN", "APPR", "ART", "NE", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}}, "stanza.4": {"line.1": {"text": "Doch la\u00df uns von Vernunft nicht bis zum Ekel streiten;", "tokens": ["Doch", "la\u00df", "uns", "von", "Ver\u00b7nunft", "nicht", "bis", "zum", "E\u00b7kel", "strei\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVIMP", "PPER", "APPR", "NN", "PTKNEG", "ADV", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und sprich: es sey ihr Theil, den Menschen falsch zu leiten.", "tokens": ["Und", "sprich", ":", "es", "sey", "ihr", "Theil", ",", "den", "Men\u00b7schen", "falsch", "zu", "lei\u00b7ten", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "$.", "PPER", "VAFIN", "PPOSAT", "NN", "$,", "ART", "NN", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Dann aber wollt ich eh zur Erde niedersehn,", "tokens": ["Dann", "a\u00b7ber", "wollt", "ich", "eh", "zur", "Er\u00b7de", "nie\u00b7der\u00b7sehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VMFIN", "PPER", "KOUS", "APPRART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Glatt, oder auch im Pelz geb\u00fcckt auf Vieren gehn,", "tokens": ["Glatt", ",", "o\u00b7der", "auch", "im", "Pelz", "ge\u00b7b\u00fcckt", "auf", "Vie\u00b7ren", "gehn", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KON", "ADV", "APPRART", "NN", "VVPP", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und mit der Sicherheit mich nimmer zu verlieren,", "tokens": ["Und", "mit", "der", "Si\u00b7cher\u00b7heit", "mich", "nim\u00b7mer", "zu", "ver\u00b7lie\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "PPER", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Des Pfaus, ja, wenn ich soll, den Schweif des Esels f\u00fchren,", "tokens": ["Des", "Pfaus", ",", "ja", ",", "wenn", "ich", "soll", ",", "den", "Schweif", "des", "E\u00b7sels", "f\u00fch\u00b7ren", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PTKANT", "$,", "KOUS", "PPER", "VMFIN", "$,", "ART", "NN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Als mit dem Titel, Mensch, nur in der Bildung sch\u00f6n,", "tokens": ["Als", "mit", "dem", "Ti\u00b7tel", ",", "Mensch", ",", "nur", "in", "der", "Bil\u00b7dung", "sch\u00f6n", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "ART", "NN", "$,", "NN", "$,", "ADV", "APPR", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und ohne Pelz und Schweif, auf Zweyen unrecht gehn.", "tokens": ["Und", "oh\u00b7ne", "Pelz", "und", "Schweif", ",", "auf", "Zwe\u00b7yen", "un\u00b7recht", "gehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "KON", "NN", "$,", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Gesichert geht das Vieh, von dem Instinkt getrieben,", "tokens": ["Ge\u00b7si\u00b7chert", "geht", "das", "Vieh", ",", "von", "dem", "Ins\u00b7tinkt", "ge\u00b7trie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VVFIN", "ART", "NN", "$,", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+--++-+-", "measure": "iambic.hexa.relaxed"}, "line.10": {"text": "Mit der Natur die Bahn, die sie ihm vorgeschrieben.", "tokens": ["Mit", "der", "Na\u00b7tur", "die", "Bahn", ",", "die", "sie", "ihm", "vor\u00b7ge\u00b7schrie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "$,", "PRELS", "PPER", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Kein Irrweg, kein Betrug verschl\u00e4gt es von der Ruh,", "tokens": ["Kein", "Irr\u00b7weg", ",", "kein", "Be\u00b7trug", "ver\u00b7schl\u00e4gt", "es", "von", "der", "Ruh", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "$,", "PIAT", "NN", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Gott herrscht in dem Instinkt, und f\u00fchrt unfehlbar zu.", "tokens": ["Gott", "herrscht", "in", "dem", "Ins\u00b7tinkt", ",", "und", "f\u00fchrt", "un\u00b7fehl\u00b7bar", "zu", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "APPR", "ART", "NN", "$,", "KON", "VVFIN", "ADJD", "PTKVZ", "$."], "meter": "++-+-+-+-+-+", "measure": "unknown.measure.septa"}, "line.13": {"text": "Du aber wirst umsonst durch zwanzig Augen sehen,", "tokens": ["Du", "a\u00b7ber", "wirst", "um\u00b7sonst", "durch", "zwan\u00b7zig", "Au\u00b7gen", "se\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VAFIN", "ADV", "APPR", "CARD", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Die Fackel in der Hand, und wirst doch irre gehen;", "tokens": ["Die", "Fa\u00b7ckel", "in", "der", "Hand", ",", "und", "wirst", "doch", "ir\u00b7re", "ge\u00b7hen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$,", "KON", "VAFIN", "ADV", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Folg, oder geh allein, in beyden bist du blind;", "tokens": ["Folg", ",", "o\u00b7der", "geh", "al\u00b7lein", ",", "in", "bey\u00b7den", "bist", "du", "blind", ";"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KON", "VVFIN", "ADV", "$,", "APPR", "PIAT", "VAFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Je gr\u00f6\u00dfere Vernunft, je tiefer Labyrinth.", "tokens": ["Je", "gr\u00f6\u00b7\u00dfe\u00b7re", "Ver\u00b7nunft", ",", "je", "tie\u00b7fer", "La\u00b7by\u00b7rinth", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "$,", "ADV", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Der Satz verscherzt dein Recht, den Erdkreis zu regieren,", "tokens": ["Der", "Satz", "ver\u00b7scherzt", "dein", "Recht", ",", "den", "Erd\u00b7kreis", "zu", "re\u00b7gie\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPOSAT", "NN", "$,", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und setzt dich in Gefahr, den Zepter zu verlieren:", "tokens": ["Und", "setzt", "dich", "in", "Ge\u00b7fahr", ",", "den", "Zep\u00b7ter", "zu", "ver\u00b7lie\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "APPR", "NN", "$,", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ein Vorzug, den kein Baur, so wenig er gedacht,", "tokens": ["Ein", "Vor\u00b7zug", ",", "den", "kein", "Baur", ",", "so", "we\u00b7nig", "er", "ge\u00b7dacht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PIAT", "NN", "$,", "ADV", "PIS", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Kein ungelehrtes Volk, sich jemals streitig macht.", "tokens": ["Kein", "un\u00b7ge\u00b7lehr\u00b7tes", "Volk", ",", "sich", "je\u00b7mals", "strei\u00b7tig", "macht", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "$,", "PRF", "ADV", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Er deckt den Schauplatz auf, wo Hitz und Fieber rasten,", "tokens": ["Er", "deckt", "den", "Schau\u00b7platz", "auf", ",", "wo", "Hitz", "und", "Fie\u00b7ber", "ras\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "PTKVZ", "$,", "PWAV", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und zeigt dir eine Welt voll Tr\u00e4umer, und Phantasten,", "tokens": ["Und", "zeigt", "dir", "ei\u00b7ne", "Welt", "voll", "Tr\u00e4u\u00b7mer", ",", "und", "Phan\u00b7tas\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ART", "NN", "ADJD", "NN", "$,", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Wo Irrthum, mit der Tracht der Wahrheit \u00fcberdeckt,", "tokens": ["Wo", "Irr\u00b7thum", ",", "mit", "der", "Tracht", "der", "Wahr\u00b7heit", "\u00fc\u00b7berd\u00b7eckt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "$,", "APPR", "ART", "NN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Um unsre H\u00e4upter schw\u00e4rmt, belustigt, oder schreckt.", "tokens": ["Um", "uns\u00b7re", "H\u00e4up\u00b7ter", "schw\u00e4rmt", ",", "be\u00b7lus\u00b7tigt", ",", "o\u00b7der", "schreckt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["KOUI", "PPOSAT", "NN", "VVFIN", "$,", "VVPP", "$,", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "So schw\u00e4rmt, wie", "tokens": ["So", "schw\u00e4rmt", ",", "wie"], "token_info": ["word", "word", "punct", "word"], "pos": ["ADV", "VVFIN", "$,", "PWAV"], "meter": "-+-", "measure": "amphibrach.single"}, "line.10": {"text": "Furcht, Hoffnung, Schrecken, Lust im Tr\u00e4umen bey dem Gotte;", "tokens": ["Furcht", ",", "Hoff\u00b7nung", ",", "Schre\u00b7cken", ",", "Lust", "im", "Tr\u00e4u\u00b7men", "bey", "dem", "Got\u00b7te", ";"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "$,", "NN", "APPRART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "An Zahl den Bl\u00e4ttern gleich, den Aehren auf der Flur,", "tokens": ["An", "Zahl", "den", "Bl\u00e4t\u00b7tern", "gleich", ",", "den", "A\u00b7eh\u00b7ren", "auf", "der", "Flur", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ART", "NN", "ADV", "$,", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.12": {"text": "Und tr\u00e4gt ver\u00e4nderlich Gestalten der Natur.", "tokens": ["Und", "tr\u00e4gt", "ver\u00b7\u00e4n\u00b7der\u00b7lich", "Ge\u00b7stal\u00b7ten", "der", "Na\u00b7tur", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "La\u00df den, der Tr\u00e4ume liebt, dies Zauberwerk ergetzen;", "tokens": ["La\u00df", "den", ",", "der", "Tr\u00e4u\u00b7me", "liebt", ",", "dies", "Zau\u00b7ber\u00b7werk", "er\u00b7get\u00b7zen", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVIMP", "ART", "$,", "ART", "NN", "VVFIN", "$,", "PDS", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Du, der du Wahrheit suchst, willst die Vernunft entsetzen?", "tokens": ["Du", ",", "der", "du", "Wahr\u00b7heit", "suchst", ",", "willst", "die", "Ver\u00b7nunft", "ent\u00b7set\u00b7zen", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PRELS", "PPER", "NN", "VVFIN", "$,", "VMFIN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Nein, la\u00df ihr noch ihr Recht \u2013 \u00bbund was f\u00fcr Rechte dann?", "tokens": ["Nein", ",", "la\u00df", "ihr", "noch", "ihr", "Recht", "\u2013", "\u00bb", "und", "was", "f\u00fcr", "Rech\u00b7te", "dann", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "VVIMP", "PPER", "ADV", "PPOSAT", "NN", "$(", "$(", "KON", "PWS", "APPR", "NN", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wer sagt mir, ob Vernunft unfehlbar f\u00fchren kann?\u00ab", "tokens": ["Wer", "sagt", "mir", ",", "ob", "Ver\u00b7nunft", "un\u00b7fehl\u00b7bar", "f\u00fch\u00b7ren", "kann", "?", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWS", "VVFIN", "PPER", "$,", "KOUS", "NN", "ADJD", "VVINF", "VMFIN", "$.", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ohnfehlbar allerdings. Doch ohn Affekt erwogen,", "tokens": ["Ohn\u00b7fehl\u00b7bar", "al\u00b7ler\u00b7dings", ".", "Doch", "ohn", "Af\u00b7fekt", "er\u00b7wo\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADV", "$.", "KON", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Im Denken recht ge\u00fcbt, vom Wahne abgezogen;", "tokens": ["Im", "Den\u00b7ken", "recht", "ge\u00b7\u00fcbt", ",", "vom", "Wah\u00b7ne", "ab\u00b7ge\u00b7zo\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADJD", "VVPP", "$,", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Als eine reine Kraft, die blo\u00df aus Gr\u00fcnden denkt,", "tokens": ["Als", "ei\u00b7ne", "rei\u00b7ne", "Kraft", ",", "die", "blo\u00df", "aus", "Gr\u00fcn\u00b7den", "denkt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "$,", "PRELS", "ADV", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und nur auf ihrem Kreis von Wahrheit eingeschr\u00e4nkt.", "tokens": ["Und", "nur", "auf", "ih\u00b7rem", "Kreis", "von", "Wahr\u00b7heit", "ein\u00b7ge\u00b7schr\u00e4nkt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "PPOSAT", "NN", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Sonst f\u00fchr ich dich zur\u00fcck, woraus ich dich gerissen,", "tokens": ["Sonst", "f\u00fchr", "ich", "dich", "zu\u00b7r\u00fcck", ",", "wo\u00b7raus", "ich", "dich", "ge\u00b7ris\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "PTKVZ", "$,", "PWAV", "PPER", "PRF", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Und st\u00fcrze dich noch eins in gleiche Finsternissen.", "tokens": ["Und", "st\u00fcr\u00b7ze", "dich", "noch", "eins", "in", "glei\u00b7che", "Fins\u00b7ter\u00b7nis\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "PIS", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Ist oft ihr Urtheil falsch, und zweifelhaft ihr Licht,", "tokens": ["Ist", "oft", "ihr", "Ur\u00b7theil", "falsch", ",", "und", "zwei\u00b7fel\u00b7haft", "ihr", "Licht", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PPOSAT", "NN", "ADJD", "$,", "KON", "ADJD", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "So sprich: wann sagt sie wahr? wo irrt sie, und wo nicht?", "tokens": ["So", "sprich", ":", "wann", "sagt", "sie", "wahr", "?", "wo", "irrt", "sie", ",", "und", "wo", "nicht", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$.", "PWAV", "VVFIN", "PPER", "PTKVZ", "$.", "PWAV", "VVFIN", "PPER", "$,", "KON", "PWAV", "PTKNEG", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Auf welche Regeln, Freund, soll ich mein Urtheil gr\u00fcnden?", "tokens": ["Auf", "wel\u00b7che", "Re\u00b7geln", ",", "Freund", ",", "soll", "ich", "mein", "Ur\u00b7theil", "gr\u00fcn\u00b7den", "?"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PWAT", "NN", "$,", "NN", "$,", "VMFIN", "PPER", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Ja, sage mir vielmehr, wo soll ich Regeln finden?", "tokens": ["Ja", ",", "sa\u00b7ge", "mir", "viel\u00b7mehr", ",", "wo", "soll", "ich", "Re\u00b7geln", "fin\u00b7den", "?"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "VVFIN", "PPER", "ADV", "$,", "PWAV", "VMFIN", "PPER", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Bey jeder frag ich dich: ist sie gewi\u00df? warum?", "tokens": ["Bey", "je\u00b7der", "frag", "ich", "dich", ":", "ist", "sie", "ge\u00b7wi\u00df", "?", "wa\u00b7rum", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "PIS", "VVFIN", "PPER", "PRF", "$.", "VAFIN", "PPER", "ADV", "$.", "PWAV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Denn das Orakel schweigt, und l\u00e4ngst ist Delphos stumm!", "tokens": ["Denn", "das", "O\u00b7ra\u00b7kel", "schweigt", ",", "und", "l\u00e4ngst", "ist", "Del\u00b7phos", "stumm", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "$,", "KON", "ADV", "VAFIN", "NE", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Dann sitz ich blind und taub in einem Gaukelspiele,", "tokens": ["Dann", "sitz", "ich", "blind", "und", "taub", "in", "ei\u00b7nem", "Gau\u00b7kel\u00b7spie\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVIMP", "PPER", "ADJD", "KON", "ADJD", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Ein schaaler", "tokens": ["Ein", "schaa\u00b7ler"], "token_info": ["word", "word"], "pos": ["ART", "ADJA"], "meter": "-+-", "measure": "amphibrach.single"}}, "stanza.7": {"line.1": {"text": "Ein einziges Gef\u00fchl, Empfindung, oder Sinn,", "tokens": ["Ein", "ein\u00b7zi\u00b7ges", "Ge\u00b7f\u00fchl", ",", "Emp\u00b7fin\u00b7dung", ",", "o\u00b7der", "Sinn", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "NN", "$,", "KON", "NN", "$,"], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.2": {"text": "Von Mexico nach Rom, von Rom bis nach", "tokens": ["Von", "Me\u00b7xi\u00b7co", "nach", "Rom", ",", "von", "Rom", "bis", "nach"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "NE", "APPR", "NE", "$,", "APPR", "NE", "ADV", "APPR"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "F\u00fchrt alle Sterbliche, in einer gleichen Klarheit,", "tokens": ["F\u00fchrt", "al\u00b7le", "Sterb\u00b7li\u00b7che", ",", "in", "ei\u00b7ner", "glei\u00b7chen", "Klar\u00b7heit", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "NN", "$,", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und \u00f6ffnet zur Vernunft f\u00fcnf Wege f\u00fcr die Wahrheit.", "tokens": ["Und", "\u00f6ff\u00b7net", "zur", "Ver\u00b7nunft", "f\u00fcnf", "We\u00b7ge", "f\u00fcr", "die", "Wahr\u00b7heit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPRART", "NN", "CARD", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Was Lappland wei\u00df gesehn, sieht auch Aegypten wei\u00df;", "tokens": ["Was", "Lap\u00b7pland", "wei\u00df", "ge\u00b7sehn", ",", "sieht", "auch", "A\u00b7e\u00b7gyp\u00b7ten", "wei\u00df", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "VVFIN", "VVPP", "$,", "VVFIN", "ADV", "NE", "VVFIN", "$."], "meter": "-+-+-++-+-+-+", "measure": "unknown.measure.septa"}, "line.6": {"text": "Die Flamme ist am Nil, und an der Wolge hei\u00df:", "tokens": ["Die", "Flam\u00b7me", "ist", "am", "Nil", ",", "und", "an", "der", "Wol\u00b7ge", "hei\u00df", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "APPRART", "NN", "$,", "KON", "APPR", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Was \u00e4ndern Zeit, und Ort an dem Gef\u00fchl der Hitze,", "tokens": ["Was", "\u00e4n\u00b7dern", "Zeit", ",", "und", "Ort", "an", "dem", "Ge\u00b7f\u00fchl", "der", "Hit\u00b7ze", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADJA", "NN", "$,", "KON", "NN", "APPR", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Ob dieser nah am Pol, der am Aequator schwitze?", "tokens": ["Ob", "die\u00b7ser", "nah", "am", "Pol", ",", "der", "am", "A\u00b7e\u00b7qua\u00b7tor", "schwit\u00b7ze", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDAT", "ADJD", "APPRART", "NN", "$,", "PRELS", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.9": {"text": "Der Morgenrose Duft, der Weihrauch, der beseelt,", "tokens": ["Der", "Mor\u00b7gen\u00b7ro\u00b7se", "Duft", ",", "der", "Weih\u00b7rauch", ",", "der", "be\u00b7seelt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "NN", "$,", "PRELS", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "W\u00fcrkt lieblich, da der Dampf aus Todtengr\u00e4bern qu\u00e4lt:", "tokens": ["W\u00fcrkt", "lieb\u00b7lich", ",", "da", "der", "Dampf", "aus", "Tod\u00b7ten\u00b7gr\u00e4\u00b7bern", "qu\u00e4lt", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "$,", "KOUS", "ART", "NN", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Und von dem Abend an, bis an die Morgenr\u00f6the,", "tokens": ["Und", "von", "dem", "A\u00b7bend", "an", ",", "bis", "an", "die", "Mor\u00b7gen\u00b7r\u00f6\u00b7the", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "PTKVZ", "$,", "KOUS", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Merkt jedes Ohr den Schall der Trommel vor der Fl\u00f6te.", "tokens": ["Merkt", "je\u00b7des", "Ohr", "den", "Schall", "der", "Trom\u00b7mel", "vor", "der", "Fl\u00f6\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "NN", "ART", "NN", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Dies ewige Gef\u00fchl hat Gott uns eingepr\u00e4gt,", "tokens": ["Dies", "e\u00b7wi\u00b7ge", "Ge\u00b7f\u00fchl", "hat", "Gott", "uns", "ein\u00b7ge\u00b7pr\u00e4gt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADJA", "NN", "VAFIN", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Und in ihm selbst den Grund der Wahrheit vest gelegt.", "tokens": ["Und", "in", "ihm", "selbst", "den", "Grund", "der", "Wahr\u00b7heit", "vest", "ge\u00b7legt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPER", "ADV", "ART", "NN", "ART", "NN", "VVFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Erst st\u00fctze die Vernunft auf so gewissen Gr\u00fcnden,", "tokens": ["Erst", "st\u00fct\u00b7ze", "die", "Ver\u00b7nunft", "auf", "so", "ge\u00b7wis\u00b7sen", "Gr\u00fcn\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPR", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Vergleiche, leite her, so wirst du weiter finden.", "tokens": ["Ver\u00b7glei\u00b7che", ",", "lei\u00b7te", "her", ",", "so", "wirst", "du", "wei\u00b7ter", "fin\u00b7den", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "PTKVZ", "$,", "ADV", "VAFIN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "So grub sie Wahrheit aus, die in der Seele schlief,", "tokens": ["So", "grub", "sie", "Wahr\u00b7heit", "aus", ",", "die", "in", "der", "See\u00b7le", "schlief", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "NN", "PTKVZ", "$,", "PRELS", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Und folgte nach und nach, wohin ihr Faden lief.", "tokens": ["Und", "folg\u00b7te", "nach", "und", "nach", ",", "wo\u00b7hin", "ihr", "Fa\u00b7den", "lief", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "KON", "APPR", "$,", "PWAV", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "So f\u00fchrte sie zuletzt, auf ihrer Dinge Leiter,", "tokens": ["So", "f\u00fchr\u00b7te", "sie", "zu\u00b7letzt", ",", "auf", "ih\u00b7rer", "Din\u00b7ge", "Lei\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "$,", "APPR", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Zum Sch\u00f6pfer, die Natur, ihr gl\u00fccklicher Begleiter.", "tokens": ["Zum", "Sch\u00f6p\u00b7fer", ",", "die", "Na\u00b7tur", ",", "ihr", "gl\u00fcck\u00b7li\u00b7cher", "Be\u00b7glei\u00b7ter", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "ART", "NN", "$,", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "So baut sie Schlu\u00df auf Schlu\u00df, und setzt, zu einer Bahn,", "tokens": ["So", "baut", "sie", "Schlu\u00df", "auf", "Schlu\u00df", ",", "und", "setzt", ",", "zu", "ei\u00b7ner", "Bahn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "NN", "APPR", "NN", "$,", "KON", "VVFIN", "$,", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Die Staffel zum Saturn ins Herz der Erden an,", "tokens": ["Die", "Staf\u00b7fel", "zum", "Sa\u00b7turn", "ins", "Herz", "der", "Er\u00b7den", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "APPRART", "NN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Worauf die Wahrheiten, wie Engel, niedersteigen,", "tokens": ["Wo\u00b7rauf", "die", "Wahr\u00b7hei\u00b7ten", ",", "wie", "En\u00b7gel", ",", "nie\u00b7ders\u00b7tei\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["PAV", "ART", "NN", "$,", "PWAV", "NE", "$,", "VVPP", "$,"], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.24": {"text": "Und ihr, was Moses sah, im fernen Schatten zeigen.", "tokens": ["Und", "ihr", ",", "was", "Mo\u00b7ses", "sah", ",", "im", "fer\u00b7nen", "Schat\u00b7ten", "zei\u00b7gen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "$,", "PRELS", "NE", "VVFIN", "$,", "APPRART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "Die g\u00f6ttliche Vernunft, die alles \u00fcberdenkt,", "tokens": ["Die", "g\u00f6tt\u00b7li\u00b7che", "Ver\u00b7nunft", ",", "die", "al\u00b7les", "\u00fc\u00b7ber\u00b7denkt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PRELS", "PIS", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ist gleich an Deutlichkeit, und Umfang unumschr\u00e4nkt:", "tokens": ["Ist", "gleich", "an", "Deut\u00b7lich\u00b7keit", ",", "und", "Um\u00b7fang", "un\u00b7um\u00b7schr\u00e4nkt", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "APPR", "NN", "$,", "KON", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Mit einem gleichen Strahl durchdringt sie H\u00f6hn und Tiefen,", "tokens": ["Mit", "ei\u00b7nem", "glei\u00b7chen", "Strahl", "durch\u00b7dringt", "sie", "H\u00f6hn", "und", "Tie\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVFIN", "PPER", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Unendlich reich an Licht, unendlich an Begriffen.", "tokens": ["Un\u00b7end\u00b7lich", "reich", "an", "Licht", ",", "un\u00b7end\u00b7lich", "an", "Be\u00b7grif\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "ADJD", "APPR", "NN", "$,", "ADJD", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Schlie\u00df sie in einen Kreis bestimmter Wahrheit ein,", "tokens": ["Schlie\u00df", "sie", "in", "ei\u00b7nen", "Kreis", "be\u00b7stimm\u00b7ter", "Wahr\u00b7heit", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ART", "NN", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und schw\u00e4ch ihr g\u00f6ttlich Licht, so wird sie endlich seyn.", "tokens": ["Und", "schw\u00e4ch", "ihr", "g\u00f6tt\u00b7lich", "Licht", ",", "so", "wird", "sie", "end\u00b7lich", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADJD", "NN", "$,", "ADV", "VAFIN", "PPER", "ADV", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "So wohnt sie Geistern bey, aus Nothdurft eingeschr\u00e4nket,", "tokens": ["So", "wohnt", "sie", "Geis\u00b7tern", "bey", ",", "aus", "Noth\u00b7durft", "ein\u00b7ge\u00b7schr\u00e4n\u00b7ket", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "NN", "PTKVZ", "$,", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und irrt nicht, wenn sie nur in ihrer Sph\u00e4re denket.", "tokens": ["Und", "irrt", "nicht", ",", "wenn", "sie", "nur", "in", "ih\u00b7rer", "Sph\u00e4\u00b7re", "den\u00b7ket", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKNEG", "$,", "KOUS", "PPER", "ADV", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "In diesen Inbegriff setz Unbetr\u00fcglichkeit;", "tokens": ["In", "die\u00b7sen", "In\u00b7be\u00b7griff", "setz", "Un\u00b7be\u00b7tr\u00fcg\u00b7lich\u00b7keit", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "In ihm ist alles Licht, und draussen Dunkelheit.", "tokens": ["In", "ihm", "ist", "al\u00b7les", "Licht", ",", "und", "draus\u00b7sen", "Dun\u00b7kel\u00b7heit", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VAFIN", "PIAT", "NN", "$,", "KON", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Woher entsteht der Zank unz\u00e4hliger Parteyen,", "tokens": ["Wo\u00b7her", "ent\u00b7steht", "der", "Zank", "un\u00b7z\u00e4h\u00b7li\u00b7ger", "Par\u00b7te\u00b7yen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Die voller Widerspruch, doch alle Wahrheit schreyen?", "tokens": ["Die", "vol\u00b7ler", "Wi\u00b7der\u00b7spruch", ",", "doch", "al\u00b7le", "Wahr\u00b7heit", "schre\u00b7yen", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ADV", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ein jeder reisset ein, und stellet wieder her,", "tokens": ["Ein", "je\u00b7der", "reis\u00b7set", "ein", ",", "und", "stel\u00b7let", "wie\u00b7der", "her", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VVFIN", "PTKVZ", "$,", "KON", "VVFIN", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und wird f\u00fcr sein Geb\u00e4u mit Lust ein M\u00e4rtyrer.", "tokens": ["Und", "wird", "f\u00fcr", "sein", "Ge\u00b7b\u00e4u", "mit", "Lust", "ein", "M\u00e4r\u00b7ty\u00b7rer", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "APPR", "PPOSAT", "NN", "APPR", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+--", "measure": "unknown.measure.penta"}, "line.5": {"text": "Der maa\u00dft sich an, mit Gott sein Werk zu \u00fcberlegen,", "tokens": ["Der", "maa\u00dft", "sich", "an", ",", "mit", "Gott", "sein", "Werk", "zu", "\u00fc\u00b7berl\u00b7e\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PRF", "PTKVZ", "$,", "APPR", "NN", "PPOSAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und dieser giebt sich M\u00fch den Himmel zu bewegen.", "tokens": ["Und", "die\u00b7ser", "giebt", "sich", "M\u00fch", "den", "Him\u00b7mel", "zu", "be\u00b7we\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VVFIN", "PRF", "NE", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Gieb jedem", "tokens": ["Gieb", "je\u00b7dem"], "token_info": ["word", "word"], "pos": ["VVIMP", "PIAT"], "meter": "-+-", "measure": "amphibrach.single"}, "line.8": {"text": "Und sey denn \u00fcberzeugt, ein jeder dreht die Welt.", "tokens": ["Und", "sey", "denn", "\u00fc\u00b7berz\u00b7eugt", ",", "ein", "je\u00b7der", "dreht", "die", "Welt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "VVPP", "$,", "ART", "PIS", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Spricht dieser: wandele! so spricht der andre: stehe!", "tokens": ["Spricht", "die\u00b7ser", ":", "wan\u00b7de\u00b7le", "!", "so", "spricht", "der", "and\u00b7re", ":", "ste\u00b7he", "!"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["VVFIN", "PDAT", "$.", "VVFIN", "$.", "ADV", "VVFIN", "ART", "ADJA", "$.", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Und jeder stirbt darauf, da\u00df seine richtig gehe.", "tokens": ["Und", "je\u00b7der", "stirbt", "da\u00b7rauf", ",", "da\u00df", "sei\u00b7ne", "rich\u00b7tig", "ge\u00b7he", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "PAV", "$,", "KOUS", "PPOSAT", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Der glaubt, durch keinen Gott die Welt hervorgebracht,", "tokens": ["Der", "glaubt", ",", "durch", "kei\u00b7nen", "Gott", "die", "Welt", "her\u00b7vor\u00b7ge\u00b7bracht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "$,", "APPR", "PIAT", "NN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Und jener braucht ihn kaum; er hat sie selbst gemacht.", "tokens": ["Und", "je\u00b7ner", "braucht", "ihn", "kaum", ";", "er", "hat", "sie", "selbst", "ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VVFIN", "PPER", "ADV", "$.", "PPER", "VAFIN", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Der lehrt die Anziehung zum Vortheil seiner Schwere,", "tokens": ["Der", "lehrt", "die", "An\u00b7zie\u00b7hung", "zum", "Vor\u00b7theil", "sei\u00b7ner", "Schwe\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ART", "NN", "APPRART", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Und der nimmt Wirbel an, und ficht f\u00fcr seine Lehre.", "tokens": ["Und", "der", "nimmt", "Wir\u00b7bel", "an", ",", "und", "ficht", "f\u00fcr", "sei\u00b7ne", "Leh\u00b7re", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "VVFIN", "NN", "PTKVZ", "$,", "KON", "ADJD", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Woher entsteht der Streit? \u2013 weil mancher Narr vergi\u00dft,", "tokens": ["Wo\u00b7her", "ent\u00b7steht", "der", "Streit", "?", "\u2013", "weil", "man\u00b7cher", "Narr", "ver\u00b7gi\u00dft", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "ART", "NN", "$.", "$(", "KOUS", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Da\u00df er die Creatur, und Gott der Sch\u00f6pfer ist.", "tokens": ["Da\u00df", "er", "die", "Crea\u00b7tur", ",", "und", "Gott", "der", "Sch\u00f6p\u00b7fer", "ist", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "$,", "KON", "NN", "ART", "NN", "VAFIN", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.17": {"text": "Weil er den Kreis verl\u00e4\u00dft, worinn sein Stand ihn schr\u00e4nket,", "tokens": ["Weil", "er", "den", "Kreis", "ver\u00b7l\u00e4\u00dft", ",", "wo\u00b7rinn", "sein", "Stand", "ihn", "schr\u00e4n\u00b7ket", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVFIN", "$,", "PWAV", "PPOSAT", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Und draussen lieber irrt, als drinnen richtig denket.", "tokens": ["Und", "draus\u00b7sen", "lie\u00b7ber", "irrt", ",", "als", "drin\u00b7nen", "rich\u00b7tig", "den\u00b7ket", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "VVFIN", "$,", "KOUS", "ADV", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Er kettet Schlu\u00df an Schlu\u00df, und baut Systemen drauf,", "tokens": ["Er", "ket\u00b7tet", "Schlu\u00df", "an", "Schlu\u00df", ",", "und", "baut", "Sys\u00b7te\u00b7men", "drauf", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "APPR", "NN", "$,", "KON", "VVFIN", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+---+", "measure": "unknown.measure.penta"}, "line.20": {"text": "Und h\u00e4ngt sie in der Luft, wie Gott die Welten, auf.", "tokens": ["Und", "h\u00e4ngt", "sie", "in", "der", "Luft", ",", "wie", "Gott", "die", "Wel\u00b7ten", ",", "auf", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "ART", "NN", "$,", "PWAV", "NN", "ART", "NN", "$,", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.10": {"line.1": {"text": "Auf Muthma\u00dfung gest\u00fctzt, willst du Gewi\u00dfheit finden?", "tokens": ["Auf", "Muth\u00b7ma\u00b7\u00dfung", "ge\u00b7st\u00fctzt", ",", "willst", "du", "Ge\u00b7wi\u00df\u00b7heit", "fin\u00b7den", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVPP", "$,", "VMFIN", "PPER", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "\u00bballein ich schliesse recht?\u00ab woraus? aus vesten Gr\u00fcnden?", "tokens": ["\u00bb", "al\u00b7lein", "ich", "schlies\u00b7se", "recht", "?", "\u00ab", "wo\u00b7raus", "?", "aus", "ves\u00b7ten", "Gr\u00fcn\u00b7den", "?"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "PPER", "VVFIN", "ADJD", "$.", "$(", "PWAV", "$.", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Sonst sey so klug du willst, die Folgen auszuziehn,", "tokens": ["Sonst", "sey", "so", "klug", "du", "willst", ",", "die", "Fol\u00b7gen", "aus\u00b7zu\u00b7ziehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "ADJD", "PPER", "VMFIN", "$,", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Biet alle Lehrer auf, vom Lock bis zum Corvin;", "tokens": ["Biet", "al\u00b7le", "Leh\u00b7rer", "auf", ",", "vom", "Lock", "bis", "zum", "Cor\u00b7vin", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PIAT", "NN", "PTKVZ", "$,", "APPRART", "NN", "APPR", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und reichte vom Saturn die Kette bis zur Erden,", "tokens": ["Und", "reich\u00b7te", "vom", "Sa\u00b7turn", "die", "Ket\u00b7te", "bis", "zur", "Er\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPRART", "NN", "ART", "NN", "APPR", "APPRART", "NN", "$,"], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.6": {"text": "So wird durch keinen Schlu\u00df der Irrthum Wahrheit werden!", "tokens": ["So", "wird", "durch", "kei\u00b7nen", "Schlu\u00df", "der", "Irr\u00b7thum", "Wahr\u00b7heit", "wer\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "APPR", "PIAT", "NN", "ART", "NN", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.11": {"line.1": {"text": "Schau, wie mit stolzem Haupt, das Sturm und Meer nicht beugt,", "tokens": ["Schau", ",", "wie", "mit", "stol\u00b7zem", "Haupt", ",", "das", "Sturm", "und", "Meer", "nicht", "beugt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PWAV", "APPR", "ADJA", "NN", "$,", "ART", "NN", "KON", "NN", "PTKNEG", "VVFIN", "$,"], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.2": {"text": "Venedig voller Trotz aus seinem Schlamme steigt;", "tokens": ["Ve\u00b7ne\u00b7dig", "vol\u00b7ler", "Trotz", "aus", "sei\u00b7nem", "Schlam\u00b7me", "steigt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.3": {"text": "Und sage: sollt es wohl, gebaut auf Sumpf, und Wellen,", "tokens": ["Und", "sa\u00b7ge", ":", "sollt", "es", "wohl", ",", "ge\u00b7baut", "auf", "Sumpf", ",", "und", "Wel\u00b7len", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "VMFIN", "PPER", "ADV", "$,", "VVPP", "APPR", "NN", "$,", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ein tausendj\u00e4hrig Haupt dem Sturm entgegen stellen:", "tokens": ["Ein", "tau\u00b7send\u00b7j\u00e4h\u00b7rig", "Haupt", "dem", "Sturm", "ent\u00b7ge\u00b7gen", "stel\u00b7len", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "ART", "NN", "PTKVZ", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wenn nicht die weise Kunst die schwache Last gesch\u00fctzt,", "tokens": ["Wenn", "nicht", "die", "wei\u00b7se", "Kunst", "die", "schwa\u00b7che", "Last", "ge\u00b7sch\u00fctzt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PTKNEG", "ART", "ADJA", "NN", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und, was der Schlamm nicht tr\u00e4gt, mit Pfeilern unterst\u00fctzt?", "tokens": ["Und", ",", "was", "der", "Schlamm", "nicht", "tr\u00e4gt", ",", "mit", "Pfei\u00b7lern", "un\u00b7ter\u00b7st\u00fctzt", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "$,", "PRELS", "ART", "NN", "PTKNEG", "VVFIN", "$,", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Da aber, wo Natur und Kunst den Grund versagen,", "tokens": ["Da", "a\u00b7ber", ",", "wo", "Na\u00b7tur", "und", "Kunst", "den", "Grund", "ver\u00b7sa\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$,", "PWAV", "NN", "KON", "NN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Wie kann ein grundlos Meer ein neu Venedig tragen?", "tokens": ["Wie", "kann", "ein", "grund\u00b7los", "Meer", "ein", "neu", "Ve\u00b7ne\u00b7dig", "tra\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "ART", "ADJD", "NN", "ART", "ADJD", "NE", "VVINF", "$."], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}}, "stanza.12": {"line.1": {"text": "La\u00df, auf den Grund zu sehn, die erste Regel seyn,", "tokens": ["La\u00df", ",", "auf", "den", "Grund", "zu", "sehn", ",", "die", "ers\u00b7te", "Re\u00b7gel", "seyn", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "$,", "APPR", "ART", "NN", "PTKZU", "VVINF", "$,", "ART", "ADJA", "NN", "VAINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Du baust selbst ein System, du reissest andre ein.", "tokens": ["Du", "baust", "selbst", "ein", "Sys\u00b7tem", ",", "du", "reis\u00b7sest", "and\u00b7re", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN", "$,", "PPER", "VVFIN", "PIS", "PTKVZ", "$."], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Sie bringt von unten auf Gewi\u00dfheit in die Lehren,", "tokens": ["Sie", "bringt", "von", "un\u00b7ten", "auf", "Ge\u00b7wi\u00df\u00b7heit", "in", "die", "Leh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ADV", "APPR", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und f\u00fchrt den graden Weg, den Irrthum zu zerst\u00f6ren.", "tokens": ["Und", "f\u00fchrt", "den", "gra\u00b7den", "Weg", ",", "den", "Irr\u00b7thum", "zu", "zer\u00b7st\u00f6\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "ADJA", "NN", "$,", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.13": {"line.1": {"text": "Sieh! wie ein Federheld, bald aufrecht, bald gekr\u00fcmmt,", "tokens": ["Sieh", "!", "wie", "ein", "Fe\u00b7der\u00b7held", ",", "bald", "auf\u00b7recht", ",", "bald", "ge\u00b7kr\u00fcmmt", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "$.", "PWAV", "ART", "NN", "$,", "ADV", "ADJD", "$,", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Um seinen Gegner tanzt, und tausend Lager nimmt.", "tokens": ["Um", "sei\u00b7nen", "Geg\u00b7ner", "tanzt", ",", "und", "tau\u00b7send", "La\u00b7ger", "nimmt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PPOSAT", "NN", "VVFIN", "$,", "KON", "CARD", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Er b\u00fcckt, er dehnet sich, und l\u00e4\u00dft die Klinge blitzen,", "tokens": ["Er", "b\u00fcckt", ",", "er", "deh\u00b7net", "sich", ",", "und", "l\u00e4\u00dft", "die", "Klin\u00b7ge", "blit\u00b7zen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VVFIN", "PRF", "$,", "KON", "VVFIN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Mit einem Fechterstreich ihm leicht die Hand zu ritzen.", "tokens": ["Mit", "ei\u00b7nem", "Fech\u00b7ter\u00b7streich", "ihm", "leicht", "die", "Hand", "zu", "rit\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PPER", "ADJD", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Vielleicht, mit mindrer Kraft, als er im Schwei\u00df verwandt,", "tokens": ["Viel\u00b7leicht", ",", "mit", "mind\u00b7rer", "Kraft", ",", "als", "er", "im", "Schwei\u00df", "ver\u00b7wandt", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "APPR", "ADJA", "NN", "$,", "KOUS", "PPER", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Rei\u00dft ihm ein St\u00e4rkerer die Waffen aus der Hand.", "tokens": ["Rei\u00dft", "ihm", "ein", "St\u00e4r\u00b7ke\u00b7rer", "die", "Waf\u00b7fen", "aus", "der", "Hand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "So qu\u00e4lt sich ein Sophist von th\u00f6rigten Systemen,", "tokens": ["So", "qu\u00e4lt", "sich", "ein", "So\u00b7phist", "von", "th\u00f6\u00b7rig\u00b7ten", "Sys\u00b7te\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "ART", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.8": {"text": "Mit l\u00e4cherlicher Wuth, den kleinsten Satz zu nehmen.", "tokens": ["Mit", "l\u00e4\u00b7cher\u00b7li\u00b7cher", "Wuth", ",", "den", "kleins\u00b7ten", "Satz", "zu", "neh\u00b7men", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "ART", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Was nur f\u00fcr einen Streich die Zankkunst ausgedacht,", "tokens": ["Was", "nur", "f\u00fcr", "ei\u00b7nen", "Streich", "die", "Zank\u00b7kunst", "aus\u00b7ge\u00b7dacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "APPR", "ART", "NN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Was der Betrug ersann, wird v\u00f6llig durchgemacht.", "tokens": ["Was", "der", "Be\u00b7trug", "er\u00b7sann", ",", "wird", "v\u00f6l\u00b7lig", "durch\u00b7ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "NN", "VVFIN", "$,", "VAFIN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Wie endigt sich der Kampf? \u2013 dem ward die Hand zerrissen:", "tokens": ["Wie", "en\u00b7digt", "sich", "der", "Kampf", "?", "\u2013", "dem", "ward", "die", "Hand", "zer\u00b7ris\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PRF", "ART", "NN", "$.", "$(", "PDS", "VAFIN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "\u00bbund dieser?\u00ab \u2013 wird vielleicht ein Wort ver\u00e4ndern m\u00fcssen.", "tokens": ["\u00bb", "und", "die\u00b7ser", "?", "\u00ab", "\u2013", "wird", "viel\u00b7leicht", "ein", "Wort", "ver\u00b7\u00e4n\u00b7dern", "m\u00fcs\u00b7sen", "."], "token_info": ["punct", "word", "word", "punct", "punct", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KON", "PDS", "$.", "$(", "$(", "VAFIN", "ADV", "ART", "NN", "VVINF", "VMINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "O Gaukler, und Sophist, ihr fechtet nur zum Scherz!", "tokens": ["O", "Gauk\u00b7ler", ",", "und", "So\u00b7phist", ",", "ihr", "fech\u00b7tet", "nur", "zum", "Scherz", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "KON", "NN", "$,", "PPER", "VVFIN", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Der Ernst st\u00fcrmt auf den Grund, und st\u00f6\u00dft sein Schwert ins Herz.", "tokens": ["Der", "Ernst", "st\u00fcrmt", "auf", "den", "Grund", ",", "und", "st\u00f6\u00dft", "sein", "Schwert", "ins", "Herz", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ART", "NN", "$,", "KON", "VVFIN", "PPOSAT", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.14": {"line.1": {"text": "Klagt ihr, o Sterbliche, nach m\u00fc\u00dfigen Gez\u00e4nken,", "tokens": ["Klagt", "ihr", ",", "o", "Sterb\u00b7li\u00b7che", ",", "nach", "m\u00fc\u00b7\u00dfi\u00b7gen", "Ge\u00b7z\u00e4n\u00b7ken", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "FM", "NN", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Das Leben sey zu kurz, das Wichtigste zu denken?", "tokens": ["Das", "Le\u00b7ben", "sey", "zu", "kurz", ",", "das", "Wich\u00b7tigs\u00b7te", "zu", "den\u00b7ken", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PTKA", "ADJD", "$,", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Spart eure Zeit, und flieht der Schule Z\u00e4nkereyn;", "tokens": ["Spart", "eu\u00b7re", "Zeit", ",", "und", "flieht", "der", "Schu\u00b7le", "Z\u00e4n\u00b7ke\u00b7reyn", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPOSAT", "NN", "$,", "KON", "VVFIN", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wie Simson, fa\u00dft den Grund, und rei\u00dft die Seulen ein!", "tokens": ["Wie", "Sim\u00b7son", ",", "fa\u00dft", "den", "Grund", ",", "und", "rei\u00dft", "die", "Seu\u00b7len", "ein", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NE", "$,", "VVFIN", "ART", "NN", "$,", "KON", "VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die Last, die St\u00fcrme kaum in hundert Jahren biegen,", "tokens": ["Die", "Last", ",", "die", "St\u00fcr\u00b7me", "kaum", "in", "hun\u00b7dert", "Jah\u00b7ren", "bie\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "ADV", "APPR", "CARD", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wird, wenn die Basis sinkt, zugleich darnieder liegen.", "tokens": ["Wird", ",", "wenn", "die", "Ba\u00b7sis", "sinkt", ",", "zu\u00b7gleich", "dar\u00b7nie\u00b7der", "lie\u00b7gen", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "$,", "KOUS", "ART", "NE", "VVFIN", "$,", "ADV", "PAV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Der Lehrer des Korans, mit viel Gelehrsamkeit,", "tokens": ["Der", "Leh\u00b7rer", "des", "Ko\u00b7rans", ",", "mit", "viel", "Ge\u00b7lehr\u00b7sam\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$,", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Durch langen Schwei\u00df erkauft, und Kosten vieler Zeit,", "tokens": ["Durch", "lan\u00b7gen", "Schwei\u00df", "er\u00b7kauft", ",", "und", "Kos\u00b7ten", "vie\u00b7ler", "Zeit", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "$,", "KON", "NN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Uebt \u00fcber jeden Satz die schwindlichten Gedanken,", "tokens": ["Uebt", "\u00fc\u00b7ber", "je\u00b7den", "Satz", "die", "schwind\u00b7lich\u00b7ten", "Ge\u00b7dan\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PIAT", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+---+-", "measure": "unknown.measure.penta"}, "line.10": {"text": "Wor\u00fcber Alis Zunft, und Omars Sch\u00fcler zanken,", "tokens": ["Wo\u00b7r\u00fc\u00b7ber", "A\u00b7lis", "Zunft", ",", "und", "O\u00b7mars", "Sch\u00fc\u00b7ler", "zan\u00b7ken", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NE", "NN", "$,", "KON", "NN", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Wie viel vergebne M\u00fch hat er umsonst verwandt,", "tokens": ["Wie", "viel", "ver\u00b7geb\u00b7ne", "M\u00fch", "hat", "er", "um\u00b7sonst", "ver\u00b7wandt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIAT", "ADJA", "NN", "VAFIN", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Eh er ihr Lehrgeb\u00e4u von Satz zu Satz verstand!", "tokens": ["Eh", "er", "ihr", "Lehr\u00b7ge\u00b7b\u00e4u", "von", "Satz", "zu", "Satz", "ver\u00b7stand", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "APPR", "NN", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Doch ohne die Geduld so th\u00f6richt zu erm\u00fcden,", "tokens": ["Doch", "oh\u00b7ne", "die", "Ge\u00b7duld", "so", "th\u00f6\u00b7richt", "zu", "er\u00b7m\u00fc\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "ADV", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "H\u00e4tt er in kurzer Zeit den ganzen Streit entschieden;", "tokens": ["H\u00e4tt", "er", "in", "kur\u00b7zer", "Zeit", "den", "gan\u00b7zen", "Streit", "ent\u00b7schie\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ADJA", "NN", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Es zeigt der erste Blick auf Mahomets Geb\u00e4u,", "tokens": ["Es", "zeigt", "der", "ers\u00b7te", "Blick", "auf", "Ma\u00b7ho\u00b7mets", "Ge\u00b7b\u00e4u", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "APPR", "NE", "NE", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Da\u00df er ein Schw\u00e4rmer war, und dies voll Possen sey.", "tokens": ["Da\u00df", "er", "ein", "Schw\u00e4r\u00b7mer", "war", ",", "und", "dies", "voll", "Pos\u00b7sen", "sey", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VAFIN", "$,", "KON", "PDS", "ADJD", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.15": {"line.1": {"text": "So such in keinem Streit dich unn\u00fctz abzumatten;", "tokens": ["So", "such", "in", "kei\u00b7nem", "Streit", "dich", "un\u00b7n\u00fctz", "ab\u00b7zu\u00b7mat\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "PIAT", "NN", "PPER", "ADJD", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Dring gleich auf deinen Feind, und fechte nicht mit Schatten.", "tokens": ["Dring", "gleich", "auf", "dei\u00b7nen", "Feind", ",", "und", "fech\u00b7te", "nicht", "mit", "Schat\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "PPOSAT", "NN", "$,", "KON", "VVFIN", "PTKNEG", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Brauch deine Augen selbst; nimm nichts auf Glauben an;", "tokens": ["Brauch", "dei\u00b7ne", "Au\u00b7gen", "selbst", ";", "nimm", "nichts", "auf", "Glau\u00b7ben", "an", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "ADV", "$.", "VVIMP", "PIS", "APPR", "NN", "PTKVZ", "$."], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.4": {"text": "Den Dienst versage nie, den Beyfall jedermann.", "tokens": ["Den", "Dienst", "ver\u00b7sa\u00b7ge", "nie", ",", "den", "Bey\u00b7fall", "je\u00b7der\u00b7mann", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "$,", "ART", "NN", "PIS", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Denk alles, was du glaubst, noch einmal ernsthaft \u00fcber;", "tokens": ["Denk", "al\u00b7les", ",", "was", "du", "glaubst", ",", "noch", "ein\u00b7mal", "ernst\u00b7haft", "\u00fc\u00b7ber", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PIS", "$,", "PWS", "PPER", "VVFIN", "$,", "ADV", "ADV", "ADJD", "APPR", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und eh du weiter eilst, halt noch, und zweifle lieber.", "tokens": ["Und", "eh", "du", "wei\u00b7ter", "eilst", ",", "halt", "noch", ",", "und", "zweif\u00b7le", "lie\u00b7ber", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "VVFIN", "$,", "VVFIN", "ADV", "$,", "KON", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Gieb keinem Vorurtheil des Alterthumes Platz;", "tokens": ["Gieb", "kei\u00b7nem", "Vor\u00b7urt\u00b7heil", "des", "Al\u00b7ter\u00b7thu\u00b7mes", "Platz", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PIAT", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Der aller\u00e4lteste ist oft der schw\u00e4chste Satz,", "tokens": ["Der", "al\u00b7le\u00b7r\u00e4l\u00b7tes\u00b7te", "ist", "oft", "der", "schw\u00e4chs\u00b7te", "Satz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VAFIN", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Im Irrthum erst erzeugt, durch Ansehn angepriesen,", "tokens": ["Im", "Irr\u00b7thum", "erst", "er\u00b7zeugt", ",", "durch", "An\u00b7sehn", "an\u00b7ge\u00b7prie\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADV", "VVPP", "$,", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Geheiligt durch die Zeit, und durch die Zeit erwiesen.", "tokens": ["Ge\u00b7hei\u00b7ligt", "durch", "die", "Zeit", ",", "und", "durch", "die", "Zeit", "er\u00b7wie\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "APPR", "ART", "NN", "$,", "KON", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Den Aberglauben flieh, der Einbildung Betrug;", "tokens": ["Den", "A\u00b7berg\u00b7lau\u00b7ben", "flieh", ",", "der", "Ein\u00b7bil\u00b7dung", "Be\u00b7trug", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "ART", "NN", "NN", "$."], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.12": {"text": "Da\u00df ganz ein Volk so glaubt, sey dir nicht Grund genug.", "tokens": ["Da\u00df", "ganz", "ein", "Volk", "so", "glaubt", ",", "sey", "dir", "nicht", "Grund", "ge\u00b7nug", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "ADV", "VVFIN", "$,", "VAFIN", "PPER", "PTKNEG", "NN", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Am ersten zweifle da, wo's schrecklich ist zu zweifeln;", "tokens": ["Am", "ers\u00b7ten", "zweif\u00b7le", "da", ",", "wo's", "schreck\u00b7lich", "ist", "zu", "zwei\u00b7feln", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "VVFIN", "ADV", "$,", "PWAV", "ADJD", "VAFIN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Was nicht mit Gr\u00fcnden kann, das sch\u00fctzet sich mit Teufeln.", "tokens": ["Was", "nicht", "mit", "Gr\u00fcn\u00b7den", "kann", ",", "das", "sch\u00fct\u00b7zet", "sich", "mit", "Teu\u00b7feln", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PTKNEG", "APPR", "NN", "VMFIN", "$,", "PDS", "VVFIN", "PRF", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Folg keiner Secte nach, so alt ihr Ursprung ist,", "tokens": ["Folg", "kei\u00b7ner", "Sec\u00b7te", "nach", ",", "so", "alt", "ihr", "Ur\u00b7sprung", "ist", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PIAT", "NN", "PTKVZ", "$,", "ADV", "ADJD", "PPOSAT", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Er mag vom Zerduscht seyn, er mag vom Trismegist.", "tokens": ["Er", "mag", "vom", "Zer\u00b7duscht", "seyn", ",", "er", "mag", "vom", "Tris\u00b7me\u00b7gist", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPRART", "NN", "VAINF", "$,", "PPER", "VMFIN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Die Meinung, und die Mod'", "tokens": ["Die", "Mei\u00b7nung", ",", "und", "die", "Mod'"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "$,", "KON", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.18": {"text": "Ein Volk von Sohn auf Sohn, und l\u00e4uft durch ganze Reiche.", "tokens": ["Ein", "Volk", "von", "Sohn", "auf", "Sohn", ",", "und", "l\u00e4uft", "durch", "gan\u00b7ze", "Rei\u00b7che", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "APPR", "NN", "$,", "KON", "VVFIN", "APPR", "ADJA", "NE", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Das, was die neue tr\u00e4gt, verlacht die alte Welt,", "tokens": ["Das", ",", "was", "die", "neu\u00b7e", "tr\u00e4gt", ",", "ver\u00b7lacht", "die", "al\u00b7te", "Welt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "$,", "PRELS", "ART", "ADJA", "VVFIN", "$,", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Europa tadelt oft, was Asien gef\u00e4llt.", "tokens": ["Eu\u00b7ro\u00b7pa", "ta\u00b7delt", "oft", ",", "was", "A\u00b7sien", "ge\u00b7f\u00e4llt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADV", "$,", "PRELS", "NE", "VVPP", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.21": {"text": "Ein jedes eignes Volk h\u00e4lt seine Regeln besser,", "tokens": ["Ein", "je\u00b7des", "eig\u00b7nes", "Volk", "h\u00e4lt", "sei\u00b7ne", "Re\u00b7geln", "bes\u00b7ser", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "ADJA", "NN", "VVFIN", "PPOSAT", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Und Gottesdienst,", "tokens": ["Und", "Got\u00b7tes\u00b7dienst", ","], "token_info": ["word", "word", "punct"], "pos": ["KON", "NN", "$,"], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.16": {"line.1": {"text": "Wie kommts, da\u00df Pechins Sch\u00f6nen nicht ohne Straucheln gehn?", "tokens": ["Wie", "kommts", ",", "da\u00df", "Pe\u00b7chins", "Sch\u00f6\u00b7nen", "nicht", "oh\u00b7ne", "Strau\u00b7cheln", "gehn", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "$,", "KOUS", "NE", "NN", "PTKNEG", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Weil die Chineser glauben, ein kleiner Fu\u00df sey sch\u00f6n.", "tokens": ["Weil", "die", "Chi\u00b7ne\u00b7ser", "glau\u00b7ben", ",", "ein", "klei\u00b7ner", "Fu\u00df", "sey", "sch\u00f6n", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "VVINF", "$,", "ART", "ADJA", "NN", "VAFIN", "ADJD", "$."], "meter": "--+--+--+-+-+", "measure": "anapaest.tri.plus"}, "line.3": {"text": "In Fesseln bildet man des M\u00e4dgens zarte F\u00fc\u00dfe,", "tokens": ["In", "Fes\u00b7seln", "bil\u00b7det", "man", "des", "M\u00e4d\u00b7gens", "zar\u00b7te", "F\u00fc\u00b7\u00dfe", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PIS", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und sorgt nicht, da\u00df sie einst auf Vieren kriechen m\u00fcsse.", "tokens": ["Und", "sorgt", "nicht", ",", "da\u00df", "sie", "einst", "auf", "Vie\u00b7ren", "krie\u00b7chen", "m\u00fcs\u00b7se", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKNEG", "$,", "KOUS", "PPER", "ADV", "APPR", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die H\u00f6ckernation, die Gulliver ersann,", "tokens": ["Die", "H\u00f6\u00b7cker\u00b7na\u00b7ti\u00b7on", ",", "die", "Gul\u00b7li\u00b7ver", "er\u00b7sann", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Sieht grade Europ\u00e4er f\u00fcr Mi\u00dfgeburten an.", "tokens": ["Sieht", "gra\u00b7de", "Eu\u00b7ro\u00b7p\u00e4\u00b7er", "f\u00fcr", "Mi\u00df\u00b7ge\u00b7bur\u00b7ten", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "NN", "APPR", "NN", "PTKVZ", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.7": {"text": "So \u00e4fft ein alter Wahn mit S\u00e4tzen und Gestalten,", "tokens": ["So", "\u00e4fft", "ein", "al\u00b7ter", "Wahn", "mit", "S\u00e4t\u00b7zen", "und", "Ge\u00b7stal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Die wir f\u00fcr die Natur und f\u00fcr die Wahrheit halten.", "tokens": ["Die", "wir", "f\u00fcr", "die", "Na\u00b7tur", "und", "f\u00fcr", "die", "Wahr\u00b7heit", "hal\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "ART", "NN", "KON", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Der Lehrer nahm es an, gest\u00fctzet zwar auf nichts;", "tokens": ["Der", "Leh\u00b7rer", "nahm", "es", "an", ",", "ge\u00b7st\u00fct\u00b7zet", "zwar", "auf", "nichts", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "PTKVZ", "$,", "VVFIN", "ADV", "APPR", "PIS", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Der Sch\u00fcler fand Beweis; dies starke Wort: er sprichts.", "tokens": ["Der", "Sch\u00fc\u00b7ler", "fand", "Be\u00b7weis", ";", "dies", "star\u00b7ke", "Wort", ":", "er", "sprichts", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "NN", "$.", "PDS", "ADJA", "NN", "$.", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Der Vater lie\u00df dem Sohn ein erbliches Verm\u00f6gen,", "tokens": ["Der", "Va\u00b7ter", "lie\u00df", "dem", "Sohn", "ein", "er\u00b7bli\u00b7ches", "Ver\u00b7m\u00f6\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.12": {"text": "Den Glauben, und sein Geld, den Irrthum, und den Segen;", "tokens": ["Den", "Glau\u00b7ben", ",", "und", "sein", "Geld", ",", "den", "Irr\u00b7thum", ",", "und", "den", "Se\u00b7gen", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "KON", "PPOSAT", "NN", "$,", "ART", "NN", "$,", "KON", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Und dieser, dem Gehei\u00df des Vaters unterthan,", "tokens": ["Und", "die\u00b7ser", ",", "dem", "Ge\u00b7hei\u00df", "des", "Va\u00b7ters", "un\u00b7ter\u00b7than", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "$,", "ART", "NN", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Empfing, mit gleicher Lust, die G\u00fcter und den Wahn.", "tokens": ["Emp\u00b7fing", ",", "mit", "glei\u00b7cher", "Lust", ",", "die", "G\u00fc\u00b7ter", "und", "den", "Wahn", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "APPR", "ADJA", "NN", "$,", "ART", "NN", "KON", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "So ward und wuchs der Wahn, so wie durch neu Gew\u00e4sser", "tokens": ["So", "ward", "und", "wuchs", "der", "Wahn", ",", "so", "wie", "durch", "neu", "Ge\u00b7w\u00e4s\u00b7ser"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "KON", "VVFIN", "ART", "NN", "$,", "ADV", "KOKOM", "APPR", "ADJD", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Ein Strom im Laufe schwillt, und wird im Gehen gr\u00f6\u00dfer.", "tokens": ["Ein", "Strom", "im", "Lau\u00b7fe", "schwillt", ",", "und", "wird", "im", "Ge\u00b7hen", "gr\u00f6\u00b7\u00dfer", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "VVFIN", "$,", "KON", "VAFIN", "APPRART", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Daher zieht, jede Welt, Barbaren Africa,", "tokens": ["Da\u00b7her", "zieht", ",", "je\u00b7de", "Welt", ",", "Bar\u00b7ba\u00b7ren", "A\u00b7fri\u00b7ca", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "$,", "PIAT", "NN", "$,", "NN", "NE", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Europa Christen auf, und T\u00fcrken Asia.", "tokens": ["Eu\u00b7ro\u00b7pa", "Chris\u00b7ten", "auf", ",", "und", "T\u00fcr\u00b7ken", "A\u00b7sia", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NE", "PTKVZ", "$,", "KON", "NN", "NE", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.19": {"text": "Und jeder Lehrer s\u00e4t der eignen Meinung Samen,", "tokens": ["Und", "je\u00b7der", "Leh\u00b7rer", "s\u00e4t", "der", "eig\u00b7nen", "Mei\u00b7nung", "Sa\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "VVFIN", "ART", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Und Secten stehen auf, getauft mit seinem Namen:", "tokens": ["Und", "Sec\u00b7ten", "ste\u00b7hen", "auf", ",", "ge\u00b7tauft", "mit", "sei\u00b7nem", "Na\u00b7men", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "PTKVZ", "$,", "VVPP", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Der stoisch, der platonisch, der ein Epicur\u00e4r,", "tokens": ["Der", "sto\u00b7isch", ",", "der", "pla\u00b7to\u00b7nisch", ",", "der", "ein", "E\u00b7pi\u00b7cu\u00b7r\u00e4r", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "$,", "PRELS", "ADJD", "$,", "PRELS", "ART", "NN", "$,"], "meter": "-+--+-+-++--+", "measure": "iambic.hexa.relaxed"}, "line.22": {"text": "Der scotisch, der thomistisch \u2013 und hundert andre mehr.", "tokens": ["Der", "sco\u00b7tisch", ",", "der", "tho\u00b7mis\u00b7tisch", "\u2013", "und", "hun\u00b7dert", "and\u00b7re", "mehr", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "$,", "PRELS", "ADJD", "$(", "KON", "CARD", "PIS", "ADV", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.23": {"text": "Doch, wer Vernunft gebraucht, erbt nicht vom Demokriten,", "tokens": ["Doch", ",", "wer", "Ver\u00b7nunft", "ge\u00b7braucht", ",", "erbt", "nicht", "vom", "De\u00b7mo\u00b7kri\u00b7ten", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "PWS", "NN", "VVPP", "$,", "VVFIN", "PTKNEG", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Und von dem Plato nicht, und nicht vom Stagiriten,", "tokens": ["Und", "von", "dem", "Pla\u00b7to", "nicht", ",", "und", "nicht", "vom", "Sta\u00b7gi\u00b7ri\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NE", "PTKNEG", "$,", "KON", "PTKNEG", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Noch Wolf, noch vom Cartes; nimmt selbst nicht Wahrheit an,", "tokens": ["Noch", "Wolf", ",", "noch", "vom", "Car\u00b7tes", ";", "nimmt", "selbst", "nicht", "Wahr\u00b7heit", "an", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NE", "$,", "ADV", "APPRART", "NN", "$.", "VVFIN", "ADV", "PTKNEG", "NN", "PTKVZ", "$,"], "meter": "-+--+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.26": {"text": "Eh er sie selbst gepr\u00fcft; er ist sein eigner Mann,", "tokens": ["Eh", "er", "sie", "selbst", "ge\u00b7pr\u00fcft", ";", "er", "ist", "sein", "eig\u00b7ner", "Mann", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "ADV", "VVPP", "$.", "PPER", "VAFIN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Der allerorten her, wie Bienen Honig, sammlet,", "tokens": ["Der", "al\u00b7le\u00b7ror\u00b7ten", "her", ",", "wie", "Bie\u00b7nen", "Ho\u00b7nig", ",", "samm\u00b7let", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "PIS", "PTKVZ", "$,", "PWAV", "NN", "NN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Mit allen richtig spricht, doch nie mit andern stammlet;", "tokens": ["Mit", "al\u00b7len", "rich\u00b7tig", "spricht", ",", "doch", "nie", "mit", "an\u00b7dern", "stamm\u00b7let", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "ADJD", "VVFIN", "$,", "ADV", "ADV", "APPR", "PIS", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Sein eigenes Orakel;", "tokens": ["Sein", "ei\u00b7ge\u00b7nes", "O\u00b7ra\u00b7kel", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$."], "meter": "-+---+-", "measure": "dactylic.init"}, "line.30": {"text": "Und, wenn er selbst verstummet, kein Delphos fragen wird;", "tokens": ["Und", ",", "wenn", "er", "selbst", "ver\u00b7stum\u00b7met", ",", "kein", "Del\u00b7phos", "fra\u00b7gen", "wird", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "PPER", "ADV", "VVFIN", "$,", "PIAT", "NN", "VVINF", "VAFIN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.31": {"text": "Der seine Wahrheit n\u00fctzt, sich nicht vom Ziel entfernet,", "tokens": ["Der", "sei\u00b7ne", "Wahr\u00b7heit", "n\u00fctzt", ",", "sich", "nicht", "vom", "Ziel", "ent\u00b7fer\u00b7net", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "VVFIN", "$,", "PRF", "PTKNEG", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Und alles zum Gebrauch, nichts blo\u00df aus Neugier, lernet.", "tokens": ["Und", "al\u00b7les", "zum", "Ge\u00b7brauch", ",", "nichts", "blo\u00df", "aus", "Neu\u00b7gier", ",", "ler\u00b7net", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "PIS", "APPRART", "NN", "$,", "PIS", "ADV", "APPR", "NN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.17": {"line.1": {"text": "Arbeite dich im Schwall der Meinungen empor;", "tokens": ["Ar\u00b7bei\u00b7te", "dich", "im", "Schwall", "der", "Mei\u00b7nun\u00b7gen", "em\u00b7por", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "APPRART", "NN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Ergreif den n\u00e4chsten Fels, und steig am Strand empor,", "tokens": ["Er\u00b7greif", "den", "n\u00e4chs\u00b7ten", "Fels", ",", "und", "steig", "am", "Strand", "em\u00b7por", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ART", "ADJA", "NN", "$,", "KON", "VVFIN", "APPRART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Eh dich der volle Strom, die Beute seiner Wogen,", "tokens": ["Eh", "dich", "der", "vol\u00b7le", "Strom", ",", "die", "Beu\u00b7te", "sei\u00b7ner", "Wo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "$,", "ART", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ins uferlose Meer mit sich hinabgezogen:", "tokens": ["Ins", "u\u00b7fer\u00b7lo\u00b7se", "Meer", "mit", "sich", "hin\u00b7ab\u00b7ge\u00b7zo\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "APPR", "PRF", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Umsonst irrt da dein Aug, umsonst suchst du den Strand,", "tokens": ["Um\u00b7sonst", "irrt", "da", "dein", "Aug", ",", "um\u00b7sonst", "suchst", "du", "den", "Strand", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "PPOSAT", "NN", "$,", "ADV", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und schwimmst mit aller Macht, und siehst nicht wieder Land.", "tokens": ["Und", "schwimmst", "mit", "al\u00b7ler", "Macht", ",", "und", "siehst", "nicht", "wie\u00b7der", "Land", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PIAT", "NN", "$,", "KON", "VVFIN", "PTKNEG", "ADV", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Versuche bald, und oft die Kr\u00e4fte deiner Fl\u00fcgel;", "tokens": ["Ver\u00b7su\u00b7che", "bald", ",", "und", "oft", "die", "Kr\u00e4f\u00b7te", "dei\u00b7ner", "Fl\u00fc\u00b7gel", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "$,", "KON", "ADV", "ART", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Streich erst am Boden her, dann schwinge dich auf H\u00fcgel:", "tokens": ["Streich", "erst", "am", "Bo\u00b7den", "her", ",", "dann", "schwin\u00b7ge", "dich", "auf", "H\u00fc\u00b7gel", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "APPRART", "NN", "PTKVZ", "$,", "ADV", "VVFIN", "PRF", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Ein jeder Flug erweckt, und st\u00e4rket die Begier,", "tokens": ["Ein", "je\u00b7der", "Flug", "er\u00b7weckt", ",", "und", "st\u00e4r\u00b7ket", "die", "Be\u00b7gier", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VVPP", "$,", "KON", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Zuletzt siehst du mit Lust Gebirge unter dir,", "tokens": ["Zu\u00b7letzt", "siehst", "du", "mit", "Lust", "Ge\u00b7bir\u00b7ge", "un\u00b7ter", "dir", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "NN", "NN", "APPR", "PPER", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Die tr\u00e4ge Pilgrimme, noch unge\u00fcbt im Wandern,", "tokens": ["Die", "tr\u00e4\u00b7ge", "Pil\u00b7grim\u00b7me", ",", "noch", "un\u00b7ge\u00b7\u00fcbt", "im", "Wan\u00b7dern", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ADV", "ADJD", "APPRART", "NN", "$,"], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.12": {"text": "Mit Schrecken vor sich sehn, und eines auf dem andern.", "tokens": ["Mit", "Schre\u00b7cken", "vor", "sich", "sehn", ",", "und", "ei\u00b7nes", "auf", "dem", "an\u00b7dern", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "PRF", "VVINF", "$,", "KON", "ART", "APPR", "ART", "ADJA", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Wenn nicht der J\u00fcngling schon Vernunft im steten Flei\u00df", "tokens": ["Wenn", "nicht", "der", "J\u00fcng\u00b7ling", "schon", "Ver\u00b7nunft", "im", "ste\u00b7ten", "Flei\u00df"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PTKNEG", "ART", "NN", "ADV", "NN", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Zum Ueberlegen \u00fcbt, wie n\u00fctzt sie wohl der Greis?", "tokens": ["Zum", "Ue\u00b7ber\u00b7le\u00b7gen", "\u00fcbt", ",", "wie", "n\u00fctzt", "sie", "wohl", "der", "Greis", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "$,", "PWAV", "VVFIN", "PPER", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Der, so die Fertigkeit im Denken zu erhalten,", "tokens": ["Der", ",", "so", "die", "Fer\u00b7tig\u00b7keit", "im", "Den\u00b7ken", "zu", "er\u00b7hal\u00b7ten", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "ADV", "ART", "NN", "APPRART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Ins hohe Alter spart, h\u00e4ngt sich, gleich einem Alten,", "tokens": ["Ins", "ho\u00b7he", "Al\u00b7ter", "spart", ",", "h\u00e4ngt", "sich", ",", "gleich", "ei\u00b7nem", "Al\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "VVFIN", "$,", "VVFIN", "PRF", "$,", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Dem schon der Bart gereift, dem G\u00e4ngelwagen an,", "tokens": ["Dem", "schon", "der", "Bart", "ge\u00b7reift", ",", "dem", "G\u00e4n\u00b7ge\u00b7lwa\u00b7gen", "an", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ART", "NN", "VVPP", "$,", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Und lernet dann erst gehn, wenn gar kein Fu\u00df mehr kann.", "tokens": ["Und", "ler\u00b7net", "dann", "erst", "gehn", ",", "wenn", "gar", "kein", "Fu\u00df", "mehr", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ADV", "VVINF", "$,", "KOUS", "ADV", "PIAT", "NN", "ADV", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.18": {"line.1": {"text": "Dies ist die Klugheit dann, die dich zu H\u00f6hen leitet,", "tokens": ["Dies", "ist", "die", "Klug\u00b7heit", "dann", ",", "die", "dich", "zu", "H\u00f6\u00b7hen", "lei\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "ADV", "$,", "PRELS", "PRF", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wohin der halbe Mensch, der P\u00f6pel, niemals schreitet.", "tokens": ["Wo\u00b7hin", "der", "hal\u00b7be", "Mensch", ",", "der", "P\u00f6\u00b7pel", ",", "nie\u00b7mals", "schrei\u00b7tet", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADJA", "NN", "$,", "ART", "NN", "$,", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "So ungleich gab zwar Gott Vernunft dem Menschen nie,", "tokens": ["So", "un\u00b7gleich", "gab", "zwar", "Gott", "Ver\u00b7nunft", "dem", "Men\u00b7schen", "nie", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "ADV", "NN", "NN", "ART", "NN", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Da\u00df der, wie Engel denkt, der etwas mehr als Vieh:", "tokens": ["Da\u00df", "der", ",", "wie", "En\u00b7gel", "denkt", ",", "der", "et\u00b7was", "mehr", "als", "Vieh", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "$,", "PWAV", "NE", "VVFIN", "$,", "PRELS", "ADV", "PIAT", "KOKOM", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wohin Aristotels", "tokens": ["Wo\u00b7hin", "A\u00b7ris\u00b7to\u00b7tels"], "token_info": ["word", "word"], "pos": ["PWAV", "NE"], "meter": "--+-+-", "measure": "anapaest.init"}, "line.6": {"text": "Dahin f\u00fchrt auch der Flei\u00df die schw\u00e4chern Xenokraten.", "tokens": ["Da\u00b7hin", "f\u00fchrt", "auch", "der", "Flei\u00df", "die", "schw\u00e4\u00b7chern", "Xe\u00b7no\u00b7kra\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "ADV", "ART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Flieh dann die Uebung nicht, zu gro\u00df auf dein Genie,", "tokens": ["Flieh", "dann", "die", "Ue\u00b7bung", "nicht", ",", "zu", "gro\u00df", "auf", "dein", "Ge\u00b7nie", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "PTKNEG", "$,", "PTKA", "ADJD", "APPR", "PPOSAT", "NN", "$,"], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.8": {"text": "Und denke nicht so stolz, dein Geist ersetze sie.", "tokens": ["Und", "den\u00b7ke", "nicht", "so", "stolz", ",", "dein", "Geist", "er\u00b7set\u00b7ze", "sie", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKNEG", "ADV", "ADJD", "$,", "PPOSAT", "NN", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Der Kranke, der getrost die Mittel von sich setzet,", "tokens": ["Der", "Kran\u00b7ke", ",", "der", "ge\u00b7trost", "die", "Mit\u00b7tel", "von", "sich", "set\u00b7zet", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ADJD", "ART", "NN", "APPR", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Und weil er St\u00e4rke merkt, sie f\u00fcr entbehrlich sch\u00e4tzet,", "tokens": ["Und", "weil", "er", "St\u00e4r\u00b7ke", "merkt", ",", "sie", "f\u00fcr", "ent\u00b7behr\u00b7lich", "sch\u00e4t\u00b7zet", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "NN", "VVFIN", "$,", "PPER", "APPR", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Giebt ein gewisses Zeichen, je weniger er klagt,", "tokens": ["Giebt", "ein", "ge\u00b7wis\u00b7ses", "Zei\u00b7chen", ",", "je", "we\u00b7ni\u00b7ger", "er", "klagt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "$,", "ADV", "ADV", "PPER", "VVFIN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.12": {"text": "Da\u00df schon der Tod im Fieber an seinem Herzen nagt;", "tokens": ["Da\u00df", "schon", "der", "Tod", "im", "Fie\u00b7ber", "an", "sei\u00b7nem", "Her\u00b7zen", "nagt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "APPRART", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.13": {"text": "Inde\u00df verzehret es die S\u00e4fte seiner Glieder,", "tokens": ["In\u00b7de\u00df", "ver\u00b7zeh\u00b7ret", "es", "die", "S\u00e4f\u00b7te", "sei\u00b7ner", "Glie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "ART", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Und fri\u00dft ihn langsam auf, und wirft ihn endlich nieder.", "tokens": ["Und", "fri\u00dft", "ihn", "lang\u00b7sam", "auf", ",", "und", "wirft", "ihn", "end\u00b7lich", "nie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADJD", "PTKVZ", "$,", "KON", "VVFIN", "PPER", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "So langsam, und so still verzehret mit der Zeit,", "tokens": ["So", "lang\u00b7sam", ",", "und", "so", "still", "ver\u00b7zeh\u00b7ret", "mit", "der", "Zeit", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "KON", "ADV", "ADJD", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Die Hecktik unsrer Seelen Gedankenlosigkeit.", "tokens": ["Die", "Heck\u00b7tik", "uns\u00b7rer", "See\u00b7len", "Ge\u00b7dan\u00b7ken\u00b7lo\u00b7sig\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.19": {"line.1": {"text": "Wie kommt es, da\u00df ein Baur, ein Schiffer, ein Soldat,", "tokens": ["Wie", "kommt", "es", ",", "da\u00df", "ein", "Baur", ",", "ein", "Schif\u00b7fer", ",", "ein", "Sol\u00b7dat", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "$,", "KOUS", "ART", "NN", "$,", "ART", "NN", "$,", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Bey harter Lebensart die gr\u00f6\u00dfte St\u00e4rke hat;", "tokens": ["Bey", "har\u00b7ter", "Le\u00b7ben\u00b7sart", "die", "gr\u00f6\u00df\u00b7te", "St\u00e4r\u00b7ke", "hat", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ART", "ADJA", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Da ein Verz\u00e4rtelter, beym Ambrosin der G\u00f6tter,", "tokens": ["Da", "ein", "Ver\u00b7z\u00e4r\u00b7tel\u00b7ter", ",", "beym", "A\u00b7mbro\u00b7sin", "der", "G\u00f6t\u00b7ter", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "$,", "APPRART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Kaum seine Glieder schleppt, und lebt auf Gunst der Wetter?", "tokens": ["Kaum", "sei\u00b7ne", "Glie\u00b7der", "schleppt", ",", "und", "lebt", "auf", "Gunst", "der", "Wet\u00b7ter", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "VVFIN", "$,", "KON", "VVFIN", "APPR", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Der ward schon als ein Kind bewegt, bald an dem Pflug,", "tokens": ["Der", "ward", "schon", "als", "ein", "Kind", "be\u00b7wegt", ",", "bald", "an", "dem", "Pflug", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "KOUS", "ART", "NN", "VVFIN", "$,", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Bald, wenn er mit dem Ruder die Wasserfl\u00e4che schlug;", "tokens": ["Bald", ",", "wenn", "er", "mit", "dem", "Ru\u00b7der", "die", "Was\u00b7ser\u00b7fl\u00e4\u00b7che", "schlug", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "PPER", "APPR", "ART", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.7": {"text": "Der Magen ward gesund, und go\u00df nahrhafte S\u00e4fte", "tokens": ["Der", "Ma\u00b7gen", "ward", "ge\u00b7sund", ",", "und", "go\u00df", "nahr\u00b7haf\u00b7te", "S\u00e4f\u00b7te"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "VVPP", "$,", "KON", "VVFIN", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "In seine Nerven aus, und gab den Gliedern Kr\u00e4fte:", "tokens": ["In", "sei\u00b7ne", "Ner\u00b7ven", "aus", ",", "und", "gab", "den", "Glie\u00b7dern", "Kr\u00e4f\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PTKVZ", "$,", "KON", "VVFIN", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Indem der Weichliche, aus Furcht der Mutter krank,", "tokens": ["In\u00b7dem", "der", "Weich\u00b7li\u00b7che", ",", "aus", "Furcht", "der", "Mut\u00b7ter", "krank", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "$,", "APPR", "NN", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "In tr\u00e4ger Musse schlief, und wenig a\u00df und trank.", "tokens": ["In", "tr\u00e4\u00b7ger", "Mus\u00b7se", "schlief", ",", "und", "we\u00b7nig", "a\u00df", "und", "trank", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "$,", "KON", "PIS", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Natur, zu einem Zweck, gab einerley Befehle;", "tokens": ["Na\u00b7tur", ",", "zu", "ei\u00b7nem", "Zweck", ",", "gab", "ei\u00b7ner\u00b7ley", "Be\u00b7feh\u00b7le", ";"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "APPR", "ART", "NN", "$,", "VVFIN", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Die Arbeit st\u00e4rkt den Leib, und st\u00e4rket auch die Seele.", "tokens": ["Die", "Ar\u00b7beit", "st\u00e4rkt", "den", "Leib", ",", "und", "st\u00e4r\u00b7ket", "auch", "die", "See\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "$,", "KON", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Mit eines Newtons Hirn, mit eben dem Verstand,", "tokens": ["Mit", "ei\u00b7nes", "New\u00b7tons", "Hirn", ",", "mit", "e\u00b7ben", "dem", "Ver\u00b7stand", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,", "APPR", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Der die Natur enth\u00fcllt, und ihr Gesetz erfand,", "tokens": ["Der", "die", "Na\u00b7tur", "ent\u00b7h\u00fcllt", ",", "und", "ihr", "Ge\u00b7setz", "er\u00b7fand", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "VVPP", "$,", "KON", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Wirst du doch, unge\u00fcbt, dich bey der Rechnung qu\u00e4len,", "tokens": ["Wirst", "du", "doch", ",", "un\u00b7ge\u00b7\u00fcbt", ",", "dich", "bey", "der", "Rech\u00b7nung", "qu\u00e4\u00b7len", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "$,", "ADJD", "$,", "PRF", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Den Regeln nachzugehn, die Sch\u00fcler nicht verfehlen.", "tokens": ["Den", "Re\u00b7geln", "nach\u00b7zu\u00b7gehn", ",", "die", "Sch\u00fc\u00b7ler", "nicht", "ver\u00b7feh\u00b7len", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVIZU", "$,", "ART", "NN", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.20": {"line.1": {"text": "Mit dieser Kunst zu denken, geh, vom Ger\u00e4usch verschont,", "tokens": ["Mit", "die\u00b7ser", "Kunst", "zu", "den\u00b7ken", ",", "geh", ",", "vom", "Ge\u00b7r\u00e4usch", "ver\u00b7schont", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "PTKZU", "VVINF", "$,", "VVFIN", "$,", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "In jene heilge Stille, wo gern die Weisheit wohnt.", "tokens": ["In", "je\u00b7ne", "heil\u00b7ge", "Stil\u00b7le", ",", "wo", "gern", "die", "Weis\u00b7heit", "wohnt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "ADJA", "NN", "$,", "PWAV", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Gefesselt mit der Welt, h\u00e4lt auf gewissen H\u00f6hen", "tokens": ["Ge\u00b7fes\u00b7selt", "mit", "der", "Welt", ",", "h\u00e4lt", "auf", "ge\u00b7wis\u00b7sen", "H\u00f6\u00b7hen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "APPR", "ART", "NN", "$,", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die Kette deinen Geist, und zwingt ihn, da zu stehen.", "tokens": ["Die", "Ket\u00b7te", "dei\u00b7nen", "Geist", ",", "und", "zwingt", "ihn", ",", "da", "zu", "ste\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "$,", "KON", "VVFIN", "PPER", "$,", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Zwar lehren, da\u00df man ganz vom K\u00f6rperlichen frey,", "tokens": ["Zwar", "leh\u00b7ren", ",", "da\u00df", "man", "ganz", "vom", "K\u00f6r\u00b7per\u00b7li\u00b7chen", "frey", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVINF", "$,", "KOUS", "PIS", "ADV", "APPRART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und in Verstand und Geist, wie aufgel\u00f6set, sey,", "tokens": ["Und", "in", "Ver\u00b7stand", "und", "Geist", ",", "wie", "auf\u00b7ge\u00b7l\u00f6\u00b7set", ",", "sey", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["KON", "APPR", "NN", "KON", "NN", "$,", "PWAV", "VVPP", "$,", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Ist metaphysisches, unsinniges Geschw\u00e4tze:", "tokens": ["Ist", "me\u00b7ta\u00b7phy\u00b7si\u00b7sches", ",", "un\u00b7sin\u00b7ni\u00b7ges", "Ge\u00b7schw\u00e4t\u00b7ze", ":"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "$,", "ADJA", "NN", "$."], "meter": "+-+-+-+-+--+-", "measure": "hexameter"}, "line.8": {"text": "Doch, da\u00df man Vorurtheil, und Mod' herunter setze,", "tokens": ["Doch", ",", "da\u00df", "man", "Vor\u00b7urt\u00b7heil", ",", "und", "Mod'", "her\u00b7un\u00b7ter", "set\u00b7ze", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "PIS", "NN", "$,", "KON", "NN", "APZR", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Der Meinung Sieger sey, gereiniget vom Wahn,", "tokens": ["Der", "Mei\u00b7nung", "Sie\u00b7ger", "sey", ",", "ge\u00b7rei\u00b7ni\u00b7get", "vom", "Wahn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VAFIN", "$,", "VVPP", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Ist, was nicht jeder kann, doch mancher schon gethan.", "tokens": ["Ist", ",", "was", "nicht", "je\u00b7der", "kann", ",", "doch", "man\u00b7cher", "schon", "ge\u00b7than", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "$,", "PRELS", "PTKNEG", "PIS", "VMFIN", "$,", "ADV", "PIS", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Wer so den Geist befreyt, schaut bald aus solchen H\u00f6hen;", "tokens": ["Wer", "so", "den", "Geist", "be\u00b7freyt", ",", "schaut", "bald", "aus", "sol\u00b7chen", "H\u00f6\u00b7hen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "ART", "NN", "VVPP", "$,", "VVFIN", "ADV", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Wie Scipio", "tokens": ["Wie", "Sci\u00b7pio"], "token_info": ["word", "word"], "pos": ["PWAV", "NE"], "meter": "-+-", "measure": "amphibrach.single"}, "line.13": {"text": "Wie ward vom Himmel ab der tiefe Erdball klein!", "tokens": ["Wie", "ward", "vom", "Him\u00b7mel", "ab", "der", "tie\u00b7fe", "Erd\u00b7ball", "klein", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "APPRART", "NN", "APPR", "ART", "ADJA", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Kaum fand er Roms Gebiet, den Fleck von Koht darein.", "tokens": ["Kaum", "fand", "er", "Roms", "Ge\u00b7biet", ",", "den", "Fleck", "von", "Koht", "da\u00b7rein", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "NE", "NN", "$,", "ART", "NN", "APPR", "NN", "PAV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.21": {"line.1": {"text": "Om, wie lange k\u00e4mpft, im ungerechten Kriege,", "tokens": ["Om", ",", "wie", "lan\u00b7ge", "k\u00e4mpft", ",", "im", "un\u00b7ge\u00b7rech\u00b7ten", "Krie\u00b7ge", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PWAV", "ADV", "VVFIN", "$,", "APPRART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.2": {"text": "Der Mensch mit der Vernunft, und freut sich b\u00f6ser Siege?", "tokens": ["Der", "Mensch", "mit", "der", "Ver\u00b7nunft", ",", "und", "freut", "sich", "b\u00f6\u00b7ser", "Sie\u00b7ge", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$,", "KON", "VVFIN", "PRF", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Zum Tode, rief Athen, wer bessre G\u00f6tter lehrt,", "tokens": ["Zum", "To\u00b7de", ",", "rief", "A\u00b7then", ",", "wer", "bess\u00b7re", "G\u00f6t\u00b7ter", "lehrt", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "VVFIN", "NE", "$,", "PWS", "VVFIN", "NN", "VVFIN", "$,"], "meter": "-+-+---+-+-+", "measure": "unknown.measure.penta"}, "line.4": {"text": "Und unsrer V\u00e4ter Brauch, und den Altar zerst\u00f6rt!", "tokens": ["Und", "uns\u00b7rer", "V\u00e4\u00b7ter", "Brauch", ",", "und", "den", "Al\u00b7tar", "zer\u00b7st\u00f6rt", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "NN", "$,", "KON", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und schau, das reine Bild der Weisheit und der Liebe", "tokens": ["Und", "schau", ",", "das", "rei\u00b7ne", "Bild", "der", "Weis\u00b7heit", "und", "der", "Lie\u00b7be"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PTKVZ", "$,", "ART", "ADJA", "NN", "ART", "NN", "KON", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wird zu der Schmach verdammt, und stirbt den Tod der Diebe.", "tokens": ["Wird", "zu", "der", "Schmach", "ver\u00b7dammt", ",", "und", "stirbt", "den", "Tod", "der", "Die\u00b7be", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "ART", "NN", "VVPP", "$,", "KON", "VVFIN", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Dem Weisen, den das Loos der Misseth\u00e4ter trifft,", "tokens": ["Dem", "Wei\u00b7sen", ",", "den", "das", "Loos", "der", "Mis\u00b7set\u00b7h\u00e4\u00b7ter", "trifft", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ART", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Reicht man kaum Bettelbrodt", "tokens": ["Reicht", "man", "kaum", "Bet\u00b7tel\u00b7brodt"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PIS", "ADV", "NN"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.9": {"text": "Ein lehrender Esop trug, seiner Zeit zur Schande,", "tokens": ["Ein", "leh\u00b7ren\u00b7der", "E\u00b7sop", "trug", ",", "sei\u00b7ner", "Zeit", "zur", "Schan\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,", "PPOSAT", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Des reichen P\u00f6bels Joch, und Epiktet die Bande.", "tokens": ["Des", "rei\u00b7chen", "P\u00f6\u00b7bels", "Joch", ",", "und", "E\u00b7pik\u00b7tet", "die", "Ban\u00b7de", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NE", "$,", "KON", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.11": {"text": "Dies war der Weisen Gl\u00fcck von allen Zeiten her;", "tokens": ["Dies", "war", "der", "Wei\u00b7sen", "Gl\u00fcck", "von", "al\u00b7len", "Zei\u00b7ten", "her", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "NN", "APPR", "PIAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Und unsre Zeit erstaunt, und wird nicht billiger.", "tokens": ["Und", "uns\u00b7re", "Zeit", "er\u00b7staunt", ",", "und", "wird", "nicht", "bil\u00b7li\u00b7ger", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVPP", "$,", "KON", "VAFIN", "PTKNEG", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Der Hof zieht T\u00e4nzer an, und n\u00e4hret M\u00fc\u00dfigg\u00e4nger,", "tokens": ["Der", "Hof", "zieht", "T\u00e4n\u00b7zer", "an", ",", "und", "n\u00e4h\u00b7ret", "M\u00fc\u00b7\u00dfig\u00b7g\u00e4n\u00b7ger", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "NN", "PTKVZ", "$,", "KON", "VVFIN", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "J\u00e4gt einen Weisen fort, und m\u00e4stet zwanzig S\u00e4nger.", "tokens": ["J\u00e4gt", "ei\u00b7nen", "Wei\u00b7sen", "fort", ",", "und", "m\u00e4s\u00b7tet", "zwan\u00b7zig", "S\u00e4n\u00b7ger", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "PTKVZ", "$,", "KON", "VVFIN", "CARD", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Die D\u00fcrftigkeit verl\u00f6scht dem Weisen, da er wacht,", "tokens": ["Die", "D\u00fcrf\u00b7tig\u00b7keit", "ver\u00b7l\u00f6scht", "dem", "Wei\u00b7sen", ",", "da", "er", "wacht", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "$,", "KOUS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Die Lampe, die den Kreis der Erden heller macht,", "tokens": ["Die", "Lam\u00b7pe", ",", "die", "den", "Kreis", "der", "Er\u00b7den", "hel\u00b7ler", "macht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ART", "NN", "ART", "NN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Umsonst rieth sein Verstand mehr, als Orakel rathen,", "tokens": ["Um\u00b7sonst", "rieth", "sein", "Ver\u00b7stand", "mehr", ",", "als", "O\u00b7ra\u00b7kel", "ra\u00b7then", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "ADV", "$,", "KOUS", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Gab im Lycurg Gesetz, und focht in C\u00e4sars Thaten:", "tokens": ["Gab", "im", "Ly\u00b7curg", "Ge\u00b7setz", ",", "und", "focht", "in", "C\u00e4\u00b7sars", "Tha\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPRART", "NN", "NN", "$,", "KON", "VVFIN", "APPR", "NE", "NN", "$."], "meter": "+-+--+-+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.19": {"text": "Regierte im Hugen der Sterne wandelnd Heer,", "tokens": ["Re\u00b7gier\u00b7te", "im", "Hu\u00b7gen", "der", "Ster\u00b7ne", "wan\u00b7delnd", "Heer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPRART", "NN", "ART", "NN", "VVPP", "NN", "$,"], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.20": {"text": "Fand im Colon die Bahn durchs ungepfl\u00fcgte Meer;", "tokens": ["Fand", "im", "Co\u00b7lon", "die", "Bahn", "durchs", "un\u00b7ge\u00b7pfl\u00fcg\u00b7te", "Meer", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPRART", "NN", "ART", "NN", "APPRART", "ADJA", "NN", "$."], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.21": {"text": "Umsonst ins Herz der Welt stieg er durch Felsenwunden,", "tokens": ["Um\u00b7sonst", "ins", "Herz", "der", "Welt", "stieg", "er", "durch", "Fel\u00b7sen\u00b7wun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "ART", "NN", "VVFIN", "PPER", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Und hat, selbst arm zu seyn, f\u00fcr Narren Gold gefunden.", "tokens": ["Und", "hat", ",", "selbst", "arm", "zu", "seyn", ",", "f\u00fcr", "Nar\u00b7ren", "Gold", "ge\u00b7fun\u00b7den", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "$,", "ADV", "ADJD", "PTKZU", "VAINF", "$,", "APPR", "NN", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Begl\u00fcckt, wenn man den Geist, der seine Fl\u00fcgel regt,", "tokens": ["Be\u00b7gl\u00fcckt", ",", "wenn", "man", "den", "Geist", ",", "der", "sei\u00b7ne", "Fl\u00fc\u00b7gel", "regt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "KOUS", "PIS", "ART", "NN", "$,", "PRELS", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Noch in die Schulen st\u00f6\u00dft, und dort an Ketten legt.", "tokens": ["Noch", "in", "die", "Schu\u00b7len", "st\u00f6\u00dft", ",", "und", "dort", "an", "Ket\u00b7ten", "legt", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "VVFIN", "$,", "KON", "ADV", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Dort mu\u00df er in das Glei\u00df der alten Lehrer treten,", "tokens": ["Dort", "mu\u00df", "er", "in", "das", "Glei\u00df", "der", "al\u00b7ten", "Leh\u00b7rer", "tre\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "APPR", "ART", "NN", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Und selbst nicht vor sich sehn, getreuer nachzubeten:", "tokens": ["Und", "selbst", "nicht", "vor", "sich", "sehn", ",", "ge\u00b7treu\u00b7er", "nach\u00b7zu\u00b7be\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ADV", "PTKNEG", "APPR", "PRF", "VVINF", "$,", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Mu\u00df wider die Vernunft aus fremden L\u00e4ndern schreyn,", "tokens": ["Mu\u00df", "wi\u00b7der", "die", "Ver\u00b7nunft", "aus", "frem\u00b7den", "L\u00e4n\u00b7dern", "schreyn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "APPR", "ART", "NN", "APPR", "ADJA", "NN", "VAINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Cartesisch in Paris, in Halle wolfisch seyn.", "tokens": ["Car\u00b7te\u00b7sisch", "in", "Pa\u00b7ris", ",", "in", "Hal\u00b7le", "wol\u00b7fisch", "seyn", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "NE", "$,", "APPR", "NE", "ADJD", "VAINF", "$."], "meter": "+----+-+-+-+", "measure": "dactylic.init"}, "line.29": {"text": "Die Mode und der Wahn ertheilt der Welt Befehle,", "tokens": ["Die", "Mo\u00b7de", "und", "der", "Wahn", "er\u00b7theilt", "der", "Welt", "Be\u00b7feh\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "VVFIN", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "Die eine f\u00fcr den Leib, der andre f\u00fcr die Seele.", "tokens": ["Die", "ei\u00b7ne", "f\u00fcr", "den", "Leib", ",", "der", "and\u00b7re", "f\u00fcr", "die", "See\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "APPR", "ART", "NN", "$,", "PRELS", "PIS", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.22": {"line.1": {"text": "Der Heilige vermischt den Weisen mit den Sp\u00f6ttern,", "tokens": ["Der", "Hei\u00b7li\u00b7ge", "ver\u00b7mischt", "den", "Wei\u00b7sen", "mit", "den", "Sp\u00f6t\u00b7tern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Denkt seiner nur im Grimm, und spricht zu ihm aus Wettern.", "tokens": ["Denkt", "sei\u00b7ner", "nur", "im", "Grimm", ",", "und", "spricht", "zu", "ihm", "aus", "Wet\u00b7tern", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "ADV", "APPRART", "NE", "$,", "KON", "VVFIN", "APPR", "PPER", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Verdank es der Geburt am Elbstrom, oder Rhein;", "tokens": ["Ver\u00b7dank", "es", "der", "Ge\u00b7burt", "am", "E\u00b7lbstrom", ",", "o\u00b7der", "Rhein", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "APPRART", "NN", "$,", "KON", "NE", "$."], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Am Euphrat w\u00fcrd er selbst ein Feind der Christen seyn,", "tokens": ["Am", "Eu\u00b7ph\u00b7rat", "w\u00fcrd", "er", "selbst", "ein", "Feind", "der", "Chris\u00b7ten", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NE", "VAFIN", "PPER", "ADV", "ART", "NN", "ART", "NN", "VAINF", "$,"], "meter": "+---+-+-+-+-+", "measure": "dactylic.init"}, "line.5": {"text": "Vernunft, schreyt er, ist blind; und darf sich nichts erk\u00fchnen,", "tokens": ["Ver\u00b7nunft", ",", "schreyt", "er", ",", "ist", "blind", ";", "und", "darf", "sich", "nichts", "er\u00b7k\u00fch\u00b7nen", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "PPER", "$,", "VAFIN", "ADJD", "$.", "KON", "VMFIN", "PRF", "PIS", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Der Glauben geht gewi\u00df; er herrsche, sie soll dienen!", "tokens": ["Der", "Glau\u00b7ben", "geht", "ge\u00b7wi\u00df", ";", "er", "herr\u00b7sche", ",", "sie", "soll", "die\u00b7nen", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "$.", "PPER", "VVFIN", "$,", "PPER", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Setz ihn in Asien, erzogen im Koran,", "tokens": ["Setz", "ihn", "in", "A\u00b7sien", ",", "er\u00b7zo\u00b7gen", "im", "Ko\u00b7ran", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "NE", "$,", "VVPP", "APPRART", "NN", "$,"], "meter": "+--+--+-+-+", "measure": "dactylic.di.plus"}, "line.8": {"text": "Und sag, was spr\u00e4ch er wohl, spr\u00e4ch er als Muselmann?", "tokens": ["Und", "sag", ",", "was", "spr\u00e4ch", "er", "wohl", ",", "spr\u00e4ch", "er", "als", "Mu\u00b7sel\u00b7mann", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "PWS", "VVFIN", "PPER", "ADV", "$,", "VVFIN", "PPER", "KOUS", "NN", "$."], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.9": {"text": "Mit eben der Vernunft, die ihn den wahren Lehren", "tokens": ["Mit", "e\u00b7ben", "der", "Ver\u00b7nunft", ",", "die", "ihn", "den", "wah\u00b7ren", "Leh\u00b7ren"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADV", "ART", "NN", "$,", "PRELS", "PPER", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Blind unterworfen hat, k\u00f6nnt er dem Irrthum schw\u00f6ren.", "tokens": ["Blind", "un\u00b7ter\u00b7wor\u00b7fen", "hat", ",", "k\u00f6nnt", "er", "dem", "Irr\u00b7thum", "schw\u00f6\u00b7ren", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVPP", "VAFIN", "$,", "VVFIN", "PPER", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.23": {"line.1": {"text": "H\u00f6r, was der Redner sagt, der die Gerichte stimmt,", "tokens": ["H\u00f6r", ",", "was", "der", "Red\u00b7ner", "sagt", ",", "der", "die", "Ge\u00b7rich\u00b7te", "stimmt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PRELS", "ART", "NN", "VVFIN", "$,", "PRELS", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und oft, statt der Vernunft, sein Geld zu H\u00fclfe nimmt:", "tokens": ["Und", "oft", ",", "statt", "der", "Ver\u00b7nunft", ",", "sein", "Geld", "zu", "H\u00fcl\u00b7fe", "nimmt", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$,", "KOUI", "ART", "NN", "$,", "PPOSAT", "NN", "APPR", "NN", "VVFIN", "$."], "meter": "-+---+-+-+-+", "measure": "dactylic.init"}, "line.3": {"text": "Hier schweige mit Vernunft! was n\u00fctzt ein leer Geschw\u00e4tze?", "tokens": ["Hier", "schwei\u00b7ge", "mit", "Ver\u00b7nunft", "!", "was", "n\u00fctzt", "ein", "leer", "Ge\u00b7schw\u00e4t\u00b7ze", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "NN", "$.", "PWS", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So will der Landesherr, so wollen die Gesetze.", "tokens": ["So", "will", "der", "Lan\u00b7des\u00b7herr", ",", "so", "wol\u00b7len", "die", "Ge\u00b7set\u00b7ze", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "NN", "$,", "ADV", "VMFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und wer gab dis Gesetz? Vielleicht ein Eigensinn,", "tokens": ["Und", "wer", "gab", "dis", "Ge\u00b7setz", "?", "Viel\u00b7leicht", "ein", "Ei\u00b7gen\u00b7sinn", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VVFIN", "PDS", "NN", "$.", "ADV", "ART", "NN", "$,"], "meter": "--+--+-+-+-+", "measure": "anapaest.di.plus"}, "line.6": {"text": "Ein Narr, ein Kammerdiener, und eine Buhlerin.", "tokens": ["Ein", "Narr", ",", "ein", "Kam\u00b7mer\u00b7die\u00b7ner", ",", "und", "ei\u00b7ne", "Buh\u00b7le\u00b7rin", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "$,", "KON", "ART", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.7": {"text": "Der Schulmann ohne Geist, von Hochmuth aufgeblasen,", "tokens": ["Der", "Schul\u00b7mann", "oh\u00b7ne", "Geist", ",", "von", "Hoch\u00b7muth", "auf\u00b7ge\u00b7bla\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "$,", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Kennt von der ersten Welt die Kleidung und die Phrasen.", "tokens": ["Kennt", "von", "der", "ers\u00b7ten", "Welt", "die", "Klei\u00b7dung", "und", "die", "Phra\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "ADJA", "NN", "ART", "NN", "KON", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Vergn\u00fcgt, wenn er mit Schwei\u00df, der seine Stirn benetzt,", "tokens": ["Ver\u00b7gn\u00fcgt", ",", "wenn", "er", "mit", "Schwei\u00df", ",", "der", "sei\u00b7ne", "Stirn", "be\u00b7netzt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "KOUS", "PPER", "APPR", "NN", "$,", "PRELS", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Virgilens Troja l\u00f6scht, und ihn in Wasser setzt:", "tokens": ["Vir\u00b7gi\u00b7lens", "Tro\u00b7ja", "l\u00f6scht", ",", "und", "ihn", "in", "Was\u00b7ser", "setzt", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VVFIN", "$,", "KON", "PPER", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Vernunft ist nicht sein Theil: was brauchts der Kunst zu denken,", "tokens": ["Ver\u00b7nunft", "ist", "nicht", "sein", "Theil", ":", "was", "brauchts", "der", "Kunst", "zu", "den\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PTKNEG", "PPOSAT", "NN", "$.", "PWS", "VVFIN", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Um in Gelehrsamkeit zw\u00f6lf Dichter zu ertr\u00e4nken?", "tokens": ["Um", "in", "Ge\u00b7lehr\u00b7sam\u00b7keit", "zw\u00f6lf", "Dich\u00b7ter", "zu", "er\u00b7tr\u00e4n\u00b7ken", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "APPR", "NN", "CARD", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Ihm, der allein den Geist der Prisciane fa\u00dft,", "tokens": ["Ihm", ",", "der", "al\u00b7lein", "den", "Geist", "der", "Pri\u00b7sci\u00b7a\u00b7ne", "fa\u00dft", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PRELS", "ADV", "ART", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Wird Lock ein Schw\u00e4tzer seyn, und Newton ein Phantast.", "tokens": ["Wird", "Lock", "ein", "Schw\u00e4t\u00b7zer", "seyn", ",", "und", "New\u00b7ton", "ein", "Phan\u00b7tast", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "ART", "NN", "VAINF", "$,", "KON", "NE", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Und doch hat die Vernunft, die alle drey beleidigt,", "tokens": ["Und", "doch", "hat", "die", "Ver\u00b7nunft", ",", "die", "al\u00b7le", "drey", "be\u00b7lei\u00b7digt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "ART", "NN", "$,", "PRELS", "PIAT", "CARD", "VVPP", "$,"], "meter": "-+---+-+-+-+-", "measure": "dactylic.init"}, "line.16": {"text": "Das Christenthum gesch\u00fctzt, und den Altar vertheidigt;", "tokens": ["Das", "Chris\u00b7ten\u00b7thum", "ge\u00b7sch\u00fctzt", ",", "und", "den", "Al\u00b7tar", "ver\u00b7thei\u00b7digt", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "$,", "KON", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Sie stellte Recht und Heil im Dracon wieder her,", "tokens": ["Sie", "stell\u00b7te", "Recht", "und", "Heil", "im", "Dra\u00b7con", "wie\u00b7der", "her", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "KON", "NN", "APPRART", "NN", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Vertrat im Tullius, und sang in dem Homer.", "tokens": ["Ver\u00b7trat", "im", "Tul\u00b7li\u00b7us", ",", "und", "sang", "in", "dem", "Ho\u00b7mer", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPRART", "NN", "$,", "KON", "VVFIN", "APPR", "ART", "NE", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}}, "stanza.24": {"line.1": {"text": "Doch la\u00df uns von Vernunft nicht bis zum Ekel streiten;", "tokens": ["Doch", "la\u00df", "uns", "von", "Ver\u00b7nunft", "nicht", "bis", "zum", "E\u00b7kel", "strei\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVIMP", "PPER", "APPR", "NN", "PTKNEG", "ADV", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und sprich: es sey ihr Theil, den Menschen falsch zu leiten.", "tokens": ["Und", "sprich", ":", "es", "sey", "ihr", "Theil", ",", "den", "Men\u00b7schen", "falsch", "zu", "lei\u00b7ten", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "$.", "PPER", "VAFIN", "PPOSAT", "NN", "$,", "ART", "NN", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Dann aber wollt ich eh zur Erde niedersehn,", "tokens": ["Dann", "a\u00b7ber", "wollt", "ich", "eh", "zur", "Er\u00b7de", "nie\u00b7der\u00b7sehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VMFIN", "PPER", "KOUS", "APPRART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Glatt, oder auch im Pelz geb\u00fcckt auf Vieren gehn,", "tokens": ["Glatt", ",", "o\u00b7der", "auch", "im", "Pelz", "ge\u00b7b\u00fcckt", "auf", "Vie\u00b7ren", "gehn", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KON", "ADV", "APPRART", "NN", "VVPP", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und mit der Sicherheit mich nimmer zu verlieren,", "tokens": ["Und", "mit", "der", "Si\u00b7cher\u00b7heit", "mich", "nim\u00b7mer", "zu", "ver\u00b7lie\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "PPER", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Des Pfaus, ja, wenn ich soll, den Schweif des Esels f\u00fchren,", "tokens": ["Des", "Pfaus", ",", "ja", ",", "wenn", "ich", "soll", ",", "den", "Schweif", "des", "E\u00b7sels", "f\u00fch\u00b7ren", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PTKANT", "$,", "KOUS", "PPER", "VMFIN", "$,", "ART", "NN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Als mit dem Titel, Mensch, nur in der Bildung sch\u00f6n,", "tokens": ["Als", "mit", "dem", "Ti\u00b7tel", ",", "Mensch", ",", "nur", "in", "der", "Bil\u00b7dung", "sch\u00f6n", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "ART", "NN", "$,", "NN", "$,", "ADV", "APPR", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und ohne Pelz und Schweif, auf Zweyen unrecht gehn.", "tokens": ["Und", "oh\u00b7ne", "Pelz", "und", "Schweif", ",", "auf", "Zwe\u00b7yen", "un\u00b7recht", "gehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "KON", "NN", "$,", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Gesichert geht das Vieh, von dem Instinkt getrieben,", "tokens": ["Ge\u00b7si\u00b7chert", "geht", "das", "Vieh", ",", "von", "dem", "Ins\u00b7tinkt", "ge\u00b7trie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VVFIN", "ART", "NN", "$,", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+--++-+-", "measure": "iambic.hexa.relaxed"}, "line.10": {"text": "Mit der Natur die Bahn, die sie ihm vorgeschrieben.", "tokens": ["Mit", "der", "Na\u00b7tur", "die", "Bahn", ",", "die", "sie", "ihm", "vor\u00b7ge\u00b7schrie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "$,", "PRELS", "PPER", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Kein Irrweg, kein Betrug verschl\u00e4gt es von der Ruh,", "tokens": ["Kein", "Irr\u00b7weg", ",", "kein", "Be\u00b7trug", "ver\u00b7schl\u00e4gt", "es", "von", "der", "Ruh", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "$,", "PIAT", "NN", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Gott herrscht in dem Instinkt, und f\u00fchrt unfehlbar zu.", "tokens": ["Gott", "herrscht", "in", "dem", "Ins\u00b7tinkt", ",", "und", "f\u00fchrt", "un\u00b7fehl\u00b7bar", "zu", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "APPR", "ART", "NN", "$,", "KON", "VVFIN", "ADJD", "PTKVZ", "$."], "meter": "++-+-+-+-+-+", "measure": "unknown.measure.septa"}, "line.13": {"text": "Du aber wirst umsonst durch zwanzig Augen sehen,", "tokens": ["Du", "a\u00b7ber", "wirst", "um\u00b7sonst", "durch", "zwan\u00b7zig", "Au\u00b7gen", "se\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VAFIN", "ADV", "APPR", "CARD", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Die Fackel in der Hand, und wirst doch irre gehen;", "tokens": ["Die", "Fa\u00b7ckel", "in", "der", "Hand", ",", "und", "wirst", "doch", "ir\u00b7re", "ge\u00b7hen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$,", "KON", "VAFIN", "ADV", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Folg, oder geh allein, in beyden bist du blind;", "tokens": ["Folg", ",", "o\u00b7der", "geh", "al\u00b7lein", ",", "in", "bey\u00b7den", "bist", "du", "blind", ";"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KON", "VVFIN", "ADV", "$,", "APPR", "PIAT", "VAFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Je gr\u00f6\u00dfere Vernunft, je tiefer Labyrinth.", "tokens": ["Je", "gr\u00f6\u00b7\u00dfe\u00b7re", "Ver\u00b7nunft", ",", "je", "tie\u00b7fer", "La\u00b7by\u00b7rinth", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "$,", "ADV", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.25": {"line.1": {"text": "Der Satz verscherzt dein Recht, den Erdkreis zu regieren,", "tokens": ["Der", "Satz", "ver\u00b7scherzt", "dein", "Recht", ",", "den", "Erd\u00b7kreis", "zu", "re\u00b7gie\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPOSAT", "NN", "$,", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und setzt dich in Gefahr, den Zepter zu verlieren:", "tokens": ["Und", "setzt", "dich", "in", "Ge\u00b7fahr", ",", "den", "Zep\u00b7ter", "zu", "ver\u00b7lie\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "APPR", "NN", "$,", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ein Vorzug, den kein Baur, so wenig er gedacht,", "tokens": ["Ein", "Vor\u00b7zug", ",", "den", "kein", "Baur", ",", "so", "we\u00b7nig", "er", "ge\u00b7dacht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PIAT", "NN", "$,", "ADV", "PIS", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Kein ungelehrtes Volk, sich jemals streitig macht.", "tokens": ["Kein", "un\u00b7ge\u00b7lehr\u00b7tes", "Volk", ",", "sich", "je\u00b7mals", "strei\u00b7tig", "macht", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "$,", "PRF", "ADV", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Er deckt den Schauplatz auf, wo Hitz und Fieber rasten,", "tokens": ["Er", "deckt", "den", "Schau\u00b7platz", "auf", ",", "wo", "Hitz", "und", "Fie\u00b7ber", "ras\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "PTKVZ", "$,", "PWAV", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und zeigt dir eine Welt voll Tr\u00e4umer, und Phantasten,", "tokens": ["Und", "zeigt", "dir", "ei\u00b7ne", "Welt", "voll", "Tr\u00e4u\u00b7mer", ",", "und", "Phan\u00b7tas\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ART", "NN", "ADJD", "NN", "$,", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Wo Irrthum, mit der Tracht der Wahrheit \u00fcberdeckt,", "tokens": ["Wo", "Irr\u00b7thum", ",", "mit", "der", "Tracht", "der", "Wahr\u00b7heit", "\u00fc\u00b7berd\u00b7eckt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "$,", "APPR", "ART", "NN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Um unsre H\u00e4upter schw\u00e4rmt, belustigt, oder schreckt.", "tokens": ["Um", "uns\u00b7re", "H\u00e4up\u00b7ter", "schw\u00e4rmt", ",", "be\u00b7lus\u00b7tigt", ",", "o\u00b7der", "schreckt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["KOUI", "PPOSAT", "NN", "VVFIN", "$,", "VVPP", "$,", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "So schw\u00e4rmt, wie", "tokens": ["So", "schw\u00e4rmt", ",", "wie"], "token_info": ["word", "word", "punct", "word"], "pos": ["ADV", "VVFIN", "$,", "PWAV"], "meter": "-+-", "measure": "amphibrach.single"}, "line.10": {"text": "Furcht, Hoffnung, Schrecken, Lust im Tr\u00e4umen bey dem Gotte;", "tokens": ["Furcht", ",", "Hoff\u00b7nung", ",", "Schre\u00b7cken", ",", "Lust", "im", "Tr\u00e4u\u00b7men", "bey", "dem", "Got\u00b7te", ";"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "$,", "NN", "APPRART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "An Zahl den Bl\u00e4ttern gleich, den Aehren auf der Flur,", "tokens": ["An", "Zahl", "den", "Bl\u00e4t\u00b7tern", "gleich", ",", "den", "A\u00b7eh\u00b7ren", "auf", "der", "Flur", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ART", "NN", "ADV", "$,", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.12": {"text": "Und tr\u00e4gt ver\u00e4nderlich Gestalten der Natur.", "tokens": ["Und", "tr\u00e4gt", "ver\u00b7\u00e4n\u00b7der\u00b7lich", "Ge\u00b7stal\u00b7ten", "der", "Na\u00b7tur", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.26": {"line.1": {"text": "La\u00df den, der Tr\u00e4ume liebt, dies Zauberwerk ergetzen;", "tokens": ["La\u00df", "den", ",", "der", "Tr\u00e4u\u00b7me", "liebt", ",", "dies", "Zau\u00b7ber\u00b7werk", "er\u00b7get\u00b7zen", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVIMP", "ART", "$,", "ART", "NN", "VVFIN", "$,", "PDS", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Du, der du Wahrheit suchst, willst die Vernunft entsetzen?", "tokens": ["Du", ",", "der", "du", "Wahr\u00b7heit", "suchst", ",", "willst", "die", "Ver\u00b7nunft", "ent\u00b7set\u00b7zen", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PRELS", "PPER", "NN", "VVFIN", "$,", "VMFIN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Nein, la\u00df ihr noch ihr Recht \u2013 \u00bbund was f\u00fcr Rechte dann?", "tokens": ["Nein", ",", "la\u00df", "ihr", "noch", "ihr", "Recht", "\u2013", "\u00bb", "und", "was", "f\u00fcr", "Rech\u00b7te", "dann", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "VVIMP", "PPER", "ADV", "PPOSAT", "NN", "$(", "$(", "KON", "PWS", "APPR", "NN", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wer sagt mir, ob Vernunft unfehlbar f\u00fchren kann?\u00ab", "tokens": ["Wer", "sagt", "mir", ",", "ob", "Ver\u00b7nunft", "un\u00b7fehl\u00b7bar", "f\u00fch\u00b7ren", "kann", "?", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWS", "VVFIN", "PPER", "$,", "KOUS", "NN", "ADJD", "VVINF", "VMFIN", "$.", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ohnfehlbar allerdings. Doch ohn Affekt erwogen,", "tokens": ["Ohn\u00b7fehl\u00b7bar", "al\u00b7ler\u00b7dings", ".", "Doch", "ohn", "Af\u00b7fekt", "er\u00b7wo\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADV", "$.", "KON", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Im Denken recht ge\u00fcbt, vom Wahne abgezogen;", "tokens": ["Im", "Den\u00b7ken", "recht", "ge\u00b7\u00fcbt", ",", "vom", "Wah\u00b7ne", "ab\u00b7ge\u00b7zo\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADJD", "VVPP", "$,", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Als eine reine Kraft, die blo\u00df aus Gr\u00fcnden denkt,", "tokens": ["Als", "ei\u00b7ne", "rei\u00b7ne", "Kraft", ",", "die", "blo\u00df", "aus", "Gr\u00fcn\u00b7den", "denkt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "$,", "PRELS", "ADV", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und nur auf ihrem Kreis von Wahrheit eingeschr\u00e4nkt.", "tokens": ["Und", "nur", "auf", "ih\u00b7rem", "Kreis", "von", "Wahr\u00b7heit", "ein\u00b7ge\u00b7schr\u00e4nkt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "PPOSAT", "NN", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Sonst f\u00fchr ich dich zur\u00fcck, woraus ich dich gerissen,", "tokens": ["Sonst", "f\u00fchr", "ich", "dich", "zu\u00b7r\u00fcck", ",", "wo\u00b7raus", "ich", "dich", "ge\u00b7ris\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "PTKVZ", "$,", "PWAV", "PPER", "PRF", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Und st\u00fcrze dich noch eins in gleiche Finsternissen.", "tokens": ["Und", "st\u00fcr\u00b7ze", "dich", "noch", "eins", "in", "glei\u00b7che", "Fins\u00b7ter\u00b7nis\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "PIS", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Ist oft ihr Urtheil falsch, und zweifelhaft ihr Licht,", "tokens": ["Ist", "oft", "ihr", "Ur\u00b7theil", "falsch", ",", "und", "zwei\u00b7fel\u00b7haft", "ihr", "Licht", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PPOSAT", "NN", "ADJD", "$,", "KON", "ADJD", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "So sprich: wann sagt sie wahr? wo irrt sie, und wo nicht?", "tokens": ["So", "sprich", ":", "wann", "sagt", "sie", "wahr", "?", "wo", "irrt", "sie", ",", "und", "wo", "nicht", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$.", "PWAV", "VVFIN", "PPER", "PTKVZ", "$.", "PWAV", "VVFIN", "PPER", "$,", "KON", "PWAV", "PTKNEG", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Auf welche Regeln, Freund, soll ich mein Urtheil gr\u00fcnden?", "tokens": ["Auf", "wel\u00b7che", "Re\u00b7geln", ",", "Freund", ",", "soll", "ich", "mein", "Ur\u00b7theil", "gr\u00fcn\u00b7den", "?"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PWAT", "NN", "$,", "NN", "$,", "VMFIN", "PPER", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Ja, sage mir vielmehr, wo soll ich Regeln finden?", "tokens": ["Ja", ",", "sa\u00b7ge", "mir", "viel\u00b7mehr", ",", "wo", "soll", "ich", "Re\u00b7geln", "fin\u00b7den", "?"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "VVFIN", "PPER", "ADV", "$,", "PWAV", "VMFIN", "PPER", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Bey jeder frag ich dich: ist sie gewi\u00df? warum?", "tokens": ["Bey", "je\u00b7der", "frag", "ich", "dich", ":", "ist", "sie", "ge\u00b7wi\u00df", "?", "wa\u00b7rum", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "PIS", "VVFIN", "PPER", "PRF", "$.", "VAFIN", "PPER", "ADV", "$.", "PWAV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Denn das Orakel schweigt, und l\u00e4ngst ist Delphos stumm!", "tokens": ["Denn", "das", "O\u00b7ra\u00b7kel", "schweigt", ",", "und", "l\u00e4ngst", "ist", "Del\u00b7phos", "stumm", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "$,", "KON", "ADV", "VAFIN", "NE", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Dann sitz ich blind und taub in einem Gaukelspiele,", "tokens": ["Dann", "sitz", "ich", "blind", "und", "taub", "in", "ei\u00b7nem", "Gau\u00b7kel\u00b7spie\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVIMP", "PPER", "ADJD", "KON", "ADJD", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Ein schaaler", "tokens": ["Ein", "schaa\u00b7ler"], "token_info": ["word", "word"], "pos": ["ART", "ADJA"], "meter": "-+-", "measure": "amphibrach.single"}}, "stanza.27": {"line.1": {"text": "Ein einziges Gef\u00fchl, Empfindung, oder Sinn,", "tokens": ["Ein", "ein\u00b7zi\u00b7ges", "Ge\u00b7f\u00fchl", ",", "Emp\u00b7fin\u00b7dung", ",", "o\u00b7der", "Sinn", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "NN", "$,", "KON", "NN", "$,"], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.2": {"text": "Von Mexico nach Rom, von Rom bis nach", "tokens": ["Von", "Me\u00b7xi\u00b7co", "nach", "Rom", ",", "von", "Rom", "bis", "nach"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "NE", "APPR", "NE", "$,", "APPR", "NE", "ADV", "APPR"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "F\u00fchrt alle Sterbliche, in einer gleichen Klarheit,", "tokens": ["F\u00fchrt", "al\u00b7le", "Sterb\u00b7li\u00b7che", ",", "in", "ei\u00b7ner", "glei\u00b7chen", "Klar\u00b7heit", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "NN", "$,", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und \u00f6ffnet zur Vernunft f\u00fcnf Wege f\u00fcr die Wahrheit.", "tokens": ["Und", "\u00f6ff\u00b7net", "zur", "Ver\u00b7nunft", "f\u00fcnf", "We\u00b7ge", "f\u00fcr", "die", "Wahr\u00b7heit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPRART", "NN", "CARD", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Was Lappland wei\u00df gesehn, sieht auch Aegypten wei\u00df;", "tokens": ["Was", "Lap\u00b7pland", "wei\u00df", "ge\u00b7sehn", ",", "sieht", "auch", "A\u00b7e\u00b7gyp\u00b7ten", "wei\u00df", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "VVFIN", "VVPP", "$,", "VVFIN", "ADV", "NE", "VVFIN", "$."], "meter": "-+-+-++-+-+-+", "measure": "unknown.measure.septa"}, "line.6": {"text": "Die Flamme ist am Nil, und an der Wolge hei\u00df:", "tokens": ["Die", "Flam\u00b7me", "ist", "am", "Nil", ",", "und", "an", "der", "Wol\u00b7ge", "hei\u00df", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "APPRART", "NN", "$,", "KON", "APPR", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Was \u00e4ndern Zeit, und Ort an dem Gef\u00fchl der Hitze,", "tokens": ["Was", "\u00e4n\u00b7dern", "Zeit", ",", "und", "Ort", "an", "dem", "Ge\u00b7f\u00fchl", "der", "Hit\u00b7ze", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADJA", "NN", "$,", "KON", "NN", "APPR", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Ob dieser nah am Pol, der am Aequator schwitze?", "tokens": ["Ob", "die\u00b7ser", "nah", "am", "Pol", ",", "der", "am", "A\u00b7e\u00b7qua\u00b7tor", "schwit\u00b7ze", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDAT", "ADJD", "APPRART", "NN", "$,", "PRELS", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.9": {"text": "Der Morgenrose Duft, der Weihrauch, der beseelt,", "tokens": ["Der", "Mor\u00b7gen\u00b7ro\u00b7se", "Duft", ",", "der", "Weih\u00b7rauch", ",", "der", "be\u00b7seelt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "NN", "$,", "PRELS", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "W\u00fcrkt lieblich, da der Dampf aus Todtengr\u00e4bern qu\u00e4lt:", "tokens": ["W\u00fcrkt", "lieb\u00b7lich", ",", "da", "der", "Dampf", "aus", "Tod\u00b7ten\u00b7gr\u00e4\u00b7bern", "qu\u00e4lt", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "$,", "KOUS", "ART", "NN", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Und von dem Abend an, bis an die Morgenr\u00f6the,", "tokens": ["Und", "von", "dem", "A\u00b7bend", "an", ",", "bis", "an", "die", "Mor\u00b7gen\u00b7r\u00f6\u00b7the", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "PTKVZ", "$,", "KOUS", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Merkt jedes Ohr den Schall der Trommel vor der Fl\u00f6te.", "tokens": ["Merkt", "je\u00b7des", "Ohr", "den", "Schall", "der", "Trom\u00b7mel", "vor", "der", "Fl\u00f6\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "NN", "ART", "NN", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Dies ewige Gef\u00fchl hat Gott uns eingepr\u00e4gt,", "tokens": ["Dies", "e\u00b7wi\u00b7ge", "Ge\u00b7f\u00fchl", "hat", "Gott", "uns", "ein\u00b7ge\u00b7pr\u00e4gt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADJA", "NN", "VAFIN", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Und in ihm selbst den Grund der Wahrheit vest gelegt.", "tokens": ["Und", "in", "ihm", "selbst", "den", "Grund", "der", "Wahr\u00b7heit", "vest", "ge\u00b7legt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPER", "ADV", "ART", "NN", "ART", "NN", "VVFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Erst st\u00fctze die Vernunft auf so gewissen Gr\u00fcnden,", "tokens": ["Erst", "st\u00fct\u00b7ze", "die", "Ver\u00b7nunft", "auf", "so", "ge\u00b7wis\u00b7sen", "Gr\u00fcn\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPR", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Vergleiche, leite her, so wirst du weiter finden.", "tokens": ["Ver\u00b7glei\u00b7che", ",", "lei\u00b7te", "her", ",", "so", "wirst", "du", "wei\u00b7ter", "fin\u00b7den", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "PTKVZ", "$,", "ADV", "VAFIN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "So grub sie Wahrheit aus, die in der Seele schlief,", "tokens": ["So", "grub", "sie", "Wahr\u00b7heit", "aus", ",", "die", "in", "der", "See\u00b7le", "schlief", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "NN", "PTKVZ", "$,", "PRELS", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Und folgte nach und nach, wohin ihr Faden lief.", "tokens": ["Und", "folg\u00b7te", "nach", "und", "nach", ",", "wo\u00b7hin", "ihr", "Fa\u00b7den", "lief", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "KON", "APPR", "$,", "PWAV", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "So f\u00fchrte sie zuletzt, auf ihrer Dinge Leiter,", "tokens": ["So", "f\u00fchr\u00b7te", "sie", "zu\u00b7letzt", ",", "auf", "ih\u00b7rer", "Din\u00b7ge", "Lei\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "$,", "APPR", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Zum Sch\u00f6pfer, die Natur, ihr gl\u00fccklicher Begleiter.", "tokens": ["Zum", "Sch\u00f6p\u00b7fer", ",", "die", "Na\u00b7tur", ",", "ihr", "gl\u00fcck\u00b7li\u00b7cher", "Be\u00b7glei\u00b7ter", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "ART", "NN", "$,", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "So baut sie Schlu\u00df auf Schlu\u00df, und setzt, zu einer Bahn,", "tokens": ["So", "baut", "sie", "Schlu\u00df", "auf", "Schlu\u00df", ",", "und", "setzt", ",", "zu", "ei\u00b7ner", "Bahn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "NN", "APPR", "NN", "$,", "KON", "VVFIN", "$,", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Die Staffel zum Saturn ins Herz der Erden an,", "tokens": ["Die", "Staf\u00b7fel", "zum", "Sa\u00b7turn", "ins", "Herz", "der", "Er\u00b7den", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "APPRART", "NN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Worauf die Wahrheiten, wie Engel, niedersteigen,", "tokens": ["Wo\u00b7rauf", "die", "Wahr\u00b7hei\u00b7ten", ",", "wie", "En\u00b7gel", ",", "nie\u00b7ders\u00b7tei\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["PAV", "ART", "NN", "$,", "PWAV", "NE", "$,", "VVPP", "$,"], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.24": {"text": "Und ihr, was Moses sah, im fernen Schatten zeigen.", "tokens": ["Und", "ihr", ",", "was", "Mo\u00b7ses", "sah", ",", "im", "fer\u00b7nen", "Schat\u00b7ten", "zei\u00b7gen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "$,", "PRELS", "NE", "VVFIN", "$,", "APPRART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.28": {"line.1": {"text": "Die g\u00f6ttliche Vernunft, die alles \u00fcberdenkt,", "tokens": ["Die", "g\u00f6tt\u00b7li\u00b7che", "Ver\u00b7nunft", ",", "die", "al\u00b7les", "\u00fc\u00b7ber\u00b7denkt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PRELS", "PIS", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ist gleich an Deutlichkeit, und Umfang unumschr\u00e4nkt:", "tokens": ["Ist", "gleich", "an", "Deut\u00b7lich\u00b7keit", ",", "und", "Um\u00b7fang", "un\u00b7um\u00b7schr\u00e4nkt", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "APPR", "NN", "$,", "KON", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Mit einem gleichen Strahl durchdringt sie H\u00f6hn und Tiefen,", "tokens": ["Mit", "ei\u00b7nem", "glei\u00b7chen", "Strahl", "durch\u00b7dringt", "sie", "H\u00f6hn", "und", "Tie\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVFIN", "PPER", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Unendlich reich an Licht, unendlich an Begriffen.", "tokens": ["Un\u00b7end\u00b7lich", "reich", "an", "Licht", ",", "un\u00b7end\u00b7lich", "an", "Be\u00b7grif\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "ADJD", "APPR", "NN", "$,", "ADJD", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Schlie\u00df sie in einen Kreis bestimmter Wahrheit ein,", "tokens": ["Schlie\u00df", "sie", "in", "ei\u00b7nen", "Kreis", "be\u00b7stimm\u00b7ter", "Wahr\u00b7heit", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ART", "NN", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und schw\u00e4ch ihr g\u00f6ttlich Licht, so wird sie endlich seyn.", "tokens": ["Und", "schw\u00e4ch", "ihr", "g\u00f6tt\u00b7lich", "Licht", ",", "so", "wird", "sie", "end\u00b7lich", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADJD", "NN", "$,", "ADV", "VAFIN", "PPER", "ADV", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "So wohnt sie Geistern bey, aus Nothdurft eingeschr\u00e4nket,", "tokens": ["So", "wohnt", "sie", "Geis\u00b7tern", "bey", ",", "aus", "Noth\u00b7durft", "ein\u00b7ge\u00b7schr\u00e4n\u00b7ket", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "NN", "PTKVZ", "$,", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und irrt nicht, wenn sie nur in ihrer Sph\u00e4re denket.", "tokens": ["Und", "irrt", "nicht", ",", "wenn", "sie", "nur", "in", "ih\u00b7rer", "Sph\u00e4\u00b7re", "den\u00b7ket", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKNEG", "$,", "KOUS", "PPER", "ADV", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "In diesen Inbegriff setz Unbetr\u00fcglichkeit;", "tokens": ["In", "die\u00b7sen", "In\u00b7be\u00b7griff", "setz", "Un\u00b7be\u00b7tr\u00fcg\u00b7lich\u00b7keit", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "In ihm ist alles Licht, und draussen Dunkelheit.", "tokens": ["In", "ihm", "ist", "al\u00b7les", "Licht", ",", "und", "draus\u00b7sen", "Dun\u00b7kel\u00b7heit", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VAFIN", "PIAT", "NN", "$,", "KON", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.29": {"line.1": {"text": "Woher entsteht der Zank unz\u00e4hliger Parteyen,", "tokens": ["Wo\u00b7her", "ent\u00b7steht", "der", "Zank", "un\u00b7z\u00e4h\u00b7li\u00b7ger", "Par\u00b7te\u00b7yen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Die voller Widerspruch, doch alle Wahrheit schreyen?", "tokens": ["Die", "vol\u00b7ler", "Wi\u00b7der\u00b7spruch", ",", "doch", "al\u00b7le", "Wahr\u00b7heit", "schre\u00b7yen", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ADV", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ein jeder reisset ein, und stellet wieder her,", "tokens": ["Ein", "je\u00b7der", "reis\u00b7set", "ein", ",", "und", "stel\u00b7let", "wie\u00b7der", "her", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VVFIN", "PTKVZ", "$,", "KON", "VVFIN", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und wird f\u00fcr sein Geb\u00e4u mit Lust ein M\u00e4rtyrer.", "tokens": ["Und", "wird", "f\u00fcr", "sein", "Ge\u00b7b\u00e4u", "mit", "Lust", "ein", "M\u00e4r\u00b7ty\u00b7rer", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "APPR", "PPOSAT", "NN", "APPR", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+--", "measure": "unknown.measure.penta"}, "line.5": {"text": "Der maa\u00dft sich an, mit Gott sein Werk zu \u00fcberlegen,", "tokens": ["Der", "maa\u00dft", "sich", "an", ",", "mit", "Gott", "sein", "Werk", "zu", "\u00fc\u00b7berl\u00b7e\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PRF", "PTKVZ", "$,", "APPR", "NN", "PPOSAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und dieser giebt sich M\u00fch den Himmel zu bewegen.", "tokens": ["Und", "die\u00b7ser", "giebt", "sich", "M\u00fch", "den", "Him\u00b7mel", "zu", "be\u00b7we\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VVFIN", "PRF", "NE", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Gieb jedem", "tokens": ["Gieb", "je\u00b7dem"], "token_info": ["word", "word"], "pos": ["VVIMP", "PIAT"], "meter": "-+-", "measure": "amphibrach.single"}, "line.8": {"text": "Und sey denn \u00fcberzeugt, ein jeder dreht die Welt.", "tokens": ["Und", "sey", "denn", "\u00fc\u00b7berz\u00b7eugt", ",", "ein", "je\u00b7der", "dreht", "die", "Welt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "VVPP", "$,", "ART", "PIS", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Spricht dieser: wandele! so spricht der andre: stehe!", "tokens": ["Spricht", "die\u00b7ser", ":", "wan\u00b7de\u00b7le", "!", "so", "spricht", "der", "and\u00b7re", ":", "ste\u00b7he", "!"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["VVFIN", "PDAT", "$.", "VVFIN", "$.", "ADV", "VVFIN", "ART", "ADJA", "$.", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Und jeder stirbt darauf, da\u00df seine richtig gehe.", "tokens": ["Und", "je\u00b7der", "stirbt", "da\u00b7rauf", ",", "da\u00df", "sei\u00b7ne", "rich\u00b7tig", "ge\u00b7he", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "PAV", "$,", "KOUS", "PPOSAT", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Der glaubt, durch keinen Gott die Welt hervorgebracht,", "tokens": ["Der", "glaubt", ",", "durch", "kei\u00b7nen", "Gott", "die", "Welt", "her\u00b7vor\u00b7ge\u00b7bracht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "$,", "APPR", "PIAT", "NN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Und jener braucht ihn kaum; er hat sie selbst gemacht.", "tokens": ["Und", "je\u00b7ner", "braucht", "ihn", "kaum", ";", "er", "hat", "sie", "selbst", "ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VVFIN", "PPER", "ADV", "$.", "PPER", "VAFIN", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Der lehrt die Anziehung zum Vortheil seiner Schwere,", "tokens": ["Der", "lehrt", "die", "An\u00b7zie\u00b7hung", "zum", "Vor\u00b7theil", "sei\u00b7ner", "Schwe\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ART", "NN", "APPRART", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Und der nimmt Wirbel an, und ficht f\u00fcr seine Lehre.", "tokens": ["Und", "der", "nimmt", "Wir\u00b7bel", "an", ",", "und", "ficht", "f\u00fcr", "sei\u00b7ne", "Leh\u00b7re", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "VVFIN", "NN", "PTKVZ", "$,", "KON", "ADJD", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Woher entsteht der Streit? \u2013 weil mancher Narr vergi\u00dft,", "tokens": ["Wo\u00b7her", "ent\u00b7steht", "der", "Streit", "?", "\u2013", "weil", "man\u00b7cher", "Narr", "ver\u00b7gi\u00dft", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "ART", "NN", "$.", "$(", "KOUS", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Da\u00df er die Creatur, und Gott der Sch\u00f6pfer ist.", "tokens": ["Da\u00df", "er", "die", "Crea\u00b7tur", ",", "und", "Gott", "der", "Sch\u00f6p\u00b7fer", "ist", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "$,", "KON", "NN", "ART", "NN", "VAFIN", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.17": {"text": "Weil er den Kreis verl\u00e4\u00dft, worinn sein Stand ihn schr\u00e4nket,", "tokens": ["Weil", "er", "den", "Kreis", "ver\u00b7l\u00e4\u00dft", ",", "wo\u00b7rinn", "sein", "Stand", "ihn", "schr\u00e4n\u00b7ket", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVFIN", "$,", "PWAV", "PPOSAT", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Und draussen lieber irrt, als drinnen richtig denket.", "tokens": ["Und", "draus\u00b7sen", "lie\u00b7ber", "irrt", ",", "als", "drin\u00b7nen", "rich\u00b7tig", "den\u00b7ket", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "VVFIN", "$,", "KOUS", "ADV", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Er kettet Schlu\u00df an Schlu\u00df, und baut Systemen drauf,", "tokens": ["Er", "ket\u00b7tet", "Schlu\u00df", "an", "Schlu\u00df", ",", "und", "baut", "Sys\u00b7te\u00b7men", "drauf", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "APPR", "NN", "$,", "KON", "VVFIN", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+---+", "measure": "unknown.measure.penta"}, "line.20": {"text": "Und h\u00e4ngt sie in der Luft, wie Gott die Welten, auf.", "tokens": ["Und", "h\u00e4ngt", "sie", "in", "der", "Luft", ",", "wie", "Gott", "die", "Wel\u00b7ten", ",", "auf", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "ART", "NN", "$,", "PWAV", "NN", "ART", "NN", "$,", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.30": {"line.1": {"text": "Auf Muthma\u00dfung gest\u00fctzt, willst du Gewi\u00dfheit finden?", "tokens": ["Auf", "Muth\u00b7ma\u00b7\u00dfung", "ge\u00b7st\u00fctzt", ",", "willst", "du", "Ge\u00b7wi\u00df\u00b7heit", "fin\u00b7den", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVPP", "$,", "VMFIN", "PPER", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "\u00bballein ich schliesse recht?\u00ab woraus? aus vesten Gr\u00fcnden?", "tokens": ["\u00bb", "al\u00b7lein", "ich", "schlies\u00b7se", "recht", "?", "\u00ab", "wo\u00b7raus", "?", "aus", "ves\u00b7ten", "Gr\u00fcn\u00b7den", "?"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "PPER", "VVFIN", "ADJD", "$.", "$(", "PWAV", "$.", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Sonst sey so klug du willst, die Folgen auszuziehn,", "tokens": ["Sonst", "sey", "so", "klug", "du", "willst", ",", "die", "Fol\u00b7gen", "aus\u00b7zu\u00b7ziehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "ADJD", "PPER", "VMFIN", "$,", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Biet alle Lehrer auf, vom Lock bis zum Corvin;", "tokens": ["Biet", "al\u00b7le", "Leh\u00b7rer", "auf", ",", "vom", "Lock", "bis", "zum", "Cor\u00b7vin", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PIAT", "NN", "PTKVZ", "$,", "APPRART", "NN", "APPR", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und reichte vom Saturn die Kette bis zur Erden,", "tokens": ["Und", "reich\u00b7te", "vom", "Sa\u00b7turn", "die", "Ket\u00b7te", "bis", "zur", "Er\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPRART", "NN", "ART", "NN", "APPR", "APPRART", "NN", "$,"], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.6": {"text": "So wird durch keinen Schlu\u00df der Irrthum Wahrheit werden!", "tokens": ["So", "wird", "durch", "kei\u00b7nen", "Schlu\u00df", "der", "Irr\u00b7thum", "Wahr\u00b7heit", "wer\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "APPR", "PIAT", "NN", "ART", "NN", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.31": {"line.1": {"text": "Schau, wie mit stolzem Haupt, das Sturm und Meer nicht beugt,", "tokens": ["Schau", ",", "wie", "mit", "stol\u00b7zem", "Haupt", ",", "das", "Sturm", "und", "Meer", "nicht", "beugt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PWAV", "APPR", "ADJA", "NN", "$,", "ART", "NN", "KON", "NN", "PTKNEG", "VVFIN", "$,"], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.2": {"text": "Venedig voller Trotz aus seinem Schlamme steigt;", "tokens": ["Ve\u00b7ne\u00b7dig", "vol\u00b7ler", "Trotz", "aus", "sei\u00b7nem", "Schlam\u00b7me", "steigt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.3": {"text": "Und sage: sollt es wohl, gebaut auf Sumpf, und Wellen,", "tokens": ["Und", "sa\u00b7ge", ":", "sollt", "es", "wohl", ",", "ge\u00b7baut", "auf", "Sumpf", ",", "und", "Wel\u00b7len", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "VMFIN", "PPER", "ADV", "$,", "VVPP", "APPR", "NN", "$,", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ein tausendj\u00e4hrig Haupt dem Sturm entgegen stellen:", "tokens": ["Ein", "tau\u00b7send\u00b7j\u00e4h\u00b7rig", "Haupt", "dem", "Sturm", "ent\u00b7ge\u00b7gen", "stel\u00b7len", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "ART", "NN", "PTKVZ", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wenn nicht die weise Kunst die schwache Last gesch\u00fctzt,", "tokens": ["Wenn", "nicht", "die", "wei\u00b7se", "Kunst", "die", "schwa\u00b7che", "Last", "ge\u00b7sch\u00fctzt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PTKNEG", "ART", "ADJA", "NN", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und, was der Schlamm nicht tr\u00e4gt, mit Pfeilern unterst\u00fctzt?", "tokens": ["Und", ",", "was", "der", "Schlamm", "nicht", "tr\u00e4gt", ",", "mit", "Pfei\u00b7lern", "un\u00b7ter\u00b7st\u00fctzt", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "$,", "PRELS", "ART", "NN", "PTKNEG", "VVFIN", "$,", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Da aber, wo Natur und Kunst den Grund versagen,", "tokens": ["Da", "a\u00b7ber", ",", "wo", "Na\u00b7tur", "und", "Kunst", "den", "Grund", "ver\u00b7sa\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$,", "PWAV", "NN", "KON", "NN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Wie kann ein grundlos Meer ein neu Venedig tragen?", "tokens": ["Wie", "kann", "ein", "grund\u00b7los", "Meer", "ein", "neu", "Ve\u00b7ne\u00b7dig", "tra\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "ART", "ADJD", "NN", "ART", "ADJD", "NE", "VVINF", "$."], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}}, "stanza.32": {"line.1": {"text": "La\u00df, auf den Grund zu sehn, die erste Regel seyn,", "tokens": ["La\u00df", ",", "auf", "den", "Grund", "zu", "sehn", ",", "die", "ers\u00b7te", "Re\u00b7gel", "seyn", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "$,", "APPR", "ART", "NN", "PTKZU", "VVINF", "$,", "ART", "ADJA", "NN", "VAINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Du baust selbst ein System, du reissest andre ein.", "tokens": ["Du", "baust", "selbst", "ein", "Sys\u00b7tem", ",", "du", "reis\u00b7sest", "and\u00b7re", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN", "$,", "PPER", "VVFIN", "PIS", "PTKVZ", "$."], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Sie bringt von unten auf Gewi\u00dfheit in die Lehren,", "tokens": ["Sie", "bringt", "von", "un\u00b7ten", "auf", "Ge\u00b7wi\u00df\u00b7heit", "in", "die", "Leh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ADV", "APPR", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und f\u00fchrt den graden Weg, den Irrthum zu zerst\u00f6ren.", "tokens": ["Und", "f\u00fchrt", "den", "gra\u00b7den", "Weg", ",", "den", "Irr\u00b7thum", "zu", "zer\u00b7st\u00f6\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "ADJA", "NN", "$,", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.33": {"line.1": {"text": "Sieh! wie ein Federheld, bald aufrecht, bald gekr\u00fcmmt,", "tokens": ["Sieh", "!", "wie", "ein", "Fe\u00b7der\u00b7held", ",", "bald", "auf\u00b7recht", ",", "bald", "ge\u00b7kr\u00fcmmt", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "$.", "PWAV", "ART", "NN", "$,", "ADV", "ADJD", "$,", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Um seinen Gegner tanzt, und tausend Lager nimmt.", "tokens": ["Um", "sei\u00b7nen", "Geg\u00b7ner", "tanzt", ",", "und", "tau\u00b7send", "La\u00b7ger", "nimmt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PPOSAT", "NN", "VVFIN", "$,", "KON", "CARD", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Er b\u00fcckt, er dehnet sich, und l\u00e4\u00dft die Klinge blitzen,", "tokens": ["Er", "b\u00fcckt", ",", "er", "deh\u00b7net", "sich", ",", "und", "l\u00e4\u00dft", "die", "Klin\u00b7ge", "blit\u00b7zen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VVFIN", "PRF", "$,", "KON", "VVFIN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Mit einem Fechterstreich ihm leicht die Hand zu ritzen.", "tokens": ["Mit", "ei\u00b7nem", "Fech\u00b7ter\u00b7streich", "ihm", "leicht", "die", "Hand", "zu", "rit\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PPER", "ADJD", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Vielleicht, mit mindrer Kraft, als er im Schwei\u00df verwandt,", "tokens": ["Viel\u00b7leicht", ",", "mit", "mind\u00b7rer", "Kraft", ",", "als", "er", "im", "Schwei\u00df", "ver\u00b7wandt", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "APPR", "ADJA", "NN", "$,", "KOUS", "PPER", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Rei\u00dft ihm ein St\u00e4rkerer die Waffen aus der Hand.", "tokens": ["Rei\u00dft", "ihm", "ein", "St\u00e4r\u00b7ke\u00b7rer", "die", "Waf\u00b7fen", "aus", "der", "Hand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "So qu\u00e4lt sich ein Sophist von th\u00f6rigten Systemen,", "tokens": ["So", "qu\u00e4lt", "sich", "ein", "So\u00b7phist", "von", "th\u00f6\u00b7rig\u00b7ten", "Sys\u00b7te\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "ART", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.8": {"text": "Mit l\u00e4cherlicher Wuth, den kleinsten Satz zu nehmen.", "tokens": ["Mit", "l\u00e4\u00b7cher\u00b7li\u00b7cher", "Wuth", ",", "den", "kleins\u00b7ten", "Satz", "zu", "neh\u00b7men", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "ART", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Was nur f\u00fcr einen Streich die Zankkunst ausgedacht,", "tokens": ["Was", "nur", "f\u00fcr", "ei\u00b7nen", "Streich", "die", "Zank\u00b7kunst", "aus\u00b7ge\u00b7dacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "APPR", "ART", "NN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Was der Betrug ersann, wird v\u00f6llig durchgemacht.", "tokens": ["Was", "der", "Be\u00b7trug", "er\u00b7sann", ",", "wird", "v\u00f6l\u00b7lig", "durch\u00b7ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "NN", "VVFIN", "$,", "VAFIN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Wie endigt sich der Kampf? \u2013 dem ward die Hand zerrissen:", "tokens": ["Wie", "en\u00b7digt", "sich", "der", "Kampf", "?", "\u2013", "dem", "ward", "die", "Hand", "zer\u00b7ris\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PRF", "ART", "NN", "$.", "$(", "PDS", "VAFIN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "\u00bbund dieser?\u00ab \u2013 wird vielleicht ein Wort ver\u00e4ndern m\u00fcssen.", "tokens": ["\u00bb", "und", "die\u00b7ser", "?", "\u00ab", "\u2013", "wird", "viel\u00b7leicht", "ein", "Wort", "ver\u00b7\u00e4n\u00b7dern", "m\u00fcs\u00b7sen", "."], "token_info": ["punct", "word", "word", "punct", "punct", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KON", "PDS", "$.", "$(", "$(", "VAFIN", "ADV", "ART", "NN", "VVINF", "VMINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "O Gaukler, und Sophist, ihr fechtet nur zum Scherz!", "tokens": ["O", "Gauk\u00b7ler", ",", "und", "So\u00b7phist", ",", "ihr", "fech\u00b7tet", "nur", "zum", "Scherz", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "KON", "NN", "$,", "PPER", "VVFIN", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Der Ernst st\u00fcrmt auf den Grund, und st\u00f6\u00dft sein Schwert ins Herz.", "tokens": ["Der", "Ernst", "st\u00fcrmt", "auf", "den", "Grund", ",", "und", "st\u00f6\u00dft", "sein", "Schwert", "ins", "Herz", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ART", "NN", "$,", "KON", "VVFIN", "PPOSAT", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.34": {"line.1": {"text": "Klagt ihr, o Sterbliche, nach m\u00fc\u00dfigen Gez\u00e4nken,", "tokens": ["Klagt", "ihr", ",", "o", "Sterb\u00b7li\u00b7che", ",", "nach", "m\u00fc\u00b7\u00dfi\u00b7gen", "Ge\u00b7z\u00e4n\u00b7ken", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "FM", "NN", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Das Leben sey zu kurz, das Wichtigste zu denken?", "tokens": ["Das", "Le\u00b7ben", "sey", "zu", "kurz", ",", "das", "Wich\u00b7tigs\u00b7te", "zu", "den\u00b7ken", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PTKA", "ADJD", "$,", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Spart eure Zeit, und flieht der Schule Z\u00e4nkereyn;", "tokens": ["Spart", "eu\u00b7re", "Zeit", ",", "und", "flieht", "der", "Schu\u00b7le", "Z\u00e4n\u00b7ke\u00b7reyn", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPOSAT", "NN", "$,", "KON", "VVFIN", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wie Simson, fa\u00dft den Grund, und rei\u00dft die Seulen ein!", "tokens": ["Wie", "Sim\u00b7son", ",", "fa\u00dft", "den", "Grund", ",", "und", "rei\u00dft", "die", "Seu\u00b7len", "ein", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NE", "$,", "VVFIN", "ART", "NN", "$,", "KON", "VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die Last, die St\u00fcrme kaum in hundert Jahren biegen,", "tokens": ["Die", "Last", ",", "die", "St\u00fcr\u00b7me", "kaum", "in", "hun\u00b7dert", "Jah\u00b7ren", "bie\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "ADV", "APPR", "CARD", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wird, wenn die Basis sinkt, zugleich darnieder liegen.", "tokens": ["Wird", ",", "wenn", "die", "Ba\u00b7sis", "sinkt", ",", "zu\u00b7gleich", "dar\u00b7nie\u00b7der", "lie\u00b7gen", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "$,", "KOUS", "ART", "NE", "VVFIN", "$,", "ADV", "PAV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Der Lehrer des Korans, mit viel Gelehrsamkeit,", "tokens": ["Der", "Leh\u00b7rer", "des", "Ko\u00b7rans", ",", "mit", "viel", "Ge\u00b7lehr\u00b7sam\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$,", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Durch langen Schwei\u00df erkauft, und Kosten vieler Zeit,", "tokens": ["Durch", "lan\u00b7gen", "Schwei\u00df", "er\u00b7kauft", ",", "und", "Kos\u00b7ten", "vie\u00b7ler", "Zeit", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "$,", "KON", "NN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Uebt \u00fcber jeden Satz die schwindlichten Gedanken,", "tokens": ["Uebt", "\u00fc\u00b7ber", "je\u00b7den", "Satz", "die", "schwind\u00b7lich\u00b7ten", "Ge\u00b7dan\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PIAT", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+---+-", "measure": "unknown.measure.penta"}, "line.10": {"text": "Wor\u00fcber Alis Zunft, und Omars Sch\u00fcler zanken,", "tokens": ["Wo\u00b7r\u00fc\u00b7ber", "A\u00b7lis", "Zunft", ",", "und", "O\u00b7mars", "Sch\u00fc\u00b7ler", "zan\u00b7ken", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NE", "NN", "$,", "KON", "NN", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Wie viel vergebne M\u00fch hat er umsonst verwandt,", "tokens": ["Wie", "viel", "ver\u00b7geb\u00b7ne", "M\u00fch", "hat", "er", "um\u00b7sonst", "ver\u00b7wandt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIAT", "ADJA", "NN", "VAFIN", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Eh er ihr Lehrgeb\u00e4u von Satz zu Satz verstand!", "tokens": ["Eh", "er", "ihr", "Lehr\u00b7ge\u00b7b\u00e4u", "von", "Satz", "zu", "Satz", "ver\u00b7stand", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "APPR", "NN", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Doch ohne die Geduld so th\u00f6richt zu erm\u00fcden,", "tokens": ["Doch", "oh\u00b7ne", "die", "Ge\u00b7duld", "so", "th\u00f6\u00b7richt", "zu", "er\u00b7m\u00fc\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "ADV", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "H\u00e4tt er in kurzer Zeit den ganzen Streit entschieden;", "tokens": ["H\u00e4tt", "er", "in", "kur\u00b7zer", "Zeit", "den", "gan\u00b7zen", "Streit", "ent\u00b7schie\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ADJA", "NN", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Es zeigt der erste Blick auf Mahomets Geb\u00e4u,", "tokens": ["Es", "zeigt", "der", "ers\u00b7te", "Blick", "auf", "Ma\u00b7ho\u00b7mets", "Ge\u00b7b\u00e4u", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "APPR", "NE", "NE", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Da\u00df er ein Schw\u00e4rmer war, und dies voll Possen sey.", "tokens": ["Da\u00df", "er", "ein", "Schw\u00e4r\u00b7mer", "war", ",", "und", "dies", "voll", "Pos\u00b7sen", "sey", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VAFIN", "$,", "KON", "PDS", "ADJD", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.35": {"line.1": {"text": "So such in keinem Streit dich unn\u00fctz abzumatten;", "tokens": ["So", "such", "in", "kei\u00b7nem", "Streit", "dich", "un\u00b7n\u00fctz", "ab\u00b7zu\u00b7mat\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "PIAT", "NN", "PPER", "ADJD", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Dring gleich auf deinen Feind, und fechte nicht mit Schatten.", "tokens": ["Dring", "gleich", "auf", "dei\u00b7nen", "Feind", ",", "und", "fech\u00b7te", "nicht", "mit", "Schat\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "PPOSAT", "NN", "$,", "KON", "VVFIN", "PTKNEG", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Brauch deine Augen selbst; nimm nichts auf Glauben an;", "tokens": ["Brauch", "dei\u00b7ne", "Au\u00b7gen", "selbst", ";", "nimm", "nichts", "auf", "Glau\u00b7ben", "an", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "ADV", "$.", "VVIMP", "PIS", "APPR", "NN", "PTKVZ", "$."], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.4": {"text": "Den Dienst versage nie, den Beyfall jedermann.", "tokens": ["Den", "Dienst", "ver\u00b7sa\u00b7ge", "nie", ",", "den", "Bey\u00b7fall", "je\u00b7der\u00b7mann", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "$,", "ART", "NN", "PIS", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Denk alles, was du glaubst, noch einmal ernsthaft \u00fcber;", "tokens": ["Denk", "al\u00b7les", ",", "was", "du", "glaubst", ",", "noch", "ein\u00b7mal", "ernst\u00b7haft", "\u00fc\u00b7ber", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PIS", "$,", "PWS", "PPER", "VVFIN", "$,", "ADV", "ADV", "ADJD", "APPR", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und eh du weiter eilst, halt noch, und zweifle lieber.", "tokens": ["Und", "eh", "du", "wei\u00b7ter", "eilst", ",", "halt", "noch", ",", "und", "zweif\u00b7le", "lie\u00b7ber", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "VVFIN", "$,", "VVFIN", "ADV", "$,", "KON", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Gieb keinem Vorurtheil des Alterthumes Platz;", "tokens": ["Gieb", "kei\u00b7nem", "Vor\u00b7urt\u00b7heil", "des", "Al\u00b7ter\u00b7thu\u00b7mes", "Platz", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PIAT", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Der aller\u00e4lteste ist oft der schw\u00e4chste Satz,", "tokens": ["Der", "al\u00b7le\u00b7r\u00e4l\u00b7tes\u00b7te", "ist", "oft", "der", "schw\u00e4chs\u00b7te", "Satz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VAFIN", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Im Irrthum erst erzeugt, durch Ansehn angepriesen,", "tokens": ["Im", "Irr\u00b7thum", "erst", "er\u00b7zeugt", ",", "durch", "An\u00b7sehn", "an\u00b7ge\u00b7prie\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADV", "VVPP", "$,", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Geheiligt durch die Zeit, und durch die Zeit erwiesen.", "tokens": ["Ge\u00b7hei\u00b7ligt", "durch", "die", "Zeit", ",", "und", "durch", "die", "Zeit", "er\u00b7wie\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "APPR", "ART", "NN", "$,", "KON", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Den Aberglauben flieh, der Einbildung Betrug;", "tokens": ["Den", "A\u00b7berg\u00b7lau\u00b7ben", "flieh", ",", "der", "Ein\u00b7bil\u00b7dung", "Be\u00b7trug", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "ART", "NN", "NN", "$."], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.12": {"text": "Da\u00df ganz ein Volk so glaubt, sey dir nicht Grund genug.", "tokens": ["Da\u00df", "ganz", "ein", "Volk", "so", "glaubt", ",", "sey", "dir", "nicht", "Grund", "ge\u00b7nug", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "ADV", "VVFIN", "$,", "VAFIN", "PPER", "PTKNEG", "NN", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Am ersten zweifle da, wo's schrecklich ist zu zweifeln;", "tokens": ["Am", "ers\u00b7ten", "zweif\u00b7le", "da", ",", "wo's", "schreck\u00b7lich", "ist", "zu", "zwei\u00b7feln", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "VVFIN", "ADV", "$,", "PWAV", "ADJD", "VAFIN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Was nicht mit Gr\u00fcnden kann, das sch\u00fctzet sich mit Teufeln.", "tokens": ["Was", "nicht", "mit", "Gr\u00fcn\u00b7den", "kann", ",", "das", "sch\u00fct\u00b7zet", "sich", "mit", "Teu\u00b7feln", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PTKNEG", "APPR", "NN", "VMFIN", "$,", "PDS", "VVFIN", "PRF", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Folg keiner Secte nach, so alt ihr Ursprung ist,", "tokens": ["Folg", "kei\u00b7ner", "Sec\u00b7te", "nach", ",", "so", "alt", "ihr", "Ur\u00b7sprung", "ist", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PIAT", "NN", "PTKVZ", "$,", "ADV", "ADJD", "PPOSAT", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Er mag vom Zerduscht seyn, er mag vom Trismegist.", "tokens": ["Er", "mag", "vom", "Zer\u00b7duscht", "seyn", ",", "er", "mag", "vom", "Tris\u00b7me\u00b7gist", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPRART", "NN", "VAINF", "$,", "PPER", "VMFIN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Die Meinung, und die Mod'", "tokens": ["Die", "Mei\u00b7nung", ",", "und", "die", "Mod'"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "$,", "KON", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.18": {"text": "Ein Volk von Sohn auf Sohn, und l\u00e4uft durch ganze Reiche.", "tokens": ["Ein", "Volk", "von", "Sohn", "auf", "Sohn", ",", "und", "l\u00e4uft", "durch", "gan\u00b7ze", "Rei\u00b7che", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "APPR", "NN", "$,", "KON", "VVFIN", "APPR", "ADJA", "NE", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Das, was die neue tr\u00e4gt, verlacht die alte Welt,", "tokens": ["Das", ",", "was", "die", "neu\u00b7e", "tr\u00e4gt", ",", "ver\u00b7lacht", "die", "al\u00b7te", "Welt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "$,", "PRELS", "ART", "ADJA", "VVFIN", "$,", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Europa tadelt oft, was Asien gef\u00e4llt.", "tokens": ["Eu\u00b7ro\u00b7pa", "ta\u00b7delt", "oft", ",", "was", "A\u00b7sien", "ge\u00b7f\u00e4llt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADV", "$,", "PRELS", "NE", "VVPP", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.21": {"text": "Ein jedes eignes Volk h\u00e4lt seine Regeln besser,", "tokens": ["Ein", "je\u00b7des", "eig\u00b7nes", "Volk", "h\u00e4lt", "sei\u00b7ne", "Re\u00b7geln", "bes\u00b7ser", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "ADJA", "NN", "VVFIN", "PPOSAT", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Und Gottesdienst,", "tokens": ["Und", "Got\u00b7tes\u00b7dienst", ","], "token_info": ["word", "word", "punct"], "pos": ["KON", "NN", "$,"], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.36": {"line.1": {"text": "Wie kommts, da\u00df Pechins Sch\u00f6nen nicht ohne Straucheln gehn?", "tokens": ["Wie", "kommts", ",", "da\u00df", "Pe\u00b7chins", "Sch\u00f6\u00b7nen", "nicht", "oh\u00b7ne", "Strau\u00b7cheln", "gehn", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "$,", "KOUS", "NE", "NN", "PTKNEG", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Weil die Chineser glauben, ein kleiner Fu\u00df sey sch\u00f6n.", "tokens": ["Weil", "die", "Chi\u00b7ne\u00b7ser", "glau\u00b7ben", ",", "ein", "klei\u00b7ner", "Fu\u00df", "sey", "sch\u00f6n", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "VVINF", "$,", "ART", "ADJA", "NN", "VAFIN", "ADJD", "$."], "meter": "--+--+--+-+-+", "measure": "anapaest.tri.plus"}, "line.3": {"text": "In Fesseln bildet man des M\u00e4dgens zarte F\u00fc\u00dfe,", "tokens": ["In", "Fes\u00b7seln", "bil\u00b7det", "man", "des", "M\u00e4d\u00b7gens", "zar\u00b7te", "F\u00fc\u00b7\u00dfe", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PIS", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und sorgt nicht, da\u00df sie einst auf Vieren kriechen m\u00fcsse.", "tokens": ["Und", "sorgt", "nicht", ",", "da\u00df", "sie", "einst", "auf", "Vie\u00b7ren", "krie\u00b7chen", "m\u00fcs\u00b7se", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKNEG", "$,", "KOUS", "PPER", "ADV", "APPR", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die H\u00f6ckernation, die Gulliver ersann,", "tokens": ["Die", "H\u00f6\u00b7cker\u00b7na\u00b7ti\u00b7on", ",", "die", "Gul\u00b7li\u00b7ver", "er\u00b7sann", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Sieht grade Europ\u00e4er f\u00fcr Mi\u00dfgeburten an.", "tokens": ["Sieht", "gra\u00b7de", "Eu\u00b7ro\u00b7p\u00e4\u00b7er", "f\u00fcr", "Mi\u00df\u00b7ge\u00b7bur\u00b7ten", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "NN", "APPR", "NN", "PTKVZ", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.7": {"text": "So \u00e4fft ein alter Wahn mit S\u00e4tzen und Gestalten,", "tokens": ["So", "\u00e4fft", "ein", "al\u00b7ter", "Wahn", "mit", "S\u00e4t\u00b7zen", "und", "Ge\u00b7stal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Die wir f\u00fcr die Natur und f\u00fcr die Wahrheit halten.", "tokens": ["Die", "wir", "f\u00fcr", "die", "Na\u00b7tur", "und", "f\u00fcr", "die", "Wahr\u00b7heit", "hal\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "ART", "NN", "KON", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Der Lehrer nahm es an, gest\u00fctzet zwar auf nichts;", "tokens": ["Der", "Leh\u00b7rer", "nahm", "es", "an", ",", "ge\u00b7st\u00fct\u00b7zet", "zwar", "auf", "nichts", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "PTKVZ", "$,", "VVFIN", "ADV", "APPR", "PIS", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Der Sch\u00fcler fand Beweis; dies starke Wort: er sprichts.", "tokens": ["Der", "Sch\u00fc\u00b7ler", "fand", "Be\u00b7weis", ";", "dies", "star\u00b7ke", "Wort", ":", "er", "sprichts", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "NN", "$.", "PDS", "ADJA", "NN", "$.", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Der Vater lie\u00df dem Sohn ein erbliches Verm\u00f6gen,", "tokens": ["Der", "Va\u00b7ter", "lie\u00df", "dem", "Sohn", "ein", "er\u00b7bli\u00b7ches", "Ver\u00b7m\u00f6\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.12": {"text": "Den Glauben, und sein Geld, den Irrthum, und den Segen;", "tokens": ["Den", "Glau\u00b7ben", ",", "und", "sein", "Geld", ",", "den", "Irr\u00b7thum", ",", "und", "den", "Se\u00b7gen", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "KON", "PPOSAT", "NN", "$,", "ART", "NN", "$,", "KON", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Und dieser, dem Gehei\u00df des Vaters unterthan,", "tokens": ["Und", "die\u00b7ser", ",", "dem", "Ge\u00b7hei\u00df", "des", "Va\u00b7ters", "un\u00b7ter\u00b7than", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "$,", "ART", "NN", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Empfing, mit gleicher Lust, die G\u00fcter und den Wahn.", "tokens": ["Emp\u00b7fing", ",", "mit", "glei\u00b7cher", "Lust", ",", "die", "G\u00fc\u00b7ter", "und", "den", "Wahn", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "APPR", "ADJA", "NN", "$,", "ART", "NN", "KON", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "So ward und wuchs der Wahn, so wie durch neu Gew\u00e4sser", "tokens": ["So", "ward", "und", "wuchs", "der", "Wahn", ",", "so", "wie", "durch", "neu", "Ge\u00b7w\u00e4s\u00b7ser"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "KON", "VVFIN", "ART", "NN", "$,", "ADV", "KOKOM", "APPR", "ADJD", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Ein Strom im Laufe schwillt, und wird im Gehen gr\u00f6\u00dfer.", "tokens": ["Ein", "Strom", "im", "Lau\u00b7fe", "schwillt", ",", "und", "wird", "im", "Ge\u00b7hen", "gr\u00f6\u00b7\u00dfer", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "VVFIN", "$,", "KON", "VAFIN", "APPRART", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Daher zieht, jede Welt, Barbaren Africa,", "tokens": ["Da\u00b7her", "zieht", ",", "je\u00b7de", "Welt", ",", "Bar\u00b7ba\u00b7ren", "A\u00b7fri\u00b7ca", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "$,", "PIAT", "NN", "$,", "NN", "NE", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Europa Christen auf, und T\u00fcrken Asia.", "tokens": ["Eu\u00b7ro\u00b7pa", "Chris\u00b7ten", "auf", ",", "und", "T\u00fcr\u00b7ken", "A\u00b7sia", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NE", "PTKVZ", "$,", "KON", "NN", "NE", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.19": {"text": "Und jeder Lehrer s\u00e4t der eignen Meinung Samen,", "tokens": ["Und", "je\u00b7der", "Leh\u00b7rer", "s\u00e4t", "der", "eig\u00b7nen", "Mei\u00b7nung", "Sa\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "VVFIN", "ART", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Und Secten stehen auf, getauft mit seinem Namen:", "tokens": ["Und", "Sec\u00b7ten", "ste\u00b7hen", "auf", ",", "ge\u00b7tauft", "mit", "sei\u00b7nem", "Na\u00b7men", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "PTKVZ", "$,", "VVPP", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Der stoisch, der platonisch, der ein Epicur\u00e4r,", "tokens": ["Der", "sto\u00b7isch", ",", "der", "pla\u00b7to\u00b7nisch", ",", "der", "ein", "E\u00b7pi\u00b7cu\u00b7r\u00e4r", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "$,", "PRELS", "ADJD", "$,", "PRELS", "ART", "NN", "$,"], "meter": "-+--+-+-++--+", "measure": "iambic.hexa.relaxed"}, "line.22": {"text": "Der scotisch, der thomistisch \u2013 und hundert andre mehr.", "tokens": ["Der", "sco\u00b7tisch", ",", "der", "tho\u00b7mis\u00b7tisch", "\u2013", "und", "hun\u00b7dert", "and\u00b7re", "mehr", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "$,", "PRELS", "ADJD", "$(", "KON", "CARD", "PIS", "ADV", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.23": {"text": "Doch, wer Vernunft gebraucht, erbt nicht vom Demokriten,", "tokens": ["Doch", ",", "wer", "Ver\u00b7nunft", "ge\u00b7braucht", ",", "erbt", "nicht", "vom", "De\u00b7mo\u00b7kri\u00b7ten", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "PWS", "NN", "VVPP", "$,", "VVFIN", "PTKNEG", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Und von dem Plato nicht, und nicht vom Stagiriten,", "tokens": ["Und", "von", "dem", "Pla\u00b7to", "nicht", ",", "und", "nicht", "vom", "Sta\u00b7gi\u00b7ri\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NE", "PTKNEG", "$,", "KON", "PTKNEG", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Noch Wolf, noch vom Cartes; nimmt selbst nicht Wahrheit an,", "tokens": ["Noch", "Wolf", ",", "noch", "vom", "Car\u00b7tes", ";", "nimmt", "selbst", "nicht", "Wahr\u00b7heit", "an", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NE", "$,", "ADV", "APPRART", "NN", "$.", "VVFIN", "ADV", "PTKNEG", "NN", "PTKVZ", "$,"], "meter": "-+--+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.26": {"text": "Eh er sie selbst gepr\u00fcft; er ist sein eigner Mann,", "tokens": ["Eh", "er", "sie", "selbst", "ge\u00b7pr\u00fcft", ";", "er", "ist", "sein", "eig\u00b7ner", "Mann", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "ADV", "VVPP", "$.", "PPER", "VAFIN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Der allerorten her, wie Bienen Honig, sammlet,", "tokens": ["Der", "al\u00b7le\u00b7ror\u00b7ten", "her", ",", "wie", "Bie\u00b7nen", "Ho\u00b7nig", ",", "samm\u00b7let", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "PIS", "PTKVZ", "$,", "PWAV", "NN", "NN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Mit allen richtig spricht, doch nie mit andern stammlet;", "tokens": ["Mit", "al\u00b7len", "rich\u00b7tig", "spricht", ",", "doch", "nie", "mit", "an\u00b7dern", "stamm\u00b7let", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "ADJD", "VVFIN", "$,", "ADV", "ADV", "APPR", "PIS", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Sein eigenes Orakel;", "tokens": ["Sein", "ei\u00b7ge\u00b7nes", "O\u00b7ra\u00b7kel", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$."], "meter": "-+---+-", "measure": "dactylic.init"}, "line.30": {"text": "Und, wenn er selbst verstummet, kein Delphos fragen wird;", "tokens": ["Und", ",", "wenn", "er", "selbst", "ver\u00b7stum\u00b7met", ",", "kein", "Del\u00b7phos", "fra\u00b7gen", "wird", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "PPER", "ADV", "VVFIN", "$,", "PIAT", "NN", "VVINF", "VAFIN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.31": {"text": "Der seine Wahrheit n\u00fctzt, sich nicht vom Ziel entfernet,", "tokens": ["Der", "sei\u00b7ne", "Wahr\u00b7heit", "n\u00fctzt", ",", "sich", "nicht", "vom", "Ziel", "ent\u00b7fer\u00b7net", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "VVFIN", "$,", "PRF", "PTKNEG", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Und alles zum Gebrauch, nichts blo\u00df aus Neugier, lernet.", "tokens": ["Und", "al\u00b7les", "zum", "Ge\u00b7brauch", ",", "nichts", "blo\u00df", "aus", "Neu\u00b7gier", ",", "ler\u00b7net", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "PIS", "APPRART", "NN", "$,", "PIS", "ADV", "APPR", "NN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.37": {"line.1": {"text": "Arbeite dich im Schwall der Meinungen empor;", "tokens": ["Ar\u00b7bei\u00b7te", "dich", "im", "Schwall", "der", "Mei\u00b7nun\u00b7gen", "em\u00b7por", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "APPRART", "NN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Ergreif den n\u00e4chsten Fels, und steig am Strand empor,", "tokens": ["Er\u00b7greif", "den", "n\u00e4chs\u00b7ten", "Fels", ",", "und", "steig", "am", "Strand", "em\u00b7por", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ART", "ADJA", "NN", "$,", "KON", "VVFIN", "APPRART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Eh dich der volle Strom, die Beute seiner Wogen,", "tokens": ["Eh", "dich", "der", "vol\u00b7le", "Strom", ",", "die", "Beu\u00b7te", "sei\u00b7ner", "Wo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "$,", "ART", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ins uferlose Meer mit sich hinabgezogen:", "tokens": ["Ins", "u\u00b7fer\u00b7lo\u00b7se", "Meer", "mit", "sich", "hin\u00b7ab\u00b7ge\u00b7zo\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "APPR", "PRF", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Umsonst irrt da dein Aug, umsonst suchst du den Strand,", "tokens": ["Um\u00b7sonst", "irrt", "da", "dein", "Aug", ",", "um\u00b7sonst", "suchst", "du", "den", "Strand", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "PPOSAT", "NN", "$,", "ADV", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und schwimmst mit aller Macht, und siehst nicht wieder Land.", "tokens": ["Und", "schwimmst", "mit", "al\u00b7ler", "Macht", ",", "und", "siehst", "nicht", "wie\u00b7der", "Land", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PIAT", "NN", "$,", "KON", "VVFIN", "PTKNEG", "ADV", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Versuche bald, und oft die Kr\u00e4fte deiner Fl\u00fcgel;", "tokens": ["Ver\u00b7su\u00b7che", "bald", ",", "und", "oft", "die", "Kr\u00e4f\u00b7te", "dei\u00b7ner", "Fl\u00fc\u00b7gel", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "$,", "KON", "ADV", "ART", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Streich erst am Boden her, dann schwinge dich auf H\u00fcgel:", "tokens": ["Streich", "erst", "am", "Bo\u00b7den", "her", ",", "dann", "schwin\u00b7ge", "dich", "auf", "H\u00fc\u00b7gel", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "APPRART", "NN", "PTKVZ", "$,", "ADV", "VVFIN", "PRF", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Ein jeder Flug erweckt, und st\u00e4rket die Begier,", "tokens": ["Ein", "je\u00b7der", "Flug", "er\u00b7weckt", ",", "und", "st\u00e4r\u00b7ket", "die", "Be\u00b7gier", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VVPP", "$,", "KON", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Zuletzt siehst du mit Lust Gebirge unter dir,", "tokens": ["Zu\u00b7letzt", "siehst", "du", "mit", "Lust", "Ge\u00b7bir\u00b7ge", "un\u00b7ter", "dir", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "NN", "NN", "APPR", "PPER", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Die tr\u00e4ge Pilgrimme, noch unge\u00fcbt im Wandern,", "tokens": ["Die", "tr\u00e4\u00b7ge", "Pil\u00b7grim\u00b7me", ",", "noch", "un\u00b7ge\u00b7\u00fcbt", "im", "Wan\u00b7dern", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ADV", "ADJD", "APPRART", "NN", "$,"], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.12": {"text": "Mit Schrecken vor sich sehn, und eines auf dem andern.", "tokens": ["Mit", "Schre\u00b7cken", "vor", "sich", "sehn", ",", "und", "ei\u00b7nes", "auf", "dem", "an\u00b7dern", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "PRF", "VVINF", "$,", "KON", "ART", "APPR", "ART", "ADJA", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Wenn nicht der J\u00fcngling schon Vernunft im steten Flei\u00df", "tokens": ["Wenn", "nicht", "der", "J\u00fcng\u00b7ling", "schon", "Ver\u00b7nunft", "im", "ste\u00b7ten", "Flei\u00df"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PTKNEG", "ART", "NN", "ADV", "NN", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Zum Ueberlegen \u00fcbt, wie n\u00fctzt sie wohl der Greis?", "tokens": ["Zum", "Ue\u00b7ber\u00b7le\u00b7gen", "\u00fcbt", ",", "wie", "n\u00fctzt", "sie", "wohl", "der", "Greis", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "$,", "PWAV", "VVFIN", "PPER", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Der, so die Fertigkeit im Denken zu erhalten,", "tokens": ["Der", ",", "so", "die", "Fer\u00b7tig\u00b7keit", "im", "Den\u00b7ken", "zu", "er\u00b7hal\u00b7ten", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "ADV", "ART", "NN", "APPRART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Ins hohe Alter spart, h\u00e4ngt sich, gleich einem Alten,", "tokens": ["Ins", "ho\u00b7he", "Al\u00b7ter", "spart", ",", "h\u00e4ngt", "sich", ",", "gleich", "ei\u00b7nem", "Al\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "VVFIN", "$,", "VVFIN", "PRF", "$,", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Dem schon der Bart gereift, dem G\u00e4ngelwagen an,", "tokens": ["Dem", "schon", "der", "Bart", "ge\u00b7reift", ",", "dem", "G\u00e4n\u00b7ge\u00b7lwa\u00b7gen", "an", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ART", "NN", "VVPP", "$,", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Und lernet dann erst gehn, wenn gar kein Fu\u00df mehr kann.", "tokens": ["Und", "ler\u00b7net", "dann", "erst", "gehn", ",", "wenn", "gar", "kein", "Fu\u00df", "mehr", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ADV", "VVINF", "$,", "KOUS", "ADV", "PIAT", "NN", "ADV", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.38": {"line.1": {"text": "Dies ist die Klugheit dann, die dich zu H\u00f6hen leitet,", "tokens": ["Dies", "ist", "die", "Klug\u00b7heit", "dann", ",", "die", "dich", "zu", "H\u00f6\u00b7hen", "lei\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "ADV", "$,", "PRELS", "PRF", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wohin der halbe Mensch, der P\u00f6pel, niemals schreitet.", "tokens": ["Wo\u00b7hin", "der", "hal\u00b7be", "Mensch", ",", "der", "P\u00f6\u00b7pel", ",", "nie\u00b7mals", "schrei\u00b7tet", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADJA", "NN", "$,", "ART", "NN", "$,", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "So ungleich gab zwar Gott Vernunft dem Menschen nie,", "tokens": ["So", "un\u00b7gleich", "gab", "zwar", "Gott", "Ver\u00b7nunft", "dem", "Men\u00b7schen", "nie", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "ADV", "NN", "NN", "ART", "NN", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Da\u00df der, wie Engel denkt, der etwas mehr als Vieh:", "tokens": ["Da\u00df", "der", ",", "wie", "En\u00b7gel", "denkt", ",", "der", "et\u00b7was", "mehr", "als", "Vieh", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "$,", "PWAV", "NE", "VVFIN", "$,", "PRELS", "ADV", "PIAT", "KOKOM", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wohin Aristotels", "tokens": ["Wo\u00b7hin", "A\u00b7ris\u00b7to\u00b7tels"], "token_info": ["word", "word"], "pos": ["PWAV", "NE"], "meter": "--+-+-", "measure": "anapaest.init"}, "line.6": {"text": "Dahin f\u00fchrt auch der Flei\u00df die schw\u00e4chern Xenokraten.", "tokens": ["Da\u00b7hin", "f\u00fchrt", "auch", "der", "Flei\u00df", "die", "schw\u00e4\u00b7chern", "Xe\u00b7no\u00b7kra\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "ADV", "ART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Flieh dann die Uebung nicht, zu gro\u00df auf dein Genie,", "tokens": ["Flieh", "dann", "die", "Ue\u00b7bung", "nicht", ",", "zu", "gro\u00df", "auf", "dein", "Ge\u00b7nie", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "PTKNEG", "$,", "PTKA", "ADJD", "APPR", "PPOSAT", "NN", "$,"], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.8": {"text": "Und denke nicht so stolz, dein Geist ersetze sie.", "tokens": ["Und", "den\u00b7ke", "nicht", "so", "stolz", ",", "dein", "Geist", "er\u00b7set\u00b7ze", "sie", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKNEG", "ADV", "ADJD", "$,", "PPOSAT", "NN", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Der Kranke, der getrost die Mittel von sich setzet,", "tokens": ["Der", "Kran\u00b7ke", ",", "der", "ge\u00b7trost", "die", "Mit\u00b7tel", "von", "sich", "set\u00b7zet", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ADJD", "ART", "NN", "APPR", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Und weil er St\u00e4rke merkt, sie f\u00fcr entbehrlich sch\u00e4tzet,", "tokens": ["Und", "weil", "er", "St\u00e4r\u00b7ke", "merkt", ",", "sie", "f\u00fcr", "ent\u00b7behr\u00b7lich", "sch\u00e4t\u00b7zet", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "NN", "VVFIN", "$,", "PPER", "APPR", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Giebt ein gewisses Zeichen, je weniger er klagt,", "tokens": ["Giebt", "ein", "ge\u00b7wis\u00b7ses", "Zei\u00b7chen", ",", "je", "we\u00b7ni\u00b7ger", "er", "klagt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "$,", "ADV", "ADV", "PPER", "VVFIN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.12": {"text": "Da\u00df schon der Tod im Fieber an seinem Herzen nagt;", "tokens": ["Da\u00df", "schon", "der", "Tod", "im", "Fie\u00b7ber", "an", "sei\u00b7nem", "Her\u00b7zen", "nagt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "APPRART", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.13": {"text": "Inde\u00df verzehret es die S\u00e4fte seiner Glieder,", "tokens": ["In\u00b7de\u00df", "ver\u00b7zeh\u00b7ret", "es", "die", "S\u00e4f\u00b7te", "sei\u00b7ner", "Glie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "ART", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Und fri\u00dft ihn langsam auf, und wirft ihn endlich nieder.", "tokens": ["Und", "fri\u00dft", "ihn", "lang\u00b7sam", "auf", ",", "und", "wirft", "ihn", "end\u00b7lich", "nie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADJD", "PTKVZ", "$,", "KON", "VVFIN", "PPER", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "So langsam, und so still verzehret mit der Zeit,", "tokens": ["So", "lang\u00b7sam", ",", "und", "so", "still", "ver\u00b7zeh\u00b7ret", "mit", "der", "Zeit", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "KON", "ADV", "ADJD", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Die Hecktik unsrer Seelen Gedankenlosigkeit.", "tokens": ["Die", "Heck\u00b7tik", "uns\u00b7rer", "See\u00b7len", "Ge\u00b7dan\u00b7ken\u00b7lo\u00b7sig\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.39": {"line.1": {"text": "Wie kommt es, da\u00df ein Baur, ein Schiffer, ein Soldat,", "tokens": ["Wie", "kommt", "es", ",", "da\u00df", "ein", "Baur", ",", "ein", "Schif\u00b7fer", ",", "ein", "Sol\u00b7dat", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "$,", "KOUS", "ART", "NN", "$,", "ART", "NN", "$,", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Bey harter Lebensart die gr\u00f6\u00dfte St\u00e4rke hat;", "tokens": ["Bey", "har\u00b7ter", "Le\u00b7ben\u00b7sart", "die", "gr\u00f6\u00df\u00b7te", "St\u00e4r\u00b7ke", "hat", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ART", "ADJA", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Da ein Verz\u00e4rtelter, beym Ambrosin der G\u00f6tter,", "tokens": ["Da", "ein", "Ver\u00b7z\u00e4r\u00b7tel\u00b7ter", ",", "beym", "A\u00b7mbro\u00b7sin", "der", "G\u00f6t\u00b7ter", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "$,", "APPRART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Kaum seine Glieder schleppt, und lebt auf Gunst der Wetter?", "tokens": ["Kaum", "sei\u00b7ne", "Glie\u00b7der", "schleppt", ",", "und", "lebt", "auf", "Gunst", "der", "Wet\u00b7ter", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "VVFIN", "$,", "KON", "VVFIN", "APPR", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Der ward schon als ein Kind bewegt, bald an dem Pflug,", "tokens": ["Der", "ward", "schon", "als", "ein", "Kind", "be\u00b7wegt", ",", "bald", "an", "dem", "Pflug", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "KOUS", "ART", "NN", "VVFIN", "$,", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Bald, wenn er mit dem Ruder die Wasserfl\u00e4che schlug;", "tokens": ["Bald", ",", "wenn", "er", "mit", "dem", "Ru\u00b7der", "die", "Was\u00b7ser\u00b7fl\u00e4\u00b7che", "schlug", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "PPER", "APPR", "ART", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.7": {"text": "Der Magen ward gesund, und go\u00df nahrhafte S\u00e4fte", "tokens": ["Der", "Ma\u00b7gen", "ward", "ge\u00b7sund", ",", "und", "go\u00df", "nahr\u00b7haf\u00b7te", "S\u00e4f\u00b7te"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "VVPP", "$,", "KON", "VVFIN", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "In seine Nerven aus, und gab den Gliedern Kr\u00e4fte:", "tokens": ["In", "sei\u00b7ne", "Ner\u00b7ven", "aus", ",", "und", "gab", "den", "Glie\u00b7dern", "Kr\u00e4f\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PTKVZ", "$,", "KON", "VVFIN", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Indem der Weichliche, aus Furcht der Mutter krank,", "tokens": ["In\u00b7dem", "der", "Weich\u00b7li\u00b7che", ",", "aus", "Furcht", "der", "Mut\u00b7ter", "krank", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "$,", "APPR", "NN", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "In tr\u00e4ger Musse schlief, und wenig a\u00df und trank.", "tokens": ["In", "tr\u00e4\u00b7ger", "Mus\u00b7se", "schlief", ",", "und", "we\u00b7nig", "a\u00df", "und", "trank", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "$,", "KON", "PIS", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Natur, zu einem Zweck, gab einerley Befehle;", "tokens": ["Na\u00b7tur", ",", "zu", "ei\u00b7nem", "Zweck", ",", "gab", "ei\u00b7ner\u00b7ley", "Be\u00b7feh\u00b7le", ";"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "APPR", "ART", "NN", "$,", "VVFIN", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Die Arbeit st\u00e4rkt den Leib, und st\u00e4rket auch die Seele.", "tokens": ["Die", "Ar\u00b7beit", "st\u00e4rkt", "den", "Leib", ",", "und", "st\u00e4r\u00b7ket", "auch", "die", "See\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "$,", "KON", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Mit eines Newtons Hirn, mit eben dem Verstand,", "tokens": ["Mit", "ei\u00b7nes", "New\u00b7tons", "Hirn", ",", "mit", "e\u00b7ben", "dem", "Ver\u00b7stand", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,", "APPR", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Der die Natur enth\u00fcllt, und ihr Gesetz erfand,", "tokens": ["Der", "die", "Na\u00b7tur", "ent\u00b7h\u00fcllt", ",", "und", "ihr", "Ge\u00b7setz", "er\u00b7fand", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "VVPP", "$,", "KON", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Wirst du doch, unge\u00fcbt, dich bey der Rechnung qu\u00e4len,", "tokens": ["Wirst", "du", "doch", ",", "un\u00b7ge\u00b7\u00fcbt", ",", "dich", "bey", "der", "Rech\u00b7nung", "qu\u00e4\u00b7len", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "$,", "ADJD", "$,", "PRF", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Den Regeln nachzugehn, die Sch\u00fcler nicht verfehlen.", "tokens": ["Den", "Re\u00b7geln", "nach\u00b7zu\u00b7gehn", ",", "die", "Sch\u00fc\u00b7ler", "nicht", "ver\u00b7feh\u00b7len", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVIZU", "$,", "ART", "NN", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.40": {"line.1": {"text": "Mit dieser Kunst zu denken, geh, vom Ger\u00e4usch verschont,", "tokens": ["Mit", "die\u00b7ser", "Kunst", "zu", "den\u00b7ken", ",", "geh", ",", "vom", "Ge\u00b7r\u00e4usch", "ver\u00b7schont", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "PTKZU", "VVINF", "$,", "VVFIN", "$,", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "In jene heilge Stille, wo gern die Weisheit wohnt.", "tokens": ["In", "je\u00b7ne", "heil\u00b7ge", "Stil\u00b7le", ",", "wo", "gern", "die", "Weis\u00b7heit", "wohnt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "ADJA", "NN", "$,", "PWAV", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Gefesselt mit der Welt, h\u00e4lt auf gewissen H\u00f6hen", "tokens": ["Ge\u00b7fes\u00b7selt", "mit", "der", "Welt", ",", "h\u00e4lt", "auf", "ge\u00b7wis\u00b7sen", "H\u00f6\u00b7hen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "APPR", "ART", "NN", "$,", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die Kette deinen Geist, und zwingt ihn, da zu stehen.", "tokens": ["Die", "Ket\u00b7te", "dei\u00b7nen", "Geist", ",", "und", "zwingt", "ihn", ",", "da", "zu", "ste\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "$,", "KON", "VVFIN", "PPER", "$,", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Zwar lehren, da\u00df man ganz vom K\u00f6rperlichen frey,", "tokens": ["Zwar", "leh\u00b7ren", ",", "da\u00df", "man", "ganz", "vom", "K\u00f6r\u00b7per\u00b7li\u00b7chen", "frey", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVINF", "$,", "KOUS", "PIS", "ADV", "APPRART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und in Verstand und Geist, wie aufgel\u00f6set, sey,", "tokens": ["Und", "in", "Ver\u00b7stand", "und", "Geist", ",", "wie", "auf\u00b7ge\u00b7l\u00f6\u00b7set", ",", "sey", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["KON", "APPR", "NN", "KON", "NN", "$,", "PWAV", "VVPP", "$,", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Ist metaphysisches, unsinniges Geschw\u00e4tze:", "tokens": ["Ist", "me\u00b7ta\u00b7phy\u00b7si\u00b7sches", ",", "un\u00b7sin\u00b7ni\u00b7ges", "Ge\u00b7schw\u00e4t\u00b7ze", ":"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "$,", "ADJA", "NN", "$."], "meter": "+-+-+-+-+--+-", "measure": "hexameter"}, "line.8": {"text": "Doch, da\u00df man Vorurtheil, und Mod' herunter setze,", "tokens": ["Doch", ",", "da\u00df", "man", "Vor\u00b7urt\u00b7heil", ",", "und", "Mod'", "her\u00b7un\u00b7ter", "set\u00b7ze", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "PIS", "NN", "$,", "KON", "NN", "APZR", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Der Meinung Sieger sey, gereiniget vom Wahn,", "tokens": ["Der", "Mei\u00b7nung", "Sie\u00b7ger", "sey", ",", "ge\u00b7rei\u00b7ni\u00b7get", "vom", "Wahn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VAFIN", "$,", "VVPP", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Ist, was nicht jeder kann, doch mancher schon gethan.", "tokens": ["Ist", ",", "was", "nicht", "je\u00b7der", "kann", ",", "doch", "man\u00b7cher", "schon", "ge\u00b7than", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "$,", "PRELS", "PTKNEG", "PIS", "VMFIN", "$,", "ADV", "PIS", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Wer so den Geist befreyt, schaut bald aus solchen H\u00f6hen;", "tokens": ["Wer", "so", "den", "Geist", "be\u00b7freyt", ",", "schaut", "bald", "aus", "sol\u00b7chen", "H\u00f6\u00b7hen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "ART", "NN", "VVPP", "$,", "VVFIN", "ADV", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Wie Scipio", "tokens": ["Wie", "Sci\u00b7pio"], "token_info": ["word", "word"], "pos": ["PWAV", "NE"], "meter": "-+-", "measure": "amphibrach.single"}, "line.13": {"text": "Wie ward vom Himmel ab der tiefe Erdball klein!", "tokens": ["Wie", "ward", "vom", "Him\u00b7mel", "ab", "der", "tie\u00b7fe", "Erd\u00b7ball", "klein", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "APPRART", "NN", "APPR", "ART", "ADJA", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Kaum fand er Roms Gebiet, den Fleck von Koht darein.", "tokens": ["Kaum", "fand", "er", "Roms", "Ge\u00b7biet", ",", "den", "Fleck", "von", "Koht", "da\u00b7rein", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "NE", "NN", "$,", "ART", "NN", "APPR", "NN", "PAV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}