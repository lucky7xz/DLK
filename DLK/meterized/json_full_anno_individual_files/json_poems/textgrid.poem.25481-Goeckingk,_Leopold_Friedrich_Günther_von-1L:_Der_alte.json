{"textgrid.poem.25481": {"metadata": {"author": {"name": "Goeckingk, Leopold Friedrich G\u00fcnther von", "birth": "N.A.", "death": "N.A."}, "title": "1L: Der alte ", "genre": "verse", "period": "N.A.", "pub_year": 1788, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Der alte ", "tokens": ["Der", "al\u00b7te"], "token_info": ["word", "word"], "pos": ["ART", "ADJA"], "meter": "-+-", "measure": "amphibrach.single"}, "line.2": {"text": "Ist wieder da. Halb Deutschland hat er kaum", "tokens": ["Ist", "wie\u00b7der", "da", ".", "Halb", "Deutschland", "hat", "er", "kaum"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "ADV", "$.", "NE", "NE", "VAFIN", "PPER", "ADV"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Durchzogen; denn der guten Seele brannten", "tokens": ["Durch\u00b7zo\u00b7gen", ";", "denn", "der", "gu\u00b7ten", "See\u00b7le", "brann\u00b7ten"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "$.", "KON", "ART", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Die Sohlen, um bei mir, der Nacht f\u00fcr Nacht im Traum'", "tokens": ["Die", "Soh\u00b7len", ",", "um", "bei", "mir", ",", "der", "Nacht", "f\u00fcr", "Nacht", "im", "Traum'"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "KOUI", "APPR", "PPER", "$,", "ART", "NN", "APPR", "NN", "APPRART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ihm vorgekommen war, (trotz allem Widerrathen", "tokens": ["Ihm", "vor\u00b7ge\u00b7kom\u00b7men", "war", ",", "(", "trotz", "al\u00b7lem", "Wi\u00b7der\u00b7ra\u00b7then"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word"], "pos": ["PPER", "VVPP", "VAFIN", "$,", "$(", "APPR", "PIS", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Der Frau,) nur bald genug zu seyn,", "tokens": ["Der", "Frau", ",", ")", "nur", "bald", "ge\u00b7nug", "zu", "seyn", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "$(", "ADV", "ADV", "ADV", "PTKZU", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und seinen Beutel voll Dukaten", "tokens": ["Und", "sei\u00b7nen", "Beu\u00b7tel", "voll", "Du\u00b7ka\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "ADJD", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Auf meinen Schreibtisch auszustreun.", "tokens": ["Auf", "mei\u00b7nen", "Schreib\u00b7tisch", "aus\u00b7zu\u00b7streun", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "\u00bbhier, Herr, ist alles, was der Elephant", "tokens": ["\u00bb", "hier", ",", "Herr", ",", "ist", "al\u00b7les", ",", "was", "der", "E\u00b7le\u00b7phant"], "token_info": ["punct", "word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["$(", "ADV", "$,", "NN", "$,", "VAFIN", "PIS", "$,", "PRELS", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Verdient mir hat. Vor allen Dingen", "tokens": ["Ver\u00b7di\u00b7ent", "mir", "hat", ".", "Vor", "al\u00b7len", "Din\u00b7gen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "PPER", "VAFIN", "$.", "APPR", "PIAT", "NN"], "meter": "----+-+-+-", "measure": "unknown.measure.tri"}, "line.11": {"text": "M\u00f6cht' ich nun gern, \u2013 mit Gott wird's ja gelingen! \u2013", "tokens": ["M\u00f6cht'", "ich", "nun", "gern", ",", "\u2013", "mit", "Gott", "wird's", "ja", "ge\u00b7lin\u00b7gen", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VMFIN", "PPER", "ADV", "ADV", "$,", "$(", "APPR", "NN", "VAFIN", "ADV", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Das treue Thier auch in sein Vaterland \u2013", "tokens": ["Das", "treu\u00b7e", "Thier", "auch", "in", "sein", "Va\u00b7ter\u00b7land", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "APPR", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "Wie hei\u00dft's doch gleich? \u2013 zur\u00fcck wohl bringen.\u00ab \u2013", "tokens": ["Wie", "hei\u00dft's", "doch", "gleich", "?", "\u2013", "zu\u00b7r\u00fcck", "wohl", "brin\u00b7gen", ".", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PWAV", "NE", "ADV", "ADV", "$.", "$(", "VVIMP", "ADV", "VVINF", "$.", "$(", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "Ei, Gr\u00fcnewald! wei\u00dft du auch wohl, wie weit", "tokens": ["Ei", ",", "Gr\u00fc\u00b7ne\u00b7wald", "!", "wei\u00dft", "du", "auch", "wohl", ",", "wie", "weit"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["NN", "$,", "NN", "$.", "VVFIN", "PPER", "ADV", "ADV", "$,", "PWAV", "ADJD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.15": {"text": "Das ", "tokens": ["Das"], "token_info": ["word"], "pos": ["PDS"], "meter": "-", "measure": "single.down"}, "line.16": {"text": "\u00bbthut nichts! Ich reis' in Gottes Namen,", "tokens": ["\u00bb", "thut", "nichts", "!", "Ich", "reis'", "in", "Got\u00b7tes", "Na\u00b7men", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PIS", "$.", "PPER", "VVFIN", "APPR", "NN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.17": {"text": "Und was ich brauch', ist eine Kleinigkeit;", "tokens": ["Und", "was", "ich", "brauch'", ",", "ist", "ei\u00b7ne", "Klei\u00b7nig\u00b7keit", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "VVFIN", "$,", "VAFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.18": {"text": "Der Elephant mu\u00df Heu im Schiffe fressen. \u2013", "tokens": ["Der", "E\u00b7le\u00b7phant", "mu\u00df", "Heu", "im", "Schif\u00b7fe", "fres\u00b7sen", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "VMFIN", "NN", "APPRART", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.19": {"text": "Doch, Sapperlot! Herr, h\u00e4tt' ich doch beinah", "tokens": ["Doch", ",", "Sap\u00b7per\u00b7lot", "!", "Herr", ",", "h\u00e4tt'", "ich", "doch", "bei\u00b7nah"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "$,", "NE", "$.", "NN", "$,", "VAFIN", "PPER", "ADV", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.20": {"text": "Mein Weib, das b\u00f6se Thier, vergessen:", "tokens": ["Mein", "Weib", ",", "das", "b\u00f6\u00b7se", "Thier", ",", "ver\u00b7ges\u00b7sen", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "ART", "ADJA", "NN", "$,", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.21": {"text": "F\u00fcr diese sorgen Sie doch ja.", "tokens": ["F\u00fcr", "die\u00b7se", "sor\u00b7gen", "Sie", "doch", "ja", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "PPER", "ADV", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.22": {"text": "Und \u2013 \u2013 ja \u2013 hab' ich das Thier an Ort und Stelle", "tokens": ["Und", "\u2013", "\u2013", "ja", "\u2013", "hab'", "ich", "das", "Thier", "an", "Ort", "und", "Stel\u00b7le"], "token_info": ["word", "punct", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "$(", "$(", "PTKANT", "$(", "VAFIN", "PPER", "ART", "NN", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.23": {"text": "Gebracht, so kehr' ich wieder um;", "tokens": ["Ge\u00b7bracht", ",", "so", "kehr'", "ich", "wie\u00b7der", "um", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "ADV", "VVFIN", "PPER", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.24": {"text": "Doch, lieber Herr, auf alle F\u00e4lle", "tokens": ["Doch", ",", "lie\u00b7ber", "Herr", ",", "auf", "al\u00b7le", "F\u00e4l\u00b7le"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "$,", "ADV", "NN", "$,", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.25": {"text": "Gefa\u00dft zu seyn\u00ab \u2013", "tokens": ["Ge\u00b7fa\u00dft", "zu", "seyn", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["VVPP", "PTKZU", "VAINF", "$(", "$("], "meter": "-+-+", "measure": "iambic.di"}, "line.26": {"text": "Auf einmal ward er stumm,", "tokens": ["Auf", "ein\u00b7mal", "ward", "er", "stumm", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "VAFIN", "PPER", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.27": {"text": "Und sah mich weinend an, als sollt' ich ihn errathen.", "tokens": ["Und", "sah", "mich", "wei\u00b7nend", "an", ",", "als", "sollt'", "ich", "ihn", "er\u00b7ra\u00b7then", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADJD", "PTKVZ", "$,", "KOUS", "VMFIN", "PPER", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Nein! sagt' ich, lieber ", "tokens": ["Nein", "!", "sagt'", "ich", ",", "lie\u00b7ber"], "token_info": ["word", "punct", "word", "word", "punct", "word"], "pos": ["PTKANT", "$.", "VVFIN", "PPER", "$,", "ADV"], "meter": "-+-+-", "measure": "iambic.di"}, "line.29": {"text": "Nimm deinen Beutel voll Dukaten,", "tokens": ["Nimm", "dei\u00b7nen", "Beu\u00b7tel", "voll", "Du\u00b7ka\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPOSAT", "NN", "ADJD", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.30": {"text": "Und kaufe Land; auf unsern fetten Saaten", "tokens": ["Und", "kau\u00b7fe", "Land", ";", "auf", "un\u00b7sern", "fet\u00b7ten", "Saa\u00b7ten"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "NN", "$.", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.31": {"text": "Vergi\u00dft der Elephant sein ", "tokens": ["Ver\u00b7gi\u00dft", "der", "E\u00b7le\u00b7phant", "sein"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "ART", "NN", "PPOSAT"], "meter": "-+-+---", "measure": "unknown.measure.di"}, "line.32": {"text": "Allein das hie\u00df nur tauben Ohren", "tokens": ["Al\u00b7lein", "das", "hie\u00df", "nur", "tau\u00b7ben", "Oh\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "PDS", "VVFIN", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.33": {"text": "Gepredigt. Er meint', an ihm sey ja", "tokens": ["Ge\u00b7pre\u00b7digt", ".", "Er", "meint'", ",", "an", "ihm", "sey", "ja"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVPP", "$.", "PPER", "VVFIN", "$,", "APPR", "PPER", "VAFIN", "ADV"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.34": {"text": "Sehr wenig oder nichts verloren;", "tokens": ["Sehr", "we\u00b7nig", "o\u00b7der", "nichts", "ver\u00b7lo\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "KON", "PIS", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.35": {"text": "Und dennoch kommt in ihm ein Mensch nach Asia,", "tokens": ["Und", "den\u00b7noch", "kommt", "in", "ihm", "ein", "Mensch", "nach", "A\u00b7sia", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "APPR", "PPER", "ART", "NN", "APPR", "NE", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.36": {"text": "Wie ", "tokens": ["Wie"], "token_info": ["word"], "pos": ["PWAV"], "meter": "+", "measure": "single.up"}, "line.37": {"text": "Das Haupt in ", "tokens": ["Das", "Haupt", "in"], "token_info": ["word", "word", "word"], "pos": ["ART", "NN", "APPR"], "meter": "-+-", "measure": "amphibrach.single"}, "line.38": {"text": "Da er durchaus sich nicht will halten lassen,", "tokens": ["Da", "er", "durc\u00b7haus", "sich", "nicht", "will", "hal\u00b7ten", "las\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PRF", "PTKNEG", "VMFIN", "VVINF", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.39": {"text": "So mag das Gl\u00fcck mit ihm und diesem Briefe gehn.", "tokens": ["So", "mag", "das", "Gl\u00fcck", "mit", "ihm", "und", "die\u00b7sem", "Brie\u00b7fe", "gehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "NN", "APPR", "PPER", "KON", "PDAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.40": {"text": "Die Sprache wird er schwerlich fassen,", "tokens": ["Die", "Spra\u00b7che", "wird", "er", "schwer\u00b7lich", "fas\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.41": {"text": "Lernt aber ein Dollmetscher ihn verstehn,", "tokens": ["Lernt", "a\u00b7ber", "ein", "Doll\u00b7met\u00b7scher", "ihn", "ver\u00b7stehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "PPER", "VVINF", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.42": {"text": "(denn sein Accent ist rauh, wie unsre Luft vom Brocken,)", "tokens": ["(", "denn", "sein", "Ac\u00b7cent", "ist", "rauh", ",", "wie", "uns\u00b7re", "Luft", "vom", "Bro\u00b7cken", ",", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "KON", "PPOSAT", "NN", "VAFIN", "ADJD", "$,", "PWAV", "PPOSAT", "NN", "APPRART", "NN", "$,", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.43": {"text": "So wird der Ton, der oft mit Thr\u00e4nen stahl,", "tokens": ["So", "wird", "der", "Ton", ",", "der", "oft", "mit", "Thr\u00e4\u00b7nen", "stahl", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "$,", "PRELS", "ADV", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.44": {"text": "So s\u00fc\u00df ", "tokens": ["So", "s\u00fc\u00df"], "token_info": ["word", "word"], "pos": ["ADV", "ADJD"], "meter": "-+", "measure": "iambic.single"}, "line.45": {"text": "Am Thurm' von ", "tokens": ["Am", "Thurm'", "von"], "token_info": ["word", "word", "word"], "pos": ["APPRART", "NN", "APPR"], "meter": "-+-", "measure": "amphibrach.single"}, "line.46": {"text": "Nur m\u00fc\u00dft ", "tokens": ["Nur", "m\u00fc\u00dft"], "token_info": ["word", "word"], "pos": ["ADV", "VMFIN"], "meter": "+-", "measure": "trochaic.single"}, "line.47": {"text": "Wenn er, und lie\u00dfet ", "tokens": ["Wenn", "er", ",", "und", "lie\u00b7\u00dfet"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["KOUS", "PPER", "$,", "KON", "VVFIN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.48": {"text": "Vorwerfen, nie sich wird bequemen,", "tokens": ["Vor\u00b7wer\u00b7fen", ",", "nie", "sich", "wird", "be\u00b7que\u00b7men", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADV", "PRF", "VAFIN", "ADJA", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.49": {"text": "Hin in den Staub vor ", "tokens": ["Hin", "in", "den", "Staub", "vor"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "ART", "NN", "APPR"], "meter": "-+-+-", "measure": "iambic.di"}, "line.50": {"text": "Befehlet ", "tokens": ["Be\u00b7feh\u00b7let"], "token_info": ["word"], "pos": ["VVFIN"], "meter": "-+-", "measure": "amphibrach.single"}, "line.51": {"text": "Da\u00df sie durch Spott ihn nicht einmal in Mienen", "tokens": ["Da\u00df", "sie", "durch", "Spott", "ihn", "nicht", "ein\u00b7mal", "in", "Mie\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "NN", "PPER", "PTKNEG", "ADV", "APPR", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.52": {"text": "Beleidigen; denn, eh' sie sich's vers\u00e4hn,", "tokens": ["Be\u00b7lei\u00b7di\u00b7gen", ";", "denn", ",", "eh'", "sie", "sich's", "ver\u00b7s\u00e4hn", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "ADV", "$,", "KOUS", "PPER", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.53": {"text": "W\u00fcrd' er mit seinen F\u00e4usten ihnen", "tokens": ["W\u00fcrd'", "er", "mit", "sei\u00b7nen", "F\u00e4us\u00b7ten", "ih\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "APPR", "PPOSAT", "NN", "PPER"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.54": {"text": "Die Nase auf den R\u00fccken drehn.", "tokens": ["Die", "Na\u00b7se", "auf", "den", "R\u00fc\u00b7cken", "drehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.55": {"text": "Auch la\u00dft ihn alles baar bezahlen;", "tokens": ["Auch", "la\u00dft", "ihn", "al\u00b7les", "baar", "be\u00b7zah\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PIS", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.56": {"text": "Denn, ", "tokens": ["Denn", ","], "token_info": ["word", "punct"], "pos": ["KON", "$,"], "meter": "+", "measure": "single.up"}, "line.57": {"text": "Mag er selbst ", "tokens": ["Mag", "er", "selbst"], "token_info": ["word", "word", "word"], "pos": ["VMFIN", "PPER", "ADV"], "meter": "+-+", "measure": "trochaic.di"}, "line.58": {"text": "F\u00fcr keinen Deut verbunden seyn.", "tokens": ["F\u00fcr", "kei\u00b7nen", "Deut", "ver\u00b7bun\u00b7den", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.59": {"text": "Zwar drang er mir mit edler Hitze", "tokens": ["Zwar", "drang", "er", "mir", "mit", "ed\u00b7ler", "Hit\u00b7ze"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.60": {"text": "Noch heute fr\u00fch die halbe Pudelm\u00fctze", "tokens": ["Noch", "heu\u00b7te", "fr\u00fch", "die", "hal\u00b7be", "Pu\u00b7del\u00b7m\u00fct\u00b7ze"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "ADJD", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.61": {"text": "Voll Kremnitzer Dukaten auf;", "tokens": ["Voll", "Krem\u00b7nit\u00b7zer", "Du\u00b7ka\u00b7ten", "auf", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "NN", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.62": {"text": "Doch wei\u00df man wohl: Von einem Fremden", "tokens": ["Doch", "wei\u00df", "man", "wohl", ":", "Von", "ei\u00b7nem", "Frem\u00b7den"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "VVFIN", "PIS", "ADV", "$.", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.63": {"text": "Will jeder Geld! Drum schickt' ich gleich nach", "tokens": ["Will", "je\u00b7der", "Geld", "!", "Drum", "schickt'", "ich", "gleich", "nach"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "PIAT", "NN", "$.", "PAV", "VVFIN", "PPER", "ADV", "APPR"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.64": {"text": "An ", "tokens": ["An"], "token_info": ["word"], "pos": ["APPR"], "meter": "+", "measure": "single.up"}, "line.65": {"text": "Der soll sie auf der See ihm geben,", "tokens": ["Der", "soll", "sie", "auf", "der", "See", "ihm", "ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PPER", "APPR", "ART", "NN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.66": {"text": "Denn sonst erhielt' ich sie mit erster Post zur\u00fcck.", "tokens": ["Denn", "sonst", "er\u00b7hielt'", "ich", "sie", "mit", "ers\u00b7ter", "Post", "zu\u00b7r\u00fcck", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "PPER", "APPR", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.67": {"text": "Was? (sagt' er oft,) Ich sollte besser leben?", "tokens": ["Was", "?", "(", "sagt'", "er", "oft", ",", ")", "Ich", "soll\u00b7te", "bes\u00b7ser", "le\u00b7ben", "?"], "token_info": ["word", "punct", "punct", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "$.", "$(", "VVFIN", "PPER", "ADV", "$,", "$(", "PPER", "VMFIN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.68": {"text": "F\u00fcr mich geh\u00f6ret sich ein St\u00fcck", "tokens": ["F\u00fcr", "mich", "ge\u00b7h\u00f6\u00b7ret", "sich", "ein", "St\u00fcck"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPER", "VVFIN", "PRF", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.69": {"text": "Hausbackenbrod, denn auf der Gottes Erde", "tokens": ["Haus\u00b7ba\u00b7cken\u00b7brod", ",", "denn", "auf", "der", "Got\u00b7tes", "Er\u00b7de"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "KON", "APPR", "ART", "NN", "NN"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.70": {"text": "Hab' ich ja weiter nichts gelernt,", "tokens": ["Hab'", "ich", "ja", "wei\u00b7ter", "nichts", "ge\u00b7lernt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "ADV", "PIS", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.71": {"text": "Als wie man Dohnen stellt und wilde Schweine k\u00f6rnt;", "tokens": ["Als", "wie", "man", "Doh\u00b7nen", "stellt", "und", "wil\u00b7de", "Schwei\u00b7ne", "k\u00f6rnt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOKOM", "PIS", "NN", "VVFIN", "KON", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.72": {"text": "Wenn ich noch lesen lernen werde,", "tokens": ["Wenn", "ich", "noch", "le\u00b7sen", "ler\u00b7nen", "wer\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VVINF", "VVINF", "VAFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.73": {"text": "Und dann mein Herr: \u00bbI\u00df, Alter!\u00ab zu mir spricht,", "tokens": ["Und", "dann", "mein", "Herr", ":", "\u00bb", "I\u00df", ",", "Al\u00b7ter", "!", "\u00ab", "zu", "mir", "spricht", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "punct", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PPOSAT", "NN", "$.", "$(", "NN", "$,", "NN", "$.", "$(", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.74": {"text": "Dann e\u00df' ich Braten; eher nicht.", "tokens": ["Dann", "e\u00df'", "ich", "Bra\u00b7ten", ";", "e\u00b7her", "nicht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "NN", "$.", "ADV", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.75": {"text": "Wie oft hat er auf Gl\u00fcck und Geld geschm\u00e4let,", "tokens": ["Wie", "oft", "hat", "er", "auf", "Gl\u00fcck", "und", "Geld", "ge\u00b7schm\u00e4\u00b7let", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "VAFIN", "PPER", "APPR", "NN", "KON", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.76": {"text": "Blo\u00df, weil nicht ich mit Sechsen fahren kann,", "tokens": ["Blo\u00df", ",", "weil", "nicht", "ich", "mit", "Sech\u00b7sen", "fah\u00b7ren", "kann", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "PTKNEG", "PPER", "APPR", "NN", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.77": {"text": "Dem, wie er glaubt, kein Buch mehr fehlet!", "tokens": ["Dem", ",", "wie", "er", "glaubt", ",", "kein", "Buch", "mehr", "feh\u00b7let", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "$,", "PWAV", "PPER", "VVFIN", "$,", "PIAT", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.78": {"text": "Verzeiht darum dem guten alten Mann'", "tokens": ["Ver\u00b7zeiht", "da\u00b7rum", "dem", "gu\u00b7ten", "al\u00b7ten", "Mann'"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PAV", "ART", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.79": {"text": "Die Schwachheit, da\u00df er gern von mir erz\u00e4hlet.", "tokens": ["Die", "Schwach\u00b7heit", ",", "da\u00df", "er", "gern", "von", "mir", "er\u00b7z\u00e4h\u00b7let", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "KOUS", "PPER", "ADV", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.80": {"text": "Ich wei\u00df, wie sehr ihn itzt der Umstand qu\u00e4let,", "tokens": ["Ich", "wei\u00df", ",", "wie", "sehr", "ihn", "itzt", "der", "Um\u00b7stand", "qu\u00e4\u00b7let", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PWAV", "ADV", "PPER", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.81": {"text": "Da\u00df er mein Buch nicht lesen kann;", "tokens": ["Da\u00df", "er", "mein", "Buch", "nicht", "le\u00b7sen", "kann", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "PTKNEG", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.82": {"text": "Denn, ", "tokens": ["Denn", ","], "token_info": ["word", "punct"], "pos": ["KON", "$,"], "meter": "+", "measure": "single.up"}, "line.83": {"text": "Ohn' alle Gnad' es dennoch h\u00f6ren.", "tokens": ["Ohn'", "al\u00b7le", "Gnad'", "es", "den\u00b7noch", "h\u00f6\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.84": {"text": "Und fiel' ihm ein, da\u00df ", "tokens": ["Und", "fiel'", "ihm", "ein", ",", "da\u00df"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["KON", "VVFIN", "PPER", "PTKVZ", "$,", "KOUS"], "meter": "-+-+-", "measure": "iambic.di"}, "line.85": {"text": "So w\u00fcrd' er sicher mit ", "tokens": ["So", "w\u00fcrd'", "er", "si\u00b7cher", "mit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "PRF", "APPR"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.86": {"text": "Im Fall' nicht ", "tokens": ["Im", "Fall'", "nicht"], "token_info": ["word", "word", "word"], "pos": ["APPRART", "NN", "PTKNEG"], "meter": "-+-", "measure": "amphibrach.single"}, "line.87": {"text": "Gleich Anstalt macht', es zu begreifen.", "tokens": ["Gleich", "An\u00b7stalt", "macht'", ",", "es", "zu", "be\u00b7grei\u00b7fen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "VVFIN", "$,", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.88": {"text": "Doch, nimmt er dort sich besser vor den Schlingen,", "tokens": ["Doch", ",", "nimmt", "er", "dort", "sich", "bes\u00b7ser", "vor", "den", "Schlin\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "VVFIN", "PPER", "ADV", "PRF", "ADJD", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.89": {"text": "Die ihm die Hitze legt, in Acht,", "tokens": ["Die", "ihm", "die", "Hit\u00b7ze", "legt", ",", "in", "Acht", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "PPER", "ART", "NN", "VVFIN", "$,", "APPR", "CARD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.90": {"text": "So thut er das, um nur mit Freudenspr\u00fcngen", "tokens": ["So", "thut", "er", "das", ",", "um", "nur", "mit", "Freu\u00b7den\u00b7spr\u00fcn\u00b7gen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PDS", "$,", "KOUI", "ADV", "APPR", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.91": {"text": "Die Rarit\u00e4t zur\u00fcck zu bringen,", "tokens": ["Die", "Ra\u00b7ri\u00b7t\u00e4t", "zu\u00b7r\u00fcck", "zu", "brin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.92": {"text": "Die meinem Weib' ist zugedacht.", "tokens": ["Die", "mei\u00b7nem", "Weib'", "ist", "zu\u00b7ge\u00b7dacht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.93": {"text": "Als er von seiner Wanderschaft verwichen", "tokens": ["Als", "er", "von", "sei\u00b7ner", "Wan\u00b7der\u00b7schaft", "ver\u00b7wi\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "PPOSAT", "NN", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.94": {"text": "Zu Hause kam, da war ihr alter Freund,", "tokens": ["Zu", "Hau\u00b7se", "kam", ",", "da", "war", "ihr", "al\u00b7ter", "Freund", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "$,", "ADV", "VAFIN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.95": {"text": "Ihr lieber Papagey, verblichen,", "tokens": ["Ihr", "lie\u00b7ber", "Pa\u00b7pa\u00b7gey", ",", "ver\u00b7bli\u00b7chen", ","], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.96": {"text": "Und ward, so oft sie sich zu seiner Gruft geschlichen,", "tokens": ["Und", "ward", ",", "so", "oft", "sie", "sich", "zu", "sei\u00b7ner", "Gruft", "ge\u00b7schli\u00b7chen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "$,", "ADV", "ADV", "PPER", "PRF", "APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.97": {"text": "Oft leise noch beklagt und still beweint.", "tokens": ["Oft", "lei\u00b7se", "noch", "be\u00b7klagt", "und", "still", "be\u00b7weint", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ADV", "VVPP", "KON", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.98": {"text": "Gib dich zufrieden, Ferdinande,", "tokens": ["Gib", "dich", "zu\u00b7frie\u00b7den", ",", "Fer\u00b7di\u00b7nan\u00b7de", ","], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["VVIMP", "PPER", "ADJD", "$,", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.99": {"text": "(sagt' ich aus Scherz,) gib dich zufrieden, Kind!", "tokens": ["(", "sagt'", "ich", "aus", "Scherz", ",", ")", "gib", "dich", "zu\u00b7frie\u00b7den", ",", "Kind", "!"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["$(", "VVFIN", "PPER", "APPR", "NN", "$,", "$(", "VVIMP", "PPER", "ADJD", "$,", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.100": {"text": "Denn ", "tokens": ["Denn"], "token_info": ["word"], "pos": ["KON"], "meter": "+", "measure": "single.up"}, "line.101": {"text": "Wo Papageyn in Menge sind. \u2013", "tokens": ["Wo", "Pa\u00b7pa\u00b7geyn", "in", "Men\u00b7ge", "sind", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWAV", "NN", "APPR", "NN", "VAFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.102": {"text": "Allein ich unbesonn'ner Thor!", "tokens": ["Al\u00b7lein", "ich", "un\u00b7be\u00b7sonn'\u00b7ner", "Thor", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.103": {"text": "Ich h\u00e4tt' ihn besser kennen m\u00fcssen;", "tokens": ["Ich", "h\u00e4tt'", "ihn", "bes\u00b7ser", "ken\u00b7nen", "m\u00fcs\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADJD", "VVINF", "VMINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.104": {"text": "Denn kaum war dieses Wort hervor,", "tokens": ["Denn", "kaum", "war", "die\u00b7ses", "Wort", "her\u00b7vor", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "PDAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.105": {"text": "So h\u00e4tte ", "tokens": ["So", "h\u00e4t\u00b7te"], "token_info": ["word", "word"], "pos": ["ADV", "VAFIN"], "meter": "-+-", "measure": "amphibrach.single"}, "line.106": {"text": "Um einen Psittich abgerissen.", "tokens": ["Um", "ei\u00b7nen", "Psit\u00b7tich", "ab\u00b7ge\u00b7ris\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUI", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.107": {"text": "Kurz, ohne da\u00df mein Weib es wissen soll,", "tokens": ["Kurz", ",", "oh\u00b7ne", "da\u00df", "mein", "Weib", "es", "wis\u00b7sen", "soll", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "KOUI", "KOUS", "PPOSAT", "NN", "PPER", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.108": {"text": "Verbrennen ihm seitdem vor Ungeduld die Sohlen,", "tokens": ["Ver\u00b7bren\u00b7nen", "ihm", "seit\u00b7dem", "vor", "Un\u00b7ge\u00b7duld", "die", "Soh\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PAV", "APPR", "NN", "ART", "NN", "$,"], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.109": {"text": "Ihr einen ganzen K\u00e4fich voll", "tokens": ["Ihr", "ei\u00b7nen", "gan\u00b7zen", "K\u00e4\u00b7fich", "voll"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "ART", "ADJA", "NN", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.110": {"text": "Der sch\u00f6nsten Papageyn zu holen.", "tokens": ["Der", "sch\u00f6ns\u00b7ten", "Pa\u00b7pa\u00b7geyn", "zu", "ho\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.111": {"text": "Kommt er aus ", "tokens": ["Kommt", "er", "aus"], "token_info": ["word", "word", "word"], "pos": ["VVFIN", "PPER", "APPR"], "meter": "+-+", "measure": "trochaic.di"}, "line.112": {"text": "Gebiet' zur\u00fcck, (der Himmel gebe, bald!)", "tokens": ["Ge\u00b7biet'", "zu\u00b7r\u00fcck", ",", "(", "der", "Him\u00b7mel", "ge\u00b7be", ",", "bald", "!", ")"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "punct", "word", "punct", "punct"], "pos": ["NN", "PTKVZ", "$,", "$(", "ART", "NN", "VVFIN", "$,", "ADV", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.113": {"text": "So soll kein Papagey ein Wort sonst sprechen lernen,", "tokens": ["So", "soll", "kein", "Pa\u00b7pa\u00b7gey", "ein", "Wort", "sonst", "spre\u00b7chen", "ler\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PIAT", "NN", "ART", "NN", "ADV", "VVINF", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.114": {"text": "Als: ", "tokens": ["Als", ":"], "token_info": ["word", "punct"], "pos": ["KOUS", "$."], "meter": "+", "measure": "single.up"}, "line.115": {"text": "Das wird, wann einst der Sturm vom Brocken", "tokens": ["Das", "wird", ",", "wann", "einst", "der", "Sturm", "vom", "Bro\u00b7cken"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "$,", "PWAV", "ADV", "ART", "NN", "APPRART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.116": {"text": "Daherrauscht \u00fcber sein Gebein,", "tokens": ["Da\u00b7her\u00b7rauscht", "\u00fc\u00b7ber", "sein", "Ge\u00b7bein", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.117": {"text": "Die Thr\u00e4nen oft mir in die Augen locken,", "tokens": ["Die", "Thr\u00e4\u00b7nen", "oft", "mir", "in", "die", "Au\u00b7gen", "lo\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "PPER", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.118": {"text": "Und mehr als das Gel\u00e4ut der Glocken,", "tokens": ["Und", "mehr", "als", "das", "Ge\u00b7l\u00e4ut", "der", "Glo\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "KOKOM", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.119": {"text": "Erweckung zum Gebete seyn.", "tokens": ["Er\u00b7we\u00b7ckung", "zum", "Ge\u00b7be\u00b7te", "seyn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPRART", "NN", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.120": {"text": "Wie gern h\u00e4tt' ich in einem Lobgedicht'", "tokens": ["Wie", "gern", "h\u00e4tt'", "ich", "in", "ei\u00b7nem", "Lob\u00b7ge\u00b7dicht'"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADV", "VAFIN", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.121": {"text": "Den zweiten Theil ihm zugeschrieben!", "tokens": ["Den", "zwei\u00b7ten", "Theil", "ihm", "zu\u00b7ge\u00b7schrie\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.122": {"text": "Nur darf man wohl bei uns, im Angesicht'", "tokens": ["Nur", "darf", "man", "wohl", "bei", "uns", ",", "im", "An\u00b7ge\u00b7sicht'"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "VMFIN", "PIS", "ADV", "APPR", "PPER", "$,", "APPRART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.123": {"text": "Des Volkes, einen Schelm von Range lieben", "tokens": ["Des", "Vol\u00b7kes", ",", "ei\u00b7nen", "Schelm", "von", "Ran\u00b7ge", "lie\u00b7ben"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "ART", "NN", "APPR", "NN", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.124": {"text": "Und ehren, einen J\u00e4ger aber nicht.", "tokens": ["Und", "eh\u00b7ren", ",", "ei\u00b7nen", "J\u00e4\u00b7ger", "a\u00b7ber", "nicht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVINF", "$,", "ART", "NN", "ADV", "PTKNEG", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.125": {"text": "Inde\u00df, wenn l\u00e4ngst schon seinen Namen", "tokens": ["In\u00b7de\u00df", ",", "wenn", "l\u00e4ngst", "schon", "sei\u00b7nen", "Na\u00b7men"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "KOUS", "ADV", "ADV", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.126": {"text": "Kein Papagey mehr ruft, mein ", "tokens": ["Kein", "Pa\u00b7pa\u00b7gey", "mehr", "ruft", ",", "mein"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["PIAT", "NN", "ADV", "VVFIN", "$,", "PPOSAT"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.127": {"text": "Mein ", "tokens": ["Mein"], "token_info": ["word"], "pos": ["PPOSAT"], "meter": "-", "measure": "single.down"}, "line.128": {"text": "Nicht mehr, wie itzt, gesch\u00e4ftig ist,", "tokens": ["Nicht", "mehr", ",", "wie", "itzt", ",", "ge\u00b7sch\u00e4f\u00b7tig", "ist", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "$,", "PWAV", "ADV", "$,", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.129": {"text": "Und keiner mehr von Deutschlands Herrn und Damen", "tokens": ["Und", "kei\u00b7ner", "mehr", "von", "Deutschlands", "Herrn", "und", "Da\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PIS", "ADV", "APPR", "NE", "NN", "KON", "NN"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.130": {"text": "Aus Langerweil' in meinem Buche liest:", "tokens": ["Aus", "Lan\u00b7ger\u00b7weil'", "in", "mei\u00b7nem", "Bu\u00b7che", "liest", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.131": {"text": "Dann wird ihn noch das Wesen kennen,", "tokens": ["Dann", "wird", "ihn", "noch", "das", "We\u00b7sen", "ken\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.132": {"text": "(nicht wahr, ein solches glaubt ", "tokens": ["(", "nicht", "wahr", ",", "ein", "sol\u00b7ches", "glaubt"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word"], "pos": ["$(", "PTKNEG", "ADJD", "$,", "ART", "PIS", "VVFIN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.133": {"text": "Das einst aus uns heraus das Gold wird brennen;", "tokens": ["Das", "einst", "aus", "uns", "he\u00b7raus", "das", "Gold", "wird", "bren\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "APPR", "PRF", "APZR", "ART", "NN", "VAFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.134": {"text": "Und o wie wenig wird von ", "tokens": ["Und", "o", "wie", "we\u00b7nig", "wird", "von"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "FM", "KOKOM", "PIS", "VAFIN", "APPR"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.135": {"text": "Verfliegen, oder sich vom Gold' als Schlacke trennen!", "tokens": ["Ver\u00b7flie\u00b7gen", ",", "o\u00b7der", "sich", "vom", "Gold'", "als", "Schla\u00b7cke", "tren\u00b7nen", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KON", "PRF", "APPRART", "NN", "KOUS", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.136": {"text": "Und, ", "tokens": ["Und", ","], "token_info": ["word", "punct"], "pos": ["KON", "$,"], "meter": "+", "measure": "single.up"}, "line.137": {"text": "Vielleicht so hohl dann wie Hollunder. \u2013", "tokens": ["Viel\u00b7leicht", "so", "hohl", "dann", "wie", "Hol\u00b7lun\u00b7der", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "ADV", "ADJD", "ADV", "KOKOM", "NN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.138": {"text": "Allein verzeiht! Ich werde, wie es scheint,", "tokens": ["Al\u00b7lein", "ver\u00b7zeiht", "!", "Ich", "wer\u00b7de", ",", "wie", "es", "scheint", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$.", "PPER", "VAFIN", "$,", "PWAV", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.139": {"text": "Zu ernsthaft; und das ist kein Wunder,", "tokens": ["Zu", "ernst\u00b7haft", ";", "und", "das", "ist", "kein", "Wun\u00b7der", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKA", "ADJD", "$.", "KON", "PDS", "VAFIN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.140": {"text": "Denn ", "tokens": ["Denn"], "token_info": ["word"], "pos": ["KON"], "meter": "+", "measure": "single.up"}, "line.141": {"text": "Des Gl\u00fccks, g\u00e4b' ich um einen solchen Freund!", "tokens": ["Des", "Gl\u00fccks", ",", "g\u00e4b'", "ich", "um", "ei\u00b7nen", "sol\u00b7chen", "Freund", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "VVFIN", "PPER", "APPR", "ART", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.142": {"text": "Ich hoff', auch Euch wird er willkommner seyn,", "tokens": ["Ich", "hoff'", ",", "auch", "Euch", "wird", "er", "will\u00b7komm\u00b7ner", "seyn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "ADV", "PPER", "VAFIN", "PPER", "ADJD", "VAINF", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.143": {"text": "(denn itzt schon lie\u00df' er kurz und klein", "tokens": ["(", "denn", "itzt", "schon", "lie\u00df'", "er", "kurz", "und", "klein"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "KON", "ADV", "ADV", "VVFIN", "PPER", "ADJD", "KON", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.144": {"text": "F\u00fcr ", "tokens": ["F\u00fcr"], "token_info": ["word"], "pos": ["NN"], "meter": "+", "measure": "single.up"}, "line.145": {"text": "Als der Gesandte ", "tokens": ["Als", "der", "Ge\u00b7sand\u00b7te"], "token_info": ["word", "word", "word"], "pos": ["KOUS", "ART", "NN"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.146": {"text": "(so hie\u00df er sonst, der ", "tokens": ["(", "so", "hie\u00df", "er", "sonst", ",", "der"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word"], "pos": ["$(", "ADV", "VVFIN", "PPER", "ADV", "$,", "PRELS"], "meter": "-+-+-", "measure": "iambic.di"}, "line.147": {"text": "Einst ", "tokens": ["Einst"], "token_info": ["word"], "pos": ["NN"], "meter": "+", "measure": "single.up"}, "line.148": {"text": "Das, durch ein Uhrwerk, Kurzweil machte,", "tokens": ["Das", ",", "durch", "ein", "Uhr\u00b7werk", ",", "Kurz\u00b7weil", "mach\u00b7te", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PDS", "$,", "APPR", "ART", "NN", "$,", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.149": {"text": "Und f\u00fcr Siamischen Kattun,", "tokens": ["Und", "f\u00fcr", "Si\u00b7a\u00b7mi\u00b7schen", "Kat\u00b7tun", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NE", "NE", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.150": {"text": "Lyoner Goldstoff \u00fcberbrachte.", "tokens": ["Ly\u00b7o\u00b7ner", "Gold\u00b7stoff", "\u00fc\u00b7berb\u00b7rach\u00b7te", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVFIN", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.151": {"text": "So nehmt ihn denn mit seinem Thiere", "tokens": ["So", "nehmt", "ihn", "denn", "mit", "sei\u00b7nem", "Thie\u00b7re"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.152": {"text": "Und mit dem F\u00e4\u00dfchen gn\u00e4dig an,", "tokens": ["Und", "mit", "dem", "F\u00e4\u00df\u00b7chen", "gn\u00e4\u00b7dig", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.153": {"text": "Das ", "tokens": ["Das"], "token_info": ["word"], "pos": ["PDS"], "meter": "-", "measure": "single.down"}, "line.154": {"text": "Weil sie nichts bessres schicken kann.", "tokens": ["Weil", "sie", "nichts", "bess\u00b7res", "schi\u00b7cken", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIS", "ADJA", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.155": {"text": "Es ist Johannisbeerenwein,", "tokens": ["Es", "ist", "Jo\u00b7han\u00b7nis\u00b7bee\u00b7ren\u00b7wein", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.156": {"text": "Wozu sie selbst die Beeren pfl\u00fcckte,", "tokens": ["Wo\u00b7zu", "sie", "selbst", "die", "Bee\u00b7ren", "pfl\u00fcck\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.157": {"text": "Woraus denn ", "tokens": ["Wo\u00b7raus", "denn"], "token_info": ["word", "word"], "pos": ["PWAV", "ADV"], "meter": "+-+", "measure": "trochaic.di"}, "line.158": {"text": "Den Saft f\u00fcr ", "tokens": ["Den", "Saft", "f\u00fcr"], "token_info": ["word", "word", "word"], "pos": ["ART", "NN", "APPR"], "meter": "-+-", "measure": "amphibrach.single"}, "line.159": {"text": "Hat er sich satt an ", "tokens": ["Hat", "er", "sich", "satt", "an"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "PRF", "ADJD", "PTKVZ"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.160": {"text": "Und sich um seinen zweiten Freund,", "tokens": ["Und", "sich", "um", "sei\u00b7nen", "zwei\u00b7ten", "Freund", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.161": {"text": "Den Elephanten, satt geweint,", "tokens": ["Den", "E\u00b7le\u00b7phan\u00b7ten", ",", "satt", "ge\u00b7weint", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.162": {"text": "Und satt gekauft an Indianschen Kr\u00e4hen:", "tokens": ["Und", "satt", "ge\u00b7kauft", "an", "In\u00b7di\u00b7an\u00b7schen", "Kr\u00e4\u00b7hen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVPP", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.163": {"text": "Dann, bitt' ich, la\u00dft ihn wieder gehen.", "tokens": ["Dann", ",", "bitt'", "ich", ",", "la\u00dft", "ihn", "wie\u00b7der", "ge\u00b7hen", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "VVFIN", "PPER", "$,", "VVIMP", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.164": {"text": "Ein Ding sey noch so schwer und k\u00fchn:", "tokens": ["Ein", "Ding", "sey", "noch", "so", "schwer", "und", "k\u00fchn", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "ADV", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.165": {"text": "Wenn er's versprach, so h\u00e4lt er auch sein Wort;", "tokens": ["Wenn", "er's", "ver\u00b7sprach", ",", "so", "h\u00e4lt", "er", "auch", "sein", "Wort", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "VVFIN", "$,", "ADV", "VVFIN", "PPER", "ADV", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.166": {"text": "Drum lief' er sicher dennoch fort,", "tokens": ["Drum", "lie\u00b7f'", "er", "si\u00b7cher", "den\u00b7noch", "fort", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "PRF", "ADV", "PTKVZ", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.167": {"text": "Und machtet ", "tokens": ["Und", "mach\u00b7tet"], "token_info": ["word", "word"], "pos": ["KON", "VVFIN"], "meter": "-+-", "measure": "amphibrach.single"}}, "stanza.2": {"line.1": {"text": "Der alte ", "tokens": ["Der", "al\u00b7te"], "token_info": ["word", "word"], "pos": ["ART", "ADJA"], "meter": "-+-", "measure": "amphibrach.single"}, "line.2": {"text": "Ist wieder da. Halb Deutschland hat er kaum", "tokens": ["Ist", "wie\u00b7der", "da", ".", "Halb", "Deutschland", "hat", "er", "kaum"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "ADV", "$.", "NE", "NE", "VAFIN", "PPER", "ADV"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Durchzogen; denn der guten Seele brannten", "tokens": ["Durch\u00b7zo\u00b7gen", ";", "denn", "der", "gu\u00b7ten", "See\u00b7le", "brann\u00b7ten"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "$.", "KON", "ART", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Die Sohlen, um bei mir, der Nacht f\u00fcr Nacht im Traum'", "tokens": ["Die", "Soh\u00b7len", ",", "um", "bei", "mir", ",", "der", "Nacht", "f\u00fcr", "Nacht", "im", "Traum'"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "KOUI", "APPR", "PPER", "$,", "ART", "NN", "APPR", "NN", "APPRART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ihm vorgekommen war, (trotz allem Widerrathen", "tokens": ["Ihm", "vor\u00b7ge\u00b7kom\u00b7men", "war", ",", "(", "trotz", "al\u00b7lem", "Wi\u00b7der\u00b7ra\u00b7then"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word"], "pos": ["PPER", "VVPP", "VAFIN", "$,", "$(", "APPR", "PIS", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Der Frau,) nur bald genug zu seyn,", "tokens": ["Der", "Frau", ",", ")", "nur", "bald", "ge\u00b7nug", "zu", "seyn", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "$(", "ADV", "ADV", "ADV", "PTKZU", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und seinen Beutel voll Dukaten", "tokens": ["Und", "sei\u00b7nen", "Beu\u00b7tel", "voll", "Du\u00b7ka\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "ADJD", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Auf meinen Schreibtisch auszustreun.", "tokens": ["Auf", "mei\u00b7nen", "Schreib\u00b7tisch", "aus\u00b7zu\u00b7streun", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "\u00bbhier, Herr, ist alles, was der Elephant", "tokens": ["\u00bb", "hier", ",", "Herr", ",", "ist", "al\u00b7les", ",", "was", "der", "E\u00b7le\u00b7phant"], "token_info": ["punct", "word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["$(", "ADV", "$,", "NN", "$,", "VAFIN", "PIS", "$,", "PRELS", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Verdient mir hat. Vor allen Dingen", "tokens": ["Ver\u00b7di\u00b7ent", "mir", "hat", ".", "Vor", "al\u00b7len", "Din\u00b7gen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "PPER", "VAFIN", "$.", "APPR", "PIAT", "NN"], "meter": "----+-+-+-", "measure": "unknown.measure.tri"}, "line.11": {"text": "M\u00f6cht' ich nun gern, \u2013 mit Gott wird's ja gelingen! \u2013", "tokens": ["M\u00f6cht'", "ich", "nun", "gern", ",", "\u2013", "mit", "Gott", "wird's", "ja", "ge\u00b7lin\u00b7gen", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VMFIN", "PPER", "ADV", "ADV", "$,", "$(", "APPR", "NN", "VAFIN", "ADV", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Das treue Thier auch in sein Vaterland \u2013", "tokens": ["Das", "treu\u00b7e", "Thier", "auch", "in", "sein", "Va\u00b7ter\u00b7land", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "APPR", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "Wie hei\u00dft's doch gleich? \u2013 zur\u00fcck wohl bringen.\u00ab \u2013", "tokens": ["Wie", "hei\u00dft's", "doch", "gleich", "?", "\u2013", "zu\u00b7r\u00fcck", "wohl", "brin\u00b7gen", ".", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PWAV", "NE", "ADV", "ADV", "$.", "$(", "VVIMP", "ADV", "VVINF", "$.", "$(", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "Ei, Gr\u00fcnewald! wei\u00dft du auch wohl, wie weit", "tokens": ["Ei", ",", "Gr\u00fc\u00b7ne\u00b7wald", "!", "wei\u00dft", "du", "auch", "wohl", ",", "wie", "weit"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["NN", "$,", "NN", "$.", "VVFIN", "PPER", "ADV", "ADV", "$,", "PWAV", "ADJD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.15": {"text": "Das ", "tokens": ["Das"], "token_info": ["word"], "pos": ["PDS"], "meter": "-", "measure": "single.down"}, "line.16": {"text": "\u00bbthut nichts! Ich reis' in Gottes Namen,", "tokens": ["\u00bb", "thut", "nichts", "!", "Ich", "reis'", "in", "Got\u00b7tes", "Na\u00b7men", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PIS", "$.", "PPER", "VVFIN", "APPR", "NN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.17": {"text": "Und was ich brauch', ist eine Kleinigkeit;", "tokens": ["Und", "was", "ich", "brauch'", ",", "ist", "ei\u00b7ne", "Klei\u00b7nig\u00b7keit", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "VVFIN", "$,", "VAFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.18": {"text": "Der Elephant mu\u00df Heu im Schiffe fressen. \u2013", "tokens": ["Der", "E\u00b7le\u00b7phant", "mu\u00df", "Heu", "im", "Schif\u00b7fe", "fres\u00b7sen", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "VMFIN", "NN", "APPRART", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.19": {"text": "Doch, Sapperlot! Herr, h\u00e4tt' ich doch beinah", "tokens": ["Doch", ",", "Sap\u00b7per\u00b7lot", "!", "Herr", ",", "h\u00e4tt'", "ich", "doch", "bei\u00b7nah"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "$,", "NE", "$.", "NN", "$,", "VAFIN", "PPER", "ADV", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.20": {"text": "Mein Weib, das b\u00f6se Thier, vergessen:", "tokens": ["Mein", "Weib", ",", "das", "b\u00f6\u00b7se", "Thier", ",", "ver\u00b7ges\u00b7sen", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "ART", "ADJA", "NN", "$,", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.21": {"text": "F\u00fcr diese sorgen Sie doch ja.", "tokens": ["F\u00fcr", "die\u00b7se", "sor\u00b7gen", "Sie", "doch", "ja", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "PPER", "ADV", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.22": {"text": "Und \u2013 \u2013 ja \u2013 hab' ich das Thier an Ort und Stelle", "tokens": ["Und", "\u2013", "\u2013", "ja", "\u2013", "hab'", "ich", "das", "Thier", "an", "Ort", "und", "Stel\u00b7le"], "token_info": ["word", "punct", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "$(", "$(", "PTKANT", "$(", "VAFIN", "PPER", "ART", "NN", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.23": {"text": "Gebracht, so kehr' ich wieder um;", "tokens": ["Ge\u00b7bracht", ",", "so", "kehr'", "ich", "wie\u00b7der", "um", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "ADV", "VVFIN", "PPER", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.24": {"text": "Doch, lieber Herr, auf alle F\u00e4lle", "tokens": ["Doch", ",", "lie\u00b7ber", "Herr", ",", "auf", "al\u00b7le", "F\u00e4l\u00b7le"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "$,", "ADV", "NN", "$,", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.25": {"text": "Gefa\u00dft zu seyn\u00ab \u2013", "tokens": ["Ge\u00b7fa\u00dft", "zu", "seyn", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["VVPP", "PTKZU", "VAINF", "$(", "$("], "meter": "-+-+", "measure": "iambic.di"}, "line.26": {"text": "Auf einmal ward er stumm,", "tokens": ["Auf", "ein\u00b7mal", "ward", "er", "stumm", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "VAFIN", "PPER", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.27": {"text": "Und sah mich weinend an, als sollt' ich ihn errathen.", "tokens": ["Und", "sah", "mich", "wei\u00b7nend", "an", ",", "als", "sollt'", "ich", "ihn", "er\u00b7ra\u00b7then", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADJD", "PTKVZ", "$,", "KOUS", "VMFIN", "PPER", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Nein! sagt' ich, lieber ", "tokens": ["Nein", "!", "sagt'", "ich", ",", "lie\u00b7ber"], "token_info": ["word", "punct", "word", "word", "punct", "word"], "pos": ["PTKANT", "$.", "VVFIN", "PPER", "$,", "ADV"], "meter": "-+-+-", "measure": "iambic.di"}, "line.29": {"text": "Nimm deinen Beutel voll Dukaten,", "tokens": ["Nimm", "dei\u00b7nen", "Beu\u00b7tel", "voll", "Du\u00b7ka\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPOSAT", "NN", "ADJD", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.30": {"text": "Und kaufe Land; auf unsern fetten Saaten", "tokens": ["Und", "kau\u00b7fe", "Land", ";", "auf", "un\u00b7sern", "fet\u00b7ten", "Saa\u00b7ten"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "NN", "$.", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.31": {"text": "Vergi\u00dft der Elephant sein ", "tokens": ["Ver\u00b7gi\u00dft", "der", "E\u00b7le\u00b7phant", "sein"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "ART", "NN", "PPOSAT"], "meter": "-+-+---", "measure": "unknown.measure.di"}, "line.32": {"text": "Allein das hie\u00df nur tauben Ohren", "tokens": ["Al\u00b7lein", "das", "hie\u00df", "nur", "tau\u00b7ben", "Oh\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "PDS", "VVFIN", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.33": {"text": "Gepredigt. Er meint', an ihm sey ja", "tokens": ["Ge\u00b7pre\u00b7digt", ".", "Er", "meint'", ",", "an", "ihm", "sey", "ja"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVPP", "$.", "PPER", "VVFIN", "$,", "APPR", "PPER", "VAFIN", "ADV"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.34": {"text": "Sehr wenig oder nichts verloren;", "tokens": ["Sehr", "we\u00b7nig", "o\u00b7der", "nichts", "ver\u00b7lo\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "KON", "PIS", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.35": {"text": "Und dennoch kommt in ihm ein Mensch nach Asia,", "tokens": ["Und", "den\u00b7noch", "kommt", "in", "ihm", "ein", "Mensch", "nach", "A\u00b7sia", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "APPR", "PPER", "ART", "NN", "APPR", "NE", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.36": {"text": "Wie ", "tokens": ["Wie"], "token_info": ["word"], "pos": ["PWAV"], "meter": "+", "measure": "single.up"}, "line.37": {"text": "Das Haupt in ", "tokens": ["Das", "Haupt", "in"], "token_info": ["word", "word", "word"], "pos": ["ART", "NN", "APPR"], "meter": "-+-", "measure": "amphibrach.single"}, "line.38": {"text": "Da er durchaus sich nicht will halten lassen,", "tokens": ["Da", "er", "durc\u00b7haus", "sich", "nicht", "will", "hal\u00b7ten", "las\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PRF", "PTKNEG", "VMFIN", "VVINF", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.39": {"text": "So mag das Gl\u00fcck mit ihm und diesem Briefe gehn.", "tokens": ["So", "mag", "das", "Gl\u00fcck", "mit", "ihm", "und", "die\u00b7sem", "Brie\u00b7fe", "gehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "NN", "APPR", "PPER", "KON", "PDAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.40": {"text": "Die Sprache wird er schwerlich fassen,", "tokens": ["Die", "Spra\u00b7che", "wird", "er", "schwer\u00b7lich", "fas\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.41": {"text": "Lernt aber ein Dollmetscher ihn verstehn,", "tokens": ["Lernt", "a\u00b7ber", "ein", "Doll\u00b7met\u00b7scher", "ihn", "ver\u00b7stehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "PPER", "VVINF", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.42": {"text": "(denn sein Accent ist rauh, wie unsre Luft vom Brocken,)", "tokens": ["(", "denn", "sein", "Ac\u00b7cent", "ist", "rauh", ",", "wie", "uns\u00b7re", "Luft", "vom", "Bro\u00b7cken", ",", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "KON", "PPOSAT", "NN", "VAFIN", "ADJD", "$,", "PWAV", "PPOSAT", "NN", "APPRART", "NN", "$,", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.43": {"text": "So wird der Ton, der oft mit Thr\u00e4nen stahl,", "tokens": ["So", "wird", "der", "Ton", ",", "der", "oft", "mit", "Thr\u00e4\u00b7nen", "stahl", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "$,", "PRELS", "ADV", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.44": {"text": "So s\u00fc\u00df ", "tokens": ["So", "s\u00fc\u00df"], "token_info": ["word", "word"], "pos": ["ADV", "ADJD"], "meter": "-+", "measure": "iambic.single"}, "line.45": {"text": "Am Thurm' von ", "tokens": ["Am", "Thurm'", "von"], "token_info": ["word", "word", "word"], "pos": ["APPRART", "NN", "APPR"], "meter": "-+-", "measure": "amphibrach.single"}, "line.46": {"text": "Nur m\u00fc\u00dft ", "tokens": ["Nur", "m\u00fc\u00dft"], "token_info": ["word", "word"], "pos": ["ADV", "VMFIN"], "meter": "+-", "measure": "trochaic.single"}, "line.47": {"text": "Wenn er, und lie\u00dfet ", "tokens": ["Wenn", "er", ",", "und", "lie\u00b7\u00dfet"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["KOUS", "PPER", "$,", "KON", "VVFIN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.48": {"text": "Vorwerfen, nie sich wird bequemen,", "tokens": ["Vor\u00b7wer\u00b7fen", ",", "nie", "sich", "wird", "be\u00b7que\u00b7men", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADV", "PRF", "VAFIN", "ADJA", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.49": {"text": "Hin in den Staub vor ", "tokens": ["Hin", "in", "den", "Staub", "vor"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "ART", "NN", "APPR"], "meter": "-+-+-", "measure": "iambic.di"}, "line.50": {"text": "Befehlet ", "tokens": ["Be\u00b7feh\u00b7let"], "token_info": ["word"], "pos": ["VVFIN"], "meter": "-+-", "measure": "amphibrach.single"}, "line.51": {"text": "Da\u00df sie durch Spott ihn nicht einmal in Mienen", "tokens": ["Da\u00df", "sie", "durch", "Spott", "ihn", "nicht", "ein\u00b7mal", "in", "Mie\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "NN", "PPER", "PTKNEG", "ADV", "APPR", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.52": {"text": "Beleidigen; denn, eh' sie sich's vers\u00e4hn,", "tokens": ["Be\u00b7lei\u00b7di\u00b7gen", ";", "denn", ",", "eh'", "sie", "sich's", "ver\u00b7s\u00e4hn", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "ADV", "$,", "KOUS", "PPER", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.53": {"text": "W\u00fcrd' er mit seinen F\u00e4usten ihnen", "tokens": ["W\u00fcrd'", "er", "mit", "sei\u00b7nen", "F\u00e4us\u00b7ten", "ih\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "APPR", "PPOSAT", "NN", "PPER"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.54": {"text": "Die Nase auf den R\u00fccken drehn.", "tokens": ["Die", "Na\u00b7se", "auf", "den", "R\u00fc\u00b7cken", "drehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.55": {"text": "Auch la\u00dft ihn alles baar bezahlen;", "tokens": ["Auch", "la\u00dft", "ihn", "al\u00b7les", "baar", "be\u00b7zah\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PIS", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.56": {"text": "Denn, ", "tokens": ["Denn", ","], "token_info": ["word", "punct"], "pos": ["KON", "$,"], "meter": "+", "measure": "single.up"}, "line.57": {"text": "Mag er selbst ", "tokens": ["Mag", "er", "selbst"], "token_info": ["word", "word", "word"], "pos": ["VMFIN", "PPER", "ADV"], "meter": "+-+", "measure": "trochaic.di"}, "line.58": {"text": "F\u00fcr keinen Deut verbunden seyn.", "tokens": ["F\u00fcr", "kei\u00b7nen", "Deut", "ver\u00b7bun\u00b7den", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.59": {"text": "Zwar drang er mir mit edler Hitze", "tokens": ["Zwar", "drang", "er", "mir", "mit", "ed\u00b7ler", "Hit\u00b7ze"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.60": {"text": "Noch heute fr\u00fch die halbe Pudelm\u00fctze", "tokens": ["Noch", "heu\u00b7te", "fr\u00fch", "die", "hal\u00b7be", "Pu\u00b7del\u00b7m\u00fct\u00b7ze"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "ADJD", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.61": {"text": "Voll Kremnitzer Dukaten auf;", "tokens": ["Voll", "Krem\u00b7nit\u00b7zer", "Du\u00b7ka\u00b7ten", "auf", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "NN", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.62": {"text": "Doch wei\u00df man wohl: Von einem Fremden", "tokens": ["Doch", "wei\u00df", "man", "wohl", ":", "Von", "ei\u00b7nem", "Frem\u00b7den"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "VVFIN", "PIS", "ADV", "$.", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.63": {"text": "Will jeder Geld! Drum schickt' ich gleich nach", "tokens": ["Will", "je\u00b7der", "Geld", "!", "Drum", "schickt'", "ich", "gleich", "nach"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "PIAT", "NN", "$.", "PAV", "VVFIN", "PPER", "ADV", "APPR"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.64": {"text": "An ", "tokens": ["An"], "token_info": ["word"], "pos": ["APPR"], "meter": "+", "measure": "single.up"}, "line.65": {"text": "Der soll sie auf der See ihm geben,", "tokens": ["Der", "soll", "sie", "auf", "der", "See", "ihm", "ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PPER", "APPR", "ART", "NN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.66": {"text": "Denn sonst erhielt' ich sie mit erster Post zur\u00fcck.", "tokens": ["Denn", "sonst", "er\u00b7hielt'", "ich", "sie", "mit", "ers\u00b7ter", "Post", "zu\u00b7r\u00fcck", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "PPER", "APPR", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.67": {"text": "Was? (sagt' er oft,) Ich sollte besser leben?", "tokens": ["Was", "?", "(", "sagt'", "er", "oft", ",", ")", "Ich", "soll\u00b7te", "bes\u00b7ser", "le\u00b7ben", "?"], "token_info": ["word", "punct", "punct", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "$.", "$(", "VVFIN", "PPER", "ADV", "$,", "$(", "PPER", "VMFIN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.68": {"text": "F\u00fcr mich geh\u00f6ret sich ein St\u00fcck", "tokens": ["F\u00fcr", "mich", "ge\u00b7h\u00f6\u00b7ret", "sich", "ein", "St\u00fcck"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPER", "VVFIN", "PRF", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.69": {"text": "Hausbackenbrod, denn auf der Gottes Erde", "tokens": ["Haus\u00b7ba\u00b7cken\u00b7brod", ",", "denn", "auf", "der", "Got\u00b7tes", "Er\u00b7de"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "KON", "APPR", "ART", "NN", "NN"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.70": {"text": "Hab' ich ja weiter nichts gelernt,", "tokens": ["Hab'", "ich", "ja", "wei\u00b7ter", "nichts", "ge\u00b7lernt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "ADV", "PIS", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.71": {"text": "Als wie man Dohnen stellt und wilde Schweine k\u00f6rnt;", "tokens": ["Als", "wie", "man", "Doh\u00b7nen", "stellt", "und", "wil\u00b7de", "Schwei\u00b7ne", "k\u00f6rnt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOKOM", "PIS", "NN", "VVFIN", "KON", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.72": {"text": "Wenn ich noch lesen lernen werde,", "tokens": ["Wenn", "ich", "noch", "le\u00b7sen", "ler\u00b7nen", "wer\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VVINF", "VVINF", "VAFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.73": {"text": "Und dann mein Herr: \u00bbI\u00df, Alter!\u00ab zu mir spricht,", "tokens": ["Und", "dann", "mein", "Herr", ":", "\u00bb", "I\u00df", ",", "Al\u00b7ter", "!", "\u00ab", "zu", "mir", "spricht", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "punct", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PPOSAT", "NN", "$.", "$(", "NN", "$,", "NN", "$.", "$(", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.74": {"text": "Dann e\u00df' ich Braten; eher nicht.", "tokens": ["Dann", "e\u00df'", "ich", "Bra\u00b7ten", ";", "e\u00b7her", "nicht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "NN", "$.", "ADV", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.75": {"text": "Wie oft hat er auf Gl\u00fcck und Geld geschm\u00e4let,", "tokens": ["Wie", "oft", "hat", "er", "auf", "Gl\u00fcck", "und", "Geld", "ge\u00b7schm\u00e4\u00b7let", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "VAFIN", "PPER", "APPR", "NN", "KON", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.76": {"text": "Blo\u00df, weil nicht ich mit Sechsen fahren kann,", "tokens": ["Blo\u00df", ",", "weil", "nicht", "ich", "mit", "Sech\u00b7sen", "fah\u00b7ren", "kann", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "PTKNEG", "PPER", "APPR", "NN", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.77": {"text": "Dem, wie er glaubt, kein Buch mehr fehlet!", "tokens": ["Dem", ",", "wie", "er", "glaubt", ",", "kein", "Buch", "mehr", "feh\u00b7let", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "$,", "PWAV", "PPER", "VVFIN", "$,", "PIAT", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.78": {"text": "Verzeiht darum dem guten alten Mann'", "tokens": ["Ver\u00b7zeiht", "da\u00b7rum", "dem", "gu\u00b7ten", "al\u00b7ten", "Mann'"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PAV", "ART", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.79": {"text": "Die Schwachheit, da\u00df er gern von mir erz\u00e4hlet.", "tokens": ["Die", "Schwach\u00b7heit", ",", "da\u00df", "er", "gern", "von", "mir", "er\u00b7z\u00e4h\u00b7let", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "KOUS", "PPER", "ADV", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.80": {"text": "Ich wei\u00df, wie sehr ihn itzt der Umstand qu\u00e4let,", "tokens": ["Ich", "wei\u00df", ",", "wie", "sehr", "ihn", "itzt", "der", "Um\u00b7stand", "qu\u00e4\u00b7let", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PWAV", "ADV", "PPER", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.81": {"text": "Da\u00df er mein Buch nicht lesen kann;", "tokens": ["Da\u00df", "er", "mein", "Buch", "nicht", "le\u00b7sen", "kann", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "PTKNEG", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.82": {"text": "Denn, ", "tokens": ["Denn", ","], "token_info": ["word", "punct"], "pos": ["KON", "$,"], "meter": "+", "measure": "single.up"}, "line.83": {"text": "Ohn' alle Gnad' es dennoch h\u00f6ren.", "tokens": ["Ohn'", "al\u00b7le", "Gnad'", "es", "den\u00b7noch", "h\u00f6\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.84": {"text": "Und fiel' ihm ein, da\u00df ", "tokens": ["Und", "fiel'", "ihm", "ein", ",", "da\u00df"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["KON", "VVFIN", "PPER", "PTKVZ", "$,", "KOUS"], "meter": "-+-+-", "measure": "iambic.di"}, "line.85": {"text": "So w\u00fcrd' er sicher mit ", "tokens": ["So", "w\u00fcrd'", "er", "si\u00b7cher", "mit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "PRF", "APPR"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.86": {"text": "Im Fall' nicht ", "tokens": ["Im", "Fall'", "nicht"], "token_info": ["word", "word", "word"], "pos": ["APPRART", "NN", "PTKNEG"], "meter": "-+-", "measure": "amphibrach.single"}, "line.87": {"text": "Gleich Anstalt macht', es zu begreifen.", "tokens": ["Gleich", "An\u00b7stalt", "macht'", ",", "es", "zu", "be\u00b7grei\u00b7fen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "VVFIN", "$,", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.88": {"text": "Doch, nimmt er dort sich besser vor den Schlingen,", "tokens": ["Doch", ",", "nimmt", "er", "dort", "sich", "bes\u00b7ser", "vor", "den", "Schlin\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "VVFIN", "PPER", "ADV", "PRF", "ADJD", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.89": {"text": "Die ihm die Hitze legt, in Acht,", "tokens": ["Die", "ihm", "die", "Hit\u00b7ze", "legt", ",", "in", "Acht", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "PPER", "ART", "NN", "VVFIN", "$,", "APPR", "CARD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.90": {"text": "So thut er das, um nur mit Freudenspr\u00fcngen", "tokens": ["So", "thut", "er", "das", ",", "um", "nur", "mit", "Freu\u00b7den\u00b7spr\u00fcn\u00b7gen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PDS", "$,", "KOUI", "ADV", "APPR", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.91": {"text": "Die Rarit\u00e4t zur\u00fcck zu bringen,", "tokens": ["Die", "Ra\u00b7ri\u00b7t\u00e4t", "zu\u00b7r\u00fcck", "zu", "brin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.92": {"text": "Die meinem Weib' ist zugedacht.", "tokens": ["Die", "mei\u00b7nem", "Weib'", "ist", "zu\u00b7ge\u00b7dacht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.93": {"text": "Als er von seiner Wanderschaft verwichen", "tokens": ["Als", "er", "von", "sei\u00b7ner", "Wan\u00b7der\u00b7schaft", "ver\u00b7wi\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "PPOSAT", "NN", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.94": {"text": "Zu Hause kam, da war ihr alter Freund,", "tokens": ["Zu", "Hau\u00b7se", "kam", ",", "da", "war", "ihr", "al\u00b7ter", "Freund", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "$,", "ADV", "VAFIN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.95": {"text": "Ihr lieber Papagey, verblichen,", "tokens": ["Ihr", "lie\u00b7ber", "Pa\u00b7pa\u00b7gey", ",", "ver\u00b7bli\u00b7chen", ","], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.96": {"text": "Und ward, so oft sie sich zu seiner Gruft geschlichen,", "tokens": ["Und", "ward", ",", "so", "oft", "sie", "sich", "zu", "sei\u00b7ner", "Gruft", "ge\u00b7schli\u00b7chen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "$,", "ADV", "ADV", "PPER", "PRF", "APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.97": {"text": "Oft leise noch beklagt und still beweint.", "tokens": ["Oft", "lei\u00b7se", "noch", "be\u00b7klagt", "und", "still", "be\u00b7weint", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ADV", "VVPP", "KON", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.98": {"text": "Gib dich zufrieden, Ferdinande,", "tokens": ["Gib", "dich", "zu\u00b7frie\u00b7den", ",", "Fer\u00b7di\u00b7nan\u00b7de", ","], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["VVIMP", "PPER", "ADJD", "$,", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.99": {"text": "(sagt' ich aus Scherz,) gib dich zufrieden, Kind!", "tokens": ["(", "sagt'", "ich", "aus", "Scherz", ",", ")", "gib", "dich", "zu\u00b7frie\u00b7den", ",", "Kind", "!"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["$(", "VVFIN", "PPER", "APPR", "NN", "$,", "$(", "VVIMP", "PPER", "ADJD", "$,", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.100": {"text": "Denn ", "tokens": ["Denn"], "token_info": ["word"], "pos": ["KON"], "meter": "+", "measure": "single.up"}, "line.101": {"text": "Wo Papageyn in Menge sind. \u2013", "tokens": ["Wo", "Pa\u00b7pa\u00b7geyn", "in", "Men\u00b7ge", "sind", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWAV", "NN", "APPR", "NN", "VAFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.102": {"text": "Allein ich unbesonn'ner Thor!", "tokens": ["Al\u00b7lein", "ich", "un\u00b7be\u00b7sonn'\u00b7ner", "Thor", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.103": {"text": "Ich h\u00e4tt' ihn besser kennen m\u00fcssen;", "tokens": ["Ich", "h\u00e4tt'", "ihn", "bes\u00b7ser", "ken\u00b7nen", "m\u00fcs\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADJD", "VVINF", "VMINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.104": {"text": "Denn kaum war dieses Wort hervor,", "tokens": ["Denn", "kaum", "war", "die\u00b7ses", "Wort", "her\u00b7vor", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "PDAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.105": {"text": "So h\u00e4tte ", "tokens": ["So", "h\u00e4t\u00b7te"], "token_info": ["word", "word"], "pos": ["ADV", "VAFIN"], "meter": "-+-", "measure": "amphibrach.single"}, "line.106": {"text": "Um einen Psittich abgerissen.", "tokens": ["Um", "ei\u00b7nen", "Psit\u00b7tich", "ab\u00b7ge\u00b7ris\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUI", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.107": {"text": "Kurz, ohne da\u00df mein Weib es wissen soll,", "tokens": ["Kurz", ",", "oh\u00b7ne", "da\u00df", "mein", "Weib", "es", "wis\u00b7sen", "soll", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "KOUI", "KOUS", "PPOSAT", "NN", "PPER", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.108": {"text": "Verbrennen ihm seitdem vor Ungeduld die Sohlen,", "tokens": ["Ver\u00b7bren\u00b7nen", "ihm", "seit\u00b7dem", "vor", "Un\u00b7ge\u00b7duld", "die", "Soh\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PAV", "APPR", "NN", "ART", "NN", "$,"], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.109": {"text": "Ihr einen ganzen K\u00e4fich voll", "tokens": ["Ihr", "ei\u00b7nen", "gan\u00b7zen", "K\u00e4\u00b7fich", "voll"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "ART", "ADJA", "NN", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.110": {"text": "Der sch\u00f6nsten Papageyn zu holen.", "tokens": ["Der", "sch\u00f6ns\u00b7ten", "Pa\u00b7pa\u00b7geyn", "zu", "ho\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.111": {"text": "Kommt er aus ", "tokens": ["Kommt", "er", "aus"], "token_info": ["word", "word", "word"], "pos": ["VVFIN", "PPER", "APPR"], "meter": "+-+", "measure": "trochaic.di"}, "line.112": {"text": "Gebiet' zur\u00fcck, (der Himmel gebe, bald!)", "tokens": ["Ge\u00b7biet'", "zu\u00b7r\u00fcck", ",", "(", "der", "Him\u00b7mel", "ge\u00b7be", ",", "bald", "!", ")"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "punct", "word", "punct", "punct"], "pos": ["NN", "PTKVZ", "$,", "$(", "ART", "NN", "VVFIN", "$,", "ADV", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.113": {"text": "So soll kein Papagey ein Wort sonst sprechen lernen,", "tokens": ["So", "soll", "kein", "Pa\u00b7pa\u00b7gey", "ein", "Wort", "sonst", "spre\u00b7chen", "ler\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PIAT", "NN", "ART", "NN", "ADV", "VVINF", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.114": {"text": "Als: ", "tokens": ["Als", ":"], "token_info": ["word", "punct"], "pos": ["KOUS", "$."], "meter": "+", "measure": "single.up"}, "line.115": {"text": "Das wird, wann einst der Sturm vom Brocken", "tokens": ["Das", "wird", ",", "wann", "einst", "der", "Sturm", "vom", "Bro\u00b7cken"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "$,", "PWAV", "ADV", "ART", "NN", "APPRART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.116": {"text": "Daherrauscht \u00fcber sein Gebein,", "tokens": ["Da\u00b7her\u00b7rauscht", "\u00fc\u00b7ber", "sein", "Ge\u00b7bein", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.117": {"text": "Die Thr\u00e4nen oft mir in die Augen locken,", "tokens": ["Die", "Thr\u00e4\u00b7nen", "oft", "mir", "in", "die", "Au\u00b7gen", "lo\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "PPER", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.118": {"text": "Und mehr als das Gel\u00e4ut der Glocken,", "tokens": ["Und", "mehr", "als", "das", "Ge\u00b7l\u00e4ut", "der", "Glo\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "KOKOM", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.119": {"text": "Erweckung zum Gebete seyn.", "tokens": ["Er\u00b7we\u00b7ckung", "zum", "Ge\u00b7be\u00b7te", "seyn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPRART", "NN", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.120": {"text": "Wie gern h\u00e4tt' ich in einem Lobgedicht'", "tokens": ["Wie", "gern", "h\u00e4tt'", "ich", "in", "ei\u00b7nem", "Lob\u00b7ge\u00b7dicht'"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADV", "VAFIN", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.121": {"text": "Den zweiten Theil ihm zugeschrieben!", "tokens": ["Den", "zwei\u00b7ten", "Theil", "ihm", "zu\u00b7ge\u00b7schrie\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.122": {"text": "Nur darf man wohl bei uns, im Angesicht'", "tokens": ["Nur", "darf", "man", "wohl", "bei", "uns", ",", "im", "An\u00b7ge\u00b7sicht'"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "VMFIN", "PIS", "ADV", "APPR", "PPER", "$,", "APPRART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.123": {"text": "Des Volkes, einen Schelm von Range lieben", "tokens": ["Des", "Vol\u00b7kes", ",", "ei\u00b7nen", "Schelm", "von", "Ran\u00b7ge", "lie\u00b7ben"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "ART", "NN", "APPR", "NN", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.124": {"text": "Und ehren, einen J\u00e4ger aber nicht.", "tokens": ["Und", "eh\u00b7ren", ",", "ei\u00b7nen", "J\u00e4\u00b7ger", "a\u00b7ber", "nicht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVINF", "$,", "ART", "NN", "ADV", "PTKNEG", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.125": {"text": "Inde\u00df, wenn l\u00e4ngst schon seinen Namen", "tokens": ["In\u00b7de\u00df", ",", "wenn", "l\u00e4ngst", "schon", "sei\u00b7nen", "Na\u00b7men"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "KOUS", "ADV", "ADV", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.126": {"text": "Kein Papagey mehr ruft, mein ", "tokens": ["Kein", "Pa\u00b7pa\u00b7gey", "mehr", "ruft", ",", "mein"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["PIAT", "NN", "ADV", "VVFIN", "$,", "PPOSAT"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.127": {"text": "Mein ", "tokens": ["Mein"], "token_info": ["word"], "pos": ["PPOSAT"], "meter": "-", "measure": "single.down"}, "line.128": {"text": "Nicht mehr, wie itzt, gesch\u00e4ftig ist,", "tokens": ["Nicht", "mehr", ",", "wie", "itzt", ",", "ge\u00b7sch\u00e4f\u00b7tig", "ist", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "$,", "PWAV", "ADV", "$,", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.129": {"text": "Und keiner mehr von Deutschlands Herrn und Damen", "tokens": ["Und", "kei\u00b7ner", "mehr", "von", "Deutschlands", "Herrn", "und", "Da\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PIS", "ADV", "APPR", "NE", "NN", "KON", "NN"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.130": {"text": "Aus Langerweil' in meinem Buche liest:", "tokens": ["Aus", "Lan\u00b7ger\u00b7weil'", "in", "mei\u00b7nem", "Bu\u00b7che", "liest", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.131": {"text": "Dann wird ihn noch das Wesen kennen,", "tokens": ["Dann", "wird", "ihn", "noch", "das", "We\u00b7sen", "ken\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.132": {"text": "(nicht wahr, ein solches glaubt ", "tokens": ["(", "nicht", "wahr", ",", "ein", "sol\u00b7ches", "glaubt"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word"], "pos": ["$(", "PTKNEG", "ADJD", "$,", "ART", "PIS", "VVFIN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.133": {"text": "Das einst aus uns heraus das Gold wird brennen;", "tokens": ["Das", "einst", "aus", "uns", "he\u00b7raus", "das", "Gold", "wird", "bren\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "APPR", "PRF", "APZR", "ART", "NN", "VAFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.134": {"text": "Und o wie wenig wird von ", "tokens": ["Und", "o", "wie", "we\u00b7nig", "wird", "von"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "FM", "KOKOM", "PIS", "VAFIN", "APPR"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.135": {"text": "Verfliegen, oder sich vom Gold' als Schlacke trennen!", "tokens": ["Ver\u00b7flie\u00b7gen", ",", "o\u00b7der", "sich", "vom", "Gold'", "als", "Schla\u00b7cke", "tren\u00b7nen", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KON", "PRF", "APPRART", "NN", "KOUS", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.136": {"text": "Und, ", "tokens": ["Und", ","], "token_info": ["word", "punct"], "pos": ["KON", "$,"], "meter": "+", "measure": "single.up"}, "line.137": {"text": "Vielleicht so hohl dann wie Hollunder. \u2013", "tokens": ["Viel\u00b7leicht", "so", "hohl", "dann", "wie", "Hol\u00b7lun\u00b7der", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "ADV", "ADJD", "ADV", "KOKOM", "NN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.138": {"text": "Allein verzeiht! Ich werde, wie es scheint,", "tokens": ["Al\u00b7lein", "ver\u00b7zeiht", "!", "Ich", "wer\u00b7de", ",", "wie", "es", "scheint", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$.", "PPER", "VAFIN", "$,", "PWAV", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.139": {"text": "Zu ernsthaft; und das ist kein Wunder,", "tokens": ["Zu", "ernst\u00b7haft", ";", "und", "das", "ist", "kein", "Wun\u00b7der", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKA", "ADJD", "$.", "KON", "PDS", "VAFIN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.140": {"text": "Denn ", "tokens": ["Denn"], "token_info": ["word"], "pos": ["KON"], "meter": "+", "measure": "single.up"}, "line.141": {"text": "Des Gl\u00fccks, g\u00e4b' ich um einen solchen Freund!", "tokens": ["Des", "Gl\u00fccks", ",", "g\u00e4b'", "ich", "um", "ei\u00b7nen", "sol\u00b7chen", "Freund", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "VVFIN", "PPER", "APPR", "ART", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.142": {"text": "Ich hoff', auch Euch wird er willkommner seyn,", "tokens": ["Ich", "hoff'", ",", "auch", "Euch", "wird", "er", "will\u00b7komm\u00b7ner", "seyn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "ADV", "PPER", "VAFIN", "PPER", "ADJD", "VAINF", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.143": {"text": "(denn itzt schon lie\u00df' er kurz und klein", "tokens": ["(", "denn", "itzt", "schon", "lie\u00df'", "er", "kurz", "und", "klein"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "KON", "ADV", "ADV", "VVFIN", "PPER", "ADJD", "KON", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.144": {"text": "F\u00fcr ", "tokens": ["F\u00fcr"], "token_info": ["word"], "pos": ["NN"], "meter": "+", "measure": "single.up"}, "line.145": {"text": "Als der Gesandte ", "tokens": ["Als", "der", "Ge\u00b7sand\u00b7te"], "token_info": ["word", "word", "word"], "pos": ["KOUS", "ART", "NN"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.146": {"text": "(so hie\u00df er sonst, der ", "tokens": ["(", "so", "hie\u00df", "er", "sonst", ",", "der"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word"], "pos": ["$(", "ADV", "VVFIN", "PPER", "ADV", "$,", "PRELS"], "meter": "-+-+-", "measure": "iambic.di"}, "line.147": {"text": "Einst ", "tokens": ["Einst"], "token_info": ["word"], "pos": ["NN"], "meter": "+", "measure": "single.up"}, "line.148": {"text": "Das, durch ein Uhrwerk, Kurzweil machte,", "tokens": ["Das", ",", "durch", "ein", "Uhr\u00b7werk", ",", "Kurz\u00b7weil", "mach\u00b7te", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PDS", "$,", "APPR", "ART", "NN", "$,", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.149": {"text": "Und f\u00fcr Siamischen Kattun,", "tokens": ["Und", "f\u00fcr", "Si\u00b7a\u00b7mi\u00b7schen", "Kat\u00b7tun", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NE", "NE", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.150": {"text": "Lyoner Goldstoff \u00fcberbrachte.", "tokens": ["Ly\u00b7o\u00b7ner", "Gold\u00b7stoff", "\u00fc\u00b7berb\u00b7rach\u00b7te", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVFIN", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.151": {"text": "So nehmt ihn denn mit seinem Thiere", "tokens": ["So", "nehmt", "ihn", "denn", "mit", "sei\u00b7nem", "Thie\u00b7re"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.152": {"text": "Und mit dem F\u00e4\u00dfchen gn\u00e4dig an,", "tokens": ["Und", "mit", "dem", "F\u00e4\u00df\u00b7chen", "gn\u00e4\u00b7dig", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.153": {"text": "Das ", "tokens": ["Das"], "token_info": ["word"], "pos": ["PDS"], "meter": "-", "measure": "single.down"}, "line.154": {"text": "Weil sie nichts bessres schicken kann.", "tokens": ["Weil", "sie", "nichts", "bess\u00b7res", "schi\u00b7cken", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIS", "ADJA", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.155": {"text": "Es ist Johannisbeerenwein,", "tokens": ["Es", "ist", "Jo\u00b7han\u00b7nis\u00b7bee\u00b7ren\u00b7wein", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.156": {"text": "Wozu sie selbst die Beeren pfl\u00fcckte,", "tokens": ["Wo\u00b7zu", "sie", "selbst", "die", "Bee\u00b7ren", "pfl\u00fcck\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.157": {"text": "Woraus denn ", "tokens": ["Wo\u00b7raus", "denn"], "token_info": ["word", "word"], "pos": ["PWAV", "ADV"], "meter": "+-+", "measure": "trochaic.di"}, "line.158": {"text": "Den Saft f\u00fcr ", "tokens": ["Den", "Saft", "f\u00fcr"], "token_info": ["word", "word", "word"], "pos": ["ART", "NN", "APPR"], "meter": "-+-", "measure": "amphibrach.single"}, "line.159": {"text": "Hat er sich satt an ", "tokens": ["Hat", "er", "sich", "satt", "an"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "PRF", "ADJD", "PTKVZ"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.160": {"text": "Und sich um seinen zweiten Freund,", "tokens": ["Und", "sich", "um", "sei\u00b7nen", "zwei\u00b7ten", "Freund", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.161": {"text": "Den Elephanten, satt geweint,", "tokens": ["Den", "E\u00b7le\u00b7phan\u00b7ten", ",", "satt", "ge\u00b7weint", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.162": {"text": "Und satt gekauft an Indianschen Kr\u00e4hen:", "tokens": ["Und", "satt", "ge\u00b7kauft", "an", "In\u00b7di\u00b7an\u00b7schen", "Kr\u00e4\u00b7hen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVPP", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.163": {"text": "Dann, bitt' ich, la\u00dft ihn wieder gehen.", "tokens": ["Dann", ",", "bitt'", "ich", ",", "la\u00dft", "ihn", "wie\u00b7der", "ge\u00b7hen", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "VVFIN", "PPER", "$,", "VVIMP", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.164": {"text": "Ein Ding sey noch so schwer und k\u00fchn:", "tokens": ["Ein", "Ding", "sey", "noch", "so", "schwer", "und", "k\u00fchn", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "ADV", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.165": {"text": "Wenn er's versprach, so h\u00e4lt er auch sein Wort;", "tokens": ["Wenn", "er's", "ver\u00b7sprach", ",", "so", "h\u00e4lt", "er", "auch", "sein", "Wort", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "VVFIN", "$,", "ADV", "VVFIN", "PPER", "ADV", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.166": {"text": "Drum lief' er sicher dennoch fort,", "tokens": ["Drum", "lie\u00b7f'", "er", "si\u00b7cher", "den\u00b7noch", "fort", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "PRF", "ADV", "PTKVZ", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.167": {"text": "Und machtet ", "tokens": ["Und", "mach\u00b7tet"], "token_info": ["word", "word"], "pos": ["KON", "VVFIN"], "meter": "-+-", "measure": "amphibrach.single"}}}}}