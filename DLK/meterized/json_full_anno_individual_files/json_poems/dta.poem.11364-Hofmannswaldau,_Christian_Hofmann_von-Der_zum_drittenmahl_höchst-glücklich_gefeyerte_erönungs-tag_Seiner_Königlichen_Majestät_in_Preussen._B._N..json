{"dta.poem.11364": {"metadata": {"author": {"name": "Hofmannswaldau, Christian Hofmann von", "birth": "N.A.", "death": "N.A."}, "title": "Der zum drittenmahl h\u00f6chst-gl\u00fccklich  \n gefeyerte er\u00f6nungs-tag Seiner  \n K\u00f6niglichen Majest\u00e4t  \n in Preussen.  \n B. N.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1709", "urn": "urn:nbn:de:kobv:b4-20283-5", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Ein h\u00f6her mag dein reich, o grosser K\u00f6nig! singen,", "tokens": ["Ein", "h\u00f6\u00b7her", "mag", "dein", "reich", ",", "o", "gros\u00b7ser", "K\u00f6\u00b7nig", "!", "sin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "ADJD", "VMFIN", "PPOSAT", "ADJD", "$,", "FM", "ADJA", "NN", "$.", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Den dein befehl erwehlt, und wei\u00dfheit ausersehn:", "tokens": ["Den", "dein", "be\u00b7fehl", "er\u00b7wehlt", ",", "und", "wei\u00df\u00b7heit", "au\u00b7ser\u00b7sehn", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "VVPP", "$,", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ich steige nicht so hoch, und bleibe nur bey dingen,", "tokens": ["Ich", "stei\u00b7ge", "nicht", "so", "hoch", ",", "und", "blei\u00b7be", "nur", "bey", "din\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "ADV", "ADJD", "$,", "KON", "VVFIN", "ADV", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die zwar unsterblich sind, doch einen tag geschehn.", "tokens": ["Die", "zwar", "uns\u00b7terb\u00b7lich", "sind", ",", "doch", "ei\u00b7nen", "tag", "ge\u00b7schehn", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJD", "VAFIN", "$,", "ADV", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Man sucht umsonst, dein lob auf einmahl auszutragen:", "tokens": ["Man", "sucht", "um\u00b7sonst", ",", "dein", "lob", "auf", "ein\u00b7mahl", "aus\u00b7zu\u00b7tra\u00b7gen", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ADV", "$,", "PPOSAT", "NN", "APPR", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wer einen tag besingt, hat schon genug zu sagen.", "tokens": ["Wer", "ei\u00b7nen", "tag", "be\u00b7singt", ",", "hat", "schon", "ge\u00b7nug", "zu", "sa\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "NN", "VVFIN", "$,", "VAFIN", "ADV", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Rom war mit jahren gro\u00df, Augustus mit der zeit,", "tokens": ["Rom", "war", "mit", "jah\u00b7ren", "gro\u00df", ",", "Au\u00b7gus\u00b7tus", "mit", "der", "zeit", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "APPR", "NN", "ADJD", "$,", "NE", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und beyde sind durch geitz und vieles blut gestiegen.", "tokens": ["Und", "bey\u00b7de", "sind", "durch", "geitz", "und", "vie\u00b7les", "blut", "ge\u00b7stie\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VAFIN", "APPR", "NN", "KON", "PIS", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Dich f\u00fchrt die tugend auf, und f\u00fchrt dich schon so weit,", "tokens": ["Dich", "f\u00fchrt", "die", "tu\u00b7gend", "auf", ",", "und", "f\u00fchrt", "dich", "schon", "so", "weit", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "PTKVZ", "$,", "KON", "VVFIN", "PPER", "ADV", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Da\u00df keiner dir getraut, mit ehren nachzufliegen.", "tokens": ["Da\u00df", "kei\u00b7ner", "dir", "ge\u00b7traut", ",", "mit", "eh\u00b7ren", "nach\u00b7zu\u00b7flie\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPER", "VVPP", "$,", "APPR", "VVINF", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Dort strich man jeden held mit h\u00f6hern farben an;", "tokens": ["Dort", "strich", "man", "je\u00b7den", "held", "mit", "h\u00f6\u00b7hern", "far\u00b7ben", "an", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "PIS", "VVFIN", "APPR", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Hier ist es kunst genung, wenn man dich treffen kan.", "tokens": ["Hier", "ist", "es", "kunst", "ge\u00b7nung", ",", "wenn", "man", "dich", "tref\u00b7fen", "kan", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ADV", "$,", "KOUS", "PIS", "PRF", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Wie weit ist doch der ruhm der Griechen nicht erschollen,", "tokens": ["Wie", "weit", "ist", "doch", "der", "ruhm", "der", "Grie\u00b7chen", "nicht", "er\u00b7schol\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VAFIN", "ADV", "ART", "NN", "ART", "NN", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der mit Persepolis auch seinen witz verbrannt?", "tokens": ["Der", "mit", "Per\u00b7se\u00b7po\u00b7lis", "auch", "sei\u00b7nen", "witz", "ver\u00b7brannt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "NE", "ADV", "PPOSAT", "NN", "VVPP", "$."], "meter": "--+--+-+-+-+", "measure": "anapaest.di.plus"}, "line.3": {"text": "Ach! h\u00e4tt er so, wie du, der tugend folgen sollen,", "tokens": ["Ach", "!", "h\u00e4tt", "er", "so", ",", "wie", "du", ",", "der", "tu\u00b7gend", "fol\u00b7gen", "sol\u00b7len", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$.", "VAFIN", "PPER", "ADV", "$,", "PWAV", "PPER", "$,", "ART", "NN", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So w\u00e4r uns wohl vielleicht sein nahme wohl bekannt.", "tokens": ["So", "w\u00e4r", "uns", "wohl", "viel\u00b7leicht", "sein", "nah\u00b7me", "wohl", "be\u00b7kannt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ADV", "PPOSAT", "NN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Was ihn ber\u00fchmt gemacht, war andern abgedrungen;", "tokens": ["Was", "ihn", "be\u00b7r\u00fchmt", "ge\u00b7macht", ",", "war", "an\u00b7dern", "ab\u00b7ge\u00b7drun\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADJD", "VVPP", "$,", "VAFIN", "PIS", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Die gr\u00f6sse deines reichs ist aus dir selbst entsprungen.", "tokens": ["Die", "gr\u00f6s\u00b7se", "dei\u00b7nes", "reichs", "ist", "aus", "dir", "selbst", "ent\u00b7sprun\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "ADJA", "VAFIN", "APPR", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Kein saurer b\u00fcrger-schwei\u00df hat deinen thron benetzt.", "tokens": ["Kein", "sau\u00b7rer", "b\u00fcr\u00b7ger\u00b7schwei\u00df", "hat", "dei\u00b7nen", "thron", "be\u00b7netzt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "VAFIN", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Was wir darbey gethan, war w\u00fcnschen, flehn und beten:", "tokens": ["Was", "wir", "dar\u00b7bey", "ge\u00b7than", ",", "war", "w\u00fcn\u00b7schen", ",", "flehn", "und", "be\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "PAV", "VVPP", "$,", "VAFIN", "VVINF", "$,", "VVINF", "KON", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wir hatten dich darauf im hertzen zwar gesetzt;", "tokens": ["Wir", "hat\u00b7ten", "dich", "da\u00b7rauf", "im", "hert\u00b7zen", "zwar", "ge\u00b7setzt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "PAV", "APPRART", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Doch eh\u2019 es m\u00f6glich schien, hattst du ihn schon betreten.", "tokens": ["Doch", "eh'", "es", "m\u00f6g\u00b7lich", "schien", ",", "hattst", "du", "ihn", "schon", "be\u00b7tre\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADJD", "VVFIN", "$,", "VAFIN", "PPER", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Du th\u00e4tst es ohne zwang, und doch aus eigner macht:", "tokens": ["Du", "th\u00e4tst", "es", "oh\u00b7ne", "zwang", ",", "und", "doch", "aus", "eig\u00b7ner", "macht", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "VVFIN", "$,", "KON", "ADV", "APPR", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Ein tag hat uns zur ruh, dich auf den thron gebracht.", "tokens": ["Ein", "tag", "hat", "uns", "zur", "ruh", ",", "dich", "auf", "den", "thron", "ge\u00b7bracht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "APPRART", "NN", "$,", "PRF", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "O segens-voller tag! der nun zum drittenmahle", "tokens": ["O", "se\u00b7gens\u00b7vol\u00b7ler", "tag", "!", "der", "nun", "zum", "drit\u00b7ten\u00b7mah\u00b7le"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "ADJA", "NN", "$.", "ART", "ADV", "APPRART", "ADJA"], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.2": {"text": "Kommt, und so offt er kommt, auch neue wunder zeigt.", "tokens": ["Kommt", ",", "und", "so", "offt", "er", "kommt", ",", "auch", "neu\u00b7e", "wun\u00b7der", "zeigt", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "KON", "ADV", "ADV", "PPER", "VVFIN", "$,", "ADV", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Dein k\u00f6nig, Brandenburg! blitzt mit des himmels strahle,", "tokens": ["Dein", "k\u00f6\u00b7nig", ",", "Bran\u00b7den\u00b7burg", "!", "blitzt", "mit", "des", "him\u00b7mels", "strah\u00b7le", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJD", "$,", "NE", "$.", "VVFIN", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.4": {"text": "Und hat dennoch ein hertz, das sich zur erden beugt.", "tokens": ["Und", "hat", "den\u00b7noch", "ein", "hertz", ",", "das", "sich", "zur", "er\u00b7den", "beugt", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "ART", "NN", "$,", "PRELS", "PRF", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Er schreckt, er schl\u00e4gt, er tritt Europens feinde nieder:", "tokens": ["Er", "schreckt", ",", "er", "schl\u00e4gt", ",", "er", "tritt", "Eu\u00b7ro\u00b7pens", "fein\u00b7de", "nie\u00b7der", ":"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VVFIN", "$,", "PPER", "VVFIN", "NE", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Gott giebt er heute sich, macht, ehr und crone wieder.", "tokens": ["Gott", "giebt", "er", "heu\u00b7te", "sich", ",", "macht", ",", "ehr", "und", "cro\u00b7ne", "wie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "ADV", "PRF", "$,", "VVFIN", "$,", "NN", "KON", "NN", "ADV", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Das werck ist ungemein, da\u00df er sich selbst gecr\u00f6nt;", "tokens": ["Das", "werck", "ist", "un\u00b7ge\u00b7mein", ",", "da\u00df", "er", "sich", "selbst", "ge\u00b7cr\u00f6nt", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "$,", "KOUS", "PPER", "PRF", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Doch, was er damahls that, w\u00fcnscht mancher noch zu k\u00f6nnen.", "tokens": ["Doch", ",", "was", "er", "da\u00b7mahls", "that", ",", "w\u00fcnscht", "man\u00b7cher", "noch", "zu", "k\u00f6n\u00b7nen", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "PWS", "PPER", "ADV", "VVFIN", "$,", "VVFIN", "PIS", "ADV", "PTKZU", "VMINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Das ist viel herrlicher, da\u00df er sein thun verh\u00f6hnt:", "tokens": ["Das", "ist", "viel", "herr\u00b7li\u00b7cher", ",", "da\u00df", "er", "sein", "thun", "ver\u00b7h\u00f6hnt", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PIAT", "ADJA", "$,", "KOUS", "PPER", "VAINF", "VVINF", "VVPP", "$."], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Den k\u00f6nig niederlegt: Den sieger wei\u00df zu nennen:", "tokens": ["Den", "k\u00f6\u00b7nig", "nie\u00b7der\u00b7legt", ":", "Den", "sie\u00b7ger", "wei\u00df", "zu", "nen\u00b7nen", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "VVPP", "$.", "ART", "ADJA", "VVFIN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Dort nahm er, was ihm GOtt aus milder huld verhengt;", "tokens": ["Dort", "nahm", "er", ",", "was", "ihm", "Gott", "aus", "mil\u00b7der", "huld", "ver\u00b7hengt", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "PWS", "PPER", "NN", "APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Hier ist er schon so reich, da\u00df er zur\u00fccke schenckt.", "tokens": ["Hier", "ist", "er", "schon", "so", "reich", ",", "da\u00df", "er", "zu\u00b7r\u00fc\u00b7cke", "schenckt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ADV", "ADJD", "$,", "KOUS", "PPER", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Jhr, die ihr helden nicht von r\u00e4ubern unterscheidet,", "tokens": ["Ihr", ",", "die", "ihr", "hel\u00b7den", "nicht", "von", "r\u00e4u\u00b7bern", "un\u00b7ter\u00b7schei\u00b7det", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PRELS", "PPOSAT", "NN", "PTKNEG", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Aus menschen g\u00f6tter macht, an GOtt zu tadeln findt,", "tokens": ["Aus", "men\u00b7schen", "g\u00f6t\u00b7ter", "macht", ",", "an", "Gott", "zu", "ta\u00b7deln", "findt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "$,", "APPR", "NN", "PTKZU", "VVINF", "VVFIN", "$,"], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.3": {"text": "Mit lobe des Trajan offt einen Nero kleidet,", "tokens": ["Mit", "lo\u00b7be", "des", "Tra\u00b7jan", "offt", "ei\u00b7nen", "Ne\u00b7ro", "klei\u00b7det", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "VVFIN", "ART", "NN", "ADV", "ART", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Das, was der erste war, an andern nur ersinnt,", "tokens": ["Das", ",", "was", "der", "ers\u00b7te", "war", ",", "an", "an\u00b7dern", "nur", "er\u00b7sinnt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "$,", "PRELS", "ART", "ADJA", "VAFIN", "$,", "APPR", "PIS", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und meint: Es gelte gleich, ein f\u00fcrst sey, wie er wolle;", "tokens": ["Und", "meint", ":", "Es", "gel\u00b7te", "gleich", ",", "ein", "f\u00fcrst", "sey", ",", "wie", "er", "wol\u00b7le", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "PPER", "VVFIN", "ADV", "$,", "ART", "ADV", "VAFIN", "$,", "PWAV", "PPER", "VMFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Lernt hier, was tugend sey! Lernt, wie man loben solle!", "tokens": ["Lernt", "hier", ",", "was", "tu\u00b7gend", "sey", "!", "Lernt", ",", "wie", "man", "lo\u00b7ben", "sol\u00b7le", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "$,", "PRELS", "ADJD", "VAFIN", "$.", "VVFIN", "$,", "PWAV", "PIS", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "Jhr setzt umsonst der welt verg\u00fcldte g\u00f6tzen vor.", "tokens": ["Ihr", "setzt", "um\u00b7sonst", "der", "welt", "ver\u00b7g\u00fcld\u00b7te", "g\u00f6t\u00b7zen", "vor", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wer wei\u00df, warum ihr schreibt, der wei\u00df auch, da\u00df ihr tr\u00fcget.", "tokens": ["Wer", "wei\u00df", ",", "wa\u00b7rum", "ihr", "schreibt", ",", "der", "wei\u00df", "auch", ",", "da\u00df", "ihr", "tr\u00fc\u00b7get", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "$,", "PWAV", "PPER", "VVFIN", "$,", "PRELS", "VVFIN", "ADV", "$,", "KOUS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Singt itzund, wenn ihr k\u00f6nnt, nach eures helden ohr,", "tokens": ["Singt", "it\u00b7zund", ",", "wenn", "ihr", "k\u00f6nnt", ",", "nach", "eu\u00b7res", "hel\u00b7den", "ohr", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "$,", "KOUS", "PPER", "VVFIN", "$,", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Da seine macht erbebt, sein trotz im staube lieget.", "tokens": ["Da", "sei\u00b7ne", "macht", "er\u00b7bebt", ",", "sein", "trotz", "im", "stau\u00b7be", "lie\u00b7get", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "VVFIN", "VVPP", "$,", "PPOSAT", "NN", "APPRART", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Der einen tag durch euch offt mehr, als C\u00e4sar that,", "tokens": ["Der", "ei\u00b7nen", "tag", "durch", "euch", "offt", "mehr", ",", "als", "C\u00e4\u00b7sar", "that", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "APPR", "PPER", "ADV", "ADV", "$,", "KOUS", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wei\u00df heute weder sich, noch euch, noch andern rath.", "tokens": ["Wei\u00df", "heu\u00b7te", "we\u00b7der", "sich", ",", "noch", "euch", ",", "noch", "an\u00b7dern", "rath", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "KON", "PRF", "$,", "ADV", "PPER", "$,", "ADV", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Wie gl\u00fccklich ist ein land, wo man die wahrheit schreibet;", "tokens": ["Wie", "gl\u00fcck\u00b7lich", "ist", "ein", "land", ",", "wo", "man", "die", "wahr\u00b7heit", "schrei\u00b7bet", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VAFIN", "ART", "NN", "$,", "PWAV", "PIS", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Darff dencken, was man will, und sagen, was man denckt:", "tokens": ["Darff", "den\u00b7cken", ",", "was", "man", "will", ",", "und", "sa\u00b7gen", ",", "was", "man", "denckt", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VMFIN", "VVINF", "$,", "PRELS", "PIS", "VMFIN", "$,", "KON", "VVINF", "$,", "PRELS", "PIS", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wo GOtt der h\u00f6chste rath, sein wort die staats-kunst bleibet:", "tokens": ["Wo", "Gott", "der", "h\u00f6chs\u00b7te", "rath", ",", "sein", "wort", "die", "staats\u00b7kunst", "blei\u00b7bet", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "ART", "ADJA", "NN", "$,", "PPOSAT", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der F\u00fcrst den krieges-stab nach den gesetzen lenckt,", "tokens": ["Der", "F\u00fcrst", "den", "krie\u00b7ge\u00b7sstab", "nach", "den", "ge\u00b7set\u00b7zen", "lenckt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und so, wie unser held, so offt er trifft und schl\u00e4get,", "tokens": ["Und", "so", ",", "wie", "un\u00b7ser", "held", ",", "so", "offt", "er", "trifft", "und", "schl\u00e4\u00b7get", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$,", "PWAV", "ADJD", "VVFIN", "$,", "ADV", "ADV", "PPER", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "In einer hand das schwerd und auch die rechte tr\u00e4get.", "tokens": ["In", "ei\u00b7ner", "hand", "das", "schwerd", "und", "auch", "die", "rech\u00b7te", "tr\u00e4\u00b7get", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "KON", "ADV", "ART", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.10": {"line.1": {"text": "Wir wissen, was es ist, und nehmen durch ihn mehr,", "tokens": ["Wir", "wis\u00b7sen", ",", "was", "es", "ist", ",", "und", "neh\u00b7men", "durch", "ihn", "mehr", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PWS", "PPER", "VAFIN", "$,", "KON", "VVFIN", "APPR", "PPER", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Als wir gedencken, zu. Wenn andre sich vergehen,", "tokens": ["Als", "wir", "ge\u00b7den\u00b7cken", ",", "zu", ".", "Wenn", "and\u00b7re", "sich", "ver\u00b7ge\u00b7hen", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NN", "$,", "PTKVZ", "$.", "KOUS", "PIS", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "F\u00fcr hochmuth truncken seyn, und doch sich nicht so sehr", "tokens": ["F\u00fcr", "hoch\u00b7muth", "trun\u00b7cken", "seyn", ",", "und", "doch", "sich", "nicht", "so", "sehr"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "ADJD", "VAINF", "$,", "KON", "ADV", "PRF", "PTKNEG", "ADV", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Durch wege der vernunfft, als falsche list, erh\u00f6hen;", "tokens": ["Durch", "we\u00b7ge", "der", "ver\u00b7nunfft", ",", "als", "fal\u00b7sche", "list", ",", "er\u00b7h\u00f6\u00b7hen", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "NN", "ART", "NN", "$,", "KOUS", "ADJA", "NN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "So bleibet ihm der ruhm, da\u00df Preussen sagen kan:", "tokens": ["So", "blei\u00b7bet", "ihm", "der", "ruhm", ",", "da\u00df", "Preus\u00b7sen", "sa\u00b7gen", "kan", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "$,", "KOUS", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Das hat mein Friderich und auch sein GOtt gethan.", "tokens": ["Das", "hat", "mein", "Fri\u00b7de\u00b7rich", "und", "auch", "sein", "Gott", "ge\u00b7than", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPOSAT", "NN", "KON", "ADV", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.11": {"line.1": {"text": "Die zeugen sind nicht weit. Reich, erbschafft, siege, bauen,", "tokens": ["Die", "zeu\u00b7gen", "sind", "nicht", "weit", ".", "Reich", ",", "erb\u00b7schafft", ",", "sie\u00b7ge", ",", "bau\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PDS", "VVFIN", "VAFIN", "PTKNEG", "ADJD", "$.", "NN", "$,", "VVFIN", "$,", "VVFIN", "$,", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Hof, kirchen, ritter, staat, pracht, k\u00fcnste, st\u00e4dte, land,", "tokens": ["Hof", ",", "kir\u00b7chen", ",", "rit\u00b7ter", ",", "staat", ",", "pracht", ",", "k\u00fcns\u00b7te", ",", "st\u00e4d\u00b7te", ",", "land", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NE", "$,", "VVFIN", "$,", "ADJA", "$,", "VVFIN", "$,", "VVFIN", "$,", "VVFIN", "$,", "VVFIN", "$,", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die alle sagen mehr, als wir mit augen schauen,", "tokens": ["Die", "al\u00b7le", "sa\u00b7gen", "mehr", ",", "als", "wir", "mit", "au\u00b7gen", "schau\u00b7en", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VVFIN", "ADV", "$,", "KOUS", "PPER", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und machen ihn und uns der gantzen welt bekannt.", "tokens": ["Und", "ma\u00b7chen", "ihn", "und", "uns", "der", "gant\u00b7zen", "welt", "be\u00b7kannt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "KON", "PPER", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Kaufft andre euer lob von rasenden poeten;", "tokens": ["Kaufft", "and\u00b7re", "eu\u00b7er", "lob", "von", "ra\u00b7sen\u00b7den", "po\u00b7e\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIS", "PPOSAT", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Hier treten thaten auf: Was ist die kunst vonn\u00f6then?", "tokens": ["Hier", "tre\u00b7ten", "tha\u00b7ten", "auf", ":", "Was", "ist", "die", "kunst", "von\u00b7n\u00f6\u00b7then", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVINF", "VVFIN", "PTKVZ", "$.", "PWS", "VAFIN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.12": {"line.1": {"text": "Je mehr man schreibt; je mehr hat unser held verricht:", "tokens": ["Je", "mehr", "man", "schreibt", ";", "je", "mehr", "hat", "un\u00b7ser", "held", "ver\u00b7richt", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PIS", "VVFIN", "$.", "ADV", "ADV", "VAFIN", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Eh man zu felde folgt, h\u00f6rt man ihn schon gewinnen.", "tokens": ["Eh", "man", "zu", "fel\u00b7de", "folgt", ",", "h\u00f6rt", "man", "ihn", "schon", "ge\u00b7win\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "APPR", "NN", "VVFIN", "$,", "VVFIN", "PIS", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "So hoch steigt der gesang der schwachen musen nicht:", "tokens": ["So", "hoch", "steigt", "der", "ge\u00b7sang", "der", "schwa\u00b7chen", "mu\u00b7sen", "nicht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "ART", "NN", "ART", "ADJA", "VMFIN", "PTKNEG", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wir brauchen zeit und jahr, was gutes auszusinnen.", "tokens": ["Wir", "brau\u00b7chen", "zeit", "und", "jahr", ",", "was", "gu\u00b7tes", "aus\u00b7zu\u00b7sin\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "KON", "NN", "$,", "PWS", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die tugend zeiget wohl, da\u00df sie, ich rede frey,", "tokens": ["Die", "tu\u00b7gend", "zei\u00b7get", "wohl", ",", "da\u00df", "sie", ",", "ich", "re\u00b7de", "frey", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "$,", "KOUS", "PPER", "$,", "PPER", "VVFIN", "ADJD", "$,"], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Bey andern g\u00e4stin nur, bey ihm zu hause sey.", "tokens": ["Bey", "an\u00b7dern", "g\u00e4s\u00b7tin", "nur", ",", "bey", "ihm", "zu", "hau\u00b7se", "sey", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ADV", "$,", "APPR", "PPER", "APPR", "NN", "VAFIN", "$."], "meter": "-+-+-++--+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.13": {"line.1": {"text": "Wie wird mir? Seh ich recht, so seh ich, grosser K\u00f6nig!", "tokens": ["Wie", "wird", "mir", "?", "Seh", "ich", "recht", ",", "so", "seh", "ich", ",", "gros\u00b7ser", "K\u00f6\u00b7nig", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PPER", "$.", "VVFIN", "PPER", "ADJD", "$,", "ADV", "VVFIN", "PPER", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Dich in der sterblichkeit mit sternen schon bedeckt;", "tokens": ["Dich", "in", "der", "sterb\u00b7lich\u00b7keit", "mit", "ster\u00b7nen", "schon", "be\u00b7deckt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "ART", "NN", "APPR", "VVFIN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Was du gethan, ist gro\u00df; Doch scheints f\u00fcr dich zu wenig,", "tokens": ["Was", "du", "ge\u00b7than", ",", "ist", "gro\u00df", ";", "Doch", "scheints", "f\u00fcr", "dich", "zu", "we\u00b7nig", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVPP", "$,", "VAFIN", "ADJD", "$.", "KON", "VVFIN", "APPR", "PPER", "PTKA", "PIS", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Gott hat noch deiner macht ein h\u00f6her ziel gesteckt:", "tokens": ["Gott", "hat", "noch", "dei\u00b7ner", "macht", "ein", "h\u00f6\u00b7her", "ziel", "ge\u00b7steckt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ADV", "PPOSAT", "VVFIN", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Du hast bi\u00dfher den krieg, wie f\u00fcrsten will geb\u00fchren,", "tokens": ["Du", "hast", "bi\u00df\u00b7her", "den", "krieg", ",", "wie", "f\u00fcrs\u00b7ten", "will", "ge\u00b7b\u00fch\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ART", "NN", "$,", "PWAV", "VVINF", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "F\u00fcr land und reich gef\u00fchrt; Jtzt solst du seinen f\u00fchren.", "tokens": ["F\u00fcr", "land", "und", "reich", "ge\u00b7f\u00fchrt", ";", "Jtzt", "solst", "du", "sei\u00b7nen", "f\u00fch\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "ADJD", "VVPP", "$.", "ADV", "VMFIN", "PPER", "PPOSAT", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.14": {"line.1": {"text": "Schau! wie der himmel winckt, da die bedr\u00e4ngte schaar", "tokens": ["Schau", "!", "wie", "der", "him\u00b7mel", "winckt", ",", "da", "die", "be\u00b7dr\u00e4ng\u00b7te", "schaar"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$.", "PWAV", "ART", "NN", "VVFIN", "$,", "KOUS", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Von deiner mutter-stadt in neuen \u00e4ngsten stehet:", "tokens": ["Von", "dei\u00b7ner", "mut\u00b7ter\u00b7stadt", "in", "neu\u00b7en", "\u00e4ngs\u00b7ten", "ste\u00b7het", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "APPR", "ADJA", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Da das, was einmahl schon dem tod entrissen war,", "tokens": ["Da", "das", ",", "was", "ein\u00b7mahl", "schon", "dem", "tod", "ent\u00b7ris\u00b7sen", "war", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDS", "$,", "PRELS", "ADV", "ADV", "ART", "NN", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Zwar dir zu theile wird, doch auch zu grunde gehet.", "tokens": ["Zwar", "dir", "zu", "thei\u00b7le", "wird", ",", "doch", "auch", "zu", "grun\u00b7de", "ge\u00b7het", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "PTKZU", "VVFIN", "VAFIN", "$,", "ADV", "ADV", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Held! dein verdru\u00df ist gro\u00df, der dir hierbey geschieht,", "tokens": ["Held", "!", "dein", "ver\u00b7dru\u00df", "ist", "gro\u00df", ",", "der", "dir", "hier\u00b7bey", "ge\u00b7schieht", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "PPOSAT", "NN", "VAFIN", "ADJD", "$,", "PRELS", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Doch dieses ist weit mehr, was man hier GOtt entzieht.", "tokens": ["Doch", "die\u00b7ses", "ist", "weit", "mehr", ",", "was", "man", "hier", "Gott", "ent\u00b7zieht", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VAFIN", "ADJD", "ADV", "$,", "PRELS", "PIS", "ADV", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.15": {"line.1": {"text": "Brich auf und r\u00e4che GOtt! Du bist darzu erwehlet,", "tokens": ["Brich", "auf", "und", "r\u00e4\u00b7che", "Gott", "!", "Du", "bist", "dar\u00b7zu", "er\u00b7weh\u00b7let", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "PTKVZ", "KON", "ADJA", "NN", "$.", "PPER", "VAFIN", "PAV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Da\u00df du vollenden solst, was er beschlossen hat.", "tokens": ["Da\u00df", "du", "voll\u00b7en\u00b7den", "solst", ",", "was", "er", "be\u00b7schlos\u00b7sen", "hat", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVINF", "VMFIN", "$,", "PWS", "PPER", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der irret, der den sieg nach volck und trouppen zehlet;", "tokens": ["Der", "ir\u00b7ret", ",", "der", "den", "sieg", "nach", "volck", "und", "troup\u00b7pen", "zeh\u00b7let", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "$,", "PRELS", "ART", "NN", "APPR", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wem GOtt zur seiten steht, dem fehlet nicht die that.", "tokens": ["Wem", "Gott", "zur", "sei\u00b7ten", "steht", ",", "dem", "feh\u00b7let", "nicht", "die", "that", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "APPRART", "NN", "VVFIN", "$,", "PRELS", "VVFIN", "PTKNEG", "ART", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Dein feind sey, wer er will, so hat er doch erfahren,", "tokens": ["Dein", "feind", "sey", ",", "wer", "er", "will", ",", "so", "hat", "er", "doch", "er\u00b7fah\u00b7ren", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "$,", "PWS", "PPER", "VMFIN", "$,", "ADV", "VAFIN", "PPER", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Da\u00df wir schon offt gesiegt, auch wenn wir schw\u00e4cher waren.", "tokens": ["Da\u00df", "wir", "schon", "offt", "ge\u00b7siegt", ",", "auch", "wenn", "wir", "schw\u00e4\u00b7cher", "wa\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "VVPP", "$,", "ADV", "KOUS", "PPER", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.16": {"line.1": {"text": "Jedoch du gehst bereits, und \u00f6ffnest eine bahn,", "tokens": ["Je\u00b7doch", "du", "gehst", "be\u00b7reits", ",", "und", "\u00f6ff\u00b7nest", "ei\u00b7ne", "bahn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VVFIN", "ADV", "$,", "KON", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die dich zum wunder macht, uns ungeschickt zum loben.", "tokens": ["Die", "dich", "zum", "wun\u00b7der", "macht", ",", "uns", "un\u00b7ge\u00b7schickt", "zum", "lo\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPRART", "NN", "VVFIN", "$,", "PPER", "ADJD", "APPRART", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die staats-list siehet dich als ihren meister an,", "tokens": ["Die", "staats\u00b7list", "sie\u00b7het", "dich", "als", "ih\u00b7ren", "meis\u00b7ter", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "KOUS", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der spielend niedertritt, was sie mit m\u00fch erhoben:", "tokens": ["Der", "spie\u00b7lend", "nie\u00b7der\u00b7tritt", ",", "was", "sie", "mit", "m\u00fch", "er\u00b7ho\u00b7ben", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "VVFIN", "$,", "PRELS", "PPER", "APPR", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Sie hatt\u2019 Europens reich f\u00fcr einen nur bestimmt;", "tokens": ["Sie", "hatt'", "Eu\u00b7ro\u00b7pens", "reich", "f\u00fcr", "ei\u00b7nen", "nur", "be\u00b7stimmt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NE", "ADJD", "APPR", "ART", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Du machst, da\u00df jeglicher ihm nur das seine nimmt.", "tokens": ["Du", "machst", ",", "da\u00df", "jeg\u00b7li\u00b7cher", "ihm", "nur", "das", "sei\u00b7ne", "nimmt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "PIAT", "PPER", "ADV", "ART", "PPOSAT", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.17": {"line.1": {"text": "Das seh ich, grosser Held! Ach denck einmahl zur\u00fccke,", "tokens": ["Das", "seh", "ich", ",", "gros\u00b7ser", "Held", "!", "Ach", "denck", "ein\u00b7mahl", "zu\u00b7r\u00fc\u00b7cke", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "$,", "ADJA", "NN", "$.", "ITJ", "ITJ", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Was, da man dich gecr\u00f6nt, mein reim dir prophezeyt.", "tokens": ["Was", ",", "da", "man", "dich", "ge\u00b7cr\u00f6nt", ",", "mein", "reim", "dir", "pro\u00b7phe\u00b7zeyt", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "$,", "KOUS", "PIS", "PRF", "VVPP", "$,", "PPOSAT", "NN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ich sprach, und glaube noch, es habe das gel\u00fccke", "tokens": ["Ich", "sprach", ",", "und", "glau\u00b7be", "noch", ",", "es", "ha\u00b7be", "das", "ge\u00b7l\u00fc\u00b7cke"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "KON", "VVFIN", "ADV", "$,", "PPER", "VAFIN", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Dir, oder deinem sohn, ein neues reich bereit.", "tokens": ["Dir", ",", "o\u00b7der", "dei\u00b7nem", "sohn", ",", "ein", "neu\u00b7es", "reich", "be\u00b7reit", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "KON", "PPOSAT", "NN", "$,", "ART", "ADJA", "ADJD", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Du erbst ein f\u00fcrstenthum der herrlichsten auf erden,", "tokens": ["Du", "erbst", "ein", "f\u00fcrs\u00b7ten\u00b7thum", "der", "herr\u00b7lichs\u00b7ten", "auf", "er\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ART", "ADJA", "APPR", "NN", "$,"], "meter": "-+-+-+-+--+--", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Wie leichtlich kan es nicht zum k\u00f6nigreiche werden.", "tokens": ["Wie", "leicht\u00b7lich", "kan", "es", "nicht", "zum", "k\u00f6\u00b7nig\u00b7rei\u00b7che", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VMFIN", "PPER", "PTKNEG", "APPRART", "ADJA", "VAINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.18": {"line.1": {"text": "Es werde! rufft die Marck und dein verdienst zugleich.", "tokens": ["Es", "wer\u00b7de", "!", "rufft", "die", "Marck", "und", "dein", "ver\u00b7dienst", "zu\u00b7gleich", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$.", "VVFIN", "ART", "NN", "KON", "PPOSAT", "NN", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der himmel setze dich zum beyspiel aller helden!", "tokens": ["Der", "him\u00b7mel", "set\u00b7ze", "dich", "zum", "bey\u00b7spiel", "al\u00b7ler", "hel\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "APPRART", "PIS", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die sonne Galliens steh, wie der monde, bleich,", "tokens": ["Die", "son\u00b7ne", "Gal\u00b7li\u00b7ens", "steh", ",", "wie", "der", "mon\u00b7de", ",", "bleich", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,", "PWAV", "ART", "NN", "$,", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wenn Fama deinen sieg wird den Antillen melden!", "tokens": ["Wenn", "Fa\u00b7ma", "dei\u00b7nen", "sieg", "wird", "den", "An\u00b7til\u00b7len", "mel\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "PPOSAT", "NN", "VAFIN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-++--+-+-", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "Wer aber, K\u00f6nig! denckt bey dieser zelt an mich?", "tokens": ["Wer", "a\u00b7ber", ",", "K\u00f6\u00b7nig", "!", "denckt", "bey", "die\u00b7ser", "zelt", "an", "mich", "?"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "$,", "NN", "$.", "VVFIN", "APPR", "PDAT", "VVFIN", "APPR", "PPER", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Du hast, was ich gesagt; Ich lebe k\u00fcmmerlich.", "tokens": ["Du", "hast", ",", "was", "ich", "ge\u00b7sagt", ";", "Ich", "le\u00b7be", "k\u00fcm\u00b7mer\u00b7lich", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "PWS", "PPER", "VVPP", "$.", "PPER", "VVFIN", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}