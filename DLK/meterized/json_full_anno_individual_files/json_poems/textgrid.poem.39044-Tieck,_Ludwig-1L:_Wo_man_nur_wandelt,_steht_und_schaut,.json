{"textgrid.poem.39044": {"metadata": {"author": {"name": "Tieck, Ludwig", "birth": "N.A.", "death": "N.A."}, "title": "1L: Wo man nur wandelt, steht und schaut,", "genre": "verse", "period": "N.A.", "pub_year": 1813, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wo man nur wandelt, steht und schaut,", "tokens": ["Wo", "man", "nur", "wan\u00b7delt", ",", "steht", "und", "schaut", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "ADV", "VVFIN", "$,", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sind auch die gesch\u00e4ftigen M\u00e4kler bereit,", "tokens": ["Sind", "auch", "die", "ge\u00b7sch\u00e4f\u00b7ti\u00b7gen", "M\u00e4k\u00b7ler", "be\u00b7reit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "ADJA", "NN", "ADJD", "$,"], "meter": "----+--+--+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Dem Fremden, den sie unerfahren w\u00e4hnen,", "tokens": ["Dem", "Frem\u00b7den", ",", "den", "sie", "un\u00b7er\u00b7fah\u00b7ren", "w\u00e4h\u00b7nen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Bilder und Kupfer aufzuschwatzen.", "tokens": ["Bil\u00b7der", "und", "Kup\u00b7fer", "auf\u00b7zu\u00b7schwat\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VVIZU", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}}, "stanza.2": {"line.1": {"text": "Mein Freund hatte heut in froher Laune", "tokens": ["Mein", "Freund", "hat\u00b7te", "heut", "in", "fro\u00b7her", "Lau\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VAFIN", "ADV", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Doch M\u00fche genug einen Schw\u00e4tzer abzusch\u00fctteln,", "tokens": ["Doch", "M\u00fc\u00b7he", "ge\u00b7nug", "ei\u00b7nen", "Schw\u00e4t\u00b7zer", "ab\u00b7zu\u00b7sch\u00fct\u00b7teln", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ADV", "ART", "NN", "VVIZU", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Indem wir auf der Gasse sprechen, uns gegen\u00fcber", "tokens": ["In\u00b7dem", "wir", "auf", "der", "Gas\u00b7se", "spre\u00b7chen", ",", "uns", "ge\u00b7gen\u00b7\u00fc\u00b7ber"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "ART", "NN", "VVINF", "$,", "PPER", "APPR"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Ein helles gl\u00e4nzendes Ladenschild eines Barbiers,", "tokens": ["Ein", "hel\u00b7les", "gl\u00e4n\u00b7zen\u00b7des", "La\u00b7den\u00b7schild", "ei\u00b7nes", "Bar\u00b7biers", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "ART", "NN", "$,"], "meter": "-+-+--+-++--+", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "Auf dem sch\u00f6ne Damen in bunten seidnen Gew\u00e4nden", "tokens": ["Auf", "dem", "sch\u00f6\u00b7ne", "Da\u00b7men", "in", "bun\u00b7ten", "seid\u00b7nen", "Ge\u00b7w\u00e4n\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "APPR", "ADJA", "PPOSAT", "NN"], "meter": "+-+-+--+-+--+-", "measure": "hexameter"}, "line.6": {"text": "Sich von zierlichen jungen Gesellen die Haare schneiden,", "tokens": ["Sich", "von", "zier\u00b7li\u00b7chen", "jun\u00b7gen", "Ge\u00b7sel\u00b7len", "die", "Haa\u00b7re", "schnei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "ADJA", "ADJA", "NN", "ART", "NN", "VVINF", "$,"], "meter": "--+--+--+--+-+-", "measure": "anapaest.tetra.plus"}, "line.7": {"text": "Den Kopfputz sich, den hochgeth\u00fcrmten, ordnen lassen.", "tokens": ["Den", "Kopf\u00b7putz", "sich", ",", "den", "hoch\u00b7get\u00b7h\u00fcrm\u00b7ten", ",", "ord\u00b7nen", "las\u00b7sen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "PRF", "$,", "ART", "ADJA", "$,", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Auf dem andern Schilde sitzen die Scheerensbed\u00fcrftigen,", "tokens": ["Auf", "dem", "an\u00b7dern", "Schil\u00b7de", "sit\u00b7zen", "die", "Schee\u00b7rens\u00b7be\u00b7d\u00fcrf\u00b7ti\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-+--+--+-+", "measure": "trochaic.septa.relaxed"}, "line.9": {"text": "Und seifend oder schabend vor ihnen die Geh\u00fclfen,", "tokens": ["Und", "sei\u00b7fend", "o\u00b7der", "scha\u00b7bend", "vor", "ih\u00b7nen", "die", "Ge\u00b7h\u00fcl\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "KON", "ADJD", "APPR", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.10": {"text": "Alle grell und bunt lustig anzuschaun.", "tokens": ["Al\u00b7le", "grell", "und", "bunt", "lus\u00b7tig", "an\u00b7zu\u00b7schaun", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJD", "KON", "ADJD", "ADJD", "VVIZU", "$."], "meter": "--+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.11": {"text": "Als uns der M\u00e4kler verl\u00e4\u00dft, ruft der scherzende Freund", "tokens": ["Als", "uns", "der", "M\u00e4k\u00b7ler", "ver\u00b7l\u00e4\u00dft", ",", "ruft", "der", "scher\u00b7zen\u00b7de", "Freund"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "NN", "VVFIN", "$,", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+--+--+--+", "measure": "iambic.penta.relaxed"}, "line.12": {"text": "Launigt doch mit Ernst in allen Mienen:", "tokens": ["Lau\u00b7nigt", "doch", "mit", "Ernst", "in", "al\u00b7len", "Mie\u00b7nen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "NE", "APPR", "PIAT", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.13": {"text": "Lieber ja als jene betr\u00fcgerischen kauf' ich diese Tableaus.", "tokens": ["Lie\u00b7ber", "ja", "als", "je\u00b7ne", "be\u00b7tr\u00fc\u00b7ge\u00b7ri\u00b7schen", "kauf'", "ich", "die\u00b7se", "Tab\u00b7le\u00b7aus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADV", "KOUS", "PDAT", "ADJA", "VVFIN", "PPER", "PDAT", "NN", "$."], "meter": "+-+-+--+-+-+-+-+-+", "measure": "trochaic.octa.plus.relaxed"}}, "stanza.3": {"line.1": {"text": "Das h\u00f6rt ein Junge des Per\u00fckenmachers,", "tokens": ["Das", "h\u00f6rt", "ein", "Jun\u00b7ge", "des", "Pe\u00b7r\u00fc\u00b7ken\u00b7ma\u00b7chers", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Der schon neugierig in unsrer N\u00e4he geweilt,", "tokens": ["Der", "schon", "neu\u00b7gie\u00b7rig", "in", "uns\u00b7rer", "N\u00e4\u00b7he", "ge\u00b7weilt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJD", "APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "+--+--+-+--+", "measure": "dactylic.di.plus"}, "line.3": {"text": "Er macht sich herbei, \u00e4ngstlich erst und dann vertrauter,", "tokens": ["Er", "macht", "sich", "her\u00b7bei", ",", "\u00e4ngst\u00b7lich", "erst", "und", "dann", "ver\u00b7trau\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "PTKVZ", "$,", "ADJD", "ADV", "KON", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Spricht und gr\u00fc\u00dft und lobet, und glaubt nun endlich", "tokens": ["Spricht", "und", "gr\u00fc\u00dft", "und", "lo\u00b7bet", ",", "und", "glaubt", "nun", "end\u00b7lich"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "KON", "VVFIN", "KON", "VVFIN", "$,", "KON", "VVFIN", "ADV", "ADV"], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.5": {"text": "Den Deutschen zu kennen und schon im Netz zu haben,", "tokens": ["Den", "Deut\u00b7schen", "zu", "ken\u00b7nen", "und", "schon", "im", "Netz", "zu", "ha\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKZU", "VVINF", "KON", "ADV", "APPRART", "NN", "PTKZU", "VAINF", "$,"], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.6": {"text": "Da\u00df sich am Abend der Vater seiner Klugheit bedanken mu\u00df.", "tokens": ["Da\u00df", "sich", "am", "A\u00b7bend", "der", "Va\u00b7ter", "sei\u00b7ner", "Klug\u00b7heit", "be\u00b7dan\u00b7ken", "mu\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "APPRART", "NN", "ART", "NN", "PPOSAT", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+--+-+-+--+-+", "measure": "iambic.septa.relaxed"}, "line.7": {"text": "Sammeln Ihr Gnaden? \u2013 O ja, mein junger Freund! \u2013", "tokens": ["Sam\u00b7meln", "Ihr", "Gna\u00b7den", "?", "\u2013", "O", "ja", ",", "mein", "jun\u00b7ger", "Freund", "!", "\u2013"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["NN", "PPOSAT", "NN", "$.", "$(", "ITJ", "ITJ", "$,", "PPOSAT", "ADJA", "NN", "$.", "$("], "meter": "+--+-+--+-+", "measure": "iambic.penta.invert"}, "line.8": {"text": "F\u00fcr Ihre G\u00fcter, Excellenz. \u2013 Gewi\u00df, mein Bester!", "tokens": ["F\u00fcr", "Ih\u00b7re", "G\u00fc\u00b7ter", ",", "Ex\u00b7cel\u00b7lenz", ".", "\u2013", "Ge\u00b7wi\u00df", ",", "mein", "Bes\u00b7ter", "!"], "token_info": ["word", "word", "word", "punct", "word", "punct", "punct", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "NN", "$.", "$(", "PTKANT", "$,", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Und Sie w\u00fcrden solche Darstellung nicht verschm\u00e4hn? \u2013", "tokens": ["Und", "Sie", "w\u00fcr\u00b7den", "sol\u00b7che", "Dar\u00b7stel\u00b7lung", "nicht", "ver\u00b7schm\u00e4hn", "?", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "PPER", "VAFIN", "PIAT", "NN", "PTKNEG", "VVINF", "$.", "$("], "meter": "+-+-+--+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.10": {"text": "O nein, ich liebe mir bunte muntre Farben,", "tokens": ["O", "nein", ",", "ich", "lie\u00b7be", "mir", "bun\u00b7te", "mun\u00b7tre", "Far\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PTKANT", "$,", "PPER", "VVFIN", "PPER", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.11": {"text": "Und euer Italien ist so voll der Kunst,", "tokens": ["Und", "eu\u00b7er", "I\u00b7ta\u00b7li\u00b7en", "ist", "so", "voll", "der", "Kunst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VAFIN", "ADV", "ADJD", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Wohin man sieht, lacht einem Gebild entgegen. \u2013", "tokens": ["Wo\u00b7hin", "man", "sieht", ",", "lacht", "ei\u00b7nem", "Ge\u00b7bild", "ent\u00b7ge\u00b7gen", ".", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWAV", "PIS", "VVFIN", "$,", "VVFIN", "ART", "NN", "PTKVZ", "$.", "$("], "meter": "-+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.13": {"text": "Wir sind, Gn\u00e4digster, als Kunstbegabte ber\u00fchmt,", "tokens": ["Wir", "sind", ",", "Gn\u00e4\u00b7digs\u00b7ter", ",", "als", "Kunst\u00b7be\u00b7gab\u00b7te", "be\u00b7r\u00fchmt", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "NN", "$,", "KOUS", "NN", "ADJD", "$,"], "meter": "-+-+--+-+--+", "measure": "iambic.penta.relaxed"}, "line.14": {"text": "Der Florentiner vor allen in ganz Italien. \u2013", "tokens": ["Der", "Flo\u00b7ren\u00b7ti\u00b7ner", "vor", "al\u00b7len", "in", "ganz", "I\u00b7ta\u00b7li\u00b7en.", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "abbreviation", "punct"], "pos": ["ART", "NN", "APPR", "PIS", "APPR", "ADV", "NE", "$("], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.15": {"text": "Doch seid Ihr theuer, mein Freund, mit guten Sachen. \u2013", "tokens": ["Doch", "seid", "Ihr", "theu\u00b7er", ",", "mein", "Freund", ",", "mit", "gu\u00b7ten", "Sa\u00b7chen", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VAFIN", "PPER", "ADJD", "$,", "PPOSAT", "NN", "$,", "APPR", "ADJA", "NN", "$.", "$("], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.16": {"text": "Wie's kommt, Excellenz, die sch\u00f6nen Bilder da", "tokens": ["Wie's", "kommt", ",", "Ex\u00b7cel\u00b7lenz", ",", "die", "sch\u00f6\u00b7nen", "Bil\u00b7der", "da"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "$,", "NN", "$,", "ART", "ADJA", "NN", "ADV"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.17": {"text": "Lie\u00dfe mein Vater um m\u00e4\u00dfigen Preis. \u2013", "tokens": ["Lie\u00b7\u00dfe", "mein", "Va\u00b7ter", "um", "m\u00e4\u00b7\u00dfi\u00b7gen", "Preis", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "APPR", "ADJA", "NN", "$.", "$("], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.18": {"text": "Auch ist es Schade, mein Sohn, derlei Gl\u00e4nzendes", "tokens": ["Auch", "ist", "es", "Scha\u00b7de", ",", "mein", "Sohn", ",", "der\u00b7lei", "Gl\u00e4n\u00b7zen\u00b7des"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "$,", "PPOSAT", "NN", "$,", "PIAT", "NN"], "meter": "-+-+--+--+--", "measure": "iambic.tetra.relaxed"}, "line.19": {"text": "Der Sonne und Luft so th\u00f6richt auszusetzen. \u2013", "tokens": ["Der", "Son\u00b7ne", "und", "Luft", "so", "th\u00f6\u00b7richt", "aus\u00b7zu\u00b7set\u00b7zen", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "KON", "NN", "ADV", "ADJD", "VVIZU", "$.", "$("], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.20": {"text": "Bei dem Gn\u00e4digsten w\u00fcrden sie ewig dauern,", "tokens": ["Bei", "dem", "Gn\u00e4\u00b7digs\u00b7ten", "w\u00fcr\u00b7den", "sie", "e\u00b7wig", "dau\u00b7ern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VAFIN", "PPER", "ADJD", "VVINF", "$,"], "meter": "+--+-+--+-+-", "measure": "iambic.penta.invert"}, "line.21": {"text": "Man firni\u00dft sie neu, so ist noch nichts daran verlohren. \u2013", "tokens": ["Man", "fir\u00b7ni\u00dft", "sie", "neu", ",", "so", "ist", "noch", "nichts", "da\u00b7ran", "ver\u00b7loh\u00b7ren", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PIS", "VVFIN", "PPER", "ADJD", "$,", "ADV", "VAFIN", "ADV", "PIS", "PAV", "VVPP", "$.", "$("], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.22": {"text": "Aber der Preis? \u2013 Wir w\u00fcrden schon einig werden. \u2013", "tokens": ["A\u00b7ber", "der", "Preis", "?", "\u2013", "Wir", "w\u00fcr\u00b7den", "schon", "ei\u00b7nig", "wer\u00b7den", ".", "\u2013"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ART", "NN", "$.", "$(", "PPER", "VAFIN", "ADV", "ADJD", "VAINF", "$.", "$("], "meter": "+--+-+--+-+-", "measure": "iambic.penta.invert"}, "line.23": {"text": "Trennt sich der Vater nicht ungern von ihnen? \u2013", "tokens": ["Trennt", "sich", "der", "Va\u00b7ter", "nicht", "un\u00b7gern", "von", "ih\u00b7nen", "?", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PRF", "ART", "NN", "PTKNEG", "ADV", "APPR", "PPER", "$.", "$("], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.24": {"text": "Er wird sie vermissen. \u2013 Allein, wenn ich sie erstehe,", "tokens": ["Er", "wird", "sie", "ver\u00b7mis\u00b7sen", ".", "\u2013", "Al\u00b7lein", ",", "wenn", "ich", "sie", "er\u00b7ste\u00b7he", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "VVPP", "$.", "$(", "ADV", "$,", "KOUS", "PPER", "PPER", "VVFIN", "$,"], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.25": {"text": "So m\u00fc\u00dft ihr mir auch den Gegenstand erkl\u00e4ren:", "tokens": ["So", "m\u00fc\u00dft", "ihr", "mir", "auch", "den", "Ge\u00b7gen\u00b7stand", "er\u00b7kl\u00e4\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PPER", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.26": {"text": "Sagt, find die Figuren aus der Mythologie entlehnt,", "tokens": ["Sagt", ",", "find", "die", "Fi\u00b7gu\u00b7ren", "aus", "der", "My\u00b7tho\u00b7lo\u00b7gie", "ent\u00b7lehnt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+--+--+-+-+-+", "measure": "amphibrach.tri.plus"}, "line.27": {"text": "So nennt mir die G\u00f6tter, die sie repr\u00e4sentiren:", "tokens": ["So", "nennt", "mir", "die", "G\u00f6t\u00b7ter", ",", "die", "sie", "re\u00b7pr\u00e4\u00b7sen\u00b7ti\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "$,", "PRELS", "PPER", "VVINF", "$."], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.28": {"text": "Oder ist die Sache christlich, so sind es wohl M\u00e4rtirer,", "tokens": ["O\u00b7der", "ist", "die", "Sa\u00b7che", "christ\u00b7lich", ",", "so", "sind", "es", "wohl", "M\u00e4r\u00b7ti\u00b7rer", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ART", "NN", "ADJD", "$,", "ADV", "VAFIN", "PPER", "ADV", "NN", "$,"], "meter": "+-+-+-+--+--+--", "measure": "trochaic.hexa.relaxed"}, "line.29": {"text": "Die dort gequ\u00e4lt so ergeben f\u00fcr den Glauben dulden.", "tokens": ["Die", "dort", "ge\u00b7qu\u00e4lt", "so", "er\u00b7ge\u00b7ben", "f\u00fcr", "den", "Glau\u00b7ben", "dul\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "VVPP", "ADV", "VVPP", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+--+-+-+-+-", "measure": "iambic.hexa.relaxed"}}, "stanza.4": {"line.1": {"text": "Da sah der Bursche den Freund mit gro\u00dfen Augen an,", "tokens": ["Da", "sah", "der", "Bur\u00b7sche", "den", "Freund", "mit", "gro\u00b7\u00dfen", "Au\u00b7gen", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ART", "NN", "APPR", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Merkte, da\u00df diesmal der Itali\u00e4ner der Geh\u00e4nselte sei,", "tokens": ["Merk\u00b7te", ",", "da\u00df", "dies\u00b7mal", "der", "I\u00b7ta\u00b7li\u00b7\u00e4\u00b7ner", "der", "Ge\u00b7h\u00e4n\u00b7sel\u00b7te", "sei", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "KOUS", "ADV", "ART", "NN", "ART", "NN", "VAFIN", "$,"], "meter": "+-+-+--+-+-+-+--+", "measure": "trochaic.octa.plus.relaxed"}, "line.3": {"text": "Wollte erst empfindlich thun, doch lachte er dann,", "tokens": ["Woll\u00b7te", "erst", "emp\u00b7find\u00b7lich", "thun", ",", "doch", "lach\u00b7te", "er", "dann", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "ADJD", "VVINF", "$,", "ADV", "VVFIN", "PPER", "ADV", "$,"], "meter": "+-+-+-+-+--+", "measure": "iambic.hexa.chol"}, "line.4": {"text": "Und mit den Worten: Excellenz sind ein Schelmchen!", "tokens": ["Und", "mit", "den", "Wor\u00b7ten", ":", "Ex\u00b7cel\u00b7lenz", "sind", "ein", "Schelm\u00b7chen", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "$.", "NN", "VAFIN", "ART", "NN", "$."], "meter": "---+---+--+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Lief er mit einem Sprunge \u00fcber die Gasse in's Haus.", "tokens": ["Lief", "er", "mit", "ei\u00b7nem", "Sprun\u00b7ge", "\u00fc\u00b7ber", "die", "Gas\u00b7se", "in's", "Haus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ART", "NN", "APPR", "ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+--+--+", "measure": "iambic.hexa.relaxed"}}, "stanza.5": {"line.1": {"text": "Wo man nur wandelt, steht und schaut,", "tokens": ["Wo", "man", "nur", "wan\u00b7delt", ",", "steht", "und", "schaut", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "ADV", "VVFIN", "$,", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sind auch die gesch\u00e4ftigen M\u00e4kler bereit,", "tokens": ["Sind", "auch", "die", "ge\u00b7sch\u00e4f\u00b7ti\u00b7gen", "M\u00e4k\u00b7ler", "be\u00b7reit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "ADJA", "NN", "ADJD", "$,"], "meter": "----+--+--+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Dem Fremden, den sie unerfahren w\u00e4hnen,", "tokens": ["Dem", "Frem\u00b7den", ",", "den", "sie", "un\u00b7er\u00b7fah\u00b7ren", "w\u00e4h\u00b7nen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Bilder und Kupfer aufzuschwatzen.", "tokens": ["Bil\u00b7der", "und", "Kup\u00b7fer", "auf\u00b7zu\u00b7schwat\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VVIZU", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}}, "stanza.6": {"line.1": {"text": "Mein Freund hatte heut in froher Laune", "tokens": ["Mein", "Freund", "hat\u00b7te", "heut", "in", "fro\u00b7her", "Lau\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VAFIN", "ADV", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Doch M\u00fche genug einen Schw\u00e4tzer abzusch\u00fctteln,", "tokens": ["Doch", "M\u00fc\u00b7he", "ge\u00b7nug", "ei\u00b7nen", "Schw\u00e4t\u00b7zer", "ab\u00b7zu\u00b7sch\u00fct\u00b7teln", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ADV", "ART", "NN", "VVIZU", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Indem wir auf der Gasse sprechen, uns gegen\u00fcber", "tokens": ["In\u00b7dem", "wir", "auf", "der", "Gas\u00b7se", "spre\u00b7chen", ",", "uns", "ge\u00b7gen\u00b7\u00fc\u00b7ber"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "ART", "NN", "VVINF", "$,", "PPER", "APPR"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Ein helles gl\u00e4nzendes Ladenschild eines Barbiers,", "tokens": ["Ein", "hel\u00b7les", "gl\u00e4n\u00b7zen\u00b7des", "La\u00b7den\u00b7schild", "ei\u00b7nes", "Bar\u00b7biers", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "ART", "NN", "$,"], "meter": "-+-+--+-++--+", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "Auf dem sch\u00f6ne Damen in bunten seidnen Gew\u00e4nden", "tokens": ["Auf", "dem", "sch\u00f6\u00b7ne", "Da\u00b7men", "in", "bun\u00b7ten", "seid\u00b7nen", "Ge\u00b7w\u00e4n\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "APPR", "ADJA", "PPOSAT", "NN"], "meter": "+-+-+--+-+--+-", "measure": "hexameter"}, "line.6": {"text": "Sich von zierlichen jungen Gesellen die Haare schneiden,", "tokens": ["Sich", "von", "zier\u00b7li\u00b7chen", "jun\u00b7gen", "Ge\u00b7sel\u00b7len", "die", "Haa\u00b7re", "schnei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "ADJA", "ADJA", "NN", "ART", "NN", "VVINF", "$,"], "meter": "--+--+--+--+-+-", "measure": "anapaest.tetra.plus"}, "line.7": {"text": "Den Kopfputz sich, den hochgeth\u00fcrmten, ordnen lassen.", "tokens": ["Den", "Kopf\u00b7putz", "sich", ",", "den", "hoch\u00b7get\u00b7h\u00fcrm\u00b7ten", ",", "ord\u00b7nen", "las\u00b7sen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "PRF", "$,", "ART", "ADJA", "$,", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Auf dem andern Schilde sitzen die Scheerensbed\u00fcrftigen,", "tokens": ["Auf", "dem", "an\u00b7dern", "Schil\u00b7de", "sit\u00b7zen", "die", "Schee\u00b7rens\u00b7be\u00b7d\u00fcrf\u00b7ti\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-+--+--+-+", "measure": "trochaic.septa.relaxed"}, "line.9": {"text": "Und seifend oder schabend vor ihnen die Geh\u00fclfen,", "tokens": ["Und", "sei\u00b7fend", "o\u00b7der", "scha\u00b7bend", "vor", "ih\u00b7nen", "die", "Ge\u00b7h\u00fcl\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "KON", "ADJD", "APPR", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.10": {"text": "Alle grell und bunt lustig anzuschaun.", "tokens": ["Al\u00b7le", "grell", "und", "bunt", "lus\u00b7tig", "an\u00b7zu\u00b7schaun", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJD", "KON", "ADJD", "ADJD", "VVIZU", "$."], "meter": "--+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.11": {"text": "Als uns der M\u00e4kler verl\u00e4\u00dft, ruft der scherzende Freund", "tokens": ["Als", "uns", "der", "M\u00e4k\u00b7ler", "ver\u00b7l\u00e4\u00dft", ",", "ruft", "der", "scher\u00b7zen\u00b7de", "Freund"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "NN", "VVFIN", "$,", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+--+--+--+", "measure": "iambic.penta.relaxed"}, "line.12": {"text": "Launigt doch mit Ernst in allen Mienen:", "tokens": ["Lau\u00b7nigt", "doch", "mit", "Ernst", "in", "al\u00b7len", "Mie\u00b7nen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "NE", "APPR", "PIAT", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.13": {"text": "Lieber ja als jene betr\u00fcgerischen kauf' ich diese Tableaus.", "tokens": ["Lie\u00b7ber", "ja", "als", "je\u00b7ne", "be\u00b7tr\u00fc\u00b7ge\u00b7ri\u00b7schen", "kauf'", "ich", "die\u00b7se", "Tab\u00b7le\u00b7aus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADV", "KOUS", "PDAT", "ADJA", "VVFIN", "PPER", "PDAT", "NN", "$."], "meter": "+-+-+--+-+-+-+-+-+", "measure": "trochaic.octa.plus.relaxed"}}, "stanza.7": {"line.1": {"text": "Das h\u00f6rt ein Junge des Per\u00fckenmachers,", "tokens": ["Das", "h\u00f6rt", "ein", "Jun\u00b7ge", "des", "Pe\u00b7r\u00fc\u00b7ken\u00b7ma\u00b7chers", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Der schon neugierig in unsrer N\u00e4he geweilt,", "tokens": ["Der", "schon", "neu\u00b7gie\u00b7rig", "in", "uns\u00b7rer", "N\u00e4\u00b7he", "ge\u00b7weilt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJD", "APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "+--+--+-+--+", "measure": "dactylic.di.plus"}, "line.3": {"text": "Er macht sich herbei, \u00e4ngstlich erst und dann vertrauter,", "tokens": ["Er", "macht", "sich", "her\u00b7bei", ",", "\u00e4ngst\u00b7lich", "erst", "und", "dann", "ver\u00b7trau\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "PTKVZ", "$,", "ADJD", "ADV", "KON", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Spricht und gr\u00fc\u00dft und lobet, und glaubt nun endlich", "tokens": ["Spricht", "und", "gr\u00fc\u00dft", "und", "lo\u00b7bet", ",", "und", "glaubt", "nun", "end\u00b7lich"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "KON", "VVFIN", "KON", "VVFIN", "$,", "KON", "VVFIN", "ADV", "ADV"], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.5": {"text": "Den Deutschen zu kennen und schon im Netz zu haben,", "tokens": ["Den", "Deut\u00b7schen", "zu", "ken\u00b7nen", "und", "schon", "im", "Netz", "zu", "ha\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKZU", "VVINF", "KON", "ADV", "APPRART", "NN", "PTKZU", "VAINF", "$,"], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.6": {"text": "Da\u00df sich am Abend der Vater seiner Klugheit bedanken mu\u00df.", "tokens": ["Da\u00df", "sich", "am", "A\u00b7bend", "der", "Va\u00b7ter", "sei\u00b7ner", "Klug\u00b7heit", "be\u00b7dan\u00b7ken", "mu\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "APPRART", "NN", "ART", "NN", "PPOSAT", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+--+-+-+--+-+", "measure": "iambic.septa.relaxed"}, "line.7": {"text": "Sammeln Ihr Gnaden? \u2013 O ja, mein junger Freund! \u2013", "tokens": ["Sam\u00b7meln", "Ihr", "Gna\u00b7den", "?", "\u2013", "O", "ja", ",", "mein", "jun\u00b7ger", "Freund", "!", "\u2013"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["NN", "PPOSAT", "NN", "$.", "$(", "ITJ", "ITJ", "$,", "PPOSAT", "ADJA", "NN", "$.", "$("], "meter": "+--+-+--+-+", "measure": "iambic.penta.invert"}, "line.8": {"text": "F\u00fcr Ihre G\u00fcter, Excellenz. \u2013 Gewi\u00df, mein Bester!", "tokens": ["F\u00fcr", "Ih\u00b7re", "G\u00fc\u00b7ter", ",", "Ex\u00b7cel\u00b7lenz", ".", "\u2013", "Ge\u00b7wi\u00df", ",", "mein", "Bes\u00b7ter", "!"], "token_info": ["word", "word", "word", "punct", "word", "punct", "punct", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "NN", "$.", "$(", "PTKANT", "$,", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Und Sie w\u00fcrden solche Darstellung nicht verschm\u00e4hn? \u2013", "tokens": ["Und", "Sie", "w\u00fcr\u00b7den", "sol\u00b7che", "Dar\u00b7stel\u00b7lung", "nicht", "ver\u00b7schm\u00e4hn", "?", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "PPER", "VAFIN", "PIAT", "NN", "PTKNEG", "VVINF", "$.", "$("], "meter": "+-+-+--+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.10": {"text": "O nein, ich liebe mir bunte muntre Farben,", "tokens": ["O", "nein", ",", "ich", "lie\u00b7be", "mir", "bun\u00b7te", "mun\u00b7tre", "Far\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PTKANT", "$,", "PPER", "VVFIN", "PPER", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.11": {"text": "Und euer Italien ist so voll der Kunst,", "tokens": ["Und", "eu\u00b7er", "I\u00b7ta\u00b7li\u00b7en", "ist", "so", "voll", "der", "Kunst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VAFIN", "ADV", "ADJD", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Wohin man sieht, lacht einem Gebild entgegen. \u2013", "tokens": ["Wo\u00b7hin", "man", "sieht", ",", "lacht", "ei\u00b7nem", "Ge\u00b7bild", "ent\u00b7ge\u00b7gen", ".", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWAV", "PIS", "VVFIN", "$,", "VVFIN", "ART", "NN", "PTKVZ", "$.", "$("], "meter": "-+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.13": {"text": "Wir sind, Gn\u00e4digster, als Kunstbegabte ber\u00fchmt,", "tokens": ["Wir", "sind", ",", "Gn\u00e4\u00b7digs\u00b7ter", ",", "als", "Kunst\u00b7be\u00b7gab\u00b7te", "be\u00b7r\u00fchmt", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "NN", "$,", "KOUS", "NN", "ADJD", "$,"], "meter": "-+-+--+-+--+", "measure": "iambic.penta.relaxed"}, "line.14": {"text": "Der Florentiner vor allen in ganz Italien. \u2013", "tokens": ["Der", "Flo\u00b7ren\u00b7ti\u00b7ner", "vor", "al\u00b7len", "in", "ganz", "I\u00b7ta\u00b7li\u00b7en.", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "abbreviation", "punct"], "pos": ["ART", "NN", "APPR", "PIS", "APPR", "ADV", "NE", "$("], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.15": {"text": "Doch seid Ihr theuer, mein Freund, mit guten Sachen. \u2013", "tokens": ["Doch", "seid", "Ihr", "theu\u00b7er", ",", "mein", "Freund", ",", "mit", "gu\u00b7ten", "Sa\u00b7chen", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VAFIN", "PPER", "ADJD", "$,", "PPOSAT", "NN", "$,", "APPR", "ADJA", "NN", "$.", "$("], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.16": {"text": "Wie's kommt, Excellenz, die sch\u00f6nen Bilder da", "tokens": ["Wie's", "kommt", ",", "Ex\u00b7cel\u00b7lenz", ",", "die", "sch\u00f6\u00b7nen", "Bil\u00b7der", "da"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "$,", "NN", "$,", "ART", "ADJA", "NN", "ADV"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.17": {"text": "Lie\u00dfe mein Vater um m\u00e4\u00dfigen Preis. \u2013", "tokens": ["Lie\u00b7\u00dfe", "mein", "Va\u00b7ter", "um", "m\u00e4\u00b7\u00dfi\u00b7gen", "Preis", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "APPR", "ADJA", "NN", "$.", "$("], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.18": {"text": "Auch ist es Schade, mein Sohn, derlei Gl\u00e4nzendes", "tokens": ["Auch", "ist", "es", "Scha\u00b7de", ",", "mein", "Sohn", ",", "der\u00b7lei", "Gl\u00e4n\u00b7zen\u00b7des"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "$,", "PPOSAT", "NN", "$,", "PIAT", "NN"], "meter": "-+-+--+--+--", "measure": "iambic.tetra.relaxed"}, "line.19": {"text": "Der Sonne und Luft so th\u00f6richt auszusetzen. \u2013", "tokens": ["Der", "Son\u00b7ne", "und", "Luft", "so", "th\u00f6\u00b7richt", "aus\u00b7zu\u00b7set\u00b7zen", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "KON", "NN", "ADV", "ADJD", "VVIZU", "$.", "$("], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.20": {"text": "Bei dem Gn\u00e4digsten w\u00fcrden sie ewig dauern,", "tokens": ["Bei", "dem", "Gn\u00e4\u00b7digs\u00b7ten", "w\u00fcr\u00b7den", "sie", "e\u00b7wig", "dau\u00b7ern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VAFIN", "PPER", "ADJD", "VVINF", "$,"], "meter": "+--+-+--+-+-", "measure": "iambic.penta.invert"}, "line.21": {"text": "Man firni\u00dft sie neu, so ist noch nichts daran verlohren. \u2013", "tokens": ["Man", "fir\u00b7ni\u00dft", "sie", "neu", ",", "so", "ist", "noch", "nichts", "da\u00b7ran", "ver\u00b7loh\u00b7ren", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PIS", "VVFIN", "PPER", "ADJD", "$,", "ADV", "VAFIN", "ADV", "PIS", "PAV", "VVPP", "$.", "$("], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.22": {"text": "Aber der Preis? \u2013 Wir w\u00fcrden schon einig werden. \u2013", "tokens": ["A\u00b7ber", "der", "Preis", "?", "\u2013", "Wir", "w\u00fcr\u00b7den", "schon", "ei\u00b7nig", "wer\u00b7den", ".", "\u2013"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ART", "NN", "$.", "$(", "PPER", "VAFIN", "ADV", "ADJD", "VAINF", "$.", "$("], "meter": "+--+-+--+-+-", "measure": "iambic.penta.invert"}, "line.23": {"text": "Trennt sich der Vater nicht ungern von ihnen? \u2013", "tokens": ["Trennt", "sich", "der", "Va\u00b7ter", "nicht", "un\u00b7gern", "von", "ih\u00b7nen", "?", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PRF", "ART", "NN", "PTKNEG", "ADV", "APPR", "PPER", "$.", "$("], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.24": {"text": "Er wird sie vermissen. \u2013 Allein, wenn ich sie erstehe,", "tokens": ["Er", "wird", "sie", "ver\u00b7mis\u00b7sen", ".", "\u2013", "Al\u00b7lein", ",", "wenn", "ich", "sie", "er\u00b7ste\u00b7he", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "VVPP", "$.", "$(", "ADV", "$,", "KOUS", "PPER", "PPER", "VVFIN", "$,"], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.25": {"text": "So m\u00fc\u00dft ihr mir auch den Gegenstand erkl\u00e4ren:", "tokens": ["So", "m\u00fc\u00dft", "ihr", "mir", "auch", "den", "Ge\u00b7gen\u00b7stand", "er\u00b7kl\u00e4\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PPER", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.26": {"text": "Sagt, find die Figuren aus der Mythologie entlehnt,", "tokens": ["Sagt", ",", "find", "die", "Fi\u00b7gu\u00b7ren", "aus", "der", "My\u00b7tho\u00b7lo\u00b7gie", "ent\u00b7lehnt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+--+--+-+-+-+", "measure": "amphibrach.tri.plus"}, "line.27": {"text": "So nennt mir die G\u00f6tter, die sie repr\u00e4sentiren:", "tokens": ["So", "nennt", "mir", "die", "G\u00f6t\u00b7ter", ",", "die", "sie", "re\u00b7pr\u00e4\u00b7sen\u00b7ti\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "$,", "PRELS", "PPER", "VVINF", "$."], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.28": {"text": "Oder ist die Sache christlich, so sind es wohl M\u00e4rtirer,", "tokens": ["O\u00b7der", "ist", "die", "Sa\u00b7che", "christ\u00b7lich", ",", "so", "sind", "es", "wohl", "M\u00e4r\u00b7ti\u00b7rer", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ART", "NN", "ADJD", "$,", "ADV", "VAFIN", "PPER", "ADV", "NN", "$,"], "meter": "+-+-+-+--+--+--", "measure": "trochaic.hexa.relaxed"}, "line.29": {"text": "Die dort gequ\u00e4lt so ergeben f\u00fcr den Glauben dulden.", "tokens": ["Die", "dort", "ge\u00b7qu\u00e4lt", "so", "er\u00b7ge\u00b7ben", "f\u00fcr", "den", "Glau\u00b7ben", "dul\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "VVPP", "ADV", "VVPP", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+--+-+-+-+-", "measure": "iambic.hexa.relaxed"}}, "stanza.8": {"line.1": {"text": "Da sah der Bursche den Freund mit gro\u00dfen Augen an,", "tokens": ["Da", "sah", "der", "Bur\u00b7sche", "den", "Freund", "mit", "gro\u00b7\u00dfen", "Au\u00b7gen", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ART", "NN", "APPR", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Merkte, da\u00df diesmal der Itali\u00e4ner der Geh\u00e4nselte sei,", "tokens": ["Merk\u00b7te", ",", "da\u00df", "dies\u00b7mal", "der", "I\u00b7ta\u00b7li\u00b7\u00e4\u00b7ner", "der", "Ge\u00b7h\u00e4n\u00b7sel\u00b7te", "sei", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "KOUS", "ADV", "ART", "NN", "ART", "NN", "VAFIN", "$,"], "meter": "+-+-+--+-+-+-+--+", "measure": "trochaic.octa.plus.relaxed"}, "line.3": {"text": "Wollte erst empfindlich thun, doch lachte er dann,", "tokens": ["Woll\u00b7te", "erst", "emp\u00b7find\u00b7lich", "thun", ",", "doch", "lach\u00b7te", "er", "dann", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "ADJD", "VVINF", "$,", "ADV", "VVFIN", "PPER", "ADV", "$,"], "meter": "+-+-+-+-+--+", "measure": "iambic.hexa.chol"}, "line.4": {"text": "Und mit den Worten: Excellenz sind ein Schelmchen!", "tokens": ["Und", "mit", "den", "Wor\u00b7ten", ":", "Ex\u00b7cel\u00b7lenz", "sind", "ein", "Schelm\u00b7chen", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "$.", "NN", "VAFIN", "ART", "NN", "$."], "meter": "---+---+--+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Lief er mit einem Sprunge \u00fcber die Gasse in's Haus.", "tokens": ["Lief", "er", "mit", "ei\u00b7nem", "Sprun\u00b7ge", "\u00fc\u00b7ber", "die", "Gas\u00b7se", "in's", "Haus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ART", "NN", "APPR", "ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+--+--+", "measure": "iambic.hexa.relaxed"}}}}}