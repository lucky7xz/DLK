{"textgrid.poem.53594": {"metadata": {"author": {"name": "Tucholsky, Kurt", "birth": "N.A.", "death": "N.A."}, "title": "Ich habe noch . . .", "genre": "verse", "period": "N.A.", "pub_year": 1912, "urn": "N.A.", "language": ["de:0.85", "da:0.14"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Dulde. Trage.", "tokens": ["Dul\u00b7de", ".", "Tra\u00b7ge", "."], "token_info": ["word", "punct", "word", "punct"], "pos": ["NE", "$.", "NN", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.2": {"text": "Bessere Tage", "tokens": ["Bes\u00b7se\u00b7re", "Ta\u00b7ge"], "token_info": ["word", "word"], "pos": ["ADJA", "NN"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "werden kommen.", "tokens": ["wer\u00b7den", "kom\u00b7men", "."], "token_info": ["word", "word", "punct"], "pos": ["VAFIN", "VVINF", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.4": {"text": "Alles mu\u00df frommen,", "tokens": ["Al\u00b7les", "mu\u00df", "from\u00b7men", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "VVINF", "$,"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.5": {"text": "denen, die fest sind.", "tokens": ["de\u00b7nen", ",", "die", "fest", "sind", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "$,", "PRELS", "ADJD", "VAFIN", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.6": {"text": "Herz, altes Kind,", "tokens": ["Herz", ",", "al\u00b7tes", "Kind", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "ADJA", "NN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "dulde, trage!", "tokens": ["dul\u00b7de", ",", "tra\u00b7ge", "!"], "token_info": ["word", "punct", "word", "punct"], "pos": ["VVFIN", "$,", "VVFIN", "$."], "meter": "+-+-", "measure": "trochaic.di"}}, "stanza.2": {"line.1": {"text": "Es wird \u2013 scheltet mich nicht einen Metaphysiker \u2013 doch einmal belohnt werden.", "tokens": ["Es", "wird", "\u2013", "schel\u00b7tet", "mich", "nicht", "ei\u00b7nen", "Me\u00b7ta\u00b7phy\u00b7si\u00b7ker", "\u2013", "doch", "ein\u00b7mal", "be\u00b7lohnt", "wer\u00b7den", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$(", "VVFIN", "PPER", "PTKNEG", "ART", "NN", "$(", "ADV", "ADV", "VVPP", "VAINF", "$."], "meter": "--+-+-+-------+---+-", "measure": "anapaest.init"}}, "stanza.3": {"line.1": {"text": "Dulde. Trage.", "tokens": ["Dul\u00b7de", ".", "Tra\u00b7ge", "."], "token_info": ["word", "punct", "word", "punct"], "pos": ["NE", "$.", "NN", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.2": {"text": "Bessere Tage", "tokens": ["Bes\u00b7se\u00b7re", "Ta\u00b7ge"], "token_info": ["word", "word"], "pos": ["ADJA", "NN"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "werden kommen.", "tokens": ["wer\u00b7den", "kom\u00b7men", "."], "token_info": ["word", "word", "punct"], "pos": ["VAFIN", "VVINF", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.4": {"text": "Alles mu\u00df frommen,", "tokens": ["Al\u00b7les", "mu\u00df", "from\u00b7men", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "VVINF", "$,"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.5": {"text": "denen, die fest sind.", "tokens": ["de\u00b7nen", ",", "die", "fest", "sind", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "$,", "PRELS", "ADJD", "VAFIN", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.6": {"text": "Herz, altes Kind,", "tokens": ["Herz", ",", "al\u00b7tes", "Kind", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "ADJA", "NN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "dulde, trage!", "tokens": ["dul\u00b7de", ",", "tra\u00b7ge", "!"], "token_info": ["word", "punct", "word", "punct"], "pos": ["VVFIN", "$,", "VVFIN", "$."], "meter": "+-+-", "measure": "trochaic.di"}}, "stanza.4": {"line.1": {"text": "Es wird \u2013 scheltet mich nicht einen Metaphysiker \u2013 doch einmal belohnt werden.", "tokens": ["Es", "wird", "\u2013", "schel\u00b7tet", "mich", "nicht", "ei\u00b7nen", "Me\u00b7ta\u00b7phy\u00b7si\u00b7ker", "\u2013", "doch", "ein\u00b7mal", "be\u00b7lohnt", "wer\u00b7den", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$(", "VVFIN", "PPER", "PTKNEG", "ART", "NN", "$(", "ADV", "ADV", "VVPP", "VAINF", "$."], "meter": "--+-+-+-------+---+-", "measure": "anapaest.init"}}}}}