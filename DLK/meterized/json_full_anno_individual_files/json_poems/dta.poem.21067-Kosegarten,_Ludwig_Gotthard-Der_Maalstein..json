{"dta.poem.21067": {"metadata": {"author": {"name": "Kosegarten, Ludwig Gotthard", "birth": "N.A.", "death": "N.A."}, "title": "Der Maalstein.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1798", "urn": "urn:nbn:de:kobv:b4-200905193300", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Wen haben sie hier in den Staub gebettet?               ", "tokens": ["Wen", "ha\u00b7ben", "sie", "hier", "in", "den", "Staub", "ge\u00b7bet\u00b7tet", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "ADV", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Wen in die enge \u00f6de Nacht verscharrt,", "tokens": ["Wen", "in", "die", "en\u00b7ge", "\u00f6\u00b7de", "Nacht", "ver\u00b7scharrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "ART", "ADJA", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Aus der kein Hahngeschrei, kein weckend Fr\u00fchroth", "tokens": ["Aus", "der", "kein", "Hahn\u00b7ge\u00b7schrei", ",", "kein", "we\u00b7ckend", "Fr\u00fch\u00b7roth"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "ART", "PIAT", "NN", "$,", "PIAT", "ADJD", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "rettet,", "tokens": ["ret\u00b7tet", ","], "token_info": ["word", "punct"], "pos": ["VVFIN", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.5": {"text": "Auf die kein Sonnenaufgang harrt?", "tokens": ["Auf", "die", "kein", "Son\u00b7nen\u00b7auf\u00b7gang", "harrt", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "In jene Nacht, in die kein Laut des Lebens,", "tokens": ["In", "je\u00b7ne", "Nacht", ",", "in", "die", "kein", "Laut", "des", "Le\u00b7bens", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "$,", "APPR", "ART", "PIAT", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Kein leiser Hoffnunglispel niederwallt;", "tokens": ["Kein", "lei\u00b7ser", "Hoff\u00b7nun\u00b7glis\u00b7pel", "nie\u00b7der\u00b7wallt", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "F\u00fcr die der Freude Sturm, der Angst Geheul vergebens", "tokens": ["F\u00fcr", "die", "der", "Freu\u00b7de", "Sturm", ",", "der", "Angst", "Ge\u00b7heul", "ver\u00b7ge\u00b7bens"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ART", "NN", "NN", "$,", "ART", "NN", "NN", "ADV"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Empor zum blauen Bogen hallt?", "tokens": ["Em\u00b7por", "zum", "blau\u00b7en", "Bo\u00b7gen", "hallt", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPRART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "In jene Nacht, in die der Witwe St\u00f6hnen,", "tokens": ["In", "je\u00b7ne", "Nacht", ",", "in", "die", "der", "Wit\u00b7we", "St\u00f6h\u00b7nen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "$,", "APPR", "PRELS", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Der Waisen Klage nicht hinunterdringt;", "tokens": ["Der", "Wai\u00b7sen", "Kla\u00b7ge", "nicht", "hin\u00b7un\u00b7ter\u00b7dringt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "In jene Ferne, draus kein Flehen und kein Sehnen", "tokens": ["In", "je\u00b7ne", "Fer\u00b7ne", ",", "draus", "kein", "Fle\u00b7hen", "und", "kein", "Seh\u00b7nen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PDAT", "NN", "$,", "PAV", "PIAT", "NN", "KON", "PIAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Den theuren Fl\u00fcchtling wiederbringt!", "tokens": ["Den", "theu\u00b7ren", "Fl\u00fccht\u00b7ling", "wie\u00b7der\u00b7bringt", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Wer ists, um den das menschliche Bedauern", "tokens": ["Wer", "ists", ",", "um", "den", "das", "menschli\u00b7che", "Be\u00b7dau\u00b7ern"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PWS", "VAFIN", "$,", "KOUI", "ART", "ART", "ADJA", "NN"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Auch des Empfindungslosern Auge n\u00e4sst,", "tokens": ["Auch", "des", "Emp\u00b7fin\u00b7dungs\u00b7lo\u00b7sern", "Au\u00b7ge", "n\u00e4sst", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Um den diess stumme Weh, diess lebensm\u00fcde", "tokens": ["Um", "den", "diess", "stum\u00b7me", "Weh", ",", "diess", "le\u00b7bens\u00b7m\u00fc\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KOUI", "ART", "ADJA", "ADJA", "NN", "$,", "FM.la", "FM.la"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Trauern", "tokens": ["Trau\u00b7ern"], "token_info": ["word"], "pos": ["NN"], "meter": "+-", "measure": "trochaic.single"}, "line.5": {"text": "Der \u00dcberbliebnen Busen presst?", "tokens": ["Der", "\u00dc\u00b7berb\u00b7lieb\u00b7nen", "Bu\u00b7sen", "presst", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Bist du es, Edler, der in unserm Kreise", "tokens": ["Bist", "du", "es", ",", "Ed\u00b7ler", ",", "der", "in", "un\u00b7serm", "Krei\u00b7se"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "PPER", "$,", "NE", "$,", "PRELS", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "So gross und so dem\u00fcthig wandelte?", "tokens": ["So", "gross", "und", "so", "de\u00b7m\u00fct\u00b7hig", "wan\u00b7del\u00b7te", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KON", "ADV", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "So friedlich und so still, so einfach und so", "tokens": ["So", "fried\u00b7lich", "und", "so", "still", ",", "so", "ein\u00b7fach", "und", "so"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "KON", "ADV", "ADJD", "$,", "ADV", "ADJD", "KON", "ADV"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "weise", "tokens": ["wei\u00b7se"], "token_info": ["word"], "pos": ["VVFIN"], "meter": "+-", "measure": "trochaic.single"}, "line.5": {"text": "Und christlich dacht' und handelte?", "tokens": ["Und", "christ\u00b7lich", "dacht'", "und", "han\u00b7del\u00b7te", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Den alle Guten liebten, die ihn kannten?", "tokens": ["Den", "al\u00b7le", "Gu\u00b7ten", "lieb\u00b7ten", ",", "die", "ihn", "kann\u00b7ten", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VVFIN", "$,", "PRELS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Dem auch der Leumund keinen Makel fand?", "tokens": ["Dem", "auch", "der", "Leu\u00b7mund", "kei\u00b7nen", "Ma\u00b7kel", "fand", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "ART", "NN", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Den unsre D\u00fcrftigen stillsegnend Vater nannten?", "tokens": ["Den", "uns\u00b7re", "D\u00fcrf\u00b7ti\u00b7gen", "still\u00b7seg\u00b7nend", "Va\u00b7ter", "nann\u00b7ten", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "ADJD", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der du mit immer offner Hand", "tokens": ["Der", "du", "mit", "im\u00b7mer", "off\u00b7ner", "Hand"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "APPR", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Holz dem Verklommnen, dem Brodlosen Speise,", "tokens": ["Holz", "dem", "Ver\u00b7klomm\u00b7nen", ",", "dem", "Brod\u00b7lo\u00b7sen", "Spei\u00b7se", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "$,", "ART", "NN", "NN", "$,"], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.2": {"text": "Dem nackten Bruder Kleidung spendetest,", "tokens": ["Dem", "nack\u00b7ten", "Bru\u00b7der", "Klei\u00b7dung", "spen\u00b7de\u00b7test", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Der unversorgten Witwe, der verlassnen Waise", "tokens": ["Der", "un\u00b7ver\u00b7sorg\u00b7ten", "Wit\u00b7we", ",", "der", "ver\u00b7lass\u00b7nen", "Wai\u00b7se"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Vollherzig dich erbarmetest?", "tokens": ["Voll\u00b7her\u00b7zig", "dich", "er\u00b7bar\u00b7me\u00b7test", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Der du, wie eignen Schmerz, den Schmerz der", "tokens": ["Der", "du", ",", "wie", "eig\u00b7nen", "Schmerz", ",", "den", "Schmerz", "der"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NE", "$,", "PWAV", "ADJA", "NN", "$,", "ART", "NN", "ART"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Schw\u00e4ren", "tokens": ["Schw\u00e4\u00b7ren"], "token_info": ["word"], "pos": ["NN"], "meter": "+-", "measure": "trochaic.single"}, "line.3": {"text": "Des pflegelosen Lazarus empfandst;", "tokens": ["Des", "pfle\u00b7ge\u00b7lo\u00b7sen", "La\u00b7za\u00b7rus", "emp\u00b7fandst", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Dir tausend Segnungen und Myriaden Z\u00e4hren", "tokens": ["Dir", "tau\u00b7send", "Seg\u00b7nun\u00b7gen", "und", "My\u00b7ria\u00b7den", "Z\u00e4h\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "CARD", "NN", "KON", "NN", "NN"], "meter": "-+-+---+--+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Des Dankes und der Lieb' erwandst? \u2014", "tokens": ["Des", "Dan\u00b7kes", "und", "der", "Lieb'", "er\u00b7wandst", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "VVFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Und dich, dem Seelelabsal, Br\u00fcder laben,", "tokens": ["Und", "dich", ",", "dem", "See\u00b7lel\u00b7ab\u00b7sal", ",", "Br\u00fc\u00b7der", "la\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PPER", "$,", "ART", "NN", "$,", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und Menschen retten, Engelwollust war,", "tokens": ["Und", "Men\u00b7schen", "ret\u00b7ten", ",", "En\u00b7gel\u00b7wol\u00b7lust", "war", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "NN", "VVINF", "$,", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Dich, Edlen, haben sie hier in den Staub be", "tokens": ["Dich", ",", "Ed\u00b7len", ",", "ha\u00b7ben", "sie", "hier", "in", "den", "Staub", "be"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "$,", "NN", "$,", "VAFIN", "PPER", "ADV", "APPR", "ART", "NN", "VVFIN"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "graben?", "tokens": ["gra\u00b7ben", "?"], "token_info": ["word", "punct"], "pos": ["VVINF", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.5": {"text": "Und alle deine Tugend war", "tokens": ["Und", "al\u00b7le", "dei\u00b7ne", "Tu\u00b7gend", "war"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PIS", "PPOSAT", "NN", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Zu schwach, den grimmen W\u00fcrger zu be-", "tokens": ["Zu", "schwach", ",", "den", "grim\u00b7men", "W\u00fcr\u00b7ger", "zu", "be"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PTKA", "ADJD", "$,", "ART", "ADJA", "NN", "APPR", "TRUNC"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "zwingen,", "tokens": ["zwin\u00b7gen", ","], "token_info": ["word", "punct"], "pos": ["VVINF", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.3": {"text": "Der hungrig seine Arme um dich schlang?", "tokens": ["Der", "hung\u00b7rig", "sei\u00b7ne", "Ar\u00b7me", "um", "dich", "schlang", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "PPOSAT", "NN", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Verloren war f\u00fcr dich der Gattin H\u00e4nderingen,", "tokens": ["Ver\u00b7lo\u00b7ren", "war", "f\u00fcr", "dich", "der", "Gat\u00b7tin", "H\u00e4n\u00b7de\u00b7rin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "APPR", "PPER", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und deiner Kinder Qualendrang?", "tokens": ["Und", "dei\u00b7ner", "Kin\u00b7der", "Qua\u00b7len\u00b7drang", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Verschlossen ist dein freundlich Aug' auf immer?", "tokens": ["Ver\u00b7schlos\u00b7sen", "ist", "dein", "freund\u00b7lich", "Aug'", "auf", "im\u00b7mer", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "PPOSAT", "ADJD", "NN", "APPR", "ADV", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Verriegelt ewig dein mitleidig Ohr?", "tokens": ["Ver\u00b7rie\u00b7gelt", "e\u00b7wig", "dein", "mit\u00b7lei\u00b7dig", "Ohr", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "PPOSAT", "ADJD", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Du liegst und schl\u00e4fst und schl\u00e4gst die schweren", "tokens": ["Du", "liegst", "und", "schl\u00e4fst", "und", "schl\u00e4gst", "die", "schwe\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "KON", "VVFIN", "ART", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wimper nimmer", "tokens": ["Wim\u00b7per", "nim\u00b7mer"], "token_info": ["word", "word"], "pos": ["NN", "ADV"], "meter": "+-+-", "measure": "trochaic.di"}, "line.5": {"text": "Aus deinem Todesschlaf empor?", "tokens": ["Aus", "dei\u00b7nem", "To\u00b7des\u00b7schlaf", "em\u00b7por", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Und Herzensreinheit, Herzensg\u00fcte w\u00e4re", "tokens": ["Und", "Her\u00b7zen\u00b7srein\u00b7heit", ",", "Her\u00b7zens\u00b7g\u00fc\u00b7te", "w\u00e4\u00b7re"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["KON", "NN", "$,", "NN", "VAFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Nicht besser, als das Gras, das Wiesen schm\u00fcckt,", "tokens": ["Nicht", "bes\u00b7ser", ",", "als", "das", "Gras", ",", "das", "Wie\u00b7sen", "schm\u00fcckt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADJD", "$,", "KOUS", "ART", "NN", "$,", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Und in der Sonne dorrt? nicht edler, als die \u00c4hre,", "tokens": ["Und", "in", "der", "Son\u00b7ne", "dorrt", "?", "nicht", "ed\u00b7ler", ",", "als", "die", "\u00c4h\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVFIN", "$.", "PTKNEG", "ADJA", "$,", "KOUS", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die halbgereift der Sturmwind knickt?", "tokens": ["Die", "halb\u00b7ge\u00b7reift", "der", "Sturm\u00b7wind", "knickt", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Nein, Menschenfreund, in diesem engen Hause", "tokens": ["Nein", ",", "Men\u00b7schen\u00b7freund", ",", "in", "die\u00b7sem", "en\u00b7gen", "Hau\u00b7se"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["PTKANT", "$,", "NN", "$,", "APPR", "PDAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Wohnt nicht dein bessres, nicht dein wahres Du!", "tokens": ["Wohnt", "nicht", "dein", "bess\u00b7res", ",", "nicht", "dein", "wah\u00b7res", "Du", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "PPOSAT", "ADJA", "$,", "PTKNEG", "PPOSAT", "ADJA", "PPER", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Dein wahres Du, zu gut f\u00fcr dieser Welt Karthause,", "tokens": ["Dein", "wah\u00b7res", "Du", ",", "zu", "gut", "f\u00fcr", "die\u00b7ser", "Welt", "Kar\u00b7thau\u00b7se", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "PPER", "$,", "PTKA", "ADJD", "APPR", "PDAT", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Flog jenen sch\u00f6nern Welten zu.", "tokens": ["Flog", "je\u00b7nen", "sch\u00f6\u00b7nern", "Wel\u00b7ten", "zu", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PDAT", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Nur dein Gewand, zerrissen und zertr\u00fcmmert,", "tokens": ["Nur", "dein", "Ge\u00b7wand", ",", "zer\u00b7ris\u00b7sen", "und", "zer\u00b7tr\u00fcm\u00b7mert", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "$,", "VVPP", "KON", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Vertrauten wir der grossen Mutter Schooss \u2014", "tokens": ["Ver\u00b7trau\u00b7ten", "wir", "der", "gros\u00b7sen", "Mut\u00b7ter", "Scho\u00b7oss"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "NN", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Ein Samenkorn, dem einst der Menschheit Blum'", "tokens": ["Ein", "Sa\u00b7men\u00b7korn", ",", "dem", "einst", "der", "Menschheit", "Blum'"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "ADV", "ART", "NN", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "entschimmert,", "tokens": ["ent\u00b7schim\u00b7mert", ","], "token_info": ["word", "punct"], "pos": ["VVPP", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.5": {"text": "Unkr\u00e4nkbar, schmerzlos, todeslos.", "tokens": ["Un\u00b7kr\u00e4nk\u00b7bar", ",", "schmerz\u00b7los", ",", "to\u00b7des\u00b7los", "."], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["ADJD", "$,", "ADJD", "$,", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "Du selbst, Verkl\u00e4rter, schwangst mit Strahlen-", "tokens": ["Du", "selbst", ",", "Ver\u00b7kl\u00e4r\u00b7ter", ",", "schwangst", "mit", "Strah\u00b7len"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["PPER", "ADV", "$,", "NN", "$,", "VVFIN", "APPR", "TRUNC"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "schnelle", "tokens": ["schnel\u00b7le"], "token_info": ["word"], "pos": ["VVFIN"], "meter": "+-", "measure": "trochaic.single"}, "line.3": {"text": "Dich \u00fcber Erdengram und Sargesnacht", "tokens": ["Dich", "\u00fc\u00b7ber", "Er\u00b7den\u00b7gram", "und", "Sar\u00b7ge\u00b7snacht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Und Gr\u00e4bereng' empor zu deines Edens Schwelle,", "tokens": ["Und", "Gr\u00e4\u00b7be\u00b7reng'", "em\u00b7por", "zu", "dei\u00b7nes", "E\u00b7dens", "Schwel\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "PTKVZ", "APPR", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wo dir ein mildrer Himmel lacht;", "tokens": ["Wo", "dir", "ein", "mild\u00b7rer", "Him\u00b7mel", "lacht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "Wo eine sch\u00f6nre Sonne dich uml\u00e4chelt,", "tokens": ["Wo", "ei\u00b7ne", "sch\u00f6n\u00b7re", "Son\u00b7ne", "dich", "um\u00b7l\u00e4\u00b7chelt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADJA", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Wo eine sch\u00f6nre Erde dich umgl\u00e4nzt,", "tokens": ["Wo", "ei\u00b7ne", "sch\u00f6n\u00b7re", "Er\u00b7de", "dich", "um\u00b7gl\u00e4nzt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADJA", "NN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Wo Gottes K\u00fchlung dir die heissen Schl\u00e4fe f\u00e4chelt,", "tokens": ["Wo", "Got\u00b7tes", "K\u00fch\u00b7lung", "dir", "die", "heis\u00b7sen", "Schl\u00e4\u00b7fe", "f\u00e4\u00b7chelt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "NN", "PPER", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und der Vollendung Kranz dich kr\u00e4nzt \u2014", "tokens": ["Und", "der", "Vol\u00b7len\u00b7dung", "Kranz", "dich", "kr\u00e4nzt"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "NN", "PPER", "VVFIN", "$("], "meter": "--+--+-+", "measure": "anapaest.di.plus"}}, "stanza.17": {"line.1": {"text": "Wie war dir, Selger, als die neue Sonne", "tokens": ["Wie", "war", "dir", ",", "Sel\u00b7ger", ",", "als", "die", "neu\u00b7e", "Son\u00b7ne"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["PWAV", "VAFIN", "PPER", "$,", "NN", "$,", "KOUS", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Dir Staunendem entgegenfunkelte?", "tokens": ["Dir", "Stau\u00b7nen\u00b7dem", "ent\u00b7ge\u00b7gen\u00b7fun\u00b7kel\u00b7te", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Als dich des Paradieses namenlose Wonne", "tokens": ["Als", "dich", "des", "Pa\u00b7ra\u00b7die\u00b7ses", "na\u00b7men\u00b7lo\u00b7se", "Won\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Hochwogig \u00fcberfluthete?", "tokens": ["Hoch\u00b7wo\u00b7gig", "\u00fc\u00b7berf\u00b7lut\u00b7he\u00b7te", "?"], "token_info": ["word", "word", "punct"], "pos": ["ADJD", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.18": {"line.1": {"text": "Wie war dir, als auf deinem hellen Pfade", "tokens": ["Wie", "war", "dir", ",", "als", "auf", "dei\u00b7nem", "hel\u00b7len", "Pfa\u00b7de"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PWAV", "VAFIN", "PPER", "$,", "KOUS", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Dir ", "tokens": ["Dir"], "token_info": ["word"], "pos": ["PPER"], "meter": "+", "measure": "single.up"}, "line.3": {"text": "Und ", "tokens": ["Und"], "token_info": ["word"], "pos": ["KON"], "meter": "+", "measure": "single.up"}, "line.4": {"text": "und ", "tokens": ["und"], "token_info": ["word"], "pos": ["KON"], "meter": "-", "measure": "single.down"}, "line.5": {"text": "Und ", "tokens": ["Und"], "token_info": ["word"], "pos": ["KON"], "meter": "+", "measure": "single.up"}}, "stanza.19": {"line.1": {"text": "Und alle, welchen heilig das Erbarmen", "tokens": ["Und", "al\u00b7le", ",", "wel\u00b7chen", "hei\u00b7lig", "das", "Er\u00b7bar\u00b7men"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "PIS", "$,", "PWAT", "ADJD", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und Bruderrettung Engelwollust war,", "tokens": ["Und", "Bru\u00b7der\u00b7ret\u00b7tung", "En\u00b7gel\u00b7wol\u00b7lust", "war", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Entgegenwandelten mit ausgestreckten Armen?", "tokens": ["Ent\u00b7ge\u00b7gen\u00b7wan\u00b7del\u00b7ten", "mit", "aus\u00b7ge\u00b7streck\u00b7ten", "Ar\u00b7men", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+---+-+-+-", "measure": "unknown.measure.penta"}, "line.4": {"text": "Vollendeter, sprich, wie dir war,", "tokens": ["Voll\u00b7en\u00b7de\u00b7ter", ",", "sprich", ",", "wie", "dir", "war", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADJD", "$,", "PWAV", "PPER", "VAFIN", "$,"], "meter": "-----+-+", "measure": "unknown.measure.di"}}, "stanza.20": {"line.1": {"text": "Als er, der Menschenretter Erster, Gr\u00f6sster,", "tokens": ["Als", "er", ",", "der", "Men\u00b7schen\u00b7ret\u00b7ter", "Ers\u00b7ter", ",", "Gr\u00f6s\u00b7ster", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "ART", "NN", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Als Jesus Christus liebend zu dir sprach:", "tokens": ["Als", "Je\u00b7sus", "Chris\u00b7tus", "lie\u00b7bend", "zu", "dir", "sprach", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "NE", "ADJD", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "\u201esey mir gegr\u00fcsst, Geliebter! Sey getrost, Er-", "tokens": ["\u201e", "sey", "mir", "ge\u00b7gr\u00fcs\u00b7st", ",", "Ge\u00b7lieb\u00b7ter", "!", "Sey", "ge\u00b7trost", ",", "Er"], "token_info": ["punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct", "word"], "pos": ["$(", "VAFIN", "PPER", "VVPP", "$,", "NN", "$.", "VAFIN", "VVPP", "$,", "TRUNC"], "meter": "+--+--+-+-+-", "measure": "dactylic.di.plus"}, "line.4": {"text": "l\u00f6s'ter!", "tokens": ["l\u00f6s'\u00b7ter", "!"], "token_info": ["word", "punct"], "pos": ["ADJD", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.5": {"text": "\u201edir folgen deine Thaten nach!", "tokens": ["\u201e", "dir", "fol\u00b7gen", "dei\u00b7ne", "Tha\u00b7ten", "nach", "!"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.21": {"line.1": {"text": "\u201emich hungerte, und du hast mich gespeiset!", "tokens": ["\u201e", "mich", "hun\u00b7ger\u00b7te", ",", "und", "du", "hast", "mich", "ge\u00b7spei\u00b7set", "!"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "$,", "KON", "PPER", "VAFIN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "\u201emich schauerte, und du hast mich erwarmt!", "tokens": ["\u201e", "mich", "schau\u00b7er\u00b7te", ",", "und", "du", "hast", "mich", "er\u00b7warmt", "!"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "$,", "KON", "PPER", "VAFIN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "\u201eich irrt' in fremden Land verlassen und ver-", "tokens": ["\u201e", "ich", "irrt'", "in", "frem\u00b7den", "Land", "ver\u00b7las\u00b7sen", "und", "ver"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "PPER", "VVFIN", "APPR", "ADJA", "NN", "VVINF", "KON", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "waiset,", "tokens": ["wai\u00b7set", ","], "token_info": ["word", "punct"], "pos": ["VVFIN", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.5": {"text": "\u201eund du hast meiner dich erbarmt.", "tokens": ["\u201e", "und", "du", "hast", "mei\u00b7ner", "dich", "er\u00b7barmt", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KON", "PPER", "VAFIN", "PPOSAT", "PPER", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.22": {"line.1": {"text": "\u201ekrank lag ich, und auf meinem Schmerzensbette", "tokens": ["\u201e", "krank", "lag", "ich", ",", "und", "auf", "mei\u00b7nem", "Schmer\u00b7zens\u00b7bet\u00b7te"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["$(", "ADJD", "VVFIN", "PPER", "$,", "KON", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "\u201ebesuchtest und erquicketest du mich.", "tokens": ["\u201e", "be\u00b7such\u00b7test", "und", "er\u00b7quic\u00b7ke\u00b7test", "du", "mich", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "KON", "VVFIN", "PPER", "PRF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "\u201egefangen lag ich hart; du sch\u00e4mtest meiner Kette", "tokens": ["\u201e", "ge\u00b7fan\u00b7gen", "lag", "ich", "hart", ";", "du", "sch\u00e4m\u00b7test", "mei\u00b7ner", "Ket\u00b7te"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["$(", "ADJD", "VVFIN", "PPER", "ADJD", "$.", "PPER", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "\u201edich nicht, kamst und umhalstest mich.\u201c \u2014", "tokens": ["\u201e", "dich", "nicht", ",", "kamst", "und", "um\u00b7hals\u00b7test", "mich", ".", "\u201c"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["$(", "PPER", "PTKNEG", "$,", "VVFIN", "KON", "VVFIN", "PPER", "$.", "$(", "$("], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.23": {"line.1": {"text": "\u201emein Herr und Gott, wann h\u00e4tt' ich dich gesehen,", "tokens": ["\u201e", "mein", "Herr", "und", "Gott", ",", "wann", "h\u00e4tt'", "ich", "dich", "ge\u00b7se\u00b7hen", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPOSAT", "NN", "KON", "NN", "$,", "PWAV", "VAFIN", "PPER", "PRF", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "\u201edich hungern, der die Welten hegt und pflegt?", "tokens": ["\u201e", "dich", "hun\u00b7gern", ",", "der", "die", "Wel\u00b7ten", "hegt", "und", "pflegt", "?"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "$,", "PRELS", "ART", "NN", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "\u201edich frieren, der du sch\u00fcrst der Sonne Flammen-", "tokens": ["\u201e", "dich", "frie\u00b7ren", ",", "der", "du", "sch\u00fcrst", "der", "Son\u00b7ne", "Flam\u00b7men"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "PPER", "VVINF", "$,", "PRELS", "PPER", "VVFIN", "ART", "NN", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "wehen?", "tokens": ["we\u00b7hen", "?"], "token_info": ["word", "punct"], "pos": ["VVFIN", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.5": {"text": "\u201edich dursten, der das Weltmeer w\u00e4gt?", "tokens": ["\u201e", "dich", "durs\u00b7ten", ",", "der", "das", "Welt\u00b7meer", "w\u00e4gt", "?"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "$,", "PRELS", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.24": {"line.1": {"text": "\u201edich nackend, der die Fr\u00fchlingsanger kleidet?", "tokens": ["\u201e", "dich", "na\u00b7ckend", ",", "der", "die", "Fr\u00fch\u00b7lings\u00b7an\u00b7ger", "klei\u00b7det", "?"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVPP", "$,", "PRELS", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "\u201edich eingekerkert, der die Himmel f\u00fcllt?", "tokens": ["\u201e", "dich", "ein\u00b7ge\u00b7ker\u00b7kert", ",", "der", "die", "Him\u00b7mel", "f\u00fcllt", "?"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVPP", "$,", "PRELS", "ART", "NN", "VVFIN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "\u201edich arm, der \u00dcberfluss aus voller Urne geudet?", "tokens": ["\u201e", "dich", "arm", ",", "der", "\u00dc\u00b7berf\u00b7luss", "aus", "vol\u00b7ler", "Ur\u00b7ne", "geu\u00b7det", "?"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "ADJD", "$,", "ART", "NN", "APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "\u201edich krank, dem alle Kraft entquillt?", "tokens": ["\u201e", "dich", "krank", ",", "dem", "al\u00b7le", "Kraft", "ent\u00b7quillt", "?"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "ADJD", "$,", "PRELS", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.25": {"line.1": {"text": "\u201ewann h\u00e4tt' ich dich erquicken und erlaben", "tokens": ["\u201e", "wann", "h\u00e4tt'", "ich", "dich", "er\u00b7qui\u00b7cken", "und", "er\u00b7la\u00b7ben"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "PWAV", "VAFIN", "PPER", "PRF", "VVINF", "KON", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "\u201eund tr\u00f6sten k\u00f6nnen, du Vollseliger?", "tokens": ["\u201e", "und", "tr\u00f6s\u00b7ten", "k\u00f6n\u00b7nen", ",", "du", "Voll\u00b7se\u00b7li\u00b7ger", "?"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "KON", "VVINF", "VMINF", "$,", "PPER", "NN", "$."], "meter": "-+-+--+---", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "\u201ewann sollt' ich dich gespeist, getr\u00e4nkt, erw\u00e4r-", "tokens": ["\u201e", "wann", "sollt'", "ich", "dich", "ge\u00b7speist", ",", "ge\u00b7tr\u00e4nkt", ",", "er\u00b7w\u00e4r"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "punct", "word"], "pos": ["$(", "PWAV", "VMFIN", "PPER", "PRF", "VVPP", "$,", "VVPP", "$,", "TRUNC"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "met haben,", "tokens": ["met", "ha\u00b7ben", ","], "token_info": ["word", "word", "punct"], "pos": ["VVFIN", "VAINF", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.5": {"text": "\u201eich Armer! ich Ohnm\u00e4chtiger!\u201c", "tokens": ["\u201e", "ich", "Ar\u00b7mer", "!", "ich", "Ohn\u00b7m\u00e4ch\u00b7ti\u00b7ger", "!", "\u201c"], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["$(", "PPER", "NN", "$.", "PPER", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.26": {"line.1": {"text": "Und liebend schaute Jesus auf dich nieder,", "tokens": ["Und", "lie\u00b7bend", "schau\u00b7te", "Je\u00b7sus", "auf", "dich", "nie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "NE", "APPR", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und sprach: \u201eIch sag' es, und ich schw\u00f6r' es dir:", "tokens": ["Und", "sprach", ":", "\u201e", "Ich", "sag'", "es", ",", "und", "ich", "schw\u00f6r'", "es", "dir", ":"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "$(", "PPER", "VVFIN", "PPER", "$,", "KON", "PPER", "VVFIN", "PPER", "PPER", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "\u201ewas du gethan hast einem meiner kleinsten Br\u00fc-", "tokens": ["\u201e", "was", "du", "ge\u00b7than", "hast", "ei\u00b7nem", "mei\u00b7ner", "kleins\u00b7ten", "Br\u00fc"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "PWS", "PPER", "VVPP", "VAFIN", "ART", "PPOSAT", "ADJA", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "der,", "tokens": ["der", ","], "token_info": ["word", "punct"], "pos": ["ART", "$,"], "meter": "-", "measure": "single.down"}, "line.5": {"text": "\u201edas thatest du, mein Bruder, mir.\u201c \u2014 \u2014", "tokens": ["\u201e", "das", "tha\u00b7test", "du", ",", "mein", "Bru\u00b7der", ",", "mir", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct", "punct", "punct", "punct"], "pos": ["$(", "PDS", "VVFIN", "PPER", "$,", "PPOSAT", "NN", "$,", "PPER", "$.", "$(", "$(", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}