{"textgrid.poem.32480": {"metadata": {"author": {"name": "Lessing, Gotthold Ephraim", "birth": "N.A.", "death": "N.A."}, "title": "Auf - - - -", "genre": "verse", "period": "N.A.", "pub_year": 1755, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Dem schlauesten Hebr\u00e4er in B**", "tokens": ["Dem", "schlau\u00b7es\u00b7ten", "Heb\u00b7r\u00e4\u00b7er", "in", "B", "*", "*"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "XY", "XY", "XY"], "meter": "-+--++--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Dem kein Betrug zu schwer, kein Kniff zu schimpflich schien,", "tokens": ["Dem", "kein", "Be\u00b7trug", "zu", "schwer", ",", "kein", "Kniff", "zu", "schimpf\u00b7lich", "schien", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "PTKA", "ADJD", "$,", "PIAT", "NN", "PTKA", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Dem Juden, der im L\u00fcgen,", "tokens": ["Dem", "Ju\u00b7den", ",", "der", "im", "L\u00fc\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "APPRART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Im Schachern und Betriegen,", "tokens": ["Im", "Scha\u00b7chern", "und", "Be\u00b7trie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Trotz Galgen und Gefahr,", "tokens": ["Trotz", "Gal\u00b7gen", "und", "Ge\u00b7fahr", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Mehr als ein Jude war,", "tokens": ["Mehr", "als", "ein", "Ju\u00b7de", "war", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "KOKOM", "ART", "NN", "VAFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Dem Helden in der Kunst zu brellen,", "tokens": ["Dem", "Hel\u00b7den", "in", "der", "Kunst", "zu", "brel\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Kams ein \u2013 \u2013 \u2013 Was gibt der Geiz nicht seinen Sklaven ein!", "tokens": ["Kams", "ein", "\u2013", "\u2013", "\u2013", "Was", "gibt", "der", "Geiz", "nicht", "sei\u00b7nen", "Skla\u00b7ven", "ein", "!"], "token_info": ["word", "word", "punct", "punct", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ART", "$(", "$(", "$(", "PWS", "VVFIN", "ART", "NN", "PTKNEG", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Von Frankreichs Witzigen den Witzigsten zu schnellen.", "tokens": ["Von", "Fran\u00b7kreichs", "Wit\u00b7zi\u00b7gen", "den", "Wit\u00b7zigs\u00b7ten", "zu", "schnel\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "NN", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.10": {"text": "Wer kann das sonst als \u2013 \u2013 \u2013 \u2013 sein?", "tokens": ["Wer", "kann", "das", "sonst", "als", "\u2013", "\u2013", "\u2013", "\u2013", "sein", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "punct", "punct", "word", "punct"], "pos": ["PWS", "VMFIN", "PDS", "ADV", "KOUS", "$(", "$(", "$(", "$(", "VAINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.11": {"text": "Recht, V** wars, der von dem schrecklichen Oedip,", "tokens": ["Recht", ",", "V", "*", "*", "wars", ",", "der", "von", "dem", "schreck\u00b7li\u00b7chen", "O\u00b7e\u00b7dip", ","], "token_info": ["word", "punct", "word", "punct", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "CARD", "XY", "XY", "VAFIN", "$,", "PRELS", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+--+-+", "measure": "trochaic.hexa.relaxed"}, "line.12": {"text": "Den saubern Witz bis zu Montperniaden trieb.", "tokens": ["Den", "sau\u00b7bern", "Witz", "bis", "zu", "Mont\u00b7per\u00b7ni\u00b7a\u00b7den", "trieb", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+++-+-+", "measure": "unknown.measure.septa"}, "line.13": {"text": "Schon war die Schlinge schlau geschlungen;", "tokens": ["Schon", "war", "die", "Schlin\u00b7ge", "schlau", "ge\u00b7schlun\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "Schon war sein Fu\u00df dem Ungl\u00fcck wankend nah,", "tokens": ["Schon", "war", "sein", "Fu\u00df", "dem", "Un\u00b7gl\u00fcck", "wan\u00b7kend", "nah", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPOSAT", "NN", "ART", "NN", "ADJD", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.15": {"text": "Schon schien die List dem Juden als gelungen,", "tokens": ["Schon", "schien", "die", "List", "dem", "Ju\u00b7den", "als", "ge\u00b7lun\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ART", "NN", "KOKOM", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.16": {"text": "Als der Betrieger schnell sich selbst gefangen sah.", "tokens": ["Als", "der", "Be\u00b7trie\u00b7ger", "schnell", "sich", "selbst", "ge\u00b7fan\u00b7gen", "sah", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ADJD", "PRF", "ADV", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Sagt Musen, welcher Gott stand hier dem Dichter bei,", "tokens": ["Sagt", "Mu\u00b7sen", ",", "wel\u00b7cher", "Gott", "stand", "hier", "dem", "Dich\u00b7ter", "bei", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "$,", "PWAT", "NN", "VVFIN", "ADV", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Und wies ihm unverh\u00fcllt verh\u00fcllte Schelmerei?", "tokens": ["Und", "wies", "ihm", "un\u00b7ver\u00b7h\u00fcllt", "ver\u00b7h\u00fcll\u00b7te", "Schel\u00b7me\u00b7rei", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADJD", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Wer sonst, als der f\u00fcrs Geld den frommen Tor betrog, Wenn er vom Dreifu\u00df selbst Orakelspr\u00fcche log?", "tokens": ["Wer", "sonst", ",", "als", "der", "f\u00fcrs", "Geld", "den", "from\u00b7men", "Tor", "be\u00b7trog", ",", "Wenn", "er", "vom", "Drei\u00b7fu\u00df", "selbst", "O\u00b7ra\u00b7kel\u00b7spr\u00fc\u00b7che", "log", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "$,", "KOUS", "ART", "ADJA", "NN", "ART", "ADJA", "NN", "VVFIN", "$,", "KOUS", "PPER", "APPRART", "NN", "ADV", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-+-+-+-+-+-+", "measure": "iambic.octa.plus"}, "line.20": {"text": "Er, der Betrug und List aus eigner \u00dcbung kennet,", "tokens": ["Er", ",", "der", "Be\u00b7trug", "und", "List", "aus", "eig\u00b7ner", "\u00dc\u00b7bung", "ken\u00b7net", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "ART", "NN", "KON", "NN", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Durch den V** gebrannt, und jeder Dichter brennet.", "tokens": ["Durch", "den", "V", "*", "*", "ge\u00b7brannt", ",", "und", "je\u00b7der", "Dich\u00b7ter", "bren\u00b7net", "."], "token_info": ["word", "word", "word", "punct", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "CARD", "XY", "XY", "VVPP", "$,", "KON", "PIAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.22": {"text": "Ja, ja, du wachtest selbst f\u00fcr deinen braven Sohn,", "tokens": ["Ja", ",", "ja", ",", "du", "wach\u00b7test", "selbst", "f\u00fcr", "dei\u00b7nen", "bra\u00b7ven", "Sohn", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PTKANT", "$,", "PPER", "VVFIN", "ADV", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Apoll, und Spott und Reu ward seines Feindes Lohn.", "tokens": ["A\u00b7poll", ",", "und", "Spott", "und", "Reu", "ward", "sei\u00b7nes", "Fein\u00b7des", "Lohn", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "KON", "NN", "KON", "NE", "VAFIN", "PPOSAT", "NN", "NN", "$."], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.24": {"text": "Du selbst \u2013 \u2013 doch wackrer Gott dich aus dem Spiel zu lassen,", "tokens": ["Du", "selbst", "\u2013", "\u2013", "doch", "wack\u00b7rer", "Gott", "dich", "aus", "dem", "Spiel", "zu", "las\u00b7sen", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "$(", "$(", "ADV", "ADJA", "NN", "PRF", "APPR", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Und kurz und gut den Grund zu fassen,", "tokens": ["Und", "kurz", "und", "gut", "den", "Grund", "zu", "fas\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "KON", "ADJD", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.26": {"text": "Warum die List,", "tokens": ["Wa\u00b7rum", "die", "List", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.27": {"text": "Dem Juden nicht gelungen ist;", "tokens": ["Dem", "Ju\u00b7den", "nicht", "ge\u00b7lun\u00b7gen", "ist", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKNEG", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.28": {"text": "So f\u00e4llt die Antwort ohngef\u00e4hr:", "tokens": ["So", "f\u00e4llt", "die", "Ant\u00b7wort", "ohn\u00b7ge\u00b7f\u00e4hr", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.29": {"text": "Herr V ** war ein gr\u00f6\u00dfrer Schelm als er.", "tokens": ["Herr", "V", "*", "*", "war", "ein", "gr\u00f6\u00df\u00b7rer", "Schelm", "als", "er", "."], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "CARD", "XY", "XY", "VAFIN", "ART", "ADJA", "NN", "KOUS", "PPER", "$."], "meter": "+-+-+-+--", "measure": "unknown.measure.tetra"}}, "stanza.2": {"line.1": {"text": "Dem schlauesten Hebr\u00e4er in B**", "tokens": ["Dem", "schlau\u00b7es\u00b7ten", "Heb\u00b7r\u00e4\u00b7er", "in", "B", "*", "*"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "XY", "XY", "XY"], "meter": "-+--++--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Dem kein Betrug zu schwer, kein Kniff zu schimpflich schien,", "tokens": ["Dem", "kein", "Be\u00b7trug", "zu", "schwer", ",", "kein", "Kniff", "zu", "schimpf\u00b7lich", "schien", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "PTKA", "ADJD", "$,", "PIAT", "NN", "PTKA", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Dem Juden, der im L\u00fcgen,", "tokens": ["Dem", "Ju\u00b7den", ",", "der", "im", "L\u00fc\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "APPRART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Im Schachern und Betriegen,", "tokens": ["Im", "Scha\u00b7chern", "und", "Be\u00b7trie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Trotz Galgen und Gefahr,", "tokens": ["Trotz", "Gal\u00b7gen", "und", "Ge\u00b7fahr", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Mehr als ein Jude war,", "tokens": ["Mehr", "als", "ein", "Ju\u00b7de", "war", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "KOKOM", "ART", "NN", "VAFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Dem Helden in der Kunst zu brellen,", "tokens": ["Dem", "Hel\u00b7den", "in", "der", "Kunst", "zu", "brel\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Kams ein \u2013 \u2013 \u2013 Was gibt der Geiz nicht seinen Sklaven ein!", "tokens": ["Kams", "ein", "\u2013", "\u2013", "\u2013", "Was", "gibt", "der", "Geiz", "nicht", "sei\u00b7nen", "Skla\u00b7ven", "ein", "!"], "token_info": ["word", "word", "punct", "punct", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ART", "$(", "$(", "$(", "PWS", "VVFIN", "ART", "NN", "PTKNEG", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Von Frankreichs Witzigen den Witzigsten zu schnellen.", "tokens": ["Von", "Fran\u00b7kreichs", "Wit\u00b7zi\u00b7gen", "den", "Wit\u00b7zigs\u00b7ten", "zu", "schnel\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "NN", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.10": {"text": "Wer kann das sonst als \u2013 \u2013 \u2013 \u2013 sein?", "tokens": ["Wer", "kann", "das", "sonst", "als", "\u2013", "\u2013", "\u2013", "\u2013", "sein", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "punct", "punct", "word", "punct"], "pos": ["PWS", "VMFIN", "PDS", "ADV", "KOUS", "$(", "$(", "$(", "$(", "VAINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.11": {"text": "Recht, V** wars, der von dem schrecklichen Oedip,", "tokens": ["Recht", ",", "V", "*", "*", "wars", ",", "der", "von", "dem", "schreck\u00b7li\u00b7chen", "O\u00b7e\u00b7dip", ","], "token_info": ["word", "punct", "word", "punct", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "CARD", "XY", "XY", "VAFIN", "$,", "PRELS", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+--+-+", "measure": "trochaic.hexa.relaxed"}, "line.12": {"text": "Den saubern Witz bis zu Montperniaden trieb.", "tokens": ["Den", "sau\u00b7bern", "Witz", "bis", "zu", "Mont\u00b7per\u00b7ni\u00b7a\u00b7den", "trieb", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+++-+-+", "measure": "unknown.measure.septa"}, "line.13": {"text": "Schon war die Schlinge schlau geschlungen;", "tokens": ["Schon", "war", "die", "Schlin\u00b7ge", "schlau", "ge\u00b7schlun\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "Schon war sein Fu\u00df dem Ungl\u00fcck wankend nah,", "tokens": ["Schon", "war", "sein", "Fu\u00df", "dem", "Un\u00b7gl\u00fcck", "wan\u00b7kend", "nah", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPOSAT", "NN", "ART", "NN", "ADJD", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.15": {"text": "Schon schien die List dem Juden als gelungen,", "tokens": ["Schon", "schien", "die", "List", "dem", "Ju\u00b7den", "als", "ge\u00b7lun\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ART", "NN", "KOKOM", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.16": {"text": "Als der Betrieger schnell sich selbst gefangen sah.", "tokens": ["Als", "der", "Be\u00b7trie\u00b7ger", "schnell", "sich", "selbst", "ge\u00b7fan\u00b7gen", "sah", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ADJD", "PRF", "ADV", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Sagt Musen, welcher Gott stand hier dem Dichter bei,", "tokens": ["Sagt", "Mu\u00b7sen", ",", "wel\u00b7cher", "Gott", "stand", "hier", "dem", "Dich\u00b7ter", "bei", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "$,", "PWAT", "NN", "VVFIN", "ADV", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Und wies ihm unverh\u00fcllt verh\u00fcllte Schelmerei?", "tokens": ["Und", "wies", "ihm", "un\u00b7ver\u00b7h\u00fcllt", "ver\u00b7h\u00fcll\u00b7te", "Schel\u00b7me\u00b7rei", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADJD", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Wer sonst, als der f\u00fcrs Geld den frommen Tor betrog, Wenn er vom Dreifu\u00df selbst Orakelspr\u00fcche log?", "tokens": ["Wer", "sonst", ",", "als", "der", "f\u00fcrs", "Geld", "den", "from\u00b7men", "Tor", "be\u00b7trog", ",", "Wenn", "er", "vom", "Drei\u00b7fu\u00df", "selbst", "O\u00b7ra\u00b7kel\u00b7spr\u00fc\u00b7che", "log", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "$,", "KOUS", "ART", "ADJA", "NN", "ART", "ADJA", "NN", "VVFIN", "$,", "KOUS", "PPER", "APPRART", "NN", "ADV", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-+-+-+-+-+-+", "measure": "iambic.octa.plus"}, "line.20": {"text": "Er, der Betrug und List aus eigner \u00dcbung kennet,", "tokens": ["Er", ",", "der", "Be\u00b7trug", "und", "List", "aus", "eig\u00b7ner", "\u00dc\u00b7bung", "ken\u00b7net", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "ART", "NN", "KON", "NN", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Durch den V** gebrannt, und jeder Dichter brennet.", "tokens": ["Durch", "den", "V", "*", "*", "ge\u00b7brannt", ",", "und", "je\u00b7der", "Dich\u00b7ter", "bren\u00b7net", "."], "token_info": ["word", "word", "word", "punct", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "CARD", "XY", "XY", "VVPP", "$,", "KON", "PIAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.22": {"text": "Ja, ja, du wachtest selbst f\u00fcr deinen braven Sohn,", "tokens": ["Ja", ",", "ja", ",", "du", "wach\u00b7test", "selbst", "f\u00fcr", "dei\u00b7nen", "bra\u00b7ven", "Sohn", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PTKANT", "$,", "PPER", "VVFIN", "ADV", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Apoll, und Spott und Reu ward seines Feindes Lohn.", "tokens": ["A\u00b7poll", ",", "und", "Spott", "und", "Reu", "ward", "sei\u00b7nes", "Fein\u00b7des", "Lohn", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "KON", "NN", "KON", "NE", "VAFIN", "PPOSAT", "NN", "NN", "$."], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.24": {"text": "Du selbst \u2013 \u2013 doch wackrer Gott dich aus dem Spiel zu lassen,", "tokens": ["Du", "selbst", "\u2013", "\u2013", "doch", "wack\u00b7rer", "Gott", "dich", "aus", "dem", "Spiel", "zu", "las\u00b7sen", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "$(", "$(", "ADV", "ADJA", "NN", "PRF", "APPR", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Und kurz und gut den Grund zu fassen,", "tokens": ["Und", "kurz", "und", "gut", "den", "Grund", "zu", "fas\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "KON", "ADJD", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.26": {"text": "Warum die List,", "tokens": ["Wa\u00b7rum", "die", "List", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.27": {"text": "Dem Juden nicht gelungen ist;", "tokens": ["Dem", "Ju\u00b7den", "nicht", "ge\u00b7lun\u00b7gen", "ist", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKNEG", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.28": {"text": "So f\u00e4llt die Antwort ohngef\u00e4hr:", "tokens": ["So", "f\u00e4llt", "die", "Ant\u00b7wort", "ohn\u00b7ge\u00b7f\u00e4hr", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.29": {"text": "Herr V ** war ein gr\u00f6\u00dfrer Schelm als er.", "tokens": ["Herr", "V", "*", "*", "war", "ein", "gr\u00f6\u00df\u00b7rer", "Schelm", "als", "er", "."], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "CARD", "XY", "XY", "VAFIN", "ART", "ADJA", "NN", "KOUS", "PPER", "$."], "meter": "+-+-+-+--", "measure": "unknown.measure.tetra"}}}}}