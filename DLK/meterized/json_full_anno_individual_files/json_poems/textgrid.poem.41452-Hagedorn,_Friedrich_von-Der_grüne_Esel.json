{"textgrid.poem.41452": {"metadata": {"author": {"name": "Hagedorn, Friedrich von", "birth": "N.A.", "death": "N.A."}, "title": "Der gr\u00fcne Esel", "genre": "verse", "period": "N.A.", "pub_year": 1731, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Es sch\u00f6pft ein Fabulist aus alten Wunderzeiten,", "tokens": ["Es", "sch\u00f6pft", "ein", "Fa\u00b7bu\u00b7list", "aus", "al\u00b7ten", "Wun\u00b7der\u00b7zei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Gibt, lenkt, und hemmt Erdichtungen den Lauf.", "tokens": ["Gibt", ",", "lenkt", ",", "und", "hemmt", "Er\u00b7dich\u00b7tun\u00b7gen", "den", "Lauf", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "VVFIN", "$,", "KON", "VVFIN", "NN", "ART", "NN", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Erz\u00e4hler halten sich bei neuern Seltenheiten", "tokens": ["Er\u00b7z\u00e4h\u00b7ler", "hal\u00b7ten", "sich", "bei", "neu\u00b7ern", "Sel\u00b7ten\u00b7hei\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "PRF", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Sogar, wie Wohlgemuth, beim gr\u00fcnen Esel, auf.", "tokens": ["So\u00b7gar", ",", "wie", "Wohl\u00b7ge\u00b7muth", ",", "beim", "gr\u00fc\u00b7nen", "E\u00b7sel", ",", "auf", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "$,", "PWAV", "NN", "$,", "APPRART", "ADJA", "NN", "$,", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Aesopus selbst lehrt oft aus Kleinigkeiten.", "tokens": ["A\u00b7e\u00b7so\u00b7pus", "selbst", "lehrt", "oft", "aus", "Klei\u00b7nig\u00b7kei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "VVFIN", "ADV", "APPR", "NN", "$."], "meter": "+--+--+-+-+-", "measure": "dactylic.di.plus"}, "line.6": {"text": "Es wollte sich ein nicht zu junges Weib,", "tokens": ["Es", "woll\u00b7te", "sich", "ein", "nicht", "zu", "jun\u00b7ges", "Weib", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PRF", "ART", "PTKNEG", "PTKZU", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Von weisen neunundvierzig Jahren,", "tokens": ["Von", "wei\u00b7sen", "neun\u00b7und\u00b7vier\u00b7zig", "Jah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "VVFIN", "CARD", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Aus innerem Beruf zum holden Zeitvertreib,", "tokens": ["Aus", "in\u00b7ne\u00b7rem", "Be\u00b7ruf", "zum", "hol\u00b7den", "Zeit\u00b7ver\u00b7treib", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Mit einem frischen Stutzer paaren,", "tokens": ["Mit", "ei\u00b7nem", "fri\u00b7schen", "Stut\u00b7zer", "paa\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Und ihrer Nachbarin, die ungemein erfahren", "tokens": ["Und", "ih\u00b7rer", "Nach\u00b7ba\u00b7rin", ",", "die", "un\u00b7ge\u00b7mein", "er\u00b7fah\u00b7ren"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "$,", "PRELS", "ADV", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Und klug war, wie Uly\u00df, den Vorsatz offenbaren.", "tokens": ["Und", "klug", "war", ",", "wie", "U\u00b7ly\u00df", ",", "den", "Vor\u00b7satz", "of\u00b7fen\u00b7ba\u00b7ren", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VAFIN", "$,", "PWAV", "NE", "$,", "ART", "NN", "VVINF", "$."], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.12": {"text": "Sagt, spricht sie, sagt mir doch: gef\u00e4llt Leander euch?", "tokens": ["Sagt", ",", "spricht", "sie", ",", "sagt", "mir", "doch", ":", "ge\u00b7f\u00e4llt", "Le\u00b7an\u00b7der", "euch", "?"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "VVFIN", "PPER", "$,", "VVFIN", "PPER", "ADV", "$.", "VVFIN", "NE", "PPER", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Ist er nicht meinem Mann, dem sel'gen Manne, gleich?", "tokens": ["Ist", "er", "nicht", "mei\u00b7nem", "Mann", ",", "dem", "sel'\u00b7gen", "Man\u00b7ne", ",", "gleich", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["VAFIN", "PPER", "PTKNEG", "PPOSAT", "NN", "$,", "ART", "ADJA", "NN", "$,", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Nur freundlicher, als er? Einander zu erbauen,", "tokens": ["Nur", "freund\u00b7li\u00b7cher", ",", "als", "er", "?", "Ein\u00b7an\u00b7der", "zu", "er\u00b7bau\u00b7en", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "KOUS", "PPER", "$.", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Soll uns der Oberpfarrherr trauen:", "tokens": ["Soll", "uns", "der", "O\u00b7berp\u00b7far\u00b7rherr", "trau\u00b7en", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "Doch, wenn wir uns, aus keuscher Liebe, frein,", "tokens": ["Doch", ",", "wenn", "wir", "uns", ",", "aus", "keu\u00b7scher", "Lie\u00b7be", ",", "frein", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "$,", "KOUS", "PPER", "PPER", "$,", "APPR", "ADJA", "NN", "$,", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.17": {"text": "Werd' ich, sagt, werd' ich nicht ein rechtes M\u00e4rchen sein?", "tokens": ["Werd'", "ich", ",", "sagt", ",", "werd'", "ich", "nicht", "ein", "rech\u00b7tes", "M\u00e4r\u00b7chen", "sein", "?"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "$,", "VVFIN", "$,", "VAFIN", "PPER", "PTKNEG", "ART", "ADJA", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Romanenschreiber, Liederdichter,", "tokens": ["Ro\u00b7ma\u00b7nen\u00b7schrei\u00b7ber", ",", "Lie\u00b7der\u00b7dich\u00b7ter", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.19": {"text": "Und die gemeinen Splitterrichter,", "tokens": ["Und", "die", "ge\u00b7mei\u00b7nen", "Split\u00b7ter\u00b7rich\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.20": {"text": "Und ach! die Weiber selbst, die Weiber mu\u00df ich scheun.", "tokens": ["Und", "ach", "!", "die", "Wei\u00b7ber", "selbst", ",", "die", "Wei\u00b7ber", "mu\u00df", "ich", "scheun", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "XY", "$.", "ART", "NN", "ADV", "$,", "ART", "NN", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Freit! lehrt die Nachbarin. La\u00dft jeden schreiben, sagen,", "tokens": ["Freit", "!", "lehrt", "die", "Nach\u00b7ba\u00b7rin", ".", "La\u00dft", "je\u00b7den", "schrei\u00b7ben", ",", "sa\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["NN", "$.", "VVFIN", "ART", "NN", "$.", "VVIMP", "PIS", "VVINF", "$,", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Ja singen, wenn er singen kann,", "tokens": ["Ja", "sin\u00b7gen", ",", "wenn", "er", "sin\u00b7gen", "kann", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "VVFIN", "$,", "KOUS", "PPER", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.23": {"text": "Es sei ein M\u00e4rchen von acht Tagen!", "tokens": ["Es", "sei", "ein", "M\u00e4r\u00b7chen", "von", "acht", "Ta\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "APPR", "CARD", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.24": {"text": "Am neunten hebt gewi\u00df sich schon ein neues an.", "tokens": ["Am", "neun\u00b7ten", "hebt", "ge\u00b7wi\u00df", "sich", "schon", "ein", "neu\u00b7es", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "VVFIN", "ADV", "PRF", "ADV", "ART", "ADJA", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Das soll mein Esel demonstriren.", "tokens": ["Das", "soll", "mein", "E\u00b7sel", "de\u00b7monst\u00b7ri\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PPOSAT", "NN", "VVINF", "$."], "meter": "+---+----", "measure": "dactylic.init"}, "line.26": {"text": "Den f\u00e4rb' ich euch so gr\u00fcn, als meinen Papagei.", "tokens": ["Den", "f\u00e4rb'", "ich", "euch", "so", "gr\u00fcn", ",", "als", "mei\u00b7nen", "Pa\u00b7pa\u00b7gei", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "PPER", "ADV", "ADJD", "$,", "KOUS", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Dann soll er durch die Stadt spazieren,", "tokens": ["Dann", "soll", "er", "durch", "die", "Stadt", "spa\u00b7zie\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.28": {"text": "Damit er allen sichtbar sei,", "tokens": ["Da\u00b7mit", "er", "al\u00b7len", "sicht\u00b7bar", "sei", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIAT", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.29": {"text": "Und alle wird das gro\u00dfe Wunder r\u00fchren.", "tokens": ["Und", "al\u00b7le", "wird", "das", "gro\u00b7\u00dfe", "Wun\u00b7der", "r\u00fch\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VAFIN", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.30": {"text": "Das tr\u00e4ge Thier wird auf den Markt gebracht,", "tokens": ["Das", "tr\u00e4\u00b7ge", "Thier", "wird", "auf", "den", "Markt", "ge\u00b7bracht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.31": {"text": "Der P\u00f6bel l\u00e4uft herzu, bewundert, gafft und lacht.", "tokens": ["Der", "P\u00f6\u00b7bel", "l\u00e4uft", "her\u00b7zu", ",", "be\u00b7wun\u00b7dert", ",", "gafft", "und", "lacht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "$,", "VVPP", "$,", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Wie? ruft man, k\u00f6nnen Esel gr\u00fcnen?", "tokens": ["Wie", "?", "ruft", "man", ",", "k\u00f6n\u00b7nen", "E\u00b7sel", "gr\u00fc\u00b7nen", "?"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "$.", "VVFIN", "PIS", "$,", "VMFIN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.33": {"text": "Das h\u00e4tt' ich nimmermehr gedacht ...", "tokens": ["Das", "h\u00e4tt'", "ich", "nim\u00b7mer\u00b7mehr", "ge\u00b7dacht", "..."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.34": {"text": "O kommt doch, seht! ... Sollt' aber diese Tracht", "tokens": ["O", "kommt", "doch", ",", "seht", "!", "...", "Sollt'", "a\u00b7ber", "die\u00b7se", "Tracht"], "token_info": ["word", "word", "word", "punct", "word", "punct", "punct", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "ADV", "$,", "VVFIN", "$.", "$(", "VMFIN", "ADV", "PDAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.35": {"text": "Nicht mehr f\u00fcr edle Pferde dienen?", "tokens": ["Nicht", "mehr", "f\u00fcr", "ed\u00b7le", "Pfer\u00b7de", "die\u00b7nen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.36": {"text": "Doch alles ist recht sch\u00f6n, wie die Natur es macht ...", "tokens": ["Doch", "al\u00b7les", "ist", "recht", "sch\u00f6n", ",", "wie", "die", "Na\u00b7tur", "es", "macht", "..."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VAFIN", "ADJD", "ADJD", "$,", "PWAV", "ART", "NN", "PPER", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "Was? die Natur? Es ist ein Werk der Kunst ...", "tokens": ["Was", "?", "die", "Na\u00b7tur", "?", "Es", "ist", "ein", "Werk", "der", "Kunst", "..."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "$.", "ART", "NN", "$.", "PPER", "VAFIN", "ART", "NN", "ART", "NN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.38": {"text": "Der Kunst? o nein, Gevatter, nein, mit Gunst!", "tokens": ["Der", "Kunst", "?", "o", "nein", ",", "Ge\u00b7vat\u00b7ter", ",", "nein", ",", "mit", "Gunst", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$.", "FM", "PTKANT", "$,", "NN", "$,", "PTKANT", "$,", "APPR", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.39": {"text": "Er ist das, was er ist, und k\u00f6mmt uns aus dem Lande", "tokens": ["Er", "ist", "das", ",", "was", "er", "ist", ",", "und", "k\u00f6mmt", "uns", "aus", "dem", "Lan\u00b7de"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PDS", "$,", "PWS", "PPER", "VAFIN", "$,", "KON", "VVFIN", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.40": {"text": "Der gr\u00fcnen Esel her. Ich wei\u00df nicht, wie es hei\u00dft:", "tokens": ["Der", "gr\u00fc\u00b7nen", "E\u00b7sel", "her", ".", "Ich", "wei\u00df", "nicht", ",", "wie", "es", "hei\u00dft", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKVZ", "$.", "PPER", "VVFIN", "PTKNEG", "$,", "PWAV", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.41": {"text": "Doch, wenn Er mir das Gegentheil beweist,", "tokens": ["Doch", ",", "wenn", "Er", "mir", "das", "Ge\u00b7gen\u00b7theil", "be\u00b7weist", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "PPER", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.42": {"text": "So gleicht im Kirchspiel Ihm kein Doctor an Verstande ...", "tokens": ["So", "gleicht", "im", "Kirch\u00b7spiel", "Ihm", "kein", "Doc\u00b7tor", "an", "Ver\u00b7stan\u00b7de", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPRART", "NN", "PPER", "PIAT", "NN", "APPR", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.43": {"text": "Der Herr hat Recht; so sprach ein Bader, der gereist,", "tokens": ["Der", "Herr", "hat", "Recht", ";", "so", "sprach", "ein", "Ba\u00b7der", ",", "der", "ge\u00b7reist", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "NN", "$.", "ADV", "VVFIN", "ART", "NN", "$,", "PRELS", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.44": {"text": "Und ein Gelehrter war. Ich habe, wider Hoffen,", "tokens": ["Und", "ein", "Ge\u00b7lehr\u00b7ter", "war", ".", "Ich", "ha\u00b7be", ",", "wi\u00b7der", "Hof\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VAFIN", "$.", "PPER", "VAFIN", "$,", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.45": {"text": "In Capo Verde selbst dergleichen angetroffen.", "tokens": ["In", "Ca\u00b7po", "Ver\u00b7de", "selbst", "derg\u00b7lei\u00b7chen", "an\u00b7ge\u00b7trof\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "NN", "ADV", "PIS", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.46": {"text": "Als F\u00fcllen sind sie gelb und blau,", "tokens": ["Als", "F\u00fcl\u00b7len", "sind", "sie", "gelb", "und", "blau", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "VAFIN", "PPER", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.47": {"text": "Hernachmals gr\u00fcn. Ich kenne sie genau.", "tokens": ["Her\u00b7nach\u00b7mals", "gr\u00fcn", ".", "Ich", "ken\u00b7ne", "sie", "ge\u00b7nau", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$.", "PPER", "VVFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.48": {"text": "Dort hielt ich anfangs auch den Mund erstaunend offen;", "tokens": ["Dort", "hielt", "ich", "an\u00b7fangs", "auch", "den", "Mund", "er\u00b7stau\u00b7nend", "of\u00b7fen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ADV", "ART", "NN", "VVPP", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.49": {"text": "Allein weit mehr, als ich in Chymia", "tokens": ["Al\u00b7lein", "weit", "mehr", ",", "als", "ich", "in", "Chy\u00b7mia"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "ADV", "$,", "KOUS", "PPER", "APPR", "NE"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.50": {"text": "Gar einen gr\u00fcnen L\u00f6wen sah.", "tokens": ["Gar", "ei\u00b7nen", "gr\u00fc\u00b7nen", "L\u00f6\u00b7wen", "sah", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.51": {"text": "Ach! seufzt' ein Weib, das gerne prophezeite,", "tokens": ["Ach", "!", "seufzt'", "ein", "Weib", ",", "das", "ger\u00b7ne", "pro\u00b7phe\u00b7zei\u00b7te", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ITJ", "$.", "VVFIN", "ART", "NN", "$,", "PRELS", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.52": {"text": "Das Ungl\u00fccksthier! beschaut es nur, ihr Leute!", "tokens": ["Das", "Un\u00b7gl\u00fcckst\u00b7hier", "!", "be\u00b7schaut", "es", "nur", ",", "ihr", "Leu\u00b7te", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$.", "VVFIN", "PPER", "ADV", "$,", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.53": {"text": "Mir hat, vor kurzer Zeit, von gr\u00fcnem Vieh getr\u00e4umt,", "tokens": ["Mir", "hat", ",", "vor", "kur\u00b7zer", "Zeit", ",", "von", "gr\u00fc\u00b7nem", "Vieh", "ge\u00b7tr\u00e4umt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "APPR", "ADJA", "NN", "$,", "APPR", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.54": {"text": "Und, leider! dieser Traum war gar nicht ungereimt,", "tokens": ["Und", ",", "lei\u00b7der", "!", "die\u00b7ser", "Traum", "war", "gar", "nicht", "un\u00b7ge\u00b7reimt", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "ADV", "$.", "PDAT", "NN", "VAFIN", "ADV", "PTKNEG", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.55": {"text": "Denn, seht! er ist erf\u00fcllt. Ein Ungl\u00fcck droht den L\u00e4ndern,", "tokens": ["Denn", ",", "seht", "!", "er", "ist", "er\u00b7f\u00fcllt", ".", "Ein", "Un\u00b7gl\u00fcck", "droht", "den", "L\u00e4n\u00b7dern", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "VVFIN", "$.", "PPER", "VAFIN", "VVPP", "$.", "ART", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.56": {"text": "Wo Thiere so die Farben \u00e4ndern.", "tokens": ["Wo", "Thie\u00b7re", "so", "die", "Far\u00b7ben", "\u00e4n\u00b7dern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.57": {"text": "Nicht wahr? Hier lie\u00dfen sich schneewei\u00dfe M\u00e4use sehn,", "tokens": ["Nicht", "wahr", "?", "Hier", "lie\u00b7\u00dfen", "sich", "schnee\u00b7wei\u00b7\u00dfe", "M\u00e4u\u00b7se", "sehn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "PTKVZ", "$.", "ADV", "VVFIN", "PRF", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.58": {"text": "Wir sahen bald hernach die besten K\u00fche schwinden.", "tokens": ["Wir", "sa\u00b7hen", "bald", "her\u00b7nach", "die", "bes\u00b7ten", "K\u00fc\u00b7he", "schwin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.59": {"text": "Seitdem sich um Paris die Purpurkatzen finden,", "tokens": ["Seit\u00b7dem", "sich", "um", "Pa\u00b7ris", "die", "Pur\u00b7pur\u00b7kat\u00b7zen", "fin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PRF", "APPR", "NE", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.60": {"text": "Soll auch die Falschheit dort recht sehr im Schwange gehn;", "tokens": ["Soll", "auch", "die", "Falschheit", "dort", "recht", "sehr", "im", "Schwan\u00b7ge", "gehn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "ART", "NN", "ADV", "ADV", "ADV", "APPRART", "NN", "VVINF", "$."], "meter": "+--+--+-+-+", "measure": "dactylic.di.plus"}, "line.61": {"text": "Kein Wunder, da\u00df daher Ha\u00df, Krieg und Mord entstehn.", "tokens": ["Kein", "Wun\u00b7der", ",", "da\u00df", "da\u00b7her", "Ha\u00df", ",", "Krieg", "und", "Mord", "ent\u00b7stehn", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "$,", "KOUS", "PAV", "NN", "$,", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Sechs Tage zeigt er sich den Haubt- und Nebengassen,", "tokens": ["Sechs", "Ta\u00b7ge", "zeigt", "er", "sich", "den", "Haub\u00b7t", "und", "Ne\u00b7ben\u00b7gas\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "VVFIN", "PPER", "PRF", "ART", "TRUNC", "KON", "NN", "$,"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Und kein Rhinoceros reizt mehr die Neubegier.", "tokens": ["Und", "kein", "Rhi\u00b7no\u00b7ce\u00b7ros", "reizt", "mehr", "die", "Neu\u00b7be\u00b7gier", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Bald aber wird auch er so aus der Acht gelassen,", "tokens": ["Bald", "a\u00b7ber", "wird", "auch", "er", "so", "aus", "der", "Acht", "ge\u00b7las\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VAFIN", "ADV", "PPER", "ADV", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Als das gemeinste M\u00fcllerthier.", "tokens": ["Als", "das", "ge\u00b7meins\u00b7te", "M\u00fcl\u00b7ler\u00b7thier", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Es sch\u00f6pft ein Fabulist aus alten Wunderzeiten,", "tokens": ["Es", "sch\u00f6pft", "ein", "Fa\u00b7bu\u00b7list", "aus", "al\u00b7ten", "Wun\u00b7der\u00b7zei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Gibt, lenkt, und hemmt Erdichtungen den Lauf.", "tokens": ["Gibt", ",", "lenkt", ",", "und", "hemmt", "Er\u00b7dich\u00b7tun\u00b7gen", "den", "Lauf", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "VVFIN", "$,", "KON", "VVFIN", "NN", "ART", "NN", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Erz\u00e4hler halten sich bei neuern Seltenheiten", "tokens": ["Er\u00b7z\u00e4h\u00b7ler", "hal\u00b7ten", "sich", "bei", "neu\u00b7ern", "Sel\u00b7ten\u00b7hei\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "PRF", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Sogar, wie Wohlgemuth, beim gr\u00fcnen Esel, auf.", "tokens": ["So\u00b7gar", ",", "wie", "Wohl\u00b7ge\u00b7muth", ",", "beim", "gr\u00fc\u00b7nen", "E\u00b7sel", ",", "auf", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "$,", "PWAV", "NN", "$,", "APPRART", "ADJA", "NN", "$,", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Aesopus selbst lehrt oft aus Kleinigkeiten.", "tokens": ["A\u00b7e\u00b7so\u00b7pus", "selbst", "lehrt", "oft", "aus", "Klei\u00b7nig\u00b7kei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "VVFIN", "ADV", "APPR", "NN", "$."], "meter": "+--+--+-+-+-", "measure": "dactylic.di.plus"}, "line.6": {"text": "Es wollte sich ein nicht zu junges Weib,", "tokens": ["Es", "woll\u00b7te", "sich", "ein", "nicht", "zu", "jun\u00b7ges", "Weib", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PRF", "ART", "PTKNEG", "PTKZU", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Von weisen neunundvierzig Jahren,", "tokens": ["Von", "wei\u00b7sen", "neun\u00b7und\u00b7vier\u00b7zig", "Jah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "VVFIN", "CARD", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Aus innerem Beruf zum holden Zeitvertreib,", "tokens": ["Aus", "in\u00b7ne\u00b7rem", "Be\u00b7ruf", "zum", "hol\u00b7den", "Zeit\u00b7ver\u00b7treib", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Mit einem frischen Stutzer paaren,", "tokens": ["Mit", "ei\u00b7nem", "fri\u00b7schen", "Stut\u00b7zer", "paa\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Und ihrer Nachbarin, die ungemein erfahren", "tokens": ["Und", "ih\u00b7rer", "Nach\u00b7ba\u00b7rin", ",", "die", "un\u00b7ge\u00b7mein", "er\u00b7fah\u00b7ren"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "$,", "PRELS", "ADV", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Und klug war, wie Uly\u00df, den Vorsatz offenbaren.", "tokens": ["Und", "klug", "war", ",", "wie", "U\u00b7ly\u00df", ",", "den", "Vor\u00b7satz", "of\u00b7fen\u00b7ba\u00b7ren", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VAFIN", "$,", "PWAV", "NE", "$,", "ART", "NN", "VVINF", "$."], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.12": {"text": "Sagt, spricht sie, sagt mir doch: gef\u00e4llt Leander euch?", "tokens": ["Sagt", ",", "spricht", "sie", ",", "sagt", "mir", "doch", ":", "ge\u00b7f\u00e4llt", "Le\u00b7an\u00b7der", "euch", "?"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "VVFIN", "PPER", "$,", "VVFIN", "PPER", "ADV", "$.", "VVFIN", "NE", "PPER", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Ist er nicht meinem Mann, dem sel'gen Manne, gleich?", "tokens": ["Ist", "er", "nicht", "mei\u00b7nem", "Mann", ",", "dem", "sel'\u00b7gen", "Man\u00b7ne", ",", "gleich", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["VAFIN", "PPER", "PTKNEG", "PPOSAT", "NN", "$,", "ART", "ADJA", "NN", "$,", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Nur freundlicher, als er? Einander zu erbauen,", "tokens": ["Nur", "freund\u00b7li\u00b7cher", ",", "als", "er", "?", "Ein\u00b7an\u00b7der", "zu", "er\u00b7bau\u00b7en", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "KOUS", "PPER", "$.", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Soll uns der Oberpfarrherr trauen:", "tokens": ["Soll", "uns", "der", "O\u00b7berp\u00b7far\u00b7rherr", "trau\u00b7en", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "Doch, wenn wir uns, aus keuscher Liebe, frein,", "tokens": ["Doch", ",", "wenn", "wir", "uns", ",", "aus", "keu\u00b7scher", "Lie\u00b7be", ",", "frein", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "$,", "KOUS", "PPER", "PPER", "$,", "APPR", "ADJA", "NN", "$,", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.17": {"text": "Werd' ich, sagt, werd' ich nicht ein rechtes M\u00e4rchen sein?", "tokens": ["Werd'", "ich", ",", "sagt", ",", "werd'", "ich", "nicht", "ein", "rech\u00b7tes", "M\u00e4r\u00b7chen", "sein", "?"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "$,", "VVFIN", "$,", "VAFIN", "PPER", "PTKNEG", "ART", "ADJA", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Romanenschreiber, Liederdichter,", "tokens": ["Ro\u00b7ma\u00b7nen\u00b7schrei\u00b7ber", ",", "Lie\u00b7der\u00b7dich\u00b7ter", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.19": {"text": "Und die gemeinen Splitterrichter,", "tokens": ["Und", "die", "ge\u00b7mei\u00b7nen", "Split\u00b7ter\u00b7rich\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.20": {"text": "Und ach! die Weiber selbst, die Weiber mu\u00df ich scheun.", "tokens": ["Und", "ach", "!", "die", "Wei\u00b7ber", "selbst", ",", "die", "Wei\u00b7ber", "mu\u00df", "ich", "scheun", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "XY", "$.", "ART", "NN", "ADV", "$,", "ART", "NN", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Freit! lehrt die Nachbarin. La\u00dft jeden schreiben, sagen,", "tokens": ["Freit", "!", "lehrt", "die", "Nach\u00b7ba\u00b7rin", ".", "La\u00dft", "je\u00b7den", "schrei\u00b7ben", ",", "sa\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["NN", "$.", "VVFIN", "ART", "NN", "$.", "VVIMP", "PIS", "VVINF", "$,", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Ja singen, wenn er singen kann,", "tokens": ["Ja", "sin\u00b7gen", ",", "wenn", "er", "sin\u00b7gen", "kann", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "VVFIN", "$,", "KOUS", "PPER", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.23": {"text": "Es sei ein M\u00e4rchen von acht Tagen!", "tokens": ["Es", "sei", "ein", "M\u00e4r\u00b7chen", "von", "acht", "Ta\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "APPR", "CARD", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.24": {"text": "Am neunten hebt gewi\u00df sich schon ein neues an.", "tokens": ["Am", "neun\u00b7ten", "hebt", "ge\u00b7wi\u00df", "sich", "schon", "ein", "neu\u00b7es", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "VVFIN", "ADV", "PRF", "ADV", "ART", "ADJA", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Das soll mein Esel demonstriren.", "tokens": ["Das", "soll", "mein", "E\u00b7sel", "de\u00b7monst\u00b7ri\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PPOSAT", "NN", "VVINF", "$."], "meter": "+---+----", "measure": "dactylic.init"}, "line.26": {"text": "Den f\u00e4rb' ich euch so gr\u00fcn, als meinen Papagei.", "tokens": ["Den", "f\u00e4rb'", "ich", "euch", "so", "gr\u00fcn", ",", "als", "mei\u00b7nen", "Pa\u00b7pa\u00b7gei", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "PPER", "ADV", "ADJD", "$,", "KOUS", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Dann soll er durch die Stadt spazieren,", "tokens": ["Dann", "soll", "er", "durch", "die", "Stadt", "spa\u00b7zie\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.28": {"text": "Damit er allen sichtbar sei,", "tokens": ["Da\u00b7mit", "er", "al\u00b7len", "sicht\u00b7bar", "sei", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIAT", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.29": {"text": "Und alle wird das gro\u00dfe Wunder r\u00fchren.", "tokens": ["Und", "al\u00b7le", "wird", "das", "gro\u00b7\u00dfe", "Wun\u00b7der", "r\u00fch\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VAFIN", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.30": {"text": "Das tr\u00e4ge Thier wird auf den Markt gebracht,", "tokens": ["Das", "tr\u00e4\u00b7ge", "Thier", "wird", "auf", "den", "Markt", "ge\u00b7bracht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.31": {"text": "Der P\u00f6bel l\u00e4uft herzu, bewundert, gafft und lacht.", "tokens": ["Der", "P\u00f6\u00b7bel", "l\u00e4uft", "her\u00b7zu", ",", "be\u00b7wun\u00b7dert", ",", "gafft", "und", "lacht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "$,", "VVPP", "$,", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Wie? ruft man, k\u00f6nnen Esel gr\u00fcnen?", "tokens": ["Wie", "?", "ruft", "man", ",", "k\u00f6n\u00b7nen", "E\u00b7sel", "gr\u00fc\u00b7nen", "?"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "$.", "VVFIN", "PIS", "$,", "VMFIN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.33": {"text": "Das h\u00e4tt' ich nimmermehr gedacht ...", "tokens": ["Das", "h\u00e4tt'", "ich", "nim\u00b7mer\u00b7mehr", "ge\u00b7dacht", "..."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.34": {"text": "O kommt doch, seht! ... Sollt' aber diese Tracht", "tokens": ["O", "kommt", "doch", ",", "seht", "!", "...", "Sollt'", "a\u00b7ber", "die\u00b7se", "Tracht"], "token_info": ["word", "word", "word", "punct", "word", "punct", "punct", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "ADV", "$,", "VVFIN", "$.", "$(", "VMFIN", "ADV", "PDAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.35": {"text": "Nicht mehr f\u00fcr edle Pferde dienen?", "tokens": ["Nicht", "mehr", "f\u00fcr", "ed\u00b7le", "Pfer\u00b7de", "die\u00b7nen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.36": {"text": "Doch alles ist recht sch\u00f6n, wie die Natur es macht ...", "tokens": ["Doch", "al\u00b7les", "ist", "recht", "sch\u00f6n", ",", "wie", "die", "Na\u00b7tur", "es", "macht", "..."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VAFIN", "ADJD", "ADJD", "$,", "PWAV", "ART", "NN", "PPER", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "Was? die Natur? Es ist ein Werk der Kunst ...", "tokens": ["Was", "?", "die", "Na\u00b7tur", "?", "Es", "ist", "ein", "Werk", "der", "Kunst", "..."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "$.", "ART", "NN", "$.", "PPER", "VAFIN", "ART", "NN", "ART", "NN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.38": {"text": "Der Kunst? o nein, Gevatter, nein, mit Gunst!", "tokens": ["Der", "Kunst", "?", "o", "nein", ",", "Ge\u00b7vat\u00b7ter", ",", "nein", ",", "mit", "Gunst", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$.", "FM", "PTKANT", "$,", "NN", "$,", "PTKANT", "$,", "APPR", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.39": {"text": "Er ist das, was er ist, und k\u00f6mmt uns aus dem Lande", "tokens": ["Er", "ist", "das", ",", "was", "er", "ist", ",", "und", "k\u00f6mmt", "uns", "aus", "dem", "Lan\u00b7de"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PDS", "$,", "PWS", "PPER", "VAFIN", "$,", "KON", "VVFIN", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.40": {"text": "Der gr\u00fcnen Esel her. Ich wei\u00df nicht, wie es hei\u00dft:", "tokens": ["Der", "gr\u00fc\u00b7nen", "E\u00b7sel", "her", ".", "Ich", "wei\u00df", "nicht", ",", "wie", "es", "hei\u00dft", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKVZ", "$.", "PPER", "VVFIN", "PTKNEG", "$,", "PWAV", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.41": {"text": "Doch, wenn Er mir das Gegentheil beweist,", "tokens": ["Doch", ",", "wenn", "Er", "mir", "das", "Ge\u00b7gen\u00b7theil", "be\u00b7weist", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "PPER", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.42": {"text": "So gleicht im Kirchspiel Ihm kein Doctor an Verstande ...", "tokens": ["So", "gleicht", "im", "Kirch\u00b7spiel", "Ihm", "kein", "Doc\u00b7tor", "an", "Ver\u00b7stan\u00b7de", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPRART", "NN", "PPER", "PIAT", "NN", "APPR", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.43": {"text": "Der Herr hat Recht; so sprach ein Bader, der gereist,", "tokens": ["Der", "Herr", "hat", "Recht", ";", "so", "sprach", "ein", "Ba\u00b7der", ",", "der", "ge\u00b7reist", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "NN", "$.", "ADV", "VVFIN", "ART", "NN", "$,", "PRELS", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.44": {"text": "Und ein Gelehrter war. Ich habe, wider Hoffen,", "tokens": ["Und", "ein", "Ge\u00b7lehr\u00b7ter", "war", ".", "Ich", "ha\u00b7be", ",", "wi\u00b7der", "Hof\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VAFIN", "$.", "PPER", "VAFIN", "$,", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.45": {"text": "In Capo Verde selbst dergleichen angetroffen.", "tokens": ["In", "Ca\u00b7po", "Ver\u00b7de", "selbst", "derg\u00b7lei\u00b7chen", "an\u00b7ge\u00b7trof\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "NN", "ADV", "PIS", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.46": {"text": "Als F\u00fcllen sind sie gelb und blau,", "tokens": ["Als", "F\u00fcl\u00b7len", "sind", "sie", "gelb", "und", "blau", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "VAFIN", "PPER", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.47": {"text": "Hernachmals gr\u00fcn. Ich kenne sie genau.", "tokens": ["Her\u00b7nach\u00b7mals", "gr\u00fcn", ".", "Ich", "ken\u00b7ne", "sie", "ge\u00b7nau", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$.", "PPER", "VVFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.48": {"text": "Dort hielt ich anfangs auch den Mund erstaunend offen;", "tokens": ["Dort", "hielt", "ich", "an\u00b7fangs", "auch", "den", "Mund", "er\u00b7stau\u00b7nend", "of\u00b7fen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ADV", "ART", "NN", "VVPP", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.49": {"text": "Allein weit mehr, als ich in Chymia", "tokens": ["Al\u00b7lein", "weit", "mehr", ",", "als", "ich", "in", "Chy\u00b7mia"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "ADV", "$,", "KOUS", "PPER", "APPR", "NE"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.50": {"text": "Gar einen gr\u00fcnen L\u00f6wen sah.", "tokens": ["Gar", "ei\u00b7nen", "gr\u00fc\u00b7nen", "L\u00f6\u00b7wen", "sah", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.51": {"text": "Ach! seufzt' ein Weib, das gerne prophezeite,", "tokens": ["Ach", "!", "seufzt'", "ein", "Weib", ",", "das", "ger\u00b7ne", "pro\u00b7phe\u00b7zei\u00b7te", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ITJ", "$.", "VVFIN", "ART", "NN", "$,", "PRELS", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.52": {"text": "Das Ungl\u00fccksthier! beschaut es nur, ihr Leute!", "tokens": ["Das", "Un\u00b7gl\u00fcckst\u00b7hier", "!", "be\u00b7schaut", "es", "nur", ",", "ihr", "Leu\u00b7te", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$.", "VVFIN", "PPER", "ADV", "$,", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.53": {"text": "Mir hat, vor kurzer Zeit, von gr\u00fcnem Vieh getr\u00e4umt,", "tokens": ["Mir", "hat", ",", "vor", "kur\u00b7zer", "Zeit", ",", "von", "gr\u00fc\u00b7nem", "Vieh", "ge\u00b7tr\u00e4umt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "APPR", "ADJA", "NN", "$,", "APPR", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.54": {"text": "Und, leider! dieser Traum war gar nicht ungereimt,", "tokens": ["Und", ",", "lei\u00b7der", "!", "die\u00b7ser", "Traum", "war", "gar", "nicht", "un\u00b7ge\u00b7reimt", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "ADV", "$.", "PDAT", "NN", "VAFIN", "ADV", "PTKNEG", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.55": {"text": "Denn, seht! er ist erf\u00fcllt. Ein Ungl\u00fcck droht den L\u00e4ndern,", "tokens": ["Denn", ",", "seht", "!", "er", "ist", "er\u00b7f\u00fcllt", ".", "Ein", "Un\u00b7gl\u00fcck", "droht", "den", "L\u00e4n\u00b7dern", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "VVFIN", "$.", "PPER", "VAFIN", "VVPP", "$.", "ART", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.56": {"text": "Wo Thiere so die Farben \u00e4ndern.", "tokens": ["Wo", "Thie\u00b7re", "so", "die", "Far\u00b7ben", "\u00e4n\u00b7dern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.57": {"text": "Nicht wahr? Hier lie\u00dfen sich schneewei\u00dfe M\u00e4use sehn,", "tokens": ["Nicht", "wahr", "?", "Hier", "lie\u00b7\u00dfen", "sich", "schnee\u00b7wei\u00b7\u00dfe", "M\u00e4u\u00b7se", "sehn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "PTKVZ", "$.", "ADV", "VVFIN", "PRF", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.58": {"text": "Wir sahen bald hernach die besten K\u00fche schwinden.", "tokens": ["Wir", "sa\u00b7hen", "bald", "her\u00b7nach", "die", "bes\u00b7ten", "K\u00fc\u00b7he", "schwin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.59": {"text": "Seitdem sich um Paris die Purpurkatzen finden,", "tokens": ["Seit\u00b7dem", "sich", "um", "Pa\u00b7ris", "die", "Pur\u00b7pur\u00b7kat\u00b7zen", "fin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PRF", "APPR", "NE", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.60": {"text": "Soll auch die Falschheit dort recht sehr im Schwange gehn;", "tokens": ["Soll", "auch", "die", "Falschheit", "dort", "recht", "sehr", "im", "Schwan\u00b7ge", "gehn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "ART", "NN", "ADV", "ADV", "ADV", "APPRART", "NN", "VVINF", "$."], "meter": "+--+--+-+-+", "measure": "dactylic.di.plus"}, "line.61": {"text": "Kein Wunder, da\u00df daher Ha\u00df, Krieg und Mord entstehn.", "tokens": ["Kein", "Wun\u00b7der", ",", "da\u00df", "da\u00b7her", "Ha\u00df", ",", "Krieg", "und", "Mord", "ent\u00b7stehn", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "$,", "KOUS", "PAV", "NN", "$,", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Sechs Tage zeigt er sich den Haubt- und Nebengassen,", "tokens": ["Sechs", "Ta\u00b7ge", "zeigt", "er", "sich", "den", "Haub\u00b7t", "und", "Ne\u00b7ben\u00b7gas\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "VVFIN", "PPER", "PRF", "ART", "TRUNC", "KON", "NN", "$,"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Und kein Rhinoceros reizt mehr die Neubegier.", "tokens": ["Und", "kein", "Rhi\u00b7no\u00b7ce\u00b7ros", "reizt", "mehr", "die", "Neu\u00b7be\u00b7gier", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Bald aber wird auch er so aus der Acht gelassen,", "tokens": ["Bald", "a\u00b7ber", "wird", "auch", "er", "so", "aus", "der", "Acht", "ge\u00b7las\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VAFIN", "ADV", "PPER", "ADV", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Als das gemeinste M\u00fcllerthier.", "tokens": ["Als", "das", "ge\u00b7meins\u00b7te", "M\u00fcl\u00b7ler\u00b7thier", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}