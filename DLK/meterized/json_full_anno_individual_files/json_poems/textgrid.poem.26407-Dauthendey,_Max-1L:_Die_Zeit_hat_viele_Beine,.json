{"textgrid.poem.26407": {"metadata": {"author": {"name": "Dauthendey, Max", "birth": "N.A.", "death": "N.A."}, "title": "1L: Die Zeit hat viele Beine,", "genre": "verse", "period": "N.A.", "pub_year": 1892, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Die Zeit hat viele Beine,", "tokens": ["Die", "Zeit", "hat", "vie\u00b7le", "Bei\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PIAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Zwei kannst Du an Dir sehn.", "tokens": ["Zwei", "kannst", "Du", "an", "Dir", "sehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "VMFIN", "PPER", "APPR", "PPER", "VVINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Zum Kommen ist das eine,", "tokens": ["Zum", "Kom\u00b7men", "ist", "das", "ei\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VAFIN", "ART", "ART", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Das andere zum Gehn.", "tokens": ["Das", "an\u00b7de\u00b7re", "zum", "Gehn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "APPRART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Ist Jemand fortgegangen,", "tokens": ["Ist", "Je\u00b7mand", "fort\u00b7ge\u00b7gan\u00b7gen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "So sieht man sich allein.", "tokens": ["So", "sieht", "man", "sich", "al\u00b7lein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "PRF", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Hast Du an ihm gehangen,", "tokens": ["Hast", "Du", "an", "ihm", "ge\u00b7han\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPR", "PPER", "VVPP", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.4": {"text": "Fallen Dir Tr\u00e4nen ein.", "tokens": ["Fal\u00b7len", "Dir", "Tr\u00e4\u00b7nen", "ein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "NN", "PTKVZ", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}}, "stanza.3": {"line.1": {"text": "So weinte auch Johanna,", "tokens": ["So", "wein\u00b7te", "auch", "Jo\u00b7han\u00b7na", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "NE", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Beweinte ihren Franz.", "tokens": ["Be\u00b7wein\u00b7te", "ih\u00b7ren", "Franz."], "token_info": ["word", "word", "abbreviation"], "pos": ["VVFIN", "PPOSAT", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.3": {"text": "Ihr Herz, sonst s\u00fc\u00df wie Manna,", "tokens": ["Ihr", "Herz", ",", "sonst", "s\u00fc\u00df", "wie", "Man\u00b7na", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "ADV", "ADJD", "KOKOM", "NE", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "Verbitterte sich ganz.", "tokens": ["Ver\u00b7bit\u00b7ter\u00b7te", "sich", "ganz", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Am Sarg sa\u00df sie daneben", "tokens": ["Am", "Sarg", "sa\u00df", "sie", "da\u00b7ne\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "VVFIN", "PPER", "PAV"], "meter": "-+--+--", "measure": "iambic.di.relaxed"}, "line.2": {"text": "Mit T\u00fcchern in der Hand.", "tokens": ["Mit", "T\u00fc\u00b7chern", "in", "der", "Hand", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und Tr\u00e4nen wollt' sie geben,", "tokens": ["Und", "Tr\u00e4\u00b7nen", "wollt'", "sie", "ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VMFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Bis ihr das Aug' leer stand.", "tokens": ["Bis", "ihr", "das", "Aug'", "leer", "stand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ART", "NN", "ADJD", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Dann hat sich ein Gedanke", "tokens": ["Dann", "hat", "sich", "ein", "Ge\u00b7dan\u00b7ke"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PRF", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Zu Hanna hingesetzt.", "tokens": ["Zu", "Han\u00b7na", "hin\u00b7ge\u00b7setzt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NE", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Er pufft sie in die Flanke,", "tokens": ["Er", "pufft", "sie", "in", "die", "Flan\u00b7ke", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Sie hat's nicht untersch\u00e4tzt.", "tokens": ["Sie", "hat's", "nicht", "un\u00b7ter\u00b7sch\u00e4tzt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Sie sammelt sich entschlossen", "tokens": ["Sie", "sam\u00b7melt", "sich", "ent\u00b7schlos\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PRF", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Und nickt voll Seelenruh'", "tokens": ["Und", "nickt", "voll", "See\u00b7len\u00b7ruh'"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADJD", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ihm, der sie angesto\u00dfen,", "tokens": ["Ihm", ",", "der", "sie", "an\u00b7ge\u00b7sto\u00b7\u00dfen", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PRELS", "PPER", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Verst\u00e4ndnisinnig zu.", "tokens": ["Ver\u00b7st\u00e4nd\u00b7ni\u00b7sin\u00b7nig", "zu", "."], "token_info": ["word", "word", "punct"], "pos": ["ADJD", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Sie nimmt ein Kohlenbecken,", "tokens": ["Sie", "nimmt", "ein", "Koh\u00b7len\u00b7be\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "F\u00fcllt's mit Holzkohlen an.", "tokens": ["F\u00fcllt's", "mit", "Holz\u00b7koh\u00b7len", "an", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "NN", "PTKVZ", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Den Tod soll das bezwecken,", "tokens": ["Den", "Tod", "soll", "das", "be\u00b7zwe\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PDS", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Wenn man nicht anders kann.", "tokens": ["Wenn", "man", "nicht", "an\u00b7ders", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PTKNEG", "ADV", "VMFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Am Fensterbrett, da lachen", "tokens": ["Am", "Fens\u00b7ter\u00b7brett", ",", "da", "la\u00b7chen"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["APPRART", "NN", "$,", "ADV", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Die Blumenst\u00f6ck' ihr zu;", "tokens": ["Die", "Blu\u00b7men\u00b7st\u00f6ck", "ihr", "zu", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Gelbe Kanari machen", "tokens": ["Gel\u00b7be", "Ka\u00b7na\u00b7ri", "ma\u00b7chen"], "token_info": ["word", "word", "word"], "pos": ["ADJA", "NN", "VVINF"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.4": {"text": "Laut singend viel Getu'.", "tokens": ["Laut", "sin\u00b7gend", "viel", "Ge\u00b7tu'", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJD", "PIAT", "NN", "$."], "meter": "++-+-+", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Und da\u00df der Tod vollkommen,", "tokens": ["Und", "da\u00df", "der", "Tod", "voll\u00b7kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Trinkt sie 'nen Liter Rum.", "tokens": ["Trinkt", "sie", "'nen", "Li\u00b7ter", "Rum", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJA", "NN", "NE", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Der Tod hat Platz genommen,", "tokens": ["Der", "Tod", "hat", "Platz", "ge\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "NN", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und doppelt kam sie um.", "tokens": ["Und", "dop\u00b7pelt", "kam", "sie", "um", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "Zu Franz kam dann Johannen", "tokens": ["Zu", "Franz", "kam", "dann", "Jo\u00b7han\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "NE", "VVFIN", "ADV", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Im Himmelbette an.", "tokens": ["Im", "Him\u00b7mel\u00b7bet\u00b7te", "an", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Niemand durft' sie verdammen,", "tokens": ["Nie\u00b7mand", "durft'", "sie", "ver\u00b7dam\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "PPER", "VVINF", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.4": {"text": "Da sie's aus Lieb' getan.", "tokens": ["Da", "sie's", "aus", "Lieb'", "ge\u00b7tan", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "Nur ist ihr Himmelsn\u00e4schen", "tokens": ["Nur", "ist", "ihr", "Him\u00b7mels\u00b7n\u00e4\u00b7schen"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPOSAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Jetzt rot \u2013 Franz l\u00e4chelt stumm.", "tokens": ["Jetzt", "rot", "\u2013", "Franz", "l\u00e4\u00b7chelt", "stumm", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$(", "NE", "VVFIN", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Sie leert noch oft ein Gl\u00e4schen,", "tokens": ["Sie", "leert", "noch", "oft", "ein", "Gl\u00e4s\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Gew\u00f6hnt ans Liter Rum.", "tokens": ["Ge\u00b7w\u00f6hnt", "ans", "Li\u00b7ter", "Rum", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVPP", "APPRART", "NN", "NE", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "Die Zeit hat viele Beine,", "tokens": ["Die", "Zeit", "hat", "vie\u00b7le", "Bei\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PIAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Zwei kannst Du an Dir sehn.", "tokens": ["Zwei", "kannst", "Du", "an", "Dir", "sehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "VMFIN", "PPER", "APPR", "PPER", "VVINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Zum Kommen ist das eine,", "tokens": ["Zum", "Kom\u00b7men", "ist", "das", "ei\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VAFIN", "ART", "ART", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Das andere zum Gehn.", "tokens": ["Das", "an\u00b7de\u00b7re", "zum", "Gehn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "APPRART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.13": {"line.1": {"text": "Ist Jemand fortgegangen,", "tokens": ["Ist", "Je\u00b7mand", "fort\u00b7ge\u00b7gan\u00b7gen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "So sieht man sich allein.", "tokens": ["So", "sieht", "man", "sich", "al\u00b7lein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "PRF", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Hast Du an ihm gehangen,", "tokens": ["Hast", "Du", "an", "ihm", "ge\u00b7han\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPR", "PPER", "VVPP", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.4": {"text": "Fallen Dir Tr\u00e4nen ein.", "tokens": ["Fal\u00b7len", "Dir", "Tr\u00e4\u00b7nen", "ein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "NN", "PTKVZ", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}}, "stanza.14": {"line.1": {"text": "So weinte auch Johanna,", "tokens": ["So", "wein\u00b7te", "auch", "Jo\u00b7han\u00b7na", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "NE", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Beweinte ihren Franz.", "tokens": ["Be\u00b7wein\u00b7te", "ih\u00b7ren", "Franz."], "token_info": ["word", "word", "abbreviation"], "pos": ["VVFIN", "PPOSAT", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.3": {"text": "Ihr Herz, sonst s\u00fc\u00df wie Manna,", "tokens": ["Ihr", "Herz", ",", "sonst", "s\u00fc\u00df", "wie", "Man\u00b7na", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "ADV", "ADJD", "KOKOM", "NE", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "Verbitterte sich ganz.", "tokens": ["Ver\u00b7bit\u00b7ter\u00b7te", "sich", "ganz", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.15": {"line.1": {"text": "Am Sarg sa\u00df sie daneben", "tokens": ["Am", "Sarg", "sa\u00df", "sie", "da\u00b7ne\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "VVFIN", "PPER", "PAV"], "meter": "-+--+--", "measure": "iambic.di.relaxed"}, "line.2": {"text": "Mit T\u00fcchern in der Hand.", "tokens": ["Mit", "T\u00fc\u00b7chern", "in", "der", "Hand", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und Tr\u00e4nen wollt' sie geben,", "tokens": ["Und", "Tr\u00e4\u00b7nen", "wollt'", "sie", "ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VMFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Bis ihr das Aug' leer stand.", "tokens": ["Bis", "ihr", "das", "Aug'", "leer", "stand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ART", "NN", "ADJD", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.16": {"line.1": {"text": "Dann hat sich ein Gedanke", "tokens": ["Dann", "hat", "sich", "ein", "Ge\u00b7dan\u00b7ke"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PRF", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Zu Hanna hingesetzt.", "tokens": ["Zu", "Han\u00b7na", "hin\u00b7ge\u00b7setzt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NE", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Er pufft sie in die Flanke,", "tokens": ["Er", "pufft", "sie", "in", "die", "Flan\u00b7ke", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Sie hat's nicht untersch\u00e4tzt.", "tokens": ["Sie", "hat's", "nicht", "un\u00b7ter\u00b7sch\u00e4tzt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.17": {"line.1": {"text": "Sie sammelt sich entschlossen", "tokens": ["Sie", "sam\u00b7melt", "sich", "ent\u00b7schlos\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PRF", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Und nickt voll Seelenruh'", "tokens": ["Und", "nickt", "voll", "See\u00b7len\u00b7ruh'"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADJD", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ihm, der sie angesto\u00dfen,", "tokens": ["Ihm", ",", "der", "sie", "an\u00b7ge\u00b7sto\u00b7\u00dfen", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PRELS", "PPER", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Verst\u00e4ndnisinnig zu.", "tokens": ["Ver\u00b7st\u00e4nd\u00b7ni\u00b7sin\u00b7nig", "zu", "."], "token_info": ["word", "word", "punct"], "pos": ["ADJD", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.18": {"line.1": {"text": "Sie nimmt ein Kohlenbecken,", "tokens": ["Sie", "nimmt", "ein", "Koh\u00b7len\u00b7be\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "F\u00fcllt's mit Holzkohlen an.", "tokens": ["F\u00fcllt's", "mit", "Holz\u00b7koh\u00b7len", "an", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "NN", "PTKVZ", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Den Tod soll das bezwecken,", "tokens": ["Den", "Tod", "soll", "das", "be\u00b7zwe\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PDS", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Wenn man nicht anders kann.", "tokens": ["Wenn", "man", "nicht", "an\u00b7ders", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PTKNEG", "ADV", "VMFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.19": {"line.1": {"text": "Am Fensterbrett, da lachen", "tokens": ["Am", "Fens\u00b7ter\u00b7brett", ",", "da", "la\u00b7chen"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["APPRART", "NN", "$,", "ADV", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Die Blumenst\u00f6ck' ihr zu;", "tokens": ["Die", "Blu\u00b7men\u00b7st\u00f6ck", "ihr", "zu", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Gelbe Kanari machen", "tokens": ["Gel\u00b7be", "Ka\u00b7na\u00b7ri", "ma\u00b7chen"], "token_info": ["word", "word", "word"], "pos": ["ADJA", "NN", "VVINF"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.4": {"text": "Laut singend viel Getu'.", "tokens": ["Laut", "sin\u00b7gend", "viel", "Ge\u00b7tu'", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJD", "PIAT", "NN", "$."], "meter": "++-+-+", "measure": "iambic.tri"}}, "stanza.20": {"line.1": {"text": "Und da\u00df der Tod vollkommen,", "tokens": ["Und", "da\u00df", "der", "Tod", "voll\u00b7kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Trinkt sie 'nen Liter Rum.", "tokens": ["Trinkt", "sie", "'nen", "Li\u00b7ter", "Rum", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJA", "NN", "NE", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Der Tod hat Platz genommen,", "tokens": ["Der", "Tod", "hat", "Platz", "ge\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "NN", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und doppelt kam sie um.", "tokens": ["Und", "dop\u00b7pelt", "kam", "sie", "um", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.21": {"line.1": {"text": "Zu Franz kam dann Johannen", "tokens": ["Zu", "Franz", "kam", "dann", "Jo\u00b7han\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "NE", "VVFIN", "ADV", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Im Himmelbette an.", "tokens": ["Im", "Him\u00b7mel\u00b7bet\u00b7te", "an", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Niemand durft' sie verdammen,", "tokens": ["Nie\u00b7mand", "durft'", "sie", "ver\u00b7dam\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "PPER", "VVINF", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.4": {"text": "Da sie's aus Lieb' getan.", "tokens": ["Da", "sie's", "aus", "Lieb'", "ge\u00b7tan", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.22": {"line.1": {"text": "Nur ist ihr Himmelsn\u00e4schen", "tokens": ["Nur", "ist", "ihr", "Him\u00b7mels\u00b7n\u00e4\u00b7schen"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPOSAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Jetzt rot \u2013 Franz l\u00e4chelt stumm.", "tokens": ["Jetzt", "rot", "\u2013", "Franz", "l\u00e4\u00b7chelt", "stumm", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$(", "NE", "VVFIN", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Sie leert noch oft ein Gl\u00e4schen,", "tokens": ["Sie", "leert", "noch", "oft", "ein", "Gl\u00e4s\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Gew\u00f6hnt ans Liter Rum.", "tokens": ["Ge\u00b7w\u00f6hnt", "ans", "Li\u00b7ter", "Rum", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVPP", "APPRART", "NN", "NE", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}}}}