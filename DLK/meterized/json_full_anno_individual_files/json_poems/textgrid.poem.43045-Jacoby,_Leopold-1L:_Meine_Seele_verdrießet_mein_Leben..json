{"textgrid.poem.43045": {"metadata": {"author": {"name": "Jacoby, Leopold", "birth": "N.A.", "death": "N.A."}, "title": "1L: Meine Seele verdrie\u00dfet mein Leben.", "genre": "verse", "period": "N.A.", "pub_year": 1867, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Meine Seele verdrie\u00dfet mein Leben.", "tokens": ["Mei\u00b7ne", "See\u00b7le", "ver\u00b7drie\u00b7\u00dfet", "mein", "Le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPOSAT", "NN", "$."], "meter": "+-+--+--+-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Ich will meine Klage erschallen lassen", "tokens": ["Ich", "will", "mei\u00b7ne", "Kla\u00b7ge", "er\u00b7schal\u00b7len", "las\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PPOSAT", "NN", "VVINF", "VVINF"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Und reden von der Betr\u00fcbni\u00df meiner Seele.", "tokens": ["Und", "re\u00b7den", "von", "der", "Be\u00b7tr\u00fcb\u00b7ni\u00df", "mei\u00b7ner", "See\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Ein Gott hat mir den Mund ge\u00f6ffnet,", "tokens": ["Ein", "Gott", "hat", "mir", "den", "Mund", "ge\u00b7\u00f6ff\u00b7net", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Ich kann nicht stumm sein.", "tokens": ["Ich", "kann", "nicht", "stumm", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PTKNEG", "ADJD", "VAINF", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.6": {"text": "Die Vorsehung hat mir ein Schwert gegeben,", "tokens": ["Die", "Vor\u00b7se\u00b7hung", "hat", "mir", "ein", "Schwert", "ge\u00b7ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Ich will es gebrauchen.", "tokens": ["Ich", "will", "es", "ge\u00b7brau\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.8": {"text": "Darum will ich reden, wer es h\u00f6ren wird,", "tokens": ["Da\u00b7rum", "will", "ich", "re\u00b7den", ",", "wer", "es", "h\u00f6\u00b7ren", "wird", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VMFIN", "PPER", "VVINF", "$,", "PWS", "PPER", "VVINF", "VAFIN", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.9": {"text": "Dem werden seine beiden Ohren gellen.", "tokens": ["Dem", "wer\u00b7den", "sei\u00b7ne", "bei\u00b7den", "Oh\u00b7ren", "gel\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPOSAT", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Siehst du den Ackersknecht dort?", "tokens": ["Siehst", "du", "den", "A\u00b7ckers\u00b7knecht", "dort", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "ADV", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Auf dem Felde stehet er neben dem Pflug,", "tokens": ["Auf", "dem", "Fel\u00b7de", "ste\u00b7het", "er", "ne\u00b7ben", "dem", "Pflug", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.3": {"text": "Neben Pferd und Rind.", "tokens": ["Ne\u00b7ben", "Pferd", "und", "Rind", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.4": {"text": "Und er spricht mit dem Rind,", "tokens": ["Und", "er", "spricht", "mit", "dem", "Rind", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.5": {"text": "Und das Thier dreht sich um", "tokens": ["Und", "das", "Thier", "dreht", "sich", "um"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "VVFIN", "PRF", "APPR"], "meter": "--++-+", "measure": "anapaest.init"}, "line.6": {"text": "Und br\u00fcllt", "tokens": ["Und", "br\u00fcllt"], "token_info": ["word", "word"], "pos": ["KON", "VVFIN"], "meter": "-+", "measure": "iambic.single"}, "line.7": {"text": "Und glotzt ihn an.", "tokens": ["Und", "glotzt", "ihn", "an", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.8": {"text": "Und er stiert ins Blaue hinein. \u2013", "tokens": ["Und", "er", "stiert", "ins", "Blau\u00b7e", "hin\u00b7ein", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "PPER", "VVFIN", "APPRART", "ADJA", "PTKVZ", "$.", "$("], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.9": {"text": "Die Sonne brennt,", "tokens": ["Die", "Son\u00b7ne", "brennt", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.10": {"text": "So ist ihm hei\u00df.", "tokens": ["So", "ist", "ihm", "hei\u00df", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.11": {"text": "Der Wind weht kalt,", "tokens": ["Der", "Wind", "weht", "kalt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJD", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.12": {"text": "So friert ihn.", "tokens": ["So", "friert", "ihn", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.13": {"text": "Das ist die Erkenntni\u00df, die man ihm gegeben.", "tokens": ["Das", "ist", "die", "Er\u00b7kennt\u00b7ni\u00df", ",", "die", "man", "ihm", "ge\u00b7ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "$,", "PRELS", "PIS", "PPER", "VVPP", "$."], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.14": {"text": "Und er peitscht auf das Pferd", "tokens": ["Und", "er", "peitscht", "auf", "das", "Pferd"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "APPR", "ART", "NN"], "meter": "--+--+", "measure": "anapaest.di.plus"}, "line.15": {"text": "Und er schl\u00e4gt das Rind;", "tokens": ["Und", "er", "schl\u00e4gt", "das", "Rind", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.16": {"text": "Aber die Peitsche, die ihm im Nacken sitzt, sieht er nicht,", "tokens": ["A\u00b7ber", "die", "Peit\u00b7sche", ",", "die", "ihm", "im", "Na\u00b7cken", "sitzt", ",", "sieht", "er", "nicht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "PRELS", "PPER", "APPRART", "NN", "VVFIN", "$,", "VVFIN", "PPER", "PTKNEG", "$,"], "meter": "+--+-+--+--+-+", "measure": "iambic.hexa.invert"}, "line.17": {"text": "Und wie er selber geschlagen wird, merkt er nicht,", "tokens": ["Und", "wie", "er", "sel\u00b7ber", "ge\u00b7schla\u00b7gen", "wird", ",", "merkt", "er", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPER", "ADV", "VVPP", "VAFIN", "$,", "VVFIN", "PPER", "PTKNEG", "$,"], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.18": {"text": "Und welch' ein Menschenleben er dahinlebt,", "tokens": ["Und", "welch'", "ein", "Men\u00b7schen\u00b7le\u00b7ben", "er", "da\u00b7hin\u00b7lebt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAT", "ART", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.19": {"text": "Das wei\u00df er nimmermehr.", "tokens": ["Das", "wei\u00df", "er", "nim\u00b7mer\u00b7mehr", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Siehst du die Bergleute dort?", "tokens": ["Siehst", "du", "die", "Berg\u00b7leu\u00b7te", "dort", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "ADV", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.2": {"text": "Beim D\u00e4mmermorgen aus den H\u00fctten kommen sie,", "tokens": ["Beim", "D\u00e4m\u00b7mer\u00b7mor\u00b7gen", "aus", "den", "H\u00fct\u00b7ten", "kom\u00b7men", "sie", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPR", "ART", "NN", "VVFIN", "PPER", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und das Grubenlicht blinkt,", "tokens": ["Und", "das", "Gru\u00b7ben\u00b7licht", "blinkt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "$,"], "meter": "--+--+", "measure": "anapaest.di.plus"}, "line.4": {"text": "Und wenn sie niederfahren, sagen sie gl\u00fcckauf!", "tokens": ["Und", "wenn", "sie", "nie\u00b7der\u00b7fah\u00b7ren", ",", "sa\u00b7gen", "sie", "gl\u00fcc\u00b7kauf", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "VVINF", "$,", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Aber auf ihren Gesichtern da wohnt der Gram,", "tokens": ["A\u00b7ber", "auf", "ih\u00b7ren", "Ge\u00b7sich\u00b7tern", "da", "wohnt", "der", "Gram", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPOSAT", "NN", "ADV", "VVFIN", "ART", "NN", "$,"], "meter": "+--+--+--+-+", "measure": "dactylic.tri.plus"}, "line.6": {"text": "Und in ihren H\u00fctten sieht es j\u00e4mmerlich aus.", "tokens": ["Und", "in", "ih\u00b7ren", "H\u00fct\u00b7ten", "sieht", "es", "j\u00e4m\u00b7mer\u00b7lich", "aus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPOSAT", "NN", "VVFIN", "PPER", "ADJD", "PTKVZ", "$."], "meter": "+-+-+-+-+--+", "measure": "iambic.hexa.chol"}, "line.7": {"text": "Lebendige Leichen sah ich sie in die Erde steigen,", "tokens": ["Le\u00b7ben\u00b7di\u00b7ge", "Lei\u00b7chen", "sah", "ich", "sie", "in", "die", "Er\u00b7de", "stei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVFIN", "PPER", "PPER", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "+---+-+--+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.8": {"text": "Lebendige Leichen kamen sie wieder hervor.", "tokens": ["Le\u00b7ben\u00b7di\u00b7ge", "Lei\u00b7chen", "ka\u00b7men", "sie", "wie\u00b7der", "her\u00b7vor", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVFIN", "PPER", "ADV", "PTKVZ", "$."], "meter": "+---+-+--+--+", "measure": "trochaic.penta.relaxed"}, "line.9": {"text": "Sie k\u00f6nnen nicht leben", "tokens": ["Sie", "k\u00f6n\u00b7nen", "nicht", "le\u00b7ben"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PTKNEG", "VVINF"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.10": {"text": "Und wollen doch nicht sterben.", "tokens": ["Und", "wol\u00b7len", "doch", "nicht", "ster\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ADV", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.11": {"text": "Und ihre Kinder und Enkel m\u00fcssen sie sehen", "tokens": ["Und", "ih\u00b7re", "Kin\u00b7der", "und", "En\u00b7kel", "m\u00fcs\u00b7sen", "sie", "se\u00b7hen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "KON", "NN", "VMFIN", "PPER", "VVINF"], "meter": "-+-+--+-+--+-", "measure": "iambic.penta.relaxed"}, "line.12": {"text": "Erbarmungslos in dasselbe Elend hineinwandern.", "tokens": ["Er\u00b7bar\u00b7mungs\u00b7los", "in", "das\u00b7sel\u00b7be", "E\u00b7lend", "hin\u00b7ein\u00b7wan\u00b7dern", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "PDAT", "NN", "VVINF", "$."], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}}, "stanza.4": {"line.1": {"text": "Aber in den Stra\u00dfen der Stadt,", "tokens": ["A\u00b7ber", "in", "den", "Stra\u00b7\u00dfen", "der", "Stadt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "ART", "NN", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Darin die Menschen wimmeln,", "tokens": ["Da\u00b7rin", "die", "Men\u00b7schen", "wim\u00b7meln", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Wenn du dicht an den H\u00e4usern gehest,", "tokens": ["Wenn", "du", "dicht", "an", "den", "H\u00e4u\u00b7sern", "ge\u00b7hest", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Kannst du es h\u00f6ren:", "tokens": ["Kannst", "du", "es", "h\u00f6\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PPER", "VVINF", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.5": {"text": "Schlag auf Schlag und sp\u00e4t und fr\u00fch,", "tokens": ["Schlag", "auf", "Schlag", "und", "sp\u00e4t", "und", "fr\u00fch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "KON", "ADJD", "KON", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Wie das Herz gehet bei einem Fieberkranken,", "tokens": ["Wie", "das", "Herz", "ge\u00b7het", "bei", "ei\u00b7nem", "Fie\u00b7ber\u00b7kran\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.7": {"text": "So schl\u00e4gt der Webstuhl", "tokens": ["So", "schl\u00e4gt", "der", "Web\u00b7stuhl"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.8": {"text": "Und fliegt das Schiffchen durch,", "tokens": ["Und", "fliegt", "das", "Schiff\u00b7chen", "durch", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "Aber auf der Spule ist der Hunger aufgewickelt,", "tokens": ["A\u00b7ber", "auf", "der", "Spu\u00b7le", "ist", "der", "Hun\u00b7ger", "auf\u00b7ge\u00b7wi\u00b7ckelt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VAFIN", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}, "line.10": {"text": "Und der wird hineingewebt", "tokens": ["Und", "der", "wird", "hin\u00b7ein\u00b7ge\u00b7webt"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "VAFIN", "VVPP"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.11": {"text": "In die gl\u00e4nzenden Zeuge.", "tokens": ["In", "die", "gl\u00e4n\u00b7zen\u00b7den", "Zeu\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}}, "stanza.5": {"line.1": {"text": "In dem Saal,", "tokens": ["In", "dem", "Saal", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.2": {"text": "Wo die Kerzen hell schimmern", "tokens": ["Wo", "die", "Ker\u00b7zen", "hell", "schim\u00b7mern"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "ART", "NN", "ADJD", "VVINF"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "Und die seidnen Gew\u00e4nder knistern und rauschen,", "tokens": ["Und", "die", "seid\u00b7nen", "Ge\u00b7w\u00e4n\u00b7der", "knis\u00b7tern", "und", "rau\u00b7schen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "PPOSAT", "NN", "VVFIN", "KON", "VVFIN", "$,"], "meter": "--+--+-+--+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Da klingt der Reigen,", "tokens": ["Da", "klingt", "der", "Rei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.5": {"text": "Und die jungen Gesichter strahlen", "tokens": ["Und", "die", "jun\u00b7gen", "Ge\u00b7sich\u00b7ter", "strah\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN", "VVINF"], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.6": {"text": "Fr\u00f6hlich vom Tanz.", "tokens": ["Fr\u00f6h\u00b7lich", "vom", "Tanz", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "APPRART", "NN", "$."], "meter": "+--+", "measure": "iambic.di.chol"}, "line.7": {"text": "Und sie setzen sich Paar an Paar", "tokens": ["Und", "sie", "set\u00b7zen", "sich", "Paar", "an", "Paar"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "PRF", "NN", "APPR", "NN"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.8": {"text": "Mit munterem Lachen", "tokens": ["Mit", "mun\u00b7te\u00b7rem", "La\u00b7chen"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ADJA", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.9": {"text": "Zum schimmernden Mahle nieder,", "tokens": ["Zum", "schim\u00b7mern\u00b7den", "Mah\u00b7le", "nie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.10": {"text": "Und die Pfropfen knallen und die Gl\u00e4ser klingen.", "tokens": ["Und", "die", "Pfrop\u00b7fen", "knal\u00b7len", "und", "die", "Gl\u00e4\u00b7ser", "klin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVINF", "KON", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.11": {"text": "Aber auf das gl\u00e4nzende Gewebe dort f\u00e4llt mein Blick,", "tokens": ["A\u00b7ber", "auf", "das", "gl\u00e4n\u00b7zen\u00b7de", "Ge\u00b7we\u00b7be", "dort", "f\u00e4llt", "mein", "Blick", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "ADV", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "+-+-+---+--+-+", "measure": "trochaic.hexa.relaxed"}, "line.12": {"text": "Und daraus hervor grauenhaft", "tokens": ["Und", "da\u00b7raus", "her\u00b7vor", "grau\u00b7en\u00b7haft"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PAV", "PTKVZ", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Das Gespenst des Hungers grinst mich an", "tokens": ["Das", "Ge\u00b7spenst", "des", "Hun\u00b7gers", "grinst", "mich", "an"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "NN", "VVFIN", "PPER", "PTKVZ"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.14": {"text": "Ueber den Tisch.", "tokens": ["Ue\u00b7ber", "den", "Tisch", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$."], "meter": "+--+", "measure": "iambic.di.chol"}}, "stanza.6": {"line.1": {"text": "Siehst du das Geb\u00e4ude dort mit den vielen Fenstern?", "tokens": ["Siehst", "du", "das", "Ge\u00b7b\u00e4u\u00b7de", "dort", "mit", "den", "vie\u00b7len", "Fens\u00b7tern", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "ADV", "APPR", "ART", "PIAT", "NN", "$."], "meter": "+-+-+-+--+-+-", "measure": "trochaic.hexa.relaxed"}, "line.2": {"text": "Und die hohen Schornsteine ragen", "tokens": ["Und", "die", "ho\u00b7hen", "Schorn\u00b7stei\u00b7ne", "ra\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN", "VVINF"], "meter": "--+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "In den blauen Fr\u00fchlingshimmel hinein?", "tokens": ["In", "den", "blau\u00b7en", "Fr\u00fch\u00b7lings\u00b7him\u00b7mel", "hin\u00b7ein", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "--+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Drunten,", "tokens": ["Drun\u00b7ten", ","], "token_info": ["word", "punct"], "pos": ["NN", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.5": {"text": "In dem dunst'gen Raum,", "tokens": ["In", "dem", "dunst'\u00b7gen", "Raum", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.6": {"text": "Dort, wo der Dampf athmet,", "tokens": ["Dort", ",", "wo", "der", "Dampf", "ath\u00b7met", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PWAV", "ART", "NN", "VVFIN", "$,"], "meter": "++--+-", "measure": "trochaic.tri.relaxed"}, "line.7": {"text": "Da spricht der Kessel", "tokens": ["Da", "spricht", "der", "Kes\u00b7sel"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.8": {"text": "Mit zisch und zisch:", "tokens": ["Mit", "zisch", "und", "zisch", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.9": {"text": "Du bist ein Mensch!", "tokens": ["Du", "bist", "ein", "Mensch", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.10": {"text": "Du bist ein Mensch!", "tokens": ["Du", "bist", "ein", "Mensch", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.11": {"text": "La\u00df dich nicht schinden!", "tokens": ["La\u00df", "dich", "nicht", "schin\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "PTKNEG", "VVINF", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.12": {"text": "La\u00df dich nicht schinden!", "tokens": ["La\u00df", "dich", "nicht", "schin\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "PTKNEG", "VVINF", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.13": {"text": "Aber droben,", "tokens": ["A\u00b7ber", "dro\u00b7ben", ","], "token_info": ["word", "word", "punct"], "pos": ["KON", "ADV", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.14": {"text": "In dem weiten Saal,", "tokens": ["In", "dem", "wei\u00b7ten", "Saal", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.15": {"text": "Wo die Spuhlen schwirren", "tokens": ["Wo", "die", "Spuh\u00b7len", "schwir\u00b7ren"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "ART", "NN", "VVINF"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.16": {"text": "Und die R\u00e4der sausen,", "tokens": ["Und", "die", "R\u00e4\u00b7der", "sau\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.17": {"text": "Kinder stehen da", "tokens": ["Kin\u00b7der", "ste\u00b7hen", "da"], "token_info": ["word", "word", "word"], "pos": ["NN", "VVFIN", "ADV"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.18": {"text": "Und kn\u00fcpfen hastig", "tokens": ["Und", "kn\u00fcp\u00b7fen", "has\u00b7tig"], "token_info": ["word", "word", "word"], "pos": ["KON", "VVFIN", "ADJD"], "meter": "-+-+-", "measure": "iambic.di"}, "line.19": {"text": "Mit ihren H\u00e4ndchen,", "tokens": ["Mit", "ih\u00b7ren", "H\u00e4nd\u00b7chen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.20": {"text": "Und kn\u00fcpfen immer", "tokens": ["Und", "kn\u00fcp\u00b7fen", "im\u00b7mer"], "token_info": ["word", "word", "word"], "pos": ["KON", "VVFIN", "ADV"], "meter": "-+-+-", "measure": "iambic.di"}, "line.21": {"text": "Ohne Ende \u2013", "tokens": ["Oh\u00b7ne", "En\u00b7de", "\u2013"], "token_info": ["word", "word", "punct"], "pos": ["APPR", "NN", "$("], "meter": "+-+-", "measure": "trochaic.di"}, "line.22": {"text": "Und sind doch Menschen", "tokens": ["Und", "sind", "doch", "Men\u00b7schen"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VAFIN", "ADV", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.23": {"text": "Und sind Kinder.", "tokens": ["Und", "sind", "Kin\u00b7der", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "NN", "$."], "meter": "+-+-", "measure": "trochaic.di"}}, "stanza.7": {"line.1": {"text": "Aber unweit daneben, da zittert die Erde", "tokens": ["A\u00b7ber", "un\u00b7weit", "da\u00b7ne\u00b7ben", ",", "da", "zit\u00b7tert", "die", "Er\u00b7de"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "PAV", "$,", "ADV", "VVFIN", "ART", "NN"], "meter": "+-+-----+--+-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Vom Sto\u00df des Hammers", "tokens": ["Vom", "Sto\u00df", "des", "Ham\u00b7mers"], "token_info": ["word", "word", "word", "word"], "pos": ["APPRART", "NN", "ART", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.3": {"text": "Und von den eisernen Schl\u00e4gen,", "tokens": ["Und", "von", "den", "ei\u00b7ser\u00b7nen", "Schl\u00e4\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Und es zischelt und es haspelt und es klopft", "tokens": ["Und", "es", "zi\u00b7schelt", "und", "es", "has\u00b7pelt", "und", "es", "klopft"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "KON", "PPER", "VVFIN", "KON", "PPER", "VVFIN"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.5": {"text": "Wie tausend Hexengeister. \u2013", "tokens": ["Wie", "tau\u00b7send", "He\u00b7xen\u00b7geis\u00b7ter", ".", "\u2013"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["PWAV", "CARD", "NN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Es ist Abend, da t\u00f6nt ein Pfiff", "tokens": ["Es", "ist", "A\u00b7bend", ",", "da", "t\u00f6nt", "ein", "Pfiff"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "NN", "$,", "ADV", "VVFIN", "ART", "NN"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.7": {"text": "Gellend laut,", "tokens": ["Gel\u00b7lend", "laut", ","], "token_info": ["word", "word", "punct"], "pos": ["VVPP", "ADJD", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.8": {"text": "Und da kommen sie heraus, trotz'ge Gestalten.", "tokens": ["Und", "da", "kom\u00b7men", "sie", "he\u00b7raus", ",", "trotz'\u00b7ge", "Ge\u00b7stal\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "PTKVZ", "$,", "ADJA", "NN", "$."], "meter": "--+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "Ihnen blitzen die Augen k\u00fchn,", "tokens": ["Ih\u00b7nen", "blit\u00b7zen", "die", "Au\u00b7gen", "k\u00fchn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADJD", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.10": {"text": "Und ihre kr\u00e4ftigen Arme", "tokens": ["Und", "ih\u00b7re", "kr\u00e4f\u00b7ti\u00b7gen", "Ar\u00b7me"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "ADJA", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.11": {"text": "M\u00f6chten wohl einmal auf Anderes schlagen", "tokens": ["M\u00f6ch\u00b7ten", "wohl", "ein\u00b7mal", "auf", "An\u00b7de\u00b7res", "schla\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "ADV", "ADV", "APPR", "PIS", "VVINF"], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.12": {"text": "Als das schuldlose Eisen.", "tokens": ["Als", "das", "schuld\u00b7lo\u00b7se", "Ei\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.13": {"text": "Es geht ein gewaltiger Geisteshauch \u00fcber die Erde,", "tokens": ["Es", "geht", "ein", "ge\u00b7wal\u00b7ti\u00b7ger", "Geis\u00b7tes\u00b7hauch", "\u00fc\u00b7ber", "die", "Er\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+--+--+--+--+-", "measure": "amphibrach.penta.plus"}, "line.14": {"text": "Desgleichen auf Erden noch nie ist gesp\u00fcret worden.", "tokens": ["Des\u00b7glei\u00b7chen", "auf", "Er\u00b7den", "noch", "nie", "ist", "ge\u00b7sp\u00fc\u00b7ret", "wor\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "ADV", "ADV", "VAFIN", "VVPP", "VAPP", "$."], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.15": {"text": "Er w\u00fchlet die Wellen auf vom Grund.", "tokens": ["Er", "w\u00fch\u00b7let", "die", "Wel\u00b7len", "auf", "vom", "Grund", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "APPRART", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.8": {"line.1": {"text": "Dem Ambo\u00df hat es Einer gesagt,", "tokens": ["Dem", "Am\u00b7bo\u00df", "hat", "es", "Ei\u00b7ner", "ge\u00b7sagt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "PIS", "VVPP", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Da\u00df er aus demselben Stoffe gemacht sei", "tokens": ["Da\u00df", "er", "aus", "dem\u00b7sel\u00b7ben", "Stof\u00b7fe", "ge\u00b7macht", "sei"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "PDAT", "NN", "VVPP", "VAFIN"], "meter": "--+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Wie der Hammer,", "tokens": ["Wie", "der", "Ham\u00b7mer", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "$,"], "meter": "--+-", "measure": "anapaest.init"}, "line.4": {"text": "Und siehe, er will nun nicht l\u00e4nger Ambo\u00df sein.", "tokens": ["Und", "sie\u00b7he", ",", "er", "will", "nun", "nicht", "l\u00e4n\u00b7ger", "Am\u00b7bo\u00df", "sein", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVIMP", "$,", "PPER", "VMFIN", "ADV", "PTKNEG", "ADJD", "NN", "VAINF", "$."], "meter": "-+--+--+-+--", "measure": "amphibrach.tri.plus"}, "line.5": {"text": "Darob ist ein gro\u00df Entsetzen gekommen auf die Schl\u00e4ger alle;", "tokens": ["Da\u00b7rob", "ist", "ein", "gro\u00df", "Ent\u00b7set\u00b7zen", "ge\u00b7kom\u00b7men", "auf", "die", "Schl\u00e4\u00b7ger", "al\u00b7le", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "ART", "ADJD", "NN", "VVPP", "APPR", "ART", "NN", "PIS", "$."], "meter": "----+-+--+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "Aber die Geschlagenen sind noch nicht besser daran", "tokens": ["A\u00b7ber", "die", "Ge\u00b7schla\u00b7ge\u00b7nen", "sind", "noch", "nicht", "bes\u00b7ser", "da\u00b7ran"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "VAFIN", "ADV", "PTKNEG", "ADJD", "PAV"], "meter": "+---+--+--+--+", "measure": "trochaic.penta.relaxed"}, "line.7": {"text": "Denn zuvor.", "tokens": ["Denn", "zu\u00b7vor", "."], "token_info": ["word", "word", "punct"], "pos": ["KON", "ADV", "$."], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.9": {"line.1": {"text": "Wie der Arzt pocht an den Leib des Menschen", "tokens": ["Wie", "der", "Arzt", "pocht", "an", "den", "Leib", "des", "Men\u00b7schen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ART", "NN", "VVFIN", "APPR", "ART", "NN", "ART", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Und horcht mit Sorgfalt, da\u00df er ihm sage:", "tokens": ["Und", "horcht", "mit", "Sorg\u00b7falt", ",", "da\u00df", "er", "ihm", "sa\u00b7ge", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "NN", "$,", "KOUS", "PPER", "PPER", "VVFIN", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Hier bist du krank,", "tokens": ["Hier", "bist", "du", "krank", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.4": {"text": "Und hier bist du schwer krank.", "tokens": ["Und", "hier", "bist", "du", "schwer", "krank", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "PPER", "ADJD", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Aber heilen kann ich dich nicht", "tokens": ["A\u00b7ber", "hei\u00b7len", "kann", "ich", "dich", "nicht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVINF", "VMFIN", "PPER", "PRF", "PTKNEG"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.6": {"text": "Und helfen kann ich dir nicht,", "tokens": ["Und", "hel\u00b7fen", "kann", "ich", "dir", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVINF", "VMFIN", "PPER", "PPER", "PTKNEG", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.7": {"text": "So ist die Erkenntni\u00df zu ihnen gekommen", "tokens": ["So", "ist", "die", "Er\u00b7kennt\u00b7ni\u00df", "zu", "ih\u00b7nen", "ge\u00b7kom\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ART", "NN", "APPR", "PPER", "VVPP"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.8": {"text": "Ihrer Krankheit,", "tokens": ["Ih\u00b7rer", "Krank\u00b7heit", ","], "token_info": ["word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.9": {"text": "Und ist noch kein Arzt da, der ihnen helfe,", "tokens": ["Und", "ist", "noch", "kein", "Arzt", "da", ",", "der", "ih\u00b7nen", "hel\u00b7fe", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "PIAT", "NN", "PTKVZ", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.10": {"text": "Und ihr Elend ist nicht auszusagen.", "tokens": ["Und", "ihr", "E\u00b7lend", "ist", "nicht", "aus\u00b7zu\u00b7sa\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VAFIN", "PTKNEG", "VVINF", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.10": {"line.1": {"text": "Seht doch, wie wunderlich es ihnen gehet.", "tokens": ["Seht", "doch", ",", "wie", "wun\u00b7der\u00b7lich", "es", "ih\u00b7nen", "ge\u00b7het", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "$,", "PWAV", "ADJD", "PPER", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Sie pflanzen das Land", "tokens": ["Sie", "pflan\u00b7zen", "das", "Land"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.3": {"text": "Und s\u00e4en die Saaten aus", "tokens": ["Und", "s\u00e4\u00b7en", "die", "Saa\u00b7ten", "aus"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ART", "NN", "APPR"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Und bringen die Ernten ein,", "tokens": ["Und", "brin\u00b7gen", "die", "Ern\u00b7ten", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Und d\u00fcrfen doch der Frucht nicht genie\u00dfen.", "tokens": ["Und", "d\u00fcr\u00b7fen", "doch", "der", "Frucht", "nicht", "ge\u00b7nie\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ADV", "ART", "NN", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Sie bauen alle H\u00e4user", "tokens": ["Sie", "bau\u00b7en", "al\u00b7le", "H\u00e4u\u00b7ser"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PIAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Und k\u00f6nnen nirgend wohnen.", "tokens": ["Und", "k\u00f6n\u00b7nen", "nir\u00b7gend", "woh\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Sie machen Alles,", "tokens": ["Sie", "ma\u00b7chen", "Al\u00b7les", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.9": {"text": "Sie schaffen Alles,", "tokens": ["Sie", "schaf\u00b7fen", "Al\u00b7les", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.10": {"text": "Und sie haben nichts.", "tokens": ["Und", "sie", "ha\u00b7ben", "nichts", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "PIS", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.11": {"text": "Ein Unrecht geschiehet hier, wer kann es ableugnen?", "tokens": ["Ein", "Un\u00b7recht", "ge\u00b7schie\u00b7het", "hier", ",", "wer", "kann", "es", "ab\u00b7leug\u00b7nen", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "$,", "PWS", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+--+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.12": {"text": "Ein blutiges Unrecht geschiehet hier,", "tokens": ["Ein", "blu\u00b7ti\u00b7ges", "Un\u00b7recht", "ge\u00b7schie\u00b7het", "hier", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ADV", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.13": {"text": "Wer wird es s\u00fchnen?", "tokens": ["Wer", "wird", "es", "s\u00fch\u00b7nen", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "VVINF", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.11": {"line.1": {"text": "Der Kaufmann ist mir hochgeachtet,", "tokens": ["Der", "Kauf\u00b7mann", "ist", "mir", "hoch\u00b7ge\u00b7ach\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Der f\u00fcr sich und die Seinen sich qu\u00e4lt", "tokens": ["Der", "f\u00fcr", "sich", "und", "die", "Sei\u00b7nen", "sich", "qu\u00e4lt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "PRF", "KON", "ART", "PPOSS", "PRF", "VVFIN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "In ehrlichem Erwerb.", "tokens": ["In", "ehr\u00b7li\u00b7chem", "Er\u00b7werb", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Ihn sch\u00e4tze ich dem Landmann gleich,", "tokens": ["Ihn", "sch\u00e4t\u00b7ze", "ich", "dem", "Land\u00b7mann", "gleich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ART", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Der den Acker bauet mit schwerer Hand", "tokens": ["Der", "den", "A\u00b7cker", "bau\u00b7et", "mit", "schwe\u00b7rer", "Hand"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ART", "NN", "VVFIN", "APPR", "ADJA", "NN"], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.6": {"text": "Und das Gespenst des Hungers abwehrt von dem Menschen.", "tokens": ["Und", "das", "Ge\u00b7spenst", "des", "Hun\u00b7gers", "ab\u00b7wehrt", "von", "dem", "Men\u00b7schen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ART", "NN", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Aber der Kaufmann ist ja auch elend.", "tokens": ["A\u00b7ber", "der", "Kauf\u00b7mann", "ist", "ja", "auch", "e\u00b7lend", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VAFIN", "ADV", "ADV", "ADJD", "$."], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}, "line.8": {"text": "Die Nachbarn lauern auf seinen Untergang;", "tokens": ["Die", "Nach\u00b7barn", "lau\u00b7ern", "auf", "sei\u00b7nen", "Un\u00b7ter\u00b7gang", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.9": {"text": "Einer jagt den andern, da\u00df er ihn verderbe.", "tokens": ["Ei\u00b7ner", "jagt", "den", "an\u00b7dern", ",", "da\u00df", "er", "ihn", "ver\u00b7der\u00b7be", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ART", "ADJA", "$,", "KOUS", "PPER", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.10": {"text": "Es ist ein Grauen mit anzusehn.", "tokens": ["Es", "ist", "ein", "Grau\u00b7en", "mit", "an\u00b7zu\u00b7sehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "APPR", "VVIZU", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.12": {"line.1": {"text": "Und dazu m\u00fcssen meine Augen sehen,", "tokens": ["Und", "da\u00b7zu", "m\u00fcs\u00b7sen", "mei\u00b7ne", "Au\u00b7gen", "se\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PAV", "VMFIN", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Wie das Blutsaugerthum schamlos waltet im Lande,", "tokens": ["Wie", "das", "Blu\u00b7tsau\u00b7ger\u00b7thum", "scham\u00b7los", "wal\u00b7tet", "im", "Lan\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "ADJD", "VVFIN", "APPRART", "NN", "$,"], "meter": "--+--+--+--+-", "measure": "anapaest.tetra.plus"}, "line.3": {"text": "Und ist keine Schranke da, die ihnen Einhalt thut,", "tokens": ["Und", "ist", "kei\u00b7ne", "Schran\u00b7ke", "da", ",", "die", "ih\u00b7nen", "Ein\u00b7halt", "thut", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PIAT", "NN", "PTKVZ", "$,", "PRELS", "PPER", "NN", "VVFIN", "$,"], "meter": "--+-+-+-+-+-+", "measure": "anapaest.init"}, "line.4": {"text": "Und kein Richter auf Erden, der sie strafe.", "tokens": ["Und", "kein", "Rich\u00b7ter", "auf", "Er\u00b7den", ",", "der", "sie", "stra\u00b7fe", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "APPR", "NN", "$,", "PRELS", "PPER", "VVFIN", "$."], "meter": "--+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Und die sich br\u00fcsten, die Ersten im Lande zu sein,", "tokens": ["Und", "die", "sich", "br\u00fcs\u00b7ten", ",", "die", "Ers\u00b7ten", "im", "Lan\u00b7de", "zu", "sein", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "PRF", "VVFIN", "$,", "ART", "NN", "APPRART", "NN", "PTKZU", "VAINF", "$,"], "meter": "-+-+--+--+--+", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Und sich einbilden, anders geboren zu sein,", "tokens": ["Und", "sich", "ein\u00b7bil\u00b7den", ",", "an\u00b7ders", "ge\u00b7bo\u00b7ren", "zu", "sein", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "VVINF", "$,", "ADV", "VVPP", "PTKZU", "VAINF", "$,"], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.7": {"text": "Als alle andern Menschen \u2013", "tokens": ["Als", "al\u00b7le", "an\u00b7dern", "Men\u00b7schen", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "ADJA", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Das doch eine Beschimpfung der Menschenw\u00fcrde ist", "tokens": ["Das", "doch", "ei\u00b7ne", "Be\u00b7schimp\u00b7fung", "der", "Men\u00b7schen\u00b7w\u00fcr\u00b7de", "ist"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "ADV", "ART", "NN", "ART", "NN", "VAFIN"], "meter": "--+--+--+-+-+", "measure": "anapaest.tri.plus"}, "line.9": {"text": "Und eine L\u00fcge im Angesicht der Wahrheit", "tokens": ["Und", "ei\u00b7ne", "L\u00fc\u00b7ge", "im", "An\u00b7ge\u00b7sicht", "der", "Wahr\u00b7heit"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "APPRART", "NN", "ART", "NN"], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.10": {"text": "Und ein Kinderspott vor der ganzen Welt \u2013", "tokens": ["Und", "ein", "Kin\u00b7der\u00b7spott", "vor", "der", "gan\u00b7zen", "Welt", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "APPR", "ART", "ADJA", "NN", "$("], "meter": "--+----+-+", "measure": "anapaest.init"}, "line.11": {"text": "Die sind mitten darunter.", "tokens": ["Die", "sind", "mit\u00b7ten", "da\u00b7run\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "PAV", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.12": {"text": "Und sie thun sich zusammen zu ganzen Banden", "tokens": ["Und", "sie", "thun", "sich", "zu\u00b7sam\u00b7men", "zu", "gan\u00b7zen", "Ban\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "PRF", "ADV", "APPR", "ADJA", "NN"], "meter": "--+--+--+-+-", "measure": "anapaest.tri.plus"}, "line.13": {"text": "Und fallen das Volk bei hellem, lichten Tage an,", "tokens": ["Und", "fal\u00b7len", "das", "Volk", "bei", "hel\u00b7lem", ",", "lich\u00b7ten", "Ta\u00b7ge", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "APPR", "ADJA", "$,", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.14": {"text": "Da\u00df sie es auspl\u00fcndern.", "tokens": ["Da\u00df", "sie", "es", "aus\u00b7pl\u00fcn\u00b7dern", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.13": {"line.1": {"text": "Und dann lachen sie noch in sich hinein", "tokens": ["Und", "dann", "la\u00b7chen", "sie", "noch", "in", "sich", "hin\u00b7ein"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "PPER", "ADV", "APPR", "PRF", "APZR"], "meter": "--+--+-+-+", "measure": "anapaest.di.plus"}, "line.2": {"text": "Und rufen: das sind die Dummen!", "tokens": ["Und", "ru\u00b7fen", ":", "das", "sind", "die", "Dum\u00b7men", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "PDS", "VAFIN", "ART", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Da es doch blo\u00df die Unwissenden sind", "tokens": ["Da", "es", "doch", "blo\u00df", "die", "Un\u00b7wis\u00b7sen\u00b7den", "sind"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "ADV", "ART", "NN", "VAFIN"], "meter": "-+-+-++-+-", "measure": "unknown.measure.penta"}, "line.4": {"text": "Und die nicht sehen k\u00f6nnen.", "tokens": ["Und", "die", "nicht", "se\u00b7hen", "k\u00f6n\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "PTKNEG", "VVINF", "VMINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Als ob es denn ein k\u00f6stlich Ding sei und ein gro\u00df Werk,", "tokens": ["Als", "ob", "es", "denn", "ein", "k\u00f6st\u00b7lich", "Ding", "sei", "und", "ein", "gro\u00df", "Werk", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "PPER", "ADV", "ART", "ADJD", "NN", "VAFIN", "KON", "ART", "ADJD", "NN", "$,"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "Einen Blinden in den Graben zu sto\u00dfen,", "tokens": ["Ei\u00b7nen", "Blin\u00b7den", "in", "den", "Gra\u00b7ben", "zu", "sto\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+--+-", "measure": "trochaic.penta.relaxed"}, "line.7": {"text": "Oder ein Kind anzulocken und auszurauben.", "tokens": ["O\u00b7der", "ein", "Kind", "an\u00b7zu\u00b7lo\u00b7cken", "und", "aus\u00b7zu\u00b7rau\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVIZU", "KON", "VVIZU", "$."], "meter": "+--++-+--+-+-", "measure": "trochaic.hexa.relaxed"}, "line.8": {"text": "Und Viele, die ein Amt hatten zum Nutzen ihrer Mitmenschen,", "tokens": ["Und", "Vie\u00b7le", ",", "die", "ein", "Amt", "hat\u00b7ten", "zum", "Nut\u00b7zen", "ih\u00b7rer", "Mit\u00b7men\u00b7schen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "$,", "PRELS", "ART", "NN", "VAFIN", "APPRART", "NN", "PPOSAT", "NN", "$,"], "meter": "-+--+-+--+-+-+-+", "measure": "iambic.septa.relaxed"}, "line.9": {"text": "Und das Amt war voll M\u00fche und Arbeit,", "tokens": ["Und", "das", "Amt", "war", "voll", "M\u00fc\u00b7he", "und", "Ar\u00b7beit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VAFIN", "ADJD", "NN", "KON", "NN", "$,"], "meter": "--+--+--+-", "measure": "anapaest.tri.plus"}, "line.10": {"text": "Die lassen ihr Amt und laufen jenen nach,", "tokens": ["Die", "las\u00b7sen", "ihr", "Amt", "und", "lau\u00b7fen", "je\u00b7nen", "nach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPOSAT", "NN", "KON", "VVFIN", "PDS", "PTKVZ", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.11": {"text": "Damit sie auch mit Gier m\u00f6gen Gold einscharren", "tokens": ["Da\u00b7mit", "sie", "auch", "mit", "Gier", "m\u00f6\u00b7gen", "Gold", "ein\u00b7schar\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "APPR", "NN", "VMFIN", "NN", "VVINF"], "meter": "-+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.12": {"text": "Ohne M\u00fche und ohne Arbeit.", "tokens": ["Oh\u00b7ne", "M\u00fc\u00b7he", "und", "oh\u00b7ne", "Ar\u00b7beit", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "APPR", "NN", "$."], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.13": {"text": "Und daf\u00fcr tausend Elende m\u00fcssen noch elender sein", "tokens": ["Und", "da\u00b7f\u00fcr", "tau\u00b7send", "E\u00b7len\u00b7de", "m\u00fcs\u00b7sen", "noch", "e\u00b7len\u00b7der", "sein"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PAV", "CARD", "NN", "VMFIN", "ADV", "ADJD", "VAINF"], "meter": "-+-+-+--+--+--+", "measure": "iambic.hexa.relaxed"}, "line.14": {"text": "Und noch mehr gequ\u00e4lt und noch mehr geschunden.", "tokens": ["Und", "noch", "mehr", "ge\u00b7qu\u00e4lt", "und", "noch", "mehr", "ge\u00b7schun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "VVPP", "KON", "ADV", "ADV", "VVPP", "$."], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.14": {"line.1": {"text": "Ich will meine Stimme erheben", "tokens": ["Ich", "will", "mei\u00b7ne", "Stim\u00b7me", "er\u00b7he\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PPOSAT", "NN", "VVINF"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Und rufen, da\u00df man es weit h\u00f6re:", "tokens": ["Und", "ru\u00b7fen", ",", "da\u00df", "man", "es", "weit", "h\u00f6\u00b7re", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "KOUS", "PIS", "PPER", "ADJD", "VVFIN", "$."], "meter": "-+-++--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Wer nicht arbeitet, der soll nicht leben!", "tokens": ["Wer", "nicht", "ar\u00b7bei\u00b7tet", ",", "der", "soll", "nicht", "le\u00b7ben", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PTKNEG", "VVFIN", "$,", "PRELS", "VMFIN", "PTKNEG", "VVINF", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Der Geist, der heut herrscht, ist eine Schmach den Menschen", "tokens": ["Der", "Geist", ",", "der", "heut", "herrscht", ",", "ist", "ei\u00b7ne", "Schmach", "den", "Men\u00b7schen"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "ADV", "VVPP", "$,", "VAFIN", "ART", "NN", "ART", "NN"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}}, "stanza.15": {"line.1": {"text": "Und eine tiefe Schande den V\u00f6lkern!", "tokens": ["Und", "ei\u00b7ne", "tie\u00b7fe", "Schan\u00b7de", "den", "V\u00f6l\u00b7kern", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "ART", "NN", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Sein Gift fri\u00dft um sich wie der Krebs.", "tokens": ["Sein", "Gift", "fri\u00dft", "um", "sich", "wie", "der", "Krebs", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "APPR", "PRF", "KOKOM", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sie haben sich steinerne Pal\u00e4ste gebaut,", "tokens": ["Sie", "ha\u00b7ben", "sich", "stei\u00b7ner\u00b7ne", "Pa\u00b7l\u00e4s\u00b7te", "ge\u00b7baut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PRF", "ADJA", "NN", "VVPP", "$,"], "meter": "-+--+---+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Aber aus allen Ecken pfeift der Betrug heraus.", "tokens": ["A\u00b7ber", "aus", "al\u00b7len", "E\u00b7cken", "pfeift", "der", "Be\u00b7trug", "he\u00b7raus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PIAT", "NN", "VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "+--+-+-+--+-+", "measure": "iambic.hexa.invert"}, "line.5": {"text": "Wenn der Arbeitsmann vorbeigeht,", "tokens": ["Wenn", "der", "Ar\u00b7beits\u00b7mann", "vor\u00b7bei\u00b7geht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "VVFIN", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.6": {"text": "Er wei\u00df nicht warum, aber er ballt die Hand zur Faust.", "tokens": ["Er", "wei\u00df", "nicht", "wa\u00b7rum", ",", "a\u00b7ber", "er", "ballt", "die", "Hand", "zur", "Faust", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "PWAV", "$,", "KON", "PPER", "VVFIN", "ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.7": {"text": "Auf seinen Aeckern da geht der Bauer", "tokens": ["Auf", "sei\u00b7nen", "A\u00b7e\u00b7ckern", "da", "geht", "der", "Bau\u00b7er"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "ADV", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Und st\u00f6hnet hinter dem Pfluge her.", "tokens": ["Und", "st\u00f6h\u00b7net", "hin\u00b7ter", "dem", "Pflu\u00b7ge", "her", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "Es ist nicht die Arbeit, die ihn st\u00f6hnen macht,", "tokens": ["Es", "ist", "nicht", "die", "Ar\u00b7beit", ",", "die", "ihn", "st\u00f6h\u00b7nen", "macht", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKNEG", "ART", "NN", "$,", "PRELS", "PPER", "VVINF", "VVFIN", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.10": {"text": "Denn sie war sonst seine Lust gewesen.", "tokens": ["Denn", "sie", "war", "sonst", "sei\u00b7ne", "Lust", "ge\u00b7we\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "ADV", "PPOSAT", "NN", "VAPP", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.11": {"text": "Aber die Halme, die er m\u00e4hen wird,", "tokens": ["A\u00b7ber", "die", "Hal\u00b7me", ",", "die", "er", "m\u00e4\u00b7hen", "wird", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "PRELS", "PPER", "VVINF", "VAFIN", "$,"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.12": {"text": "Sie sind nicht mehr sein,", "tokens": ["Sie", "sind", "nicht", "mehr", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKNEG", "ADV", "VAINF", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.13": {"text": "Und sein Haus, darinnen seine Eltern gewohnt,", "tokens": ["Und", "sein", "Haus", ",", "da\u00b7rin\u00b7nen", "sei\u00b7ne", "El\u00b7tern", "ge\u00b7wohnt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "$,", "ADV", "PPOSAT", "NN", "VVPP", "$,"], "meter": "--+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.14": {"text": "Er wird es bald verlassen,", "tokens": ["Er", "wird", "es", "bald", "ver\u00b7las\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.15": {"text": "Frage doch die V\u00f6gel unter dem Himmel,", "tokens": ["Fra\u00b7ge", "doch", "die", "V\u00f6\u00b7gel", "un\u00b7ter", "dem", "Him\u00b7mel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+--+-", "measure": "trochaic.penta.relaxed"}, "line.16": {"text": "Die werden dir's sagen.", "tokens": ["Die", "wer\u00b7den", "dir's", "sa\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PIS", "VVINF", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.16": {"line.1": {"text": "Und haben sich \u00f6ffentliche Bl\u00e4tter gemacht,", "tokens": ["Und", "ha\u00b7ben", "sich", "\u00f6f\u00b7fent\u00b7li\u00b7che", "Bl\u00e4t\u00b7ter", "ge\u00b7macht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PRF", "ADJA", "NN", "VVPP", "$,"], "meter": "-+--++--+--+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Die sprechen von Allem, was nicht ist", "tokens": ["Die", "spre\u00b7chen", "von", "Al\u00b7lem", ",", "was", "nicht", "ist"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PDS", "VVFIN", "APPR", "PIS", "$,", "PRELS", "PTKNEG", "VAFIN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Und was nicht gewesen ist.", "tokens": ["Und", "was", "nicht", "ge\u00b7we\u00b7sen", "ist", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PTKNEG", "VAPP", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Aber was gerecht ist, das reden sie nicht,", "tokens": ["A\u00b7ber", "was", "ge\u00b7recht", "ist", ",", "das", "re\u00b7den", "sie", "nicht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ADJD", "VAFIN", "$,", "PDS", "VVFIN", "PPER", "PTKNEG", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.5": {"text": "Und was noth thut, das sagen sie nicht.", "tokens": ["Und", "was", "noth", "thut", ",", "das", "sa\u00b7gen", "sie", "nicht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "NN", "VVFIN", "$,", "PDS", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.6": {"text": "Nach Gewicht steht da das Talent zu Kauf,", "tokens": ["Nach", "Ge\u00b7wicht", "steht", "da", "das", "Ta\u00b7lent", "zu", "Kauf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "ADV", "ART", "NN", "APPR", "NN", "$,"], "meter": "+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.7": {"text": "Und talentvoll und gewissenlos", "tokens": ["Und", "ta\u00b7lent\u00b7voll", "und", "ge\u00b7wis\u00b7sen\u00b7los"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ADJD", "KON", "ADJD"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Ist bei ihnen einunddasselbe geworden,", "tokens": ["Ist", "bei", "ih\u00b7nen", "ein\u00b7und\u00b7das\u00b7sel\u00b7be", "ge\u00b7wor\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "PPER", "ADJA", "VAPP", "$,"], "meter": "+-+-+--+--+-", "measure": "trochaic.penta.relaxed"}, "line.9": {"text": "Darum sind sie mit Grund gering geachtet.", "tokens": ["Da\u00b7rum", "sind", "sie", "mit", "Grund", "ge\u00b7ring", "ge\u00b7ach\u00b7tet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "PPER", "APPR", "NN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Sie vernichten das Denken,", "tokens": ["Sie", "ver\u00b7nich\u00b7ten", "das", "Den\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.11": {"text": "Das h\u00f6chste Gut des Menschen,", "tokens": ["Das", "h\u00f6chs\u00b7te", "Gut", "des", "Men\u00b7schen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.12": {"text": "Und sie machen stumpfsinnig anstatt zu belehren.", "tokens": ["Und", "sie", "ma\u00b7chen", "stumpf\u00b7sin\u00b7nig", "an\u00b7statt", "zu", "be\u00b7leh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ADJD", "ADJD", "PTKZU", "VVINF", "$."], "meter": "--+--+-+-+-+-", "measure": "anapaest.di.plus"}, "line.13": {"text": "Und r\u00fchmen sich dessen mit Heuchell\u00fcgen", "tokens": ["Und", "r\u00fch\u00b7men", "sich", "des\u00b7sen", "mit", "Heu\u00b7chel\u00b7l\u00fc\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PRF", "PDS", "APPR", "NN"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.14": {"text": "Und nennen ihr Geldgesch\u00e4ft", "tokens": ["Und", "nen\u00b7nen", "ihr", "Geld\u00b7ge\u00b7sch\u00e4ft"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPOSAT", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.15": {"text": "Eine Geisteswohlthat f\u00fcr das Volk.", "tokens": ["Ei\u00b7ne", "Geis\u00b7tes\u00b7wohlt\u00b7hat", "f\u00fcr", "das", "Volk", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.16": {"text": "Sie haben einen feinen Teppich \u00fcber den Sumpf gebreitet", "tokens": ["Sie", "ha\u00b7ben", "ei\u00b7nen", "fei\u00b7nen", "Tep\u00b7pich", "\u00fc\u00b7ber", "den", "Sumpf", "ge\u00b7brei\u00b7tet"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "APPR", "ART", "NN", "VVPP"], "meter": "-+-+-+-+-+--+-+-", "measure": "iambic.septa.relaxed"}, "line.17": {"text": "Und sehen wohl zu, da\u00df nichts durchdringe.", "tokens": ["Und", "se\u00b7hen", "wohl", "zu", ",", "da\u00df", "nichts", "durch\u00b7drin\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "PTKVZ", "$,", "KOUS", "PIS", "VVFIN", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.18": {"text": "Kinder schreiben darin", "tokens": ["Kin\u00b7der", "schrei\u00b7ben", "da\u00b7rin"], "token_info": ["word", "word", "word"], "pos": ["NN", "VVFIN", "PAV"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.19": {"text": "Und N\u00e4rrische m\u00fcssen die Welt regieren.", "tokens": ["Und", "N\u00e4r\u00b7ri\u00b7sche", "m\u00fcs\u00b7sen", "die", "Welt", "re\u00b7gie\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VMFIN", "ART", "NN", "VVINF", "$."], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.20": {"text": "Das Schlagwort ist ihre Angriffswaffe,", "tokens": ["Das", "Schlag\u00b7wort", "ist", "ih\u00b7re", "An\u00b7griffs\u00b7waf\u00b7fe", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.21": {"text": "Und die Phrasen sind ihr t\u00e4gliches Brot.", "tokens": ["Und", "die", "Phra\u00b7sen", "sind", "ihr", "t\u00e4g\u00b7li\u00b7ches", "Brot", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VAFIN", "PPOSAT", "ADJA", "NN", "$."], "meter": "--+-+-+--+", "measure": "iambic.tetra.chol"}, "line.22": {"text": "Die Phrase aber ist der Betrug mit Worten,", "tokens": ["Die", "Phra\u00b7se", "a\u00b7ber", "ist", "der", "Be\u00b7trug", "mit", "Wor\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VAFIN", "ART", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.23": {"text": "Und das Schlagw\u00f6rterthum", "tokens": ["Und", "das", "Schlag\u00b7w\u00f6r\u00b7ter\u00b7thum"], "token_info": ["word", "word", "word"], "pos": ["KON", "ART", "NN"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.24": {"text": "Der Mi\u00dfbrauch gerechter Worte.", "tokens": ["Der", "Mi\u00df\u00b7brauch", "ge\u00b7rech\u00b7ter", "Wor\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.17": {"line.1": {"text": "Wer gewohnt ist, mit klaren Blicken um sich zu schau'n,", "tokens": ["Wer", "ge\u00b7wohnt", "ist", ",", "mit", "kla\u00b7ren", "Bli\u00b7cken", "um", "sich", "zu", "schau'n", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVPP", "VAFIN", "$,", "APPR", "ADJA", "NN", "APPR", "PRF", "PTKZU", "VVINF", "$,"], "meter": "--+--+-+--+-+", "measure": "anapaest.di.plus"}, "line.2": {"text": "Wer sich den schlichten Verstand nicht mag verr\u00fccken lassen", "tokens": ["Wer", "sich", "den", "schlich\u00b7ten", "Ver\u00b7stand", "nicht", "mag", "ver\u00b7r\u00fc\u00b7cken", "las\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWS", "PRF", "ART", "ADJA", "NN", "PTKNEG", "VMFIN", "VVINF", "VVINF"], "meter": "-+-+--+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Und wer seine Sprache liebt, das edelste Geschenk,", "tokens": ["Und", "wer", "sei\u00b7ne", "Spra\u00b7che", "liebt", ",", "das", "e\u00b7dels\u00b7te", "Ge\u00b7schenk", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPOSAT", "NN", "VVFIN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}, "line.4": {"text": "Das dem Menschen ein Gott gegeben,", "tokens": ["Das", "dem", "Men\u00b7schen", "ein", "Gott", "ge\u00b7ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ART", "NN", "ART", "NN", "VVPP", "$,"], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.5": {"text": "Der steht vor der Phrase", "tokens": ["Der", "steht", "vor", "der", "Phra\u00b7se"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "APPR", "ART", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.6": {"text": "Wie vor den Schnalzlauten,", "tokens": ["Wie", "vor", "den", "Schnalz\u00b7lau\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPR", "ART", "NN", "$,"], "meter": "-+-++-", "measure": "unknown.measure.tri"}, "line.7": {"text": "Die die Wilden in Afrika sprechen.", "tokens": ["Die", "die", "Wil\u00b7den", "in", "Af\u00b7ri\u00b7ka", "spre\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "APPR", "NE", "VVINF", "$."], "meter": "--+--+--+-", "measure": "anapaest.tri.plus"}, "line.8": {"text": "Ein Gemisch von Schallwellen schl\u00e4gt an sein Ohr,", "tokens": ["Ein", "Ge\u00b7misch", "von", "Schall\u00b7wel\u00b7len", "schl\u00e4gt", "an", "sein", "Ohr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.9": {"text": "Er h\u00f6rt Laute und wei\u00df keinen Sinn,", "tokens": ["Er", "h\u00f6rt", "Lau\u00b7te", "und", "wei\u00df", "kei\u00b7nen", "Sinn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "KON", "VVFIN", "PIAT", "NN", "$,"], "meter": "-++-+-+-+", "measure": "unknown.measure.penta"}, "line.10": {"text": "Wie Seifenblasen", "tokens": ["Wie", "Sei\u00b7fen\u00b7bla\u00b7sen"], "token_info": ["word", "word"], "pos": ["PWAV", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.11": {"text": "Bl\u00e4hen sich die bunten Worte auf,", "tokens": ["Bl\u00e4\u00b7hen", "sich", "die", "bun\u00b7ten", "Wor\u00b7te", "auf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.12": {"text": "Und wenn sie geplatzt sind,", "tokens": ["Und", "wenn", "sie", "ge\u00b7platzt", "sind", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "VVPP", "VAFIN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.13": {"text": "So ist darinnen das pure Nichts.", "tokens": ["So", "ist", "da\u00b7rin\u00b7nen", "das", "pu\u00b7re", "Nichts", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.14": {"text": "Aber dichtgedr\u00e4ngt stehen die H\u00f6rer umher", "tokens": ["A\u00b7ber", "dicht\u00b7ge\u00b7dr\u00e4ngt", "ste\u00b7hen", "die", "H\u00f6\u00b7rer", "um\u00b7her"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "VVFIN", "ART", "NN", "PTKVZ"], "meter": "+-+--+--+--+", "measure": "trochaic.penta.relaxed"}, "line.15": {"text": "Und klatschen rasenden Beifall.", "tokens": ["Und", "klat\u00b7schen", "ra\u00b7sen\u00b7den", "Bei\u00b7fall", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "ADJA", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.16": {"text": "Und sein Gem\u00fcth wird von Trauer erf\u00fcllt,", "tokens": ["Und", "sein", "Ge\u00b7m\u00fcth", "wird", "von", "Trau\u00b7er", "er\u00b7f\u00fcllt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VAFIN", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.17": {"text": "Und ein unendlicher Ekel ergreift ihn.", "tokens": ["Und", "ein", "un\u00b7end\u00b7li\u00b7cher", "E\u00b7kel", "er\u00b7greift", "ihn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "VVFIN", "PPER", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.18": {"line.1": {"text": "Aber die Dichter, die heut leben,", "tokens": ["A\u00b7ber", "die", "Dich\u00b7ter", ",", "die", "heut", "le\u00b7ben", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "PRELS", "ADV", "VVINF", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Haben sie denn Augen, um nicht zu sehn?", "tokens": ["Ha\u00b7ben", "sie", "denn", "Au\u00b7gen", ",", "um", "nicht", "zu", "sehn", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "NN", "$,", "KOUI", "PTKNEG", "PTKZU", "VVINF", "$."], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Haben sie denn einen Mund, um nicht zu sprechen?", "tokens": ["Ha\u00b7ben", "sie", "denn", "ei\u00b7nen", "Mund", ",", "um", "nicht", "zu", "spre\u00b7chen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ART", "NN", "$,", "KOUI", "PTKNEG", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.4": {"text": "Ach! die besten von ihnen sind gar alt geworden.", "tokens": ["Ach", "!", "die", "bes\u00b7ten", "von", "ih\u00b7nen", "sind", "gar", "alt", "ge\u00b7wor\u00b7den", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$.", "ART", "ADJA", "APPR", "PPER", "VAFIN", "ADV", "ADJD", "VAPP", "$."], "meter": "+-+--+-+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.5": {"text": "Sie haben sich zur\u00fcckgezogen in gerechtem Groll", "tokens": ["Sie", "ha\u00b7ben", "sich", "zu\u00b7r\u00fcck\u00b7ge\u00b7zo\u00b7gen", "in", "ge\u00b7rech\u00b7tem", "Groll"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PRF", "VVPP", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.6": {"text": "Und schreiben nicht mehr,", "tokens": ["Und", "schrei\u00b7ben", "nicht", "mehr", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKNEG", "ADV", "$,"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.7": {"text": "Und die noch schreiben, sind nicht die besten.", "tokens": ["Und", "die", "noch", "schrei\u00b7ben", ",", "sind", "nicht", "die", "bes\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADV", "VVINF", "$,", "VAFIN", "PTKNEG", "ART", "ADJA", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Da ist keiner,", "tokens": ["Da", "ist", "kei\u00b7ner", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIS", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.9": {"text": "Der mit Ernst die Wahrheit m\u00f6chte verk\u00fcnden,", "tokens": ["Der", "mit", "Ernst", "die", "Wahr\u00b7heit", "m\u00f6ch\u00b7te", "ver\u00b7k\u00fcn\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "NE", "ART", "NN", "VMFIN", "VVINF", "$,"], "meter": "--+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "Ob schon die Spatzen auf den D\u00e4chern davon reden.", "tokens": ["Ob", "schon", "die", "Spat\u00b7zen", "auf", "den", "D\u00e4\u00b7chern", "da\u00b7von", "re\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "APPR", "ART", "NN", "PAV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Da ist keiner, der das Schwert ergreift,", "tokens": ["Da", "ist", "kei\u00b7ner", ",", "der", "das", "Schwert", "er\u00b7greift", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIS", "$,", "PRELS", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.12": {"text": "Das blitzende, scharfe Schwert,", "tokens": ["Das", "blit\u00b7zen\u00b7de", ",", "schar\u00b7fe", "Schwert", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "ADJA", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.13": {"text": "Ein Lied zu singen zur rechten Zeit", "tokens": ["Ein", "Lied", "zu", "sin\u00b7gen", "zur", "rech\u00b7ten", "Zeit"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "PTKZU", "VVINF", "APPRART", "ADJA", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.14": {"text": "Mit klingender Form,", "tokens": ["Mit", "klin\u00b7gen\u00b7der", "Form", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.15": {"text": "Aber im Inhalt schonungslos, r\u00fccksichtslos.", "tokens": ["A\u00b7ber", "im", "In\u00b7halt", "scho\u00b7nungs\u00b7los", ",", "r\u00fcck\u00b7sichts\u00b7los", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "APPRART", "NN", "ADJD", "$,", "ADJD", "$."], "meter": "+--+-+--+-+", "measure": "iambic.penta.invert"}, "line.16": {"text": "Die Poesie ist zum Gewerbe geworden.", "tokens": ["Die", "Poe\u00b7sie", "ist", "zum", "Ge\u00b7wer\u00b7be", "ge\u00b7wor\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "APPRART", "NN", "VAPP", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.17": {"text": "Wer am meisten bezahlt bekommt,", "tokens": ["Wer", "am", "meis\u00b7ten", "be\u00b7zahlt", "be\u00b7kommt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPRART", "PIS", "VVPP", "VVFIN", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.18": {"text": "Ist unter ihnen der gr\u00f6\u00dfte Dichter.", "tokens": ["Ist", "un\u00b7ter", "ih\u00b7nen", "der", "gr\u00f6\u00df\u00b7te", "Dich\u00b7ter."], "token_info": ["word", "word", "word", "word", "word", "abbreviation"], "pos": ["VAFIN", "APPR", "PPER", "ART", "ADJA", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.19": {"text": "Was todt und begraben ist,", "tokens": ["Was", "todt", "und", "be\u00b7gra\u00b7ben", "ist", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADJD", "KON", "VVPP", "VAFIN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.20": {"text": "Dagegen k\u00e4mpfen sie,", "tokens": ["Da\u00b7ge\u00b7gen", "k\u00e4mp\u00b7fen", "sie", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.21": {"text": "Und was keinem am Herzen liegt,", "tokens": ["Und", "was", "kei\u00b7nem", "am", "Her\u00b7zen", "liegt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PIS", "APPRART", "NN", "VVFIN", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.22": {"text": "Das bringen sie vor.", "tokens": ["Das", "brin\u00b7gen", "sie", "vor", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.23": {"text": "Mit Stroh gehen sie schwanger", "tokens": ["Mit", "Stroh", "ge\u00b7hen", "sie", "schwan\u00b7ger"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "VVFIN", "PPER", "ADJA"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.24": {"text": "Und Stoppeln geb\u00e4ren sie.", "tokens": ["Und", "Stop\u00b7peln", "ge\u00b7b\u00e4\u00b7ren", "sie", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "PPER", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.25": {"text": "Einen Stecknadelknopf Gold", "tokens": ["Ei\u00b7nen", "Steck\u00b7na\u00b7del\u00b7knopf", "Gold"], "token_info": ["word", "word", "word"], "pos": ["ART", "NN", "NN"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.26": {"text": "Walzen sie zu einem b\u00e4ndigen Romane aus,", "tokens": ["Wal\u00b7zen", "sie", "zu", "ei\u00b7nem", "b\u00e4n\u00b7di\u00b7gen", "Ro\u00b7ma\u00b7ne", "aus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "APPR", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}, "line.27": {"text": "Und sie schl\u00e4fern lieber die Gedanken der Menschen ein,", "tokens": ["Und", "sie", "schl\u00e4\u00b7fern", "lie\u00b7ber", "die", "Ge\u00b7dan\u00b7ken", "der", "Men\u00b7schen", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ADV", "ART", "NN", "ART", "NN", "PTKVZ", "$,"], "meter": "--+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.28": {"text": "Statt neue zu wecken. \u2013", "tokens": ["Statt", "neu\u00b7e", "zu", "we\u00b7cken", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "ADJA", "PTKZU", "VVINF", "$.", "$("], "meter": "+---+-", "measure": "dactylic.init"}, "line.29": {"text": "W\u00fcst und \u00f6de sieht es auf der B\u00fchne aus,", "tokens": ["W\u00fcst", "und", "\u00f6\u00b7de", "sieht", "es", "auf", "der", "B\u00fch\u00b7ne", "aus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KON", "ADJD", "VVFIN", "PPER", "APPR", "ART", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.30": {"text": "Und ich habe Beifall klatschen sehn solchem Schund,", "tokens": ["Und", "ich", "ha\u00b7be", "Bei\u00b7fall", "klat\u00b7schen", "sehn", "sol\u00b7chem", "Schund", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "NN", "VVINF", "VVFIN", "PIAT", "NN", "$,"], "meter": "+-+-+-+-+--+", "measure": "iambic.hexa.chol"}, "line.31": {"text": "Da\u00df ich nicht wu\u00dfte, ob ich unter Irren war,", "tokens": ["Da\u00df", "ich", "nicht", "wu\u00df\u00b7te", ",", "ob", "ich", "un\u00b7ter", "Ir\u00b7ren", "war", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "VVFIN", "$,", "KOUS", "PPER", "APPR", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Oder in Gemeinschaft vernunftbegabter Menschen.", "tokens": ["O\u00b7der", "in", "Ge\u00b7mein\u00b7schaft", "ver\u00b7nunft\u00b7be\u00b7gab\u00b7ter", "Men\u00b7schen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "ADJA", "NN", "$."], "meter": "+-+-+--+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.33": {"text": "Und sie nennen sich selber Epigonen.", "tokens": ["Und", "sie", "nen\u00b7nen", "sich", "sel\u00b7ber", "E\u00b7pi\u00b7go\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PRF", "ADV", "NN", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}}, "stanza.19": {"line.1": {"text": "Wohl hat es Heroen in unserer Dichtkunst gegeben;", "tokens": ["Wohl", "hat", "es", "He\u00b7roen", "in", "un\u00b7se\u00b7rer", "Dicht\u00b7kunst", "ge\u00b7ge\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "NN", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+--+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Aber im Staub vor ihnen zu liegen", "tokens": ["A\u00b7ber", "im", "Staub", "vor", "ih\u00b7nen", "zu", "lie\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPRART", "NN", "APPR", "PPER", "PTKZU", "VVINF"], "meter": "+--+-+--+-", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Und im Gef\u00fchl der eig'nen Ohnmacht anzubeten,", "tokens": ["Und", "im", "Ge\u00b7f\u00fchl", "der", "eig'\u00b7nen", "Ohn\u00b7macht", "an\u00b7zu\u00b7be\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "NN", "ART", "ADJA", "NN", "VVIZU", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Das ist Sklaven-Art.", "tokens": ["Das", "ist", "Skla\u00b7ven\u00b7Art", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "NN", "$."], "meter": "--+-+", "measure": "anapaest.init"}, "line.5": {"text": "Nicht also gebietet der Genius,", "tokens": ["Nicht", "al\u00b7so", "ge\u00b7bie\u00b7tet", "der", "Ge\u00b7nius", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "VVFIN", "ART", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Sondern mit ernstem Munde spricht er:", "tokens": ["Son\u00b7dern", "mit", "erns\u00b7tem", "Mun\u00b7de", "spricht", "er", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ADJA", "NN", "VVFIN", "PPER", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}}, "stanza.20": {"line.1": {"text": "Liebend sollst du dein Haupt vor ihnen beugen", "tokens": ["Lie\u00b7bend", "sollst", "du", "dein", "Haupt", "vor", "ih\u00b7nen", "beu\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADJD", "VMFIN", "PPER", "PPOSAT", "NN", "APPR", "PPER", "VVINF"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.2": {"text": "Und dich freuen in deinem Herzen,", "tokens": ["Und", "dich", "freu\u00b7en", "in", "dei\u00b7nem", "Her\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "Da\u00df du solche Vorbilder hast.", "tokens": ["Da\u00df", "du", "sol\u00b7che", "Vor\u00b7bil\u00b7der", "hast", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIAT", "NN", "VAFIN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.4": {"text": "Aber mit stolzem Aufblick als ein freier Mann", "tokens": ["A\u00b7ber", "mit", "stol\u00b7zem", "Auf\u00b7blick", "als", "ein", "frei\u00b7er", "Mann"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ADJA", "NN", "KOKOM", "ART", "ADJA", "NN"], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.5": {"text": "Sollst du dir selber sagen:", "tokens": ["Sollst", "du", "dir", "sel\u00b7ber", "sa\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Das H\u00f6chste in der Poesie ", "tokens": ["Das", "H\u00f6chs\u00b7te", "in", "der", "Poe\u00b7sie"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "APPR", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Da\u00df mir von Anfang verboten w\u00e4r',", "tokens": ["Da\u00df", "mir", "von", "An\u00b7fang", "ver\u00b7bo\u00b7ten", "w\u00e4r'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NN", "VVPP", "VAFIN", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.8": {"text": "Es zu erreichen.", "tokens": ["Es", "zu", "er\u00b7rei\u00b7chen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.9": {"text": "Gelingt es nicht,", "tokens": ["Ge\u00b7lingt", "es", "nicht", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKNEG", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.10": {"text": "So wird das Ziel adeln den Versuch", "tokens": ["So", "wird", "das", "Ziel", "a\u00b7deln", "den", "Ver\u00b7such"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ART", "NN", "VVINF", "ART", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.11": {"text": "Und ihn bewundernswerth erscheinen lassen", "tokens": ["Und", "ihn", "be\u00b7wun\u00b7derns\u00b7werth", "er\u00b7schei\u00b7nen", "las\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "ADJD", "VVINF", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Dort, wo er stehn blieb.", "tokens": ["Dort", ",", "wo", "er", "stehn", "blieb", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PWAV", "PPER", "VVINF", "VVFIN", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.21": {"line.1": {"text": "Damals,", "tokens": ["Da\u00b7mals", ","], "token_info": ["word", "punct"], "pos": ["ADV", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.2": {"text": "Als ich umherging einsam", "tokens": ["Als", "ich", "um\u00b7her\u00b7ging", "ein\u00b7sam"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PPER", "VVFIN", "ADJD"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und in mir selbst verlassen,", "tokens": ["Und", "in", "mir", "selbst", "ver\u00b7las\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPER", "ADV", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Verstanden von keinem,", "tokens": ["Ver\u00b7stan\u00b7den", "von", "kei\u00b7nem", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPR", "PIS", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.5": {"text": "Geliebt von keinem,", "tokens": ["Ge\u00b7liebt", "von", "kei\u00b7nem", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVPP", "APPR", "PIS", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.6": {"text": "Und keinen Menschen auf Erden liebend,", "tokens": ["Und", "kei\u00b7nen", "Men\u00b7schen", "auf", "Er\u00b7den", "lie\u00b7bend", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "APPR", "NN", "ADJD", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Die du mir damals ein neues Leben gegeben", "tokens": ["Die", "du", "mir", "da\u00b7mals", "ein", "neu\u00b7es", "Le\u00b7ben", "ge\u00b7ge\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "PPER", "ADV", "ART", "ADJA", "NN", "VVPP"], "meter": "-+-+-++-+--+-", "measure": "iambic.hexa.relaxed"}, "line.8": {"text": "Und eine solche Bl\u00fcthenf\u00fclle von Poesien,", "tokens": ["Und", "ei\u00b7ne", "sol\u00b7che", "Bl\u00fc\u00b7then\u00b7f\u00fcl\u00b7le", "von", "Poe\u00b7si\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "PIAT", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.9": {"text": "Da\u00df ich aufjauchzen mu\u00dfte", "tokens": ["Da\u00df", "ich", "auf\u00b7jauch\u00b7zen", "mu\u00df\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PPER", "VVINF", "VMFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.10": {"text": "Im tiefsten Elend:", "tokens": ["Im", "tiefs\u00b7ten", "E\u00b7lend", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.22": {"line.1": {"text": "Meine Seele verdrie\u00dfet mein Leben.", "tokens": ["Mei\u00b7ne", "See\u00b7le", "ver\u00b7drie\u00b7\u00dfet", "mein", "Le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPOSAT", "NN", "$."], "meter": "+-+--+--+-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Ich will meine Klage erschallen lassen", "tokens": ["Ich", "will", "mei\u00b7ne", "Kla\u00b7ge", "er\u00b7schal\u00b7len", "las\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PPOSAT", "NN", "VVINF", "VVINF"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Und reden von der Betr\u00fcbni\u00df meiner Seele.", "tokens": ["Und", "re\u00b7den", "von", "der", "Be\u00b7tr\u00fcb\u00b7ni\u00df", "mei\u00b7ner", "See\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Ein Gott hat mir den Mund ge\u00f6ffnet,", "tokens": ["Ein", "Gott", "hat", "mir", "den", "Mund", "ge\u00b7\u00f6ff\u00b7net", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Ich kann nicht stumm sein.", "tokens": ["Ich", "kann", "nicht", "stumm", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PTKNEG", "ADJD", "VAINF", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.6": {"text": "Die Vorsehung hat mir ein Schwert gegeben,", "tokens": ["Die", "Vor\u00b7se\u00b7hung", "hat", "mir", "ein", "Schwert", "ge\u00b7ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Ich will es gebrauchen.", "tokens": ["Ich", "will", "es", "ge\u00b7brau\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.8": {"text": "Darum will ich reden, wer es h\u00f6ren wird,", "tokens": ["Da\u00b7rum", "will", "ich", "re\u00b7den", ",", "wer", "es", "h\u00f6\u00b7ren", "wird", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VMFIN", "PPER", "VVINF", "$,", "PWS", "PPER", "VVINF", "VAFIN", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.9": {"text": "Dem werden seine beiden Ohren gellen.", "tokens": ["Dem", "wer\u00b7den", "sei\u00b7ne", "bei\u00b7den", "Oh\u00b7ren", "gel\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPOSAT", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.23": {"line.1": {"text": "Siehst du den Ackersknecht dort?", "tokens": ["Siehst", "du", "den", "A\u00b7ckers\u00b7knecht", "dort", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "ADV", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Auf dem Felde stehet er neben dem Pflug,", "tokens": ["Auf", "dem", "Fel\u00b7de", "ste\u00b7het", "er", "ne\u00b7ben", "dem", "Pflug", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.3": {"text": "Neben Pferd und Rind.", "tokens": ["Ne\u00b7ben", "Pferd", "und", "Rind", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.4": {"text": "Und er spricht mit dem Rind,", "tokens": ["Und", "er", "spricht", "mit", "dem", "Rind", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.5": {"text": "Und das Thier dreht sich um", "tokens": ["Und", "das", "Thier", "dreht", "sich", "um"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "VVFIN", "PRF", "APPR"], "meter": "--++-+", "measure": "anapaest.init"}, "line.6": {"text": "Und br\u00fcllt", "tokens": ["Und", "br\u00fcllt"], "token_info": ["word", "word"], "pos": ["KON", "VVFIN"], "meter": "-+", "measure": "iambic.single"}, "line.7": {"text": "Und glotzt ihn an.", "tokens": ["Und", "glotzt", "ihn", "an", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.8": {"text": "Und er stiert ins Blaue hinein. \u2013", "tokens": ["Und", "er", "stiert", "ins", "Blau\u00b7e", "hin\u00b7ein", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "PPER", "VVFIN", "APPRART", "ADJA", "PTKVZ", "$.", "$("], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.9": {"text": "Die Sonne brennt,", "tokens": ["Die", "Son\u00b7ne", "brennt", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.10": {"text": "So ist ihm hei\u00df.", "tokens": ["So", "ist", "ihm", "hei\u00df", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.11": {"text": "Der Wind weht kalt,", "tokens": ["Der", "Wind", "weht", "kalt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJD", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.12": {"text": "So friert ihn.", "tokens": ["So", "friert", "ihn", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.13": {"text": "Das ist die Erkenntni\u00df, die man ihm gegeben.", "tokens": ["Das", "ist", "die", "Er\u00b7kennt\u00b7ni\u00df", ",", "die", "man", "ihm", "ge\u00b7ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "$,", "PRELS", "PIS", "PPER", "VVPP", "$."], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.14": {"text": "Und er peitscht auf das Pferd", "tokens": ["Und", "er", "peitscht", "auf", "das", "Pferd"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "APPR", "ART", "NN"], "meter": "--+--+", "measure": "anapaest.di.plus"}, "line.15": {"text": "Und er schl\u00e4gt das Rind;", "tokens": ["Und", "er", "schl\u00e4gt", "das", "Rind", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.16": {"text": "Aber die Peitsche, die ihm im Nacken sitzt, sieht er nicht,", "tokens": ["A\u00b7ber", "die", "Peit\u00b7sche", ",", "die", "ihm", "im", "Na\u00b7cken", "sitzt", ",", "sieht", "er", "nicht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "PRELS", "PPER", "APPRART", "NN", "VVFIN", "$,", "VVFIN", "PPER", "PTKNEG", "$,"], "meter": "+--+-+--+--+-+", "measure": "iambic.hexa.invert"}, "line.17": {"text": "Und wie er selber geschlagen wird, merkt er nicht,", "tokens": ["Und", "wie", "er", "sel\u00b7ber", "ge\u00b7schla\u00b7gen", "wird", ",", "merkt", "er", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPER", "ADV", "VVPP", "VAFIN", "$,", "VVFIN", "PPER", "PTKNEG", "$,"], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.18": {"text": "Und welch' ein Menschenleben er dahinlebt,", "tokens": ["Und", "welch'", "ein", "Men\u00b7schen\u00b7le\u00b7ben", "er", "da\u00b7hin\u00b7lebt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAT", "ART", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.19": {"text": "Das wei\u00df er nimmermehr.", "tokens": ["Das", "wei\u00df", "er", "nim\u00b7mer\u00b7mehr", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.24": {"line.1": {"text": "Siehst du die Bergleute dort?", "tokens": ["Siehst", "du", "die", "Berg\u00b7leu\u00b7te", "dort", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "ADV", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.2": {"text": "Beim D\u00e4mmermorgen aus den H\u00fctten kommen sie,", "tokens": ["Beim", "D\u00e4m\u00b7mer\u00b7mor\u00b7gen", "aus", "den", "H\u00fct\u00b7ten", "kom\u00b7men", "sie", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPR", "ART", "NN", "VVFIN", "PPER", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und das Grubenlicht blinkt,", "tokens": ["Und", "das", "Gru\u00b7ben\u00b7licht", "blinkt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "$,"], "meter": "--+--+", "measure": "anapaest.di.plus"}, "line.4": {"text": "Und wenn sie niederfahren, sagen sie gl\u00fcckauf!", "tokens": ["Und", "wenn", "sie", "nie\u00b7der\u00b7fah\u00b7ren", ",", "sa\u00b7gen", "sie", "gl\u00fcc\u00b7kauf", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "VVINF", "$,", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Aber auf ihren Gesichtern da wohnt der Gram,", "tokens": ["A\u00b7ber", "auf", "ih\u00b7ren", "Ge\u00b7sich\u00b7tern", "da", "wohnt", "der", "Gram", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPOSAT", "NN", "ADV", "VVFIN", "ART", "NN", "$,"], "meter": "+--+--+--+-+", "measure": "dactylic.tri.plus"}, "line.6": {"text": "Und in ihren H\u00fctten sieht es j\u00e4mmerlich aus.", "tokens": ["Und", "in", "ih\u00b7ren", "H\u00fct\u00b7ten", "sieht", "es", "j\u00e4m\u00b7mer\u00b7lich", "aus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPOSAT", "NN", "VVFIN", "PPER", "ADJD", "PTKVZ", "$."], "meter": "+-+-+-+-+--+", "measure": "iambic.hexa.chol"}, "line.7": {"text": "Lebendige Leichen sah ich sie in die Erde steigen,", "tokens": ["Le\u00b7ben\u00b7di\u00b7ge", "Lei\u00b7chen", "sah", "ich", "sie", "in", "die", "Er\u00b7de", "stei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVFIN", "PPER", "PPER", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "+---+-+--+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.8": {"text": "Lebendige Leichen kamen sie wieder hervor.", "tokens": ["Le\u00b7ben\u00b7di\u00b7ge", "Lei\u00b7chen", "ka\u00b7men", "sie", "wie\u00b7der", "her\u00b7vor", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVFIN", "PPER", "ADV", "PTKVZ", "$."], "meter": "+---+-+--+--+", "measure": "trochaic.penta.relaxed"}, "line.9": {"text": "Sie k\u00f6nnen nicht leben", "tokens": ["Sie", "k\u00f6n\u00b7nen", "nicht", "le\u00b7ben"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PTKNEG", "VVINF"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.10": {"text": "Und wollen doch nicht sterben.", "tokens": ["Und", "wol\u00b7len", "doch", "nicht", "ster\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ADV", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.11": {"text": "Und ihre Kinder und Enkel m\u00fcssen sie sehen", "tokens": ["Und", "ih\u00b7re", "Kin\u00b7der", "und", "En\u00b7kel", "m\u00fcs\u00b7sen", "sie", "se\u00b7hen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "KON", "NN", "VMFIN", "PPER", "VVINF"], "meter": "-+-+--+-+--+-", "measure": "iambic.penta.relaxed"}, "line.12": {"text": "Erbarmungslos in dasselbe Elend hineinwandern.", "tokens": ["Er\u00b7bar\u00b7mungs\u00b7los", "in", "das\u00b7sel\u00b7be", "E\u00b7lend", "hin\u00b7ein\u00b7wan\u00b7dern", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "PDAT", "NN", "VVINF", "$."], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}}, "stanza.25": {"line.1": {"text": "Aber in den Stra\u00dfen der Stadt,", "tokens": ["A\u00b7ber", "in", "den", "Stra\u00b7\u00dfen", "der", "Stadt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "ART", "NN", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Darin die Menschen wimmeln,", "tokens": ["Da\u00b7rin", "die", "Men\u00b7schen", "wim\u00b7meln", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Wenn du dicht an den H\u00e4usern gehest,", "tokens": ["Wenn", "du", "dicht", "an", "den", "H\u00e4u\u00b7sern", "ge\u00b7hest", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Kannst du es h\u00f6ren:", "tokens": ["Kannst", "du", "es", "h\u00f6\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PPER", "VVINF", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.5": {"text": "Schlag auf Schlag und sp\u00e4t und fr\u00fch,", "tokens": ["Schlag", "auf", "Schlag", "und", "sp\u00e4t", "und", "fr\u00fch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "KON", "ADJD", "KON", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Wie das Herz gehet bei einem Fieberkranken,", "tokens": ["Wie", "das", "Herz", "ge\u00b7het", "bei", "ei\u00b7nem", "Fie\u00b7ber\u00b7kran\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.7": {"text": "So schl\u00e4gt der Webstuhl", "tokens": ["So", "schl\u00e4gt", "der", "Web\u00b7stuhl"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.8": {"text": "Und fliegt das Schiffchen durch,", "tokens": ["Und", "fliegt", "das", "Schiff\u00b7chen", "durch", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "Aber auf der Spule ist der Hunger aufgewickelt,", "tokens": ["A\u00b7ber", "auf", "der", "Spu\u00b7le", "ist", "der", "Hun\u00b7ger", "auf\u00b7ge\u00b7wi\u00b7ckelt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VAFIN", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}, "line.10": {"text": "Und der wird hineingewebt", "tokens": ["Und", "der", "wird", "hin\u00b7ein\u00b7ge\u00b7webt"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "VAFIN", "VVPP"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.11": {"text": "In die gl\u00e4nzenden Zeuge.", "tokens": ["In", "die", "gl\u00e4n\u00b7zen\u00b7den", "Zeu\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}}, "stanza.26": {"line.1": {"text": "In dem Saal,", "tokens": ["In", "dem", "Saal", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.2": {"text": "Wo die Kerzen hell schimmern", "tokens": ["Wo", "die", "Ker\u00b7zen", "hell", "schim\u00b7mern"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "ART", "NN", "ADJD", "VVINF"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "Und die seidnen Gew\u00e4nder knistern und rauschen,", "tokens": ["Und", "die", "seid\u00b7nen", "Ge\u00b7w\u00e4n\u00b7der", "knis\u00b7tern", "und", "rau\u00b7schen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "PPOSAT", "NN", "VVFIN", "KON", "VVFIN", "$,"], "meter": "--+--+-+--+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Da klingt der Reigen,", "tokens": ["Da", "klingt", "der", "Rei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.5": {"text": "Und die jungen Gesichter strahlen", "tokens": ["Und", "die", "jun\u00b7gen", "Ge\u00b7sich\u00b7ter", "strah\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN", "VVINF"], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.6": {"text": "Fr\u00f6hlich vom Tanz.", "tokens": ["Fr\u00f6h\u00b7lich", "vom", "Tanz", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "APPRART", "NN", "$."], "meter": "+--+", "measure": "iambic.di.chol"}, "line.7": {"text": "Und sie setzen sich Paar an Paar", "tokens": ["Und", "sie", "set\u00b7zen", "sich", "Paar", "an", "Paar"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "PRF", "NN", "APPR", "NN"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.8": {"text": "Mit munterem Lachen", "tokens": ["Mit", "mun\u00b7te\u00b7rem", "La\u00b7chen"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ADJA", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.9": {"text": "Zum schimmernden Mahle nieder,", "tokens": ["Zum", "schim\u00b7mern\u00b7den", "Mah\u00b7le", "nie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.10": {"text": "Und die Pfropfen knallen und die Gl\u00e4ser klingen.", "tokens": ["Und", "die", "Pfrop\u00b7fen", "knal\u00b7len", "und", "die", "Gl\u00e4\u00b7ser", "klin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVINF", "KON", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.11": {"text": "Aber auf das gl\u00e4nzende Gewebe dort f\u00e4llt mein Blick,", "tokens": ["A\u00b7ber", "auf", "das", "gl\u00e4n\u00b7zen\u00b7de", "Ge\u00b7we\u00b7be", "dort", "f\u00e4llt", "mein", "Blick", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "ADV", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "+-+-+---+--+-+", "measure": "trochaic.hexa.relaxed"}, "line.12": {"text": "Und daraus hervor grauenhaft", "tokens": ["Und", "da\u00b7raus", "her\u00b7vor", "grau\u00b7en\u00b7haft"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PAV", "PTKVZ", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Das Gespenst des Hungers grinst mich an", "tokens": ["Das", "Ge\u00b7spenst", "des", "Hun\u00b7gers", "grinst", "mich", "an"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "NN", "VVFIN", "PPER", "PTKVZ"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.14": {"text": "Ueber den Tisch.", "tokens": ["Ue\u00b7ber", "den", "Tisch", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$."], "meter": "+--+", "measure": "iambic.di.chol"}}, "stanza.27": {"line.1": {"text": "Siehst du das Geb\u00e4ude dort mit den vielen Fenstern?", "tokens": ["Siehst", "du", "das", "Ge\u00b7b\u00e4u\u00b7de", "dort", "mit", "den", "vie\u00b7len", "Fens\u00b7tern", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "ADV", "APPR", "ART", "PIAT", "NN", "$."], "meter": "+-+-+-+--+-+-", "measure": "trochaic.hexa.relaxed"}, "line.2": {"text": "Und die hohen Schornsteine ragen", "tokens": ["Und", "die", "ho\u00b7hen", "Schorn\u00b7stei\u00b7ne", "ra\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN", "VVINF"], "meter": "--+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "In den blauen Fr\u00fchlingshimmel hinein?", "tokens": ["In", "den", "blau\u00b7en", "Fr\u00fch\u00b7lings\u00b7him\u00b7mel", "hin\u00b7ein", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "--+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Drunten,", "tokens": ["Drun\u00b7ten", ","], "token_info": ["word", "punct"], "pos": ["NN", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.5": {"text": "In dem dunst'gen Raum,", "tokens": ["In", "dem", "dunst'\u00b7gen", "Raum", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.6": {"text": "Dort, wo der Dampf athmet,", "tokens": ["Dort", ",", "wo", "der", "Dampf", "ath\u00b7met", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PWAV", "ART", "NN", "VVFIN", "$,"], "meter": "++--+-", "measure": "trochaic.tri.relaxed"}, "line.7": {"text": "Da spricht der Kessel", "tokens": ["Da", "spricht", "der", "Kes\u00b7sel"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.8": {"text": "Mit zisch und zisch:", "tokens": ["Mit", "zisch", "und", "zisch", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.9": {"text": "Du bist ein Mensch!", "tokens": ["Du", "bist", "ein", "Mensch", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.10": {"text": "Du bist ein Mensch!", "tokens": ["Du", "bist", "ein", "Mensch", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.11": {"text": "La\u00df dich nicht schinden!", "tokens": ["La\u00df", "dich", "nicht", "schin\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "PTKNEG", "VVINF", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.12": {"text": "La\u00df dich nicht schinden!", "tokens": ["La\u00df", "dich", "nicht", "schin\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "PTKNEG", "VVINF", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.13": {"text": "Aber droben,", "tokens": ["A\u00b7ber", "dro\u00b7ben", ","], "token_info": ["word", "word", "punct"], "pos": ["KON", "ADV", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.14": {"text": "In dem weiten Saal,", "tokens": ["In", "dem", "wei\u00b7ten", "Saal", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.15": {"text": "Wo die Spuhlen schwirren", "tokens": ["Wo", "die", "Spuh\u00b7len", "schwir\u00b7ren"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "ART", "NN", "VVINF"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.16": {"text": "Und die R\u00e4der sausen,", "tokens": ["Und", "die", "R\u00e4\u00b7der", "sau\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.17": {"text": "Kinder stehen da", "tokens": ["Kin\u00b7der", "ste\u00b7hen", "da"], "token_info": ["word", "word", "word"], "pos": ["NN", "VVFIN", "ADV"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.18": {"text": "Und kn\u00fcpfen hastig", "tokens": ["Und", "kn\u00fcp\u00b7fen", "has\u00b7tig"], "token_info": ["word", "word", "word"], "pos": ["KON", "VVFIN", "ADJD"], "meter": "-+-+-", "measure": "iambic.di"}, "line.19": {"text": "Mit ihren H\u00e4ndchen,", "tokens": ["Mit", "ih\u00b7ren", "H\u00e4nd\u00b7chen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.20": {"text": "Und kn\u00fcpfen immer", "tokens": ["Und", "kn\u00fcp\u00b7fen", "im\u00b7mer"], "token_info": ["word", "word", "word"], "pos": ["KON", "VVFIN", "ADV"], "meter": "-+-+-", "measure": "iambic.di"}, "line.21": {"text": "Ohne Ende \u2013", "tokens": ["Oh\u00b7ne", "En\u00b7de", "\u2013"], "token_info": ["word", "word", "punct"], "pos": ["APPR", "NN", "$("], "meter": "+-+-", "measure": "trochaic.di"}, "line.22": {"text": "Und sind doch Menschen", "tokens": ["Und", "sind", "doch", "Men\u00b7schen"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VAFIN", "ADV", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.23": {"text": "Und sind Kinder.", "tokens": ["Und", "sind", "Kin\u00b7der", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "NN", "$."], "meter": "+-+-", "measure": "trochaic.di"}}, "stanza.28": {"line.1": {"text": "Aber unweit daneben, da zittert die Erde", "tokens": ["A\u00b7ber", "un\u00b7weit", "da\u00b7ne\u00b7ben", ",", "da", "zit\u00b7tert", "die", "Er\u00b7de"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "PAV", "$,", "ADV", "VVFIN", "ART", "NN"], "meter": "+-+-----+--+-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Vom Sto\u00df des Hammers", "tokens": ["Vom", "Sto\u00df", "des", "Ham\u00b7mers"], "token_info": ["word", "word", "word", "word"], "pos": ["APPRART", "NN", "ART", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.3": {"text": "Und von den eisernen Schl\u00e4gen,", "tokens": ["Und", "von", "den", "ei\u00b7ser\u00b7nen", "Schl\u00e4\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Und es zischelt und es haspelt und es klopft", "tokens": ["Und", "es", "zi\u00b7schelt", "und", "es", "has\u00b7pelt", "und", "es", "klopft"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "KON", "PPER", "VVFIN", "KON", "PPER", "VVFIN"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.5": {"text": "Wie tausend Hexengeister. \u2013", "tokens": ["Wie", "tau\u00b7send", "He\u00b7xen\u00b7geis\u00b7ter", ".", "\u2013"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["PWAV", "CARD", "NN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Es ist Abend, da t\u00f6nt ein Pfiff", "tokens": ["Es", "ist", "A\u00b7bend", ",", "da", "t\u00f6nt", "ein", "Pfiff"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "NN", "$,", "ADV", "VVFIN", "ART", "NN"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.7": {"text": "Gellend laut,", "tokens": ["Gel\u00b7lend", "laut", ","], "token_info": ["word", "word", "punct"], "pos": ["VVPP", "ADJD", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.8": {"text": "Und da kommen sie heraus, trotz'ge Gestalten.", "tokens": ["Und", "da", "kom\u00b7men", "sie", "he\u00b7raus", ",", "trotz'\u00b7ge", "Ge\u00b7stal\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "PTKVZ", "$,", "ADJA", "NN", "$."], "meter": "--+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "Ihnen blitzen die Augen k\u00fchn,", "tokens": ["Ih\u00b7nen", "blit\u00b7zen", "die", "Au\u00b7gen", "k\u00fchn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADJD", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.10": {"text": "Und ihre kr\u00e4ftigen Arme", "tokens": ["Und", "ih\u00b7re", "kr\u00e4f\u00b7ti\u00b7gen", "Ar\u00b7me"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "ADJA", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.11": {"text": "M\u00f6chten wohl einmal auf Anderes schlagen", "tokens": ["M\u00f6ch\u00b7ten", "wohl", "ein\u00b7mal", "auf", "An\u00b7de\u00b7res", "schla\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "ADV", "ADV", "APPR", "PIS", "VVINF"], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.12": {"text": "Als das schuldlose Eisen.", "tokens": ["Als", "das", "schuld\u00b7lo\u00b7se", "Ei\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.13": {"text": "Es geht ein gewaltiger Geisteshauch \u00fcber die Erde,", "tokens": ["Es", "geht", "ein", "ge\u00b7wal\u00b7ti\u00b7ger", "Geis\u00b7tes\u00b7hauch", "\u00fc\u00b7ber", "die", "Er\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+--+--+--+--+-", "measure": "amphibrach.penta.plus"}, "line.14": {"text": "Desgleichen auf Erden noch nie ist gesp\u00fcret worden.", "tokens": ["Des\u00b7glei\u00b7chen", "auf", "Er\u00b7den", "noch", "nie", "ist", "ge\u00b7sp\u00fc\u00b7ret", "wor\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "ADV", "ADV", "VAFIN", "VVPP", "VAPP", "$."], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.15": {"text": "Er w\u00fchlet die Wellen auf vom Grund.", "tokens": ["Er", "w\u00fch\u00b7let", "die", "Wel\u00b7len", "auf", "vom", "Grund", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "APPRART", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.29": {"line.1": {"text": "Dem Ambo\u00df hat es Einer gesagt,", "tokens": ["Dem", "Am\u00b7bo\u00df", "hat", "es", "Ei\u00b7ner", "ge\u00b7sagt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "PIS", "VVPP", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Da\u00df er aus demselben Stoffe gemacht sei", "tokens": ["Da\u00df", "er", "aus", "dem\u00b7sel\u00b7ben", "Stof\u00b7fe", "ge\u00b7macht", "sei"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "PDAT", "NN", "VVPP", "VAFIN"], "meter": "--+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Wie der Hammer,", "tokens": ["Wie", "der", "Ham\u00b7mer", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "$,"], "meter": "--+-", "measure": "anapaest.init"}, "line.4": {"text": "Und siehe, er will nun nicht l\u00e4nger Ambo\u00df sein.", "tokens": ["Und", "sie\u00b7he", ",", "er", "will", "nun", "nicht", "l\u00e4n\u00b7ger", "Am\u00b7bo\u00df", "sein", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVIMP", "$,", "PPER", "VMFIN", "ADV", "PTKNEG", "ADJD", "NN", "VAINF", "$."], "meter": "-+--+--+-+--", "measure": "amphibrach.tri.plus"}, "line.5": {"text": "Darob ist ein gro\u00df Entsetzen gekommen auf die Schl\u00e4ger alle;", "tokens": ["Da\u00b7rob", "ist", "ein", "gro\u00df", "Ent\u00b7set\u00b7zen", "ge\u00b7kom\u00b7men", "auf", "die", "Schl\u00e4\u00b7ger", "al\u00b7le", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "ART", "ADJD", "NN", "VVPP", "APPR", "ART", "NN", "PIS", "$."], "meter": "----+-+--+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "Aber die Geschlagenen sind noch nicht besser daran", "tokens": ["A\u00b7ber", "die", "Ge\u00b7schla\u00b7ge\u00b7nen", "sind", "noch", "nicht", "bes\u00b7ser", "da\u00b7ran"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "VAFIN", "ADV", "PTKNEG", "ADJD", "PAV"], "meter": "+---+--+--+--+", "measure": "trochaic.penta.relaxed"}, "line.7": {"text": "Denn zuvor.", "tokens": ["Denn", "zu\u00b7vor", "."], "token_info": ["word", "word", "punct"], "pos": ["KON", "ADV", "$."], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.30": {"line.1": {"text": "Wie der Arzt pocht an den Leib des Menschen", "tokens": ["Wie", "der", "Arzt", "pocht", "an", "den", "Leib", "des", "Men\u00b7schen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ART", "NN", "VVFIN", "APPR", "ART", "NN", "ART", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Und horcht mit Sorgfalt, da\u00df er ihm sage:", "tokens": ["Und", "horcht", "mit", "Sorg\u00b7falt", ",", "da\u00df", "er", "ihm", "sa\u00b7ge", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "NN", "$,", "KOUS", "PPER", "PPER", "VVFIN", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Hier bist du krank,", "tokens": ["Hier", "bist", "du", "krank", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.4": {"text": "Und hier bist du schwer krank.", "tokens": ["Und", "hier", "bist", "du", "schwer", "krank", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "PPER", "ADJD", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Aber heilen kann ich dich nicht", "tokens": ["A\u00b7ber", "hei\u00b7len", "kann", "ich", "dich", "nicht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVINF", "VMFIN", "PPER", "PRF", "PTKNEG"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.6": {"text": "Und helfen kann ich dir nicht,", "tokens": ["Und", "hel\u00b7fen", "kann", "ich", "dir", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVINF", "VMFIN", "PPER", "PPER", "PTKNEG", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.7": {"text": "So ist die Erkenntni\u00df zu ihnen gekommen", "tokens": ["So", "ist", "die", "Er\u00b7kennt\u00b7ni\u00df", "zu", "ih\u00b7nen", "ge\u00b7kom\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ART", "NN", "APPR", "PPER", "VVPP"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.8": {"text": "Ihrer Krankheit,", "tokens": ["Ih\u00b7rer", "Krank\u00b7heit", ","], "token_info": ["word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.9": {"text": "Und ist noch kein Arzt da, der ihnen helfe,", "tokens": ["Und", "ist", "noch", "kein", "Arzt", "da", ",", "der", "ih\u00b7nen", "hel\u00b7fe", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "PIAT", "NN", "PTKVZ", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.10": {"text": "Und ihr Elend ist nicht auszusagen.", "tokens": ["Und", "ihr", "E\u00b7lend", "ist", "nicht", "aus\u00b7zu\u00b7sa\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VAFIN", "PTKNEG", "VVINF", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.31": {"line.1": {"text": "Seht doch, wie wunderlich es ihnen gehet.", "tokens": ["Seht", "doch", ",", "wie", "wun\u00b7der\u00b7lich", "es", "ih\u00b7nen", "ge\u00b7het", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "$,", "PWAV", "ADJD", "PPER", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Sie pflanzen das Land", "tokens": ["Sie", "pflan\u00b7zen", "das", "Land"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.3": {"text": "Und s\u00e4en die Saaten aus", "tokens": ["Und", "s\u00e4\u00b7en", "die", "Saa\u00b7ten", "aus"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ART", "NN", "APPR"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Und bringen die Ernten ein,", "tokens": ["Und", "brin\u00b7gen", "die", "Ern\u00b7ten", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Und d\u00fcrfen doch der Frucht nicht genie\u00dfen.", "tokens": ["Und", "d\u00fcr\u00b7fen", "doch", "der", "Frucht", "nicht", "ge\u00b7nie\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ADV", "ART", "NN", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Sie bauen alle H\u00e4user", "tokens": ["Sie", "bau\u00b7en", "al\u00b7le", "H\u00e4u\u00b7ser"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PIAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Und k\u00f6nnen nirgend wohnen.", "tokens": ["Und", "k\u00f6n\u00b7nen", "nir\u00b7gend", "woh\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Sie machen Alles,", "tokens": ["Sie", "ma\u00b7chen", "Al\u00b7les", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.9": {"text": "Sie schaffen Alles,", "tokens": ["Sie", "schaf\u00b7fen", "Al\u00b7les", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.10": {"text": "Und sie haben nichts.", "tokens": ["Und", "sie", "ha\u00b7ben", "nichts", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "PIS", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.11": {"text": "Ein Unrecht geschiehet hier, wer kann es ableugnen?", "tokens": ["Ein", "Un\u00b7recht", "ge\u00b7schie\u00b7het", "hier", ",", "wer", "kann", "es", "ab\u00b7leug\u00b7nen", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "$,", "PWS", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+--+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.12": {"text": "Ein blutiges Unrecht geschiehet hier,", "tokens": ["Ein", "blu\u00b7ti\u00b7ges", "Un\u00b7recht", "ge\u00b7schie\u00b7het", "hier", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ADV", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.13": {"text": "Wer wird es s\u00fchnen?", "tokens": ["Wer", "wird", "es", "s\u00fch\u00b7nen", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "VVINF", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.32": {"line.1": {"text": "Der Kaufmann ist mir hochgeachtet,", "tokens": ["Der", "Kauf\u00b7mann", "ist", "mir", "hoch\u00b7ge\u00b7ach\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Der f\u00fcr sich und die Seinen sich qu\u00e4lt", "tokens": ["Der", "f\u00fcr", "sich", "und", "die", "Sei\u00b7nen", "sich", "qu\u00e4lt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "PRF", "KON", "ART", "PPOSS", "PRF", "VVFIN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "In ehrlichem Erwerb.", "tokens": ["In", "ehr\u00b7li\u00b7chem", "Er\u00b7werb", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Ihn sch\u00e4tze ich dem Landmann gleich,", "tokens": ["Ihn", "sch\u00e4t\u00b7ze", "ich", "dem", "Land\u00b7mann", "gleich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ART", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Der den Acker bauet mit schwerer Hand", "tokens": ["Der", "den", "A\u00b7cker", "bau\u00b7et", "mit", "schwe\u00b7rer", "Hand"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ART", "NN", "VVFIN", "APPR", "ADJA", "NN"], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.6": {"text": "Und das Gespenst des Hungers abwehrt von dem Menschen.", "tokens": ["Und", "das", "Ge\u00b7spenst", "des", "Hun\u00b7gers", "ab\u00b7wehrt", "von", "dem", "Men\u00b7schen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ART", "NN", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Aber der Kaufmann ist ja auch elend.", "tokens": ["A\u00b7ber", "der", "Kauf\u00b7mann", "ist", "ja", "auch", "e\u00b7lend", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VAFIN", "ADV", "ADV", "ADJD", "$."], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}, "line.8": {"text": "Die Nachbarn lauern auf seinen Untergang;", "tokens": ["Die", "Nach\u00b7barn", "lau\u00b7ern", "auf", "sei\u00b7nen", "Un\u00b7ter\u00b7gang", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.9": {"text": "Einer jagt den andern, da\u00df er ihn verderbe.", "tokens": ["Ei\u00b7ner", "jagt", "den", "an\u00b7dern", ",", "da\u00df", "er", "ihn", "ver\u00b7der\u00b7be", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ART", "ADJA", "$,", "KOUS", "PPER", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.10": {"text": "Es ist ein Grauen mit anzusehn.", "tokens": ["Es", "ist", "ein", "Grau\u00b7en", "mit", "an\u00b7zu\u00b7sehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "APPR", "VVIZU", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.33": {"line.1": {"text": "Und dazu m\u00fcssen meine Augen sehen,", "tokens": ["Und", "da\u00b7zu", "m\u00fcs\u00b7sen", "mei\u00b7ne", "Au\u00b7gen", "se\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PAV", "VMFIN", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Wie das Blutsaugerthum schamlos waltet im Lande,", "tokens": ["Wie", "das", "Blu\u00b7tsau\u00b7ger\u00b7thum", "scham\u00b7los", "wal\u00b7tet", "im", "Lan\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "ADJD", "VVFIN", "APPRART", "NN", "$,"], "meter": "--+--+--+--+-", "measure": "anapaest.tetra.plus"}, "line.3": {"text": "Und ist keine Schranke da, die ihnen Einhalt thut,", "tokens": ["Und", "ist", "kei\u00b7ne", "Schran\u00b7ke", "da", ",", "die", "ih\u00b7nen", "Ein\u00b7halt", "thut", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PIAT", "NN", "PTKVZ", "$,", "PRELS", "PPER", "NN", "VVFIN", "$,"], "meter": "--+-+-+-+-+-+", "measure": "anapaest.init"}, "line.4": {"text": "Und kein Richter auf Erden, der sie strafe.", "tokens": ["Und", "kein", "Rich\u00b7ter", "auf", "Er\u00b7den", ",", "der", "sie", "stra\u00b7fe", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "APPR", "NN", "$,", "PRELS", "PPER", "VVFIN", "$."], "meter": "--+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Und die sich br\u00fcsten, die Ersten im Lande zu sein,", "tokens": ["Und", "die", "sich", "br\u00fcs\u00b7ten", ",", "die", "Ers\u00b7ten", "im", "Lan\u00b7de", "zu", "sein", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "PRF", "VVFIN", "$,", "ART", "NN", "APPRART", "NN", "PTKZU", "VAINF", "$,"], "meter": "-+-+--+--+--+", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Und sich einbilden, anders geboren zu sein,", "tokens": ["Und", "sich", "ein\u00b7bil\u00b7den", ",", "an\u00b7ders", "ge\u00b7bo\u00b7ren", "zu", "sein", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "VVINF", "$,", "ADV", "VVPP", "PTKZU", "VAINF", "$,"], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.7": {"text": "Als alle andern Menschen \u2013", "tokens": ["Als", "al\u00b7le", "an\u00b7dern", "Men\u00b7schen", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "ADJA", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Das doch eine Beschimpfung der Menschenw\u00fcrde ist", "tokens": ["Das", "doch", "ei\u00b7ne", "Be\u00b7schimp\u00b7fung", "der", "Men\u00b7schen\u00b7w\u00fcr\u00b7de", "ist"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "ADV", "ART", "NN", "ART", "NN", "VAFIN"], "meter": "--+--+--+-+-+", "measure": "anapaest.tri.plus"}, "line.9": {"text": "Und eine L\u00fcge im Angesicht der Wahrheit", "tokens": ["Und", "ei\u00b7ne", "L\u00fc\u00b7ge", "im", "An\u00b7ge\u00b7sicht", "der", "Wahr\u00b7heit"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "APPRART", "NN", "ART", "NN"], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.10": {"text": "Und ein Kinderspott vor der ganzen Welt \u2013", "tokens": ["Und", "ein", "Kin\u00b7der\u00b7spott", "vor", "der", "gan\u00b7zen", "Welt", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "APPR", "ART", "ADJA", "NN", "$("], "meter": "--+----+-+", "measure": "anapaest.init"}, "line.11": {"text": "Die sind mitten darunter.", "tokens": ["Die", "sind", "mit\u00b7ten", "da\u00b7run\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "PAV", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.12": {"text": "Und sie thun sich zusammen zu ganzen Banden", "tokens": ["Und", "sie", "thun", "sich", "zu\u00b7sam\u00b7men", "zu", "gan\u00b7zen", "Ban\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "PRF", "ADV", "APPR", "ADJA", "NN"], "meter": "--+--+--+-+-", "measure": "anapaest.tri.plus"}, "line.13": {"text": "Und fallen das Volk bei hellem, lichten Tage an,", "tokens": ["Und", "fal\u00b7len", "das", "Volk", "bei", "hel\u00b7lem", ",", "lich\u00b7ten", "Ta\u00b7ge", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "APPR", "ADJA", "$,", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.14": {"text": "Da\u00df sie es auspl\u00fcndern.", "tokens": ["Da\u00df", "sie", "es", "aus\u00b7pl\u00fcn\u00b7dern", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.34": {"line.1": {"text": "Und dann lachen sie noch in sich hinein", "tokens": ["Und", "dann", "la\u00b7chen", "sie", "noch", "in", "sich", "hin\u00b7ein"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "PPER", "ADV", "APPR", "PRF", "APZR"], "meter": "--+--+-+-+", "measure": "anapaest.di.plus"}, "line.2": {"text": "Und rufen: das sind die Dummen!", "tokens": ["Und", "ru\u00b7fen", ":", "das", "sind", "die", "Dum\u00b7men", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "PDS", "VAFIN", "ART", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Da es doch blo\u00df die Unwissenden sind", "tokens": ["Da", "es", "doch", "blo\u00df", "die", "Un\u00b7wis\u00b7sen\u00b7den", "sind"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "ADV", "ART", "NN", "VAFIN"], "meter": "-+-+-++-+-", "measure": "unknown.measure.penta"}, "line.4": {"text": "Und die nicht sehen k\u00f6nnen.", "tokens": ["Und", "die", "nicht", "se\u00b7hen", "k\u00f6n\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "PTKNEG", "VVINF", "VMINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Als ob es denn ein k\u00f6stlich Ding sei und ein gro\u00df Werk,", "tokens": ["Als", "ob", "es", "denn", "ein", "k\u00f6st\u00b7lich", "Ding", "sei", "und", "ein", "gro\u00df", "Werk", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "PPER", "ADV", "ART", "ADJD", "NN", "VAFIN", "KON", "ART", "ADJD", "NN", "$,"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "Einen Blinden in den Graben zu sto\u00dfen,", "tokens": ["Ei\u00b7nen", "Blin\u00b7den", "in", "den", "Gra\u00b7ben", "zu", "sto\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+--+-", "measure": "trochaic.penta.relaxed"}, "line.7": {"text": "Oder ein Kind anzulocken und auszurauben.", "tokens": ["O\u00b7der", "ein", "Kind", "an\u00b7zu\u00b7lo\u00b7cken", "und", "aus\u00b7zu\u00b7rau\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVIZU", "KON", "VVIZU", "$."], "meter": "+--++-+--+-+-", "measure": "trochaic.hexa.relaxed"}, "line.8": {"text": "Und Viele, die ein Amt hatten zum Nutzen ihrer Mitmenschen,", "tokens": ["Und", "Vie\u00b7le", ",", "die", "ein", "Amt", "hat\u00b7ten", "zum", "Nut\u00b7zen", "ih\u00b7rer", "Mit\u00b7men\u00b7schen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "$,", "PRELS", "ART", "NN", "VAFIN", "APPRART", "NN", "PPOSAT", "NN", "$,"], "meter": "-+--+-+--+-+-+-+", "measure": "iambic.septa.relaxed"}, "line.9": {"text": "Und das Amt war voll M\u00fche und Arbeit,", "tokens": ["Und", "das", "Amt", "war", "voll", "M\u00fc\u00b7he", "und", "Ar\u00b7beit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VAFIN", "ADJD", "NN", "KON", "NN", "$,"], "meter": "--+--+--+-", "measure": "anapaest.tri.plus"}, "line.10": {"text": "Die lassen ihr Amt und laufen jenen nach,", "tokens": ["Die", "las\u00b7sen", "ihr", "Amt", "und", "lau\u00b7fen", "je\u00b7nen", "nach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPOSAT", "NN", "KON", "VVFIN", "PDS", "PTKVZ", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.11": {"text": "Damit sie auch mit Gier m\u00f6gen Gold einscharren", "tokens": ["Da\u00b7mit", "sie", "auch", "mit", "Gier", "m\u00f6\u00b7gen", "Gold", "ein\u00b7schar\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "APPR", "NN", "VMFIN", "NN", "VVINF"], "meter": "-+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.12": {"text": "Ohne M\u00fche und ohne Arbeit.", "tokens": ["Oh\u00b7ne", "M\u00fc\u00b7he", "und", "oh\u00b7ne", "Ar\u00b7beit", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "APPR", "NN", "$."], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.13": {"text": "Und daf\u00fcr tausend Elende m\u00fcssen noch elender sein", "tokens": ["Und", "da\u00b7f\u00fcr", "tau\u00b7send", "E\u00b7len\u00b7de", "m\u00fcs\u00b7sen", "noch", "e\u00b7len\u00b7der", "sein"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PAV", "CARD", "NN", "VMFIN", "ADV", "ADJD", "VAINF"], "meter": "-+-+-+--+--+--+", "measure": "iambic.hexa.relaxed"}, "line.14": {"text": "Und noch mehr gequ\u00e4lt und noch mehr geschunden.", "tokens": ["Und", "noch", "mehr", "ge\u00b7qu\u00e4lt", "und", "noch", "mehr", "ge\u00b7schun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "VVPP", "KON", "ADV", "ADV", "VVPP", "$."], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.35": {"line.1": {"text": "Ich will meine Stimme erheben", "tokens": ["Ich", "will", "mei\u00b7ne", "Stim\u00b7me", "er\u00b7he\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PPOSAT", "NN", "VVINF"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Und rufen, da\u00df man es weit h\u00f6re:", "tokens": ["Und", "ru\u00b7fen", ",", "da\u00df", "man", "es", "weit", "h\u00f6\u00b7re", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "KOUS", "PIS", "PPER", "ADJD", "VVFIN", "$."], "meter": "-+-++--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Wer nicht arbeitet, der soll nicht leben!", "tokens": ["Wer", "nicht", "ar\u00b7bei\u00b7tet", ",", "der", "soll", "nicht", "le\u00b7ben", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PTKNEG", "VVFIN", "$,", "PRELS", "VMFIN", "PTKNEG", "VVINF", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Der Geist, der heut herrscht, ist eine Schmach den Menschen", "tokens": ["Der", "Geist", ",", "der", "heut", "herrscht", ",", "ist", "ei\u00b7ne", "Schmach", "den", "Men\u00b7schen"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "ADV", "VVPP", "$,", "VAFIN", "ART", "NN", "ART", "NN"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}}, "stanza.36": {"line.1": {"text": "Und eine tiefe Schande den V\u00f6lkern!", "tokens": ["Und", "ei\u00b7ne", "tie\u00b7fe", "Schan\u00b7de", "den", "V\u00f6l\u00b7kern", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "ART", "NN", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Sein Gift fri\u00dft um sich wie der Krebs.", "tokens": ["Sein", "Gift", "fri\u00dft", "um", "sich", "wie", "der", "Krebs", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "APPR", "PRF", "KOKOM", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sie haben sich steinerne Pal\u00e4ste gebaut,", "tokens": ["Sie", "ha\u00b7ben", "sich", "stei\u00b7ner\u00b7ne", "Pa\u00b7l\u00e4s\u00b7te", "ge\u00b7baut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PRF", "ADJA", "NN", "VVPP", "$,"], "meter": "-+--+---+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Aber aus allen Ecken pfeift der Betrug heraus.", "tokens": ["A\u00b7ber", "aus", "al\u00b7len", "E\u00b7cken", "pfeift", "der", "Be\u00b7trug", "he\u00b7raus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PIAT", "NN", "VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "+--+-+-+--+-+", "measure": "iambic.hexa.invert"}, "line.5": {"text": "Wenn der Arbeitsmann vorbeigeht,", "tokens": ["Wenn", "der", "Ar\u00b7beits\u00b7mann", "vor\u00b7bei\u00b7geht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "VVFIN", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.6": {"text": "Er wei\u00df nicht warum, aber er ballt die Hand zur Faust.", "tokens": ["Er", "wei\u00df", "nicht", "wa\u00b7rum", ",", "a\u00b7ber", "er", "ballt", "die", "Hand", "zur", "Faust", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "PWAV", "$,", "KON", "PPER", "VVFIN", "ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.7": {"text": "Auf seinen Aeckern da geht der Bauer", "tokens": ["Auf", "sei\u00b7nen", "A\u00b7e\u00b7ckern", "da", "geht", "der", "Bau\u00b7er"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "ADV", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Und st\u00f6hnet hinter dem Pfluge her.", "tokens": ["Und", "st\u00f6h\u00b7net", "hin\u00b7ter", "dem", "Pflu\u00b7ge", "her", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "Es ist nicht die Arbeit, die ihn st\u00f6hnen macht,", "tokens": ["Es", "ist", "nicht", "die", "Ar\u00b7beit", ",", "die", "ihn", "st\u00f6h\u00b7nen", "macht", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKNEG", "ART", "NN", "$,", "PRELS", "PPER", "VVINF", "VVFIN", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.10": {"text": "Denn sie war sonst seine Lust gewesen.", "tokens": ["Denn", "sie", "war", "sonst", "sei\u00b7ne", "Lust", "ge\u00b7we\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "ADV", "PPOSAT", "NN", "VAPP", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.11": {"text": "Aber die Halme, die er m\u00e4hen wird,", "tokens": ["A\u00b7ber", "die", "Hal\u00b7me", ",", "die", "er", "m\u00e4\u00b7hen", "wird", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "PRELS", "PPER", "VVINF", "VAFIN", "$,"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.12": {"text": "Sie sind nicht mehr sein,", "tokens": ["Sie", "sind", "nicht", "mehr", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKNEG", "ADV", "VAINF", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.13": {"text": "Und sein Haus, darinnen seine Eltern gewohnt,", "tokens": ["Und", "sein", "Haus", ",", "da\u00b7rin\u00b7nen", "sei\u00b7ne", "El\u00b7tern", "ge\u00b7wohnt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "$,", "ADV", "PPOSAT", "NN", "VVPP", "$,"], "meter": "--+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.14": {"text": "Er wird es bald verlassen,", "tokens": ["Er", "wird", "es", "bald", "ver\u00b7las\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.15": {"text": "Frage doch die V\u00f6gel unter dem Himmel,", "tokens": ["Fra\u00b7ge", "doch", "die", "V\u00f6\u00b7gel", "un\u00b7ter", "dem", "Him\u00b7mel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+--+-", "measure": "trochaic.penta.relaxed"}, "line.16": {"text": "Die werden dir's sagen.", "tokens": ["Die", "wer\u00b7den", "dir's", "sa\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PIS", "VVINF", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.37": {"line.1": {"text": "Und haben sich \u00f6ffentliche Bl\u00e4tter gemacht,", "tokens": ["Und", "ha\u00b7ben", "sich", "\u00f6f\u00b7fent\u00b7li\u00b7che", "Bl\u00e4t\u00b7ter", "ge\u00b7macht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PRF", "ADJA", "NN", "VVPP", "$,"], "meter": "-+--++--+--+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Die sprechen von Allem, was nicht ist", "tokens": ["Die", "spre\u00b7chen", "von", "Al\u00b7lem", ",", "was", "nicht", "ist"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PDS", "VVFIN", "APPR", "PIS", "$,", "PRELS", "PTKNEG", "VAFIN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Und was nicht gewesen ist.", "tokens": ["Und", "was", "nicht", "ge\u00b7we\u00b7sen", "ist", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PTKNEG", "VAPP", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Aber was gerecht ist, das reden sie nicht,", "tokens": ["A\u00b7ber", "was", "ge\u00b7recht", "ist", ",", "das", "re\u00b7den", "sie", "nicht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ADJD", "VAFIN", "$,", "PDS", "VVFIN", "PPER", "PTKNEG", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.5": {"text": "Und was noth thut, das sagen sie nicht.", "tokens": ["Und", "was", "noth", "thut", ",", "das", "sa\u00b7gen", "sie", "nicht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "NN", "VVFIN", "$,", "PDS", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.6": {"text": "Nach Gewicht steht da das Talent zu Kauf,", "tokens": ["Nach", "Ge\u00b7wicht", "steht", "da", "das", "Ta\u00b7lent", "zu", "Kauf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "ADV", "ART", "NN", "APPR", "NN", "$,"], "meter": "+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.7": {"text": "Und talentvoll und gewissenlos", "tokens": ["Und", "ta\u00b7lent\u00b7voll", "und", "ge\u00b7wis\u00b7sen\u00b7los"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ADJD", "KON", "ADJD"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Ist bei ihnen einunddasselbe geworden,", "tokens": ["Ist", "bei", "ih\u00b7nen", "ein\u00b7und\u00b7das\u00b7sel\u00b7be", "ge\u00b7wor\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "PPER", "ADJA", "VAPP", "$,"], "meter": "+-+-+--+--+-", "measure": "trochaic.penta.relaxed"}, "line.9": {"text": "Darum sind sie mit Grund gering geachtet.", "tokens": ["Da\u00b7rum", "sind", "sie", "mit", "Grund", "ge\u00b7ring", "ge\u00b7ach\u00b7tet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "PPER", "APPR", "NN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Sie vernichten das Denken,", "tokens": ["Sie", "ver\u00b7nich\u00b7ten", "das", "Den\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.11": {"text": "Das h\u00f6chste Gut des Menschen,", "tokens": ["Das", "h\u00f6chs\u00b7te", "Gut", "des", "Men\u00b7schen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.12": {"text": "Und sie machen stumpfsinnig anstatt zu belehren.", "tokens": ["Und", "sie", "ma\u00b7chen", "stumpf\u00b7sin\u00b7nig", "an\u00b7statt", "zu", "be\u00b7leh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ADJD", "ADJD", "PTKZU", "VVINF", "$."], "meter": "--+--+-+-+-+-", "measure": "anapaest.di.plus"}, "line.13": {"text": "Und r\u00fchmen sich dessen mit Heuchell\u00fcgen", "tokens": ["Und", "r\u00fch\u00b7men", "sich", "des\u00b7sen", "mit", "Heu\u00b7chel\u00b7l\u00fc\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PRF", "PDS", "APPR", "NN"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.14": {"text": "Und nennen ihr Geldgesch\u00e4ft", "tokens": ["Und", "nen\u00b7nen", "ihr", "Geld\u00b7ge\u00b7sch\u00e4ft"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPOSAT", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.15": {"text": "Eine Geisteswohlthat f\u00fcr das Volk.", "tokens": ["Ei\u00b7ne", "Geis\u00b7tes\u00b7wohlt\u00b7hat", "f\u00fcr", "das", "Volk", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.16": {"text": "Sie haben einen feinen Teppich \u00fcber den Sumpf gebreitet", "tokens": ["Sie", "ha\u00b7ben", "ei\u00b7nen", "fei\u00b7nen", "Tep\u00b7pich", "\u00fc\u00b7ber", "den", "Sumpf", "ge\u00b7brei\u00b7tet"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "APPR", "ART", "NN", "VVPP"], "meter": "-+-+-+-+-+--+-+-", "measure": "iambic.septa.relaxed"}, "line.17": {"text": "Und sehen wohl zu, da\u00df nichts durchdringe.", "tokens": ["Und", "se\u00b7hen", "wohl", "zu", ",", "da\u00df", "nichts", "durch\u00b7drin\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "PTKVZ", "$,", "KOUS", "PIS", "VVFIN", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.18": {"text": "Kinder schreiben darin", "tokens": ["Kin\u00b7der", "schrei\u00b7ben", "da\u00b7rin"], "token_info": ["word", "word", "word"], "pos": ["NN", "VVFIN", "PAV"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.19": {"text": "Und N\u00e4rrische m\u00fcssen die Welt regieren.", "tokens": ["Und", "N\u00e4r\u00b7ri\u00b7sche", "m\u00fcs\u00b7sen", "die", "Welt", "re\u00b7gie\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VMFIN", "ART", "NN", "VVINF", "$."], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.20": {"text": "Das Schlagwort ist ihre Angriffswaffe,", "tokens": ["Das", "Schlag\u00b7wort", "ist", "ih\u00b7re", "An\u00b7griffs\u00b7waf\u00b7fe", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.21": {"text": "Und die Phrasen sind ihr t\u00e4gliches Brot.", "tokens": ["Und", "die", "Phra\u00b7sen", "sind", "ihr", "t\u00e4g\u00b7li\u00b7ches", "Brot", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VAFIN", "PPOSAT", "ADJA", "NN", "$."], "meter": "--+-+-+--+", "measure": "iambic.tetra.chol"}, "line.22": {"text": "Die Phrase aber ist der Betrug mit Worten,", "tokens": ["Die", "Phra\u00b7se", "a\u00b7ber", "ist", "der", "Be\u00b7trug", "mit", "Wor\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VAFIN", "ART", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.23": {"text": "Und das Schlagw\u00f6rterthum", "tokens": ["Und", "das", "Schlag\u00b7w\u00f6r\u00b7ter\u00b7thum"], "token_info": ["word", "word", "word"], "pos": ["KON", "ART", "NN"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.24": {"text": "Der Mi\u00dfbrauch gerechter Worte.", "tokens": ["Der", "Mi\u00df\u00b7brauch", "ge\u00b7rech\u00b7ter", "Wor\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.38": {"line.1": {"text": "Wer gewohnt ist, mit klaren Blicken um sich zu schau'n,", "tokens": ["Wer", "ge\u00b7wohnt", "ist", ",", "mit", "kla\u00b7ren", "Bli\u00b7cken", "um", "sich", "zu", "schau'n", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVPP", "VAFIN", "$,", "APPR", "ADJA", "NN", "APPR", "PRF", "PTKZU", "VVINF", "$,"], "meter": "--+--+-+--+-+", "measure": "anapaest.di.plus"}, "line.2": {"text": "Wer sich den schlichten Verstand nicht mag verr\u00fccken lassen", "tokens": ["Wer", "sich", "den", "schlich\u00b7ten", "Ver\u00b7stand", "nicht", "mag", "ver\u00b7r\u00fc\u00b7cken", "las\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWS", "PRF", "ART", "ADJA", "NN", "PTKNEG", "VMFIN", "VVINF", "VVINF"], "meter": "-+-+--+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Und wer seine Sprache liebt, das edelste Geschenk,", "tokens": ["Und", "wer", "sei\u00b7ne", "Spra\u00b7che", "liebt", ",", "das", "e\u00b7dels\u00b7te", "Ge\u00b7schenk", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPOSAT", "NN", "VVFIN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}, "line.4": {"text": "Das dem Menschen ein Gott gegeben,", "tokens": ["Das", "dem", "Men\u00b7schen", "ein", "Gott", "ge\u00b7ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ART", "NN", "ART", "NN", "VVPP", "$,"], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.5": {"text": "Der steht vor der Phrase", "tokens": ["Der", "steht", "vor", "der", "Phra\u00b7se"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "APPR", "ART", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.6": {"text": "Wie vor den Schnalzlauten,", "tokens": ["Wie", "vor", "den", "Schnalz\u00b7lau\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPR", "ART", "NN", "$,"], "meter": "-+-++-", "measure": "unknown.measure.tri"}, "line.7": {"text": "Die die Wilden in Afrika sprechen.", "tokens": ["Die", "die", "Wil\u00b7den", "in", "Af\u00b7ri\u00b7ka", "spre\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "APPR", "NE", "VVINF", "$."], "meter": "--+--+--+-", "measure": "anapaest.tri.plus"}, "line.8": {"text": "Ein Gemisch von Schallwellen schl\u00e4gt an sein Ohr,", "tokens": ["Ein", "Ge\u00b7misch", "von", "Schall\u00b7wel\u00b7len", "schl\u00e4gt", "an", "sein", "Ohr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.9": {"text": "Er h\u00f6rt Laute und wei\u00df keinen Sinn,", "tokens": ["Er", "h\u00f6rt", "Lau\u00b7te", "und", "wei\u00df", "kei\u00b7nen", "Sinn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "KON", "VVFIN", "PIAT", "NN", "$,"], "meter": "-++-+-+-+", "measure": "unknown.measure.penta"}, "line.10": {"text": "Wie Seifenblasen", "tokens": ["Wie", "Sei\u00b7fen\u00b7bla\u00b7sen"], "token_info": ["word", "word"], "pos": ["PWAV", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.11": {"text": "Bl\u00e4hen sich die bunten Worte auf,", "tokens": ["Bl\u00e4\u00b7hen", "sich", "die", "bun\u00b7ten", "Wor\u00b7te", "auf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.12": {"text": "Und wenn sie geplatzt sind,", "tokens": ["Und", "wenn", "sie", "ge\u00b7platzt", "sind", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "VVPP", "VAFIN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.13": {"text": "So ist darinnen das pure Nichts.", "tokens": ["So", "ist", "da\u00b7rin\u00b7nen", "das", "pu\u00b7re", "Nichts", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.14": {"text": "Aber dichtgedr\u00e4ngt stehen die H\u00f6rer umher", "tokens": ["A\u00b7ber", "dicht\u00b7ge\u00b7dr\u00e4ngt", "ste\u00b7hen", "die", "H\u00f6\u00b7rer", "um\u00b7her"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "VVFIN", "ART", "NN", "PTKVZ"], "meter": "+-+--+--+--+", "measure": "trochaic.penta.relaxed"}, "line.15": {"text": "Und klatschen rasenden Beifall.", "tokens": ["Und", "klat\u00b7schen", "ra\u00b7sen\u00b7den", "Bei\u00b7fall", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "ADJA", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.16": {"text": "Und sein Gem\u00fcth wird von Trauer erf\u00fcllt,", "tokens": ["Und", "sein", "Ge\u00b7m\u00fcth", "wird", "von", "Trau\u00b7er", "er\u00b7f\u00fcllt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VAFIN", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.17": {"text": "Und ein unendlicher Ekel ergreift ihn.", "tokens": ["Und", "ein", "un\u00b7end\u00b7li\u00b7cher", "E\u00b7kel", "er\u00b7greift", "ihn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "VVFIN", "PPER", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.39": {"line.1": {"text": "Aber die Dichter, die heut leben,", "tokens": ["A\u00b7ber", "die", "Dich\u00b7ter", ",", "die", "heut", "le\u00b7ben", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "PRELS", "ADV", "VVINF", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Haben sie denn Augen, um nicht zu sehn?", "tokens": ["Ha\u00b7ben", "sie", "denn", "Au\u00b7gen", ",", "um", "nicht", "zu", "sehn", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "NN", "$,", "KOUI", "PTKNEG", "PTKZU", "VVINF", "$."], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Haben sie denn einen Mund, um nicht zu sprechen?", "tokens": ["Ha\u00b7ben", "sie", "denn", "ei\u00b7nen", "Mund", ",", "um", "nicht", "zu", "spre\u00b7chen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ART", "NN", "$,", "KOUI", "PTKNEG", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.4": {"text": "Ach! die besten von ihnen sind gar alt geworden.", "tokens": ["Ach", "!", "die", "bes\u00b7ten", "von", "ih\u00b7nen", "sind", "gar", "alt", "ge\u00b7wor\u00b7den", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$.", "ART", "ADJA", "APPR", "PPER", "VAFIN", "ADV", "ADJD", "VAPP", "$."], "meter": "+-+--+-+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.5": {"text": "Sie haben sich zur\u00fcckgezogen in gerechtem Groll", "tokens": ["Sie", "ha\u00b7ben", "sich", "zu\u00b7r\u00fcck\u00b7ge\u00b7zo\u00b7gen", "in", "ge\u00b7rech\u00b7tem", "Groll"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PRF", "VVPP", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.6": {"text": "Und schreiben nicht mehr,", "tokens": ["Und", "schrei\u00b7ben", "nicht", "mehr", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKNEG", "ADV", "$,"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.7": {"text": "Und die noch schreiben, sind nicht die besten.", "tokens": ["Und", "die", "noch", "schrei\u00b7ben", ",", "sind", "nicht", "die", "bes\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADV", "VVINF", "$,", "VAFIN", "PTKNEG", "ART", "ADJA", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Da ist keiner,", "tokens": ["Da", "ist", "kei\u00b7ner", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIS", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.9": {"text": "Der mit Ernst die Wahrheit m\u00f6chte verk\u00fcnden,", "tokens": ["Der", "mit", "Ernst", "die", "Wahr\u00b7heit", "m\u00f6ch\u00b7te", "ver\u00b7k\u00fcn\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "NE", "ART", "NN", "VMFIN", "VVINF", "$,"], "meter": "--+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "Ob schon die Spatzen auf den D\u00e4chern davon reden.", "tokens": ["Ob", "schon", "die", "Spat\u00b7zen", "auf", "den", "D\u00e4\u00b7chern", "da\u00b7von", "re\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "APPR", "ART", "NN", "PAV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Da ist keiner, der das Schwert ergreift,", "tokens": ["Da", "ist", "kei\u00b7ner", ",", "der", "das", "Schwert", "er\u00b7greift", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIS", "$,", "PRELS", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.12": {"text": "Das blitzende, scharfe Schwert,", "tokens": ["Das", "blit\u00b7zen\u00b7de", ",", "schar\u00b7fe", "Schwert", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "ADJA", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.13": {"text": "Ein Lied zu singen zur rechten Zeit", "tokens": ["Ein", "Lied", "zu", "sin\u00b7gen", "zur", "rech\u00b7ten", "Zeit"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "PTKZU", "VVINF", "APPRART", "ADJA", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.14": {"text": "Mit klingender Form,", "tokens": ["Mit", "klin\u00b7gen\u00b7der", "Form", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.15": {"text": "Aber im Inhalt schonungslos, r\u00fccksichtslos.", "tokens": ["A\u00b7ber", "im", "In\u00b7halt", "scho\u00b7nungs\u00b7los", ",", "r\u00fcck\u00b7sichts\u00b7los", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "APPRART", "NN", "ADJD", "$,", "ADJD", "$."], "meter": "+--+-+--+-+", "measure": "iambic.penta.invert"}, "line.16": {"text": "Die Poesie ist zum Gewerbe geworden.", "tokens": ["Die", "Poe\u00b7sie", "ist", "zum", "Ge\u00b7wer\u00b7be", "ge\u00b7wor\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "APPRART", "NN", "VAPP", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.17": {"text": "Wer am meisten bezahlt bekommt,", "tokens": ["Wer", "am", "meis\u00b7ten", "be\u00b7zahlt", "be\u00b7kommt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPRART", "PIS", "VVPP", "VVFIN", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.18": {"text": "Ist unter ihnen der gr\u00f6\u00dfte Dichter.", "tokens": ["Ist", "un\u00b7ter", "ih\u00b7nen", "der", "gr\u00f6\u00df\u00b7te", "Dich\u00b7ter."], "token_info": ["word", "word", "word", "word", "word", "abbreviation"], "pos": ["VAFIN", "APPR", "PPER", "ART", "ADJA", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.19": {"text": "Was todt und begraben ist,", "tokens": ["Was", "todt", "und", "be\u00b7gra\u00b7ben", "ist", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADJD", "KON", "VVPP", "VAFIN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.20": {"text": "Dagegen k\u00e4mpfen sie,", "tokens": ["Da\u00b7ge\u00b7gen", "k\u00e4mp\u00b7fen", "sie", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.21": {"text": "Und was keinem am Herzen liegt,", "tokens": ["Und", "was", "kei\u00b7nem", "am", "Her\u00b7zen", "liegt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PIS", "APPRART", "NN", "VVFIN", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.22": {"text": "Das bringen sie vor.", "tokens": ["Das", "brin\u00b7gen", "sie", "vor", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.23": {"text": "Mit Stroh gehen sie schwanger", "tokens": ["Mit", "Stroh", "ge\u00b7hen", "sie", "schwan\u00b7ger"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "VVFIN", "PPER", "ADJA"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.24": {"text": "Und Stoppeln geb\u00e4ren sie.", "tokens": ["Und", "Stop\u00b7peln", "ge\u00b7b\u00e4\u00b7ren", "sie", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "PPER", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.25": {"text": "Einen Stecknadelknopf Gold", "tokens": ["Ei\u00b7nen", "Steck\u00b7na\u00b7del\u00b7knopf", "Gold"], "token_info": ["word", "word", "word"], "pos": ["ART", "NN", "NN"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.26": {"text": "Walzen sie zu einem b\u00e4ndigen Romane aus,", "tokens": ["Wal\u00b7zen", "sie", "zu", "ei\u00b7nem", "b\u00e4n\u00b7di\u00b7gen", "Ro\u00b7ma\u00b7ne", "aus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "APPR", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}, "line.27": {"text": "Und sie schl\u00e4fern lieber die Gedanken der Menschen ein,", "tokens": ["Und", "sie", "schl\u00e4\u00b7fern", "lie\u00b7ber", "die", "Ge\u00b7dan\u00b7ken", "der", "Men\u00b7schen", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ADV", "ART", "NN", "ART", "NN", "PTKVZ", "$,"], "meter": "--+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.28": {"text": "Statt neue zu wecken. \u2013", "tokens": ["Statt", "neu\u00b7e", "zu", "we\u00b7cken", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "ADJA", "PTKZU", "VVINF", "$.", "$("], "meter": "+---+-", "measure": "dactylic.init"}, "line.29": {"text": "W\u00fcst und \u00f6de sieht es auf der B\u00fchne aus,", "tokens": ["W\u00fcst", "und", "\u00f6\u00b7de", "sieht", "es", "auf", "der", "B\u00fch\u00b7ne", "aus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KON", "ADJD", "VVFIN", "PPER", "APPR", "ART", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.30": {"text": "Und ich habe Beifall klatschen sehn solchem Schund,", "tokens": ["Und", "ich", "ha\u00b7be", "Bei\u00b7fall", "klat\u00b7schen", "sehn", "sol\u00b7chem", "Schund", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "NN", "VVINF", "VVFIN", "PIAT", "NN", "$,"], "meter": "+-+-+-+-+--+", "measure": "iambic.hexa.chol"}, "line.31": {"text": "Da\u00df ich nicht wu\u00dfte, ob ich unter Irren war,", "tokens": ["Da\u00df", "ich", "nicht", "wu\u00df\u00b7te", ",", "ob", "ich", "un\u00b7ter", "Ir\u00b7ren", "war", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "VVFIN", "$,", "KOUS", "PPER", "APPR", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Oder in Gemeinschaft vernunftbegabter Menschen.", "tokens": ["O\u00b7der", "in", "Ge\u00b7mein\u00b7schaft", "ver\u00b7nunft\u00b7be\u00b7gab\u00b7ter", "Men\u00b7schen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "ADJA", "NN", "$."], "meter": "+-+-+--+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.33": {"text": "Und sie nennen sich selber Epigonen.", "tokens": ["Und", "sie", "nen\u00b7nen", "sich", "sel\u00b7ber", "E\u00b7pi\u00b7go\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PRF", "ADV", "NN", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}}, "stanza.40": {"line.1": {"text": "Wohl hat es Heroen in unserer Dichtkunst gegeben;", "tokens": ["Wohl", "hat", "es", "He\u00b7roen", "in", "un\u00b7se\u00b7rer", "Dicht\u00b7kunst", "ge\u00b7ge\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "NN", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+--+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Aber im Staub vor ihnen zu liegen", "tokens": ["A\u00b7ber", "im", "Staub", "vor", "ih\u00b7nen", "zu", "lie\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPRART", "NN", "APPR", "PPER", "PTKZU", "VVINF"], "meter": "+--+-+--+-", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Und im Gef\u00fchl der eig'nen Ohnmacht anzubeten,", "tokens": ["Und", "im", "Ge\u00b7f\u00fchl", "der", "eig'\u00b7nen", "Ohn\u00b7macht", "an\u00b7zu\u00b7be\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "NN", "ART", "ADJA", "NN", "VVIZU", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Das ist Sklaven-Art.", "tokens": ["Das", "ist", "Skla\u00b7ven\u00b7Art", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "NN", "$."], "meter": "--+-+", "measure": "anapaest.init"}, "line.5": {"text": "Nicht also gebietet der Genius,", "tokens": ["Nicht", "al\u00b7so", "ge\u00b7bie\u00b7tet", "der", "Ge\u00b7nius", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "VVFIN", "ART", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Sondern mit ernstem Munde spricht er:", "tokens": ["Son\u00b7dern", "mit", "erns\u00b7tem", "Mun\u00b7de", "spricht", "er", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ADJA", "NN", "VVFIN", "PPER", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}}, "stanza.41": {"line.1": {"text": "Liebend sollst du dein Haupt vor ihnen beugen", "tokens": ["Lie\u00b7bend", "sollst", "du", "dein", "Haupt", "vor", "ih\u00b7nen", "beu\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADJD", "VMFIN", "PPER", "PPOSAT", "NN", "APPR", "PPER", "VVINF"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.2": {"text": "Und dich freuen in deinem Herzen,", "tokens": ["Und", "dich", "freu\u00b7en", "in", "dei\u00b7nem", "Her\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "Da\u00df du solche Vorbilder hast.", "tokens": ["Da\u00df", "du", "sol\u00b7che", "Vor\u00b7bil\u00b7der", "hast", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIAT", "NN", "VAFIN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.4": {"text": "Aber mit stolzem Aufblick als ein freier Mann", "tokens": ["A\u00b7ber", "mit", "stol\u00b7zem", "Auf\u00b7blick", "als", "ein", "frei\u00b7er", "Mann"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ADJA", "NN", "KOKOM", "ART", "ADJA", "NN"], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.5": {"text": "Sollst du dir selber sagen:", "tokens": ["Sollst", "du", "dir", "sel\u00b7ber", "sa\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Das H\u00f6chste in der Poesie ", "tokens": ["Das", "H\u00f6chs\u00b7te", "in", "der", "Poe\u00b7sie"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "APPR", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Da\u00df mir von Anfang verboten w\u00e4r',", "tokens": ["Da\u00df", "mir", "von", "An\u00b7fang", "ver\u00b7bo\u00b7ten", "w\u00e4r'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NN", "VVPP", "VAFIN", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.8": {"text": "Es zu erreichen.", "tokens": ["Es", "zu", "er\u00b7rei\u00b7chen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.9": {"text": "Gelingt es nicht,", "tokens": ["Ge\u00b7lingt", "es", "nicht", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKNEG", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.10": {"text": "So wird das Ziel adeln den Versuch", "tokens": ["So", "wird", "das", "Ziel", "a\u00b7deln", "den", "Ver\u00b7such"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ART", "NN", "VVINF", "ART", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.11": {"text": "Und ihn bewundernswerth erscheinen lassen", "tokens": ["Und", "ihn", "be\u00b7wun\u00b7derns\u00b7werth", "er\u00b7schei\u00b7nen", "las\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "ADJD", "VVINF", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Dort, wo er stehn blieb.", "tokens": ["Dort", ",", "wo", "er", "stehn", "blieb", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PWAV", "PPER", "VVINF", "VVFIN", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.42": {"line.1": {"text": "Damals,", "tokens": ["Da\u00b7mals", ","], "token_info": ["word", "punct"], "pos": ["ADV", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.2": {"text": "Als ich umherging einsam", "tokens": ["Als", "ich", "um\u00b7her\u00b7ging", "ein\u00b7sam"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PPER", "VVFIN", "ADJD"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und in mir selbst verlassen,", "tokens": ["Und", "in", "mir", "selbst", "ver\u00b7las\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPER", "ADV", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Verstanden von keinem,", "tokens": ["Ver\u00b7stan\u00b7den", "von", "kei\u00b7nem", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPR", "PIS", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.5": {"text": "Geliebt von keinem,", "tokens": ["Ge\u00b7liebt", "von", "kei\u00b7nem", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVPP", "APPR", "PIS", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.6": {"text": "Und keinen Menschen auf Erden liebend,", "tokens": ["Und", "kei\u00b7nen", "Men\u00b7schen", "auf", "Er\u00b7den", "lie\u00b7bend", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "APPR", "NN", "ADJD", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Die du mir damals ein neues Leben gegeben", "tokens": ["Die", "du", "mir", "da\u00b7mals", "ein", "neu\u00b7es", "Le\u00b7ben", "ge\u00b7ge\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "PPER", "ADV", "ART", "ADJA", "NN", "VVPP"], "meter": "-+-+-++-+--+-", "measure": "iambic.hexa.relaxed"}, "line.8": {"text": "Und eine solche Bl\u00fcthenf\u00fclle von Poesien,", "tokens": ["Und", "ei\u00b7ne", "sol\u00b7che", "Bl\u00fc\u00b7then\u00b7f\u00fcl\u00b7le", "von", "Poe\u00b7si\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "PIAT", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.9": {"text": "Da\u00df ich aufjauchzen mu\u00dfte", "tokens": ["Da\u00df", "ich", "auf\u00b7jauch\u00b7zen", "mu\u00df\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PPER", "VVINF", "VMFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.10": {"text": "Im tiefsten Elend:", "tokens": ["Im", "tiefs\u00b7ten", "E\u00b7lend", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "$."], "meter": "-+-+-", "measure": "iambic.di"}}}}}