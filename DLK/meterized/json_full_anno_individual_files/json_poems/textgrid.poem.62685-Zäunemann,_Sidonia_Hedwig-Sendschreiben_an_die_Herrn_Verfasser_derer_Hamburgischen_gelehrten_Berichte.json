{"textgrid.poem.62685": {"metadata": {"author": {"name": "Z\u00e4unemann, Sidonia Hedwig", "birth": "N.A.", "death": "N.A."}, "title": "Sendschreiben an die Herrn Verfasser derer Hamburgischen gelehrten Berichte", "genre": "verse", "period": "N.A.", "pub_year": 1727, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Was hat ", "tokens": ["Was", "hat"], "token_info": ["word", "word"], "pos": ["PWS", "VAFIN"], "meter": "-+", "measure": "iambic.single"}, "line.2": {"text": "Das Ihr ein holdes Blat mir j\u00fcngsthin zugeschrieben?", "tokens": ["Das", "Ihr", "ein", "hol\u00b7des", "Blat", "mir", "j\u00fcng\u00b7sthin", "zu\u00b7ge\u00b7schrie\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ART", "ADJA", "NN", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Was bracht Euch doch darzu? Was nehmt ihr zum Behuf,", "tokens": ["Was", "bracht", "Euch", "doch", "dar\u00b7zu", "?", "Was", "nehmt", "ihr", "zum", "Be\u00b7huf", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "PAV", "$.", "PWS", "VVFIN", "PPER", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ists nicht die H\u00f6flichkeit? Denn schwerlich hat der Ruf", "tokens": ["Ists", "nicht", "die", "H\u00f6f\u00b7lich\u00b7keit", "?", "Denn", "schwer\u00b7lich", "hat", "der", "Ruf"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NE", "PTKNEG", "ART", "NN", "$.", "KON", "ADJD", "VAFIN", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Von meinem heischen Rohr dergleichen w\u00fcrken k\u00f6nnen.", "tokens": ["Von", "mei\u00b7nem", "hei\u00b7schen", "Rohr", "derg\u00b7lei\u00b7chen", "w\u00fcr\u00b7ken", "k\u00f6n\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "PIS", "VVINF", "VMINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Ich hab es wohl erwegt: Drum werdet ihr verg\u00f6nnen,", "tokens": ["Ich", "hab", "es", "wohl", "er\u00b7wegt", ":", "Drum", "wer\u00b7det", "ihr", "ver\u00b7g\u00f6n\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "VVPP", "$.", "PAV", "VAFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Da\u00df meine Feder setzt: ", "tokens": ["Da\u00df", "mei\u00b7ne", "Fe\u00b7der", "setzt", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "Hat blo\u00df die H\u00f6flichkeit zur Absicht und zum Ziel.", "tokens": ["Hat", "blo\u00df", "die", "H\u00f6f\u00b7lich\u00b7keit", "zur", "Ab\u00b7sicht", "und", "zum", "Ziel", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "APPRART", "NN", "KON", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Man sagt zwar sonsten wohl, man k\u00f6nte bey den Linden", "tokens": ["Man", "sagt", "zwar", "sons\u00b7ten", "wohl", ",", "man", "k\u00f6n\u00b7te", "bey", "den", "Lin\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "ADV", "ADV", "ADV", "$,", "PIS", "VMFIN", "APPR", "ART", "NE"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Dergleichen sonderlich vor andern sehn und finden.", "tokens": ["Derg\u00b7lei\u00b7chen", "son\u00b7der\u00b7lich", "vor", "an\u00b7dern", "sehn", "und", "fin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "ADJD", "APPR", "PIS", "VVINF", "KON", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Ein Meister schmeichelt sich, und legt sich dieses bey.", "tokens": ["Ein", "Meis\u00b7ter", "schmei\u00b7chelt", "sich", ",", "und", "legt", "sich", "die\u00b7ses", "bey", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PRF", "$,", "KON", "VVFIN", "PRF", "PDAT", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Allein wer w\u00e4re wohl so th\u00f6rigt, k\u00fchn und frey,", "tokens": ["Al\u00b7lein", "wer", "w\u00e4\u00b7re", "wohl", "so", "th\u00f6\u00b7rigt", ",", "k\u00fchn", "und", "frey", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PWS", "VAFIN", "ADV", "ADV", "ADJD", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Der diesen Ruhm nicht auch der Elbe g\u00f6nnen wolte,", "tokens": ["Der", "die\u00b7sen", "Ruhm", "nicht", "auch", "der", "El\u00b7be", "g\u00f6n\u00b7nen", "wol\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PDAT", "NN", "PTKNEG", "ADV", "ART", "NE", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Wofern er Euer Thun genau erforschen solte?", "tokens": ["Wo\u00b7fern", "er", "Eu\u00b7er", "Thun", "ge\u00b7nau", "er\u00b7for\u00b7schen", "sol\u00b7te", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "ADJD", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Die\u00df zeugt ja Euer Brief. Und die Erfahrung lehrt,", "tokens": ["Die\u00df", "zeugt", "ja", "Eu\u00b7er", "Brief", ".", "Und", "die", "Er\u00b7fah\u00b7rung", "lehrt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "PPOSAT", "NN", "$.", "KON", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Da\u00df Niedersachsen auch die H\u00f6flichkeit verehrt.", "tokens": ["Da\u00df", "Nie\u00b7der\u00b7sach\u00b7sen", "auch", "die", "H\u00f6f\u00b7lich\u00b7keit", "ver\u00b7ehrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "ADV", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Was aber suchet Ihr ", "tokens": ["Was", "a\u00b7ber", "su\u00b7chet", "Ihr"], "token_info": ["word", "word", "word", "word"], "pos": ["PWS", "ADV", "VVFIN", "PPER"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.18": {"text": "Befiehlt die Billigkeit, erlaubt die Wahrheit heucheln?", "tokens": ["Be\u00b7fiehlt", "die", "Bil\u00b7lig\u00b7keit", ",", "er\u00b7laubt", "die", "Wahr\u00b7heit", "heu\u00b7cheln", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$,", "VVFIN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Wie? w\u00e4r mein Kiel geschickt? was dichtet Ihr mir an?", "tokens": ["Wie", "?", "w\u00e4r", "mein", "Kiel", "ge\u00b7schickt", "?", "was", "dich\u00b7tet", "Ihr", "mir", "an", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$.", "VAFIN", "PPOSAT", "NN", "VVPP", "$.", "PWS", "VVFIN", "PPER", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Ich weis nicht, ob Ihr mir hierbey zu viel gethan?", "tokens": ["Ich", "weis", "nicht", ",", "ob", "Ihr", "mir", "hier\u00b7bey", "zu", "viel", "ge\u00b7than", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKVZ", "PTKNEG", "$,", "KOUS", "PPER", "PPER", "ADV", "PTKA", "PIS", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Hier komt nach Eurem Wunsch die Ode der Hussaren.", "tokens": ["Hier", "komt", "nach", "Eu\u00b7rem", "Wunsch", "die", "O\u00b7de", "der", "Hus\u00b7sa\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "PPOSAT", "NN", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Die\u00df ist mein ganzer Rest. Nun kan ich keins mehr spahren.", "tokens": ["Die\u00df", "ist", "mein", "gan\u00b7zer", "Rest", ".", "Nun", "kan", "ich", "keins", "mehr", "spah\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPOSAT", "ADJA", "NN", "$.", "ADV", "VMFIN", "PPER", "PIAT", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Den angenehmen Brief von unserm Held ", "tokens": ["Den", "an\u00b7ge\u00b7neh\u00b7men", "Brief", "von", "un\u00b7serm", "Held"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.24": {"text": "Den haben viele zwar der gr\u00f6\u00dften hier gesehn.", "tokens": ["Den", "ha\u00b7ben", "vie\u00b7le", "zwar", "der", "gr\u00f6\u00df\u00b7ten", "hier", "ge\u00b7sehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PIS", "ADV", "ART", "ADJA", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Ich aber habe nie die Abschrift unternommen,", "tokens": ["Ich", "a\u00b7ber", "ha\u00b7be", "nie", "die", "Ab\u00b7schrift", "un\u00b7ter\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VAFIN", "ADV", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Drum wird an dessen stat hierbey was anders kommen,", "tokens": ["Drum", "wird", "an", "des\u00b7sen", "stat", "hier\u00b7bey", "was", "an\u00b7ders", "kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "APPR", "PDS", "VVFIN", "ADV", "PWS", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "So davon Zeugni\u00df giebt. Wer weis ob nicht ", "tokens": ["So", "da\u00b7von", "Zeug\u00b7ni\u00df", "giebt", ".", "Wer", "weis", "ob", "nicht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "PAV", "NN", "VVFIN", "$.", "PWS", "PTKVZ", "KOUS", "PTKNEG"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.28": {"text": "Auf mich erz\u00fcrnet w\u00e4r? wofern die ganze Welt", "tokens": ["Auf", "mich", "er\u00b7z\u00fcr\u00b7net", "w\u00e4r", "?", "wo\u00b7fern", "die", "gan\u00b7ze", "Welt"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "PPER", "VVFIN", "VAFIN", "$.", "KOUS", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Den Hand-Brief, den Er mir so gn\u00e4dig \u00fcberschickte,", "tokens": ["Den", "Han\u00b7dBrief", ",", "den", "Er", "mir", "so", "gn\u00e4\u00b7dig", "\u00fc\u00b7bersc\u00b7hick\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "PPER", "ADV", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "In Abschrift, oder gar in ofnem Druck erblickte.", "tokens": ["In", "Ab\u00b7schrift", ",", "o\u00b7der", "gar", "in", "of\u00b7nem", "Druck", "er\u00b7blick\u00b7te", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "KON", "ADV", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Drum hab ich ihn verwahrt, damit es nicht gescheh.", "tokens": ["Drum", "hab", "ich", "ihn", "ver\u00b7wahrt", ",", "da\u00b7mit", "es", "nicht", "ge\u00b7scheh", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "PPER", "PPER", "VVPP", "$,", "KOUS", "PPER", "PTKNEG", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Dieweil ich zum Beschlu\u00df aus Eurem Brief erseh,", "tokens": ["Die\u00b7weil", "ich", "zum", "Be\u00b7schlu\u00df", "aus", "Eu\u00b7rem", "Brief", "er\u00b7seh", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPRART", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "Da\u00df Ihr in Willens habt, ein Pack gelehrter Sachen,", "tokens": ["Da\u00df", "Ihr", "in", "Wil\u00b7lens", "habt", ",", "ein", "Pack", "ge\u00b7lehr\u00b7ter", "Sa\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NN", "VAFIN", "$,", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "Mir bey Gelegenheit geneigt zu \u00fcbermachen,", "tokens": ["Mir", "bey", "Ge\u00b7le\u00b7gen\u00b7heit", "ge\u00b7neigt", "zu", "\u00fc\u00b7ber\u00b7ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "NN", "VVPP", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "So danck ich im voraus nach Pflicht und Schuldigkeit", "tokens": ["So", "danck", "ich", "im", "vo\u00b7raus", "nach", "Pflicht", "und", "Schul\u00b7dig\u00b7keit"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "PPER", "APPRART", "ADV", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "Denn ", "tokens": ["Denn"], "token_info": ["word"], "pos": ["KON"], "meter": "+", "measure": "single.up"}}, "stanza.2": {"line.1": {"text": "Was hat ", "tokens": ["Was", "hat"], "token_info": ["word", "word"], "pos": ["PWS", "VAFIN"], "meter": "-+", "measure": "iambic.single"}, "line.2": {"text": "Das Ihr ein holdes Blat mir j\u00fcngsthin zugeschrieben?", "tokens": ["Das", "Ihr", "ein", "hol\u00b7des", "Blat", "mir", "j\u00fcng\u00b7sthin", "zu\u00b7ge\u00b7schrie\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ART", "ADJA", "NN", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Was bracht Euch doch darzu? Was nehmt ihr zum Behuf,", "tokens": ["Was", "bracht", "Euch", "doch", "dar\u00b7zu", "?", "Was", "nehmt", "ihr", "zum", "Be\u00b7huf", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "PAV", "$.", "PWS", "VVFIN", "PPER", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ists nicht die H\u00f6flichkeit? Denn schwerlich hat der Ruf", "tokens": ["Ists", "nicht", "die", "H\u00f6f\u00b7lich\u00b7keit", "?", "Denn", "schwer\u00b7lich", "hat", "der", "Ruf"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NE", "PTKNEG", "ART", "NN", "$.", "KON", "ADJD", "VAFIN", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Von meinem heischen Rohr dergleichen w\u00fcrken k\u00f6nnen.", "tokens": ["Von", "mei\u00b7nem", "hei\u00b7schen", "Rohr", "derg\u00b7lei\u00b7chen", "w\u00fcr\u00b7ken", "k\u00f6n\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "PIS", "VVINF", "VMINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Ich hab es wohl erwegt: Drum werdet ihr verg\u00f6nnen,", "tokens": ["Ich", "hab", "es", "wohl", "er\u00b7wegt", ":", "Drum", "wer\u00b7det", "ihr", "ver\u00b7g\u00f6n\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "VVPP", "$.", "PAV", "VAFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Da\u00df meine Feder setzt: ", "tokens": ["Da\u00df", "mei\u00b7ne", "Fe\u00b7der", "setzt", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "Hat blo\u00df die H\u00f6flichkeit zur Absicht und zum Ziel.", "tokens": ["Hat", "blo\u00df", "die", "H\u00f6f\u00b7lich\u00b7keit", "zur", "Ab\u00b7sicht", "und", "zum", "Ziel", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "APPRART", "NN", "KON", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Man sagt zwar sonsten wohl, man k\u00f6nte bey den Linden", "tokens": ["Man", "sagt", "zwar", "sons\u00b7ten", "wohl", ",", "man", "k\u00f6n\u00b7te", "bey", "den", "Lin\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "ADV", "ADV", "ADV", "$,", "PIS", "VMFIN", "APPR", "ART", "NE"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Dergleichen sonderlich vor andern sehn und finden.", "tokens": ["Derg\u00b7lei\u00b7chen", "son\u00b7der\u00b7lich", "vor", "an\u00b7dern", "sehn", "und", "fin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "ADJD", "APPR", "PIS", "VVINF", "KON", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Ein Meister schmeichelt sich, und legt sich dieses bey.", "tokens": ["Ein", "Meis\u00b7ter", "schmei\u00b7chelt", "sich", ",", "und", "legt", "sich", "die\u00b7ses", "bey", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PRF", "$,", "KON", "VVFIN", "PRF", "PDAT", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Allein wer w\u00e4re wohl so th\u00f6rigt, k\u00fchn und frey,", "tokens": ["Al\u00b7lein", "wer", "w\u00e4\u00b7re", "wohl", "so", "th\u00f6\u00b7rigt", ",", "k\u00fchn", "und", "frey", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PWS", "VAFIN", "ADV", "ADV", "ADJD", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Der diesen Ruhm nicht auch der Elbe g\u00f6nnen wolte,", "tokens": ["Der", "die\u00b7sen", "Ruhm", "nicht", "auch", "der", "El\u00b7be", "g\u00f6n\u00b7nen", "wol\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PDAT", "NN", "PTKNEG", "ADV", "ART", "NE", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Wofern er Euer Thun genau erforschen solte?", "tokens": ["Wo\u00b7fern", "er", "Eu\u00b7er", "Thun", "ge\u00b7nau", "er\u00b7for\u00b7schen", "sol\u00b7te", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "ADJD", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Die\u00df zeugt ja Euer Brief. Und die Erfahrung lehrt,", "tokens": ["Die\u00df", "zeugt", "ja", "Eu\u00b7er", "Brief", ".", "Und", "die", "Er\u00b7fah\u00b7rung", "lehrt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "PPOSAT", "NN", "$.", "KON", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Da\u00df Niedersachsen auch die H\u00f6flichkeit verehrt.", "tokens": ["Da\u00df", "Nie\u00b7der\u00b7sach\u00b7sen", "auch", "die", "H\u00f6f\u00b7lich\u00b7keit", "ver\u00b7ehrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "ADV", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Was aber suchet Ihr ", "tokens": ["Was", "a\u00b7ber", "su\u00b7chet", "Ihr"], "token_info": ["word", "word", "word", "word"], "pos": ["PWS", "ADV", "VVFIN", "PPER"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.18": {"text": "Befiehlt die Billigkeit, erlaubt die Wahrheit heucheln?", "tokens": ["Be\u00b7fiehlt", "die", "Bil\u00b7lig\u00b7keit", ",", "er\u00b7laubt", "die", "Wahr\u00b7heit", "heu\u00b7cheln", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$,", "VVFIN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Wie? w\u00e4r mein Kiel geschickt? was dichtet Ihr mir an?", "tokens": ["Wie", "?", "w\u00e4r", "mein", "Kiel", "ge\u00b7schickt", "?", "was", "dich\u00b7tet", "Ihr", "mir", "an", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$.", "VAFIN", "PPOSAT", "NN", "VVPP", "$.", "PWS", "VVFIN", "PPER", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Ich weis nicht, ob Ihr mir hierbey zu viel gethan?", "tokens": ["Ich", "weis", "nicht", ",", "ob", "Ihr", "mir", "hier\u00b7bey", "zu", "viel", "ge\u00b7than", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKVZ", "PTKNEG", "$,", "KOUS", "PPER", "PPER", "ADV", "PTKA", "PIS", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Hier komt nach Eurem Wunsch die Ode der Hussaren.", "tokens": ["Hier", "komt", "nach", "Eu\u00b7rem", "Wunsch", "die", "O\u00b7de", "der", "Hus\u00b7sa\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "PPOSAT", "NN", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Die\u00df ist mein ganzer Rest. Nun kan ich keins mehr spahren.", "tokens": ["Die\u00df", "ist", "mein", "gan\u00b7zer", "Rest", ".", "Nun", "kan", "ich", "keins", "mehr", "spah\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPOSAT", "ADJA", "NN", "$.", "ADV", "VMFIN", "PPER", "PIAT", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Den angenehmen Brief von unserm Held ", "tokens": ["Den", "an\u00b7ge\u00b7neh\u00b7men", "Brief", "von", "un\u00b7serm", "Held"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.24": {"text": "Den haben viele zwar der gr\u00f6\u00dften hier gesehn.", "tokens": ["Den", "ha\u00b7ben", "vie\u00b7le", "zwar", "der", "gr\u00f6\u00df\u00b7ten", "hier", "ge\u00b7sehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PIS", "ADV", "ART", "ADJA", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Ich aber habe nie die Abschrift unternommen,", "tokens": ["Ich", "a\u00b7ber", "ha\u00b7be", "nie", "die", "Ab\u00b7schrift", "un\u00b7ter\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VAFIN", "ADV", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Drum wird an dessen stat hierbey was anders kommen,", "tokens": ["Drum", "wird", "an", "des\u00b7sen", "stat", "hier\u00b7bey", "was", "an\u00b7ders", "kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "APPR", "PDS", "VVFIN", "ADV", "PWS", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "So davon Zeugni\u00df giebt. Wer weis ob nicht ", "tokens": ["So", "da\u00b7von", "Zeug\u00b7ni\u00df", "giebt", ".", "Wer", "weis", "ob", "nicht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "PAV", "NN", "VVFIN", "$.", "PWS", "PTKVZ", "KOUS", "PTKNEG"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.28": {"text": "Auf mich erz\u00fcrnet w\u00e4r? wofern die ganze Welt", "tokens": ["Auf", "mich", "er\u00b7z\u00fcr\u00b7net", "w\u00e4r", "?", "wo\u00b7fern", "die", "gan\u00b7ze", "Welt"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "PPER", "VVFIN", "VAFIN", "$.", "KOUS", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Den Hand-Brief, den Er mir so gn\u00e4dig \u00fcberschickte,", "tokens": ["Den", "Han\u00b7dBrief", ",", "den", "Er", "mir", "so", "gn\u00e4\u00b7dig", "\u00fc\u00b7bersc\u00b7hick\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "PPER", "ADV", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "In Abschrift, oder gar in ofnem Druck erblickte.", "tokens": ["In", "Ab\u00b7schrift", ",", "o\u00b7der", "gar", "in", "of\u00b7nem", "Druck", "er\u00b7blick\u00b7te", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "KON", "ADV", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Drum hab ich ihn verwahrt, damit es nicht gescheh.", "tokens": ["Drum", "hab", "ich", "ihn", "ver\u00b7wahrt", ",", "da\u00b7mit", "es", "nicht", "ge\u00b7scheh", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "PPER", "PPER", "VVPP", "$,", "KOUS", "PPER", "PTKNEG", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Dieweil ich zum Beschlu\u00df aus Eurem Brief erseh,", "tokens": ["Die\u00b7weil", "ich", "zum", "Be\u00b7schlu\u00df", "aus", "Eu\u00b7rem", "Brief", "er\u00b7seh", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPRART", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "Da\u00df Ihr in Willens habt, ein Pack gelehrter Sachen,", "tokens": ["Da\u00df", "Ihr", "in", "Wil\u00b7lens", "habt", ",", "ein", "Pack", "ge\u00b7lehr\u00b7ter", "Sa\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NN", "VAFIN", "$,", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "Mir bey Gelegenheit geneigt zu \u00fcbermachen,", "tokens": ["Mir", "bey", "Ge\u00b7le\u00b7gen\u00b7heit", "ge\u00b7neigt", "zu", "\u00fc\u00b7ber\u00b7ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "NN", "VVPP", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "So danck ich im voraus nach Pflicht und Schuldigkeit", "tokens": ["So", "danck", "ich", "im", "vo\u00b7raus", "nach", "Pflicht", "und", "Schul\u00b7dig\u00b7keit"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "PPER", "APPRART", "ADV", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "Denn ", "tokens": ["Denn"], "token_info": ["word"], "pos": ["KON"], "meter": "+", "measure": "single.up"}}}}}