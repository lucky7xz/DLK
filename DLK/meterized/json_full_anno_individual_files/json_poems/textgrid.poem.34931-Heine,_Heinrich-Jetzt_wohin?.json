{"textgrid.poem.34931": {"metadata": {"author": {"name": "Heine, Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "Jetzt wohin?", "genre": "verse", "period": "N.A.", "pub_year": 1826, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Jetzt wohin? Der dumme Fu\u00df", "tokens": ["Jetzt", "wo\u00b7hin", "?", "Der", "dum\u00b7me", "Fu\u00df"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "PWAV", "$.", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Will mich gern nach Deutschland tragen;", "tokens": ["Will", "mich", "gern", "nach", "Deutschland", "tra\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "APPR", "NE", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Doch es sch\u00fcttelt klug das Haupt", "tokens": ["Doch", "es", "sch\u00fct\u00b7telt", "klug", "das", "Haupt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "ADJD", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Mein Verstand und scheint zu sagen:", "tokens": ["Mein", "Ver\u00b7stand", "und", "scheint", "zu", "sa\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "VVFIN", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "\u203azwar beendigt ist der Krieg,", "tokens": ["\u203a", "zwar", "be\u00b7en\u00b7digt", "ist", "der", "Krieg", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VVPP", "VAFIN", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Doch die Kriegsgerichte blieben,", "tokens": ["Doch", "die", "Kriegs\u00b7ge\u00b7rich\u00b7te", "blie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und es hei\u00dft, du habest einst", "tokens": ["Und", "es", "hei\u00dft", ",", "du", "ha\u00b7best", "einst"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "$,", "PPER", "VAFIN", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Viel Erschie\u00dfliches geschrieben.\u2039", "tokens": ["Viel", "Er\u00b7schie\u00df\u00b7li\u00b7ches", "ge\u00b7schrie\u00b7ben", ".", "\u2039"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["PIAT", "ADJA", "VVPP", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Das ist wahr, unangenehm", "tokens": ["Das", "ist", "wahr", ",", "un\u00b7an\u00b7ge\u00b7nehm"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["PDS", "VAFIN", "ADJD", "$,", "ADJD"], "meter": "----+-+", "measure": "unknown.measure.di"}, "line.2": {"text": "W\u00e4r mir das Erschossenwerden;", "tokens": ["W\u00e4r", "mir", "das", "Er\u00b7schos\u00b7sen\u00b7wer\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Bin kein Held, es fehlen mir", "tokens": ["Bin", "kein", "Held", ",", "es", "feh\u00b7len", "mir"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["VAFIN", "PIAT", "NN", "$,", "PPER", "VVFIN", "PPER"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Die pathetischen Geb\u00e4rden.", "tokens": ["Die", "pa\u00b7the\u00b7ti\u00b7schen", "Ge\u00b7b\u00e4r\u00b7den", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.4": {"line.1": {"text": "Gern w\u00fcrd ich nach England gehn,", "tokens": ["Gern", "w\u00fcrd", "ich", "nach", "En\u00b7gland", "gehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "APPR", "NE", "VVINF", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "W\u00e4ren dort nicht Kohlend\u00e4mpfe", "tokens": ["W\u00e4\u00b7ren", "dort", "nicht", "Koh\u00b7len\u00b7d\u00e4mp\u00b7fe"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "PTKNEG", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und Engl\u00e4nder \u2013 schon ihr Duft", "tokens": ["Und", "En\u00b7gl\u00e4n\u00b7der", "\u2013", "schon", "ihr", "Duft"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["KON", "NN", "$(", "ADV", "PPOSAT", "NN"], "meter": "-++-+-+", "measure": "unknown.measure.tetra"}, "line.4": {"text": "Gibt Erbrechen mir und Kr\u00e4mpfe.", "tokens": ["Gibt", "Er\u00b7bre\u00b7chen", "mir", "und", "Kr\u00e4mp\u00b7fe", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "PPER", "KON", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Manchmal kommt mir in den Sinn,", "tokens": ["Manch\u00b7mal", "kommt", "mir", "in", "den", "Sinn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Nach Amerika zu segeln,", "tokens": ["Nach", "A\u00b7me\u00b7ri\u00b7ka", "zu", "se\u00b7geln", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Nach dem gro\u00dfen Freiheitstall,", "tokens": ["Nach", "dem", "gro\u00b7\u00dfen", "Frei\u00b7heit\u00b7stall", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Der bewohnt von Gleichheitsflegeln \u2013", "tokens": ["Der", "be\u00b7wohnt", "von", "Gleich\u00b7heits\u00b7fle\u00b7geln", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "VVPP", "APPR", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Doch es \u00e4ngstet mich ein Land,", "tokens": ["Doch", "es", "\u00e4ngs\u00b7tet", "mich", "ein", "Land", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Wo die Menschen Tabak k\u00e4uen,", "tokens": ["Wo", "die", "Men\u00b7schen", "Ta\u00b7bak", "k\u00e4u\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wo sie ohne K\u00f6nig kegeln,", "tokens": ["Wo", "sie", "oh\u00b7ne", "K\u00f6\u00b7nig", "ke\u00b7geln", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "APPR", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wo sie ohne Spucknapf speien.", "tokens": ["Wo", "sie", "oh\u00b7ne", "Spuck\u00b7napf", "spei\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "APPR", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Ru\u00dfland, dieses sch\u00f6ne Reich,", "tokens": ["Ru\u00df\u00b7land", ",", "die\u00b7ses", "sch\u00f6\u00b7ne", "Reich", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PDAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "W\u00fcrde mir vielleicht behagen,", "tokens": ["W\u00fcr\u00b7de", "mir", "viel\u00b7leicht", "be\u00b7ha\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Doch im Winter k\u00f6nnte ich", "tokens": ["Doch", "im", "Win\u00b7ter", "k\u00f6nn\u00b7te", "ich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPRART", "NN", "VMFIN", "PPER"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Dort die Knute nicht ertragen.", "tokens": ["Dort", "die", "Knu\u00b7te", "nicht", "er\u00b7tra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "PTKNEG", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Traurig schau ich in die H\u00f6h',", "tokens": ["Trau\u00b7rig", "schau", "ich", "in", "die", "H\u00f6h'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Wo viel tausend Sterne nicken \u2013", "tokens": ["Wo", "viel", "tau\u00b7send", "Ster\u00b7ne", "ni\u00b7cken", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "CARD", "NN", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Aber meinen eignen Stern", "tokens": ["A\u00b7ber", "mei\u00b7nen", "eig\u00b7nen", "Stern"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Kann ich nirgens dort erblicken.", "tokens": ["Kann", "ich", "nir\u00b7gens", "dort", "er\u00b7bli\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "ADV", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Hat im g\u00fcldnen Labyrinth", "tokens": ["Hat", "im", "g\u00fcld\u00b7nen", "La\u00b7by\u00b7rinth"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "APPRART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Sich vielleicht verirrt am Himmel,", "tokens": ["Sich", "viel\u00b7leicht", "ver\u00b7irrt", "am", "Him\u00b7mel", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADV", "VVPP", "APPRART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wie ich selber mich verirrt", "tokens": ["Wie", "ich", "sel\u00b7ber", "mich", "ver\u00b7irrt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "ADV", "PPER", "VVPP"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "In dem irdischen Get\u00fcmmel. \u2013", "tokens": ["In", "dem", "ir\u00b7di\u00b7schen", "Ge\u00b7t\u00fcm\u00b7mel", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Jetzt wohin? Der dumme Fu\u00df", "tokens": ["Jetzt", "wo\u00b7hin", "?", "Der", "dum\u00b7me", "Fu\u00df"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "PWAV", "$.", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Will mich gern nach Deutschland tragen;", "tokens": ["Will", "mich", "gern", "nach", "Deutschland", "tra\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "APPR", "NE", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Doch es sch\u00fcttelt klug das Haupt", "tokens": ["Doch", "es", "sch\u00fct\u00b7telt", "klug", "das", "Haupt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "ADJD", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Mein Verstand und scheint zu sagen:", "tokens": ["Mein", "Ver\u00b7stand", "und", "scheint", "zu", "sa\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "VVFIN", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "\u203azwar beendigt ist der Krieg,", "tokens": ["\u203a", "zwar", "be\u00b7en\u00b7digt", "ist", "der", "Krieg", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VVPP", "VAFIN", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Doch die Kriegsgerichte blieben,", "tokens": ["Doch", "die", "Kriegs\u00b7ge\u00b7rich\u00b7te", "blie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und es hei\u00dft, du habest einst", "tokens": ["Und", "es", "hei\u00dft", ",", "du", "ha\u00b7best", "einst"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "$,", "PPER", "VAFIN", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Viel Erschie\u00dfliches geschrieben.\u2039", "tokens": ["Viel", "Er\u00b7schie\u00df\u00b7li\u00b7ches", "ge\u00b7schrie\u00b7ben", ".", "\u2039"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["PIAT", "ADJA", "VVPP", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Das ist wahr, unangenehm", "tokens": ["Das", "ist", "wahr", ",", "un\u00b7an\u00b7ge\u00b7nehm"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["PDS", "VAFIN", "ADJD", "$,", "ADJD"], "meter": "----+-+", "measure": "unknown.measure.di"}, "line.2": {"text": "W\u00e4r mir das Erschossenwerden;", "tokens": ["W\u00e4r", "mir", "das", "Er\u00b7schos\u00b7sen\u00b7wer\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Bin kein Held, es fehlen mir", "tokens": ["Bin", "kein", "Held", ",", "es", "feh\u00b7len", "mir"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["VAFIN", "PIAT", "NN", "$,", "PPER", "VVFIN", "PPER"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Die pathetischen Geb\u00e4rden.", "tokens": ["Die", "pa\u00b7the\u00b7ti\u00b7schen", "Ge\u00b7b\u00e4r\u00b7den", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.13": {"line.1": {"text": "Gern w\u00fcrd ich nach England gehn,", "tokens": ["Gern", "w\u00fcrd", "ich", "nach", "En\u00b7gland", "gehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "APPR", "NE", "VVINF", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "W\u00e4ren dort nicht Kohlend\u00e4mpfe", "tokens": ["W\u00e4\u00b7ren", "dort", "nicht", "Koh\u00b7len\u00b7d\u00e4mp\u00b7fe"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "PTKNEG", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und Engl\u00e4nder \u2013 schon ihr Duft", "tokens": ["Und", "En\u00b7gl\u00e4n\u00b7der", "\u2013", "schon", "ihr", "Duft"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["KON", "NN", "$(", "ADV", "PPOSAT", "NN"], "meter": "-++-+-+", "measure": "unknown.measure.tetra"}, "line.4": {"text": "Gibt Erbrechen mir und Kr\u00e4mpfe.", "tokens": ["Gibt", "Er\u00b7bre\u00b7chen", "mir", "und", "Kr\u00e4mp\u00b7fe", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "PPER", "KON", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "Manchmal kommt mir in den Sinn,", "tokens": ["Manch\u00b7mal", "kommt", "mir", "in", "den", "Sinn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Nach Amerika zu segeln,", "tokens": ["Nach", "A\u00b7me\u00b7ri\u00b7ka", "zu", "se\u00b7geln", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Nach dem gro\u00dfen Freiheitstall,", "tokens": ["Nach", "dem", "gro\u00b7\u00dfen", "Frei\u00b7heit\u00b7stall", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Der bewohnt von Gleichheitsflegeln \u2013", "tokens": ["Der", "be\u00b7wohnt", "von", "Gleich\u00b7heits\u00b7fle\u00b7geln", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "VVPP", "APPR", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.15": {"line.1": {"text": "Doch es \u00e4ngstet mich ein Land,", "tokens": ["Doch", "es", "\u00e4ngs\u00b7tet", "mich", "ein", "Land", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Wo die Menschen Tabak k\u00e4uen,", "tokens": ["Wo", "die", "Men\u00b7schen", "Ta\u00b7bak", "k\u00e4u\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wo sie ohne K\u00f6nig kegeln,", "tokens": ["Wo", "sie", "oh\u00b7ne", "K\u00f6\u00b7nig", "ke\u00b7geln", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "APPR", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wo sie ohne Spucknapf speien.", "tokens": ["Wo", "sie", "oh\u00b7ne", "Spuck\u00b7napf", "spei\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "APPR", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.16": {"line.1": {"text": "Ru\u00dfland, dieses sch\u00f6ne Reich,", "tokens": ["Ru\u00df\u00b7land", ",", "die\u00b7ses", "sch\u00f6\u00b7ne", "Reich", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PDAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "W\u00fcrde mir vielleicht behagen,", "tokens": ["W\u00fcr\u00b7de", "mir", "viel\u00b7leicht", "be\u00b7ha\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Doch im Winter k\u00f6nnte ich", "tokens": ["Doch", "im", "Win\u00b7ter", "k\u00f6nn\u00b7te", "ich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPRART", "NN", "VMFIN", "PPER"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Dort die Knute nicht ertragen.", "tokens": ["Dort", "die", "Knu\u00b7te", "nicht", "er\u00b7tra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "PTKNEG", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.17": {"line.1": {"text": "Traurig schau ich in die H\u00f6h',", "tokens": ["Trau\u00b7rig", "schau", "ich", "in", "die", "H\u00f6h'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Wo viel tausend Sterne nicken \u2013", "tokens": ["Wo", "viel", "tau\u00b7send", "Ster\u00b7ne", "ni\u00b7cken", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "CARD", "NN", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Aber meinen eignen Stern", "tokens": ["A\u00b7ber", "mei\u00b7nen", "eig\u00b7nen", "Stern"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Kann ich nirgens dort erblicken.", "tokens": ["Kann", "ich", "nir\u00b7gens", "dort", "er\u00b7bli\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "ADV", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.18": {"line.1": {"text": "Hat im g\u00fcldnen Labyrinth", "tokens": ["Hat", "im", "g\u00fcld\u00b7nen", "La\u00b7by\u00b7rinth"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "APPRART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Sich vielleicht verirrt am Himmel,", "tokens": ["Sich", "viel\u00b7leicht", "ver\u00b7irrt", "am", "Him\u00b7mel", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADV", "VVPP", "APPRART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wie ich selber mich verirrt", "tokens": ["Wie", "ich", "sel\u00b7ber", "mich", "ver\u00b7irrt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "ADV", "PPER", "VVPP"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "In dem irdischen Get\u00fcmmel. \u2013", "tokens": ["In", "dem", "ir\u00b7di\u00b7schen", "Ge\u00b7t\u00fcm\u00b7mel", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}}}}