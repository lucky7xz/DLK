{"textgrid.poem.60681": {"metadata": {"author": {"name": "La Fontaine, Jean de", "birth": "N.A.", "death": "N.A."}, "title": "1L: Ein blutjunges M\u00e4uschen, das nichts noch gesehn,", "genre": "verse", "period": "N.A.", "pub_year": 1658, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ein blutjunges M\u00e4uschen, das nichts noch gesehn,", "tokens": ["Ein", "blut\u00b7jun\u00b7ges", "M\u00e4u\u00b7schen", ",", "das", "nichts", "noch", "ge\u00b7sehn", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PRELS", "PIS", "ADV", "VVPP", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "W\u00e4r ahnungslos beinah ums Leben gekommen.", "tokens": ["W\u00e4r", "ah\u00b7nungs\u00b7los", "bei\u00b7nah", "ums", "Le\u00b7ben", "ge\u00b7kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "ADV", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "H\u00f6rt, wie's seiner Mutter erz\u00e4hlt, was geschehn:", "tokens": ["H\u00f6rt", ",", "wie's", "sei\u00b7ner", "Mut\u00b7ter", "er\u00b7z\u00e4hlt", ",", "was", "ge\u00b7schehn", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "$,", "KOUS", "PPOSAT", "NN", "VVFIN", "$,", "PRELS", "VVPP", "$."], "meter": "+-+-+--+--+", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "\u00bbich hatte wie spielend die Berge genommen,", "tokens": ["\u00bb", "ich", "hat\u00b7te", "wie", "spie\u00b7lend", "die", "Ber\u00b7ge", "ge\u00b7nom\u00b7men", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "KOKOM", "ADJD", "ART", "NN", "VVPP", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.5": {"text": "Die rings unser Reich umstehn,", "tokens": ["Die", "rings", "un\u00b7ser", "Reich", "um\u00b7stehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Und trottete wie eine junge Ratte dahin.", "tokens": ["Und", "trot\u00b7te\u00b7te", "wie", "ei\u00b7ne", "jun\u00b7ge", "Rat\u00b7te", "da\u00b7hin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "KOKOM", "ART", "ADJA", "NN", "PAV", "$."], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.7": {"text": "Da sah ich zwei Tiere gehn:", "tokens": ["Da", "sah", "ich", "zwei", "Tie\u00b7re", "gehn", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "CARD", "NN", "VVINF", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "Das eine sanftm\u00fctig und z\u00e4rtlich und sch\u00f6n,", "tokens": ["Das", "ei\u00b7ne", "sanft\u00b7m\u00fc\u00b7tig", "und", "z\u00e4rt\u00b7lich", "und", "sch\u00f6n", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ART", "ADJD", "KON", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-++--+--+", "measure": "iambic.penta.relaxed"}, "line.9": {"text": "Das andere grob und von z\u00e4nkischem Sinn.", "tokens": ["Das", "an\u00b7de\u00b7re", "grob", "und", "von", "z\u00e4n\u00b7ki\u00b7schem", "Sinn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJD", "KON", "APPR", "ADJA", "NN", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.10": {"text": "Das machte ein rohes und schrilles Gekreisch", "tokens": ["Das", "mach\u00b7te", "ein", "ro\u00b7hes", "und", "schril\u00b7les", "Ge\u00b7kreisch"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "ART", "ADJA", "KON", "ADJA", "NN"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.11": {"text": "Und hatte am Kopf einen Fetzen Fleisch", "tokens": ["Und", "hat\u00b7te", "am", "Kopf", "ei\u00b7nen", "Fet\u00b7zen", "Fleisch"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "APPRART", "NN", "ART", "NN", "NN"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.12": {"text": "Und fuhr durch die Luft voll Verwegenheit,", "tokens": ["Und", "fuhr", "durch", "die", "Luft", "voll", "Ver\u00b7we\u00b7gen\u00b7heit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "ADJD", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.13": {"text": "Und sein Schwanz war buschig und breit.\u00ab", "tokens": ["Und", "sein", "Schwanz", "war", "bu\u00b7schig", "und", "breit", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "PPOSAT", "NN", "VAFIN", "ADJD", "KON", "ADJD", "$.", "$("], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.14": {"text": "Kurz, unser M\u00e4uschen machte da", "tokens": ["Kurz", ",", "un\u00b7ser", "M\u00e4u\u00b7schen", "mach\u00b7te", "da"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["ADJD", "$,", "PPOSAT", "NN", "VVFIN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Der Mutter von einem H\u00e4hnchen ein Bild,", "tokens": ["Der", "Mut\u00b7ter", "von", "ei\u00b7nem", "H\u00e4hn\u00b7chen", "ein", "Bild", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "ART", "NN", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.16": {"text": "Als sei das ein Tier aus Amerika.", "tokens": ["Als", "sei", "das", "ein", "Tier", "aus", "A\u00b7me\u00b7ri\u00b7ka", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VAFIN", "PDS", "ART", "NN", "APPR", "NE", "$."], "meter": "-+--+-+---", "measure": "iambic.tri.relaxed"}, "line.17": {"text": "\u00bbes schlug sich\u00ab, erz\u00e4hlte es, \u00bbfuchsteufelswild", "tokens": ["\u00bb", "es", "schlug", "sich", "\u00ab", ",", "er\u00b7z\u00e4hl\u00b7te", "es", ",", "\u00bb", "fuchs\u00b7teu\u00b7fels\u00b7wild"], "token_info": ["punct", "word", "word", "word", "punct", "punct", "word", "word", "punct", "punct", "word"], "pos": ["$(", "PPER", "VVFIN", "PRF", "$(", "$,", "VVFIN", "PPER", "$,", "$(", "NN"], "meter": "-+--+--++-+", "measure": "iambic.penta.relaxed"}, "line.18": {"text": "Die Schenkel mit seinen Armen", "tokens": ["Die", "Schen\u00b7kel", "mit", "sei\u00b7nen", "Ar\u00b7men"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.19": {"text": "Und machte Spektakel zum Gotterbarmen,", "tokens": ["Und", "mach\u00b7te", "Spek\u00b7ta\u00b7kel", "zum", "Got\u00b7ter\u00b7bar\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.20": {"text": "Da\u00df ich mit all meinem Mut im Schild", "tokens": ["Da\u00df", "ich", "mit", "all", "mei\u00b7nem", "Mut", "im", "Schild"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "PIAT", "PPOSAT", "NN", "APPRART", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.21": {"text": "Mein Heil im Rei\u00dfausnehmen suchte", "tokens": ["Mein", "Heil", "im", "Rei\u00df\u00b7aus\u00b7neh\u00b7men", "such\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "APPRART", "NN", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.22": {"text": "Und das Vieh im Herzen verfluchte.", "tokens": ["Und", "das", "Vieh", "im", "Her\u00b7zen", "ver\u00b7fluch\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "APPRART", "NN", "VVFIN", "$."], "meter": "--+-+--+-", "measure": "iambic.tri.relaxed"}, "line.23": {"text": "So ward ich mit jenem Tier, das so mild", "tokens": ["So", "ward", "ich", "mit", "je\u00b7nem", "Tier", ",", "das", "so", "mild"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "APPR", "PDAT", "NN", "$,", "PRELS", "ADV", "ADJD"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.24": {"text": "Mir erschien, leider gar nicht bekannt.", "tokens": ["Mir", "er\u00b7schien", ",", "lei\u00b7der", "gar", "nicht", "be\u00b7kannt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "ADV", "ADV", "PTKNEG", "ADJD", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.25": {"text": "Getigert und samten war sein Fell,", "tokens": ["Ge\u00b7ti\u00b7gert", "und", "sam\u00b7ten", "war", "sein", "Fell", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "KON", "VVFIN", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "----+-+-+", "measure": "unknown.measure.tri"}, "line.26": {"text": "Dem\u00fctig sein Auge und dennoch so hell.", "tokens": ["De\u00b7m\u00fc\u00b7tig", "sein", "Au\u00b7ge", "und", "den\u00b7noch", "so", "hell", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "PPOSAT", "NN", "KON", "ADV", "ADV", "ADJD", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.27": {"text": "Ich glaube, es ist mit uns M\u00e4usen verwandt,", "tokens": ["Ich", "glau\u00b7be", ",", "es", "ist", "mit", "uns", "M\u00e4u\u00b7sen", "ver\u00b7wandt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VAFIN", "APPR", "PPER", "NN", "VVPP", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.28": {"text": "Denn Ohren hat es ganz \u00e4hnlich wie wir.", "tokens": ["Denn", "Oh\u00b7ren", "hat", "es", "ganz", "\u00e4hn\u00b7lich", "wie", "wir", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VAFIN", "PPER", "ADV", "ADJD", "KOKOM", "PPER", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.29": {"text": "Ich wollte es gr\u00fc\u00dfen, da hat jener Fant", "tokens": ["Ich", "woll\u00b7te", "es", "gr\u00fc\u00b7\u00dfen", ",", "da", "hat", "je\u00b7ner", "Fant"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PPER", "VVINF", "$,", "ADV", "VAFIN", "PDAT", "NN"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.30": {"text": "Getobt, da\u00df ich schleunigst davongerannt.\u00ab", "tokens": ["Ge\u00b7tobt", ",", "da\u00df", "ich", "schleu\u00b7nigst", "da\u00b7von\u00b7ge\u00b7rannt", ".", "\u00ab"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVPP", "$,", "KOUS", "PPER", "ADV", "VVFIN", "$.", "$("], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.31": {"text": "Da sprach die Alte: \u00bbMein Kind, jenes Tier,", "tokens": ["Da", "sprach", "die", "Al\u00b7te", ":", "\u00bb", "Mein", "Kind", ",", "je\u00b7nes", "Tier", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$.", "$(", "PPOSAT", "NN", "$,", "PDAT", "NN", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.32": {"text": "Das dir so liebensw\u00fcrdig erschienen,", "tokens": ["Das", "dir", "so", "lie\u00b7bens\u00b7w\u00fcr\u00b7dig", "er\u00b7schie\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "ADV", "ADJD", "VVPP", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.33": {"text": "Hei\u00dft Katze, und trotz der scheinheiligen Mienen", "tokens": ["Hei\u00dft", "Kat\u00b7ze", ",", "und", "trotz", "der", "schein\u00b7hei\u00b7li\u00b7gen", "Mie\u00b7nen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "NN", "$,", "KON", "APPR", "ART", "ADJA", "NN"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.34": {"text": "Verfolgt es die Unsern mit M\u00f6rdergier.", "tokens": ["Ver\u00b7folgt", "es", "die", "Un\u00b7sern", "mit", "M\u00f6r\u00b7der\u00b7gier", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "APPR", "NN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.35": {"text": "Das andre indes ist ein harmloses Tier,", "tokens": ["Das", "and\u00b7re", "in\u00b7des", "ist", "ein", "harm\u00b7lo\u00b7ses", "Tier", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.36": {"text": "Wird uns vielleicht als Mahlzeit dienen", "tokens": ["Wird", "uns", "viel\u00b7leicht", "als", "Mahl\u00b7zeit", "die\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "ADV", "KOUS", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.37": {"text": "Demn\u00e4chst einmal; bei der Katze jedoch", "tokens": ["Dem\u00b7n\u00e4chst", "ein\u00b7mal", ";", "bei", "der", "Kat\u00b7ze", "je\u00b7doch"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "$.", "APPR", "ART", "NN", "ADV"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.38": {"text": "Sind ", "tokens": ["Sind"], "token_info": ["word"], "pos": ["VAFIN"], "meter": "-", "measure": "single.down"}, "line.39": {"text": "Bei vielen Leuten stimmt es nicht,", "tokens": ["Bei", "vie\u00b7len", "Leu\u00b7ten", "stimmt", "es", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVFIN", "PPER", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.40": {"text": "Wenn man sie sch\u00e4tzt nach ihrem Gesicht!\u00ab", "tokens": ["Wenn", "man", "sie", "sch\u00e4tzt", "nach", "ih\u00b7rem", "Ge\u00b7sicht", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PIS", "PPER", "VVFIN", "APPR", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.2": {"line.1": {"text": "Ein blutjunges M\u00e4uschen, das nichts noch gesehn,", "tokens": ["Ein", "blut\u00b7jun\u00b7ges", "M\u00e4u\u00b7schen", ",", "das", "nichts", "noch", "ge\u00b7sehn", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PRELS", "PIS", "ADV", "VVPP", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "W\u00e4r ahnungslos beinah ums Leben gekommen.", "tokens": ["W\u00e4r", "ah\u00b7nungs\u00b7los", "bei\u00b7nah", "ums", "Le\u00b7ben", "ge\u00b7kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "ADV", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "H\u00f6rt, wie's seiner Mutter erz\u00e4hlt, was geschehn:", "tokens": ["H\u00f6rt", ",", "wie's", "sei\u00b7ner", "Mut\u00b7ter", "er\u00b7z\u00e4hlt", ",", "was", "ge\u00b7schehn", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "$,", "KOUS", "PPOSAT", "NN", "VVFIN", "$,", "PRELS", "VVPP", "$."], "meter": "+-+-+--+--+", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "\u00bbich hatte wie spielend die Berge genommen,", "tokens": ["\u00bb", "ich", "hat\u00b7te", "wie", "spie\u00b7lend", "die", "Ber\u00b7ge", "ge\u00b7nom\u00b7men", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "KOKOM", "ADJD", "ART", "NN", "VVPP", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.5": {"text": "Die rings unser Reich umstehn,", "tokens": ["Die", "rings", "un\u00b7ser", "Reich", "um\u00b7stehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Und trottete wie eine junge Ratte dahin.", "tokens": ["Und", "trot\u00b7te\u00b7te", "wie", "ei\u00b7ne", "jun\u00b7ge", "Rat\u00b7te", "da\u00b7hin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "KOKOM", "ART", "ADJA", "NN", "PAV", "$."], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.7": {"text": "Da sah ich zwei Tiere gehn:", "tokens": ["Da", "sah", "ich", "zwei", "Tie\u00b7re", "gehn", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "CARD", "NN", "VVINF", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "Das eine sanftm\u00fctig und z\u00e4rtlich und sch\u00f6n,", "tokens": ["Das", "ei\u00b7ne", "sanft\u00b7m\u00fc\u00b7tig", "und", "z\u00e4rt\u00b7lich", "und", "sch\u00f6n", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ART", "ADJD", "KON", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-++--+--+", "measure": "iambic.penta.relaxed"}, "line.9": {"text": "Das andere grob und von z\u00e4nkischem Sinn.", "tokens": ["Das", "an\u00b7de\u00b7re", "grob", "und", "von", "z\u00e4n\u00b7ki\u00b7schem", "Sinn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJD", "KON", "APPR", "ADJA", "NN", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.10": {"text": "Das machte ein rohes und schrilles Gekreisch", "tokens": ["Das", "mach\u00b7te", "ein", "ro\u00b7hes", "und", "schril\u00b7les", "Ge\u00b7kreisch"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "ART", "ADJA", "KON", "ADJA", "NN"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.11": {"text": "Und hatte am Kopf einen Fetzen Fleisch", "tokens": ["Und", "hat\u00b7te", "am", "Kopf", "ei\u00b7nen", "Fet\u00b7zen", "Fleisch"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "APPRART", "NN", "ART", "NN", "NN"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.12": {"text": "Und fuhr durch die Luft voll Verwegenheit,", "tokens": ["Und", "fuhr", "durch", "die", "Luft", "voll", "Ver\u00b7we\u00b7gen\u00b7heit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "ADJD", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.13": {"text": "Und sein Schwanz war buschig und breit.\u00ab", "tokens": ["Und", "sein", "Schwanz", "war", "bu\u00b7schig", "und", "breit", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "PPOSAT", "NN", "VAFIN", "ADJD", "KON", "ADJD", "$.", "$("], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.14": {"text": "Kurz, unser M\u00e4uschen machte da", "tokens": ["Kurz", ",", "un\u00b7ser", "M\u00e4u\u00b7schen", "mach\u00b7te", "da"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["ADJD", "$,", "PPOSAT", "NN", "VVFIN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Der Mutter von einem H\u00e4hnchen ein Bild,", "tokens": ["Der", "Mut\u00b7ter", "von", "ei\u00b7nem", "H\u00e4hn\u00b7chen", "ein", "Bild", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "ART", "NN", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.16": {"text": "Als sei das ein Tier aus Amerika.", "tokens": ["Als", "sei", "das", "ein", "Tier", "aus", "A\u00b7me\u00b7ri\u00b7ka", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VAFIN", "PDS", "ART", "NN", "APPR", "NE", "$."], "meter": "-+--+-+---", "measure": "iambic.tri.relaxed"}, "line.17": {"text": "\u00bbes schlug sich\u00ab, erz\u00e4hlte es, \u00bbfuchsteufelswild", "tokens": ["\u00bb", "es", "schlug", "sich", "\u00ab", ",", "er\u00b7z\u00e4hl\u00b7te", "es", ",", "\u00bb", "fuchs\u00b7teu\u00b7fels\u00b7wild"], "token_info": ["punct", "word", "word", "word", "punct", "punct", "word", "word", "punct", "punct", "word"], "pos": ["$(", "PPER", "VVFIN", "PRF", "$(", "$,", "VVFIN", "PPER", "$,", "$(", "NN"], "meter": "-+--+--++-+", "measure": "iambic.penta.relaxed"}, "line.18": {"text": "Die Schenkel mit seinen Armen", "tokens": ["Die", "Schen\u00b7kel", "mit", "sei\u00b7nen", "Ar\u00b7men"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.19": {"text": "Und machte Spektakel zum Gotterbarmen,", "tokens": ["Und", "mach\u00b7te", "Spek\u00b7ta\u00b7kel", "zum", "Got\u00b7ter\u00b7bar\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.20": {"text": "Da\u00df ich mit all meinem Mut im Schild", "tokens": ["Da\u00df", "ich", "mit", "all", "mei\u00b7nem", "Mut", "im", "Schild"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "PIAT", "PPOSAT", "NN", "APPRART", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.21": {"text": "Mein Heil im Rei\u00dfausnehmen suchte", "tokens": ["Mein", "Heil", "im", "Rei\u00df\u00b7aus\u00b7neh\u00b7men", "such\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "APPRART", "NN", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.22": {"text": "Und das Vieh im Herzen verfluchte.", "tokens": ["Und", "das", "Vieh", "im", "Her\u00b7zen", "ver\u00b7fluch\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "APPRART", "NN", "VVFIN", "$."], "meter": "--+-+--+-", "measure": "iambic.tri.relaxed"}, "line.23": {"text": "So ward ich mit jenem Tier, das so mild", "tokens": ["So", "ward", "ich", "mit", "je\u00b7nem", "Tier", ",", "das", "so", "mild"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "APPR", "PDAT", "NN", "$,", "PRELS", "ADV", "ADJD"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.24": {"text": "Mir erschien, leider gar nicht bekannt.", "tokens": ["Mir", "er\u00b7schien", ",", "lei\u00b7der", "gar", "nicht", "be\u00b7kannt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "ADV", "ADV", "PTKNEG", "ADJD", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.25": {"text": "Getigert und samten war sein Fell,", "tokens": ["Ge\u00b7ti\u00b7gert", "und", "sam\u00b7ten", "war", "sein", "Fell", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "KON", "VVFIN", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "----+-+-+", "measure": "unknown.measure.tri"}, "line.26": {"text": "Dem\u00fctig sein Auge und dennoch so hell.", "tokens": ["De\u00b7m\u00fc\u00b7tig", "sein", "Au\u00b7ge", "und", "den\u00b7noch", "so", "hell", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "PPOSAT", "NN", "KON", "ADV", "ADV", "ADJD", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.27": {"text": "Ich glaube, es ist mit uns M\u00e4usen verwandt,", "tokens": ["Ich", "glau\u00b7be", ",", "es", "ist", "mit", "uns", "M\u00e4u\u00b7sen", "ver\u00b7wandt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VAFIN", "APPR", "PPER", "NN", "VVPP", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.28": {"text": "Denn Ohren hat es ganz \u00e4hnlich wie wir.", "tokens": ["Denn", "Oh\u00b7ren", "hat", "es", "ganz", "\u00e4hn\u00b7lich", "wie", "wir", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VAFIN", "PPER", "ADV", "ADJD", "KOKOM", "PPER", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.29": {"text": "Ich wollte es gr\u00fc\u00dfen, da hat jener Fant", "tokens": ["Ich", "woll\u00b7te", "es", "gr\u00fc\u00b7\u00dfen", ",", "da", "hat", "je\u00b7ner", "Fant"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PPER", "VVINF", "$,", "ADV", "VAFIN", "PDAT", "NN"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.30": {"text": "Getobt, da\u00df ich schleunigst davongerannt.\u00ab", "tokens": ["Ge\u00b7tobt", ",", "da\u00df", "ich", "schleu\u00b7nigst", "da\u00b7von\u00b7ge\u00b7rannt", ".", "\u00ab"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVPP", "$,", "KOUS", "PPER", "ADV", "VVFIN", "$.", "$("], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.31": {"text": "Da sprach die Alte: \u00bbMein Kind, jenes Tier,", "tokens": ["Da", "sprach", "die", "Al\u00b7te", ":", "\u00bb", "Mein", "Kind", ",", "je\u00b7nes", "Tier", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$.", "$(", "PPOSAT", "NN", "$,", "PDAT", "NN", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.32": {"text": "Das dir so liebensw\u00fcrdig erschienen,", "tokens": ["Das", "dir", "so", "lie\u00b7bens\u00b7w\u00fcr\u00b7dig", "er\u00b7schie\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "ADV", "ADJD", "VVPP", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.33": {"text": "Hei\u00dft Katze, und trotz der scheinheiligen Mienen", "tokens": ["Hei\u00dft", "Kat\u00b7ze", ",", "und", "trotz", "der", "schein\u00b7hei\u00b7li\u00b7gen", "Mie\u00b7nen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "NN", "$,", "KON", "APPR", "ART", "ADJA", "NN"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.34": {"text": "Verfolgt es die Unsern mit M\u00f6rdergier.", "tokens": ["Ver\u00b7folgt", "es", "die", "Un\u00b7sern", "mit", "M\u00f6r\u00b7der\u00b7gier", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "APPR", "NN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.35": {"text": "Das andre indes ist ein harmloses Tier,", "tokens": ["Das", "and\u00b7re", "in\u00b7des", "ist", "ein", "harm\u00b7lo\u00b7ses", "Tier", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.36": {"text": "Wird uns vielleicht als Mahlzeit dienen", "tokens": ["Wird", "uns", "viel\u00b7leicht", "als", "Mahl\u00b7zeit", "die\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "ADV", "KOUS", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.37": {"text": "Demn\u00e4chst einmal; bei der Katze jedoch", "tokens": ["Dem\u00b7n\u00e4chst", "ein\u00b7mal", ";", "bei", "der", "Kat\u00b7ze", "je\u00b7doch"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "$.", "APPR", "ART", "NN", "ADV"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.38": {"text": "Sind ", "tokens": ["Sind"], "token_info": ["word"], "pos": ["VAFIN"], "meter": "-", "measure": "single.down"}, "line.39": {"text": "Bei vielen Leuten stimmt es nicht,", "tokens": ["Bei", "vie\u00b7len", "Leu\u00b7ten", "stimmt", "es", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVFIN", "PPER", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.40": {"text": "Wenn man sie sch\u00e4tzt nach ihrem Gesicht!\u00ab", "tokens": ["Wenn", "man", "sie", "sch\u00e4tzt", "nach", "ih\u00b7rem", "Ge\u00b7sicht", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PIS", "PPER", "VVFIN", "APPR", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}}}}}