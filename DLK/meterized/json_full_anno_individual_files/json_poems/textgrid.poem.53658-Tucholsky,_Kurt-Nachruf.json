{"textgrid.poem.53658": {"metadata": {"author": {"name": "Tucholsky, Kurt", "birth": "N.A.", "death": "N.A."}, "title": "Nachruf", "genre": "verse", "period": "N.A.", "pub_year": 1912, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Geha\u00dft, weil du Konkursverwalter", "tokens": ["Ge\u00b7ha\u00dft", ",", "weil", "du", "Kon\u00b7kurs\u00b7ver\u00b7wal\u00b7ter"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["VVPP", "$,", "KOUS", "PPER", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "der Pleitefirma Deutsches Reich,", "tokens": ["der", "Plei\u00b7te\u00b7fir\u00b7ma", "Deut\u00b7sches", "Reich", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "liegst du zerschossen als ein kalter", "tokens": ["liegst", "du", "zer\u00b7schos\u00b7sen", "als", "ein", "kal\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "VVINF", "KOKOM", "ART", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "und toter Mann \u2013 und Deutschland ist das gleich.", "tokens": ["und", "to\u00b7ter", "Mann", "\u2013", "und", "Deutschland", "ist", "das", "gleich", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "$(", "KON", "NE", "VAFIN", "PDS", "ADV", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.2": {"line.1": {"text": "Es kostet nichts. In Blutkapiteln", "tokens": ["Es", "kos\u00b7tet", "nichts", ".", "In", "Blut\u00b7ka\u00b7pi\u00b7teln"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VVFIN", "PIS", "$.", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "erlebten wirs \u2013 was kriegt solch Vieh?", "tokens": ["er\u00b7leb\u00b7ten", "wirs", "\u2013", "was", "kriegt", "solch", "Vieh", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "$(", "PWS", "VVFIN", "PIAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Den Auslandspa\u00df \u2013 \u203aNichts zu ermitteln\u2039:", "tokens": ["Den", "Aus\u00b7land\u00b7spa\u00df", "\u2013", "\u203a", "Nichts", "zu", "er\u00b7mit\u00b7teln", "\u2039", ":"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "$(", "$(", "PIS", "PTKZU", "VVINF", "$(", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "so k\u00e4mpft der Geist der Monarchie.", "tokens": ["so", "k\u00e4mpft", "der", "Geist", "der", "Mon\u00b7ar\u00b7chie", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Geha\u00dft, weil du Zivilcourage", "tokens": ["Ge\u00b7ha\u00dft", ",", "weil", "du", "Zi\u00b7vil\u00b7cou\u00b7ra\u00b7ge"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["VVPP", "$,", "KOUS", "PPER", "NN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "den Herren vom Monokel zeigst \u2013", "tokens": ["den", "Her\u00b7ren", "vom", "Mo\u00b7no\u00b7kel", "zeigst", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "weil du schon Siebzehn die Blamage", "tokens": ["weil", "du", "schon", "Sieb\u00b7zehn", "die", "Bla\u00b7ma\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "NN", "ART", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "der Ludend\u00f6rffer nicht verschweigst . . .", "tokens": ["der", "Lu\u00b7den\u00b7d\u00f6rf\u00b7fer", "nicht", "ver\u00b7schweigst", ".", ".", "."], "token_info": ["word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["ART", "NN", "PTKNEG", "VVFIN", "$.", "$.", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Das kann der Deutsche nicht vertragen:", "tokens": ["Das", "kann", "der", "Deut\u00b7sche", "nicht", "ver\u00b7tra\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "ART", "NN", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "da\u00df einer ihm die Wahrheit sagt,", "tokens": ["da\u00df", "ei\u00b7ner", "ihm", "die", "Wahr\u00b7heit", "sagt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "da\u00df einer ohne Leutnantskragen", "tokens": ["da\u00df", "ei\u00b7ner", "oh\u00b7ne", "Leut\u00b7nants\u00b7kra\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PIS", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "den Landsknechtgeist von dannen jagt.", "tokens": ["den", "Lands\u00b7knecht\u00b7geist", "von", "dan\u00b7nen", "jagt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "So fielst du.", "tokens": ["So", "fielst", "du", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.2": {"text": "Hinter deiner Bahre", "tokens": ["Hin\u00b7ter", "dei\u00b7ner", "Bah\u00b7re"], "token_info": ["word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "gehn grinsend, die den Mord gewollt:", "tokens": ["gehn", "grin\u00b7send", ",", "die", "den", "Mord", "ge\u00b7wollt", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "$,", "PRELS", "ART", "NN", "VMPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "in Uniform und im Talare", "tokens": ["in", "U\u00b7ni\u00b7form", "und", "im", "Ta\u00b7la\u00b7re"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "APPRART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "der wildgewordne Teutobold.", "tokens": ["der", "wild\u00b7ge\u00b7word\u00b7ne", "Teu\u00b7to\u00b7bold", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Und wie dein Blut die Steine netzte,", "tokens": ["Und", "wie", "dein", "Blut", "die", "Stei\u00b7ne", "netz\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPOSAT", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "da atmet auf das Milit\u00e4r.", "tokens": ["da", "at\u00b7met", "auf", "das", "Mi\u00b7li\u00b7t\u00e4r", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Es kondoliert, wer grad noch hetzte . . .", "tokens": ["Es", "kon\u00b7do\u00b7liert", ",", "wer", "grad", "noch", "hetz\u00b7te", ".", ".", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PPER", "VVFIN", "$,", "PWS", "ADV", "ADV", "VVFIN", "$.", "$.", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Du warst der Erste nicht \u2013 bist nicht der Letzte.", "tokens": ["Du", "warst", "der", "Ers\u00b7te", "nicht", "\u2013", "bist", "nicht", "der", "Letz\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "PTKNEG", "$(", "VAFIN", "PTKNEG", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Prost Helfferich!", "tokens": ["Prost", "Helf\u00b7fe\u00b7rich", "!"], "token_info": ["word", "word", "punct"], "pos": ["NN", "NE", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.6": {"text": "Der kommt nicht mehr.", "tokens": ["Der", "kommt", "nicht", "mehr", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PTKNEG", "ADV", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.7": {"line.1": {"text": "Geha\u00dft, weil du Konkursverwalter", "tokens": ["Ge\u00b7ha\u00dft", ",", "weil", "du", "Kon\u00b7kurs\u00b7ver\u00b7wal\u00b7ter"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["VVPP", "$,", "KOUS", "PPER", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "der Pleitefirma Deutsches Reich,", "tokens": ["der", "Plei\u00b7te\u00b7fir\u00b7ma", "Deut\u00b7sches", "Reich", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "liegst du zerschossen als ein kalter", "tokens": ["liegst", "du", "zer\u00b7schos\u00b7sen", "als", "ein", "kal\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "VVINF", "KOKOM", "ART", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "und toter Mann \u2013 und Deutschland ist das gleich.", "tokens": ["und", "to\u00b7ter", "Mann", "\u2013", "und", "Deutschland", "ist", "das", "gleich", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "$(", "KON", "NE", "VAFIN", "PDS", "ADV", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.8": {"line.1": {"text": "Es kostet nichts. In Blutkapiteln", "tokens": ["Es", "kos\u00b7tet", "nichts", ".", "In", "Blut\u00b7ka\u00b7pi\u00b7teln"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VVFIN", "PIS", "$.", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "erlebten wirs \u2013 was kriegt solch Vieh?", "tokens": ["er\u00b7leb\u00b7ten", "wirs", "\u2013", "was", "kriegt", "solch", "Vieh", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "$(", "PWS", "VVFIN", "PIAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Den Auslandspa\u00df \u2013 \u203aNichts zu ermitteln\u2039:", "tokens": ["Den", "Aus\u00b7land\u00b7spa\u00df", "\u2013", "\u203a", "Nichts", "zu", "er\u00b7mit\u00b7teln", "\u2039", ":"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "$(", "$(", "PIS", "PTKZU", "VVINF", "$(", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "so k\u00e4mpft der Geist der Monarchie.", "tokens": ["so", "k\u00e4mpft", "der", "Geist", "der", "Mon\u00b7ar\u00b7chie", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Geha\u00dft, weil du Zivilcourage", "tokens": ["Ge\u00b7ha\u00dft", ",", "weil", "du", "Zi\u00b7vil\u00b7cou\u00b7ra\u00b7ge"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["VVPP", "$,", "KOUS", "PPER", "NN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "den Herren vom Monokel zeigst \u2013", "tokens": ["den", "Her\u00b7ren", "vom", "Mo\u00b7no\u00b7kel", "zeigst", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "weil du schon Siebzehn die Blamage", "tokens": ["weil", "du", "schon", "Sieb\u00b7zehn", "die", "Bla\u00b7ma\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "NN", "ART", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "der Ludend\u00f6rffer nicht verschweigst . . .", "tokens": ["der", "Lu\u00b7den\u00b7d\u00f6rf\u00b7fer", "nicht", "ver\u00b7schweigst", ".", ".", "."], "token_info": ["word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["ART", "NN", "PTKNEG", "VVFIN", "$.", "$.", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Das kann der Deutsche nicht vertragen:", "tokens": ["Das", "kann", "der", "Deut\u00b7sche", "nicht", "ver\u00b7tra\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "ART", "NN", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "da\u00df einer ihm die Wahrheit sagt,", "tokens": ["da\u00df", "ei\u00b7ner", "ihm", "die", "Wahr\u00b7heit", "sagt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "da\u00df einer ohne Leutnantskragen", "tokens": ["da\u00df", "ei\u00b7ner", "oh\u00b7ne", "Leut\u00b7nants\u00b7kra\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PIS", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "den Landsknechtgeist von dannen jagt.", "tokens": ["den", "Lands\u00b7knecht\u00b7geist", "von", "dan\u00b7nen", "jagt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "So fielst du.", "tokens": ["So", "fielst", "du", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.2": {"text": "Hinter deiner Bahre", "tokens": ["Hin\u00b7ter", "dei\u00b7ner", "Bah\u00b7re"], "token_info": ["word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "gehn grinsend, die den Mord gewollt:", "tokens": ["gehn", "grin\u00b7send", ",", "die", "den", "Mord", "ge\u00b7wollt", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "$,", "PRELS", "ART", "NN", "VMPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "in Uniform und im Talare", "tokens": ["in", "U\u00b7ni\u00b7form", "und", "im", "Ta\u00b7la\u00b7re"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "APPRART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "der wildgewordne Teutobold.", "tokens": ["der", "wild\u00b7ge\u00b7word\u00b7ne", "Teu\u00b7to\u00b7bold", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Und wie dein Blut die Steine netzte,", "tokens": ["Und", "wie", "dein", "Blut", "die", "Stei\u00b7ne", "netz\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPOSAT", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "da atmet auf das Milit\u00e4r.", "tokens": ["da", "at\u00b7met", "auf", "das", "Mi\u00b7li\u00b7t\u00e4r", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Es kondoliert, wer grad noch hetzte . . .", "tokens": ["Es", "kon\u00b7do\u00b7liert", ",", "wer", "grad", "noch", "hetz\u00b7te", ".", ".", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PPER", "VVFIN", "$,", "PWS", "ADV", "ADV", "VVFIN", "$.", "$.", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Du warst der Erste nicht \u2013 bist nicht der Letzte.", "tokens": ["Du", "warst", "der", "Ers\u00b7te", "nicht", "\u2013", "bist", "nicht", "der", "Letz\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "PTKNEG", "$(", "VAFIN", "PTKNEG", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Prost Helfferich!", "tokens": ["Prost", "Helf\u00b7fe\u00b7rich", "!"], "token_info": ["word", "word", "punct"], "pos": ["NN", "NE", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.6": {"text": "Der kommt nicht mehr.", "tokens": ["Der", "kommt", "nicht", "mehr", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PTKNEG", "ADV", "$."], "meter": "-+-+", "measure": "iambic.di"}}}}}