{"textgrid.poem.31170": {"metadata": {"author": {"name": "Holz, Arno", "birth": "N.A.", "death": "N.A."}, "title": "Paysage intime", "genre": "verse", "period": "N.A.", "pub_year": 1896, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Sternklar \u00fcber seinem Filz", "tokens": ["Stern\u00b7klar", "\u00fc\u00b7ber", "sei\u00b7nem", "Filz"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "W\u00f6lbte sich der Winterhimmel", "tokens": ["W\u00f6lb\u00b7te", "sich", "der", "Win\u00b7ter\u00b7him\u00b7mel"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PRF", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und, die D\u00e4cher dick verschneit,", "tokens": ["Und", ",", "die", "D\u00e4\u00b7cher", "dick", "ver\u00b7schneit", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "ART", "NN", "ADJD", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Lag das schlummernde Berlin.", "tokens": ["Lag", "das", "schlum\u00b7mern\u00b7de", "Ber\u00b7lin", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NE", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}}, "stanza.2": {"line.1": {"text": "Leider war die Gaslaterne,", "tokens": ["Lei\u00b7der", "war", "die", "Gas\u00b7la\u00b7ter\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Die ihr gelblich ins Gesicht schien,", "tokens": ["Die", "ihr", "gelb\u00b7lich", "ins", "Ge\u00b7sicht", "schien", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADJD", "APPRART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Nicht mehr hell genug dazu.", "tokens": ["Nicht", "mehr", "hell", "ge\u00b7nug", "da\u00b7zu", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "ADJD", "ADV", "PAV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Erst als kichernd sie im Hausflur", "tokens": ["Erst", "als", "ki\u00b7chernd", "sie", "im", "Haus\u00b7flur"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "KOUS", "ADJD", "PPER", "APPRART", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Sich mit seinen Schwefelh\u00f6lzchen", "tokens": ["Sich", "mit", "sei\u00b7nen", "Schwe\u00b7fel\u00b7h\u00f6lz\u00b7chen"], "token_info": ["word", "word", "word", "word"], "pos": ["PRF", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Ihren Wachsstock angez\u00fcndet,", "tokens": ["Ih\u00b7ren", "Wachs\u00b7stock", "an\u00b7ge\u00b7z\u00fcn\u00b7det", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Sah er, dass sein Schmetterling", "tokens": ["Sah", "er", ",", "dass", "sein", "Schmet\u00b7ter\u00b7ling"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "PPER", "$,", "KOUS", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Schon zu unversch\u00e4mt l\u00e4dirt war.", "tokens": ["Schon", "zu", "un\u00b7ver\u00b7sch\u00e4mt", "l\u00e4\u00b7dirt", "war", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKA", "ADJD", "VVPP", "VAFIN", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.4": {"line.1": {"text": "Sich nach r\u00fcckw\u00e4rts concentriren?", "tokens": ["Sich", "nach", "r\u00fcck\u00b7w\u00e4rts", "con\u00b7cent\u00b7ri\u00b7ren", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "ADV", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Nein, die Hausth\u00fcr war schon zu!", "tokens": ["Nein", ",", "die", "Hau\u00b7sth\u00fcr", "war", "schon", "zu", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "ART", "NN", "VAFIN", "ADV", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Pech! Pfui Deibel! Und verdriesslich,", "tokens": ["Pech", "!", "Pfui", "Dei\u00b7bel", "!", "Und", "ver\u00b7driess\u00b7lich", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "$.", "NE", "NE", "$.", "KON", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Kritisch jede Stufe pr\u00fcfend,", "tokens": ["Kri\u00b7tisch", "je\u00b7de", "Stu\u00b7fe", "pr\u00fc\u00b7fend", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PIAT", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Tappte er ihr langsam nach.", "tokens": ["Tapp\u00b7te", "er", "ihr", "lang\u00b7sam", "nach", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "ADJD", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Fern vom Hinterhaus her johlte", "tokens": ["Fern", "vom", "Hin\u00b7ter\u00b7haus", "her", "johl\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "APPRART", "NN", "APZR", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ein versp\u00e4teter Geburtstag,", "tokens": ["Ein", "ver\u00b7sp\u00e4\u00b7te\u00b7ter", "Ge\u00b7burts\u00b7tag", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und das Flakerlicht des Kerzchens,", "tokens": ["Und", "das", "Fla\u00b7ker\u00b7licht", "des", "Kerz\u00b7chens", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Das sich vor ihm aus dem Dunkeln,", "tokens": ["Das", "sich", "vor", "ihm", "aus", "dem", "Dun\u00b7keln", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PRF", "APPR", "PPER", "APPR", "ART", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Wie ein Irrlicht abhob, streifte", "tokens": ["Wie", "ein", "Irr\u00b7licht", "ab\u00b7hob", ",", "streif\u00b7te"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["PWAV", "ART", "NN", "VVFIN", "$,", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Ab und zu ein Porzellanschild", "tokens": ["Ab", "und", "zu", "ein", "Por\u00b7zel\u00b7lan\u00b7schild"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "KON", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Baltrutsch, las er auf dem einen,", "tokens": ["Balt\u00b7rutsch", ",", "las", "er", "auf", "dem", "ei\u00b7nen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "PPER", "APPR", "ART", "ART", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Baltrutsch, Knopf-Arbeiter. \u2013 Endlich!", "tokens": ["Balt\u00b7rutsch", ",", "Knopf\u00b7A\u00b7rbei\u00b7ter", ".", "\u2013", "End\u00b7lich", "!"], "token_info": ["word", "punct", "word", "punct", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$.", "$(", "ADV", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Gut, dass wenigstens ihr Zimmer,", "tokens": ["Gut", ",", "dass", "we\u00b7nigs\u00b7tens", "ihr", "Zim\u00b7mer", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "KOUS", "ADV", "PPOSAT", "NN", "$,"], "meter": "+-+---+-", "measure": "unknown.measure.tri"}, "line.2": {"text": "Dessen Th\u00fcr erst frisch ge\u00f6lt schien,", "tokens": ["Des\u00b7sen", "Th\u00fcr", "erst", "frisch", "ge\u00b7\u00f6lt", "schien", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "ADV", "ADJD", "VVPP", "VVFIN", "$,"], "meter": "+-+-+---", "measure": "unknown.measure.tri"}, "line.3": {"text": "Eingermassen wohnlich war.", "tokens": ["Ein\u00b7ger\u00b7mas\u00b7sen", "wohn\u00b7lich", "war", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Feuerroth im Ofen gl\u00fchte", "tokens": ["Feu\u00b7er\u00b7roth", "im", "O\u00b7fen", "gl\u00fch\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "APPRART", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Grad das letzte Sch\u00e4uflein Kohlen,", "tokens": ["Grad", "das", "letz\u00b7te", "Sch\u00e4uf\u00b7lein", "Koh\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und ein sauberes Rouleau", "tokens": ["Und", "ein", "sau\u00b7be\u00b7res", "Rou\u00b7le\u00b7au"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.4": {"text": "Schob sich schneeweiss vor das Fenster.", "tokens": ["Schob", "sich", "schnee\u00b7weiss", "vor", "das", "Fens\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "An die gr\u00fcngestreifte Wand", "tokens": ["An", "die", "gr\u00fcn\u00b7ge\u00b7streif\u00b7te", "Wand"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "War ein Christusbild genagelt.", "tokens": ["War", "ein", "Chris\u00b7tus\u00b7bild", "ge\u00b7na\u00b7gelt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "In das aufgedeckte Bett,", "tokens": ["In", "das", "auf\u00b7ge\u00b7deck\u00b7te", "Bett", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Das davorstand, d\u00e4mmerte", "tokens": ["Das", "da\u00b7vor\u00b7stand", ",", "d\u00e4m\u00b7mer\u00b7te"], "token_info": ["word", "word", "punct", "word"], "pos": ["PDS", "VVFIN", "$,", "VVFIN"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.3": {"text": "Mattblau eine kleine Ampel,", "tokens": ["Matt\u00b7blau", "ei\u00b7ne", "klei\u00b7ne", "Am\u00b7pel", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und das obligate Sopha", "tokens": ["Und", "das", "ob\u00b7li\u00b7ga\u00b7te", "So\u00b7pha"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.5": {"text": "Stand ihm grade gegen\u00fcber.", "tokens": ["Stand", "ihm", "gra\u00b7de", "ge\u00b7gen\u00b7\u00fc\u00b7ber", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "PTKVZ", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Auch die Marmortoilette", "tokens": ["Auch", "die", "Mar\u00b7mor\u00b7to\u00b7i\u00b7let\u00b7te"], "token_info": ["word", "word", "word"], "pos": ["ADV", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Fehlte selbstverst\u00e4ndlich nicht.", "tokens": ["Fehl\u00b7te", "selbst\u00b7ver\u00b7st\u00e4nd\u00b7lich", "nicht", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "PTKNEG", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Zwei bis drei zerbrochne St\u00fchle", "tokens": ["Zwei", "bis", "drei", "zer\u00b7broch\u00b7ne", "St\u00fch\u00b7le"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["CARD", "APPR", "CARD", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Bl\u00e4tterten daneben cynisch", "tokens": ["Bl\u00e4t\u00b7ter\u00b7ten", "da\u00b7ne\u00b7ben", "cy\u00b7nisch"], "token_info": ["word", "word", "word"], "pos": ["NN", "PAV", "ADJD"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Ihre Memoiren auf.", "tokens": ["Ih\u00b7re", "Me\u00b7moi\u00b7ren", "auf", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PTKVZ", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}}, "stanza.13": {"line.1": {"text": "Freilich, wie diverse Lieder,", "tokens": ["Frei\u00b7lich", ",", "wie", "di\u00b7ver\u00b7se", "Lie\u00b7der", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PWAV", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Memoiren ohne Worte.", "tokens": ["Me\u00b7moi\u00b7ren", "oh\u00b7ne", "Wor\u00b7te", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.14": {"line.1": {"text": "\u00bbnun? Was schenkst du mir denn Schatz?\u00ab", "tokens": ["\u00bb", "nun", "?", "Was", "schenkst", "du", "mir", "denn", "Schatz", "?", "\u00ab"], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADV", "$.", "PWS", "VVFIN", "PPER", "PPER", "ADV", "NN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Und die vollen nackten Arme", "tokens": ["Und", "die", "vol\u00b7len", "nack\u00b7ten", "Ar\u00b7me"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Frech um seinen Hals geringelt,", "tokens": ["Frech", "um", "sei\u00b7nen", "Hals", "ge\u00b7rin\u00b7gelt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Presste ihn die weisse Bestie", "tokens": ["Press\u00b7te", "ihn", "die", "weis\u00b7se", "Be\u00b7stie"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "PPER", "ART", "ADJA", "NN"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.5": {"text": "Fest an ihre blossen Br\u00fcste.", "tokens": ["Fest", "an", "ih\u00b7re", "blos\u00b7sen", "Br\u00fcs\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.15": {"line.1": {"text": "Doch, da k\u00fcrzlich erst der Erste", "tokens": ["Doch", ",", "da", "k\u00fcrz\u00b7lich", "erst", "der", "Ers\u00b7te"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "$,", "KOUS", "ADV", "ADV", "ART", "ADJA"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.2": {"text": "Ihm das Portemonnaie gef\u00fcllt,", "tokens": ["Ihm", "das", "Por\u00b7te\u00b7mon\u00b7nai\u00b7e", "ge\u00b7f\u00fcllt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Wurden sie bald handelseins.", "tokens": ["Wur\u00b7den", "sie", "bald", "han\u00b7del\u00b7seins", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.16": {"line.1": {"text": "W\u00e4hrend er sich noch bem\u00fchte,", "tokens": ["W\u00e4h\u00b7rend", "er", "sich", "noch", "be\u00b7m\u00fch\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sich die Stiefel auszuziehn,", "tokens": ["Sich", "die", "Stie\u00b7fel", "aus\u00b7zu\u00b7ziehn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PRF", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Lachte auch sein Kaufobjekt,", "tokens": ["Lach\u00b7te", "auch", "sein", "Kauf\u00b7ob\u00b7jekt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Nackt wie Eva, schon vom Bett her.", "tokens": ["Nackt", "wie", "E\u00b7va", ",", "schon", "vom", "Bett", "her", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KOKOM", "NN", "$,", "ADV", "APPRART", "NN", "PTKVZ", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.17": {"line.1": {"text": "F\u00fcnf Minuten sp\u00e4ter noch,", "tokens": ["F\u00fcnf", "Mi\u00b7nu\u00b7ten", "sp\u00e4\u00b7ter", "noch", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "ADJD", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Und das indiscrete L\u00e4mpchen", "tokens": ["Und", "das", "in\u00b7di\u00b7scre\u00b7te", "L\u00e4mp\u00b7chen"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Flackert, leuchtet und verlischt.", "tokens": ["Fla\u00b7ckert", ",", "leuch\u00b7tet", "und", "ver\u00b7lischt", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "VVFIN", "KON", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.18": {"line.1": {"text": "Dunkelheit! Vom Ofenrost her,", "tokens": ["Dun\u00b7kel\u00b7heit", "!", "Vom", "O\u00b7fen\u00b7rost", "her", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$.", "APPRART", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Leis hinzitternd \u00fcber die Dielen,", "tokens": ["Leis", "hin\u00b7zit\u00b7ternd", "\u00fc\u00b7ber", "die", "Die\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVPP", "APPR", "ART", "NN", "$,"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "Nur ein magrer, rother Lichtstreif,", "tokens": ["Nur", "ein", "mag\u00b7rer", ",", "ro\u00b7ther", "Licht\u00b7streif", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und ins faltige Rouleau", "tokens": ["Und", "ins", "fal\u00b7ti\u00b7ge", "Rou\u00b7le\u00b7au"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPRART", "ADJA", "NN"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.5": {"text": "Malt sich fernher von der Strasse", "tokens": ["Malt", "sich", "fern\u00b7her", "von", "der", "Stras\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "PRF", "ADV", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Fahl das Licht der Gaslaternen.", "tokens": ["Fahl", "das", "Licht", "der", "Gas\u00b7la\u00b7ter\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.19": {"line.1": {"text": "Dunkelheit! Nur ab und zu", "tokens": ["Dun\u00b7kel\u00b7heit", "!", "Nur", "ab", "und", "zu"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$.", "ADV", "PTKVZ", "KON", "APPR"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Bricht ein heftig schweres Athmen", "tokens": ["Bricht", "ein", "hef\u00b7tig", "schwe\u00b7res", "Ath\u00b7men"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "ADJD", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Hastig durch die tiefe Stille,", "tokens": ["Has\u00b7tig", "durch", "die", "tie\u00b7fe", "Stil\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und dazwischen rauscht's und knittert's", "tokens": ["Und", "da\u00b7zwi\u00b7schen", "rauscht's", "und", "knit\u00b7tert's"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PAV", "VVFIN", "KON", "NE"], "meter": "----+-+-", "measure": "unknown.measure.di"}, "line.5": {"text": "Durch die Luft wie frisches Bettzeug.", "tokens": ["Durch", "die", "Luft", "wie", "fri\u00b7sches", "Bett\u00b7zeug", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "KOKOM", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.20": {"line.1": {"text": "Dunkelheit! Im Hause gingen", "tokens": ["Dun\u00b7kel\u00b7heit", "!", "Im", "Hau\u00b7se", "gin\u00b7gen"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NN", "$.", "APPRART", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Schon zum f\u00fcnften Mal die Uhren,", "tokens": ["Schon", "zum", "f\u00fcnf\u00b7ten", "Mal", "die", "Uh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "ADJA", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und das Zimmer fing sich an", "tokens": ["Und", "das", "Zim\u00b7mer", "fing", "sich", "an"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "VVFIN", "PRF", "APPR"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Leise grau in grau zu malen.", "tokens": ["Lei\u00b7se", "grau", "in", "grau", "zu", "ma\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "APPR", "ADJD", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.21": {"line.1": {"text": "\u00bbbleib doch noch!\u00ab \u00bbNein, lass, ich muss gehn!\u00ab", "tokens": ["\u00bb", "bleib", "doch", "noch", "!", "\u00ab", "\u00bb", "Nein", ",", "lass", ",", "ich", "muss", "gehn", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "punct", "punct", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VVFIN", "ADV", "ADV", "$.", "$(", "$(", "PTKANT", "$,", "VVFIN", "$,", "PPER", "VMFIN", "VVINF", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und aus ihrem Arm sich windend,", "tokens": ["Und", "aus", "ih\u00b7rem", "Arm", "sich", "win\u00b7dend", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPOSAT", "NN", "PRF", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Tappte er nach seinen Kleidern", "tokens": ["Tapp\u00b7te", "er", "nach", "sei\u00b7nen", "Klei\u00b7dern"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und begann sich anzuziehn.", "tokens": ["Und", "be\u00b7gann", "sich", "an\u00b7zu\u00b7ziehn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "VVIZU", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.22": {"line.1": {"text": "Ihren bleichen, runden Kopf", "tokens": ["Ih\u00b7ren", "blei\u00b7chen", ",", "run\u00b7den", "Kopf"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["PPOSAT", "ADJA", "$,", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Matt auf ihren Arm gest\u00fctzt,", "tokens": ["Matt", "auf", "ih\u00b7ren", "Arm", "ge\u00b7st\u00fctzt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Sah sie ihm mechanisch zu.", "tokens": ["Sah", "sie", "ihm", "me\u00b7cha\u00b7nisch", "zu", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "ADJD", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.23": {"line.1": {"text": "\u00bbkommst du wieder?\u00ab Gottseidank!", "tokens": ["\u00bb", "kommst", "du", "wie\u00b7der", "?", "\u00ab", "Gott\u00b7sei\u00b7dank", "!"], "token_info": ["punct", "word", "word", "word", "punct", "punct", "word", "punct"], "pos": ["$(", "VVFIN", "PPER", "ADV", "$.", "$(", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Jetzt nur noch den Rock und \u2013", "tokens": ["Jetzt", "nur", "noch", "den", "Rock", "und", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "ART", "NN", "KON", "$("], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "\u00bbkommst du wieder?\u00ab \u2013 jetzt: \u00bbAdieu!\u00ab", "tokens": ["\u00bb", "kommst", "du", "wie\u00b7der", "?", "\u00ab", "\u2013", "jetzt", ":", "\u00bb", "A\u00b7die\u00b7u", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "punct", "punct", "punct", "word", "punct", "punct", "word", "punct", "punct"], "pos": ["$(", "VVFIN", "PPER", "ADV", "$.", "$(", "$(", "ADV", "$.", "$(", "ADV", "$.", "$("], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.24": {"line.1": {"text": "Unten, auf dem Hausflur, kam ihm", "tokens": ["Un\u00b7ten", ",", "auf", "dem", "Haus\u00b7flur", ",", "kam", "ihm"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "$,", "APPR", "ART", "NN", "$,", "VVFIN", "PPER"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Eine Zeitungsfrau entgegen.", "tokens": ["Ei\u00b7ne", "Zei\u00b7tungs\u00b7frau", "ent\u00b7ge\u00b7gen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.25": {"line.1": {"text": "Donnerwetter! Schon so sp\u00e4t?", "tokens": ["Don\u00b7ner\u00b7wet\u00b7ter", "!", "Schon", "so", "sp\u00e4t", "?"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$.", "ADV", "ADV", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Und den Kragen seines Mantels", "tokens": ["Und", "den", "Kra\u00b7gen", "sei\u00b7nes", "Man\u00b7tels"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Hoch bis unters Kinn gekn\u00f6pft,", "tokens": ["Hoch", "bis", "un\u00b7ters", "Kinn", "ge\u00b7kn\u00f6pft", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "APPRART", "NN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Trat er fr\u00f6stelnd vor die Th\u00fcr.", "tokens": ["Trat", "er", "fr\u00f6s\u00b7telnd", "vor", "die", "Th\u00fcr."], "token_info": ["word", "word", "word", "word", "word", "abbreviation"], "pos": ["VVFIN", "PPER", "ADJD", "APPR", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.26": {"line.1": {"text": "Schmutzig lag vor ihm die Strasse,", "tokens": ["Schmut\u00b7zig", "lag", "vor", "ihm", "die", "Stras\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPR", "PPER", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Schmutzig wie ein altes Schnupftuch,", "tokens": ["Schmut\u00b7zig", "wie", "ein", "al\u00b7tes", "Schnupf\u00b7tuch", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "KOKOM", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und vom grauverhangnen Himmel", "tokens": ["Und", "vom", "grau\u00b7ver\u00b7hang\u00b7nen", "Him\u00b7mel"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPRART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Rieselte ein feiner Nebel.", "tokens": ["Rie\u00b7sel\u00b7te", "ein", "fei\u00b7ner", "Ne\u00b7bel", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "$."], "meter": "+---+-+-", "measure": "dactylic.init"}}, "stanza.27": {"line.1": {"text": "\u00bbbrrr!\u00ab Und vor sich selbst aus Ekel", "tokens": ["\u00bb", "brrr", "!", "\u00ab", "Und", "vor", "sich", "selbst", "aus", "E\u00b7kel"], "token_info": ["punct", "word", "punct", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "PTKVZ", "$.", "$(", "KON", "APPR", "PRF", "ADV", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Spie er mitten in die Gosse.", "tokens": ["Spie", "er", "mit\u00b7ten", "in", "die", "Gos\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.28": {"line.1": {"text": "Sternklar \u00fcber seinem Filz", "tokens": ["Stern\u00b7klar", "\u00fc\u00b7ber", "sei\u00b7nem", "Filz"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "W\u00f6lbte sich der Winterhimmel", "tokens": ["W\u00f6lb\u00b7te", "sich", "der", "Win\u00b7ter\u00b7him\u00b7mel"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PRF", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und, die D\u00e4cher dick verschneit,", "tokens": ["Und", ",", "die", "D\u00e4\u00b7cher", "dick", "ver\u00b7schneit", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "ART", "NN", "ADJD", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Lag das schlummernde Berlin.", "tokens": ["Lag", "das", "schlum\u00b7mern\u00b7de", "Ber\u00b7lin", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NE", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}}, "stanza.29": {"line.1": {"text": "Leider war die Gaslaterne,", "tokens": ["Lei\u00b7der", "war", "die", "Gas\u00b7la\u00b7ter\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Die ihr gelblich ins Gesicht schien,", "tokens": ["Die", "ihr", "gelb\u00b7lich", "ins", "Ge\u00b7sicht", "schien", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADJD", "APPRART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Nicht mehr hell genug dazu.", "tokens": ["Nicht", "mehr", "hell", "ge\u00b7nug", "da\u00b7zu", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "ADJD", "ADV", "PAV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.30": {"line.1": {"text": "Erst als kichernd sie im Hausflur", "tokens": ["Erst", "als", "ki\u00b7chernd", "sie", "im", "Haus\u00b7flur"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "KOUS", "ADJD", "PPER", "APPRART", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Sich mit seinen Schwefelh\u00f6lzchen", "tokens": ["Sich", "mit", "sei\u00b7nen", "Schwe\u00b7fel\u00b7h\u00f6lz\u00b7chen"], "token_info": ["word", "word", "word", "word"], "pos": ["PRF", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Ihren Wachsstock angez\u00fcndet,", "tokens": ["Ih\u00b7ren", "Wachs\u00b7stock", "an\u00b7ge\u00b7z\u00fcn\u00b7det", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Sah er, dass sein Schmetterling", "tokens": ["Sah", "er", ",", "dass", "sein", "Schmet\u00b7ter\u00b7ling"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "PPER", "$,", "KOUS", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Schon zu unversch\u00e4mt l\u00e4dirt war.", "tokens": ["Schon", "zu", "un\u00b7ver\u00b7sch\u00e4mt", "l\u00e4\u00b7dirt", "war", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKA", "ADJD", "VVPP", "VAFIN", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.31": {"line.1": {"text": "Sich nach r\u00fcckw\u00e4rts concentriren?", "tokens": ["Sich", "nach", "r\u00fcck\u00b7w\u00e4rts", "con\u00b7cent\u00b7ri\u00b7ren", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "ADV", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Nein, die Hausth\u00fcr war schon zu!", "tokens": ["Nein", ",", "die", "Hau\u00b7sth\u00fcr", "war", "schon", "zu", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "ART", "NN", "VAFIN", "ADV", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Pech! Pfui Deibel! Und verdriesslich,", "tokens": ["Pech", "!", "Pfui", "Dei\u00b7bel", "!", "Und", "ver\u00b7driess\u00b7lich", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "$.", "NE", "NE", "$.", "KON", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Kritisch jede Stufe pr\u00fcfend,", "tokens": ["Kri\u00b7tisch", "je\u00b7de", "Stu\u00b7fe", "pr\u00fc\u00b7fend", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PIAT", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Tappte er ihr langsam nach.", "tokens": ["Tapp\u00b7te", "er", "ihr", "lang\u00b7sam", "nach", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "ADJD", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.32": {"line.1": {"text": "Fern vom Hinterhaus her johlte", "tokens": ["Fern", "vom", "Hin\u00b7ter\u00b7haus", "her", "johl\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "APPRART", "NN", "APZR", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ein versp\u00e4teter Geburtstag,", "tokens": ["Ein", "ver\u00b7sp\u00e4\u00b7te\u00b7ter", "Ge\u00b7burts\u00b7tag", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und das Flakerlicht des Kerzchens,", "tokens": ["Und", "das", "Fla\u00b7ker\u00b7licht", "des", "Kerz\u00b7chens", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Das sich vor ihm aus dem Dunkeln,", "tokens": ["Das", "sich", "vor", "ihm", "aus", "dem", "Dun\u00b7keln", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PRF", "APPR", "PPER", "APPR", "ART", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Wie ein Irrlicht abhob, streifte", "tokens": ["Wie", "ein", "Irr\u00b7licht", "ab\u00b7hob", ",", "streif\u00b7te"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["PWAV", "ART", "NN", "VVFIN", "$,", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Ab und zu ein Porzellanschild", "tokens": ["Ab", "und", "zu", "ein", "Por\u00b7zel\u00b7lan\u00b7schild"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "KON", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.33": {"line.1": {"text": "Baltrutsch, las er auf dem einen,", "tokens": ["Balt\u00b7rutsch", ",", "las", "er", "auf", "dem", "ei\u00b7nen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "PPER", "APPR", "ART", "ART", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Baltrutsch, Knopf-Arbeiter. \u2013 Endlich!", "tokens": ["Balt\u00b7rutsch", ",", "Knopf\u00b7A\u00b7rbei\u00b7ter", ".", "\u2013", "End\u00b7lich", "!"], "token_info": ["word", "punct", "word", "punct", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$.", "$(", "ADV", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.34": {"line.1": {"text": "Gut, dass wenigstens ihr Zimmer,", "tokens": ["Gut", ",", "dass", "we\u00b7nigs\u00b7tens", "ihr", "Zim\u00b7mer", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "KOUS", "ADV", "PPOSAT", "NN", "$,"], "meter": "+-+---+-", "measure": "unknown.measure.tri"}, "line.2": {"text": "Dessen Th\u00fcr erst frisch ge\u00f6lt schien,", "tokens": ["Des\u00b7sen", "Th\u00fcr", "erst", "frisch", "ge\u00b7\u00f6lt", "schien", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "ADV", "ADJD", "VVPP", "VVFIN", "$,"], "meter": "+-+-+---", "measure": "unknown.measure.tri"}, "line.3": {"text": "Eingermassen wohnlich war.", "tokens": ["Ein\u00b7ger\u00b7mas\u00b7sen", "wohn\u00b7lich", "war", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.35": {"line.1": {"text": "Feuerroth im Ofen gl\u00fchte", "tokens": ["Feu\u00b7er\u00b7roth", "im", "O\u00b7fen", "gl\u00fch\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "APPRART", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Grad das letzte Sch\u00e4uflein Kohlen,", "tokens": ["Grad", "das", "letz\u00b7te", "Sch\u00e4uf\u00b7lein", "Koh\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und ein sauberes Rouleau", "tokens": ["Und", "ein", "sau\u00b7be\u00b7res", "Rou\u00b7le\u00b7au"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.4": {"text": "Schob sich schneeweiss vor das Fenster.", "tokens": ["Schob", "sich", "schnee\u00b7weiss", "vor", "das", "Fens\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.36": {"line.1": {"text": "An die gr\u00fcngestreifte Wand", "tokens": ["An", "die", "gr\u00fcn\u00b7ge\u00b7streif\u00b7te", "Wand"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "War ein Christusbild genagelt.", "tokens": ["War", "ein", "Chris\u00b7tus\u00b7bild", "ge\u00b7na\u00b7gelt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.37": {"line.1": {"text": "In das aufgedeckte Bett,", "tokens": ["In", "das", "auf\u00b7ge\u00b7deck\u00b7te", "Bett", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Das davorstand, d\u00e4mmerte", "tokens": ["Das", "da\u00b7vor\u00b7stand", ",", "d\u00e4m\u00b7mer\u00b7te"], "token_info": ["word", "word", "punct", "word"], "pos": ["PDS", "VVFIN", "$,", "VVFIN"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.3": {"text": "Mattblau eine kleine Ampel,", "tokens": ["Matt\u00b7blau", "ei\u00b7ne", "klei\u00b7ne", "Am\u00b7pel", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und das obligate Sopha", "tokens": ["Und", "das", "ob\u00b7li\u00b7ga\u00b7te", "So\u00b7pha"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.5": {"text": "Stand ihm grade gegen\u00fcber.", "tokens": ["Stand", "ihm", "gra\u00b7de", "ge\u00b7gen\u00b7\u00fc\u00b7ber", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "PTKVZ", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.38": {"line.1": {"text": "Auch die Marmortoilette", "tokens": ["Auch", "die", "Mar\u00b7mor\u00b7to\u00b7i\u00b7let\u00b7te"], "token_info": ["word", "word", "word"], "pos": ["ADV", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Fehlte selbstverst\u00e4ndlich nicht.", "tokens": ["Fehl\u00b7te", "selbst\u00b7ver\u00b7st\u00e4nd\u00b7lich", "nicht", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "PTKNEG", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.39": {"line.1": {"text": "Zwei bis drei zerbrochne St\u00fchle", "tokens": ["Zwei", "bis", "drei", "zer\u00b7broch\u00b7ne", "St\u00fch\u00b7le"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["CARD", "APPR", "CARD", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Bl\u00e4tterten daneben cynisch", "tokens": ["Bl\u00e4t\u00b7ter\u00b7ten", "da\u00b7ne\u00b7ben", "cy\u00b7nisch"], "token_info": ["word", "word", "word"], "pos": ["NN", "PAV", "ADJD"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Ihre Memoiren auf.", "tokens": ["Ih\u00b7re", "Me\u00b7moi\u00b7ren", "auf", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PTKVZ", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}}, "stanza.40": {"line.1": {"text": "Freilich, wie diverse Lieder,", "tokens": ["Frei\u00b7lich", ",", "wie", "di\u00b7ver\u00b7se", "Lie\u00b7der", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PWAV", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Memoiren ohne Worte.", "tokens": ["Me\u00b7moi\u00b7ren", "oh\u00b7ne", "Wor\u00b7te", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.41": {"line.1": {"text": "\u00bbnun? Was schenkst du mir denn Schatz?\u00ab", "tokens": ["\u00bb", "nun", "?", "Was", "schenkst", "du", "mir", "denn", "Schatz", "?", "\u00ab"], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADV", "$.", "PWS", "VVFIN", "PPER", "PPER", "ADV", "NN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Und die vollen nackten Arme", "tokens": ["Und", "die", "vol\u00b7len", "nack\u00b7ten", "Ar\u00b7me"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Frech um seinen Hals geringelt,", "tokens": ["Frech", "um", "sei\u00b7nen", "Hals", "ge\u00b7rin\u00b7gelt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Presste ihn die weisse Bestie", "tokens": ["Press\u00b7te", "ihn", "die", "weis\u00b7se", "Be\u00b7stie"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "PPER", "ART", "ADJA", "NN"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.5": {"text": "Fest an ihre blossen Br\u00fcste.", "tokens": ["Fest", "an", "ih\u00b7re", "blos\u00b7sen", "Br\u00fcs\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.42": {"line.1": {"text": "Doch, da k\u00fcrzlich erst der Erste", "tokens": ["Doch", ",", "da", "k\u00fcrz\u00b7lich", "erst", "der", "Ers\u00b7te"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "$,", "KOUS", "ADV", "ADV", "ART", "ADJA"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.2": {"text": "Ihm das Portemonnaie gef\u00fcllt,", "tokens": ["Ihm", "das", "Por\u00b7te\u00b7mon\u00b7nai\u00b7e", "ge\u00b7f\u00fcllt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Wurden sie bald handelseins.", "tokens": ["Wur\u00b7den", "sie", "bald", "han\u00b7del\u00b7seins", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.43": {"line.1": {"text": "W\u00e4hrend er sich noch bem\u00fchte,", "tokens": ["W\u00e4h\u00b7rend", "er", "sich", "noch", "be\u00b7m\u00fch\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sich die Stiefel auszuziehn,", "tokens": ["Sich", "die", "Stie\u00b7fel", "aus\u00b7zu\u00b7ziehn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PRF", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Lachte auch sein Kaufobjekt,", "tokens": ["Lach\u00b7te", "auch", "sein", "Kauf\u00b7ob\u00b7jekt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Nackt wie Eva, schon vom Bett her.", "tokens": ["Nackt", "wie", "E\u00b7va", ",", "schon", "vom", "Bett", "her", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KOKOM", "NN", "$,", "ADV", "APPRART", "NN", "PTKVZ", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.44": {"line.1": {"text": "F\u00fcnf Minuten sp\u00e4ter noch,", "tokens": ["F\u00fcnf", "Mi\u00b7nu\u00b7ten", "sp\u00e4\u00b7ter", "noch", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "ADJD", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Und das indiscrete L\u00e4mpchen", "tokens": ["Und", "das", "in\u00b7di\u00b7scre\u00b7te", "L\u00e4mp\u00b7chen"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Flackert, leuchtet und verlischt.", "tokens": ["Fla\u00b7ckert", ",", "leuch\u00b7tet", "und", "ver\u00b7lischt", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "VVFIN", "KON", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.45": {"line.1": {"text": "Dunkelheit! Vom Ofenrost her,", "tokens": ["Dun\u00b7kel\u00b7heit", "!", "Vom", "O\u00b7fen\u00b7rost", "her", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$.", "APPRART", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Leis hinzitternd \u00fcber die Dielen,", "tokens": ["Leis", "hin\u00b7zit\u00b7ternd", "\u00fc\u00b7ber", "die", "Die\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVPP", "APPR", "ART", "NN", "$,"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "Nur ein magrer, rother Lichtstreif,", "tokens": ["Nur", "ein", "mag\u00b7rer", ",", "ro\u00b7ther", "Licht\u00b7streif", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und ins faltige Rouleau", "tokens": ["Und", "ins", "fal\u00b7ti\u00b7ge", "Rou\u00b7le\u00b7au"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPRART", "ADJA", "NN"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.5": {"text": "Malt sich fernher von der Strasse", "tokens": ["Malt", "sich", "fern\u00b7her", "von", "der", "Stras\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "PRF", "ADV", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Fahl das Licht der Gaslaternen.", "tokens": ["Fahl", "das", "Licht", "der", "Gas\u00b7la\u00b7ter\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.46": {"line.1": {"text": "Dunkelheit! Nur ab und zu", "tokens": ["Dun\u00b7kel\u00b7heit", "!", "Nur", "ab", "und", "zu"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$.", "ADV", "PTKVZ", "KON", "APPR"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Bricht ein heftig schweres Athmen", "tokens": ["Bricht", "ein", "hef\u00b7tig", "schwe\u00b7res", "Ath\u00b7men"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "ADJD", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Hastig durch die tiefe Stille,", "tokens": ["Has\u00b7tig", "durch", "die", "tie\u00b7fe", "Stil\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und dazwischen rauscht's und knittert's", "tokens": ["Und", "da\u00b7zwi\u00b7schen", "rauscht's", "und", "knit\u00b7tert's"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PAV", "VVFIN", "KON", "NE"], "meter": "----+-+-", "measure": "unknown.measure.di"}, "line.5": {"text": "Durch die Luft wie frisches Bettzeug.", "tokens": ["Durch", "die", "Luft", "wie", "fri\u00b7sches", "Bett\u00b7zeug", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "KOKOM", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.47": {"line.1": {"text": "Dunkelheit! Im Hause gingen", "tokens": ["Dun\u00b7kel\u00b7heit", "!", "Im", "Hau\u00b7se", "gin\u00b7gen"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NN", "$.", "APPRART", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Schon zum f\u00fcnften Mal die Uhren,", "tokens": ["Schon", "zum", "f\u00fcnf\u00b7ten", "Mal", "die", "Uh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "ADJA", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und das Zimmer fing sich an", "tokens": ["Und", "das", "Zim\u00b7mer", "fing", "sich", "an"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "VVFIN", "PRF", "APPR"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Leise grau in grau zu malen.", "tokens": ["Lei\u00b7se", "grau", "in", "grau", "zu", "ma\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "APPR", "ADJD", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.48": {"line.1": {"text": "\u00bbbleib doch noch!\u00ab \u00bbNein, lass, ich muss gehn!\u00ab", "tokens": ["\u00bb", "bleib", "doch", "noch", "!", "\u00ab", "\u00bb", "Nein", ",", "lass", ",", "ich", "muss", "gehn", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "punct", "punct", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VVFIN", "ADV", "ADV", "$.", "$(", "$(", "PTKANT", "$,", "VVFIN", "$,", "PPER", "VMFIN", "VVINF", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und aus ihrem Arm sich windend,", "tokens": ["Und", "aus", "ih\u00b7rem", "Arm", "sich", "win\u00b7dend", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPOSAT", "NN", "PRF", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Tappte er nach seinen Kleidern", "tokens": ["Tapp\u00b7te", "er", "nach", "sei\u00b7nen", "Klei\u00b7dern"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und begann sich anzuziehn.", "tokens": ["Und", "be\u00b7gann", "sich", "an\u00b7zu\u00b7ziehn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "VVIZU", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.49": {"line.1": {"text": "Ihren bleichen, runden Kopf", "tokens": ["Ih\u00b7ren", "blei\u00b7chen", ",", "run\u00b7den", "Kopf"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["PPOSAT", "ADJA", "$,", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Matt auf ihren Arm gest\u00fctzt,", "tokens": ["Matt", "auf", "ih\u00b7ren", "Arm", "ge\u00b7st\u00fctzt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Sah sie ihm mechanisch zu.", "tokens": ["Sah", "sie", "ihm", "me\u00b7cha\u00b7nisch", "zu", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "ADJD", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.50": {"line.1": {"text": "\u00bbkommst du wieder?\u00ab Gottseidank!", "tokens": ["\u00bb", "kommst", "du", "wie\u00b7der", "?", "\u00ab", "Gott\u00b7sei\u00b7dank", "!"], "token_info": ["punct", "word", "word", "word", "punct", "punct", "word", "punct"], "pos": ["$(", "VVFIN", "PPER", "ADV", "$.", "$(", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Jetzt nur noch den Rock und \u2013", "tokens": ["Jetzt", "nur", "noch", "den", "Rock", "und", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "ART", "NN", "KON", "$("], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "\u00bbkommst du wieder?\u00ab \u2013 jetzt: \u00bbAdieu!\u00ab", "tokens": ["\u00bb", "kommst", "du", "wie\u00b7der", "?", "\u00ab", "\u2013", "jetzt", ":", "\u00bb", "A\u00b7die\u00b7u", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "punct", "punct", "punct", "word", "punct", "punct", "word", "punct", "punct"], "pos": ["$(", "VVFIN", "PPER", "ADV", "$.", "$(", "$(", "ADV", "$.", "$(", "ADV", "$.", "$("], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.51": {"line.1": {"text": "Unten, auf dem Hausflur, kam ihm", "tokens": ["Un\u00b7ten", ",", "auf", "dem", "Haus\u00b7flur", ",", "kam", "ihm"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "$,", "APPR", "ART", "NN", "$,", "VVFIN", "PPER"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Eine Zeitungsfrau entgegen.", "tokens": ["Ei\u00b7ne", "Zei\u00b7tungs\u00b7frau", "ent\u00b7ge\u00b7gen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.52": {"line.1": {"text": "Donnerwetter! Schon so sp\u00e4t?", "tokens": ["Don\u00b7ner\u00b7wet\u00b7ter", "!", "Schon", "so", "sp\u00e4t", "?"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$.", "ADV", "ADV", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Und den Kragen seines Mantels", "tokens": ["Und", "den", "Kra\u00b7gen", "sei\u00b7nes", "Man\u00b7tels"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Hoch bis unters Kinn gekn\u00f6pft,", "tokens": ["Hoch", "bis", "un\u00b7ters", "Kinn", "ge\u00b7kn\u00f6pft", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "APPRART", "NN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Trat er fr\u00f6stelnd vor die Th\u00fcr.", "tokens": ["Trat", "er", "fr\u00f6s\u00b7telnd", "vor", "die", "Th\u00fcr."], "token_info": ["word", "word", "word", "word", "word", "abbreviation"], "pos": ["VVFIN", "PPER", "ADJD", "APPR", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.53": {"line.1": {"text": "Schmutzig lag vor ihm die Strasse,", "tokens": ["Schmut\u00b7zig", "lag", "vor", "ihm", "die", "Stras\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPR", "PPER", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Schmutzig wie ein altes Schnupftuch,", "tokens": ["Schmut\u00b7zig", "wie", "ein", "al\u00b7tes", "Schnupf\u00b7tuch", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "KOKOM", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und vom grauverhangnen Himmel", "tokens": ["Und", "vom", "grau\u00b7ver\u00b7hang\u00b7nen", "Him\u00b7mel"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPRART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Rieselte ein feiner Nebel.", "tokens": ["Rie\u00b7sel\u00b7te", "ein", "fei\u00b7ner", "Ne\u00b7bel", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "$."], "meter": "+---+-+-", "measure": "dactylic.init"}}, "stanza.54": {"line.1": {"text": "\u00bbbrrr!\u00ab Und vor sich selbst aus Ekel", "tokens": ["\u00bb", "brrr", "!", "\u00ab", "Und", "vor", "sich", "selbst", "aus", "E\u00b7kel"], "token_info": ["punct", "word", "punct", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "PTKVZ", "$.", "$(", "KON", "APPR", "PRF", "ADV", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Spie er mitten in die Gosse.", "tokens": ["Spie", "er", "mit\u00b7ten", "in", "die", "Gos\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}}}}