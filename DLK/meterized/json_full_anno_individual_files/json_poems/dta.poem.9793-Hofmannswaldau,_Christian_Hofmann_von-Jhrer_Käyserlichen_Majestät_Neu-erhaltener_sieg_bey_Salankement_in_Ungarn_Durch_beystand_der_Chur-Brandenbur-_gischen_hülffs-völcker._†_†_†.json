{"dta.poem.9793": {"metadata": {"author": {"name": "Hofmannswaldau, Christian Hofmann von", "birth": "N.A.", "death": "N.A."}, "title": "Jhrer K\u00e4yserlichen Majest\u00e4t  \n Neu-erhaltener sieg bey Salankement in Ungarn/  \n Durch beystand der Chur-Brandenbur-  \n gischen h\u00fclffs-v\u00f6lcker.  \n \u2020 \u2020 \u2020", "genre": "Lyrik", "period": "N.A.", "pub_year": "1697", "urn": "urn:nbn:de:kobv:b4-200905199377", "language": ["de:0.85", "id:0.14"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Ungarn mu\u00df auch dieses jahr", "tokens": ["Un\u00b7garn", "mu\u00df", "auch", "die\u00b7ses", "jahr"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "VMFIN", "ADV", "PDAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Mit den Brandenburgern siegen;", "tokens": ["Mit", "den", "Bran\u00b7den\u00b7bur\u00b7gern", "sie\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und beweiset wunderbar/", "tokens": ["Und", "be\u00b7wei\u00b7set", "wun\u00b7der\u00b7bar", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wie sichs immer m\u00fcssen f\u00fcgen/", "tokens": ["Wie", "sichs", "im\u00b7mer", "m\u00fcs\u00b7sen", "f\u00fc\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "ADV", "VMFIN", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Da\u00df so offt wir uns zum streit", "tokens": ["Da\u00df", "so", "offt", "wir", "uns", "zum", "streit"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "ADV", "PPER", "PRF", "APPRART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "F\u00fcr dis K\u00f6nigreich verbunden;", "tokens": ["F\u00fcr", "dis", "K\u00f6\u00b7nig\u00b7reich", "ver\u00b7bun\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PDS", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Leopold daun allezeit", "tokens": ["Leo\u00b7pold", "daun", "al\u00b7le\u00b7zeit"], "token_info": ["word", "word", "word"], "pos": ["NE", "VVFIN", "ADV"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "Ungezweifelt \u00fcberwunden.", "tokens": ["Un\u00b7ge\u00b7zwei\u00b7felt", "\u00fc\u00b7berw\u00b7un\u00b7den", "."], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Ofens nie gez\u00e4hmter wall", "tokens": ["O\u00b7fens", "nie", "ge\u00b7z\u00e4hm\u00b7ter", "wall"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ADV", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Ward durch uns zu erst erbrochen;", "tokens": ["Ward", "durch", "uns", "zu", "erst", "er\u00b7bro\u00b7chen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "PPER", "APPR", "ADV", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und den letzten \u00fcberfall", "tokens": ["Und", "den", "letz\u00b7ten", "\u00fc\u00b7berf\u00b7all"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Hat itzt dieser sieg gerochen.", "tokens": ["Hat", "itzt", "die\u00b7ser", "sieg", "ge\u00b7ro\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PDAT", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Was der Gro\u00df-Vizier gewan", "tokens": ["Was", "der", "Gro\u00df\u00b7Vi\u00b7zier", "ge\u00b7wan"], "token_info": ["word", "word", "word", "word"], "pos": ["PWS", "ART", "NN", "VVPP"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Ist durch diese schlacht zernichtet;", "tokens": ["Ist", "durch", "die\u00b7se", "schlacht", "zer\u00b7nich\u00b7tet", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "PDAT", "ADJD", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Und was hat auff diesem plan", "tokens": ["Und", "was", "hat", "auff", "die\u00b7sem", "plan"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWS", "VAFIN", "APPR", "PDAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Nicht vorl\u00e4ngst ein Sparr verrichtet?", "tokens": ["Nicht", "vor\u00b7l\u00e4ngst", "ein", "Sparr", "ver\u00b7rich\u00b7tet", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Aber kan es anders seyn?", "tokens": ["A\u00b7ber", "kan", "es", "an\u00b7ders", "seyn", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "ADV", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Oesterreichs und unsre waffen", "tokens": ["O\u00b7es\u00b7ter\u00b7reichs", "und", "uns\u00b7re", "waf\u00b7fen"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "KON", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Scheinen gleichsam \u00fcberein", "tokens": ["Schei\u00b7nen", "gleich\u00b7sam", "\u00fc\u00b7be\u00b7re\u00b7in"], "token_info": ["word", "word", "word"], "pos": ["NN", "ADJD", "PTKVZ"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Und f\u00fcr einen mann geschaffen.", "tokens": ["Und", "f\u00fcr", "ei\u00b7nen", "mann", "ge\u00b7schaf\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Adler fast einander gleich/", "tokens": ["Ad\u00b7ler", "fast", "ein\u00b7an\u00b7der", "gleich", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ADV", "ADV", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Die von einem stamm entsprossen/", "tokens": ["Die", "von", "ei\u00b7nem", "stamm", "ent\u00b7spros\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "VVPP", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Sind einander f\u00fcr das reich", "tokens": ["Sind", "ein\u00b7an\u00b7der", "f\u00fcr", "das", "reich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "PRF", "APPR", "ART", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Auch die besten h\u00fclffs-genossen.", "tokens": ["Auch", "die", "bes\u00b7ten", "h\u00fclffs\u00b7ge\u00b7nos\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Wohl uns bey der eigenschafft!", "tokens": ["Wohl", "uns", "bey", "der", "ei\u00b7gen\u00b7schafft", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Wie sie itzt f\u00fcr Ungarn streiten/", "tokens": ["Wie", "sie", "itzt", "f\u00fcr", "Un\u00b7garn", "strei\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "APPR", "NE", "VVFIN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Also wird sich ihre krafft", "tokens": ["Al\u00b7so", "wird", "sich", "ih\u00b7re", "krafft"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PRF", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Bald auf Franckreich selbst erbreiten.", "tokens": ["Bald", "auf", "Fran\u00b7ck\u00b7reich", "selbst", "er\u00b7brei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NE", "ADV", "VVINF", "$."], "meter": "--+-+--+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Wenn die Adler erst den mond/", "tokens": ["Wenn", "die", "Ad\u00b7ler", "erst", "den", "mond", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ADV", "ART", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Als die vor-maur \u00fcberstiegen;", "tokens": ["Als", "die", "vor\u00b7maur", "\u00fc\u00b7bers\u00b7tie\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJD", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Werden sie/ wie sie gewohnt/", "tokens": ["Wer\u00b7den", "sie", "/", "wie", "sie", "ge\u00b7wohnt", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "$(", "PWAV", "PPER", "VVPP", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "Leichter in die sonne fliegen.", "tokens": ["Leich\u00b7ter", "in", "die", "son\u00b7ne", "flie\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}}}}