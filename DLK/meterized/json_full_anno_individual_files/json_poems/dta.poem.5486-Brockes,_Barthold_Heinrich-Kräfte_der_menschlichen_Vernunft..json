{"dta.poem.5486": {"metadata": {"author": {"name": "Brockes, Barthold Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "Kr\u00e4fte der menschlichen Vernunft.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1736", "urn": "urn:nbn:de:kobv:b4-200905198582", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Hier seh ich, an verschiednen Stellen,", "tokens": ["Hier", "seh", "ich", ",", "an", "ver\u00b7schied\u00b7nen", "Stel\u00b7len", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ein Silber-reines Wasser qvellen,", "tokens": ["Ein", "Sil\u00b7ber\u00b7rei\u00b7nes", "Was\u00b7ser", "qvel\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Erst \u00fcber weissem Sande fliessen,", "tokens": ["Erst", "\u00fc\u00b7ber", "weis\u00b7sem", "San\u00b7de", "flies\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Hernach sich \u00fcbers Land ergiessen,", "tokens": ["Her\u00b7nach", "sich", "\u00fc\u00b7bers", "Land", "er\u00b7gies\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PRF", "APPRART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Sich \u00fcber Weg und Fu\u00df-Steig lencken,", "tokens": ["Sich", "\u00fc\u00b7ber", "Weg", "und", "Fu\u00df\u00b7Steig", "len\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "NN", "KON", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Und Wiesen, Gras und Kraut ertr\u00e4ncken.", "tokens": ["Und", "Wie\u00b7sen", ",", "Gras", "und", "Kraut", "er\u00b7tr\u00e4n\u00b7cken", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "$,", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Mir fiel bey diesem Wasser, ein:", "tokens": ["Mir", "fiel", "bey", "die\u00b7sem", "Was\u00b7ser", ",", "ein", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PDAT", "NN", "$,", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Es hie\u00df der Sch\u00f6pfer, auf der Erden", "tokens": ["Es", "hie\u00df", "der", "Sch\u00f6p\u00b7fer", ",", "auf", "der", "Er\u00b7den"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Zwar alle Ding\u2019 und C\u00f6rper werden;", "tokens": ["Zwar", "al\u00b7le", "Ding'", "und", "C\u00f6r\u00b7per", "wer\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "KON", "NN", "VAINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Doch k\u00f6nnen sie sich nicht allein", "tokens": ["Doch", "k\u00f6n\u00b7nen", "sie", "sich", "nicht", "al\u00b7lein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VMFIN", "PPER", "PRF", "PTKNEG", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Nach Ordnung und Vernunft regieren;", "tokens": ["Nach", "Ord\u00b7nung", "und", "Ver\u00b7nunft", "re\u00b7gie\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Es m\u00fcssen darum Menschen seyn,", "tokens": ["Es", "m\u00fcs\u00b7sen", "da\u00b7rum", "Men\u00b7schen", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PAV", "NN", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Um sie zum rechten Zweck zu f\u00fchren.", "tokens": ["Um", "sie", "zum", "rech\u00b7ten", "Zweck", "zu", "f\u00fch\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PPER", "APPRART", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Dem Geist des Menschen ist die Kraft", "tokens": ["Dem", "Geist", "des", "Men\u00b7schen", "ist", "die", "Kraft"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "NN", "VAFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Von dem, der alles schuf, geschencket,", "tokens": ["Von", "dem", ",", "der", "al\u00b7les", "schuf", ",", "ge\u00b7schen\u00b7cket", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "ART", "$,", "PRELS", "PIS", "VVFIN", "$,", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Da\u00df er der C\u00f6rper Eigenschaft", "tokens": ["Da\u00df", "er", "der", "C\u00f6r\u00b7per", "Ei\u00b7gen\u00b7schaft"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Nach Regul, Maa\u00df und Ordnung lencket.", "tokens": ["Nach", "Re\u00b7gul", ",", "Maa\u00df", "und", "Ord\u00b7nung", "len\u00b7cket", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Was k\u00f6nnte nicht, aus diesem Bach,", "tokens": ["Was", "k\u00f6nn\u00b7te", "nicht", ",", "aus", "die\u00b7sem", "Bach", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PTKNEG", "$,", "APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Der Tag und Nacht best\u00e4ndig l\u00e4uft,", "tokens": ["Der", "Tag", "und", "Nacht", "be\u00b7st\u00e4n\u00b7dig", "l\u00e4uft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Und, sonder Aufsicht, nach und nach", "tokens": ["Und", ",", "son\u00b7der", "Auf\u00b7sicht", ",", "nach", "und", "nach"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "$,", "KON", "NN", "$,", "APPR", "KON", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Das Land verderbet und ers\u00e4uft,", "tokens": ["Das", "Land", "ver\u00b7der\u00b7bet", "und", "er\u00b7s\u00e4uft", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "So wol zur Lust, als Fruchtbarkeit der Erden,", "tokens": ["So", "wol", "zur", "Lust", ",", "als", "Frucht\u00b7bar\u00b7keit", "der", "Er\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPRART", "NN", "$,", "KOUS", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.17": {"text": "F\u00fcr Nutzen nicht geschaffet werden?", "tokens": ["F\u00fcr", "Nut\u00b7zen", "nicht", "ge\u00b7schaf\u00b7fet", "wer\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PTKNEG", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Solch unsern Geist betrachtendes Erwegen", "tokens": ["Solch", "un\u00b7sern", "Geist", "be\u00b7trach\u00b7ten\u00b7des", "Er\u00b7we\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIS", "PPOSAT", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Kann uns aufs neu von unsers Geistes Wehrt,", "tokens": ["Kann", "uns", "aufs", "neu", "von", "un\u00b7sers", "Geis\u00b7tes", "Wehrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "APPRART", "ADJD", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Und was f\u00fcr Gaben ihm beschehrt,", "tokens": ["Und", "was", "f\u00fcr", "Ga\u00b7ben", "ihm", "be\u00b7schehrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "APPR", "NN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Wahrheit klar vor Augen legen.", "tokens": ["Die", "Wahr\u00b7heit", "klar", "vor", "Au\u00b7gen", "le\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Verdienet es demnach gar wol, mit ernstem Dencken,", "tokens": ["Ver\u00b7die\u00b7net", "es", "dem\u00b7nach", "gar", "wol", ",", "mit", "erns\u00b7tem", "Den\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PAV", "ADV", "ADV", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der Seelen Kraft auf ihre Kraft zu lencken,", "tokens": ["Der", "See\u00b7len", "Kraft", "auf", "ih\u00b7re", "Kraft", "zu", "len\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "APPR", "PPOSAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und, ", "tokens": ["Und", ","], "token_info": ["word", "punct"], "pos": ["KON", "$,"], "meter": "+", "measure": "single.up"}, "line.4": {"text": "Die Wunder, welche GOtt in sie zu sencken", "tokens": ["Die", "Wun\u00b7der", ",", "wel\u00b7che", "Gott", "in", "sie", "zu", "sen\u00b7cken"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PWAT", "NN", "APPR", "PPER", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Sie wehrt geachtet hat, ihn dadurch zu erh\u00f6hn:", "tokens": ["Sie", "wehrt", "ge\u00b7ach\u00b7tet", "hat", ",", "ihn", "da\u00b7durch", "zu", "er\u00b7h\u00f6hn", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "VVPP", "VAFIN", "$,", "PPER", "PAV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Es ist wahr, es hat der Mensch nicht die schnelle", "tokens": ["Es", "ist", "wahr", ",", "es", "hat", "der", "Mensch", "nicht", "die", "schnel\u00b7le"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADJD", "$,", "PPER", "VAFIN", "ART", "NN", "PTKNEG", "ART", "ADJA"], "meter": "+-+-+-+--+-", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Seine Stelle zu ver\u00e4ndern, und sich \u00fcber Thal und H\u00fcgel", "tokens": ["Sei\u00b7ne", "Stel\u00b7le", "zu", "ver\u00b7\u00e4n\u00b7dern", ",", "und", "sich", "\u00fc\u00b7ber", "Thal", "und", "H\u00fc\u00b7gel"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "PTKZU", "VVINF", "$,", "KON", "PRF", "APPR", "NN", "KON", "NN"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.3": {"text": "Schnellen V\u00f6geln gleich zu schwingen, und sich, in so kur-", "tokens": ["Schnel\u00b7len", "V\u00f6\u00b7geln", "gleich", "zu", "schwin\u00b7gen", ",", "und", "sich", ",", "in", "so", "kur"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["ADJA", "NN", "ADV", "PTKZU", "VVINF", "$,", "KON", "PRF", "$,", "APPR", "ADV", "TRUNC"], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}, "line.4": {"text": "An entfernten Ort zu schaffen: denn er hat ja keine Fl\u00fcgel.", "tokens": ["An", "ent\u00b7fern\u00b7ten", "Ort", "zu", "schaf\u00b7fen", ":", "denn", "er", "hat", "ja", "kei\u00b7ne", "Fl\u00fc\u00b7gel", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "PTKZU", "VVINF", "$.", "KON", "PPER", "VAFIN", "ADV", "PIAT", "NN", "$."], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.5": {"text": "Gleichfals sind wir nicht so starck, wie verschiedne Thiere, die", "tokens": ["Gleich\u00b7fals", "sind", "wir", "nicht", "so", "starck", ",", "wie", "ver\u00b7schied\u00b7ne", "Thie\u00b7re", ",", "die"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["ADV", "VAFIN", "PPER", "PTKNEG", "ADV", "ADJD", "$,", "PWAV", "ADJA", "NN", "$,", "PRELS"], "meter": "-+--+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "Wir, Bewundrungs-voll, mit H\u00f6rnern, Z\u00e4hnen, Sta-", "tokens": ["Wir", ",", "Be\u00b7wun\u00b7drungs\u00b7voll", ",", "mit", "H\u00f6r\u00b7nern", ",", "Z\u00e4h\u00b7nen", ",", "Sta"], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "word", "punct", "word"], "pos": ["PPER", "$,", "NN", "$,", "APPR", "NN", "$,", "NN", "$,", "TRUNC"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.7": {"text": "Sich zu sch\u00fctzen, sich zu n\u00e4hren, wunderbar bewaffnet", "tokens": ["Sich", "zu", "sch\u00fct\u00b7zen", ",", "sich", "zu", "n\u00e4h\u00b7ren", ",", "wun\u00b7der\u00b7bar", "be\u00b7waff\u00b7net"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["PRF", "PTKZU", "VVINF", "$,", "PRF", "PTKZU", "VVINF", "$,", "ADJD", "VVFIN"], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}, "line.8": {"text": "Ja, noch mehr; wir finden uns nicht gekleidet, wie das Vieh,", "tokens": ["Ja", ",", "noch", "mehr", ";", "wir", "fin\u00b7den", "uns", "nicht", "ge\u00b7klei\u00b7det", ",", "wie", "das", "Vieh", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "ADV", "ADV", "$.", "PPER", "VVFIN", "PPER", "PTKNEG", "VVPP", "$,", "PWAV", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.9": {"text": "Von den H\u00e4nden der Natur, da die Menschen auf der", "tokens": ["Von", "den", "H\u00e4n\u00b7den", "der", "Na\u00b7tur", ",", "da", "die", "Men\u00b7schen", "auf", "der"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ART", "NN", "$,", "KOUS", "ART", "NN", "APPR", "ART"], "meter": "--+---+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "Ohne Peltz-Werck, Federn, Schuppen, gegen Wetter, Hitz\u2019", "tokens": ["Oh\u00b7ne", "Peltz\u00b7\u00b7Werck", ",", "Fe\u00b7dern", ",", "Schup\u00b7pen", ",", "ge\u00b7gen", "Wet\u00b7ter", ",", "Hitz'"], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "punct", "word"], "pos": ["APPR", "NN", "$,", "NN", "$,", "NN", "$,", "APPR", "NN", "$,", "NN"], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}, "line.11": {"text": "Ohne den geringsten Schutz, nackt und blo\u00df gebohren", "tokens": ["Oh\u00b7ne", "den", "ge\u00b7rings\u00b7ten", "Schutz", ",", "nackt", "und", "blo\u00df", "ge\u00b7boh\u00b7ren"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "$,", "ADJD", "KON", "ADV", "VVPP"], "meter": "+-+-+-++-+-+-", "measure": "unknown.measure.septa"}, "line.12": {"text": "Schickt so nackte D\u00fcrftigkeit sich zum K\u00f6nige der Erden?", "tokens": ["Schickt", "so", "nack\u00b7te", "D\u00fcrf\u00b7tig\u00b7keit", "sich", "zum", "K\u00f6\u00b7ni\u00b7ge", "der", "Er\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADJA", "NN", "PRF", "APPRART", "NN", "ART", "NN", "$."], "meter": "+-+-+-++-+-+-+-", "measure": "unknown.measure.octa.plus"}}, "stanza.6": {"line.1": {"text": "Antwort:", "tokens": ["Ant\u00b7wort", ":"], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.2": {"text": "Uns ist die Vernunft geschenckt, und durch diese sind wir", "tokens": ["Uns", "ist", "die", "Ver\u00b7nunft", "ge\u00b7schenckt", ",", "und", "durch", "die\u00b7se", "sind", "wir"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "NN", "VVPP", "$,", "KON", "APPR", "PDS", "VAFIN", "PPER"], "meter": "-+--+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Starck, und wol versorgt mit allem, was uns n\u00f6htig thut,", "tokens": ["Starck", ",", "und", "wol", "ver\u00b7sorgt", "mit", "al\u00b7lem", ",", "was", "uns", "n\u00f6h\u00b7tig", "thut", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KON", "ADV", "VVPP", "APPR", "PIS", "$,", "PRELS", "PPER", "ADJD", "VVFIN", "$,"], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}}, "stanza.7": {"line.1": {"text": "Durch dieselbe werden wir \u00fcberzeuglich gnug belehret,", "tokens": ["Durch", "die\u00b7sel\u00b7be", "wer\u00b7den", "wir", "\u00fc\u00b7berz\u00b7eug\u00b7lich", "gnug", "be\u00b7leh\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "VAFIN", "PPER", "ADJD", "ADV", "VVFIN", "$,"], "meter": "+-+-+--+-+-+-+-", "measure": "trochaic.septa.relaxed"}, "line.2": {"text": "Da\u00df was alle Thiere haben, eigentlich uns zugeh\u00f6ret.", "tokens": ["Da\u00df", "was", "al\u00b7le", "Thie\u00b7re", "ha\u00b7ben", ",", "ei\u00b7gent\u00b7lich", "uns", "zu\u00b7ge\u00b7h\u00f6\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PRELS", "PIAT", "NN", "VAFIN", "$,", "ADV", "PPER", "VVPP", "$."], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.3": {"text": "Da\u00df sie w\u00fcrcklich unsre Sclaven, da\u00df ihr\u2019 Arbeit, Dienst", "tokens": ["Da\u00df", "sie", "w\u00fcrck\u00b7lich", "uns\u00b7re", "Scla\u00b7ven", ",", "da\u00df", "ih\u00b7r'", "Ar\u00b7beit", ",", "Dienst"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["KOUS", "PPER", "ADJD", "PPOSAT", "NN", "$,", "KOUS", "PPOSAT", "NN", "$,", "NN"], "meter": "+-+-+-+--+-+-+", "measure": "trochaic.septa.relaxed"}, "line.4": {"text": "Uns allein zu unserm Nutzen, Dienst und Willk\u00fchr \u00fcber-", "tokens": ["Uns", "al\u00b7lein", "zu", "un\u00b7serm", "Nut\u00b7zen", ",", "Dienst", "und", "Will\u00b7k\u00fchr", "\u00fc\u00b7ber"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "APPR", "PPOSAT", "NN", "$,", "NN", "KON", "NN", "TRUNC"], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}}, "stanza.8": {"line.1": {"text": "Haben wir ein Wildpr\u00e4t n\u00f6htig; wird ein Falck, ein", "tokens": ["Ha\u00b7ben", "wir", "ein", "Wild\u00b7pr\u00e4t", "n\u00f6h\u00b7tig", ";", "wird", "ein", "Falck", ",", "ein"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["VAFIN", "PPER", "ART", "NN", "ADJD", "$.", "VAFIN", "ART", "NN", "$,", "ART"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.2": {"text": "Welcher, sonder unsre M\u00fche, das, was man verlangt, be-", "tokens": ["Wel\u00b7cher", ",", "son\u00b7der", "uns\u00b7re", "M\u00fc\u00b7he", ",", "das", ",", "was", "man", "ver\u00b7langt", ",", "be"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["PWAT", "$,", "KON", "PPOSAT", "NN", "$,", "PDS", "$,", "PRELS", "PIS", "VVFIN", "$,", "TRUNC"], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}, "line.3": {"text": "Und in unsre K\u00fcche liefert. Aendert sich die Jahres-Zeit,", "tokens": ["Und", "in", "uns\u00b7re", "K\u00fc\u00b7che", "lie\u00b7fert", ".", "A\u00b7en\u00b7dert", "sich", "die", "Jah\u00b7res\u00b7Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPOSAT", "NN", "VVFIN", "$.", "VVFIN", "PRF", "ART", "NN", "$,"], "meter": "-+--+-+--+-+-+-+", "measure": "iambic.septa.relaxed"}, "line.4": {"text": "Und wir wollen, uns zum Schutz und zur Zier, ein an-", "tokens": ["Und", "wir", "wol\u00b7len", ",", "uns", "zum", "Schutz", "und", "zur", "Zier", ",", "ein", "an"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "PPER", "VMFIN", "$,", "PPER", "APPRART", "NN", "KON", "APPRART", "NN", "$,", "ART", "TRUNC"], "meter": "+-+-+-+--+-+", "measure": "trochaic.hexa.relaxed"}, "line.5": {"text": "Zins\u2019t das Schaf uns seine Wolle, zollet das Cameel sein", "tokens": ["Zins't", "das", "Schaf", "uns", "sei\u00b7ne", "Wol\u00b7le", ",", "zol\u00b7let", "das", "Ca\u00b7meel", "sein"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "NN", "PPER", "PPOSAT", "NN", "$,", "VVFIN", "ART", "NN", "PPOSAT"], "meter": "+-+-+-+-+--+-+", "measure": "trochaic.septa.relaxed"}, "line.6": {"text": "Und es spinnt der Seiden-Wurm uns ein leicht und sch\u00f6n", "tokens": ["Und", "es", "spinnt", "der", "Sei\u00b7den\u00b7Wurm", "uns", "ein", "leicht", "und", "sch\u00f6n"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "ART", "NN", "PPER", "ART", "ADJD", "KON", "ADJD"], "meter": "--+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.7": {"text": "Es ern\u00e4hren uns die Thiere, sie bewahren uns so gar,", "tokens": ["Es", "er\u00b7n\u00e4h\u00b7ren", "uns", "die", "Thie\u00b7re", ",", "sie", "be\u00b7wah\u00b7ren", "uns", "so", "gar", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ART", "NN", "$,", "PPER", "VVFIN", "PPER", "ADV", "ADV", "$,"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.8": {"text": "Ja sie tragen unsre Lasten, bau\u2019n und pfl\u00fcgen unser Land;", "tokens": ["Ja", "sie", "tra\u00b7gen", "uns\u00b7re", "Las\u00b7ten", ",", "bau'n", "und", "pfl\u00fc\u00b7gen", "un\u00b7ser", "Land", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "PPER", "VVFIN", "PPOSAT", "NN", "$,", "VVFIN", "KON", "VVFIN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.9": {"text": "Dieses ist noch nicht genug: Es sind nicht die Thiere nur,", "tokens": ["Die\u00b7ses", "ist", "noch", "nicht", "ge\u00b7nug", ":", "Es", "sind", "nicht", "die", "Thie\u00b7re", "nur", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "PTKNEG", "ADV", "$.", "PPER", "VAFIN", "PTKNEG", "ART", "NN", "ADV", "$,"], "meter": "+-+-+-+--+-+-+", "measure": "trochaic.septa.relaxed"}, "line.10": {"text": "Die uns Kunst und St\u00e4rcke leih\u2019n; die Vernunft zwingt,", "tokens": ["Die", "uns", "Kunst", "und", "St\u00e4r\u00b7cke", "leih'n", ";", "die", "Ver\u00b7nunft", "zwingt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "NN", "KON", "NN", "VVINF", "$.", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+--+-", "measure": "trochaic.penta.relaxed"}, "line.11": {"text": "Auch die Unempfindlichsten unter aller Creatur.", "tokens": ["Auch", "die", "Un\u00b7emp\u00b7find\u00b7lichs\u00b7ten", "un\u00b7ter", "al\u00b7ler", "Crea\u00b7tur", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "APPR", "PIAT", "NN", "$."], "meter": "+-+--+-+-+--+", "measure": "trochaic.hexa.relaxed"}, "line.12": {"text": "Selbst die allerst\u00e4rcksten Eichen, die auf hohen Bergen", "tokens": ["Selbst", "die", "al\u00b7ler\u00b7st\u00e4rcks\u00b7ten", "Ei\u00b7chen", ",", "die", "auf", "ho\u00b7hen", "Ber\u00b7gen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "ART", "ADJA", "NN", "$,", "PRELS", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}, "line.13": {"text": "Bringet sie zu uns herab; sie weis Fel\u00df und Stein zu trennen", "tokens": ["Brin\u00b7get", "sie", "zu", "uns", "her\u00b7ab", ";", "sie", "weis", "Fel\u00df", "und", "Stein", "zu", "tren\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "APPR", "PPER", "ADV", "$.", "PPER", "PTKVZ", "NN", "KON", "NN", "PTKZU", "VVINF"], "meter": "+-+-+-+--+-+-+-", "measure": "trochaic.septa.relaxed"}, "line.14": {"text": "Aus der Erden duncklem Scho\u00df, da\u00df wir sicher wohnen", "tokens": ["Aus", "der", "Er\u00b7den", "dunck\u00b7lem", "Scho\u00df", ",", "da\u00df", "wir", "si\u00b7cher", "woh\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ADJA", "NN", "$,", "KOUS", "PPER", "PRF", "VVINF"], "meter": "--+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.15": {"text": "Wollen wir von einem Land-Strich, auch selbst \u00fcbers Meer,", "tokens": ["Wol\u00b7len", "wir", "von", "ei\u00b7nem", "Lan\u00b7dStrich", ",", "auch", "selbst", "\u00fc\u00b7bers", "Meer", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ART", "NN", "$,", "ADV", "ADV", "APPRART", "NN", "$,"], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}, "line.16": {"text": "Wahre haben, oder senden, ja auch selbst mit ihnen wandern;", "tokens": ["Wah\u00b7re", "ha\u00b7ben", ",", "o\u00b7der", "sen\u00b7den", ",", "ja", "auch", "selbst", "mit", "ih\u00b7nen", "wan\u00b7dern", ";"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "VAFIN", "$,", "KON", "VVINF", "$,", "ADV", "ADV", "ADV", "APPR", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}}, "stanza.9": {"line.1": {"text": "Brauchen wir, zu diesem Endzweck, der Gew\u00e4sser Fl\u00fc\u00dfigkeit,", "tokens": ["Brau\u00b7chen", "wir", ",", "zu", "die\u00b7sem", "End\u00b7zweck", ",", "der", "Ge\u00b7w\u00e4s\u00b7ser", "Fl\u00fc\u00b7\u00dfig\u00b7keit", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "APPR", "PDAT", "NN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.2": {"text": "Auch der L\u00fcfte Hauch, den Wind. Elementen und Metallen", "tokens": ["Auch", "der", "L\u00fcf\u00b7te", "Hauch", ",", "den", "Wind", ".", "E\u00b7le\u00b7men\u00b7ten", "und", "Me\u00b7tal\u00b7len"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "NN", "$,", "ART", "NN", "$.", "NN", "KON", "NN"], "meter": "--+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Sind, durch Kr\u00e4fte der Vernunft, uns zu unserm Dienst", "tokens": ["Sind", ",", "durch", "Kr\u00e4f\u00b7te", "der", "Ver\u00b7nunft", ",", "uns", "zu", "un\u00b7serm", "Dienst"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VAFIN", "$,", "APPR", "NN", "ART", "NN", "$,", "PPER", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+--+-+", "measure": "trochaic.hexa.relaxed"}, "line.4": {"text": "Wo sie was von C\u00f6rpern brauchen, nimmt sie, was ihr", "tokens": ["Wo", "sie", "was", "von", "C\u00f6r\u00b7pern", "brau\u00b7chen", ",", "nimmt", "sie", ",", "was", "ihr"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["PWAV", "PPER", "PIS", "APPR", "NE", "VVFIN", "$,", "VVFIN", "PPER", "$,", "PWS", "PPER"], "meter": "+-+-+-+-+--+", "measure": "iambic.hexa.chol"}, "line.5": {"text": "Sind wir gleich nur klein, doch giebet die Vernunft uns", "tokens": ["Sind", "wir", "gleich", "nur", "klein", ",", "doch", "gie\u00b7bet", "die", "Ver\u00b7nunft", "uns"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "ADV", "ADV", "ADJD", "$,", "ADV", "VVFIN", "ART", "NN", "PPER"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.6": {"text": "Die sonst anders keine Gr\u00e4ntzen, als der Erden Gr\u00e4ntzen", "tokens": ["Die", "sonst", "an\u00b7ders", "kei\u00b7ne", "Gr\u00e4nt\u00b7zen", ",", "als", "der", "Er\u00b7den", "Gr\u00e4nt\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADV", "ADV", "PIAT", "NN", "$,", "KOUS", "ART", "NN", "NN"], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}, "line.7": {"text": "Deren Fl\u00e4che wir bewohnen. Was wir wollen wird voll-", "tokens": ["De\u00b7ren", "Fl\u00e4\u00b7che", "wir", "be\u00b7woh\u00b7nen", ".", "Was", "wir", "wol\u00b7len", "wird", "voll"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "PPER", "VVINF", "$.", "PWS", "PPER", "VMFIN", "VAFIN", "TRUNC"], "meter": "+-+-+-+-+-+--+", "measure": "iambic.septa.chol"}, "line.8": {"text": "So bey Nordens kaltem Eys\u2019, als wo stets die Sonne brennet.", "tokens": ["So", "bey", "Nor\u00b7dens", "kal\u00b7tem", "Eys'", ",", "als", "wo", "stets", "die", "Son\u00b7ne", "bren\u00b7net", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NE", "ADJA", "NN", "$,", "KOUS", "PWAV", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "--+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.9": {"text": "Wir verbinden, so zu reden, beyde Theile dieser Welt,", "tokens": ["Wir", "ver\u00b7bin\u00b7den", ",", "so", "zu", "re\u00b7den", ",", "bey\u00b7de", "Thei\u00b7le", "die\u00b7ser", "Welt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVINF", "$,", "ADV", "PTKZU", "VVINF", "$,", "PIAT", "NN", "PDAT", "NN", "$,"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.10": {"text": "Ohn uns gleichsam zu bewegen, wann und wie es uns gef\u00e4llt.", "tokens": ["Ohn", "uns", "gleich\u00b7sam", "zu", "be\u00b7we\u00b7gen", ",", "wann", "und", "wie", "es", "uns", "ge\u00b7f\u00e4llt", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PPER", "ADJD", "PTKZU", "VVINF", "$,", "PWAV", "KON", "PWAV", "PPER", "PPER", "VVPP", "$."], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.11": {"text": "Die Gedancken mahlen wir; diese Schrift wird weggesandt,", "tokens": ["Die", "Ge\u00b7dan\u00b7cken", "mah\u00b7len", "wir", ";", "die\u00b7se", "Schrift", "wird", "weg\u00b7ge\u00b7sandt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "$.", "PDAT", "NN", "VAFIN", "VVPP", "$,"], "meter": "--+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.12": {"text": "Und durch so viel tausend Menschen dringet sie, macht un-", "tokens": ["Und", "durch", "so", "viel", "tau\u00b7send", "Men\u00b7schen", "drin\u00b7get", "sie", ",", "macht", "un"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "APPR", "ADV", "ADV", "CARD", "NN", "VVFIN", "PPER", "$,", "VVFIN", "TRUNC"], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.13": {"text": "Auf viel tausend Meilen kund, um denselben zu erf\u00fcllen;", "tokens": ["Auf", "viel", "tau\u00b7send", "Mei\u00b7len", "kund", ",", "um", "den\u00b7sel\u00b7ben", "zu", "er\u00b7f\u00fcl\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "CARD", "NN", "PTKVZ", "$,", "KOUI", "PDS", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+--+-+-+-", "measure": "trochaic.septa.relaxed"}, "line.14": {"text": "Ja man machet durch den Druck ihn der gantzen Welt", "tokens": ["Ja", "man", "ma\u00b7chet", "durch", "den", "Druck", "ihn", "der", "gant\u00b7zen", "Welt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "PIS", "VVFIN", "APPR", "ART", "NN", "PPER", "ART", "ADJA", "NN"], "meter": "+-+-+-+--+-+", "measure": "trochaic.hexa.relaxed"}, "line.15": {"text": "L\u00e4\u00dft ihn gar, nach unserm Tod\u2019, auch die sp\u00e4tste Nach-", "tokens": ["L\u00e4\u00dft", "ihn", "gar", ",", "nach", "un\u00b7serm", "Tod'", ",", "auch", "die", "sp\u00e4ts\u00b7te", "Nach"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "$,", "APPR", "PPOSAT", "NN", "$,", "ADV", "ART", "ADJA", "TRUNC"], "meter": "+-+-+-+--+-+", "measure": "trochaic.hexa.relaxed"}, "line.16": {"text": "Mehr als tausend Jahr hinaus, so da\u00df wir bekennen m\u00fcssen:", "tokens": ["Mehr", "als", "tau\u00b7send", "Jahr", "hin\u00b7aus", ",", "so", "da\u00df", "wir", "be\u00b7ken\u00b7nen", "m\u00fcs\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "KOKOM", "CARD", "NN", "APZR", "$,", "ADV", "KOUS", "PPER", "VVINF", "VMINF", "$."], "meter": "+-+-+-+--+-+-+-", "measure": "trochaic.septa.relaxed"}, "line.17": {"text": "Alle Wunder der Vernunft haben weder Ziel noch Ende!", "tokens": ["Al\u00b7le", "Wun\u00b7der", "der", "Ver\u00b7nunft", "ha\u00b7ben", "we\u00b7der", "Ziel", "noch", "En\u00b7de", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "ART", "NN", "VAFIN", "KON", "NN", "ADV", "NN", "$."], "meter": "+-+---+--+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.18": {"text": "Sie versch\u00f6nert, sie verbessert, und bereichert alle St\u00e4nde;", "tokens": ["Sie", "ver\u00b7sch\u00f6\u00b7nert", ",", "sie", "ver\u00b7bes\u00b7sert", ",", "und", "be\u00b7rei\u00b7chert", "al\u00b7le", "St\u00e4n\u00b7de", ";"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VVPP", "$,", "KON", "VVFIN", "PIAT", "NN", "$."], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.19": {"text": "Sie ist in der K\u00fcnstler Fingern minder nicht bewunderns", "tokens": ["Sie", "ist", "in", "der", "K\u00fcnst\u00b7ler", "Fin\u00b7gern", "min\u00b7der", "nicht", "be\u00b7wun\u00b7derns"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "APPR", "ART", "NN", "NN", "ADV", "PTKNEG", "ADJA"], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.20": {"text": "Als in der Gelehrten Schriften, worinn sie uns eine Quelle,", "tokens": ["Als", "in", "der", "Ge\u00b7lehr\u00b7ten", "Schrif\u00b7ten", ",", "wo\u00b7rinn", "sie", "uns", "ei\u00b7ne", "Quel\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "ART", "NN", "NN", "$,", "PWAV", "PPER", "PRF", "ART", "NN", "$,"], "meter": "-+--+-+-+---+-+-", "measure": "iambic.hexa.relaxed"}}, "stanza.10": {"line.1": {"text": "Die nicht zu ersch\u00f6pfen ist, von Belehrung, Trost, Vergn\u00fcgen,", "tokens": ["Die", "nicht", "zu", "er\u00b7sch\u00f6p\u00b7fen", "ist", ",", "von", "Be\u00b7leh\u00b7rung", ",", "Trost", ",", "Ver\u00b7gn\u00fc\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ART", "PTKNEG", "PTKZU", "VVINF", "VAFIN", "$,", "APPR", "NN", "$,", "NN", "$,", "NN", "$,"], "meter": "-+--+--+-+-+-+-", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Besserung und H\u00fclfe wird; ja sie wei\u00df annoch zu f\u00fcgen,", "tokens": ["Bes\u00b7se\u00b7rung", "und", "H\u00fcl\u00b7fe", "wird", ";", "ja", "sie", "wei\u00df", "an\u00b7noch", "zu", "f\u00fc\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VAFIN", "$.", "ADV", "PPER", "VVFIN", "ADV", "PTKZU", "VVINF", "$,"], "meter": "+---+--+-+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.3": {"text": "In so vielen Wirckungen, Nutzen und Vortreflichkeit,", "tokens": ["In", "so", "vie\u00b7len", "Wir\u00b7ckun\u00b7gen", ",", "Nut\u00b7zen", "und", "Vor\u00b7tre\u00b7flich\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "PIAT", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "+-+--+-+--+--+", "measure": "trochaic.hexa.relaxed"}, "line.4": {"text": "Einen Vorzug der annoch gr\u00f6ssere Vollkommenheit", "tokens": ["Ei\u00b7nen", "Vor\u00b7zug", "der", "an\u00b7noch", "gr\u00f6s\u00b7se\u00b7re", "Voll\u00b7kom\u00b7men\u00b7heit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "ADV", "ADJA", "NN"], "meter": "+-+--+-+-+-+-+", "measure": "trochaic.septa.relaxed"}, "line.5": {"text": "Jhres edlen Wesens weiset, den wir Augen-f\u00e4llig mercken", "tokens": ["Ih\u00b7res", "ed\u00b7len", "We\u00b7sens", "wei\u00b7set", ",", "den", "wir", "Au\u00b7gen\u00b7f\u00e4l\u00b7lig", "mer\u00b7cken"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN", "VVFIN", "$,", "PRELS", "PPER", "ADJD", "VVINF"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.6": {"text": "Und zu Tage legen k\u00f6nnen, sie ist von des Sch\u00f6pfers Wercken", "tokens": ["Und", "zu", "Ta\u00b7ge", "le\u00b7gen", "k\u00f6n\u00b7nen", ",", "sie", "ist", "von", "des", "Sch\u00f6p\u00b7fers", "Wer\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "NN", "VVINF", "VMINF", "$,", "PPER", "VAFIN", "APPR", "ART", "NN", "NN"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.7": {"text": "Recht der Mittel-Punct auf Erden; recht der Endzweck", "tokens": ["Recht", "der", "Mit\u00b7tel\u00b7Punct", "auf", "Er\u00b7den", ";", "recht", "der", "End\u00b7zweck"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "ART", "NN", "APPR", "NN", "$.", "ADV", "ART", "NN"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.8": {"text": "Ja sie macht von ihnen allen gleichsam recht die Harmonie.", "tokens": ["Ja", "sie", "macht", "von", "ih\u00b7nen", "al\u00b7len", "gleich\u00b7sam", "recht", "die", "Har\u00b7mo\u00b7nie", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "PPER", "VVFIN", "APPR", "PPER", "PIAT", "ADJD", "ADJD", "ART", "NN", "$."], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}}, "stanza.11": {"line.1": {"text": "La\u00dft uns einen Augenblick die Vernunft vom Erd-", "tokens": ["La\u00dft", "uns", "ei\u00b7nen", "Au\u00b7gen\u00b7blick", "die", "Ver\u00b7nunft", "vom", "Erd"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVIMP", "PPER", "ART", "NN", "ART", "NN", "APPRART", "NN"], "meter": "--+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "La\u00dft uns dencken, da\u00df kein Mensch sich auf Erden mehr", "tokens": ["La\u00dft", "uns", "den\u00b7cken", ",", "da\u00df", "kein", "Mensch", "sich", "auf", "Er\u00b7den", "mehr"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVIMP", "PPER", "VVINF", "$,", "KOUS", "PIAT", "NN", "PRF", "APPR", "NN", "ADV"], "meter": "+-+-+-+--+-+", "measure": "trochaic.hexa.relaxed"}, "line.3": {"text": "Alsobald ist alles weg, was des Sch\u00f6pfers Werck verbindet,", "tokens": ["Al\u00b7so\u00b7bald", "ist", "al\u00b7les", "weg", ",", "was", "des", "Sch\u00f6p\u00b7fers", "Werck", "ver\u00b7bin\u00b7det", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIS", "PTKVZ", "$,", "PRELS", "ART", "NN", "NN", "VVFIN", "$,"], "meter": "+-+-+-+--+-+-+-", "measure": "trochaic.septa.relaxed"}, "line.4": {"text": "Alsobald wird alle Ordnung fort, ein Jrrthum allgemein,", "tokens": ["Al\u00b7so\u00b7bald", "wird", "al\u00b7le", "Ord\u00b7nung", "fort", ",", "ein", "Jrr\u00b7thum", "all\u00b7ge\u00b7mein", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIAT", "NN", "PTKVZ", "$,", "ART", "NN", "ADJD", "$,"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.5": {"text": "Schmutz und Unrath allenthalben, \u00fcberall Verwirrung seyn.", "tokens": ["Schmutz", "und", "Un\u00b7rath", "al\u00b7len\u00b7thal\u00b7ben", ",", "\u00fc\u00b7be\u00b7rall", "Ver\u00b7wir\u00b7rung", "seyn", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "ADV", "$,", "ADV", "NN", "VAINF", "$."], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.6": {"text": "Von dem hellen Sonnen-Licht w\u00fcrde zwar der Kreis der", "tokens": ["Von", "dem", "hel\u00b7len", "Son\u00b7nen\u00b7Licht", "w\u00fcr\u00b7de", "zwar", "der", "Kreis", "der"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "VAFIN", "ADV", "ART", "NN", "ART"], "meter": "+-+-+-+--+-+-", "measure": "trochaic.hexa.relaxed"}, "line.7": {"text": "Angestrahlet und gef\u00e4rbt, lieblich, sch\u00f6n, und pr\u00e4chtig", "tokens": ["An\u00b7ge\u00b7strah\u00b7let", "und", "ge\u00b7f\u00e4rbt", ",", "lieb\u00b7lich", ",", "sch\u00f6n", ",", "und", "pr\u00e4ch\u00b7tig"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word"], "pos": ["NE", "KON", "VVPP", "$,", "ADJD", "$,", "ADJD", "$,", "KON", "ADJD"], "meter": "+-+-+-+--+-+-", "measure": "trochaic.hexa.relaxed"}, "line.8": {"text": "Doch die Erde, welche blind, braucht vom hellen Glantz", "tokens": ["Doch", "die", "Er\u00b7de", ",", "wel\u00b7che", "blind", ",", "braucht", "vom", "hel\u00b7len", "Glantz"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "$,", "PRELS", "ADJD", "$,", "VVFIN", "APPRART", "ADJA", "NN"], "meter": "+-+-+--+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.9": {"text": "Und von aller ihrer Sch\u00f6nheit, Farben, Pracht und", "tokens": ["Und", "von", "al\u00b7ler", "ih\u00b7rer", "Sch\u00f6n\u00b7heit", ",", "Far\u00b7ben", ",", "Pracht", "und"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["KON", "APPR", "PIAT", "PPOSAT", "NN", "$,", "NN", "$,", "NN", "KON"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.10": {"text": "Durch die W\u00e4rme, Thau und Regen, w\u00fcrden zwar die", "tokens": ["Durch", "die", "W\u00e4r\u00b7me", ",", "Thau", "und", "Re\u00b7gen", ",", "w\u00fcr\u00b7den", "zwar", "die"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "$,", "NN", "KON", "NN", "$,", "VAFIN", "ADV", "ART"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.11": {"text": "Und das Feld mit Gras bedecken auch verschiedne Fr\u00fccht\u2019", "tokens": ["Und", "das", "Feld", "mit", "Gras", "be\u00b7de\u00b7cken", "auch", "ver\u00b7schied\u00b7ne", "Fr\u00fccht'"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "APPR", "NN", "VVFIN", "ADV", "ADJA", "NN"], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}, "line.12": {"text": "Doch es sind verlohrne Sch\u00e4tze. Keinem wird es Nutzen", "tokens": ["Doch", "es", "sind", "ver\u00b7lohr\u00b7ne", "Sch\u00e4t\u00b7ze", ".", "Kei\u00b7nem", "wird", "es", "Nut\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VAFIN", "ADJA", "NN", "$.", "PIS", "VAFIN", "PPER", "NN"], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}}, "stanza.12": {"line.1": {"text": "Niemand um sie einzusammlen, zu verzehren, aufzur\u00e4umen,", "tokens": ["Nie\u00b7mand", "um", "sie", "ein\u00b7zu\u00b7samm\u00b7len", ",", "zu", "ver\u00b7zeh\u00b7ren", ",", "auf\u00b7zu\u00b7r\u00e4u\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["PIS", "APPR", "PPER", "VVIZU", "$,", "PTKZU", "VVINF", "$,", "VVIZU", "$,"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.2": {"text": "Und das Unkraut zu vertilgen w\u00e4re da. Die Erde w\u00fcrde,", "tokens": ["Und", "das", "Un\u00b7kraut", "zu", "ver\u00b7til\u00b7gen", "w\u00e4\u00b7re", "da", ".", "Die", "Er\u00b7de", "w\u00fcr\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "PTKZU", "VVINF", "VAFIN", "ADV", "$.", "ART", "NN", "VAFIN", "$,"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.3": {"text": "Wie man es nicht leugnen kann, zwar verschiedne Thiere", "tokens": ["Wie", "man", "es", "nicht", "leug\u00b7nen", "kann", ",", "zwar", "ver\u00b7schied\u00b7ne", "Thie\u00b7re"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWAV", "PIS", "PPER", "PTKNEG", "VVINF", "VMFIN", "$,", "ADV", "ADJA", "NN"], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Aber diese niemand nutzen, keinem einen Dienst gew\u00e4hren.", "tokens": ["A\u00b7ber", "die\u00b7se", "nie\u00b7mand", "nut\u00b7zen", ",", "kei\u00b7nem", "ei\u00b7nen", "Dienst", "ge\u00b7w\u00e4h\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "PIS", "VVINF", "$,", "PIS", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.5": {"text": "Nicht geschohrne Schaafe w\u00fcrden der beschmutzten Wolle", "tokens": ["Nicht", "ge\u00b7schohr\u00b7ne", "Schaa\u00b7fe", "w\u00fcr\u00b7den", "der", "be\u00b7schmutz\u00b7ten", "Wol\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PTKNEG", "ADJA", "NN", "VAFIN", "ART", "ADJA", "NN"], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}, "line.6": {"text": "K\u00fcmmerlich nur tragen k\u00f6nnen. Ja es w\u00fcrden K\u00fch\u2019 und", "tokens": ["K\u00fcm\u00b7mer\u00b7lich", "nur", "tra\u00b7gen", "k\u00f6n\u00b7nen", ".", "Ja", "es", "w\u00fcr\u00b7den", "K\u00fch'", "und"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADJD", "ADV", "VVINF", "VMINF", "$.", "PTKANT", "PPER", "VAFIN", "NN", "KON"], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}, "line.7": {"text": "Von zu vieler Milch beschwert, kranck und ungemolcken", "tokens": ["Von", "zu", "vie\u00b7ler", "Milch", "be\u00b7schwert", ",", "kranck", "und", "un\u00b7ge\u00b7mol\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "APPR", "PIAT", "NN", "VVPP", "$,", "ADJD", "KON", "NN"], "meter": "+-+-+-+--+-+-", "measure": "trochaic.hexa.relaxed"}, "line.8": {"text": "Nichts als lauter Wiederspruch w\u00fcrd\u2019 an allen Orten seyn.", "tokens": ["Nichts", "als", "lau\u00b7ter", "Wie\u00b7der\u00b7spruch", "w\u00fcrd'", "an", "al\u00b7len", "Or\u00b7ten", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "KOKOM", "PIAT", "NN", "VAFIN", "APPR", "PIAT", "NN", "VAINF", "$."], "meter": "+-+-+-+-+--+-+", "measure": "trochaic.septa.relaxed"}, "line.9": {"text": "Steine, die zum Bauen t\u00fcchtig, schlie\u00dft der Schoo\u00df der Er-", "tokens": ["Stei\u00b7ne", ",", "die", "zum", "Bau\u00b7en", "t\u00fcch\u00b7tig", ",", "schlie\u00dft", "der", "Schoo\u00df", "der", "Er"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "PRELS", "APPRART", "NN", "ADJD", "$,", "VVFIN", "ART", "NN", "ART", "TRUNC"], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}, "line.10": {"text": "Nebst den k\u00f6stlichsten Metallen; doch Bewohner fehlen ihr,", "tokens": ["Nebst", "den", "k\u00f6st\u00b7lichs\u00b7ten", "Me\u00b7tal\u00b7len", ";", "doch", "Be\u00b7woh\u00b7ner", "feh\u00b7len", "ihr", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$.", "ADV", "NN", "VVFIN", "PPER", "$,"], "meter": "+-+---+-+-+-+-+", "measure": "unknown.measure.septa"}, "line.11": {"text": "Ja so wol als kluge K\u00fcnstler, welche sonst aus tausend", "tokens": ["Ja", "so", "wol", "als", "klu\u00b7ge", "K\u00fcnst\u00b7ler", ",", "wel\u00b7che", "sonst", "aus", "tau\u00b7send"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PTKANT", "ADV", "ADV", "KOUS", "ADJA", "NN", "$,", "PRELS", "ADV", "APPR", "CARD"], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}, "line.12": {"text": "Tausendfache Sch\u00e4tzbarkeiten, zur Beqvemlichkeit, zur Zier,", "tokens": ["Tau\u00b7send\u00b7fa\u00b7che", "Sch\u00e4tz\u00b7bar\u00b7kei\u00b7ten", ",", "zur", "Be\u00b7qvem\u00b7lich\u00b7keit", ",", "zur", "Zier", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "APPRART", "NN", "$,", "APPRART", "NN", "$,"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.13": {"text": "So zum Nutzen, als Ergetzen, zu formiren und zu machen", "tokens": ["So", "zum", "Nut\u00b7zen", ",", "als", "Er\u00b7get\u00b7zen", ",", "zu", "for\u00b7mi\u00b7ren", "und", "zu", "ma\u00b7chen"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "APPRART", "NN", "$,", "KOUS", "NN", "$,", "PTKZU", "VVINF", "KON", "PTKZU", "VVINF"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.14": {"text": "Tauglich und geschicklich sind. Es ist ihre Fl\u00e4ch\u2019 ein Garten,", "tokens": ["Taug\u00b7lich", "und", "ge\u00b7schick\u00b7lich", "sind", ".", "Es", "ist", "ih\u00b7re", "Fl\u00e4ch'", "ein", "Gar\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "KON", "ADJD", "VAFIN", "$.", "PPER", "VAFIN", "PPOSAT", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+-+--+-+-", "measure": "trochaic.septa.relaxed"}, "line.15": {"text": "Angef\u00fcllt von Pracht und Sch\u00f6nheit von fast ungezehlten", "tokens": ["An\u00b7ge\u00b7f\u00fcllt", "von", "Pracht", "und", "Sch\u00f6n\u00b7heit", "von", "fast", "un\u00b7ge\u00b7zehl\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVPP", "APPR", "NN", "KON", "NN", "APPR", "ADV", "ADJA"], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}, "line.16": {"text": "Aber er ist nicht zu sehn. Die Natur in ihrer Pracht", "tokens": ["A\u00b7ber", "er", "ist", "nicht", "zu", "sehn", ".", "Die", "Na\u00b7tur", "in", "ih\u00b7rer", "Pracht"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VAFIN", "PTKNEG", "PTKZU", "VVINF", "$.", "ART", "NN", "APPR", "PPOSAT", "NN"], "meter": "+--+--+--+-+-+", "measure": "dactylic.tri.plus"}, "line.17": {"text": "Ist ein wundersch\u00f6ner Schau-Platz; wovon aber keine Spur", "tokens": ["Ist", "ein", "wun\u00b7der\u00b7sch\u00f6\u00b7ner", "Schau\u00b7Platz", ";", "wo\u00b7von", "a\u00b7ber", "kei\u00b7ne", "Spur"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VAFIN", "ART", "ADJA", "NN", "$.", "PWAV", "ADV", "PIAT", "NN"], "meter": "+-+-+-++--+-+-+", "measure": "trochaic.octa.plus.relaxed"}, "line.18": {"text": "Jemand in die Augen f\u00e4llt. Aber la\u00dft uns der Natur", "tokens": ["Je\u00b7mand", "in", "die", "Au\u00b7gen", "f\u00e4llt", ".", "A\u00b7ber", "la\u00dft", "uns", "der", "Na\u00b7tur"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PIS", "APPR", "ART", "NN", "VVFIN", "$.", "KON", "VVIMP", "PPER", "ART", "NN"], "meter": "+-+-+-+--+-+-+", "measure": "trochaic.septa.relaxed"}, "line.19": {"text": "Nur den Menschen wiedergeben! la\u00dft nur die Vernunft", "tokens": ["Nur", "den", "Men\u00b7schen", "wie\u00b7der\u00b7ge\u00b7ben", "!", "la\u00dft", "nur", "die", "Ver\u00b7nunft"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "VVINF", "$.", "VVIMP", "ADV", "ART", "NN"], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}, "line.20": {"text": "Wieder dargestellet werden!", "tokens": ["Wie\u00b7der", "dar\u00b7ge\u00b7stel\u00b7let", "wer\u00b7den", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "VVPP", "VAINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.21": {"text": "Alsobald wird ein Verband, ein Zusammenhang, Verst\u00e4ndni\u00df", "tokens": ["Al\u00b7so\u00b7bald", "wird", "ein", "Ver\u00b7band", ",", "ein", "Zu\u00b7sam\u00b7men\u00b7hang", ",", "Ver\u00b7st\u00e4nd\u00b7ni\u00df"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word"], "pos": ["ADV", "VAFIN", "ART", "NN", "$,", "ART", "NN", "$,", "NN"], "meter": "+-+-+-+-+--+-+-", "measure": "trochaic.septa.relaxed"}, "line.22": {"text": "Eine Harmonie und Einheit, Lust, Empfindlichkeit,", "tokens": ["Ei\u00b7ne", "Har\u00b7mo\u00b7nie", "und", "Ein\u00b7heit", ",", "Lust", ",", "Emp\u00b7find\u00b7lich\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "$,", "NN", "$,", "NN", "$,"], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}}}}}