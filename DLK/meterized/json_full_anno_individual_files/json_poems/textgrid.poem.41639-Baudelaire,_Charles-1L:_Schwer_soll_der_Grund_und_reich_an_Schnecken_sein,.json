{"textgrid.poem.41639": {"metadata": {"author": {"name": "Baudelaire, Charles", "birth": "N.A.", "death": "N.A."}, "title": "1L: Schwer soll der Grund und reich an Schnecken sein,", "genre": "verse", "period": "N.A.", "pub_year": 1844, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Schwer soll der Grund und reich an Schnecken sein,", "tokens": ["Schwer", "soll", "der", "Grund", "und", "reich", "an", "Schne\u00b7cken", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VMFIN", "ART", "NN", "KON", "ADJD", "APPR", "NN", "VAINF", "$,"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.2": {"text": "Wo meine Gruft zu schaufeln ich begehre,", "tokens": ["Wo", "mei\u00b7ne", "Gruft", "zu", "schau\u00b7feln", "ich", "be\u00b7geh\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "NN", "PTKZU", "VVFIN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Da\u00df dort zum Schlaf sich streckt mein alterndes Gebein", "tokens": ["Da\u00df", "dort", "zum", "Schlaf", "sich", "streckt", "mein", "al\u00b7tern\u00b7des", "Ge\u00b7bein"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "APPRART", "NN", "PRF", "VVFIN", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und im Vergessen ruht gleich wie der Hai im Meere.", "tokens": ["Und", "im", "Ver\u00b7ges\u00b7sen", "ruht", "gleich", "wie", "der", "Hai", "im", "Mee\u00b7re", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "NN", "VVFIN", "ADV", "KOKOM", "ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Ich hasse Testamente, Grab und Stein,", "tokens": ["Ich", "has\u00b7se", "Tes\u00b7ta\u00b7men\u00b7te", ",", "Grab", "und", "Stein", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Und von der Welt erbettl ich keine Z\u00e4hre;", "tokens": ["Und", "von", "der", "Welt", "er\u00b7bettl", "ich", "kei\u00b7ne", "Z\u00e4h\u00b7re", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVFIN", "PPER", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Nein, lieber l\u00fcde ich den Schwarm der Raben ein,", "tokens": ["Nein", ",", "lie\u00b7ber", "l\u00fc\u00b7de", "ich", "den", "Schwarm", "der", "Ra\u00b7ben", "ein", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "ADV", "VVFIN", "PPER", "ART", "NN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Damit er st\u00fcckweis mein verwesend Aas verzehre.", "tokens": ["Da\u00b7mit", "er", "st\u00fcck\u00b7weis", "mein", "ver\u00b7we\u00b7send", "Aas", "ver\u00b7zeh\u00b7re", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "PPOSAT", "VVPP", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "O W\u00fcrmer! Schwarz Geleit ohn Auge, ohne Ohr!", "tokens": ["O", "W\u00fcr\u00b7mer", "!", "Schwarz", "Ge\u00b7leit", "ohn", "Au\u00b7ge", ",", "oh\u00b7ne", "Ohr", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "NN", "$.", "NE", "NN", "APPR", "NN", "$,", "KOUI", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ein Abgeschiedner kommt, der froh den Tod erkor.", "tokens": ["Ein", "Ab\u00b7ge\u00b7schied\u00b7ner", "kommt", ",", "der", "froh", "den", "Tod", "er\u00b7kor", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "PRELS", "ADJD", "ART", "NN", "NE", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ihr S\u00f6hne des Zerfalls, die dem Genusse leben,", "tokens": ["Ihr", "S\u00f6h\u00b7ne", "des", "Zer\u00b7falls", ",", "die", "dem", "Ge\u00b7nus\u00b7se", "le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ART", "NN", "$,", "PRELS", "ART", "NN", "VVINF", "$,"], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}}, "stanza.4": {"line.1": {"text": "Durch meine Tr\u00fcmmer kriecht mit reuelosem Mut", "tokens": ["Durch", "mei\u00b7ne", "Tr\u00fcm\u00b7mer", "kriecht", "mit", "reu\u00b7e\u00b7lo\u00b7sem", "Mut"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und sagt mir: kann es wohl noch eine Folter geben", "tokens": ["Und", "sagt", "mir", ":", "kann", "es", "wohl", "noch", "ei\u00b7ne", "Fol\u00b7ter", "ge\u00b7ben"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "$.", "VMFIN", "PPER", "ADV", "ADV", "ART", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "F\u00fcr den entseelten Leib, der tot bei Toten ruht?", "tokens": ["F\u00fcr", "den", "ent\u00b7seel\u00b7ten", "Leib", ",", "der", "tot", "bei", "To\u00b7ten", "ruht", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,", "PRELS", "ADJD", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Schwer soll der Grund und reich an Schnecken sein,", "tokens": ["Schwer", "soll", "der", "Grund", "und", "reich", "an", "Schne\u00b7cken", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VMFIN", "ART", "NN", "KON", "ADJD", "APPR", "NN", "VAINF", "$,"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.2": {"text": "Wo meine Gruft zu schaufeln ich begehre,", "tokens": ["Wo", "mei\u00b7ne", "Gruft", "zu", "schau\u00b7feln", "ich", "be\u00b7geh\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "NN", "PTKZU", "VVFIN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Da\u00df dort zum Schlaf sich streckt mein alterndes Gebein", "tokens": ["Da\u00df", "dort", "zum", "Schlaf", "sich", "streckt", "mein", "al\u00b7tern\u00b7des", "Ge\u00b7bein"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "APPRART", "NN", "PRF", "VVFIN", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und im Vergessen ruht gleich wie der Hai im Meere.", "tokens": ["Und", "im", "Ver\u00b7ges\u00b7sen", "ruht", "gleich", "wie", "der", "Hai", "im", "Mee\u00b7re", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "NN", "VVFIN", "ADV", "KOKOM", "ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Ich hasse Testamente, Grab und Stein,", "tokens": ["Ich", "has\u00b7se", "Tes\u00b7ta\u00b7men\u00b7te", ",", "Grab", "und", "Stein", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Und von der Welt erbettl ich keine Z\u00e4hre;", "tokens": ["Und", "von", "der", "Welt", "er\u00b7bettl", "ich", "kei\u00b7ne", "Z\u00e4h\u00b7re", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVFIN", "PPER", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Nein, lieber l\u00fcde ich den Schwarm der Raben ein,", "tokens": ["Nein", ",", "lie\u00b7ber", "l\u00fc\u00b7de", "ich", "den", "Schwarm", "der", "Ra\u00b7ben", "ein", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "ADV", "VVFIN", "PPER", "ART", "NN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Damit er st\u00fcckweis mein verwesend Aas verzehre.", "tokens": ["Da\u00b7mit", "er", "st\u00fcck\u00b7weis", "mein", "ver\u00b7we\u00b7send", "Aas", "ver\u00b7zeh\u00b7re", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "PPOSAT", "VVPP", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "O W\u00fcrmer! Schwarz Geleit ohn Auge, ohne Ohr!", "tokens": ["O", "W\u00fcr\u00b7mer", "!", "Schwarz", "Ge\u00b7leit", "ohn", "Au\u00b7ge", ",", "oh\u00b7ne", "Ohr", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "NN", "$.", "NE", "NN", "APPR", "NN", "$,", "KOUI", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ein Abgeschiedner kommt, der froh den Tod erkor.", "tokens": ["Ein", "Ab\u00b7ge\u00b7schied\u00b7ner", "kommt", ",", "der", "froh", "den", "Tod", "er\u00b7kor", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "PRELS", "ADJD", "ART", "NN", "NE", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ihr S\u00f6hne des Zerfalls, die dem Genusse leben,", "tokens": ["Ihr", "S\u00f6h\u00b7ne", "des", "Zer\u00b7falls", ",", "die", "dem", "Ge\u00b7nus\u00b7se", "le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ART", "NN", "$,", "PRELS", "ART", "NN", "VVINF", "$,"], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}}, "stanza.8": {"line.1": {"text": "Durch meine Tr\u00fcmmer kriecht mit reuelosem Mut", "tokens": ["Durch", "mei\u00b7ne", "Tr\u00fcm\u00b7mer", "kriecht", "mit", "reu\u00b7e\u00b7lo\u00b7sem", "Mut"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und sagt mir: kann es wohl noch eine Folter geben", "tokens": ["Und", "sagt", "mir", ":", "kann", "es", "wohl", "noch", "ei\u00b7ne", "Fol\u00b7ter", "ge\u00b7ben"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "$.", "VMFIN", "PPER", "ADV", "ADV", "ART", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "F\u00fcr den entseelten Leib, der tot bei Toten ruht?", "tokens": ["F\u00fcr", "den", "ent\u00b7seel\u00b7ten", "Leib", ",", "der", "tot", "bei", "To\u00b7ten", "ruht", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,", "PRELS", "ADJD", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}