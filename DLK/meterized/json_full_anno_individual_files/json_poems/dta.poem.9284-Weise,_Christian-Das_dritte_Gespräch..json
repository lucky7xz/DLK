{"dta.poem.9284": {"metadata": {"author": {"name": "Weise, Christian", "birth": "N.A.", "death": "N.A."}, "title": "Das dritte Gespr\u00e4ch.", "genre": "Lyrik; Drama; Prosa", "period": "N.A.", "pub_year": "1701", "urn": "urn:nbn:de:kobv:b4-25043-0", "language": ["de:0.99"], "booktitle": "Weise, Christian: \u00dcberfl\u00fc\u00dfige Gedancken Der gr\u00fcnenden jugend. Leipzig, 1701."}, "poem": {"stanza.1": {"line.1": {"text": "Du sprichst zu mir ich soll nicht thalen", "tokens": ["Du", "sprichst", "zu", "mir", "ich", "soll", "nicht", "tha\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "PPER", "PPER", "VMFIN", "PTKNEG", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wenn ich ein bi\u00dfgen lose bin/", "tokens": ["Wenn", "ich", "ein", "bi\u00df\u00b7gen", "lo\u00b7se", "bin", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "VAFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und sagst zu unterschiednen mahlen", "tokens": ["Und", "sagst", "zu", "un\u00b7ter\u00b7schied\u00b7nen", "mah\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PTKZU", "VVINF", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Er geh doch weg/ er scher sich hin/", "tokens": ["Er", "geh", "doch", "weg", "/", "er", "scher", "sich", "hin", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "$(", "PPER", "ADJD", "PRF", "PTKVZ", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Er lasse sich doch endlich sagen", "tokens": ["Er", "las\u00b7se", "sich", "doch", "end\u00b7lich", "sa\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PRF", "ADV", "ADV", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Ich kan das thalen nicht vertragen.", "tokens": ["Ich", "kan", "das", "tha\u00b7len", "nicht", "ver\u00b7tra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PDS", "VVFIN", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "2. Du n\u00e4rrgen la\u00df mich immer thalen/", "tokens": ["Du", "n\u00e4rr\u00b7gen", "la\u00df", "mich", "im\u00b7mer", "tha\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "VVIMP", "PPER", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die thaler sind das beste geld/", "tokens": ["Die", "tha\u00b7ler", "sind", "das", "bes\u00b7te", "geld", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und welche wol damit bezahlen/", "tokens": ["Und", "wel\u00b7che", "wol", "da\u00b7mit", "be\u00b7zah\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRELS", "ADV", "PAV", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die hat man lieb in aller welt/", "tokens": ["Die", "hat", "man", "lieb", "in", "al\u00b7ler", "welt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PIS", "ADJD", "APPR", "PIAT", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Derhalben wirstu gleicher massen", "tokens": ["Der\u00b7hal\u00b7ben", "wirs\u00b7tu", "glei\u00b7cher", "mas\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["PAV", "VAFIN", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Bey dir die m\u00fcntze gelten lassen.", "tokens": ["Bey", "dir", "die", "m\u00fcnt\u00b7ze", "gel\u00b7ten", "las\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ART", "ADJA", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "3. Ein thaler ist ein sch\u00f6nes st\u00fccke", "tokens": ["Ein", "tha\u00b7ler", "ist", "ein", "sch\u00f6\u00b7nes", "st\u00fc\u00b7cke"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "VAFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Das man zu ehren brauchen mag/", "tokens": ["Das", "man", "zu", "eh\u00b7ren", "brau\u00b7chen", "mag", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PIS", "PTKZU", "VVINF", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Er ist von klaren silber dicke/", "tokens": ["Er", "ist", "von", "kla\u00b7ren", "sil\u00b7ber", "di\u00b7cke", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und f\u00fchrt den allerbesten schlag.", "tokens": ["Und", "f\u00fchrt", "den", "al\u00b7ler\u00b7bes\u00b7ten", "schlag", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "De\u00dfwegen mu\u00df ich mich befleissen", "tokens": ["De\u00df\u00b7we\u00b7gen", "mu\u00df", "ich", "mich", "be\u00b7fleis\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PAV", "VMFIN", "PPER", "PRF", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Damit ich kan ein thaler heissen.", "tokens": ["Da\u00b7mit", "ich", "kan", "ein", "tha\u00b7ler", "heis\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VMFIN", "ART", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "4. Was nutzt mir doch ein kahler dreyer/", "tokens": ["Was", "nutzt", "mir", "doch", "ein", "kah\u00b7ler", "drey\u00b7er", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "ART", "ADJA", "ADJA", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Der nicht einmahl die farbe h\u00e4lt?", "tokens": ["Der", "nicht", "ein\u00b7mahl", "die", "far\u00b7be", "h\u00e4lt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PTKNEG", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Was taug ein vierling und ein zweyer?", "tokens": ["Was", "taug", "ein", "vier\u00b7ling", "und", "ein", "zwey\u00b7er", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ART", "NN", "KON", "ART", "ADJA", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Es ist ein blosses huren-geld:", "tokens": ["Es", "ist", "ein", "blos\u00b7ses", "hu\u00b7ren\u00b7geld", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Vom schweren kupfergeld aus Schweden", "tokens": ["Vom", "schwe\u00b7ren", "kup\u00b7fer\u00b7geld", "aus", "Schwe\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPRART", "ADJA", "NN", "APPR", "NE"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Begehr ich nicht einmahl zu reden.", "tokens": ["Be\u00b7gehr", "ich", "nicht", "ein\u00b7mahl", "zu", "re\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PTKNEG", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "5. Hingegen la\u00df die thaler kommen/", "tokens": ["Hin\u00b7ge\u00b7gen", "la\u00df", "die", "tha\u00b7ler", "kom\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVIMP", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die finden allzeit ihren platz/", "tokens": ["Die", "fin\u00b7den", "all\u00b7zeit", "ih\u00b7ren", "platz", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und wenn sie werden eingenommen/", "tokens": ["Und", "wenn", "sie", "wer\u00b7den", "ein\u00b7ge\u00b7nom\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Legt man sie heimlich in den schatz/", "tokens": ["Legt", "man", "sie", "heim\u00b7lich", "in", "den", "schatz", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PPER", "ADJD", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Da\u00df nicht die leute wie sie wollen", "tokens": ["Da\u00df", "nicht", "die", "leu\u00b7te", "wie", "sie", "wol\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PTKNEG", "ART", "NN", "KOKOM", "PPER", "VMFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Das sch\u00f6ne geld begreiffen sollen.", "tokens": ["Das", "sch\u00f6\u00b7ne", "geld", "be\u00b7greif\u00b7fen", "sol\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "6. Ich bin kein ungewisser praler.", "tokens": ["Ich", "bin", "kein", "un\u00b7ge\u00b7wis\u00b7ser", "pra\u00b7ler", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Nimm mich zu deinem thaler an/", "tokens": ["Nimm", "mich", "zu", "dei\u00b7nem", "tha\u00b7ler", "an", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "APPR", "PPOSAT", "NN", "PTKVZ", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wer wei\u00df wo ich noch einen thaler", "tokens": ["Wer", "wei\u00df", "wo", "ich", "noch", "ei\u00b7nen", "tha\u00b7ler"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "PWAV", "PPER", "ADV", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Bey dir zuwege bringen kan/", "tokens": ["Bey", "dir", "zu\u00b7we\u00b7ge", "brin\u00b7gen", "kan", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ADV", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Alsdenn so hastu gut gel\u00fccke", "tokens": ["Als\u00b7denn", "so", "has\u00b7tu", "gut", "ge\u00b7l\u00fc\u00b7cke"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "VAFIN", "ADJD", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Und den ducaten in der sicke.", "tokens": ["Und", "den", "du\u00b7ca\u00b7ten", "in", "der", "si\u00b7cke", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}