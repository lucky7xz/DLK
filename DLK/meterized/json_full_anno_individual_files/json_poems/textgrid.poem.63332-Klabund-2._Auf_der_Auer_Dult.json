{"textgrid.poem.63332": {"metadata": {"author": {"name": "Klabund", "birth": "N.A.", "death": "N.A."}, "title": "2. Auf der Auer Dult", "genre": "verse", "period": "N.A.", "pub_year": 1909, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Hier ist viel Kram und Tand und Traum geschichtet...", "tokens": ["Hier", "ist", "viel", "Kram", "und", "Tand", "und", "Traum", "ge\u00b7schich\u00b7tet", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIAT", "NN", "KON", "NN", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ein alter Stich, von Staub und Rost befleckt:", "tokens": ["Ein", "al\u00b7ter", "Stich", ",", "von", "Staub", "und", "Rost", "be\u00b7fleckt", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "APPR", "NN", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Prometheus, wie er seine Fackel reckt,", "tokens": ["Pro\u00b7me\u00b7theus", ",", "wie", "er", "sei\u00b7ne", "Fa\u00b7ckel", "reckt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PWAV", "PPER", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Hier Dante, wie er die Comedia dichtet.", "tokens": ["Hier", "Dan\u00b7te", ",", "wie", "er", "die", "Co\u00b7me\u00b7dia", "dich\u00b7tet", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "PWAV", "PPER", "ART", "NE", "VVFIN", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.2": {"line.1": {"text": "Vor einer S\u00fc\u00dfigkeitenbude schleckt", "tokens": ["Vor", "ei\u00b7ner", "S\u00fc\u00b7\u00dfig\u00b7kei\u00b7ten\u00b7bu\u00b7de", "schleckt"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Ein kleines M\u00e4del f\u00fcr ein Zehnerl S\u00fc\u00dfes.", "tokens": ["Ein", "klei\u00b7nes", "M\u00e4\u00b7del", "f\u00fcr", "ein", "Zeh\u00b7nerl", "S\u00fc\u00b7\u00dfes", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Sie hebt den Kinderblick. O sprich und gr\u00fc\u00df es,", "tokens": ["Sie", "hebt", "den", "Kin\u00b7der\u00b7blick", ".", "O", "sprich", "und", "gr\u00fc\u00df", "es", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$.", "NE", "ADJD", "KON", "VVFIN", "PPER", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Eh' ihre Seele sich mit Rost befleckt...", "tokens": ["Eh'", "ih\u00b7re", "See\u00b7le", "sich", "mit", "Rost", "be\u00b7fleckt", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "PRF", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "La\u00df sie um zwanzig Jahre \u00e4lter sein...", "tokens": ["La\u00df", "sie", "um", "zwan\u00b7zig", "Jah\u00b7re", "\u00e4l\u00b7ter", "sein", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "APPR", "CARD", "NN", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Dann hat hier auf der Dult sie ihren Stand:", "tokens": ["Dann", "hat", "hier", "auf", "der", "Dult", "sie", "ih\u00b7ren", "Stand", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "APPR", "ART", "NN", "PPER", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Feil h\u00e4lt sie ihres Lebens Lug und Tand \u2013", "tokens": ["Feil", "h\u00e4lt", "sie", "ih\u00b7res", "Le\u00b7bens", "Lug", "und", "Tand", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "PPOSAT", "NN", "NE", "KON", "NN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Und es wird eine kleine Welt her sein,", "tokens": ["Und", "es", "wird", "ei\u00b7ne", "klei\u00b7ne", "Welt", "her", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "ART", "ADJA", "NN", "APZR", "VAINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Da\u00df du sie dunkel einst err\u00f6ten machtest,", "tokens": ["Da\u00df", "du", "sie", "dun\u00b7kel", "einst", "er\u00b7r\u00f6\u00b7ten", "mach\u00b7test", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "ADJD", "ADV", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Weil ihrem Kinderl\u00e4cheln du entgegenlachtest...", "tokens": ["Weil", "ih\u00b7rem", "Kin\u00b7der\u00b7l\u00e4\u00b7cheln", "du", "ent\u00b7ge\u00b7gen\u00b7lach\u00b7test", "..."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "PPER", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Hier ist viel Kram und Tand und Traum geschichtet...", "tokens": ["Hier", "ist", "viel", "Kram", "und", "Tand", "und", "Traum", "ge\u00b7schich\u00b7tet", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIAT", "NN", "KON", "NN", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ein alter Stich, von Staub und Rost befleckt:", "tokens": ["Ein", "al\u00b7ter", "Stich", ",", "von", "Staub", "und", "Rost", "be\u00b7fleckt", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "APPR", "NN", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Prometheus, wie er seine Fackel reckt,", "tokens": ["Pro\u00b7me\u00b7theus", ",", "wie", "er", "sei\u00b7ne", "Fa\u00b7ckel", "reckt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PWAV", "PPER", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Hier Dante, wie er die Comedia dichtet.", "tokens": ["Hier", "Dan\u00b7te", ",", "wie", "er", "die", "Co\u00b7me\u00b7dia", "dich\u00b7tet", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "PWAV", "PPER", "ART", "NE", "VVFIN", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.6": {"line.1": {"text": "Vor einer S\u00fc\u00dfigkeitenbude schleckt", "tokens": ["Vor", "ei\u00b7ner", "S\u00fc\u00b7\u00dfig\u00b7kei\u00b7ten\u00b7bu\u00b7de", "schleckt"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Ein kleines M\u00e4del f\u00fcr ein Zehnerl S\u00fc\u00dfes.", "tokens": ["Ein", "klei\u00b7nes", "M\u00e4\u00b7del", "f\u00fcr", "ein", "Zeh\u00b7nerl", "S\u00fc\u00b7\u00dfes", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Sie hebt den Kinderblick. O sprich und gr\u00fc\u00df es,", "tokens": ["Sie", "hebt", "den", "Kin\u00b7der\u00b7blick", ".", "O", "sprich", "und", "gr\u00fc\u00df", "es", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$.", "NE", "ADJD", "KON", "VVFIN", "PPER", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Eh' ihre Seele sich mit Rost befleckt...", "tokens": ["Eh'", "ih\u00b7re", "See\u00b7le", "sich", "mit", "Rost", "be\u00b7fleckt", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "PRF", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.7": {"line.1": {"text": "La\u00df sie um zwanzig Jahre \u00e4lter sein...", "tokens": ["La\u00df", "sie", "um", "zwan\u00b7zig", "Jah\u00b7re", "\u00e4l\u00b7ter", "sein", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "APPR", "CARD", "NN", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Dann hat hier auf der Dult sie ihren Stand:", "tokens": ["Dann", "hat", "hier", "auf", "der", "Dult", "sie", "ih\u00b7ren", "Stand", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "APPR", "ART", "NN", "PPER", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Feil h\u00e4lt sie ihres Lebens Lug und Tand \u2013", "tokens": ["Feil", "h\u00e4lt", "sie", "ih\u00b7res", "Le\u00b7bens", "Lug", "und", "Tand", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "PPOSAT", "NN", "NE", "KON", "NN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.8": {"line.1": {"text": "Und es wird eine kleine Welt her sein,", "tokens": ["Und", "es", "wird", "ei\u00b7ne", "klei\u00b7ne", "Welt", "her", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "ART", "ADJA", "NN", "APZR", "VAINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Da\u00df du sie dunkel einst err\u00f6ten machtest,", "tokens": ["Da\u00df", "du", "sie", "dun\u00b7kel", "einst", "er\u00b7r\u00f6\u00b7ten", "mach\u00b7test", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "ADJD", "ADV", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Weil ihrem Kinderl\u00e4cheln du entgegenlachtest...", "tokens": ["Weil", "ih\u00b7rem", "Kin\u00b7der\u00b7l\u00e4\u00b7cheln", "du", "ent\u00b7ge\u00b7gen\u00b7lach\u00b7test", "..."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "PPER", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}