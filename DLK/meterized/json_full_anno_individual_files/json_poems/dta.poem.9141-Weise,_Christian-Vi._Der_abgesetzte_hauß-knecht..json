{"dta.poem.9141": {"metadata": {"author": {"name": "Weise, Christian", "birth": "N.A.", "death": "N.A."}, "title": "Vi.  \n Der abgesetzte hau\u00df-knecht.", "genre": "Lyrik; Drama; Prosa", "period": "N.A.", "pub_year": "1701", "urn": "urn:nbn:de:kobv:b4-25043-0", "language": ["de:0.99"], "booktitle": "Weise, Christian: \u00dcberfl\u00fc\u00dfige Gedancken Der gr\u00fcnenden jugend. Leipzig, 1701."}, "poem": {"stanza.1": {"line.1": {"text": "Du liebe junge magd/ dein treuer hau\u00dfknecht kommt/", "tokens": ["Du", "lie\u00b7be", "jun\u00b7ge", "magd", "/", "dein", "treu\u00b7er", "hau\u00df\u00b7knecht", "kommt", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJA", "NN", "$(", "PPOSAT", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Indem er hier und da betr\u00fcbten abschied nimmt/", "tokens": ["In\u00b7dem", "er", "hier", "und", "da", "be\u00b7tr\u00fcb\u00b7ten", "ab\u00b7schied", "nimmt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "KON", "ADV", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und giebt dir auch die hand/ wie sauer gehts ihm ein/", "tokens": ["Und", "giebt", "dir", "auch", "die", "hand", "/", "wie", "sau\u00b7er", "gehts", "ihm", "ein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "ART", "NN", "$(", "PWAV", "ADJD", "VVFIN", "PPER", "ART", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Da\u00df er nicht weiter darff dein lieber hau\u00df-knecht seyn.", "tokens": ["Da\u00df", "er", "nicht", "wei\u00b7ter", "darff", "dein", "lie\u00b7ber", "hau\u00df\u00b7knecht", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "ADV", "VMFIN", "PPOSAT", "ADJA", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "2. Ach nim\u0303 die fromme hand/ nim\u0303 sie zu guter letzt/", "tokens": ["Ach", "nim\u0303", "die", "from\u00b7me", "hand", "/", "nim\u0303", "sie", "zu", "gu\u00b7ter", "letzt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "ADV", "ART", "ADJA", "NN", "$(", "VVIMP", "PPER", "APPR", "ADJA", "ADV", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und dencke da\u00df sie dich zwar \u00f6ffters hat ergetzt.", "tokens": ["Und", "den\u00b7cke", "da\u00df", "sie", "dich", "zwar", "\u00f6ff\u00b7ters", "hat", "er\u00b7getzt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "KOUS", "PPER", "PRF", "ADV", "ADV", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wann sie aus schuldigkeit dir einen dienst gethan/", "tokens": ["Wann", "sie", "aus", "schul\u00b7dig\u00b7keit", "dir", "ei\u00b7nen", "dienst", "ge\u00b7than", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "APPR", "NN", "PPER", "ART", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Doch da\u00df sie weiter nicht im dienste bleiben kan.", "tokens": ["Doch", "da\u00df", "sie", "wei\u00b7ter", "nicht", "im", "diens\u00b7te", "blei\u00b7ben", "kan", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "PTKNEG", "APPRART", "ADJA", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "3. Ich sage nur nicht viel/ es geht mir freylich nah/", "tokens": ["Ich", "sa\u00b7ge", "nur", "nicht", "viel", "/", "es", "geht", "mir", "frey\u00b7lich", "nah", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PTKNEG", "ADV", "$(", "PPER", "VVFIN", "PPER", "ADV", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Doch dieses ist gewi\u00df/ ich bliebe gerne da.", "tokens": ["Doch", "die\u00b7ses", "ist", "ge\u00b7wi\u00df", "/", "ich", "blie\u00b7be", "ger\u00b7ne", "da", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VAFIN", "ADV", "$(", "PPER", "VVFIN", "ADV", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Du liebe junge magd/ du kennest meinen sinn/", "tokens": ["Du", "lie\u00b7be", "jun\u00b7ge", "magd", "/", "du", "ken\u00b7nest", "mei\u00b7nen", "sinn", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJA", "NN", "$(", "PPER", "VVFIN", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Du weist da\u00df ich bey dir am allerliebsten bin.", "tokens": ["Du", "weist", "da\u00df", "ich", "bey", "dir", "am", "al\u00b7ler\u00b7liebs\u00b7ten", "bin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KOUS", "PPER", "APPR", "PPER", "APPRART", "ADJA", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "4. Dieweil ich aber nun das ding nicht \u00e4ndern kan/", "tokens": ["Die\u00b7weil", "ich", "a\u00b7ber", "nun", "das", "ding", "nicht", "\u00e4n\u00b7dern", "kan", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "ART", "NN", "PTKNEG", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "So nim doch meinen gru\u00df mit gutem hertzen an/", "tokens": ["So", "nim", "doch", "mei\u00b7nen", "gru\u00df", "mit", "gu\u00b7tem", "hert\u00b7zen", "an", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVIMP", "ADV", "PPOSAT", "NN", "APPR", "ADJA", "NN", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und wisse/ da\u00df du zwar nicht allzugrosse lust/", "tokens": ["Und", "wis\u00b7se", "/", "da\u00df", "du", "zwar", "nicht", "all\u00b7zu\u00b7gros\u00b7se", "lust", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$(", "KOUS", "PPER", "ADV", "PTKNEG", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Jedoch ein frommes kind hinfort entrathen must.", "tokens": ["Je\u00b7doch", "ein", "from\u00b7mes", "kind", "hin\u00b7fort", "ent\u00b7ra\u00b7then", "must", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "ADV", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "5. Hab ich dich ja erz\u00fcrnt durch irgend einen tritt/", "tokens": ["Hab", "ich", "dich", "ja", "er\u00b7z\u00fcrnt", "durch", "ir\u00b7gend", "ei\u00b7nen", "tritt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PRF", "ADV", "VVFIN", "APPR", "ADV", "PIS", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "So gib mir doch den trost auf meine reise mit/", "tokens": ["So", "gib", "mir", "doch", "den", "trost", "auf", "mei\u00b7ne", "rei\u00b7se", "mit", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVIMP", "PPER", "ADV", "ART", "NN", "APPR", "PPOSAT", "NN", "APPR", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und gib mir zu verstehn ohn allen heuchel-schein/", "tokens": ["Und", "gib", "mir", "zu", "ver\u00b7stehn", "ohn", "al\u00b7len", "heu\u00b7chel\u00b7schein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVIMP", "PPER", "PTKZU", "VVINF", "APPR", "PIAT", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Da\u00df aller mi\u00df-verstand nun soll vergessen seyn.", "tokens": ["Da\u00df", "al\u00b7ler", "mi\u00df\u00b7ver\u00b7stand", "nun", "soll", "ver\u00b7ges\u00b7sen", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "NN", "ADV", "VMFIN", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "6. Wiewol ich habe dir f\u00fcrwar kein leid gethan/", "tokens": ["Wie\u00b7wol", "ich", "ha\u00b7be", "dir", "f\u00fcr\u00b7war", "kein", "leid", "ge\u00b7than", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VAFIN", "PPER", "ADV", "PIAT", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Schau nur die gantze zeit in meinem leben an:", "tokens": ["Schau", "nur", "die", "gant\u00b7ze", "zeit", "in", "mei\u00b7nem", "le\u00b7ben", "an", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ART", "ADJA", "NN", "APPR", "PPOSAT", "VVFIN", "PTKVZ", "$."], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.3": {"text": "Hast du was ausgelegt nicht als ich es gemeint/", "tokens": ["Hast", "du", "was", "aus\u00b7ge\u00b7legt", "nicht", "als", "ich", "es", "ge\u00b7meint", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PIS", "VVFIN", "PTKNEG", "KOUS", "PPER", "PPER", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So sey der auslegung und nicht der sache feind.", "tokens": ["So", "sey", "der", "aus\u00b7le\u00b7gung", "und", "nicht", "der", "sa\u00b7che", "feind", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "KON", "PTKNEG", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "7. Ob ich gleich manches mahl sehr ausgelassen bin", "tokens": ["Ob", "ich", "gleich", "man\u00b7ches", "mahl", "sehr", "aus\u00b7ge\u00b7las\u00b7sen", "bin"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "PIS", "ADV", "ADV", "VVPP", "VAFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "So kom\u0303t die fr\u00f6mmigkeit mir doch nicht aus dem sinn;", "tokens": ["So", "kom\u0303t", "die", "fr\u00f6m\u00b7mig\u00b7keit", "mir", "doch", "nicht", "aus", "dem", "sinn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "PPER", "ADV", "PTKNEG", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ich bin so von natur/ ich kan nicht anders thun/", "tokens": ["Ich", "bin", "so", "von", "na\u00b7tur", "/", "ich", "kan", "nicht", "an\u00b7ders", "thun", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "APPR", "NN", "$(", "PPER", "VMFIN", "PTKNEG", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ich kan nicht gar zu lang auff einer stelle ruhn.", "tokens": ["Ich", "kan", "nicht", "gar", "zu", "lang", "auff", "ei\u00b7ner", "stel\u00b7le", "ruhn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PTKNEG", "ADV", "PTKA", "ADJD", "APPR", "ART", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "8. Wer aber mein gem\u00fcth darbey betrachten wil/", "tokens": ["Wer", "a\u00b7ber", "mein", "ge\u00b7m\u00fcth", "dar\u00b7bey", "be\u00b7trach\u00b7ten", "wil", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "PPOSAT", "NN", "PAV", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der findet sicherlich das rechte widerspiel:", "tokens": ["Der", "fin\u00b7det", "si\u00b7cher\u00b7lich", "das", "rech\u00b7te", "wi\u00b7der\u00b7spiel", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PRF", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "So lose manches wort in meinen reden scheint/", "tokens": ["So", "lo\u00b7se", "man\u00b7ches", "wort", "in", "mei\u00b7nen", "re\u00b7den", "scheint", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIAT", "NN", "APPR", "PPOSAT", "VVINF", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So gut und redlich hats mein hertze wohl gemeynt.", "tokens": ["So", "gut", "und", "red\u00b7lich", "hats", "mein", "hert\u00b7ze", "wohl", "ge\u00b7meynt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KON", "ADJD", "VAFIN", "PPOSAT", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "9. Es steht in dieser welt doch aus der massen sch\u00f6n/", "tokens": ["Es", "steht", "in", "die\u00b7ser", "welt", "doch", "aus", "der", "mas\u00b7sen", "sch\u00f6n", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PDAT", "NN", "ADV", "APPR", "ART", "NN", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wann treue seelen recht in stiller freundschafft stehn:", "tokens": ["Wann", "treu\u00b7e", "see\u00b7len", "recht", "in", "stil\u00b7ler", "freund\u00b7schafft", "stehn", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "ADV", "ADJD", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Man ist drum nicht verliebt/ man ist einander gut/", "tokens": ["Man", "ist", "drum", "nicht", "ver\u00b7liebt", "/", "man", "ist", "ein\u00b7an\u00b7der", "gut", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "PAV", "PTKNEG", "VVPP", "$(", "PIS", "VAFIN", "ADV", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Als wie ein guter freund mit seinem freunde thut.", "tokens": ["Als", "wie", "ein", "gu\u00b7ter", "freund", "mit", "sei\u00b7nem", "freun\u00b7de", "thut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOKOM", "ART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.10": {"line.1": {"text": "10. Ich darff nicht mehr so thun/ ich habe so gethan/", "tokens": ["Ich", "darff", "nicht", "mehr", "so", "thun", "/", "ich", "ha\u00b7be", "so", "ge\u00b7than", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PTKNEG", "ADV", "ADV", "VVINF", "$(", "PPER", "VAFIN", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Nimm alles was geschehn im besten auf und an/", "tokens": ["Nimm", "al\u00b7les", "was", "ge\u00b7schehn", "im", "bes\u00b7ten", "auf", "und", "an", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PIS", "PWS", "VVPP", "APPRART", "VVFIN", "PTKVZ", "KON", "APPR", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und g\u00f6nne mir zuletzt ein freundlich angesicht/", "tokens": ["Und", "g\u00f6n\u00b7ne", "mir", "zu\u00b7letzt", "ein", "freund\u00b7lich", "an\u00b7ge\u00b7sicht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "ART", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Doch meine bangigkeit siehst du die helffte nicht.", "tokens": ["Doch", "mei\u00b7ne", "ban\u00b7gig\u00b7keit", "siehst", "du", "die", "helff\u00b7te", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "PPER", "ART", "ADJA", "PTKNEG", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.11": {"line.1": {"text": "11. Hiemit zu guter nacht du liebe junge magd/", "tokens": ["Hie\u00b7mit", "zu", "gu\u00b7ter", "nacht", "du", "lie\u00b7be", "jun\u00b7ge", "magd", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ADJA", "NN", "PPER", "VVFIN", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Was hilfft es wan\u0303 man sich gleich noch so sehr beklagt;", "tokens": ["Was", "hilfft", "es", "wa\u00f1", "man", "sich", "gleich", "noch", "so", "sehr", "be\u00b7klagt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "VVFIN", "PIS", "PRF", "ADV", "ADV", "ADV", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ich mu\u00df doch endlich fort/ kan es nicht jetzt geschehn/", "tokens": ["Ich", "mu\u00df", "doch", "end\u00b7lich", "fort", "/", "kan", "es", "nicht", "jetzt", "ge\u00b7schehn", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "ADV", "PTKVZ", "$(", "VMFIN", "PPER", "PTKNEG", "ADV", "VVPP", "$("], "meter": "-+-+-+---+-+", "measure": "unknown.measure.penta"}, "line.4": {"text": "So kan ich dich vielleicht auff deiner hochzeit sehn.", "tokens": ["So", "kan", "ich", "dich", "viel\u00b7leicht", "auff", "dei\u00b7ner", "hoch\u00b7zeit", "sehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PRF", "ADV", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.12": {"line.1": {"text": "12. Und wa\u00df ich bi\u00df dahin verborgen halten wil", "tokens": ["Und", "wa\u00df", "ich", "bi\u00df", "da\u00b7hin", "ver\u00b7bor\u00b7gen", "hal\u00b7ten", "wil"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "ADV", "PAV", "VVPP", "VVINF", "VMFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Das soll die losung seyn bey deinen hochzeit-spiel/", "tokens": ["Das", "soll", "die", "lo\u00b7sung", "seyn", "bey", "dei\u00b7nen", "hoch\u00b7zeit\u00b7spiel", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "ART", "NN", "VAINF", "APPR", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Judessen lebe wohl und pr\u00fcfe meinen sinn", "tokens": ["Ju\u00b7des\u00b7sen", "le\u00b7be", "wohl", "und", "pr\u00fc\u00b7fe", "mei\u00b7nen", "sinn"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "ADV", "KON", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ob ich nicht bi\u00df daher dein treuer hau\u00dfknecht bin.", "tokens": ["Ob", "ich", "nicht", "bi\u00df", "da\u00b7her", "dein", "treu\u00b7er", "hau\u00df\u00b7knecht", "bin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "ADV", "PAV", "PPOSAT", "ADJA", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}