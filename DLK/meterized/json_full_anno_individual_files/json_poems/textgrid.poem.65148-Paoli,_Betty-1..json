{"textgrid.poem.65148": {"metadata": {"author": {"name": "Paoli, Betty", "birth": "N.A.", "death": "N.A."}, "title": "1.", "genre": "verse", "period": "N.A.", "pub_year": 1854, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "\u00bbprinz Edgar nahet! unser Hort!", "tokens": ["\u00bb", "prinz", "Ed\u00b7gar", "na\u00b7het", "!", "un\u00b7ser", "Hort", "!"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "NE", "NE", "VVFIN", "$.", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Sohn von unserm K\u00f6nigsstamme!\u00ab", "tokens": ["Der", "Sohn", "von", "un\u00b7serm", "K\u00f6\u00b7nigs\u00b7stam\u00b7me", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "APPR", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "So scholl's, und z\u00fcndend trug das Wort", "tokens": ["So", "scholl's", ",", "und", "z\u00fcn\u00b7dend", "trug", "das", "Wort"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "$,", "KON", "ADJD", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Durch's Hochland eine lohe Flamme.", "tokens": ["Durch's", "Hoch\u00b7land", "ei\u00b7ne", "lo\u00b7he", "Flam\u00b7me", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Der \u00e4rmste Knecht, der Bettler schier,", "tokens": ["Der", "\u00e4rms\u00b7te", "Knecht", ",", "der", "Bett\u00b7ler", "schier", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wie die mit Rang und Gut Belehnten,", "tokens": ["Wie", "die", "mit", "Rang", "und", "Gut", "Be\u00b7lehn\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "APPR", "NN", "KON", "ADJD", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Sie scharten sich um das Panier", "tokens": ["Sie", "schar\u00b7ten", "sich", "um", "das", "Pa\u00b7nier"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "ART", "NN"], "meter": "-+---+-+", "measure": "dactylic.init"}, "line.8": {"text": "Des heimgekehrten Pr\u00e4tendenten.", "tokens": ["Des", "heim\u00b7ge\u00b7kehr\u00b7ten", "Pr\u00e4\u00b7ten\u00b7den\u00b7ten", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Nach B\u00fcchs' und Schwert griff jede Hand,", "tokens": ["Nach", "B\u00fcchs'", "und", "Schwert", "griff", "je\u00b7de", "Hand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "KON", "NN", "VVFIN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Aufzuckend gen Hannovers Farben,", "tokens": ["Auf\u00b7zu\u00b7ckend", "gen", "Han\u00b7no\u00b7vers", "Far\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVPP", "APPR", "NE", "NN", "$,"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "Und selig wurden die genannt,", "tokens": ["Und", "se\u00b7lig", "wur\u00b7den", "die", "ge\u00b7nannt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VAFIN", "ART", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die so in heil'gem Kampfe starben.", "tokens": ["Die", "so", "in", "heil'\u00b7gem", "Kamp\u00b7fe", "star\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Sie ", "tokens": ["Sie"], "token_info": ["word"], "pos": ["PPER"], "meter": "+", "measure": "single.up"}, "line.6": {"text": "Trank noch ihr Herz Begeistrungsodem!", "tokens": ["Trank", "noch", "ihr", "Herz", "Be\u00b7geis\u00b7trun\u00b7gso\u00b7dem", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "PPOSAT", "NN", "NN", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.7": {"text": "Sie sahen nicht den Tag der Schmach,", "tokens": ["Sie", "sa\u00b7hen", "nicht", "den", "Tag", "der", "Schmach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Den Ungl\u00fcckstag nicht bei Culloden. \u2013", "tokens": ["Den", "Un\u00b7gl\u00fccks\u00b7tag", "nicht", "bei", "Cul\u00b7lo\u00b7den", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "PTKNEG", "APPR", "NN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Dem Tage folgt ein Dunkel dicht,", "tokens": ["Dem", "Ta\u00b7ge", "folgt", "ein", "Dun\u00b7kel", "dicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das blanke Beile nur durchhellen.", "tokens": ["Das", "blan\u00b7ke", "Bei\u00b7le", "nur", "durch\u00b7hel\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "In Edinburg sitzt ein Gericht", "tokens": ["In", "E\u00b7din\u00b7burg", "sitzt", "ein", "Ge\u00b7richt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "NE", "VVFIN", "ART", "NN"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.4": {"text": "Zum Spruche \u00fcber die Rebellen.", "tokens": ["Zum", "Spru\u00b7che", "\u00fc\u00b7ber", "die", "Re\u00b7bel\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+--+--", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Da ist kein Mann so gro\u00df, so gut,", "tokens": ["Da", "ist", "kein", "Mann", "so", "gro\u00df", ",", "so", "gut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIAT", "NN", "ADV", "ADJD", "$,", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Da\u00df ihn der Ha\u00df zu treffen scheue!", "tokens": ["Da\u00df", "ihn", "der", "Ha\u00df", "zu", "tref\u00b7fen", "scheu\u00b7e", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Es rauchet das Schafott vom Blut", "tokens": ["Es", "rau\u00b7chet", "das", "Scha\u00b7fott", "vom", "Blut"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPRART", "NN"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.8": {"text": "Hochedler M\u00e4rtyrer der Treue.", "tokens": ["Ho\u00b7ched\u00b7ler", "M\u00e4r\u00b7ty\u00b7rer", "der", "Treu\u00b7e", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ART", "NN", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}}, "stanza.4": {"line.1": {"text": "Durch eh'rne Strenge, finstern Zwang", "tokens": ["Durch", "eh'r\u00b7ne", "Stren\u00b7ge", ",", "fins\u00b7tern", "Zwang"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "ADJA", "NN", "$,", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Will st\u00fcrzen man den alten Glauben,", "tokens": ["Will", "st\u00fcr\u00b7zen", "man", "den", "al\u00b7ten", "Glau\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "VVFIN", "PIS", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "In r\u00fccksichtslosem Uebergang", "tokens": ["In", "r\u00fcck\u00b7sichts\u00b7lo\u00b7sem", "Ue\u00b7ber\u00b7gang"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Dem Volk sein eigenst Wesen rauben.", "tokens": ["Dem", "Volk", "sein", "ei\u00b7genst", "We\u00b7sen", "rau\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "ADV", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Da\u00df welk von ", "tokens": ["Da\u00df", "welk", "von"], "token_info": ["word", "word", "word"], "pos": ["KOUS", "ADJD", "APPR"], "meter": "-+-", "measure": "amphibrach.single"}, "line.6": {"text": "Sein Selbst wie dessen \u00e4u\u00dfre Zeichen,", "tokens": ["Sein", "Selbst", "wie", "des\u00b7sen", "\u00e4u\u00df\u00b7re", "Zei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KOKOM", "PDS", "VVFIN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Soll Kaledoniens Recht und Brauch", "tokens": ["Soll", "Ka\u00b7le\u00b7do\u00b7ni\u00b7ens", "Recht", "und", "Brauch"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VMFIN", "NE", "NN", "KON", "NN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Dem englischen Gesetze weichen.", "tokens": ["Dem", "eng\u00b7li\u00b7schen", "Ge\u00b7set\u00b7ze", "wei\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Auch auf des Hochlands S\u00f6hne, die", "tokens": ["Auch", "auf", "des", "Hoch\u00b7lands", "S\u00f6h\u00b7ne", ",", "die"], "token_info": ["word", "word", "word", "word", "word", "punct", "word"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN", "$,", "PRELS"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Im Dienst von Englands Fahne stehen,", "tokens": ["Im", "Dienst", "von", "En\u00b7glands", "Fah\u00b7ne", "ste\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPR", "NE", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Ist man bedacht und l\u00e4\u00dft f\u00fcr sie", "tokens": ["Ist", "man", "be\u00b7dacht", "und", "l\u00e4\u00dft", "f\u00fcr", "sie"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PIS", "VVPP", "KON", "VVFIN", "APPR", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Den folgenden Befehl ergehen:", "tokens": ["Den", "fol\u00b7gen\u00b7den", "Be\u00b7fehl", "er\u00b7ge\u00b7hen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "\u00bbwenn Urlaub ein Soldat begehrt,", "tokens": ["\u00bb", "wenn", "Ur\u00b7laub", "ein", "Sol\u00b7dat", "be\u00b7gehrt", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "NN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Sind ihm drei Tage freizugeben;", "tokens": ["Sind", "ihm", "drei", "Ta\u00b7ge", "frei\u00b7zu\u00b7ge\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "CARD", "NN", "VVINF", "$."], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.7": {"text": "Doch wer dann nicht zur\u00fcckekehrt,", "tokens": ["Doch", "wer", "dann", "nicht", "zu\u00b7r\u00fc\u00b7cke\u00b7kehrt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ADV", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Der b\u00fc\u00dft die Schuld mit seinem Leben!", "tokens": ["Der", "b\u00fc\u00dft", "die", "Schuld", "mit", "sei\u00b7nem", "Le\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ART", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Es droht solch blutiges Geschick", "tokens": ["Es", "droht", "solch", "blu\u00b7ti\u00b7ges", "Ge\u00b7schick"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Nicht blo\u00df dem Fl\u00fcchtling, dem Verr\u00e4ter,", "tokens": ["Nicht", "blo\u00df", "dem", "Fl\u00fccht\u00b7ling", ",", "dem", "Ver\u00b7r\u00e4\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "ART", "NN", "$,", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Nein! Jenem auch, der kehrt zur\u00fcck", "tokens": ["Nein", "!", "Je\u00b7nem", "auch", ",", "der", "kehrt", "zu\u00b7r\u00fcck"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["PTKANT", "$.", "PDAT", "ADV", "$,", "PRELS", "VVFIN", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Um eine Tagesl\u00e4nge sp\u00e4ter.", "tokens": ["Um", "ei\u00b7ne", "Ta\u00b7ges\u00b7l\u00e4n\u00b7ge", "sp\u00e4\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUI", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Wer auch um eine Stunde nur", "tokens": ["Wer", "auch", "um", "ei\u00b7ne", "Stun\u00b7de", "nur"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "ADV", "APPR", "ART", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Die Frist des Urlaubs \u00fcberschreitet,", "tokens": ["Die", "Frist", "des", "Ur\u00b7laubs", "\u00fc\u00b7bersc\u00b7hrei\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Der hat, verletzend seinen Schwur,", "tokens": ["Der", "hat", ",", "ver\u00b7let\u00b7zend", "sei\u00b7nen", "Schwur", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "$,", "VVPP", "VAINF", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Sich selbst den Weg zum Grab bereitet.\u00ab", "tokens": ["Sich", "selbst", "den", "Weg", "zum", "Grab", "be\u00b7rei\u00b7tet", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PRF", "ADV", "ART", "NN", "APPRART", "NN", "VVFIN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "\u00bbprinz Edgar nahet! unser Hort!", "tokens": ["\u00bb", "prinz", "Ed\u00b7gar", "na\u00b7het", "!", "un\u00b7ser", "Hort", "!"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "NE", "NE", "VVFIN", "$.", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Sohn von unserm K\u00f6nigsstamme!\u00ab", "tokens": ["Der", "Sohn", "von", "un\u00b7serm", "K\u00f6\u00b7nigs\u00b7stam\u00b7me", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "APPR", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "So scholl's, und z\u00fcndend trug das Wort", "tokens": ["So", "scholl's", ",", "und", "z\u00fcn\u00b7dend", "trug", "das", "Wort"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "$,", "KON", "ADJD", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Durch's Hochland eine lohe Flamme.", "tokens": ["Durch's", "Hoch\u00b7land", "ei\u00b7ne", "lo\u00b7he", "Flam\u00b7me", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Der \u00e4rmste Knecht, der Bettler schier,", "tokens": ["Der", "\u00e4rms\u00b7te", "Knecht", ",", "der", "Bett\u00b7ler", "schier", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wie die mit Rang und Gut Belehnten,", "tokens": ["Wie", "die", "mit", "Rang", "und", "Gut", "Be\u00b7lehn\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "APPR", "NN", "KON", "ADJD", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Sie scharten sich um das Panier", "tokens": ["Sie", "schar\u00b7ten", "sich", "um", "das", "Pa\u00b7nier"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "ART", "NN"], "meter": "-+---+-+", "measure": "dactylic.init"}, "line.8": {"text": "Des heimgekehrten Pr\u00e4tendenten.", "tokens": ["Des", "heim\u00b7ge\u00b7kehr\u00b7ten", "Pr\u00e4\u00b7ten\u00b7den\u00b7ten", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Nach B\u00fcchs' und Schwert griff jede Hand,", "tokens": ["Nach", "B\u00fcchs'", "und", "Schwert", "griff", "je\u00b7de", "Hand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "KON", "NN", "VVFIN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Aufzuckend gen Hannovers Farben,", "tokens": ["Auf\u00b7zu\u00b7ckend", "gen", "Han\u00b7no\u00b7vers", "Far\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVPP", "APPR", "NE", "NN", "$,"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "Und selig wurden die genannt,", "tokens": ["Und", "se\u00b7lig", "wur\u00b7den", "die", "ge\u00b7nannt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VAFIN", "ART", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die so in heil'gem Kampfe starben.", "tokens": ["Die", "so", "in", "heil'\u00b7gem", "Kamp\u00b7fe", "star\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Sie ", "tokens": ["Sie"], "token_info": ["word"], "pos": ["PPER"], "meter": "+", "measure": "single.up"}, "line.6": {"text": "Trank noch ihr Herz Begeistrungsodem!", "tokens": ["Trank", "noch", "ihr", "Herz", "Be\u00b7geis\u00b7trun\u00b7gso\u00b7dem", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "PPOSAT", "NN", "NN", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.7": {"text": "Sie sahen nicht den Tag der Schmach,", "tokens": ["Sie", "sa\u00b7hen", "nicht", "den", "Tag", "der", "Schmach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Den Ungl\u00fcckstag nicht bei Culloden. \u2013", "tokens": ["Den", "Un\u00b7gl\u00fccks\u00b7tag", "nicht", "bei", "Cul\u00b7lo\u00b7den", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "PTKNEG", "APPR", "NN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Dem Tage folgt ein Dunkel dicht,", "tokens": ["Dem", "Ta\u00b7ge", "folgt", "ein", "Dun\u00b7kel", "dicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das blanke Beile nur durchhellen.", "tokens": ["Das", "blan\u00b7ke", "Bei\u00b7le", "nur", "durch\u00b7hel\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "In Edinburg sitzt ein Gericht", "tokens": ["In", "E\u00b7din\u00b7burg", "sitzt", "ein", "Ge\u00b7richt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "NE", "VVFIN", "ART", "NN"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.4": {"text": "Zum Spruche \u00fcber die Rebellen.", "tokens": ["Zum", "Spru\u00b7che", "\u00fc\u00b7ber", "die", "Re\u00b7bel\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+--+--", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Da ist kein Mann so gro\u00df, so gut,", "tokens": ["Da", "ist", "kein", "Mann", "so", "gro\u00df", ",", "so", "gut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIAT", "NN", "ADV", "ADJD", "$,", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Da\u00df ihn der Ha\u00df zu treffen scheue!", "tokens": ["Da\u00df", "ihn", "der", "Ha\u00df", "zu", "tref\u00b7fen", "scheu\u00b7e", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Es rauchet das Schafott vom Blut", "tokens": ["Es", "rau\u00b7chet", "das", "Scha\u00b7fott", "vom", "Blut"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPRART", "NN"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.8": {"text": "Hochedler M\u00e4rtyrer der Treue.", "tokens": ["Ho\u00b7ched\u00b7ler", "M\u00e4r\u00b7ty\u00b7rer", "der", "Treu\u00b7e", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ART", "NN", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}}, "stanza.10": {"line.1": {"text": "Durch eh'rne Strenge, finstern Zwang", "tokens": ["Durch", "eh'r\u00b7ne", "Stren\u00b7ge", ",", "fins\u00b7tern", "Zwang"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "ADJA", "NN", "$,", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Will st\u00fcrzen man den alten Glauben,", "tokens": ["Will", "st\u00fcr\u00b7zen", "man", "den", "al\u00b7ten", "Glau\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "VVFIN", "PIS", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "In r\u00fccksichtslosem Uebergang", "tokens": ["In", "r\u00fcck\u00b7sichts\u00b7lo\u00b7sem", "Ue\u00b7ber\u00b7gang"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Dem Volk sein eigenst Wesen rauben.", "tokens": ["Dem", "Volk", "sein", "ei\u00b7genst", "We\u00b7sen", "rau\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "ADV", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Da\u00df welk von ", "tokens": ["Da\u00df", "welk", "von"], "token_info": ["word", "word", "word"], "pos": ["KOUS", "ADJD", "APPR"], "meter": "-+-", "measure": "amphibrach.single"}, "line.6": {"text": "Sein Selbst wie dessen \u00e4u\u00dfre Zeichen,", "tokens": ["Sein", "Selbst", "wie", "des\u00b7sen", "\u00e4u\u00df\u00b7re", "Zei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KOKOM", "PDS", "VVFIN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Soll Kaledoniens Recht und Brauch", "tokens": ["Soll", "Ka\u00b7le\u00b7do\u00b7ni\u00b7ens", "Recht", "und", "Brauch"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VMFIN", "NE", "NN", "KON", "NN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Dem englischen Gesetze weichen.", "tokens": ["Dem", "eng\u00b7li\u00b7schen", "Ge\u00b7set\u00b7ze", "wei\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Auch auf des Hochlands S\u00f6hne, die", "tokens": ["Auch", "auf", "des", "Hoch\u00b7lands", "S\u00f6h\u00b7ne", ",", "die"], "token_info": ["word", "word", "word", "word", "word", "punct", "word"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN", "$,", "PRELS"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Im Dienst von Englands Fahne stehen,", "tokens": ["Im", "Dienst", "von", "En\u00b7glands", "Fah\u00b7ne", "ste\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPR", "NE", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Ist man bedacht und l\u00e4\u00dft f\u00fcr sie", "tokens": ["Ist", "man", "be\u00b7dacht", "und", "l\u00e4\u00dft", "f\u00fcr", "sie"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PIS", "VVPP", "KON", "VVFIN", "APPR", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Den folgenden Befehl ergehen:", "tokens": ["Den", "fol\u00b7gen\u00b7den", "Be\u00b7fehl", "er\u00b7ge\u00b7hen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "\u00bbwenn Urlaub ein Soldat begehrt,", "tokens": ["\u00bb", "wenn", "Ur\u00b7laub", "ein", "Sol\u00b7dat", "be\u00b7gehrt", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "NN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Sind ihm drei Tage freizugeben;", "tokens": ["Sind", "ihm", "drei", "Ta\u00b7ge", "frei\u00b7zu\u00b7ge\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "CARD", "NN", "VVINF", "$."], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.7": {"text": "Doch wer dann nicht zur\u00fcckekehrt,", "tokens": ["Doch", "wer", "dann", "nicht", "zu\u00b7r\u00fc\u00b7cke\u00b7kehrt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ADV", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Der b\u00fc\u00dft die Schuld mit seinem Leben!", "tokens": ["Der", "b\u00fc\u00dft", "die", "Schuld", "mit", "sei\u00b7nem", "Le\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ART", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Es droht solch blutiges Geschick", "tokens": ["Es", "droht", "solch", "blu\u00b7ti\u00b7ges", "Ge\u00b7schick"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Nicht blo\u00df dem Fl\u00fcchtling, dem Verr\u00e4ter,", "tokens": ["Nicht", "blo\u00df", "dem", "Fl\u00fccht\u00b7ling", ",", "dem", "Ver\u00b7r\u00e4\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "ART", "NN", "$,", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Nein! Jenem auch, der kehrt zur\u00fcck", "tokens": ["Nein", "!", "Je\u00b7nem", "auch", ",", "der", "kehrt", "zu\u00b7r\u00fcck"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["PTKANT", "$.", "PDAT", "ADV", "$,", "PRELS", "VVFIN", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Um eine Tagesl\u00e4nge sp\u00e4ter.", "tokens": ["Um", "ei\u00b7ne", "Ta\u00b7ges\u00b7l\u00e4n\u00b7ge", "sp\u00e4\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUI", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Wer auch um eine Stunde nur", "tokens": ["Wer", "auch", "um", "ei\u00b7ne", "Stun\u00b7de", "nur"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "ADV", "APPR", "ART", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Die Frist des Urlaubs \u00fcberschreitet,", "tokens": ["Die", "Frist", "des", "Ur\u00b7laubs", "\u00fc\u00b7bersc\u00b7hrei\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Der hat, verletzend seinen Schwur,", "tokens": ["Der", "hat", ",", "ver\u00b7let\u00b7zend", "sei\u00b7nen", "Schwur", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "$,", "VVPP", "VAINF", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Sich selbst den Weg zum Grab bereitet.\u00ab", "tokens": ["Sich", "selbst", "den", "Weg", "zum", "Grab", "be\u00b7rei\u00b7tet", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PRF", "ADV", "ART", "NN", "APPRART", "NN", "VVFIN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}