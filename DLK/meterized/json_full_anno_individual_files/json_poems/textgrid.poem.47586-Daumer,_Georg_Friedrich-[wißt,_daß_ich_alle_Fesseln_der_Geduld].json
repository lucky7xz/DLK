{"textgrid.poem.47586": {"metadata": {"author": {"name": "Daumer, Georg Friedrich", "birth": "N.A.", "death": "N.A."}, "title": "[wi\u00dft, da\u00df ich alle Fesseln der Geduld]", "genre": "verse", "period": "N.A.", "pub_year": 1837, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wi\u00dft, da\u00df ich alle Fesseln der Geduld", "tokens": ["Wi\u00dft", ",", "da\u00df", "ich", "al\u00b7le", "Fes\u00b7seln", "der", "Ge\u00b7duld"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "$,", "KOUS", "PPER", "PIAT", "NN", "ART", "NN"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.2": {"text": "Zerrissen habe;", "tokens": ["Zer\u00b7ris\u00b7sen", "ha\u00b7be", ";"], "token_info": ["word", "word", "punct"], "pos": ["VVPP", "VAFIN", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.3": {"text": "Wi\u00dft, da\u00df ich mich der Ungebundenheit", "tokens": ["Wi\u00dft", ",", "da\u00df", "ich", "mich", "der", "Un\u00b7ge\u00b7bun\u00b7den\u00b7heit"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "$,", "KOUS", "PPER", "PRF", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Beflissen habe;", "tokens": ["Be\u00b7flis\u00b7sen", "ha\u00b7be", ";"], "token_info": ["word", "word", "punct"], "pos": ["VVPP", "VAFIN", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.2": {"line.1": {"text": "Wi\u00dft, da\u00df ich aller heiligen Br\u00e4uche mich", "tokens": ["Wi\u00dft", ",", "da\u00df", "ich", "al\u00b7ler", "hei\u00b7li\u00b7gen", "Br\u00e4u\u00b7che", "mich"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "$,", "KOUS", "PPER", "PIAT", "ADJA", "NN", "PPER"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Entbunden habe,", "tokens": ["Ent\u00b7bun\u00b7den", "ha\u00b7be", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "VAFIN", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.3": {"text": "Und doch die allerreinste Seelenruh'", "tokens": ["Und", "doch", "die", "al\u00b7ler\u00b7reins\u00b7te", "See\u00b7len\u00b7ruh'"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Zum Kissen habe!", "tokens": ["Zum", "Kis\u00b7sen", "ha\u00b7be", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VAFIN", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.3": {"line.1": {"text": "Was thut es auch, da\u00df ich der Kaba mich", "tokens": ["Was", "thut", "es", "auch", ",", "da\u00df", "ich", "der", "Ka\u00b7ba", "mich"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "$,", "KOUS", "PPER", "ART", "NN", "PPER"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Entfremdet habe,", "tokens": ["Ent\u00b7frem\u00b7det", "ha\u00b7be", ","], "token_info": ["word", "word", "punct"], "pos": ["VVPP", "VAFIN", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.3": {"text": "Da ich zur Kaba ihres Augenlichts", "tokens": ["Da", "ich", "zur", "Ka\u00b7ba", "ih\u00b7res", "Au\u00b7gen\u00b7lichts"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPRART", "NN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Narcissen habe?", "tokens": ["Nar\u00b7cis\u00b7sen", "ha\u00b7be", "?"], "token_info": ["word", "word", "punct"], "pos": ["NN", "VAFIN", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.4": {"line.1": {"text": "Wenn ich die Hyacinthen ihres Haars", "tokens": ["Wenn", "ich", "die", "Hya\u00b7cin\u00b7then", "ih\u00b7res", "Haars"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "NN", "PPOSAT", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "In H\u00e4nden habe,", "tokens": ["In", "H\u00e4n\u00b7den", "ha\u00b7be", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "VAFIN", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.3": {"text": "Sagt, Freunde, was ich an dem Rosenkranz", "tokens": ["Sagt", ",", "Freun\u00b7de", ",", "was", "ich", "an", "dem", "Ro\u00b7sen\u00b7kranz"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "$,", "NN", "$,", "PWS", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Zu missen habe?", "tokens": ["Zu", "mis\u00b7sen", "ha\u00b7be", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "VAFIN", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.5": {"line.1": {"text": "Wi\u00dft, da\u00df ich selbst nach Edens Fr\u00fcchten kein", "tokens": ["Wi\u00dft", ",", "da\u00df", "ich", "selbst", "nach", "E\u00b7dens", "Fr\u00fcch\u00b7ten", "kein"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "$,", "KOUS", "PPER", "ADV", "APPR", "NE", "NN", "PIAT"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Verlangen habe,", "tokens": ["Ver\u00b7lan\u00b7gen", "ha\u00b7be", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "VAFIN", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.3": {"text": "Weil ich in meines Liebchens Apfelkinn", "tokens": ["Weil", "ich", "in", "mei\u00b7nes", "Lieb\u00b7chens", "Ap\u00b7fel\u00b7kinn"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Gebissen habe.", "tokens": ["Ge\u00b7bis\u00b7sen", "ha\u00b7be", "."], "token_info": ["word", "word", "punct"], "pos": ["VVPP", "VAFIN", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.6": {"line.1": {"text": "Doch nun Ade, da ich zur Schenke nun", "tokens": ["Doch", "nun", "A\u00b7de", ",", "da", "ich", "zur", "Schen\u00b7ke", "nun"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "NN", "$,", "KOUS", "PPER", "APPRART", "NN", "ADV"], "meter": "--+--+-+-+", "measure": "anapaest.di.plus"}, "line.2": {"text": "Zu eilen habe,", "tokens": ["Zu", "ei\u00b7len", "ha\u00b7be", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "VAFIN", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.3": {"text": "Und in Betreff des Kirchengangs ein zart", "tokens": ["Und", "in", "Be\u00b7treff", "des", "Kir\u00b7chen\u00b7gangs", "ein", "zart"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "NN", "ART", "NN", "ART", "ADJD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Gewissen habe.", "tokens": ["Ge\u00b7wis\u00b7sen", "ha\u00b7be", "."], "token_info": ["word", "word", "punct"], "pos": ["VVPP", "VAFIN", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.7": {"line.1": {"text": "Wi\u00dft, da\u00df ich alle Fesseln der Geduld", "tokens": ["Wi\u00dft", ",", "da\u00df", "ich", "al\u00b7le", "Fes\u00b7seln", "der", "Ge\u00b7duld"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "$,", "KOUS", "PPER", "PIAT", "NN", "ART", "NN"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.2": {"text": "Zerrissen habe;", "tokens": ["Zer\u00b7ris\u00b7sen", "ha\u00b7be", ";"], "token_info": ["word", "word", "punct"], "pos": ["VVPP", "VAFIN", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.3": {"text": "Wi\u00dft, da\u00df ich mich der Ungebundenheit", "tokens": ["Wi\u00dft", ",", "da\u00df", "ich", "mich", "der", "Un\u00b7ge\u00b7bun\u00b7den\u00b7heit"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "$,", "KOUS", "PPER", "PRF", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Beflissen habe;", "tokens": ["Be\u00b7flis\u00b7sen", "ha\u00b7be", ";"], "token_info": ["word", "word", "punct"], "pos": ["VVPP", "VAFIN", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.8": {"line.1": {"text": "Wi\u00dft, da\u00df ich aller heiligen Br\u00e4uche mich", "tokens": ["Wi\u00dft", ",", "da\u00df", "ich", "al\u00b7ler", "hei\u00b7li\u00b7gen", "Br\u00e4u\u00b7che", "mich"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "$,", "KOUS", "PPER", "PIAT", "ADJA", "NN", "PPER"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Entbunden habe,", "tokens": ["Ent\u00b7bun\u00b7den", "ha\u00b7be", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "VAFIN", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.3": {"text": "Und doch die allerreinste Seelenruh'", "tokens": ["Und", "doch", "die", "al\u00b7ler\u00b7reins\u00b7te", "See\u00b7len\u00b7ruh'"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Zum Kissen habe!", "tokens": ["Zum", "Kis\u00b7sen", "ha\u00b7be", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VAFIN", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.9": {"line.1": {"text": "Was thut es auch, da\u00df ich der Kaba mich", "tokens": ["Was", "thut", "es", "auch", ",", "da\u00df", "ich", "der", "Ka\u00b7ba", "mich"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "$,", "KOUS", "PPER", "ART", "NN", "PPER"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Entfremdet habe,", "tokens": ["Ent\u00b7frem\u00b7det", "ha\u00b7be", ","], "token_info": ["word", "word", "punct"], "pos": ["VVPP", "VAFIN", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.3": {"text": "Da ich zur Kaba ihres Augenlichts", "tokens": ["Da", "ich", "zur", "Ka\u00b7ba", "ih\u00b7res", "Au\u00b7gen\u00b7lichts"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPRART", "NN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Narcissen habe?", "tokens": ["Nar\u00b7cis\u00b7sen", "ha\u00b7be", "?"], "token_info": ["word", "word", "punct"], "pos": ["NN", "VAFIN", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.10": {"line.1": {"text": "Wenn ich die Hyacinthen ihres Haars", "tokens": ["Wenn", "ich", "die", "Hya\u00b7cin\u00b7then", "ih\u00b7res", "Haars"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "NN", "PPOSAT", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "In H\u00e4nden habe,", "tokens": ["In", "H\u00e4n\u00b7den", "ha\u00b7be", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "VAFIN", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.3": {"text": "Sagt, Freunde, was ich an dem Rosenkranz", "tokens": ["Sagt", ",", "Freun\u00b7de", ",", "was", "ich", "an", "dem", "Ro\u00b7sen\u00b7kranz"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "$,", "NN", "$,", "PWS", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Zu missen habe?", "tokens": ["Zu", "mis\u00b7sen", "ha\u00b7be", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "VAFIN", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.11": {"line.1": {"text": "Wi\u00dft, da\u00df ich selbst nach Edens Fr\u00fcchten kein", "tokens": ["Wi\u00dft", ",", "da\u00df", "ich", "selbst", "nach", "E\u00b7dens", "Fr\u00fcch\u00b7ten", "kein"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "$,", "KOUS", "PPER", "ADV", "APPR", "NE", "NN", "PIAT"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Verlangen habe,", "tokens": ["Ver\u00b7lan\u00b7gen", "ha\u00b7be", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "VAFIN", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.3": {"text": "Weil ich in meines Liebchens Apfelkinn", "tokens": ["Weil", "ich", "in", "mei\u00b7nes", "Lieb\u00b7chens", "Ap\u00b7fel\u00b7kinn"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Gebissen habe.", "tokens": ["Ge\u00b7bis\u00b7sen", "ha\u00b7be", "."], "token_info": ["word", "word", "punct"], "pos": ["VVPP", "VAFIN", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.12": {"line.1": {"text": "Doch nun Ade, da ich zur Schenke nun", "tokens": ["Doch", "nun", "A\u00b7de", ",", "da", "ich", "zur", "Schen\u00b7ke", "nun"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "NN", "$,", "KOUS", "PPER", "APPRART", "NN", "ADV"], "meter": "--+--+-+-+", "measure": "anapaest.di.plus"}, "line.2": {"text": "Zu eilen habe,", "tokens": ["Zu", "ei\u00b7len", "ha\u00b7be", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "VAFIN", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.3": {"text": "Und in Betreff des Kirchengangs ein zart", "tokens": ["Und", "in", "Be\u00b7treff", "des", "Kir\u00b7chen\u00b7gangs", "ein", "zart"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "NN", "ART", "NN", "ART", "ADJD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Gewissen habe.", "tokens": ["Ge\u00b7wis\u00b7sen", "ha\u00b7be", "."], "token_info": ["word", "word", "punct"], "pos": ["VVPP", "VAFIN", "$."], "meter": "-+-+-", "measure": "iambic.di"}}}}}