{"dta.poem.19809": {"metadata": {"author": {"name": "Brentano, Clemens", "birth": "N.A.", "death": "N.A."}, "title": "Trutz den Meistern .", "genre": "Lyrik", "period": "N.A.", "pub_year": "1808", "urn": "urn:nbn:de:kobv:b4-20090519168", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Drum ihr Gesellen halt euch gut,               ", "tokens": ["Drum", "ihr", "Ge\u00b7sel\u00b7len", "halt", "euch", "gut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PPOSAT", "NN", "VVFIN", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Zu Hamburg das junge Blut,", "tokens": ["Zu", "Ham\u00b7burg", "das", "jun\u00b7ge", "Blut", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "ART", "ADJA", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Thut die Meister scheren;", "tokens": ["Thut", "die", "Meis\u00b7ter", "sche\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Rommodedom und Faldrida,", "tokens": ["Rom\u00b7mo\u00b7de\u00b7dom", "und", "Fald\u00b7ri\u00b7da", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "KON", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Thut die Meister scheren.", "tokens": ["Thut", "die", "Meis\u00b7ter", "sche\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.2": {"line.1": {"text": "Sagt in vierzehn Tage auf,", "tokens": ["Sagt", "in", "vier\u00b7zehn", "Ta\u00b7ge", "auf", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "CARD", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Reiset fort mit schnellem Lauf,", "tokens": ["Rei\u00b7set", "fort", "mit", "schnel\u00b7lem", "Lauf", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Thut die Welt durchreisen; Romod. etc.", "tokens": ["Thut", "die", "Welt", "durc\u00b7hrei\u00b7sen", ";", "Ro\u00b7mod", ".", "et\u00b7c."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "abbreviation"], "pos": ["NE", "ART", "NN", "VVINF", "$.", "NN", "$.", "ADV"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.3": {"line.1": {"text": "So ihr an Ort und Stelle werd kommen,", "tokens": ["So", "ihr", "an", "Ort", "und", "Stel\u00b7le", "werd", "kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "APPR", "NN", "KON", "NN", "VAFIN", "VVINF", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Sagt die Meister habn genommen", "tokens": ["Sagt", "die", "Meis\u00b7ter", "habn", "ge\u00b7nom\u00b7men"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "NN", "VAFIN", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Geld aus unserer Lade; Romod. etc.", "tokens": ["Geld", "aus", "un\u00b7se\u00b7rer", "La\u00b7de", ";", "Ro\u00b7mod", ".", "et\u00b7c."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "abbreviation"], "pos": ["NN", "APPR", "PPOSAT", "NN", "$.", "NN", "$.", "ADV"], "meter": "+-+--+--+", "measure": "trochaic.tetra.relaxed"}}, "stanza.4": {"line.1": {"text": "Den Gesellen, die davon sprechen,", "tokens": ["Den", "Ge\u00b7sel\u00b7len", ",", "die", "da\u00b7von", "spre\u00b7chen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PAV", "VVINF", "$,"], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.2": {"text": "Wollen wir den Hals zerbrechen,", "tokens": ["Wol\u00b7len", "wir", "den", "Hals", "zer\u00b7bre\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Ja sie sollen schweigen; Romod. etc.", "tokens": ["Ja", "sie", "sol\u00b7len", "schwei\u00b7gen", ";", "Ro\u00b7mod", ".", "et\u00b7c."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "abbreviation"], "pos": ["PTKANT", "PPER", "VMFIN", "VVINF", "$.", "NN", "$.", "ADV"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.5": {"line.1": {"text": "Gesellen gingen nach Altona hinaus,", "tokens": ["Ge\u00b7sel\u00b7len", "gin\u00b7gen", "nach", "Al\u00b7to\u00b7na", "hin\u00b7aus", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "APPR", "NE", "APZR", "$,"], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Lebten da in Saus und Schmau\u00df,", "tokens": ["Leb\u00b7ten", "da", "in", "Saus", "und", "Schmau\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Auf des Meisters Gelder: Romod. etc.", "tokens": ["Auf", "des", "Meis\u00b7ters", "Gel\u00b7der", ":", "Ro\u00b7mod", ".", "et\u00b7c."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "abbreviation"], "pos": ["APPR", "ART", "NN", "NN", "$.", "NN", "$.", "ADV"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.6": {"line.1": {"text": "Als sie ein Vierzehn Tage gelegen,", "tokens": ["Als", "sie", "ein", "Vier\u00b7zehn", "Ta\u00b7ge", "ge\u00b7le\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "CARD", "NN", "VVPP", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Wollten sie das Geld erlegen,", "tokens": ["Woll\u00b7ten", "sie", "das", "Geld", "er\u00b7le\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wollten sie es wohl \u00e4ndern: Romod. etc.", "tokens": ["Woll\u00b7ten", "sie", "es", "wohl", "\u00e4n\u00b7dern", ":", "Ro\u00b7mod", ".", "et\u00b7c."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "abbreviation"], "pos": ["VMFIN", "PPER", "PPER", "ADV", "VVINF", "$.", "NN", "$.", "ADV"], "meter": "+-+--+--+", "measure": "trochaic.tetra.relaxed"}}, "stanza.7": {"line.1": {"text": "Gesellen th\u00e4ten sich resolviren,", "tokens": ["Ge\u00b7sel\u00b7len", "th\u00e4\u00b7ten", "sich", "re\u00b7sol\u00b7vi\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PRF", "VVINF", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Nach der Herberg zu spaziren,", "tokens": ["Nach", "der", "Her\u00b7berg", "zu", "spa\u00b7zi\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Th\u00e4ten da brav saufen: Romod. etc.", "tokens": ["Th\u00e4\u00b7ten", "da", "brav", "sau\u00b7fen", ":", "Ro\u00b7mod", ".", "et\u00b7c."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "abbreviation"], "pos": ["VVFIN", "ADV", "ADJD", "VVINF", "$.", "NN", "$.", "ADV"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.8": {"line.1": {"text": "Th\u00fcren wurden zugemacht,", "tokens": ["Th\u00fc\u00b7ren", "wur\u00b7den", "zu\u00b7ge\u00b7macht", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Trommel geschlagen, da\u00df es kracht,", "tokens": ["Trom\u00b7mel", "ge\u00b7schla\u00b7gen", ",", "da\u00df", "es", "kracht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VVPP", "$,", "KOUS", "PPER", "VVFIN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.3": {"text": "B\u00fcrger schlugen L\u00e4rmen: Romod. etc.", "tokens": ["B\u00fcr\u00b7ger", "schlu\u00b7gen", "L\u00e4r\u00b7men", ":", "Ro\u00b7mod", ".", "et\u00b7c."], "token_info": ["word", "word", "word", "punct", "word", "punct", "abbreviation"], "pos": ["NN", "ADJA", "NN", "$.", "NN", "$.", "ADV"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.9": {"line.1": {"text": "Vor die Herberg kamen an", "tokens": ["Vor", "die", "Her\u00b7berg", "ka\u00b7men", "an"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "VVFIN", "PTKVZ"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Mehr als drei\u00dfig tausend Mann,", "tokens": ["Mehr", "als", "drei\u00b7\u00dfig", "tau\u00b7send", "Mann", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "KOKOM", "CARD", "CARD", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "B\u00fcrger und Soldaten: Romod. etc.", "tokens": ["B\u00fcr\u00b7ger", "und", "Sol\u00b7da\u00b7ten", ":", "Ro\u00b7mod", ".", "et\u00b7c."], "token_info": ["word", "word", "word", "punct", "word", "punct", "abbreviation"], "pos": ["NN", "KON", "NN", "$.", "NN", "$.", "ADV"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.10": {"line.1": {"text": "Tischler gaben sich gefangen,", "tokens": ["Tischler", "ga\u00b7ben", "sich", "ge\u00b7fan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PRF", "PTKVZ", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Kamen den Herren entgegen gegangen,", "tokens": ["Ka\u00b7men", "den", "Her\u00b7ren", "ent\u00b7ge\u00b7gen", "ge\u00b7gan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "PTKVZ", "VVPP", "$,"], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.3": {"text": "Fragten was sie wolten: Romod. etc.", "tokens": ["Frag\u00b7ten", "was", "sie", "wol\u00b7ten", ":", "Ro\u00b7mod", ".", "et\u00b7c."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "abbreviation"], "pos": ["NN", "PWS", "PPER", "VMFIN", "$.", "NN", "$.", "ADV"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.11": {"line.1": {"text": "Wir verlangen nicht mehr als Recht,", "tokens": ["Wir", "ver\u00b7lan\u00b7gen", "nicht", "mehr", "als", "Recht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "ADV", "KOUS", "NN", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.2": {"text": "Oder es wird Hamburg schlecht,", "tokens": ["O\u00b7der", "es", "wird", "Ham\u00b7burg", "schlecht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "NE", "VVFIN", "$,"], "meter": "+---+-+", "measure": "dactylic.init"}, "line.3": {"text": "Dieses Jahr ergehen: Romod. etc.", "tokens": ["Die\u00b7ses", "Jahr", "er\u00b7ge\u00b7hen", ":", "Ro\u00b7mod", ".", "et\u00b7c."], "token_info": ["word", "word", "word", "punct", "word", "punct", "abbreviation"], "pos": ["PDAT", "NN", "VVINF", "$.", "NN", "$.", "ADV"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.12": {"line.1": {"text": "Schornsteinfeger fuhren fort:", "tokens": ["Schorn\u00b7stein\u00b7fe\u00b7ger", "fuh\u00b7ren", "fort", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PTKVZ", "$."], "meter": "+---+-+", "measure": "dactylic.init"}, "line.2": {"text": "Tischler saget nur ein Wort,", "tokens": ["Tischler", "sa\u00b7get", "nur", "ein", "Wort", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Sollen wir drein werfen: Romod. etc.", "tokens": ["Sol\u00b7len", "wir", "drein", "wer\u00b7fen", ":", "Ro\u00b7mod", ".", "et\u00b7c."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "abbreviation"], "pos": ["VMFIN", "PPER", "ADV", "VVINF", "$.", "NN", "$.", "ADV"], "meter": "+--++--+", "measure": "iambic.tetra.chol"}}, "stanza.13": {"line.1": {"text": "Tischler kamen aus Arest,", "tokens": ["Tischler", "ka\u00b7men", "aus", "A\u00b7rest", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "APPR", "NE", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Liessen sich aufs allerbest", "tokens": ["Lies\u00b7sen", "sich", "aufs", "al\u00b7ler\u00b7best"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PRF", "APPRART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Die Trompeten blasen: Romod. etc.", "tokens": ["Die", "Trom\u00b7pe\u00b7ten", "bla\u00b7sen", ":", "Ro\u00b7mod", ".", "et\u00b7c."], "token_info": ["word", "word", "word", "punct", "word", "punct", "abbreviation"], "pos": ["ART", "NN", "VVINF", "$.", "NN", "$.", "ADV"], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.14": {"line.1": {"text": "Andre Handwerker allzumal", "tokens": ["And\u00b7re", "Hand\u00b7wer\u00b7ker", "all\u00b7zu\u00b7mal"], "token_info": ["word", "word", "word"], "pos": ["ADJA", "NN", "ADV"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.2": {"text": "Riefen Vivat \u00fcberall,", "tokens": ["Rie\u00b7fen", "Vi\u00b7vat", "\u00fc\u00b7be\u00b7rall", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "NN", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Es leben unsre Br\u00fcder: Romod. etc.", "tokens": ["Es", "le\u00b7ben", "uns\u00b7re", "Br\u00fc\u00b7der", ":", "Ro\u00b7mod", ".", "et\u00b7c."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "abbreviation"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "$.", "NN", "$.", "ADV"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.15": {"line.1": {"text": "Nun Adjeu mein Lied ist aus,", "tokens": ["Nun", "Ad\u00b7jeu", "mein", "Lied", "ist", "aus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NE", "PPOSAT", "NN", "VAFIN", "PTKVZ", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Meister m\u00fcssen gehn nach Haus,", "tokens": ["Meis\u00b7ter", "m\u00fcs\u00b7sen", "gehn", "nach", "Haus", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "VVINF", "APPR", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "All ihr Gut verkauffen: Romod. etc.", "tokens": ["All", "ihr", "Gut", "ver\u00b7kauf\u00b7fen", ":", "Ro\u00b7mod", ".", "et\u00b7c."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "abbreviation"], "pos": ["PIAT", "PPOSAT", "NN", "VVINF", "$.", "NN", "$.", "ADV"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.16": {"line.1": {"text": "Wer hat uns dis Lied erdacht,", "tokens": ["Wer", "hat", "uns", "dis", "Lied", "er\u00b7dacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "PDS", "NN", "VVPP", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Das haben brave Burschen gemacht,", "tokens": ["Das", "ha\u00b7ben", "bra\u00b7ve", "Bur\u00b7schen", "ge\u00b7macht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Die die Welt durchreisen,", "tokens": ["Die", "die", "Welt", "durc\u00b7hrei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Rommodedom und Faldrida,", "tokens": ["Rom\u00b7mo\u00b7de\u00b7dom", "und", "Fald\u00b7ri\u00b7da", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "KON", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die die Welt durchreisen.", "tokens": ["Die", "die", "Welt", "durc\u00b7hrei\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}}}}