{"textgrid.poem.24554": {"metadata": {"author": {"name": "Hunold, Christian Friedrich", "birth": "N.A.", "death": "N.A."}, "title": "Als ein guter Freund den Doctor-Hut \u00fcberkam", "genre": "verse", "period": "N.A.", "pub_year": 1701, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wenn/ Hochgeehrter Freund/ die ", "tokens": ["Wenn", "/", "Hoch\u00b7geehr\u00b7ter", "Freund", "/", "die"], "token_info": ["word", "punct", "word", "word", "punct", "word"], "pos": ["KOUS", "$(", "ADJA", "NN", "$(", "ART"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Auf deinen Ehren-Tag was frohes aufzusetzen/", "tokens": ["Auf", "dei\u00b7nen", "Eh\u00b7ren\u00b7Tag", "was", "fro\u00b7hes", "auf\u00b7zu\u00b7set\u00b7zen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PWS", "ADJA", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "So glaube/ da\u00df der Kiel aus treuen Hertzen schreibt/", "tokens": ["So", "glau\u00b7be", "/", "da\u00df", "der", "Kiel", "aus", "treu\u00b7en", "Hert\u00b7zen", "schreibt", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$(", "KOUS", "ART", "NN", "APPR", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und dein verdientes Lob so rein/ als mein Ergetzen.", "tokens": ["Und", "dein", "ver\u00b7dien\u00b7tes", "Lob", "so", "rein", "/", "als", "mein", "Er\u00b7get\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "ADV", "ADJD", "$(", "KOKOM", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Denn was mich r\u00fchren soll/ mu\u00df wahre Freundschafft seyn/", "tokens": ["Denn", "was", "mich", "r\u00fch\u00b7ren", "soll", "/", "mu\u00df", "wah\u00b7re", "Freund\u00b7schafft", "seyn", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "VVINF", "VMFIN", "$(", "VMFIN", "ADJA", "NN", "VAINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Ein Tugend-voller Geist/ und Wissenschafft darneben/", "tokens": ["Ein", "Tu\u00b7gen\u00b7dvol\u00b7ler", "Geist", "/", "und", "Wis\u00b7sen\u00b7schafft", "dar\u00b7ne\u00b7ben", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$(", "KON", "NN", "PAV", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und itzo trifft der Zug bey mir vollkommen ein/", "tokens": ["Und", "it\u00b7zo", "trifft", "der", "Zug", "bey", "mir", "voll\u00b7kom\u00b7men", "ein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "ART", "NN", "APPR", "PPER", "ADJD", "ART", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Da\u00df meine ", "tokens": ["Da\u00df", "mei\u00b7ne"], "token_info": ["word", "word"], "pos": ["KOUS", "PPOSAT"], "meter": "-+-", "measure": "amphibrach.single"}, "line.9": {"text": "Denn dieser bl\u00fcht vor sich/ ich letze mich nur dran;", "tokens": ["Denn", "die\u00b7ser", "bl\u00fcht", "vor", "sich", "/", "ich", "let\u00b7ze", "mich", "nur", "dran", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VVFIN", "APPR", "PRF", "$(", "PPER", "VVFIN", "PPER", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Und deiner Feder ist samt der gelehrten Zungen", "tokens": ["Und", "dei\u00b7ner", "Fe\u00b7der", "ist", "samt", "der", "ge\u00b7lehr\u00b7ten", "Zun\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "VAFIN", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.11": {"text": "Di\u00df alles/ welches dir zum Ruhm gereichen kan/", "tokens": ["Di\u00df", "al\u00b7les", "/", "wel\u00b7ches", "dir", "zum", "Ruhm", "ge\u00b7rei\u00b7chen", "kan", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PIS", "$(", "PWS", "PPER", "APPRART", "NN", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Mehr sch\u00f6n und gr\u00fcndlicher/ als heute mir gelungen.", "tokens": ["Mehr", "sch\u00f6n", "und", "gr\u00fcnd\u00b7li\u00b7cher", "/", "als", "heu\u00b7te", "mir", "ge\u00b7lun\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KON", "ADJD", "$(", "KOKOM", "ADV", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Gelehrsamkeit/ Verstand und Klugheit sind die drey/", "tokens": ["Ge\u00b7lehr\u00b7sam\u00b7keit", "/", "Ver\u00b7stand", "und", "Klug\u00b7heit", "sind", "die", "drey", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "NN", "KON", "NN", "VAFIN", "ART", "CARD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Die Edle Musen einst zu Rechts-Gelehrten machen.", "tokens": ["Die", "Ed\u00b7le", "Mu\u00b7sen", "einst", "zu", "Rechts\u00b7Ge\u00b7lehr\u00b7ten", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Was nun darzu geh\u00f6rt/ f\u00e4llt dir am besten bey/", "tokens": ["Was", "nun", "dar\u00b7zu", "ge\u00b7h\u00f6rt", "/", "f\u00e4llt", "dir", "am", "bes\u00b7ten", "bey", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "PAV", "VVFIN", "$(", "VVFIN", "PPER", "PTKA", "ADJD", "APPR", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Du findest/ suche nur/ sie selbst in deinen Sachen.", "tokens": ["Du", "fin\u00b7dest", "/", "su\u00b7che", "nur", "/", "sie", "selbst", "in", "dei\u00b7nen", "Sa\u00b7chen", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$(", "VVFIN", "ADV", "$(", "PPER", "ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Es schicket sich darzu der muntre Fr\u00fchling nicht.", "tokens": ["Es", "schi\u00b7cket", "sich", "dar\u00b7zu", "der", "mun\u00b7tre", "Fr\u00fch\u00b7ling", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "PAV", "ART", "ADJA", "NN", "PTKNEG", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Wenn andere zu fr\u00fch der Ehre-K\u00fctzel sticht/", "tokens": ["Wenn", "an\u00b7de\u00b7re", "zu", "fr\u00fch", "der", "Eh\u00b7re\u00b7K\u00fct\u00b7zel", "sticht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PTKA", "ADJD", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Als ob die Wei\u00dfheit auch im Nahmen k\u00f6nne sitzen:", "tokens": ["Als", "ob", "die", "Wei\u00df\u00b7heit", "auch", "im", "Nah\u00b7men", "k\u00f6n\u00b7ne", "sit\u00b7zen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "ART", "NN", "ADV", "APPRART", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "So spahrt die Klugheit di\u00df in deine Sommers-Zeit/", "tokens": ["So", "spahrt", "die", "Klug\u00b7heit", "di\u00df", "in", "dei\u00b7ne", "Som\u00b7mer\u00b7sZeit", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "PDS", "APPR", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Da alles reifft und brennt/ da alles Fr\u00fcchte tr\u00e4get.", "tokens": ["Da", "al\u00b7les", "reifft", "und", "brennt", "/", "da", "al\u00b7les", "Fr\u00fcch\u00b7te", "tr\u00e4\u00b7get", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "VVFIN", "KON", "VVFIN", "$(", "ADV", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Zwar wei\u00df ich allzuwohl/ da\u00df aus Bescheidenheit", "tokens": ["Zwar", "wei\u00df", "ich", "all\u00b7zu\u00b7wohl", "/", "da\u00df", "aus", "Be\u00b7schei\u00b7den\u00b7heit"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "$(", "KOUS", "APPR", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Mein Wehrter Freund sich nie die Ehre beygeleget.", "tokens": ["Mein", "Wehr\u00b7ter", "Freund", "sich", "nie", "die", "Eh\u00b7re", "bey\u00b7ge\u00b7le\u00b7get", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "NN", "PRF", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Doch die gelehrte Welt belohnet so den Flei\u00df/", "tokens": ["Doch", "die", "ge\u00b7lehr\u00b7te", "Welt", "be\u00b7loh\u00b7net", "so", "den", "Flei\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "VVFIN", "ADV", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Wer in ihr leben will/ mu\u00df ihre W\u00fcrden haben.", "tokens": ["Wer", "in", "ihr", "le\u00b7ben", "will", "/", "mu\u00df", "ih\u00b7re", "W\u00fcr\u00b7den", "ha\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "PPER", "VVINF", "VMFIN", "$(", "VMFIN", "PPOSAT", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Und ob ich allzuwohl von deiner Tugend wei\u00df/", "tokens": ["Und", "ob", "ich", "all\u00b7zu\u00b7wohl", "von", "dei\u00b7ner", "Tu\u00b7gend", "wei\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "APPR", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "So wei\u00df die Tugend auch von deinen edlen Gaben.", "tokens": ["So", "wei\u00df", "die", "Tu\u00b7gend", "auch", "von", "dei\u00b7nen", "ed\u00b7len", "Ga\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ADV", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Ich w\u00fcnsche Gl\u00fcck darzu. Ihr Musen aber seht/", "tokens": ["Ich", "w\u00fcn\u00b7sche", "Gl\u00fcck", "dar\u00b7zu", ".", "Ihr", "Mu\u00b7sen", "a\u00b7ber", "seht", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "PAV", "$.", "PPOSAT", "NN", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Ein Edler tritt anitzt in den gelehrten Orden/", "tokens": ["Ein", "Ed\u00b7ler", "tritt", "a\u00b7nitzt", "in", "den", "ge\u00b7lehr\u00b7ten", "Or\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "APPR", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "Von dem zu seinem Ruhm die seltne Frage geht:", "tokens": ["Von", "dem", "zu", "sei\u00b7nem", "Ruhm", "die", "selt\u00b7ne", "Fra\u00b7ge", "geht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "APPR", "PPOSAT", "NN", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Warum Herr ", "tokens": ["Wa\u00b7rum", "Herr"], "token_info": ["word", "word"], "pos": ["PWAV", "NN"], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.2": {"line.1": {"text": "Wenn/ Hochgeehrter Freund/ die ", "tokens": ["Wenn", "/", "Hoch\u00b7geehr\u00b7ter", "Freund", "/", "die"], "token_info": ["word", "punct", "word", "word", "punct", "word"], "pos": ["KOUS", "$(", "ADJA", "NN", "$(", "ART"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Auf deinen Ehren-Tag was frohes aufzusetzen/", "tokens": ["Auf", "dei\u00b7nen", "Eh\u00b7ren\u00b7Tag", "was", "fro\u00b7hes", "auf\u00b7zu\u00b7set\u00b7zen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PWS", "ADJA", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "So glaube/ da\u00df der Kiel aus treuen Hertzen schreibt/", "tokens": ["So", "glau\u00b7be", "/", "da\u00df", "der", "Kiel", "aus", "treu\u00b7en", "Hert\u00b7zen", "schreibt", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$(", "KOUS", "ART", "NN", "APPR", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und dein verdientes Lob so rein/ als mein Ergetzen.", "tokens": ["Und", "dein", "ver\u00b7dien\u00b7tes", "Lob", "so", "rein", "/", "als", "mein", "Er\u00b7get\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "ADV", "ADJD", "$(", "KOKOM", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Denn was mich r\u00fchren soll/ mu\u00df wahre Freundschafft seyn/", "tokens": ["Denn", "was", "mich", "r\u00fch\u00b7ren", "soll", "/", "mu\u00df", "wah\u00b7re", "Freund\u00b7schafft", "seyn", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "VVINF", "VMFIN", "$(", "VMFIN", "ADJA", "NN", "VAINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Ein Tugend-voller Geist/ und Wissenschafft darneben/", "tokens": ["Ein", "Tu\u00b7gen\u00b7dvol\u00b7ler", "Geist", "/", "und", "Wis\u00b7sen\u00b7schafft", "dar\u00b7ne\u00b7ben", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$(", "KON", "NN", "PAV", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und itzo trifft der Zug bey mir vollkommen ein/", "tokens": ["Und", "it\u00b7zo", "trifft", "der", "Zug", "bey", "mir", "voll\u00b7kom\u00b7men", "ein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "ART", "NN", "APPR", "PPER", "ADJD", "ART", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Da\u00df meine ", "tokens": ["Da\u00df", "mei\u00b7ne"], "token_info": ["word", "word"], "pos": ["KOUS", "PPOSAT"], "meter": "-+-", "measure": "amphibrach.single"}, "line.9": {"text": "Denn dieser bl\u00fcht vor sich/ ich letze mich nur dran;", "tokens": ["Denn", "die\u00b7ser", "bl\u00fcht", "vor", "sich", "/", "ich", "let\u00b7ze", "mich", "nur", "dran", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VVFIN", "APPR", "PRF", "$(", "PPER", "VVFIN", "PPER", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Und deiner Feder ist samt der gelehrten Zungen", "tokens": ["Und", "dei\u00b7ner", "Fe\u00b7der", "ist", "samt", "der", "ge\u00b7lehr\u00b7ten", "Zun\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "VAFIN", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.11": {"text": "Di\u00df alles/ welches dir zum Ruhm gereichen kan/", "tokens": ["Di\u00df", "al\u00b7les", "/", "wel\u00b7ches", "dir", "zum", "Ruhm", "ge\u00b7rei\u00b7chen", "kan", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PIS", "$(", "PWS", "PPER", "APPRART", "NN", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Mehr sch\u00f6n und gr\u00fcndlicher/ als heute mir gelungen.", "tokens": ["Mehr", "sch\u00f6n", "und", "gr\u00fcnd\u00b7li\u00b7cher", "/", "als", "heu\u00b7te", "mir", "ge\u00b7lun\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KON", "ADJD", "$(", "KOKOM", "ADV", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Gelehrsamkeit/ Verstand und Klugheit sind die drey/", "tokens": ["Ge\u00b7lehr\u00b7sam\u00b7keit", "/", "Ver\u00b7stand", "und", "Klug\u00b7heit", "sind", "die", "drey", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "NN", "KON", "NN", "VAFIN", "ART", "CARD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Die Edle Musen einst zu Rechts-Gelehrten machen.", "tokens": ["Die", "Ed\u00b7le", "Mu\u00b7sen", "einst", "zu", "Rechts\u00b7Ge\u00b7lehr\u00b7ten", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Was nun darzu geh\u00f6rt/ f\u00e4llt dir am besten bey/", "tokens": ["Was", "nun", "dar\u00b7zu", "ge\u00b7h\u00f6rt", "/", "f\u00e4llt", "dir", "am", "bes\u00b7ten", "bey", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "PAV", "VVFIN", "$(", "VVFIN", "PPER", "PTKA", "ADJD", "APPR", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Du findest/ suche nur/ sie selbst in deinen Sachen.", "tokens": ["Du", "fin\u00b7dest", "/", "su\u00b7che", "nur", "/", "sie", "selbst", "in", "dei\u00b7nen", "Sa\u00b7chen", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$(", "VVFIN", "ADV", "$(", "PPER", "ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Es schicket sich darzu der muntre Fr\u00fchling nicht.", "tokens": ["Es", "schi\u00b7cket", "sich", "dar\u00b7zu", "der", "mun\u00b7tre", "Fr\u00fch\u00b7ling", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "PAV", "ART", "ADJA", "NN", "PTKNEG", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Wenn andere zu fr\u00fch der Ehre-K\u00fctzel sticht/", "tokens": ["Wenn", "an\u00b7de\u00b7re", "zu", "fr\u00fch", "der", "Eh\u00b7re\u00b7K\u00fct\u00b7zel", "sticht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PTKA", "ADJD", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Als ob die Wei\u00dfheit auch im Nahmen k\u00f6nne sitzen:", "tokens": ["Als", "ob", "die", "Wei\u00df\u00b7heit", "auch", "im", "Nah\u00b7men", "k\u00f6n\u00b7ne", "sit\u00b7zen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "ART", "NN", "ADV", "APPRART", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "So spahrt die Klugheit di\u00df in deine Sommers-Zeit/", "tokens": ["So", "spahrt", "die", "Klug\u00b7heit", "di\u00df", "in", "dei\u00b7ne", "Som\u00b7mer\u00b7sZeit", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "PDS", "APPR", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Da alles reifft und brennt/ da alles Fr\u00fcchte tr\u00e4get.", "tokens": ["Da", "al\u00b7les", "reifft", "und", "brennt", "/", "da", "al\u00b7les", "Fr\u00fcch\u00b7te", "tr\u00e4\u00b7get", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "VVFIN", "KON", "VVFIN", "$(", "ADV", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Zwar wei\u00df ich allzuwohl/ da\u00df aus Bescheidenheit", "tokens": ["Zwar", "wei\u00df", "ich", "all\u00b7zu\u00b7wohl", "/", "da\u00df", "aus", "Be\u00b7schei\u00b7den\u00b7heit"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "$(", "KOUS", "APPR", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Mein Wehrter Freund sich nie die Ehre beygeleget.", "tokens": ["Mein", "Wehr\u00b7ter", "Freund", "sich", "nie", "die", "Eh\u00b7re", "bey\u00b7ge\u00b7le\u00b7get", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "NN", "PRF", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Doch die gelehrte Welt belohnet so den Flei\u00df/", "tokens": ["Doch", "die", "ge\u00b7lehr\u00b7te", "Welt", "be\u00b7loh\u00b7net", "so", "den", "Flei\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "VVFIN", "ADV", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Wer in ihr leben will/ mu\u00df ihre W\u00fcrden haben.", "tokens": ["Wer", "in", "ihr", "le\u00b7ben", "will", "/", "mu\u00df", "ih\u00b7re", "W\u00fcr\u00b7den", "ha\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "PPER", "VVINF", "VMFIN", "$(", "VMFIN", "PPOSAT", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Und ob ich allzuwohl von deiner Tugend wei\u00df/", "tokens": ["Und", "ob", "ich", "all\u00b7zu\u00b7wohl", "von", "dei\u00b7ner", "Tu\u00b7gend", "wei\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "APPR", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "So wei\u00df die Tugend auch von deinen edlen Gaben.", "tokens": ["So", "wei\u00df", "die", "Tu\u00b7gend", "auch", "von", "dei\u00b7nen", "ed\u00b7len", "Ga\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ADV", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Ich w\u00fcnsche Gl\u00fcck darzu. Ihr Musen aber seht/", "tokens": ["Ich", "w\u00fcn\u00b7sche", "Gl\u00fcck", "dar\u00b7zu", ".", "Ihr", "Mu\u00b7sen", "a\u00b7ber", "seht", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "PAV", "$.", "PPOSAT", "NN", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Ein Edler tritt anitzt in den gelehrten Orden/", "tokens": ["Ein", "Ed\u00b7ler", "tritt", "a\u00b7nitzt", "in", "den", "ge\u00b7lehr\u00b7ten", "Or\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "APPR", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "Von dem zu seinem Ruhm die seltne Frage geht:", "tokens": ["Von", "dem", "zu", "sei\u00b7nem", "Ruhm", "die", "selt\u00b7ne", "Fra\u00b7ge", "geht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "APPR", "PPOSAT", "NN", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Warum Herr ", "tokens": ["Wa\u00b7rum", "Herr"], "token_info": ["word", "word"], "pos": ["PWAV", "NN"], "meter": "+-+", "measure": "trochaic.di"}}}}}