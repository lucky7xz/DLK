{"textgrid.poem.52918": {"metadata": {"author": {"name": "Dingelstedt, Franz von", "birth": "N.A.", "death": "N.A."}, "title": "1L: Ein K\u00f6nigreich hab' ich gesehen,", "genre": "verse", "period": "N.A.", "pub_year": 1847, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ein K\u00f6nigreich hab' ich gesehen,", "tokens": ["Ein", "K\u00f6\u00b7nig\u00b7reich", "hab'", "ich", "ge\u00b7se\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "So eins gibt's auf der Welt nicht mehr:", "tokens": ["So", "eins", "gibt's", "auf", "der", "Welt", "nicht", "mehr", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "VVFIN", "APPR", "ART", "NN", "PTKNEG", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mit offnem Munde blieb ich stehen,", "tokens": ["Mit", "off\u00b7nem", "Mun\u00b7de", "blieb", "ich", "ste\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und sah und staunte rings umher.", "tokens": ["Und", "sah", "und", "staun\u00b7te", "rings", "um\u00b7her", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "KON", "VVFIN", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Das war ein Wohlsein allerwegen", "tokens": ["Das", "war", "ein", "Wohl\u00b7sein", "al\u00b7ler\u00b7we\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "ART", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "In Haus und Hof, zu Stadt und Land,", "tokens": ["In", "Haus", "und", "Hof", ",", "zu", "Stadt", "und", "Land", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$,", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ein rechter reicher Gottes-Segen,", "tokens": ["Ein", "rech\u00b7ter", "rei\u00b7cher", "Got\u00b7tes\u00b7Se\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJD", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wie ihn mein Auge nirgends fand.", "tokens": ["Wie", "ihn", "mein", "Au\u00b7ge", "nir\u00b7gends", "fand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PPOSAT", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Die Stra\u00dfen statt von Kriegsmilizen", "tokens": ["Die", "Stra\u00b7\u00dfen", "statt", "von", "Kriegs\u00b7mi\u00b7li\u00b7zen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Waren von B\u00fcrgern reich belebt,", "tokens": ["Wa\u00b7ren", "von", "B\u00fcr\u00b7gern", "reich", "be\u00b7lebt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "NN", "ADJD", "VVPP", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Der Hafen hat von Mastenspitzen,", "tokens": ["Der", "Ha\u00b7fen", "hat", "von", "Mas\u00b7ten\u00b7spit\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Von R\u00e4dern die Chauss\u00e9e gebebt.", "tokens": ["Von", "R\u00e4\u00b7dern", "die", "Chaus\u00b7s\u00e9e", "ge\u00b7bebt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.4": {"line.1": {"text": "Von Polizei- und Amts-Verboten,", "tokens": ["Von", "Po\u00b7li\u00b7zei", "und", "Amts\u00b7Ver\u00b7bo\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "TRUNC", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Von Maut-Tarif und Br\u00fcckengeld,", "tokens": ["Von", "Maut\u00b7Ta\u00b7rif", "und", "Br\u00fc\u00b7cken\u00b7geld", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Schlagbaum und andren Schwerenoten", "tokens": ["Schlag\u00b7baum", "und", "an\u00b7dren", "Schwe\u00b7re\u00b7no\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "KON", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "War auch nicht eine ausgestellt.", "tokens": ["War", "auch", "nicht", "ei\u00b7ne", "aus\u00b7ge\u00b7stellt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PTKNEG", "ART", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Und drinnen? \u2013 O da hat ein Glaube", "tokens": ["Und", "drin\u00b7nen", "?", "\u2013", "O", "da", "hat", "ein", "Glau\u00b7be"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "$.", "$(", "NE", "ADV", "VAFIN", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ganz ohne Pfaff und Priesterstand", "tokens": ["Ganz", "oh\u00b7ne", "Pfaff", "und", "Pries\u00b7ter\u00b7stand"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "NE", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Leuchtend, wie einst des Geistes Taube,", "tokens": ["Leuch\u00b7tend", ",", "wie", "einst", "des", "Geis\u00b7tes", "Tau\u00b7be", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PWAV", "ADV", "ART", "NN", "NN", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Geschwebt ob dem begl\u00fcckten Land.", "tokens": ["Ge\u00b7schwebt", "ob", "dem", "be\u00b7gl\u00fcck\u00b7ten", "Land", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "KOUS", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Und keine Spur von Mystizismus,", "tokens": ["Und", "kei\u00b7ne", "Spur", "von", "Mys\u00b7ti\u00b7zis\u00b7mus", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "APPR", "NE", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Von Dunkelm\u00e4nner-Muckerei,", "tokens": ["Von", "Dun\u00b7kel\u00b7m\u00e4n\u00b7ner\u00b7Mu\u00b7cke\u00b7rei", ","], "token_info": ["word", "word", "punct"], "pos": ["APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Selbst Luthertum, Katholizismus", "tokens": ["Selbst", "Lu\u00b7ther\u00b7tum", ",", "Ka\u00b7tho\u00b7li\u00b7zis\u00b7mus"], "token_info": ["word", "word", "punct", "word"], "pos": ["ADV", "NE", "$,", "NN"], "meter": "+-++-+-+-", "measure": "unknown.measure.penta"}, "line.4": {"text": "Und Gar-Nichts galt f\u00fcr einerlei!", "tokens": ["Und", "Ga\u00b7rNichts", "galt", "f\u00fcr", "ei\u00b7ner\u00b7lei", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "APPR", "PIS", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Und Schrift und Wort war freigegeben,", "tokens": ["Und", "Schrift", "und", "Wort", "war", "frei\u00b7ge\u00b7ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "KON", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die Presse seufzte Tag und Nacht,", "tokens": ["Die", "Pres\u00b7se", "seufz\u00b7te", "Tag", "und", "Nacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Jedwede Kraft und jedes Streben,", "tokens": ["Jed\u00b7we\u00b7de", "Kraft", "und", "je\u00b7des", "Stre\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "KON", "PIAT", "NN", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Wenn echt, ward wirksam auch gemacht.", "tokens": ["Wenn", "echt", ",", "ward", "wirk\u00b7sam", "auch", "ge\u00b7macht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJD", "$,", "VAFIN", "ADJD", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Vom K\u00f6nig war nicht viel zu sehen,", "tokens": ["Vom", "K\u00f6\u00b7nig", "war", "nicht", "viel", "zu", "se\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VAFIN", "PTKNEG", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und doch schien er an jedem Ort,", "tokens": ["Und", "doch", "schien", "er", "an", "je\u00b7dem", "Ort", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "APPR", "PIAT", "NN", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.3": {"text": "Und wollt' er wo zu Fu\u00dfe gehen,", "tokens": ["Und", "wollt'", "er", "wo", "zu", "Fu\u00b7\u00dfe", "ge\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "PWAV", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Trug man ihr auf den H\u00e4nden fort.", "tokens": ["Trug", "man", "ihr", "auf", "den", "H\u00e4n\u00b7den", "fort", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PPER", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.9": {"line.1": {"text": "Die St\u00e4nde zeigten so viel Dummheit,", "tokens": ["Die", "St\u00e4n\u00b7de", "zeig\u00b7ten", "so", "viel", "Dumm\u00b7heit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Als guten St\u00e4nden n\u00f6tig tut,", "tokens": ["Als", "gu\u00b7ten", "St\u00e4n\u00b7den", "n\u00f6\u00b7tig", "tut", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "NN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mehr R\u00fchrigkeit und minder Stummheit", "tokens": ["Mehr", "R\u00fch\u00b7rig\u00b7keit", "und", "min\u00b7der", "Stumm\u00b7heit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "KON", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und just den rechten Redemut.", "tokens": ["Und", "just", "den", "rech\u00b7ten", "Re\u00b7de\u00b7mut", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "M\u00e4tressen gab es und Spione", "tokens": ["M\u00e4\u00b7tres\u00b7sen", "gab", "es", "und", "Spi\u00b7o\u00b7ne"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "PPER", "KON", "NN"], "meter": "-+-+--+--", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Als Rarit\u00e4t ein Paar im Land,", "tokens": ["Als", "Ra\u00b7ri\u00b7t\u00e4t", "ein", "Paar", "im", "Land", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "ART", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und f\u00fcr die Zeitung der Barone", "tokens": ["Und", "f\u00fcr", "die", "Zei\u00b7tung", "der", "Ba\u00b7ro\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Im Tollhaus einen Pr\u00e4numerant.", "tokens": ["Im", "Toll\u00b7haus", "ei\u00b7nen", "Pr\u00e4\u00b7nu\u00b7me\u00b7rant", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.11": {"line.1": {"text": "Und Freiheit lag und gr\u00fcner Friede", "tokens": ["Und", "Frei\u00b7heit", "lag", "und", "gr\u00fc\u00b7ner", "Frie\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "NN", "VVFIN", "KON", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und \u00dcberflu\u00df und Lebenslust", "tokens": ["Und", "\u00dc\u00b7berf\u00b7lu\u00df", "und", "Le\u00b7bens\u00b7lust"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wie eine blitzende \u00c4gide", "tokens": ["Wie", "ei\u00b7ne", "blit\u00b7zen\u00b7de", "\u00c4\u00b7gi\u00b7de"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Gar herrlich ob des Reiches Brust.", "tokens": ["Gar", "herr\u00b7lich", "ob", "des", "Rei\u00b7ches", "Brust", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KOUS", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Die Dichter sangen wie sie wollten,", "tokens": ["Die", "Dich\u00b7ter", "san\u00b7gen", "wie", "sie", "woll\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "KOKOM", "PPER", "VMFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Der eine hart, der andre weich,", "tokens": ["Der", "ei\u00b7ne", "hart", ",", "der", "and\u00b7re", "weich", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ART", "ADJD", "$,", "PRELS", "PIS", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und keiner ward darum gescholten,", "tokens": ["Und", "kei\u00b7ner", "ward", "da\u00b7rum", "ge\u00b7schol\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VAFIN", "PAV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "War er nicht einer Schule gleich.", "tokens": ["War", "er", "nicht", "ei\u00b7ner", "Schu\u00b7le", "gleich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PTKNEG", "ART", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Noch hatt' ich, ganz in Schaun verloren,", "tokens": ["Noch", "hatt'", "ich", ",", "ganz", "in", "Schaun", "ver\u00b7lo\u00b7ren", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "$,", "ADV", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Des Besten Laute still gelauscht,", "tokens": ["Des", "Bes\u00b7ten", "Lau\u00b7te", "still", "ge\u00b7lauscht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Als pl\u00f6tzlich, dicht vor meinen Ohren,", "tokens": ["Als", "pl\u00f6tz\u00b7lich", ",", "dicht", "vor", "mei\u00b7nen", "Oh\u00b7ren", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJD", "$,", "ADJD", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ein fremder Klang vernehmlich rauscht.", "tokens": ["Ein", "frem\u00b7der", "Klang", "ver\u00b7nehm\u00b7lich", "rauscht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Ich \u2013 wachte auf \u2013 .. Wo? \u2013 Im Gef\u00e4ngnis,", "tokens": ["Ich", "\u2013", "wach\u00b7te", "auf", "\u2013", "..", "Wo", "?", "\u2013", "Im", "Ge\u00b7f\u00e4ng\u00b7nis", ","], "token_info": ["word", "punct", "word", "word", "punct", "punct", "word", "punct", "punct", "word", "word", "punct"], "pos": ["PPER", "$(", "VVFIN", "APPR", "$(", "$.", "PWAV", "$.", "$(", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Vom Klirrn der Kett' an meinem Fu\u00df ...", "tokens": ["Vom", "Klirrn", "der", "Kett'", "an", "mei\u00b7nem", "Fu\u00df", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "APPR", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "O ungl\u00fcckseliges Verh\u00e4ngnis!", "tokens": ["O", "un\u00b7gl\u00fcck\u00b7se\u00b7li\u00b7ges", "Ver\u00b7h\u00e4ng\u00b7nis", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$."], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Da\u00df man auch stets erwachen mu\u00df!", "tokens": ["Da\u00df", "man", "auch", "stets", "er\u00b7wa\u00b7chen", "mu\u00df", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ADV", "ADV", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "Vor meinem Fenster stund das Gitter", "tokens": ["Vor", "mei\u00b7nem", "Fens\u00b7ter", "stund", "das", "Git\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "So fest wie fr\u00fcher in der Mauer,", "tokens": ["So", "fest", "wie", "fr\u00fc\u00b7her", "in", "der", "Mau\u00b7er", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KOKOM", "ADJD", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und \u00fcber mir sang \u2013 ohne Zither! \u2013", "tokens": ["Und", "\u00fc\u00b7ber", "mir", "sang", "\u2013", "oh\u00b7ne", "Zi\u00b7ther", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["KON", "APPR", "PPER", "VVFIN", "$(", "APPR", "NN", "$.", "$("], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Ein Strauchdieb seinen Gassenhauer.", "tokens": ["Ein", "Strauch\u00b7dieb", "sei\u00b7nen", "Gas\u00b7sen\u00b7hau\u00b7er", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "Ein K\u00f6nigreich hab' ich gesehen,", "tokens": ["Ein", "K\u00f6\u00b7nig\u00b7reich", "hab'", "ich", "ge\u00b7se\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "So eins gibt's auf der Welt nicht mehr:", "tokens": ["So", "eins", "gibt's", "auf", "der", "Welt", "nicht", "mehr", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "VVFIN", "APPR", "ART", "NN", "PTKNEG", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mit offnem Munde blieb ich stehen,", "tokens": ["Mit", "off\u00b7nem", "Mun\u00b7de", "blieb", "ich", "ste\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und sah und staunte rings umher.", "tokens": ["Und", "sah", "und", "staun\u00b7te", "rings", "um\u00b7her", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "KON", "VVFIN", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.17": {"line.1": {"text": "Das war ein Wohlsein allerwegen", "tokens": ["Das", "war", "ein", "Wohl\u00b7sein", "al\u00b7ler\u00b7we\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "ART", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "In Haus und Hof, zu Stadt und Land,", "tokens": ["In", "Haus", "und", "Hof", ",", "zu", "Stadt", "und", "Land", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$,", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ein rechter reicher Gottes-Segen,", "tokens": ["Ein", "rech\u00b7ter", "rei\u00b7cher", "Got\u00b7tes\u00b7Se\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJD", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wie ihn mein Auge nirgends fand.", "tokens": ["Wie", "ihn", "mein", "Au\u00b7ge", "nir\u00b7gends", "fand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PPOSAT", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.18": {"line.1": {"text": "Die Stra\u00dfen statt von Kriegsmilizen", "tokens": ["Die", "Stra\u00b7\u00dfen", "statt", "von", "Kriegs\u00b7mi\u00b7li\u00b7zen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Waren von B\u00fcrgern reich belebt,", "tokens": ["Wa\u00b7ren", "von", "B\u00fcr\u00b7gern", "reich", "be\u00b7lebt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "NN", "ADJD", "VVPP", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Der Hafen hat von Mastenspitzen,", "tokens": ["Der", "Ha\u00b7fen", "hat", "von", "Mas\u00b7ten\u00b7spit\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Von R\u00e4dern die Chauss\u00e9e gebebt.", "tokens": ["Von", "R\u00e4\u00b7dern", "die", "Chaus\u00b7s\u00e9e", "ge\u00b7bebt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.19": {"line.1": {"text": "Von Polizei- und Amts-Verboten,", "tokens": ["Von", "Po\u00b7li\u00b7zei", "und", "Amts\u00b7Ver\u00b7bo\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "TRUNC", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Von Maut-Tarif und Br\u00fcckengeld,", "tokens": ["Von", "Maut\u00b7Ta\u00b7rif", "und", "Br\u00fc\u00b7cken\u00b7geld", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Schlagbaum und andren Schwerenoten", "tokens": ["Schlag\u00b7baum", "und", "an\u00b7dren", "Schwe\u00b7re\u00b7no\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "KON", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "War auch nicht eine ausgestellt.", "tokens": ["War", "auch", "nicht", "ei\u00b7ne", "aus\u00b7ge\u00b7stellt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PTKNEG", "ART", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.20": {"line.1": {"text": "Und drinnen? \u2013 O da hat ein Glaube", "tokens": ["Und", "drin\u00b7nen", "?", "\u2013", "O", "da", "hat", "ein", "Glau\u00b7be"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "$.", "$(", "NE", "ADV", "VAFIN", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ganz ohne Pfaff und Priesterstand", "tokens": ["Ganz", "oh\u00b7ne", "Pfaff", "und", "Pries\u00b7ter\u00b7stand"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "NE", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Leuchtend, wie einst des Geistes Taube,", "tokens": ["Leuch\u00b7tend", ",", "wie", "einst", "des", "Geis\u00b7tes", "Tau\u00b7be", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PWAV", "ADV", "ART", "NN", "NN", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Geschwebt ob dem begl\u00fcckten Land.", "tokens": ["Ge\u00b7schwebt", "ob", "dem", "be\u00b7gl\u00fcck\u00b7ten", "Land", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "KOUS", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.21": {"line.1": {"text": "Und keine Spur von Mystizismus,", "tokens": ["Und", "kei\u00b7ne", "Spur", "von", "Mys\u00b7ti\u00b7zis\u00b7mus", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "APPR", "NE", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Von Dunkelm\u00e4nner-Muckerei,", "tokens": ["Von", "Dun\u00b7kel\u00b7m\u00e4n\u00b7ner\u00b7Mu\u00b7cke\u00b7rei", ","], "token_info": ["word", "word", "punct"], "pos": ["APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Selbst Luthertum, Katholizismus", "tokens": ["Selbst", "Lu\u00b7ther\u00b7tum", ",", "Ka\u00b7tho\u00b7li\u00b7zis\u00b7mus"], "token_info": ["word", "word", "punct", "word"], "pos": ["ADV", "NE", "$,", "NN"], "meter": "+-++-+-+-", "measure": "unknown.measure.penta"}, "line.4": {"text": "Und Gar-Nichts galt f\u00fcr einerlei!", "tokens": ["Und", "Ga\u00b7rNichts", "galt", "f\u00fcr", "ei\u00b7ner\u00b7lei", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "APPR", "PIS", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.22": {"line.1": {"text": "Und Schrift und Wort war freigegeben,", "tokens": ["Und", "Schrift", "und", "Wort", "war", "frei\u00b7ge\u00b7ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "KON", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die Presse seufzte Tag und Nacht,", "tokens": ["Die", "Pres\u00b7se", "seufz\u00b7te", "Tag", "und", "Nacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Jedwede Kraft und jedes Streben,", "tokens": ["Jed\u00b7we\u00b7de", "Kraft", "und", "je\u00b7des", "Stre\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "KON", "PIAT", "NN", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Wenn echt, ward wirksam auch gemacht.", "tokens": ["Wenn", "echt", ",", "ward", "wirk\u00b7sam", "auch", "ge\u00b7macht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJD", "$,", "VAFIN", "ADJD", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.23": {"line.1": {"text": "Vom K\u00f6nig war nicht viel zu sehen,", "tokens": ["Vom", "K\u00f6\u00b7nig", "war", "nicht", "viel", "zu", "se\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VAFIN", "PTKNEG", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und doch schien er an jedem Ort,", "tokens": ["Und", "doch", "schien", "er", "an", "je\u00b7dem", "Ort", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "APPR", "PIAT", "NN", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.3": {"text": "Und wollt' er wo zu Fu\u00dfe gehen,", "tokens": ["Und", "wollt'", "er", "wo", "zu", "Fu\u00b7\u00dfe", "ge\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "PWAV", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Trug man ihr auf den H\u00e4nden fort.", "tokens": ["Trug", "man", "ihr", "auf", "den", "H\u00e4n\u00b7den", "fort", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PPER", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.24": {"line.1": {"text": "Die St\u00e4nde zeigten so viel Dummheit,", "tokens": ["Die", "St\u00e4n\u00b7de", "zeig\u00b7ten", "so", "viel", "Dumm\u00b7heit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Als guten St\u00e4nden n\u00f6tig tut,", "tokens": ["Als", "gu\u00b7ten", "St\u00e4n\u00b7den", "n\u00f6\u00b7tig", "tut", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "NN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mehr R\u00fchrigkeit und minder Stummheit", "tokens": ["Mehr", "R\u00fch\u00b7rig\u00b7keit", "und", "min\u00b7der", "Stumm\u00b7heit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "KON", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und just den rechten Redemut.", "tokens": ["Und", "just", "den", "rech\u00b7ten", "Re\u00b7de\u00b7mut", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.25": {"line.1": {"text": "M\u00e4tressen gab es und Spione", "tokens": ["M\u00e4\u00b7tres\u00b7sen", "gab", "es", "und", "Spi\u00b7o\u00b7ne"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "PPER", "KON", "NN"], "meter": "-+-+--+--", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Als Rarit\u00e4t ein Paar im Land,", "tokens": ["Als", "Ra\u00b7ri\u00b7t\u00e4t", "ein", "Paar", "im", "Land", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "ART", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und f\u00fcr die Zeitung der Barone", "tokens": ["Und", "f\u00fcr", "die", "Zei\u00b7tung", "der", "Ba\u00b7ro\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Im Tollhaus einen Pr\u00e4numerant.", "tokens": ["Im", "Toll\u00b7haus", "ei\u00b7nen", "Pr\u00e4\u00b7nu\u00b7me\u00b7rant", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.26": {"line.1": {"text": "Und Freiheit lag und gr\u00fcner Friede", "tokens": ["Und", "Frei\u00b7heit", "lag", "und", "gr\u00fc\u00b7ner", "Frie\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "NN", "VVFIN", "KON", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und \u00dcberflu\u00df und Lebenslust", "tokens": ["Und", "\u00dc\u00b7berf\u00b7lu\u00df", "und", "Le\u00b7bens\u00b7lust"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wie eine blitzende \u00c4gide", "tokens": ["Wie", "ei\u00b7ne", "blit\u00b7zen\u00b7de", "\u00c4\u00b7gi\u00b7de"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Gar herrlich ob des Reiches Brust.", "tokens": ["Gar", "herr\u00b7lich", "ob", "des", "Rei\u00b7ches", "Brust", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KOUS", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.27": {"line.1": {"text": "Die Dichter sangen wie sie wollten,", "tokens": ["Die", "Dich\u00b7ter", "san\u00b7gen", "wie", "sie", "woll\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "KOKOM", "PPER", "VMFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Der eine hart, der andre weich,", "tokens": ["Der", "ei\u00b7ne", "hart", ",", "der", "and\u00b7re", "weich", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ART", "ADJD", "$,", "PRELS", "PIS", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und keiner ward darum gescholten,", "tokens": ["Und", "kei\u00b7ner", "ward", "da\u00b7rum", "ge\u00b7schol\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VAFIN", "PAV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "War er nicht einer Schule gleich.", "tokens": ["War", "er", "nicht", "ei\u00b7ner", "Schu\u00b7le", "gleich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PTKNEG", "ART", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.28": {"line.1": {"text": "Noch hatt' ich, ganz in Schaun verloren,", "tokens": ["Noch", "hatt'", "ich", ",", "ganz", "in", "Schaun", "ver\u00b7lo\u00b7ren", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "$,", "ADV", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Des Besten Laute still gelauscht,", "tokens": ["Des", "Bes\u00b7ten", "Lau\u00b7te", "still", "ge\u00b7lauscht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Als pl\u00f6tzlich, dicht vor meinen Ohren,", "tokens": ["Als", "pl\u00f6tz\u00b7lich", ",", "dicht", "vor", "mei\u00b7nen", "Oh\u00b7ren", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJD", "$,", "ADJD", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ein fremder Klang vernehmlich rauscht.", "tokens": ["Ein", "frem\u00b7der", "Klang", "ver\u00b7nehm\u00b7lich", "rauscht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.29": {"line.1": {"text": "Ich \u2013 wachte auf \u2013 .. Wo? \u2013 Im Gef\u00e4ngnis,", "tokens": ["Ich", "\u2013", "wach\u00b7te", "auf", "\u2013", "..", "Wo", "?", "\u2013", "Im", "Ge\u00b7f\u00e4ng\u00b7nis", ","], "token_info": ["word", "punct", "word", "word", "punct", "punct", "word", "punct", "punct", "word", "word", "punct"], "pos": ["PPER", "$(", "VVFIN", "APPR", "$(", "$.", "PWAV", "$.", "$(", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Vom Klirrn der Kett' an meinem Fu\u00df ...", "tokens": ["Vom", "Klirrn", "der", "Kett'", "an", "mei\u00b7nem", "Fu\u00df", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "APPR", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "O ungl\u00fcckseliges Verh\u00e4ngnis!", "tokens": ["O", "un\u00b7gl\u00fcck\u00b7se\u00b7li\u00b7ges", "Ver\u00b7h\u00e4ng\u00b7nis", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$."], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Da\u00df man auch stets erwachen mu\u00df!", "tokens": ["Da\u00df", "man", "auch", "stets", "er\u00b7wa\u00b7chen", "mu\u00df", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ADV", "ADV", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.30": {"line.1": {"text": "Vor meinem Fenster stund das Gitter", "tokens": ["Vor", "mei\u00b7nem", "Fens\u00b7ter", "stund", "das", "Git\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "So fest wie fr\u00fcher in der Mauer,", "tokens": ["So", "fest", "wie", "fr\u00fc\u00b7her", "in", "der", "Mau\u00b7er", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KOKOM", "ADJD", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und \u00fcber mir sang \u2013 ohne Zither! \u2013", "tokens": ["Und", "\u00fc\u00b7ber", "mir", "sang", "\u2013", "oh\u00b7ne", "Zi\u00b7ther", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["KON", "APPR", "PPER", "VVFIN", "$(", "APPR", "NN", "$.", "$("], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Ein Strauchdieb seinen Gassenhauer.", "tokens": ["Ein", "Strauch\u00b7dieb", "sei\u00b7nen", "Gas\u00b7sen\u00b7hau\u00b7er", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}