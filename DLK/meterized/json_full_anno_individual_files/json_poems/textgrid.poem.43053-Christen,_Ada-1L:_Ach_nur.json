{"textgrid.poem.43053": {"metadata": {"author": {"name": "Christen, Ada", "birth": "N.A.", "death": "N.A."}, "title": "1L: Ach nur ", "genre": "verse", "period": "N.A.", "pub_year": 1870, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ach nur ", "tokens": ["Ach", "nur"], "token_info": ["word", "word"], "pos": ["ITJ", "ADV"], "meter": "+-", "measure": "trochaic.single"}, "line.2": {"text": "Noch in deine Arme hin,", "tokens": ["Noch", "in", "dei\u00b7ne", "Ar\u00b7me", "hin", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und nur ", "tokens": ["Und", "nur"], "token_info": ["word", "word"], "pos": ["KON", "ADV"], "meter": "-+", "measure": "iambic.single"}, "line.4": {"text": "Was ich war und was ich bin!", "tokens": ["Was", "ich", "war", "und", "was", "ich", "bin", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VAFIN", "KON", "PWS", "PPER", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Ach nur ", "tokens": ["Ach", "nur"], "token_info": ["word", "word"], "pos": ["ITJ", "ADV"], "meter": "+-", "measure": "trochaic.single"}, "line.2": {"text": "Wie du einst gewesen bist;", "tokens": ["Wie", "du", "einst", "ge\u00b7we\u00b7sen", "bist", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "VAPP", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und dann Alles wieder leiden,", "tokens": ["Und", "dann", "Al\u00b7les", "wie\u00b7der", "lei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PIS", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Was schon war und was noch ist.", "tokens": ["Was", "schon", "war", "und", "was", "noch", "ist", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "VAFIN", "KON", "PWS", "ADV", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Ach nur ", "tokens": ["Ach", "nur"], "token_info": ["word", "word"], "pos": ["ITJ", "ADV"], "meter": "+-", "measure": "trochaic.single"}, "line.2": {"text": "Noch in deine Arme hin,", "tokens": ["Noch", "in", "dei\u00b7ne", "Ar\u00b7me", "hin", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und nur ", "tokens": ["Und", "nur"], "token_info": ["word", "word"], "pos": ["KON", "ADV"], "meter": "-+", "measure": "iambic.single"}, "line.4": {"text": "Was ich war und was ich bin!", "tokens": ["Was", "ich", "war", "und", "was", "ich", "bin", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VAFIN", "KON", "PWS", "PPER", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Ach nur ", "tokens": ["Ach", "nur"], "token_info": ["word", "word"], "pos": ["ITJ", "ADV"], "meter": "+-", "measure": "trochaic.single"}, "line.2": {"text": "Wie du einst gewesen bist;", "tokens": ["Wie", "du", "einst", "ge\u00b7we\u00b7sen", "bist", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "VAPP", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und dann Alles wieder leiden,", "tokens": ["Und", "dann", "Al\u00b7les", "wie\u00b7der", "lei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PIS", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Was schon war und was noch ist.", "tokens": ["Was", "schon", "war", "und", "was", "noch", "ist", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "VAFIN", "KON", "PWS", "ADV", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}