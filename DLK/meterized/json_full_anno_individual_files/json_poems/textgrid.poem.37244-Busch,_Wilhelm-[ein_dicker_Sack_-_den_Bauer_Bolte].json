{"textgrid.poem.37244": {"metadata": {"author": {"name": "Busch, Wilhelm", "birth": "N.A.", "death": "N.A."}, "title": "[ein dicker Sack - den Bauer Bolte]", "genre": "verse", "period": "N.A.", "pub_year": 1870, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ein dicker Sack \u2013 den Bauer Bolte,", "tokens": ["Ein", "di\u00b7cker", "Sack", "\u2013", "den", "Bau\u00b7er", "Bol\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$(", "ART", "NN", "NE", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Der ihn zur M\u00fchle tragen wollte,", "tokens": ["Der", "ihn", "zur", "M\u00fch\u00b7le", "tra\u00b7gen", "woll\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPRART", "NN", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Um auszuruhn, mal hingestellt", "tokens": ["Um", "aus\u00b7zu\u00b7ruhn", ",", "mal", "hin\u00b7ge\u00b7stellt"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["KOUI", "VVIZU", "$,", "ADV", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Dicht an ein reifes \u00c4hrenfeld \u2013", "tokens": ["Dicht", "an", "ein", "rei\u00b7fes", "\u00c4h\u00b7ren\u00b7feld", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Legt sich in w\u00fcrdevolle Falten", "tokens": ["Legt", "sich", "in", "w\u00fcr\u00b7de\u00b7vol\u00b7le", "Fal\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PRF", "APPR", "ADJA", "NN"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.6": {"text": "Und f\u00e4ngt 'ne Rede an zu halten.", "tokens": ["Und", "f\u00e4ngt", "'ne", "Re\u00b7de", "an", "zu", "hal\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "APZR", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Ich, sprach er, bin der volle Sack.", "tokens": ["Ich", ",", "sprach", "er", ",", "bin", "der", "vol\u00b7le", "Sack", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "VVFIN", "PPER", "$,", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ihr \u00c4hren seid nur d\u00fcnnes Pack.", "tokens": ["Ihr", "\u00c4h\u00b7ren", "seid", "nur", "d\u00fcn\u00b7nes", "Pack", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADV", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ich bin's, der euch auf dieser Welt", "tokens": ["Ich", "bin's", ",", "der", "euch", "auf", "die\u00b7ser", "Welt"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "$,", "PRELS", "PPER", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "In Einigkeit zusammenh\u00e4lt.", "tokens": ["In", "Ei\u00b7nig\u00b7keit", "zu\u00b7sam\u00b7men\u00b7h\u00e4lt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ich bin's, der hoch vonn\u00f6ten ist,", "tokens": ["Ich", "bin's", ",", "der", "hoch", "von\u00b7n\u00f6\u00b7ten", "ist", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "PRELS", "ADJD", "ADV", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Da\u00df euch das Federvieh nicht fri\u00dft;", "tokens": ["Da\u00df", "euch", "das", "Fe\u00b7der\u00b7vieh", "nicht", "fri\u00dft", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Ich, dessen hohe Fassungskraft", "tokens": ["Ich", ",", "des\u00b7sen", "ho\u00b7he", "Fas\u00b7sungs\u00b7kraft"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["PPER", "$,", "PRELAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Euch schlie\u00dflich in die M\u00fchle schafft.", "tokens": ["Euch", "schlie\u00df\u00b7lich", "in", "die", "M\u00fch\u00b7le", "schafft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Verneigt euch tief, denn ich bin Der!", "tokens": ["Ver\u00b7neigt", "euch", "tief", ",", "denn", "ich", "bin", "Der", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "$,", "KON", "PPER", "VAFIN", "ART", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Was w\u00e4ret ihr, wenn ich nicht w\u00e4r?", "tokens": ["Was", "w\u00e4\u00b7ret", "ihr", ",", "wenn", "ich", "nicht", "w\u00e4r", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "$,", "KOUS", "PPER", "PTKNEG", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Sanft rauschen die \u00c4hren:", "tokens": ["Sanft", "rau\u00b7schen", "die", "\u00c4h\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ART", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.3": {"line.1": {"text": "Du w\u00e4rst ein leerer Schlauch, wenn wir nicht w\u00e4ren.", "tokens": ["Du", "w\u00e4rst", "ein", "lee\u00b7rer", "Schlauch", ",", "wenn", "wir", "nicht", "w\u00e4\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "$,", "KOUS", "PPER", "PTKNEG", "VAFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Ein dicker Sack \u2013 den Bauer Bolte,", "tokens": ["Ein", "di\u00b7cker", "Sack", "\u2013", "den", "Bau\u00b7er", "Bol\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$(", "ART", "NN", "NE", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Der ihn zur M\u00fchle tragen wollte,", "tokens": ["Der", "ihn", "zur", "M\u00fch\u00b7le", "tra\u00b7gen", "woll\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPRART", "NN", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Um auszuruhn, mal hingestellt", "tokens": ["Um", "aus\u00b7zu\u00b7ruhn", ",", "mal", "hin\u00b7ge\u00b7stellt"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["KOUI", "VVIZU", "$,", "ADV", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Dicht an ein reifes \u00c4hrenfeld \u2013", "tokens": ["Dicht", "an", "ein", "rei\u00b7fes", "\u00c4h\u00b7ren\u00b7feld", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Legt sich in w\u00fcrdevolle Falten", "tokens": ["Legt", "sich", "in", "w\u00fcr\u00b7de\u00b7vol\u00b7le", "Fal\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PRF", "APPR", "ADJA", "NN"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.6": {"text": "Und f\u00e4ngt 'ne Rede an zu halten.", "tokens": ["Und", "f\u00e4ngt", "'ne", "Re\u00b7de", "an", "zu", "hal\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "APZR", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Ich, sprach er, bin der volle Sack.", "tokens": ["Ich", ",", "sprach", "er", ",", "bin", "der", "vol\u00b7le", "Sack", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "VVFIN", "PPER", "$,", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ihr \u00c4hren seid nur d\u00fcnnes Pack.", "tokens": ["Ihr", "\u00c4h\u00b7ren", "seid", "nur", "d\u00fcn\u00b7nes", "Pack", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADV", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ich bin's, der euch auf dieser Welt", "tokens": ["Ich", "bin's", ",", "der", "euch", "auf", "die\u00b7ser", "Welt"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "$,", "PRELS", "PPER", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "In Einigkeit zusammenh\u00e4lt.", "tokens": ["In", "Ei\u00b7nig\u00b7keit", "zu\u00b7sam\u00b7men\u00b7h\u00e4lt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ich bin's, der hoch vonn\u00f6ten ist,", "tokens": ["Ich", "bin's", ",", "der", "hoch", "von\u00b7n\u00f6\u00b7ten", "ist", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "PRELS", "ADJD", "ADV", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Da\u00df euch das Federvieh nicht fri\u00dft;", "tokens": ["Da\u00df", "euch", "das", "Fe\u00b7der\u00b7vieh", "nicht", "fri\u00dft", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Ich, dessen hohe Fassungskraft", "tokens": ["Ich", ",", "des\u00b7sen", "ho\u00b7he", "Fas\u00b7sungs\u00b7kraft"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["PPER", "$,", "PRELAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Euch schlie\u00dflich in die M\u00fchle schafft.", "tokens": ["Euch", "schlie\u00df\u00b7lich", "in", "die", "M\u00fch\u00b7le", "schafft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Verneigt euch tief, denn ich bin Der!", "tokens": ["Ver\u00b7neigt", "euch", "tief", ",", "denn", "ich", "bin", "Der", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "$,", "KON", "PPER", "VAFIN", "ART", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Was w\u00e4ret ihr, wenn ich nicht w\u00e4r?", "tokens": ["Was", "w\u00e4\u00b7ret", "ihr", ",", "wenn", "ich", "nicht", "w\u00e4r", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "$,", "KOUS", "PPER", "PTKNEG", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Sanft rauschen die \u00c4hren:", "tokens": ["Sanft", "rau\u00b7schen", "die", "\u00c4h\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ART", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.6": {"line.1": {"text": "Du w\u00e4rst ein leerer Schlauch, wenn wir nicht w\u00e4ren.", "tokens": ["Du", "w\u00e4rst", "ein", "lee\u00b7rer", "Schlauch", ",", "wenn", "wir", "nicht", "w\u00e4\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "$,", "KOUS", "PPER", "PTKNEG", "VAFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}}}}