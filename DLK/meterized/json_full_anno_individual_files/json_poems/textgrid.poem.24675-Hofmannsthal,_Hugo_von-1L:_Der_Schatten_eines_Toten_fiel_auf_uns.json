{"textgrid.poem.24675": {"metadata": {"author": {"name": "Hofmannsthal, Hugo von", "birth": "N.A.", "death": "N.A."}, "title": "1L: Der Schatten eines Toten fiel auf uns", "genre": "verse", "period": "N.A.", "pub_year": 1891, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Der Schatten eines Toten fiel auf uns", "tokens": ["Der", "Schat\u00b7ten", "ei\u00b7nes", "To\u00b7ten", "fiel", "auf", "uns"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "NN", "VVFIN", "APPR", "PPER"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Und einer K\u00fcnstlerseele letzter Kampf,", "tokens": ["Und", "ei\u00b7ner", "K\u00fcnst\u00b7ler\u00b7see\u00b7le", "letz\u00b7ter", "Kampf", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Der Seele, die sich sterben zugesehn", "tokens": ["Der", "See\u00b7le", ",", "die", "sich", "ster\u00b7ben", "zu\u00b7ge\u00b7sehn"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "PRF", "VVINF", "VVINF"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Und die noch malen wollte ihren Krampf.", "tokens": ["Und", "die", "noch", "ma\u00b7len", "woll\u00b7te", "ih\u00b7ren", "Krampf", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADV", "VVINF", "VMFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Und uns durchzitterte die b\u00f6se Gier,", "tokens": ["Und", "uns", "durch\u00b7zit\u00b7ter\u00b7te", "die", "b\u00f6\u00b7se", "Gier", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Nachzuempfinden dieses Toten Graun,", "tokens": ["Nach\u00b7zu\u00b7em\u00b7pfin\u00b7den", "die\u00b7ses", "To\u00b7ten", "Graun", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PDAT", "NN", "NE", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Als k\u00f6nnten wir durch sein gebrochnes Aug", "tokens": ["Als", "k\u00f6nn\u00b7ten", "wir", "durch", "sein", "ge\u00b7broch\u00b7nes", "Aug"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "VMFIN", "PPER", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Die tiefgeheimen Lebensgr\u00fcnde schaun.", "tokens": ["Die", "tief\u00b7ge\u00b7hei\u00b7men", "Le\u00b7bens\u00b7gr\u00fcn\u00b7de", "schaun", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Und wie ein Sterbender sich st\u00f6hnend w\u00e4lzt", "tokens": ["Und", "wie", "ein", "Ster\u00b7ben\u00b7der", "sich", "st\u00f6h\u00b7nend", "w\u00e4lzt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "ART", "NN", "PRF", "ADJD", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Und seine Decken zuckend von sich st\u00f6\u00dft,", "tokens": ["Und", "sei\u00b7ne", "De\u00b7cken", "zu\u00b7ckend", "von", "sich", "st\u00f6\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVPP", "APPR", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "So hatte ", "tokens": ["So", "hat\u00b7te"], "token_info": ["word", "word"], "pos": ["ADV", "VAFIN"], "meter": "-+-", "measure": "amphibrach.single"}, "line.4": {"text": "Verh\u00fcllte Qual, bet\u00e4ubte Qual entbl\u00f6\u00dft.", "tokens": ["Ver\u00b7h\u00fcll\u00b7te", "Qual", ",", "be\u00b7t\u00e4ub\u00b7te", "Qual", "ent\u00b7bl\u00f6\u00dft", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Unsagbar widerw\u00e4rtig quoll es auf,", "tokens": ["Un\u00b7sag\u00b7bar", "wi\u00b7der\u00b7w\u00e4r\u00b7tig", "quoll", "es", "auf", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADJD", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.2": {"text": "Wie Wellen, Ekelwellen brachs herein,", "tokens": ["Wie", "Wel\u00b7len", ",", "E\u00b7kel\u00b7wel\u00b7len", "brachs", "her\u00b7ein", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "$,", "NN", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "So sinnlos leer und frierend kalt und \u00f6d,", "tokens": ["So", "sinn\u00b7los", "leer", "und", "frie\u00b7rend", "kalt", "und", "\u00f6d", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ADJD", "KON", "ADJD", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Ein Atemzug der \u00fcberreichsten Pein:", "tokens": ["Ein", "A\u00b7tem\u00b7zug", "der", "\u00fc\u00b7berr\u00b7eichs\u00b7ten", "Pein", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "Als w\u00e4r des Lebens Inhalt ausgel\u00f6scht,", "tokens": ["Als", "w\u00e4r", "des", "Le\u00b7bens", "In\u00b7halt", "aus\u00b7ge\u00b7l\u00f6scht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VAFIN", "ART", "NN", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Das Heiligste gel\u00f6st in Qualm und Dunst ...", "tokens": ["Das", "Hei\u00b7ligs\u00b7te", "ge\u00b7l\u00f6st", "in", "Qualm", "und", "Dunst", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Verstehn, Gestalten, K\u00fcnstler sein, wozu?", "tokens": ["Ver\u00b7stehn", ",", "Ge\u00b7stal\u00b7ten", ",", "K\u00fcnst\u00b7ler", "sein", ",", "wo\u00b7zu", "?"], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["VVFIN", "$,", "NN", "$,", "NN", "VAINF", "$,", "PWAV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Wozu denn Leben? und wozu die Kunst?", "tokens": ["Wo\u00b7zu", "denn", "Le\u00b7ben", "?", "und", "wo\u00b7zu", "die", "Kunst", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "KON", "NN", "$.", "KON", "PWAV", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "Erlognes an Erlognes, Wort an Wort", "tokens": ["Er\u00b7log\u00b7nes", "an", "Er\u00b7log\u00b7nes", ",", "Wort", "an", "Wort"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["FM.la", "FM.la", "FM.la", "$,", "NN", "APPR", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Wie bunte Steinchen aneinanderreihn!", "tokens": ["Wie", "bun\u00b7te", "Stein\u00b7chen", "an\u00b7ein\u00b7an\u00b7der\u00b7reihn", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Was wissen wir, wodurchs zusammenh\u00e4lt;", "tokens": ["Was", "wis\u00b7sen", "wir", ",", "wo\u00b7durchs", "zu\u00b7sam\u00b7men\u00b7h\u00e4lt", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "$,", "PWAV", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Und mu\u00df es so, und kann nicht anders sein?!", "tokens": ["Und", "mu\u00df", "es", "so", ",", "und", "kann", "nicht", "an\u00b7ders", "sein", "?!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "ADV", "$,", "KON", "VMFIN", "PTKNEG", "ADV", "VAINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.7": {"line.1": {"text": "Und w\u00e4r der Blick, mit dem wir es erschaun,", "tokens": ["Und", "w\u00e4r", "der", "Blick", ",", "mit", "dem", "wir", "es", "er\u00b7schaun", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ART", "NN", "$,", "APPR", "PRELS", "PPER", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Nur unser, unser der ertr\u00e4umte Schein!", "tokens": ["Nur", "un\u00b7ser", ",", "un\u00b7ser", "der", "er\u00b7tr\u00e4um\u00b7te", "Schein", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "PPOSAT", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Er ist es nicht, und was ich denke, ist,", "tokens": ["Er", "ist", "es", "nicht", ",", "und", "was", "ich", "den\u00b7ke", ",", "ist", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "PTKNEG", "$,", "KON", "PWS", "PPER", "VVFIN", "$,", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Ja, dieser Schrei ist Nachhall, ist nicht mein!", "tokens": ["Ja", ",", "die\u00b7ser", "Schrei", "ist", "Nach\u00b7hall", ",", "ist", "nicht", "mein", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PDAT", "NN", "VAFIN", "NN", "$,", "VAFIN", "PTKNEG", "PPOSAT", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.8": {"line.1": {"text": "Nur eins ist mein, wie's auch dem Tier geh\u00f6rt,", "tokens": ["Nur", "eins", "ist", "mein", ",", "wie's", "auch", "dem", "Tier", "ge\u00b7h\u00f6rt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "VAFIN", "PPOSAT", "$,", "VVFIN", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Ist nicht gespenstisch, keinem nachgef\u00fchlt;", "tokens": ["Ist", "nicht", "ge\u00b7spens\u00b7tisch", ",", "kei\u00b7nem", "nach\u00b7ge\u00b7f\u00fchlt", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "PTKNEG", "ADJD", "$,", "PIS", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Da\u00df mich bei deiner trostverschlo\u00dfnen Angst", "tokens": ["Da\u00df", "mich", "bei", "dei\u00b7ner", "trost\u00b7ver\u00b7schlo\u00df\u00b7nen", "Angst"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Ein seltsam dumpfes Mitleid hat durchw\u00fchlt.", "tokens": ["Ein", "selt\u00b7sam", "dum\u00b7pfes", "Mit\u00b7leid", "hat", "durch\u00b7w\u00fchlt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "ADJA", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.9": {"line.1": {"text": "Und da\u00df ich, selber ohne Trost und Rat,", "tokens": ["Und", "da\u00df", "ich", ",", "sel\u00b7ber", "oh\u00b7ne", "Trost", "und", "Rat", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "$,", "ADV", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Dich tr\u00f6sten wollte, wie ein Kind ein Kind,", "tokens": ["Dich", "tr\u00f6s\u00b7ten", "woll\u00b7te", ",", "wie", "ein", "Kind", "ein", "Kind", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVINF", "VMFIN", "$,", "PWAV", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Das nichts von unverstandnem Kummer wei\u00df,", "tokens": ["Das", "nichts", "von", "un\u00b7ver\u00b7stand\u00b7nem", "Kum\u00b7mer", "wei\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PIS", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Von Dingen, die unfa\u00dfbar in uns sind.", "tokens": ["Von", "Din\u00b7gen", ",", "die", "un\u00b7fa\u00df\u00b7bar", "in", "uns", "sind", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "PRELS", "ADJD", "APPR", "PPER", "VAFIN", "$."], "meter": "-+--+---+-", "measure": "iambic.tri.relaxed"}}, "stanza.10": {"line.1": {"text": "Das ist vielleicht das Letzte was uns bleibt,", "tokens": ["Das", "ist", "viel\u00b7leicht", "das", "Letz\u00b7te", "was", "uns", "bleibt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "ART", "ADJA", "PWS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Wenn der Gedanke ungedacht schon l\u00fcgt:", "tokens": ["Wenn", "der", "Ge\u00b7dan\u00b7ke", "un\u00b7ge\u00b7dacht", "schon", "l\u00fcgt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ADJD", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Da\u00df auf ein zitternd Herz das andre lauscht", "tokens": ["Da\u00df", "auf", "ein", "zit\u00b7ternd", "Herz", "das", "and\u00b7re", "lauscht"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "APPR", "ART", "ADJD", "NN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Und leisen Drucks zur Hand die Hand sich f\u00fcgt ...", "tokens": ["Und", "lei\u00b7sen", "Drucks", "zur", "Hand", "die", "Hand", "sich", "f\u00fcgt", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "APPRART", "NN", "ART", "NN", "PRF", "VVFIN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.11": {"line.1": {"text": "Der Schatten eines Toten fiel auf uns", "tokens": ["Der", "Schat\u00b7ten", "ei\u00b7nes", "To\u00b7ten", "fiel", "auf", "uns"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "NN", "VVFIN", "APPR", "PPER"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Und einer K\u00fcnstlerseele letzter Kampf,", "tokens": ["Und", "ei\u00b7ner", "K\u00fcnst\u00b7ler\u00b7see\u00b7le", "letz\u00b7ter", "Kampf", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Der Seele, die sich sterben zugesehn", "tokens": ["Der", "See\u00b7le", ",", "die", "sich", "ster\u00b7ben", "zu\u00b7ge\u00b7sehn"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "PRF", "VVINF", "VVINF"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Und die noch malen wollte ihren Krampf.", "tokens": ["Und", "die", "noch", "ma\u00b7len", "woll\u00b7te", "ih\u00b7ren", "Krampf", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADV", "VVINF", "VMFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.12": {"line.1": {"text": "Und uns durchzitterte die b\u00f6se Gier,", "tokens": ["Und", "uns", "durch\u00b7zit\u00b7ter\u00b7te", "die", "b\u00f6\u00b7se", "Gier", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Nachzuempfinden dieses Toten Graun,", "tokens": ["Nach\u00b7zu\u00b7em\u00b7pfin\u00b7den", "die\u00b7ses", "To\u00b7ten", "Graun", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PDAT", "NN", "NE", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Als k\u00f6nnten wir durch sein gebrochnes Aug", "tokens": ["Als", "k\u00f6nn\u00b7ten", "wir", "durch", "sein", "ge\u00b7broch\u00b7nes", "Aug"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "VMFIN", "PPER", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Die tiefgeheimen Lebensgr\u00fcnde schaun.", "tokens": ["Die", "tief\u00b7ge\u00b7hei\u00b7men", "Le\u00b7bens\u00b7gr\u00fcn\u00b7de", "schaun", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.13": {"line.1": {"text": "Und wie ein Sterbender sich st\u00f6hnend w\u00e4lzt", "tokens": ["Und", "wie", "ein", "Ster\u00b7ben\u00b7der", "sich", "st\u00f6h\u00b7nend", "w\u00e4lzt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "ART", "NN", "PRF", "ADJD", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Und seine Decken zuckend von sich st\u00f6\u00dft,", "tokens": ["Und", "sei\u00b7ne", "De\u00b7cken", "zu\u00b7ckend", "von", "sich", "st\u00f6\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVPP", "APPR", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "So hatte ", "tokens": ["So", "hat\u00b7te"], "token_info": ["word", "word"], "pos": ["ADV", "VAFIN"], "meter": "-+-", "measure": "amphibrach.single"}, "line.4": {"text": "Verh\u00fcllte Qual, bet\u00e4ubte Qual entbl\u00f6\u00dft.", "tokens": ["Ver\u00b7h\u00fcll\u00b7te", "Qual", ",", "be\u00b7t\u00e4ub\u00b7te", "Qual", "ent\u00b7bl\u00f6\u00dft", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.14": {"line.1": {"text": "Unsagbar widerw\u00e4rtig quoll es auf,", "tokens": ["Un\u00b7sag\u00b7bar", "wi\u00b7der\u00b7w\u00e4r\u00b7tig", "quoll", "es", "auf", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADJD", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.2": {"text": "Wie Wellen, Ekelwellen brachs herein,", "tokens": ["Wie", "Wel\u00b7len", ",", "E\u00b7kel\u00b7wel\u00b7len", "brachs", "her\u00b7ein", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "$,", "NN", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "So sinnlos leer und frierend kalt und \u00f6d,", "tokens": ["So", "sinn\u00b7los", "leer", "und", "frie\u00b7rend", "kalt", "und", "\u00f6d", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ADJD", "KON", "ADJD", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Ein Atemzug der \u00fcberreichsten Pein:", "tokens": ["Ein", "A\u00b7tem\u00b7zug", "der", "\u00fc\u00b7berr\u00b7eichs\u00b7ten", "Pein", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.15": {"line.1": {"text": "Als w\u00e4r des Lebens Inhalt ausgel\u00f6scht,", "tokens": ["Als", "w\u00e4r", "des", "Le\u00b7bens", "In\u00b7halt", "aus\u00b7ge\u00b7l\u00f6scht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VAFIN", "ART", "NN", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Das Heiligste gel\u00f6st in Qualm und Dunst ...", "tokens": ["Das", "Hei\u00b7ligs\u00b7te", "ge\u00b7l\u00f6st", "in", "Qualm", "und", "Dunst", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Verstehn, Gestalten, K\u00fcnstler sein, wozu?", "tokens": ["Ver\u00b7stehn", ",", "Ge\u00b7stal\u00b7ten", ",", "K\u00fcnst\u00b7ler", "sein", ",", "wo\u00b7zu", "?"], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["VVFIN", "$,", "NN", "$,", "NN", "VAINF", "$,", "PWAV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Wozu denn Leben? und wozu die Kunst?", "tokens": ["Wo\u00b7zu", "denn", "Le\u00b7ben", "?", "und", "wo\u00b7zu", "die", "Kunst", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "KON", "NN", "$.", "KON", "PWAV", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.16": {"line.1": {"text": "Erlognes an Erlognes, Wort an Wort", "tokens": ["Er\u00b7log\u00b7nes", "an", "Er\u00b7log\u00b7nes", ",", "Wort", "an", "Wort"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["FM.la", "FM.la", "FM.la", "$,", "NN", "APPR", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Wie bunte Steinchen aneinanderreihn!", "tokens": ["Wie", "bun\u00b7te", "Stein\u00b7chen", "an\u00b7ein\u00b7an\u00b7der\u00b7reihn", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Was wissen wir, wodurchs zusammenh\u00e4lt;", "tokens": ["Was", "wis\u00b7sen", "wir", ",", "wo\u00b7durchs", "zu\u00b7sam\u00b7men\u00b7h\u00e4lt", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "$,", "PWAV", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Und mu\u00df es so, und kann nicht anders sein?!", "tokens": ["Und", "mu\u00df", "es", "so", ",", "und", "kann", "nicht", "an\u00b7ders", "sein", "?!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "ADV", "$,", "KON", "VMFIN", "PTKNEG", "ADV", "VAINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.17": {"line.1": {"text": "Und w\u00e4r der Blick, mit dem wir es erschaun,", "tokens": ["Und", "w\u00e4r", "der", "Blick", ",", "mit", "dem", "wir", "es", "er\u00b7schaun", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ART", "NN", "$,", "APPR", "PRELS", "PPER", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Nur unser, unser der ertr\u00e4umte Schein!", "tokens": ["Nur", "un\u00b7ser", ",", "un\u00b7ser", "der", "er\u00b7tr\u00e4um\u00b7te", "Schein", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "PPOSAT", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Er ist es nicht, und was ich denke, ist,", "tokens": ["Er", "ist", "es", "nicht", ",", "und", "was", "ich", "den\u00b7ke", ",", "ist", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "PTKNEG", "$,", "KON", "PWS", "PPER", "VVFIN", "$,", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Ja, dieser Schrei ist Nachhall, ist nicht mein!", "tokens": ["Ja", ",", "die\u00b7ser", "Schrei", "ist", "Nach\u00b7hall", ",", "ist", "nicht", "mein", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PDAT", "NN", "VAFIN", "NN", "$,", "VAFIN", "PTKNEG", "PPOSAT", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.18": {"line.1": {"text": "Nur eins ist mein, wie's auch dem Tier geh\u00f6rt,", "tokens": ["Nur", "eins", "ist", "mein", ",", "wie's", "auch", "dem", "Tier", "ge\u00b7h\u00f6rt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "VAFIN", "PPOSAT", "$,", "VVFIN", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Ist nicht gespenstisch, keinem nachgef\u00fchlt;", "tokens": ["Ist", "nicht", "ge\u00b7spens\u00b7tisch", ",", "kei\u00b7nem", "nach\u00b7ge\u00b7f\u00fchlt", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "PTKNEG", "ADJD", "$,", "PIS", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Da\u00df mich bei deiner trostverschlo\u00dfnen Angst", "tokens": ["Da\u00df", "mich", "bei", "dei\u00b7ner", "trost\u00b7ver\u00b7schlo\u00df\u00b7nen", "Angst"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Ein seltsam dumpfes Mitleid hat durchw\u00fchlt.", "tokens": ["Ein", "selt\u00b7sam", "dum\u00b7pfes", "Mit\u00b7leid", "hat", "durch\u00b7w\u00fchlt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "ADJA", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.19": {"line.1": {"text": "Und da\u00df ich, selber ohne Trost und Rat,", "tokens": ["Und", "da\u00df", "ich", ",", "sel\u00b7ber", "oh\u00b7ne", "Trost", "und", "Rat", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "$,", "ADV", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Dich tr\u00f6sten wollte, wie ein Kind ein Kind,", "tokens": ["Dich", "tr\u00f6s\u00b7ten", "woll\u00b7te", ",", "wie", "ein", "Kind", "ein", "Kind", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVINF", "VMFIN", "$,", "PWAV", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Das nichts von unverstandnem Kummer wei\u00df,", "tokens": ["Das", "nichts", "von", "un\u00b7ver\u00b7stand\u00b7nem", "Kum\u00b7mer", "wei\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PIS", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Von Dingen, die unfa\u00dfbar in uns sind.", "tokens": ["Von", "Din\u00b7gen", ",", "die", "un\u00b7fa\u00df\u00b7bar", "in", "uns", "sind", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "PRELS", "ADJD", "APPR", "PPER", "VAFIN", "$."], "meter": "-+--+---+-", "measure": "iambic.tri.relaxed"}}, "stanza.20": {"line.1": {"text": "Das ist vielleicht das Letzte was uns bleibt,", "tokens": ["Das", "ist", "viel\u00b7leicht", "das", "Letz\u00b7te", "was", "uns", "bleibt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "ART", "ADJA", "PWS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Wenn der Gedanke ungedacht schon l\u00fcgt:", "tokens": ["Wenn", "der", "Ge\u00b7dan\u00b7ke", "un\u00b7ge\u00b7dacht", "schon", "l\u00fcgt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ADJD", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Da\u00df auf ein zitternd Herz das andre lauscht", "tokens": ["Da\u00df", "auf", "ein", "zit\u00b7ternd", "Herz", "das", "and\u00b7re", "lauscht"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "APPR", "ART", "ADJD", "NN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Und leisen Drucks zur Hand die Hand sich f\u00fcgt ...", "tokens": ["Und", "lei\u00b7sen", "Drucks", "zur", "Hand", "die", "Hand", "sich", "f\u00fcgt", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "APPRART", "NN", "ART", "NN", "PRF", "VVFIN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}}}}